{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Fetching activations from a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import git\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "rc_fonts = {\n",
    "    \"text.usetex\": True,\n",
    "    \"text.latex.preamble\": \"\\n\".join(\n",
    "        [r\"\\usepackage{libertine}\", r\"\\usepackage[libertine]{newtxmath}\", r\"\\usepackage{inconsolata}\"]\n",
    "    ),\n",
    "}\n",
    "mpl.rcParams.update(rc_fonts)\n",
    "plt.rcParams.update(rc_fonts)\n",
    "sns.set_theme(style=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Functions for loading model and fetching activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_tokenizer(model_name: str):\n",
    "    \"\"\"Load a pretrained model and tokenizer from huggingface.\n",
    "\n",
    "    Args:\n",
    "        model_name: The name of the pretrained model to load.\n",
    "\n",
    "    Returns:\n",
    "        model: The loaded model.\n",
    "        tokenizer: The loaded tokenizer.\n",
    "    \"\"\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.eval()\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_reprs(model, input_ids: torch.Tensor, bias_norms: list[int]):\n",
    "    bsz, seq_len = input_ids.shape\n",
    "\n",
    "    bias_results = {}\n",
    "\n",
    "    for in_idx, input in tqdm.notebook.tqdm(enumerate(input_ids), desc=\"inputs...\", total=bsz):\n",
    "        bias_results[in_idx] = {b: {} for b in bias_norms}\n",
    "\n",
    "        def emb_hook(self, inputs, output, bias, store_ctx):\n",
    "            b_u = torch.randn(model.config.d_model)\n",
    "            b = (b_u / torch.linalg.vector_norm(b_u)) * bias\n",
    "\n",
    "            b = b.to(output.device)\n",
    "\n",
    "            output = output + b.unsqueeze(0)\n",
    "            store_ctx[bias][\"before_raw\"] = output\n",
    "            store_ctx[bias][\"before\"] = torch.linalg.vector_norm(output).item()\n",
    "            return output\n",
    "\n",
    "        def trn_hook(self, inputs, output, bias, store_ctx):\n",
    "            output = output[0]\n",
    "            store_ctx[bias][\"after\"] = torch.linalg.vector_norm(output).item()\n",
    "            store_ctx[bias][\"after_raw\"] = output\n",
    "\n",
    "        for N in tqdm.notebook.tqdm(bias_norms, desc=\"Biases...\", leave=False):\n",
    "            handles = [\n",
    "                model.pico_decoder.embedding_proj.register_forward_hook(\n",
    "                    partial(emb_hook, bias=N, store_ctx=bias_results[in_idx])\n",
    "                ),\n",
    "                model.pico_decoder.layers[-1].register_forward_hook(\n",
    "                    partial(trn_hook, bias=N, store_ctx=bias_results[in_idx])\n",
    "                ),\n",
    "            ]\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                model(input.unsqueeze(0))\n",
    "\n",
    "            for handle in handles:\n",
    "                handle.remove()\n",
    "\n",
    "    return bias_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    r\"\\texttt{pico-relora}\": {\n",
    "        \"repo_url\": \"https://huggingface.co/yuvalw/pico-relora-tiny-v2-sn\",\n",
    "        \"commit_hash\": \"f567508a0d79eb738a23a117a6753650a9969405\",\n",
    "        \"clone_dir\": Path(\"../runs/rem-relora-tiny-20k\"),\n",
    "    },\n",
    "    r\"\\texttt{pico-decoder}\": {\n",
    "        \"repo_url\": \"https://huggingface.co/pico-lm/pico-decoder-tiny\",\n",
    "        \"commit_hash\": \"9c866480418eeeb9946b0aaf4318bcdde46db83f\",\n",
    "        \"clone_dir\": Path(\"../runs/rem-decoder-tiny-20k\"),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in models.values():\n",
    "    if not d[\"clone_dir\"].exists():\n",
    "        repo = git.Repo.clone_from(d[\"repo_url\"], d[\"clone_dir\"])\n",
    "    else:\n",
    "        repo = git.Repo(d[\"clone_dir\"])\n",
    "\n",
    "    repo.git.checkout(d[\"commit_hash\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-23 21:48:12,703] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to mps (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0523 21:48:12.901000 67203 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "for mname in models:\n",
    "    model, tokenizer = load_model_tokenizer(models[mname][\"clone_dir\"])\n",
    "    models[mname][\"model\"] = model.to(\"mps\")\n",
    "    models[mname][\"tokenizer\"] = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random indices, both models have the same tokenizer\n",
    "tokenizer = models[r\"\\texttt{pico-relora}\"][\"tokenizer\"]\n",
    "\n",
    "special_ids = set(tokenizer.added_tokens_decoder.keys())\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "valid_ids = [i for i in range(vocab_size) if i not in special_ids]\n",
    "\n",
    "# match godey\n",
    "batch_size = 16\n",
    "seq_len = 512\n",
    "\n",
    "random_ids = torch.stack(\n",
    "    [torch.tensor(np.random.choice(valid_ids, size=seq_len), dtype=torch.long) for _ in range(batch_size)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f15d1d7a48944978607bd656c1a021f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "inputs...:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1934f37bb2d14373b229ce32c2122073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8fa539f2e1a4817bb427b1a688b0abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effe9457ce8d446ea16d22bbcb3a8480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13d97f03efb4bb7ad5f550f9d61d43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f9f1fcc7bf45e3bce8f431bab951a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03dc44bb27b4fc681f10c00cfdf39e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d212729fbedc4485816bf4edb95845b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504df3d49554451c83a44589a59b15ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b892745230841dc80b8413a649ca6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e4149390e4a439a89e1691007b3f054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433579f1f88b4d3cac260bc6f0f8935f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95468c09155342a596a367c01e13a9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45565f094c324c50b0325fe20e1a14ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00c97f80ddb49699c7782060a25ccec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7385874ac63e4574b04f509cbe99a6eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5af13637cb495c96ae27429133bd00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c401e2a8619432ba1ef45b4c239e321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "inputs...:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94499ebea04248d1ab2dfa56db4a529d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12215756ebee4704be845ff09b2cf07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa20a4d141564478b0ddaeeb071cefa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b8cd301a5246c2b74f3cae1c0e76e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3836a37dbb244579836b3fabf6a205a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd8de33d0d049fc9a6938fc4cc2248d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788d0183801c4d319490a121016637f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd60186865f74bed8342894d6a6cc8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8128e526ecf04094a96f1cc9b00bf036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f650089c1f064da3ad3f8d0a84a732c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5971ef7ae4b74b0d9ecf8d7ce7bae650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf9532fc3fa41a0ad66673fd803de82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e537c6154709435aa52f9e0f6f5449e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e659479037c458f8e503aab37114d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6293b380c95489ab6ef91c6c5a1be0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f7861445fa4e358e4ffa49072e0558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Biases...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = {}\n",
    "for mname in models:\n",
    "    model = models[mname][\"model\"]\n",
    "    res = fetch_reprs(model, random_ids.to(model.device), range(0, 51, 5))\n",
    "    results[mname] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data to dataframe\n",
    "def _get_data():\n",
    "    for mname, model_dict in results.items():\n",
    "        for grp_idx, grp_dict in model_dict.items():\n",
    "            for bias_size, res_dict in grp_dict.items():\n",
    "                # remember that rows are the destination index that wants info from other tokens\n",
    "                # source tokens are being attended to\n",
    "                before = res_dict[\"before\"]\n",
    "                after = res_dict[\"after\"]\n",
    "                yield (mname, grp_idx, bias_size, before, after)\n",
    "\n",
    "\n",
    "data_df = pd.DataFrame(\n",
    "    _get_data(),\n",
    "    columns=[\"Model\", \"SeqId\", \"BiasNorm\", \"Before\", \"After\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_norm_data():\n",
    "    for row in data_df.groupby(by=[\"Model\", \"BiasNorm\"]).agg(\"mean\").reset_index().itertuples():\n",
    "        yield row.Model, row.BiasNorm, \"Input\", row.Before\n",
    "        yield row.Model, row.BiasNorm, \"Output\", row.After\n",
    "\n",
    "\n",
    "norm_data_df = pd.DataFrame(_get_norm_data(), columns=[\"Model\", \"BiasNorm\", \"When\", \"ReprNorm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#004D40\", \"#D81B60\"]\n",
    "palette = dict(zip([\"Input\", \"Output\"], colors))\n",
    "\n",
    "dodge = 0.4\n",
    "size = 8\n",
    "font_scale = 3\n",
    "\n",
    "sns.set_theme(font_scale=font_scale, rc={\"axes.grid\": \"True\", \"axes.grid.which\": \"both\"})\n",
    "\n",
    "g = sns.FacetGrid(\n",
    "    data=norm_data_df,\n",
    "    col=\"Model\",\n",
    "    # row=\"Component\",\n",
    "    height=8,\n",
    "    aspect=1,\n",
    "    sharey=True,\n",
    "    sharex=True,\n",
    "    margin_titles=False,\n",
    ")\n",
    "\n",
    "# g.set_titles(template=r\"Model = \\texttt{{{col_name}}}\")\n",
    "\n",
    "\n",
    "g.map_dataframe(sns.lineplot, x=\"BiasNorm\", y=\"ReprNorm\", hue=\"When\", palette=palette, markers=[\"s\", \"o\"])\n",
    "\n",
    "g.set_axis_labels(\"Checkpoint step / 1000\", \"PER\")\n",
    "\n",
    "for idx, ax in enumerate(g.axes.flat):\n",
    "    # steps = no[\"Step\"].unique()\n",
    "    # ax.set_xticks(steps)\n",
    "    if idx == 0:\n",
    "        ax.legend(bbox_to_anchor=(0, 1), loc=\"upper left\", ncols=2)\n",
    "\n",
    "plt.savefig(\"../graphs/anisotropy-norm.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f15401ba0f322aa12af871c8a7369e4b5c15cd04566131c2cee112fb01acfcde"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
