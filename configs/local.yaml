checkpointing:
  run_name: local
  qualify_run_name: true

  save_every_n_steps: 10

  save_checkpoint_repo_id: null # set to null to disable uploading checkpoints to HuggingFace Hub

  training:
    load_latest_checkpoint: false
  
  learning_dynamics:
    layer_suffixes: []

model:
  n_layers: 2

data:
  dataset: pico-lm/pretokenized-paloma-tinsy
  dataloader:
    full_batch_size: 1
    sub_batch_size: 1
    max_seq_len: 10
  
logging:
  experiment_tracker: null # set to null to disable experiment tracking

  log_every_n_steps: 10

training:
  fabric: 
    accelerator: mps

  learning_rate: 0.001
  max_steps: 10

  optimization:
    lr: 0.001
    lr_warmup_steps: 10

    gradient_accumulation_steps: 1

evaluation:
  evaluation_metrics: null