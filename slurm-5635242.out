sed: -e expression #1, char 1: unknown command: `â'
/var/spool/slurm/slurmd/job5635242/slurm_script: line 29: 4*: syntax error: operand expected (error token is "*")
Loading rhel8/default-amp
  Loading requirement: rhel8/slurm singularity/current rhel8/global cuda/11.4
    libpciaccess/0.16/gcc-9.4.0-6fonbj6 libiconv/1.16/gcc-9.4.0-ahebbov
    libxml2/2.9.12/gcc-9.4.0-gnknt5e ncurses/6.2/gcc-9.4.0-aiirok7
    hwloc/2.5.0/gcc-9.4.0-7sqomga libevent/2.1.12/gcc-9.4.0-hgny7cm
    numactl/2.0.14/gcc-9.4.0-52dwc6n cuda/11.4.0/gcc-9.4.0-3hnxhjt
    gdrcopy/2.2/gcc-9.4.0-e4igtfp knem/1.1.4/gcc-9.4.0-bpbxgva
    libnl/3.3.0/gcc-9.4.0-whwhrwb rdma-core/34.0/gcc-9.4.0-5eo5n2u
    ucx/1.11.1/gcc-9.4.0-lktqyl4 openmpi/4.1.1/gcc-9.4.0-epagguv

[1m[0;34m=== Git LFS Setup ===[0m

Hook already exists: pre-push

	#!/bin/sh
	command -v git-lfs >/dev/null 2>&1 || { printf >&2 "\n%s\n\n" "This repository is configured for Git LFS but 'git-lfs' was not found on your path. If you no longer wish to use Git LFS, remove this hook by deleting the 'pre-push' file in the hooks directory (set by 'core.hookspath'; usually '.git/hooks')."; exit 2; }
	git lfs pre-push "$@"

To resolve this, either:
  1: run `git lfs update --manual` for instructions on how to merge hooks.
  2: run `git lfs update --force` to overwrite your hook.
[0;32mâœ“ git-lfs installed and initialized[0m

[1m[0;34m=== CUDA Version Check ===[0m

[0;32mâœ“ CUDA version 12.4 detected[0m

[1m[0;34m=== Environment Variables ===[0m

[0;32mâœ“ Loading environment variables from .env...[0m
[0;32mâœ“ Both HF_TOKEN and WANDB_API_KEY are set and loaded![0m

[1m[0;34m=== Poetry Setup ===[0m

[0;32mâœ“ Poetry already installed[0m
[0;32mâœ“ Poetry environment already exists[0m

[1m[0;34m=== Pre-commit Setup ===[0m

Installing pre-commit hooks...
pre-commit installed at .git/hooks/pre-commit
[0;32mâœ“ Pre-commit hooks installed[0m
Running pre-commit hooks on all files...
[INFO] Initializing environment for https://github.com/astral-sh/ruff-pre-commit.
[INFO] Installing environment for https://github.com/astral-sh/ruff-pre-commit.
[INFO] Once installed this environment will be reused.
[INFO] This may take a few minutes...
ruff.....................................................................Failed
- hook id: ruff
- exit code: 1

src/training/utils/io.py:1:1: D100 Missing docstring in public module
src/training/utils/io.py:5:5: D417 Missing argument description in the docstring for `use_backoff`: `initial_delay`
  |
5 | def use_backoff(max_retries=10, initial_delay=1, backoff_factor=2):
  |     ^^^^^^^^^^^ D417
6 |     """
7 |     Universal retry wrapper with exponential backoff for any function, but primarily for loading
  |

Found 2 errors.

ruff-format..............................................................Failed
- hook id: ruff-format
- files were modified by this hook

1 file reformatted, 24 files left unchanged

[0;32mâœ“ Pre-commit initial run complete[0m

[1m[0;34m=== Setup Status ===[0m

[0;32mâœ“ Setup Complete! ðŸŽ‰[0m
[0;32mâœ“ To activate the virtual environment, run: poetry shell[0m
wandb: WARNING This integration is tested and supported for lightning Fabric 2.1.3.
wandb: WARNING             Please report any issues to https://github.com/wandb/wandb/issues with the tag `lightning-fabric`.
wandb: WARNING This integration is tested and supported for lightning Fabric 2.1.3.
wandb: WARNING             Please report any issues to https://github.com/wandb/wandb/issues with the tag `lightning-fabric`.
wandb: WARNING This integration is tested and supported for lightning Fabric 2.1.3.
wandb: WARNING             Please report any issues to https://github.com/wandb/wandb/issues with the tag `lightning-fabric`.
wandb: WARNING This integration is tested and supported for lightning Fabric 2.1.3.
wandb: WARNING             Please report any issues to https://github.com/wandb/wandb/issues with the tag `lightning-fabric`.
wandb: WARNING This integration is tested and supported for lightning Fabric 2.1.3.
wandb: WARNING             Please report any issues to https://github.com/wandb/wandb/issues with the tag `lightning-fabric`.
wandb: WARNING This integration is tested and supported for lightning Fabric 2.1.3.
wandb: WARNING             Please report any issues to https://github.com/wandb/wandb/issues with the tag `lightning-fabric`.
wandb: WARNING This integration is tested and supported for lightning Fabric 2.1.3.
wandb: WARNING             Please report any issues to https://github.com/wandb/wandb/issues with the tag `lightning-fabric`.
wandb: WARNING This integration is tested and supported for lightning Fabric 2.1.3.
wandb: WARNING             Please report any issues to https://github.com/wandb/wandb/issues with the tag `lightning-fabric`.
wandb: WARNING This integration is tested and supported for lightning Fabric 2.1.3.
wandb: WARNING             Please report any issues to https://github.com/wandb/wandb/issues with the tag `lightning-fabric`.
wandb: WARNING This integration is tested and supported for lightning Fabric 2.1.3.
wandb: WARNING             Please report any issues to https://github.com/wandb/wandb/issues with the tag `lightning-fabric`.
wandb: WARNING This integration is tested and supported for lightning Fabric 2.1.3.
wandb: WARNING             Please report any issues to https://github.com/wandb/wandb/issues with the tag `lightning-fabric`.
wandb: WARNING This integration is tested and supported for lightning Fabric 2.1.3.
wandb: WARNING             Please report any issues to https://github.com/wandb/wandb/issues with the tag `lightning-fabric`.
wandb: WARNING This integration is tested and supported for lightning Fabric 2.1.3.
wandb: WARNING             Please report any issues to https://github.com/wandb/wandb/issues with the tag `lightning-fabric`.
wandb: WARNING This integration is tested and supported for lightning Fabric 2.1.3.
wandb: WARNING             Please report any issues to https://github.com/wandb/wandb/issues with the tag `lightning-fabric`.
wandb: WARNING This integration is tested and supported for lightning Fabric 2.1.3.
wandb: WARNING             Please report any issues to https://github.com/wandb/wandb/issues with the tag `lightning-fabric`.
wandb: WARNING This integration is tested and supported for lightning Fabric 2.1.3.
wandb: WARNING             Please report any issues to https://github.com/wandb/wandb/issues with the tag `lightning-fabric`.
[2025-03-02 10:08:34,839] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-02 10:08:34,839] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-02 10:08:34,839] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-02 10:08:34,839] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-02 10:08:34,839] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-02 10:08:34,839] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-02 10:08:34,839] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-02 10:08:34,839] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-02 10:08:34,839] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-02 10:08:34,839] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-02 10:08:34,839] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-02 10:08:34,839] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-02 10:08:34,839] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-02 10:08:34,839] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-02 10:08:34,839] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-02 10:08:34,839] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/16
initializing deepspeed distributed: GLOBAL_RANK: 8, MEMBER: 9/16
initializing deepspeed distributed: GLOBAL_RANK: 4, MEMBER: 5/16
initializing deepspeed distributed: GLOBAL_RANK: 12, MEMBER: 13/16
initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/16
initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/16
initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/16
initializing deepspeed distributed: GLOBAL_RANK: 11, MEMBER: 12/16
initializing deepspeed distributed: GLOBAL_RANK: 6, MEMBER: 7/16
initializing deepspeed distributed: GLOBAL_RANK: 7, MEMBER: 8/16
initializing deepspeed distributed: GLOBAL_RANK: 5, MEMBER: 6/16
initializing deepspeed distributed: GLOBAL_RANK: 15, MEMBER: 16/16
initializing deepspeed distributed: GLOBAL_RANK: 10, MEMBER: 11/16
initializing deepspeed distributed: GLOBAL_RANK: 13, MEMBER: 14/16
initializing deepspeed distributed: GLOBAL_RANK: 9, MEMBER: 10/16
initializing deepspeed distributed: GLOBAL_RANK: 14, MEMBER: 15/16
Enabling DeepSpeed BF16. Model parameters and inputs will be cast to `bfloat16`.
gpu-q-9:206472:206472 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-9:206472:206472 [0] NCCL INFO Bootstrap : Using eno8303:10.43.74.9<0>
gpu-q-9:206472:206472 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gpu-q-9:206472:206472 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gpu-q-9:206472:206472 [0] NCCL INFO NET/Plugin: Using internal network plugin.
gpu-q-9:206472:206472 [0] NCCL INFO cudaDriverVersion 12040
NCCL version 2.21.5+cuda12.4
gpu-q-9:206472:206832 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
gpu-q-9:206472:206832 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-9:206472:206832 [0] NCCL INFO NCCL_IB_HCA set to mlx5
gpu-q-9:206472:206832 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_3:1/IB [RO]; OOB eno8303:10.43.74.9<0>
gpu-q-9:206472:206832 [0] NCCL INFO Using non-device net plugin version 0
gpu-q-9:206472:206832 [0] NCCL INFO Using network IB
gpu-q-9:206472:206832 [0] NCCL INFO ncclCommInitRank comm 0x565455965680 rank 0 nranks 16 cudaDev 0 nvmlDev 0 busId 1000 commId 0xab369c58f444f4f9 - Init START
gpu-q-9:206472:206832 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000
gpu-q-9:206472:206832 [0] NCCL INFO NVLS multicast support is not available on dev 0
gpu-q-9:206472:206832 [0] NCCL INFO comm 0x565455965680 rank 0 nRanks 16 nNodes 4 localRanks 4 localRank 0 MNNVL 0
gpu-q-9:206472:206832 [0] NCCL INFO Channel 00/08 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
gpu-q-9:206472:206832 [0] NCCL INFO Channel 01/08 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
gpu-q-9:206472:206832 [0] NCCL INFO Channel 02/08 :    0   3   1   6   4   7   5  10   8  11   9  14  12  15  13   2
gpu-q-9:206472:206832 [0] NCCL INFO Channel 03/08 :    0   3   1   6   4   7   5  10   8  11   9  14  12  15  13   2
gpu-q-9:206472:206832 [0] NCCL INFO Channel 04/08 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
gpu-q-9:206472:206832 [0] NCCL INFO Channel 05/08 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
gpu-q-9:206472:206832 [0] NCCL INFO Channel 06/08 :    0   3   1   6   4   7   5  10   8  11   9  14  12  15  13   2
gpu-q-9:206472:206832 [0] NCCL INFO Channel 07/08 :    0   3   1   6   4   7   5  10   8  11   9  14  12  15  13   2
gpu-q-9:206472:206832 [0] NCCL INFO Trees [0] 1/8/-1->0->-1 [1] 1/8/-1->0->-1 [2] 1/-1/-1->0->3 [3] -1/-1/-1->0->2 [4] 1/-1/-1->0->4 [5] 1/-1/-1->0->4 [6] 1/-1/-1->0->3 [7] -1/-1/-1->0->2
gpu-q-9:206472:206832 [0] NCCL INFO P2P Chunksize set to 131072
gpu-q-9:206472:206832 [0] NCCL INFO Channel 00/0 : 15[3] -> 0[0] [receive] via NET/IB/0
gpu-q-9:206472:206832 [0] NCCL INFO Channel 01/0 : 15[3] -> 0[0] [receive] via NET/IB/1
gpu-q-9:206472:206832 [0] NCCL INFO Channel 04/0 : 15[3] -> 0[0] [receive] via NET/IB/0
gpu-q-9:206472:206832 [0] NCCL INFO Channel 05/0 : 15[3] -> 0[0] [receive] via NET/IB/1
gpu-q-9:206472:206832 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206472:206832 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206472:206832 [0] NCCL INFO Channel 04/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206472:206832 [0] NCCL INFO Channel 05/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206472:206832 [0] NCCL INFO Channel 02/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206472:206832 [0] NCCL INFO Channel 03/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206472:206832 [0] NCCL INFO Channel 06/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206472:206832 [0] NCCL INFO Channel 07/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206472:206832 [0] NCCL INFO Connected all rings
gpu-q-9:206472:206832 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206472:206832 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206472:206832 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206472:206832 [0] NCCL INFO Channel 07/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206472:206832 [0] NCCL INFO Channel 04/0 : 0[0] -> 4[0] [send] via NET/IB/0
gpu-q-9:206472:206832 [0] NCCL INFO Channel 05/0 : 0[0] -> 4[0] [send] via NET/IB/1
gpu-q-9:206472:206832 [0] NCCL INFO Channel 00/0 : 8[0] -> 0[0] [receive] via NET/IB/0
gpu-q-9:206472:206832 [0] NCCL INFO Channel 01/0 : 8[0] -> 0[0] [receive] via NET/IB/1
gpu-q-35:2680339:2680339 [0] NCCL INFO cudaDriverVersion 12040
gpu-q-35:2680339:2680339 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-35:2680339:2680339 [0] NCCL INFO Bootstrap : Using eno8303:10.43.74.53<0>
gpu-q-35:2680339:2680339 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gpu-q-35:2680339:2680339 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gpu-q-35:2680339:2680339 [0] NCCL INFO NET/Plugin: Using internal network plugin.
gpu-q-35:2680339:2680697 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
gpu-q-35:2680339:2680697 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-35:2680339:2680697 [0] NCCL INFO NCCL_IB_HCA set to mlx5
gpu-q-35:2680339:2680697 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB eno8303:10.43.74.53<0>
gpu-q-35:2680339:2680697 [0] NCCL INFO Using non-device net plugin version 0
gpu-q-9:206472:206832 [0] NCCL INFO Channel 00/0 : 0[0] -> 8[0] [send] via NET/IB/0
gpu-q-9:206472:206832 [0] NCCL INFO Channel 01/0 : 0[0] -> 8[0] [send] via NET/IB/1
gpu-q-35:2680339:2680697 [0] NCCL INFO Using network IB
gpu-q-35:2680339:2680697 [0] NCCL INFO ncclCommInitRank comm 0x55ccea88a700 rank 8 nranks 16 cudaDev 0 nvmlDev 0 busId 1000 commId 0xab369c58f444f4f9 - Init START
gpu-q-35:2680339:2680697 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000
gpu-q-35:2680339:2680697 [0] NCCL INFO NVLS multicast support is not available on dev 0
gpu-q-35:2680339:2680697 [0] NCCL INFO comm 0x55ccea88a700 rank 8 nRanks 16 nNodes 4 localRanks 4 localRank 0 MNNVL 0
gpu-q-35:2680339:2680697 [0] NCCL INFO Trees [0] 9/12/-1->8->0 [1] 9/12/-1->8->0 [2] 9/-1/-1->8->11 [3] -1/-1/-1->8->10 [4] 9/-1/-1->8->5 [5] 9/-1/-1->8->5 [6] 9/-1/-1->8->11 [7] -1/-1/-1->8->10
gpu-q-35:2680339:2680697 [0] NCCL INFO P2P Chunksize set to 131072
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 00/0 : 7[3] -> 8[0] [receive] via NET/IB/0
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 01/0 : 7[3] -> 8[0] [receive] via NET/IB/1
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 04/0 : 7[3] -> 8[0] [receive] via NET/IB/0
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 05/0 : 7[3] -> 8[0] [receive] via NET/IB/1
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 00/0 : 8[0] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 01/0 : 8[0] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 04/0 : 8[0] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 05/0 : 8[0] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 02/0 : 8[0] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 03/0 : 8[0] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 06/0 : 8[0] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 07/0 : 8[0] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680339:2680697 [0] NCCL INFO Connected all rings
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 02/0 : 8[0] -> 9[1] via P2P/CUMEM/read
gpu-q-29:272945:272945 [0] NCCL INFO cudaDriverVersion 12040
gpu-q-29:272945:272945 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-29:272945:272945 [0] NCCL INFO Bootstrap : Using eno8303:10.43.74.41<0>
gpu-q-29:272945:272945 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gpu-q-29:272945:272945 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gpu-q-29:272945:272945 [0] NCCL INFO NET/Plugin: Using internal network plugin.
gpu-q-29:272945:273307 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
gpu-q-29:272945:273307 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-29:272945:273307 [0] NCCL INFO NCCL_IB_HCA set to mlx5
gpu-q-29:272945:273307 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_3:1/IB [RO]; OOB eno8303:10.43.74.41<0>
gpu-q-29:272945:273307 [0] NCCL INFO Using non-device net plugin version 0
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 06/0 : 8[0] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 03/0 : 8[0] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 07/0 : 8[0] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 04/0 : 5[1] -> 8[0] [receive] via NET/IB/0
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 05/0 : 5[1] -> 8[0] [receive] via NET/IB/1
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 00/0 : 8[0] -> 12[0] [send] via NET/IB/0
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 01/0 : 8[0] -> 12[0] [send] via NET/IB/1
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 00/0 : 0[0] -> 8[0] [receive] via NET/IB/0
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 01/0 : 0[0] -> 8[0] [receive] via NET/IB/1
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 00/0 : 8[0] -> 0[0] [send] via NET/IB/0
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 01/0 : 8[0] -> 0[0] [send] via NET/IB/1
gpu-q-29:272945:273307 [0] NCCL INFO Using network IB
gpu-q-29:272945:273307 [0] NCCL INFO ncclCommInitRank comm 0x5586e6932dc0 rank 4 nranks 16 cudaDev 0 nvmlDev 0 busId 1000 commId 0xab369c58f444f4f9 - Init START
gpu-q-29:272945:273307 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000
gpu-q-29:272945:273307 [0] NCCL INFO NVLS multicast support is not available on dev 0
gpu-q-29:272945:273307 [0] NCCL INFO comm 0x5586e6932dc0 rank 4 nRanks 16 nNodes 4 localRanks 4 localRank 0 MNNVL 0
gpu-q-29:272945:273307 [0] NCCL INFO Trees [0] 5/-1/-1->4->9 [1] 5/-1/-1->4->9 [2] 5/-1/-1->4->7 [3] -1/-1/-1->4->6 [4] 5/0/-1->4->12 [5] 5/0/-1->4->12 [6] 5/-1/-1->4->7 [7] -1/-1/-1->4->6
gpu-q-29:272945:273307 [0] NCCL INFO P2P Chunksize set to 131072
gpu-q-29:272945:273307 [0] NCCL INFO Channel 00/0 : 3[3] -> 4[0] [receive] via NET/IB/0
gpu-q-29:272945:273307 [0] NCCL INFO Channel 01/0 : 3[3] -> 4[0] [receive] via NET/IB/1
gpu-q-29:272945:273307 [0] NCCL INFO Channel 04/0 : 3[3] -> 4[0] [receive] via NET/IB/0
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 00/0 : 12[0] -> 8[0] [receive] via NET/IB/0
gpu-q-29:272945:273307 [0] NCCL INFO Channel 05/0 : 3[3] -> 4[0] [receive] via NET/IB/1
gpu-q-29:272945:273307 [0] NCCL INFO Channel 00/0 : 4[0] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272945:273307 [0] NCCL INFO Channel 01/0 : 4[0] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272945:273307 [0] NCCL INFO Channel 04/0 : 4[0] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272945:273307 [0] NCCL INFO Channel 05/0 : 4[0] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272945:273307 [0] NCCL INFO Channel 02/0 : 4[0] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272945:273307 [0] NCCL INFO Channel 03/0 : 4[0] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272945:273307 [0] NCCL INFO Channel 06/0 : 4[0] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272945:273307 [0] NCCL INFO Channel 07/0 : 4[0] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272945:273307 [0] NCCL INFO Connected all rings
gpu-q-29:272945:273307 [0] NCCL INFO Channel 02/0 : 4[0] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272945:273307 [0] NCCL INFO Channel 06/0 : 4[0] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272945:273307 [0] NCCL INFO Channel 03/0 : 4[0] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272945:273307 [0] NCCL INFO Channel 07/0 : 4[0] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272945:273307 [0] NCCL INFO Channel 04/0 : 0[0] -> 4[0] [receive] via NET/IB/0
gpu-q-29:272945:273307 [0] NCCL INFO Channel 05/0 : 0[0] -> 4[0] [receive] via NET/IB/1
gpu-q-29:272945:273307 [0] NCCL INFO Channel 00/0 : 4[0] -> 9[1] [send] via NET/IB/0
gpu-q-29:272945:273307 [0] NCCL INFO Channel 01/0 : 4[0] -> 9[1] [send] via NET/IB/1
gpu-q-29:272945:273307 [0] NCCL INFO Channel 04/0 : 12[0] -> 4[0] [receive] via NET/IB/0
gpu-q-29:272945:273307 [0] NCCL INFO Channel 05/0 : 12[0] -> 4[0] [receive] via NET/IB/1
gpu-q-29:272945:273307 [0] NCCL INFO Channel 04/0 : 4[0] -> 12[0] [send] via NET/IB/0
gpu-q-29:272945:273307 [0] NCCL INFO Channel 05/0 : 4[0] -> 12[0] [send] via NET/IB/1
gpu-q-29:272945:273307 [0] NCCL INFO Channel 00/0 : 9[1] -> 4[0] [receive] via NET/IB/0
gpu-q-29:272945:273307 [0] NCCL INFO Channel 01/0 : 9[1] -> 4[0] [receive] via NET/IB/1
gpu-q-35:2680341:2680341 [2] NCCL INFO cudaDriverVersion 12040
gpu-q-35:2680341:2680341 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-35:2680341:2680341 [2] NCCL INFO Bootstrap : Using eno8303:10.43.74.53<0>
gpu-q-35:2680341:2680341 [2] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gpu-q-35:2680341:2680341 [2] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gpu-q-35:2680341:2680341 [2] NCCL INFO NET/Plugin: Using internal network plugin.
gpu-q-35:2680341:2680698 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
gpu-q-35:2680341:2680698 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-35:2680341:2680698 [2] NCCL INFO NCCL_IB_HCA set to mlx5
gpu-q-35:2680341:2680698 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB eno8303:10.43.74.53<0>
gpu-q-35:2680341:2680698 [2] NCCL INFO Using non-device net plugin version 0
gpu-q-35:2680341:2680698 [2] NCCL INFO Using network IB
gpu-q-35:2680341:2680698 [2] NCCL INFO ncclCommInitRank comm 0x557ccb6f3980 rank 10 nranks 16 cudaDev 2 nvmlDev 2 busId 81000 commId 0xab369c58f444f4f9 - Init START
gpu-q-35:2680341:2680698 [2] NCCL INFO Setting affinity for GPU 2 to ffff0000,00000000,00000000,00000000
gpu-q-35:2680341:2680698 [2] NCCL INFO NVLS multicast support is not available on dev 2
gpu-q-35:2680341:2680698 [2] NCCL INFO comm 0x557ccb6f3980 rank 10 nRanks 16 nNodes 4 localRanks 4 localRank 2 MNNVL 0
gpu-q-35:2680341:2680698 [2] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 11/-1/-1->10->9 [2] 11/14/-1->10->2 [3] 8/-1/-1->10->9 [4] 11/-1/-1->10->9 [5] 11/-1/-1->10->9 [6] 11/-1/-1->10->7 [7] 8/-1/-1->10->9
gpu-q-35:2680341:2680698 [2] NCCL INFO P2P Chunksize set to 131072
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 00/0 : 10[2] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 01/0 : 10[2] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 04/0 : 10[2] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 05/0 : 10[2] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 02/0 : 5[1] -> 10[2] [receive] via NET/IB/0
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 03/0 : 5[1] -> 10[2] [receive] via NET/IB/1
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 06/0 : 5[1] -> 10[2] [receive] via NET/IB/0
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 07/0 : 5[1] -> 10[2] [receive] via NET/IB/1
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 02/0 : 10[2] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 03/0 : 10[2] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 06/0 : 10[2] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 07/0 : 10[2] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680341:2680698 [2] NCCL INFO Connected all rings
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 02/0 : 10[2] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 06/0 : 10[2] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 06/0 : 7[3] -> 10[2] [receive] via NET/IB/0
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 02/0 : 10[2] -> 14[2] [send] via NET/IB/0
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 02/0 : 2[2] -> 10[2] [receive] via NET/IB/0
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 02/0 : 10[2] -> 2[2] [send] via NET/IB/0
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 02/0 : 14[2] -> 10[2] [receive] via NET/IB/0
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 06/0 : 10[2] -> 7[3] [send] via NET/IB/0
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 00/0 : 10[2] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 01/0 : 10[2] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 03/0 : 10[2] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 04/0 : 10[2] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 05/0 : 10[2] -> 9[1] via P2P/CUMEM/read
gpu-q-9:206474:206474 [2] NCCL INFO cudaDriverVersion 12040
gpu-q-9:206474:206474 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-9:206474:206474 [2] NCCL INFO Bootstrap : Using eno8303:10.43.74.9<0>
gpu-q-9:206474:206474 [2] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gpu-q-9:206474:206474 [2] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gpu-q-9:206474:206474 [2] NCCL INFO NET/Plugin: Using internal network plugin.
gpu-q-9:206474:206835 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
gpu-q-9:206474:206835 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-9:206474:206835 [2] NCCL INFO NCCL_IB_HCA set to mlx5
gpu-q-9:206474:206835 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_3:1/IB [RO]; OOB eno8303:10.43.74.9<0>
gpu-q-9:206474:206835 [2] NCCL INFO Using non-device net plugin version 0
gpu-q-9:206474:206835 [2] NCCL INFO Using network IB
gpu-q-9:206474:206835 [2] NCCL INFO ncclCommInitRank comm 0x55d159a68f00 rank 2 nranks 16 cudaDev 2 nvmlDev 2 busId 81000 commId 0xab369c58f444f4f9 - Init START
gpu-q-9:206474:206835 [2] NCCL INFO Setting affinity for GPU 2 to ffff0000,00000000,00000000,00000000
gpu-q-9:206474:206835 [2] NCCL INFO NVLS multicast support is not available on dev 2
gpu-q-9:206474:206835 [2] NCCL INFO comm 0x55d159a68f00 rank 2 nRanks 16 nNodes 4 localRanks 4 localRank 2 MNNVL 0
gpu-q-9:206474:206835 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/10/-1->2->-1 [3] 0/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->6 [7] 0/-1/-1->2->1
gpu-q-9:206474:206835 [2] NCCL INFO P2P Chunksize set to 131072
gpu-q-9:206474:206835 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206474:206835 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206474:206835 [2] NCCL INFO Channel 04/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gpu-q-29:272946:272946 [1] NCCL INFO cudaDriverVersion 12040
gpu-q-29:272946:272946 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-29:272946:272946 [1] NCCL INFO Bootstrap : Using eno8303:10.43.74.41<0>
gpu-q-29:272946:272946 [1] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gpu-q-29:272946:272946 [1] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gpu-q-29:272946:272946 [1] NCCL INFO NET/Plugin: Using internal network plugin.
gpu-q-29:272946:273305 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
gpu-q-29:272946:273305 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-29:272946:273305 [1] NCCL INFO NCCL_IB_HCA set to mlx5
gpu-q-29:272946:273305 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_3:1/IB [RO]; OOB eno8303:10.43.74.41<0>
gpu-q-29:272946:273305 [1] NCCL INFO Using non-device net plugin version 0
gpu-q-9:206474:206835 [2] NCCL INFO Channel 05/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206474:206835 [2] NCCL INFO Channel 02/0 : 13[1] -> 2[2] [receive] via NET/IB/2
gpu-q-9:206474:206835 [2] NCCL INFO Channel 03/0 : 13[1] -> 2[2] [receive] via NET/IB/0
gpu-q-9:206474:206835 [2] NCCL INFO Channel 06/0 : 13[1] -> 2[2] [receive] via NET/IB/2
gpu-q-9:206474:206835 [2] NCCL INFO Channel 07/0 : 13[1] -> 2[2] [receive] via NET/IB/0
gpu-q-9:206474:206835 [2] NCCL INFO Channel 02/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206474:206835 [2] NCCL INFO Channel 03/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206474:206835 [2] NCCL INFO Channel 06/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206474:206835 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206474:206835 [2] NCCL INFO Connected all rings
gpu-q-9:206474:206835 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206474:206835 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gpu-q-35:2680342:2680342 [3] NCCL INFO cudaDriverVersion 12040
gpu-q-35:2680342:2680342 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-35:2680342:2680342 [3] NCCL INFO Bootstrap : Using eno8303:10.43.74.53<0>
gpu-q-35:2680342:2680342 [3] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gpu-q-35:2680342:2680342 [3] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gpu-q-35:2680342:2680342 [3] NCCL INFO NET/Plugin: Using internal network plugin.
gpu-q-35:2680342:2680700 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
gpu-q-35:2680342:2680700 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-35:2680342:2680700 [3] NCCL INFO NCCL_IB_HCA set to mlx5
gpu-q-35:2680342:2680700 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB eno8303:10.43.74.53<0>
gpu-q-35:2680342:2680700 [3] NCCL INFO Using non-device net plugin version 0
gpu-q-29:272946:273305 [1] NCCL INFO Using network IB
gpu-q-29:272946:273305 [1] NCCL INFO ncclCommInitRank comm 0x5558aedaef00 rank 5 nranks 16 cudaDev 1 nvmlDev 1 busId 41000 commId 0xab369c58f444f4f9 - Init START
gpu-q-29:272946:273305 [1] NCCL INFO Setting affinity for GPU 1 to ffff0000
gpu-q-29:272946:273305 [1] NCCL INFO NVLS multicast support is not available on dev 1
gpu-q-29:272946:273305 [1] NCCL INFO comm 0x5558aedaef00 rank 5 nRanks 16 nNodes 4 localRanks 4 localRank 1 MNNVL 0
gpu-q-29:272946:273305 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] -1/-1/-1->5->4 [3] 6/-1/-1->5->7 [4] 6/8/-1->5->4 [5] 6/8/-1->5->4 [6] -1/-1/-1->5->4 [7] 6/11/-1->5->7
gpu-q-29:272946:273305 [1] NCCL INFO P2P Chunksize set to 131072
gpu-q-29:272946:273305 [1] NCCL INFO Channel 00/0 : 5[1] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272946:273305 [1] NCCL INFO Channel 01/0 : 5[1] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272946:273305 [1] NCCL INFO Channel 04/0 : 5[1] -> 6[2] via P2P/CUMEM/read
gpu-q-9:206474:206835 [2] NCCL INFO Channel 06/0 : 2[2] -> 6[2] [send] via NET/IB/2
gpu-q-9:206474:206835 [2] NCCL INFO Channel 02/0 : 10[2] -> 2[2] [receive] via NET/IB/2
gpu-q-9:206474:206835 [2] NCCL INFO Channel 02/0 : 2[2] -> 10[2] [send] via NET/IB/2
gpu-q-9:206474:206835 [2] NCCL INFO Channel 06/0 : 6[2] -> 2[2] [receive] via NET/IB/2
gpu-q-9:206474:206835 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206474:206835 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206474:206835 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206474:206835 [2] NCCL INFO Channel 04/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206474:206835 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206474:206835 [2] NCCL INFO Channel 07/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206474:206835 [2] NCCL INFO Connected all trees
gpu-q-9:206474:206835 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-35:2680342:2680700 [3] NCCL INFO Using network IB
gpu-q-35:2680342:2680700 [3] NCCL INFO ncclCommInitRank comm 0x55d745510980 rank 11 nranks 16 cudaDev 3 nvmlDev 3 busId c1000 commId 0xab369c58f444f4f9 - Init START
gpu-q-35:2680342:2680700 [3] NCCL INFO Setting affinity for GPU 3 to ffff0000,00000000,00000000
gpu-q-35:2680342:2680700 [3] NCCL INFO NVLS multicast support is not available on dev 3
gpu-q-35:2680342:2680700 [3] NCCL INFO comm 0x55d745510980 rank 11 nRanks 16 nNodes 4 localRanks 4 localRank 3 MNNVL 0
gpu-q-35:2680342:2680700 [3] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] -1/-1/-1->11->10 [2] 8/6/-1->11->10 [3] 9/15/-1->11->3 [4] -1/-1/-1->11->10 [5] -1/-1/-1->11->10 [6] 8/-1/-1->11->10 [7] 9/-1/-1->11->5
gpu-q-35:2680342:2680700 [3] NCCL INFO P2P Chunksize set to 131072
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 00/0 : 11[3] -> 12[0] [send] via NET/IB/0
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 01/0 : 11[3] -> 12[0] [send] via NET/IB/1
gpu-q-29:272946:273305 [1] NCCL INFO Channel 05/0 : 5[1] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272946:273305 [1] NCCL INFO Channel 02/0 : 5[1] -> 10[2] [send] via NET/IB/2
gpu-q-29:272946:273305 [1] NCCL INFO Channel 03/0 : 5[1] -> 10[2] [send] via NET/IB/0
gpu-q-29:272946:273305 [1] NCCL INFO Channel 06/0 : 5[1] -> 10[2] [send] via NET/IB/2
gpu-q-29:272946:273305 [1] NCCL INFO Channel 07/0 : 5[1] -> 10[2] [send] via NET/IB/0
gpu-q-29:272946:273305 [1] NCCL INFO Connected all rings
gpu-q-29:272946:273305 [1] NCCL INFO Channel 03/0 : 5[1] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272946:273305 [1] NCCL INFO Channel 07/0 : 5[1] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272946:273305 [1] NCCL INFO Channel 03/0 : 5[1] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272946:273305 [1] NCCL INFO Channel 07/0 : 5[1] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272946:273305 [1] NCCL INFO Channel 04/0 : 5[1] -> 8[0] [send] via NET/IB/0
gpu-q-29:272946:273305 [1] NCCL INFO Channel 05/0 : 5[1] -> 8[0] [send] via NET/IB/1
gpu-q-49:1203803:1203803 [0] NCCL INFO cudaDriverVersion 12040
gpu-q-49:1203803:1203803 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-49:1203803:1203803 [0] NCCL INFO Bootstrap : Using eno8303:10.43.74.73<0>
gpu-q-49:1203803:1203803 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gpu-q-49:1203803:1203803 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gpu-q-49:1203803:1203803 [0] NCCL INFO NET/Plugin: Using internal network plugin.
gpu-q-49:1203803:1204157 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
gpu-q-49:1203803:1204157 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-49:1203803:1204157 [0] NCCL INFO NCCL_IB_HCA set to mlx5
gpu-q-49:1203803:1204157 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB eno8303:10.43.74.73<0>
gpu-q-49:1203803:1204157 [0] NCCL INFO Using non-device net plugin version 0
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 04/0 : 11[3] -> 12[0] [send] via NET/IB/0
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 05/0 : 11[3] -> 12[0] [send] via NET/IB/1
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 02/0 : 11[3] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 03/0 : 11[3] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 06/0 : 11[3] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 07/0 : 11[3] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680342:2680700 [3] NCCL INFO Connected all rings
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 03/0 : 11[3] -> 15[3] [send] via NET/IB/1
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 02/0 : 6[2] -> 11[3] [receive] via NET/IB/0
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 07/0 : 5[1] -> 11[3] [receive] via NET/IB/1
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 03/0 : 3[3] -> 11[3] [receive] via NET/IB/1
gpu-q-29:272946:273305 [1] NCCL INFO Channel 07/0 : 5[1] -> 11[3] [send] via NET/IB/0
gpu-q-29:272946:273305 [1] NCCL INFO Channel 07/0 : 11[3] -> 5[1] [receive] via NET/IB/0
gpu-q-29:272946:273305 [1] NCCL INFO Channel 04/0 : 8[0] -> 5[1] [receive] via NET/IB/0
gpu-q-29:272946:273305 [1] NCCL INFO Channel 05/0 : 8[0] -> 5[1] [receive] via NET/IB/1
gpu-q-29:272946:273305 [1] NCCL INFO Channel 00/0 : 5[1] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272946:273305 [1] NCCL INFO Channel 01/0 : 5[1] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272946:273305 [1] NCCL INFO Channel 02/0 : 5[1] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272946:273305 [1] NCCL INFO Channel 04/0 : 5[1] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272946:273305 [1] NCCL INFO Channel 05/0 : 5[1] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272946:273305 [1] NCCL INFO Channel 06/0 : 5[1] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272946:273305 [1] NCCL INFO Connected all trees
gpu-q-29:272946:273305 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-49:1203803:1204157 [0] NCCL INFO Using network IB
gpu-q-49:1203803:1204157 [0] NCCL INFO ncclCommInitRank comm 0x558a03ac4f80 rank 12 nranks 16 cudaDev 0 nvmlDev 0 busId 1000 commId 0xab369c58f444f4f9 - Init START
gpu-q-49:1203803:1204157 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000
gpu-q-49:1203803:1204157 [0] NCCL INFO NVLS multicast support is not available on dev 0
gpu-q-49:1203803:1204157 [0] NCCL INFO comm 0x558a03ac4f80 rank 12 nRanks 16 nNodes 4 localRanks 4 localRank 0 MNNVL 0
gpu-q-49:1203803:1204157 [0] NCCL INFO Trees [0] 13/-1/-1->12->8 [1] 13/-1/-1->12->8 [2] 13/-1/-1->12->15 [3] -1/-1/-1->12->14 [4] 13/4/-1->12->-1 [5] 13/4/-1->12->-1 [6] 13/-1/-1->12->15 [7] -1/-1/-1->12->14
gpu-q-49:1203803:1204157 [0] NCCL INFO P2P Chunksize set to 131072
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 00/0 : 11[3] -> 12[0] [receive] via NET/IB/0
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 01/0 : 11[3] -> 12[0] [receive] via NET/IB/1
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 03/0 : 11[3] -> 3[3] [send] via NET/IB/1
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 07/0 : 11[3] -> 5[1] [send] via NET/IB/1
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 02/0 : 11[3] -> 6[2] [send] via NET/IB/0
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 03/0 : 15[3] -> 11[3] [receive] via NET/IB/1
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 02/0 : 11[3] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 06/0 : 11[3] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 00/0 : 11[3] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 01/0 : 11[3] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 02/0 : 11[3] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 04/0 : 11[3] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 05/0 : 11[3] -> 10[2] via P2P/CUMEM/read
gpu-q-29:272947:272947 [2] NCCL INFO cudaDriverVersion 12040
gpu-q-29:272947:272947 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-29:272947:272947 [2] NCCL INFO Bootstrap : Using eno8303:10.43.74.41<0>
gpu-q-29:272947:272947 [2] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gpu-q-29:272947:272947 [2] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gpu-q-29:272947:272947 [2] NCCL INFO NET/Plugin: Using internal network plugin.
gpu-q-29:272947:273306 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
gpu-q-29:272947:273306 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-29:272947:273306 [2] NCCL INFO NCCL_IB_HCA set to mlx5
gpu-q-29:272947:273306 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_3:1/IB [RO]; OOB eno8303:10.43.74.41<0>
gpu-q-29:272947:273306 [2] NCCL INFO Using non-device net plugin version 0
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 04/0 : 11[3] -> 12[0] [receive] via NET/IB/0
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 05/0 : 11[3] -> 12[0] [receive] via NET/IB/1
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 00/0 : 12[0] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 01/0 : 12[0] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 04/0 : 12[0] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 05/0 : 12[0] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 02/0 : 12[0] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 03/0 : 12[0] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 06/0 : 12[0] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 07/0 : 12[0] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203803:1204157 [0] NCCL INFO Connected all rings
gpu-q-35:2680342:2680700 [3] NCCL INFO Channel 06/0 : 11[3] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680342:2680700 [3] NCCL INFO Connected all trees
gpu-q-29:272947:273306 [2] NCCL INFO Using network IB
gpu-q-29:272947:273306 [2] NCCL INFO ncclCommInitRank comm 0x5602f9b91000 rank 6 nranks 16 cudaDev 2 nvmlDev 2 busId 81000 commId 0xab369c58f444f4f9 - Init START
gpu-q-29:272947:273306 [2] NCCL INFO Setting affinity for GPU 2 to ffff0000,00000000,00000000,00000000
gpu-q-29:272947:273306 [2] NCCL INFO NVLS multicast support is not available on dev 2
gpu-q-29:272947:273306 [2] NCCL INFO comm 0x5602f9b91000 rank 6 nRanks 16 nNodes 4 localRanks 4 localRank 2 MNNVL 0
gpu-q-29:272947:273306 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->11 [3] 4/-1/-1->6->5 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/2/-1->6->14 [7] 4/-1/-1->6->5
gpu-q-29:272947:273306 [2] NCCL INFO P2P Chunksize set to 131072
gpu-q-29:272947:273306 [2] NCCL INFO Channel 00/0 : 6[2] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272947:273306 [2] NCCL INFO Channel 01/0 : 6[2] -> 7[3] via P2P/CUMEM/read
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 02/0 : 12[0] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 06/0 : 12[0] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 03/0 : 12[0] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 07/0 : 12[0] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 00/0 : 8[0] -> 12[0] [receive] via NET/IB/0
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 01/0 : 8[0] -> 12[0] [receive] via NET/IB/1
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 04/0 : 4[0] -> 12[0] [receive] via NET/IB/0
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 05/0 : 4[0] -> 12[0] [receive] via NET/IB/1
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 04/0 : 12[0] -> 4[0] [send] via NET/IB/0
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 05/0 : 12[0] -> 4[0] [send] via NET/IB/1
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 00/0 : 12[0] -> 8[0] [send] via NET/IB/0
gpu-q-35:2680340:2680340 [1] NCCL INFO cudaDriverVersion 12040
gpu-q-35:2680340:2680340 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-35:2680340:2680340 [1] NCCL INFO Bootstrap : Using eno8303:10.43.74.53<0>
gpu-q-35:2680340:2680340 [1] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gpu-q-35:2680340:2680340 [1] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gpu-q-35:2680340:2680340 [1] NCCL INFO NET/Plugin: Using internal network plugin.
gpu-q-35:2680340:2680699 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
gpu-q-35:2680340:2680699 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-35:2680340:2680699 [1] NCCL INFO NCCL_IB_HCA set to mlx5
gpu-q-35:2680340:2680699 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB eno8303:10.43.74.53<0>
gpu-q-35:2680340:2680699 [1] NCCL INFO Using non-device net plugin version 0
gpu-q-29:272947:273306 [2] NCCL INFO Channel 04/0 : 6[2] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272947:273306 [2] NCCL INFO Channel 05/0 : 6[2] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272947:273306 [2] NCCL INFO Channel 02/0 : 1[1] -> 6[2] [receive] via NET/IB/2
gpu-q-29:272947:273306 [2] NCCL INFO Channel 03/0 : 1[1] -> 6[2] [receive] via NET/IB/0
gpu-q-29:272947:273306 [2] NCCL INFO Channel 06/0 : 1[1] -> 6[2] [receive] via NET/IB/2
gpu-q-29:272947:273306 [2] NCCL INFO Channel 07/0 : 1[1] -> 6[2] [receive] via NET/IB/0
gpu-q-29:272947:273306 [2] NCCL INFO Channel 02/0 : 6[2] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272947:273306 [2] NCCL INFO Channel 03/0 : 6[2] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272947:273306 [2] NCCL INFO Channel 06/0 : 6[2] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272947:273306 [2] NCCL INFO Channel 07/0 : 6[2] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272947:273306 [2] NCCL INFO Connected all rings
gpu-q-29:272947:273306 [2] NCCL INFO Channel 02/0 : 6[2] -> 7[3] via P2P/CUMEM/read
gpu-q-49:1203803:1204157 [0] NCCL INFO Channel 01/0 : 12[0] -> 8[0] [send] via NET/IB/1
gpu-q-49:1203803:1204157 [0] NCCL INFO Connected all trees
gpu-q-35:2680340:2680699 [1] NCCL INFO Using network IB
gpu-q-35:2680340:2680699 [1] NCCL INFO ncclCommInitRank comm 0x55f8eb51a040 rank 9 nranks 16 cudaDev 1 nvmlDev 1 busId 41000 commId 0xab369c58f444f4f9 - Init START
gpu-q-35:2680340:2680699 [1] NCCL INFO Setting affinity for GPU 1 to ffff0000
gpu-q-35:2680340:2680699 [1] NCCL INFO NVLS multicast support is not available on dev 1
gpu-q-35:2680340:2680699 [1] NCCL INFO comm 0x55f8eb51a040 rank 9 nRanks 16 nNodes 4 localRanks 4 localRank 1 MNNVL 0
gpu-q-35:2680340:2680699 [1] NCCL INFO Trees [0] 10/4/-1->9->8 [1] 10/4/-1->9->8 [2] -1/-1/-1->9->8 [3] 10/7/-1->9->11 [4] 10/-1/-1->9->8 [5] 10/-1/-1->9->8 [6] -1/-1/-1->9->8 [7] 10/-1/-1->9->11
gpu-q-35:2680340:2680699 [1] NCCL INFO P2P Chunksize set to 131072
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 00/0 : 9[1] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 01/0 : 9[1] -> 10[2] via P2P/CUMEM/read
gpu-q-29:272947:273306 [2] NCCL INFO Channel 06/0 : 6[2] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272947:273306 [2] NCCL INFO Channel 06/0 : 2[2] -> 6[2] [receive] via NET/IB/2
gpu-q-29:272947:273306 [2] NCCL INFO Channel 02/0 : 6[2] -> 11[3] [send] via NET/IB/2
gpu-q-29:272947:273306 [2] NCCL INFO Channel 06/0 : 14[2] -> 6[2] [receive] via NET/IB/2
gpu-q-29:272947:273306 [2] NCCL INFO Channel 06/0 : 6[2] -> 14[2] [send] via NET/IB/2
gpu-q-29:272947:273306 [2] NCCL INFO Channel 02/0 : 11[3] -> 6[2] [receive] via NET/IB/2
gpu-q-29:272947:273306 [2] NCCL INFO Channel 06/0 : 6[2] -> 2[2] [send] via NET/IB/2
gpu-q-29:272947:273306 [2] NCCL INFO Channel 00/0 : 6[2] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272947:273306 [2] NCCL INFO Channel 01/0 : 6[2] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272947:273306 [2] NCCL INFO Channel 03/0 : 6[2] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272947:273306 [2] NCCL INFO Channel 04/0 : 6[2] -> 5[1] via P2P/CUMEM/read
gpu-q-49:1203805:1203805 [2] NCCL INFO cudaDriverVersion 12040
gpu-q-49:1203805:1203805 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-49:1203805:1203805 [2] NCCL INFO Bootstrap : Using eno8303:10.43.74.73<0>
gpu-q-49:1203805:1203805 [2] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gpu-q-49:1203805:1203805 [2] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gpu-q-49:1203805:1203805 [2] NCCL INFO NET/Plugin: Using internal network plugin.
gpu-q-49:1203805:1204158 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
gpu-q-49:1203805:1204158 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-49:1203805:1204158 [2] NCCL INFO NCCL_IB_HCA set to mlx5
gpu-q-49:1203805:1204158 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB eno8303:10.43.74.73<0>
gpu-q-49:1203805:1204158 [2] NCCL INFO Using non-device net plugin version 0
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 04/0 : 9[1] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 05/0 : 9[1] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 02/0 : 9[1] -> 14[2] [send] via NET/IB/0
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 03/0 : 9[1] -> 14[2] [send] via NET/IB/1
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 06/0 : 9[1] -> 14[2] [send] via NET/IB/0
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 07/0 : 9[1] -> 14[2] [send] via NET/IB/1
gpu-q-35:2680340:2680699 [1] NCCL INFO Connected all rings
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 03/0 : 9[1] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 07/0 : 9[1] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 03/0 : 7[3] -> 9[1] [receive] via NET/IB/1
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 03/0 : 9[1] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 07/0 : 9[1] -> 11[3] via P2P/CUMEM/read
gpu-q-29:272947:273306 [2] NCCL INFO Channel 05/0 : 6[2] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272947:273306 [2] NCCL INFO Channel 07/0 : 6[2] -> 5[1] via P2P/CUMEM/read
gpu-q-49:1203805:1204158 [2] NCCL INFO Using network IB
gpu-q-49:1203805:1204158 [2] NCCL INFO ncclCommInitRank comm 0x556b1db767c0 rank 14 nranks 16 cudaDev 2 nvmlDev 2 busId 81000 commId 0xab369c58f444f4f9 - Init START
gpu-q-49:1203805:1204158 [2] NCCL INFO Setting affinity for GPU 2 to ffff0000,00000000,00000000,00000000
gpu-q-49:1203805:1204158 [2] NCCL INFO NVLS multicast support is not available on dev 2
gpu-q-49:1203805:1204158 [2] NCCL INFO comm 0x556b1db767c0 rank 14 nRanks 16 nNodes 4 localRanks 4 localRank 2 MNNVL 0
gpu-q-49:1203805:1204158 [2] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13 [2] 15/-1/-1->14->10 [3] 12/-1/-1->14->13 [4] 15/-1/-1->14->13 [5] 15/-1/-1->14->13 [6] 15/6/-1->14->-1 [7] 12/-1/-1->14->13
gpu-q-49:1203805:1204158 [2] NCCL INFO P2P Chunksize set to 131072
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 00/0 : 14[2] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 01/0 : 14[2] -> 15[3] via P2P/CUMEM/read
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 00/0 : 4[0] -> 9[1] [receive] via NET/IB/0
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 01/0 : 4[0] -> 9[1] [receive] via NET/IB/1
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 00/0 : 9[1] -> 4[0] [send] via NET/IB/0
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 01/0 : 9[1] -> 4[0] [send] via NET/IB/1
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 03/0 : 9[1] -> 7[3] [send] via NET/IB/1
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 00/0 : 9[1] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 01/0 : 9[1] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 02/0 : 9[1] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 04/0 : 9[1] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 05/0 : 9[1] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680340:2680699 [1] NCCL INFO Channel 06/0 : 9[1] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680340:2680699 [1] NCCL INFO Connected all trees
gpu-q-29:272948:272948 [3] NCCL INFO cudaDriverVersion 12040
gpu-q-29:272948:272948 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-29:272948:272948 [3] NCCL INFO Bootstrap : Using eno8303:10.43.74.41<0>
gpu-q-29:272948:272948 [3] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gpu-q-29:272948:272948 [3] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gpu-q-29:272948:272948 [3] NCCL INFO NET/Plugin: Using internal network plugin.
gpu-q-29:272948:273308 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
gpu-q-29:272948:273308 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-29:272948:273308 [3] NCCL INFO NCCL_IB_HCA set to mlx5
gpu-q-29:272948:273308 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_3:1/IB [RO]; OOB eno8303:10.43.74.41<0>
gpu-q-29:272948:273308 [3] NCCL INFO Using non-device net plugin version 0
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 04/0 : 14[2] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 05/0 : 14[2] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 02/0 : 9[1] -> 14[2] [receive] via NET/IB/0
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 03/0 : 9[1] -> 14[2] [receive] via NET/IB/1
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 06/0 : 9[1] -> 14[2] [receive] via NET/IB/0
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 07/0 : 9[1] -> 14[2] [receive] via NET/IB/1
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 02/0 : 14[2] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 03/0 : 14[2] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 06/0 : 14[2] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 07/0 : 14[2] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203805:1204158 [2] NCCL INFO Connected all rings
gpu-q-35:2680340:2680699 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-29:272948:273308 [3] NCCL INFO Using network IB
gpu-q-29:272948:273308 [3] NCCL INFO ncclCommInitRank comm 0x558edf434400 rank 7 nranks 16 cudaDev 3 nvmlDev 3 busId c1000 commId 0xab369c58f444f4f9 - Init START
gpu-q-29:272948:273308 [3] NCCL INFO Setting affinity for GPU 3 to ffff0000,00000000,00000000
gpu-q-29:272948:273308 [3] NCCL INFO NVLS multicast support is not available on dev 3
gpu-q-29:272948:273308 [3] NCCL INFO comm 0x558edf434400 rank 7 nRanks 16 nNodes 4 localRanks 4 localRank 3 MNNVL 0
gpu-q-29:272948:273308 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] 4/-1/-1->7->6 [3] 5/-1/-1->7->9 [4] -1/-1/-1->7->6 [5] -1/-1/-1->7->6 [6] 4/10/-1->7->6 [7] 5/3/-1->7->15
gpu-q-29:272948:273308 [3] NCCL INFO P2P Chunksize set to 131072
gpu-q-29:272948:273308 [3] NCCL INFO Channel 00/0 : 7[3] -> 8[0] [send] via NET/IB/0
gpu-q-29:272948:273308 [3] NCCL INFO Channel 01/0 : 7[3] -> 8[0] [send] via NET/IB/1
gpu-q-29:272948:273308 [3] NCCL INFO Channel 04/0 : 7[3] -> 8[0] [send] via NET/IB/0
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 02/0 : 14[2] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 06/0 : 14[2] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 02/0 : 10[2] -> 14[2] [receive] via NET/IB/0
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 06/0 : 6[2] -> 14[2] [receive] via NET/IB/0
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 06/0 : 14[2] -> 6[2] [send] via NET/IB/0
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 02/0 : 14[2] -> 10[2] [send] via NET/IB/0
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 00/0 : 14[2] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 01/0 : 14[2] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 03/0 : 14[2] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 04/0 : 14[2] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 05/0 : 14[2] -> 13[1] via P2P/CUMEM/read
gpu-q-29:272948:273308 [3] NCCL INFO Channel 05/0 : 7[3] -> 8[0] [send] via NET/IB/1
gpu-q-29:272948:273308 [3] NCCL INFO Channel 02/0 : 7[3] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272948:273308 [3] NCCL INFO Channel 03/0 : 7[3] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272948:273308 [3] NCCL INFO Channel 06/0 : 7[3] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272948:273308 [3] NCCL INFO Channel 07/0 : 7[3] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272948:273308 [3] NCCL INFO Connected all rings
gpu-q-29:272948:273308 [3] NCCL INFO Channel 03/0 : 7[3] -> 9[1] [send] via NET/IB/0
gpu-q-29:272948:273308 [3] NCCL INFO Channel 06/0 : 7[3] -> 10[2] [send] via NET/IB/2
gpu-q-29:272948:273308 [3] NCCL INFO Channel 07/0 : 3[3] -> 7[3] [receive] via NET/IB/0
gpu-q-29:272948:273308 [3] NCCL INFO Channel 07/0 : 15[3] -> 7[3] [receive] via NET/IB/0
gpu-q-29:272948:273308 [3] NCCL INFO Channel 07/0 : 7[3] -> 15[3] [send] via NET/IB/0
gpu-q-29:272948:273308 [3] NCCL INFO Channel 07/0 : 7[3] -> 3[3] [send] via NET/IB/0
gpu-q-49:1203805:1204158 [2] NCCL INFO Channel 07/0 : 14[2] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203805:1204158 [2] NCCL INFO Connected all trees
gpu-q-29:272948:273308 [3] NCCL INFO Channel 06/0 : 10[2] -> 7[3] [receive] via NET/IB/2
gpu-q-29:272948:273308 [3] NCCL INFO Channel 02/0 : 7[3] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272948:273308 [3] NCCL INFO Channel 06/0 : 7[3] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272948:273308 [3] NCCL INFO Channel 03/0 : 9[1] -> 7[3] [receive] via NET/IB/0
gpu-q-29:272948:273308 [3] NCCL INFO Channel 00/0 : 7[3] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272948:273308 [3] NCCL INFO Channel 01/0 : 7[3] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272948:273308 [3] NCCL INFO Channel 02/0 : 7[3] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272948:273308 [3] NCCL INFO Channel 04/0 : 7[3] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272948:273308 [3] NCCL INFO Channel 05/0 : 7[3] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272948:273308 [3] NCCL INFO Channel 06/0 : 7[3] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272948:273308 [3] NCCL INFO Connected all trees
gpu-q-29:272948:273308 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-9:206475:206475 [3] NCCL INFO cudaDriverVersion 12040
gpu-q-9:206475:206475 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-9:206475:206475 [3] NCCL INFO Bootstrap : Using eno8303:10.43.74.9<0>
gpu-q-9:206475:206475 [3] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gpu-q-9:206475:206475 [3] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gpu-q-9:206475:206475 [3] NCCL INFO NET/Plugin: Using internal network plugin.
gpu-q-9:206475:206833 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
gpu-q-9:206475:206833 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-9:206475:206833 [3] NCCL INFO NCCL_IB_HCA set to mlx5
gpu-q-9:206475:206833 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_3:1/IB [RO]; OOB eno8303:10.43.74.9<0>
gpu-q-9:206475:206833 [3] NCCL INFO Using non-device net plugin version 0
gpu-q-9:206475:206833 [3] NCCL INFO Using network IB
gpu-q-9:206475:206833 [3] NCCL INFO ncclCommInitRank comm 0x55bcafb12ec0 rank 3 nranks 16 cudaDev 3 nvmlDev 3 busId c1000 commId 0xab369c58f444f4f9 - Init START
gpu-q-9:206475:206833 [3] NCCL INFO Setting affinity for GPU 3 to ffff0000,00000000,00000000
gpu-q-9:206475:206833 [3] NCCL INFO NVLS multicast support is not available on dev 3
gpu-q-9:206475:206833 [3] NCCL INFO comm 0x55bcafb12ec0 rank 3 nRanks 16 nNodes 4 localRanks 4 localRank 3 MNNVL 0
gpu-q-9:206475:206833 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] 0/-1/-1->3->2 [3] 1/11/-1->3->-1 [4] -1/-1/-1->3->2 [5] -1/-1/-1->3->2 [6] 0/-1/-1->3->2 [7] 1/-1/-1->3->7
gpu-q-9:206475:206833 [3] NCCL INFO P2P Chunksize set to 131072
gpu-q-9:206475:206833 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[0] [send] via NET/IB/0
gpu-q-9:206475:206833 [3] NCCL INFO Channel 01/0 : 3[3] -> 4[0] [send] via NET/IB/1
gpu-q-9:206475:206833 [3] NCCL INFO Channel 04/0 : 3[3] -> 4[0] [send] via NET/IB/0
gpu-q-9:206475:206833 [3] NCCL INFO Channel 05/0 : 3[3] -> 4[0] [send] via NET/IB/1
gpu-q-9:206475:206833 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206475:206833 [3] NCCL INFO Channel 03/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206475:206833 [3] NCCL INFO Channel 06/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206475:206833 [3] NCCL INFO Channel 07/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206475:206833 [3] NCCL INFO Connected all rings
gpu-q-9:206475:206833 [3] NCCL INFO Channel 07/0 : 3[3] -> 7[3] [send] via NET/IB/0
gpu-q-9:206475:206833 [3] NCCL INFO Channel 03/0 : 11[3] -> 3[3] [receive] via NET/IB/0
gpu-q-9:206475:206833 [3] NCCL INFO Channel 03/0 : 3[3] -> 11[3] [send] via NET/IB/0
gpu-q-9:206475:206833 [3] NCCL INFO Channel 07/0 : 7[3] -> 3[3] [receive] via NET/IB/0
gpu-q-9:206475:206833 [3] NCCL INFO Channel 02/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206475:206833 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206475:206833 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206475:206833 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206475:206833 [3] NCCL INFO Channel 02/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206475:206833 [3] NCCL INFO Channel 04/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206475:206833 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206475:206833 [3] NCCL INFO Channel 06/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206475:206833 [3] NCCL INFO Connected all trees
gpu-q-9:206475:206833 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-9:206475:206833 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-9:206475:206833 [3] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gpu-q-9:206475:206833 [3] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gpu-q-49:1203804:1203804 [1] NCCL INFO cudaDriverVersion 12040
gpu-q-49:1203804:1203804 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-49:1203804:1203804 [1] NCCL INFO Bootstrap : Using eno8303:10.43.74.73<0>
gpu-q-49:1203804:1203804 [1] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gpu-q-49:1203804:1203804 [1] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gpu-q-49:1203804:1203804 [1] NCCL INFO NET/Plugin: Using internal network plugin.
gpu-q-49:1203804:1204156 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
gpu-q-49:1203804:1204156 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-49:1203804:1204156 [1] NCCL INFO NCCL_IB_HCA set to mlx5
gpu-q-49:1203804:1204156 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB eno8303:10.43.74.73<0>
gpu-q-49:1203804:1204156 [1] NCCL INFO Using non-device net plugin version 0
gpu-q-49:1203804:1204156 [1] NCCL INFO Using network IB
gpu-q-49:1203804:1204156 [1] NCCL INFO ncclCommInitRank comm 0x557776b83ec0 rank 13 nranks 16 cudaDev 1 nvmlDev 1 busId 41000 commId 0xab369c58f444f4f9 - Init START
gpu-q-49:1203804:1204156 [1] NCCL INFO Setting affinity for GPU 1 to ffff0000
gpu-q-49:1203804:1204156 [1] NCCL INFO NVLS multicast support is not available on dev 1
gpu-q-49:1203804:1204156 [1] NCCL INFO comm 0x557776b83ec0 rank 13 nRanks 16 nNodes 4 localRanks 4 localRank 1 MNNVL 0
gpu-q-49:1203804:1204156 [1] NCCL INFO Trees [0] 14/-1/-1->13->12 [1] 14/-1/-1->13->12 [2] -1/-1/-1->13->12 [3] 14/-1/-1->13->15 [4] 14/-1/-1->13->12 [5] 14/-1/-1->13->12 [6] -1/-1/-1->13->12 [7] 14/-1/-1->13->15
gpu-q-49:1203804:1204156 [1] NCCL INFO P2P Chunksize set to 131072
gpu-q-49:1203804:1204156 [1] NCCL INFO Channel 00/0 : 13[1] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203804:1204156 [1] NCCL INFO Channel 01/0 : 13[1] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203804:1204156 [1] NCCL INFO Channel 04/0 : 13[1] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203804:1204156 [1] NCCL INFO Channel 05/0 : 13[1] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203804:1204156 [1] NCCL INFO Channel 02/0 : 13[1] -> 2[2] [send] via NET/IB/0
gpu-q-49:1203804:1204156 [1] NCCL INFO Channel 03/0 : 13[1] -> 2[2] [send] via NET/IB/1
gpu-q-49:1203804:1204156 [1] NCCL INFO Channel 06/0 : 13[1] -> 2[2] [send] via NET/IB/0
gpu-q-49:1203804:1204156 [1] NCCL INFO Channel 07/0 : 13[1] -> 2[2] [send] via NET/IB/1
gpu-q-49:1203804:1204156 [1] NCCL INFO Connected all rings
gpu-q-49:1203804:1204156 [1] NCCL INFO Channel 03/0 : 13[1] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203804:1204156 [1] NCCL INFO Channel 07/0 : 13[1] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203804:1204156 [1] NCCL INFO Channel 03/0 : 13[1] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203804:1204156 [1] NCCL INFO Channel 07/0 : 13[1] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203804:1204156 [1] NCCL INFO Channel 00/0 : 13[1] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203804:1204156 [1] NCCL INFO Channel 01/0 : 13[1] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203804:1204156 [1] NCCL INFO Channel 02/0 : 13[1] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203804:1204156 [1] NCCL INFO Channel 04/0 : 13[1] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203804:1204156 [1] NCCL INFO Channel 05/0 : 13[1] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203804:1204156 [1] NCCL INFO Channel 06/0 : 13[1] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203804:1204156 [1] NCCL INFO Connected all trees
gpu-q-49:1203804:1204156 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-49:1203804:1204156 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-49:1203804:1204156 [1] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gpu-q-49:1203804:1204156 [1] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gpu-q-49:1203806:1203806 [3] NCCL INFO cudaDriverVersion 12040
gpu-q-49:1203806:1203806 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-49:1203806:1203806 [3] NCCL INFO Bootstrap : Using eno8303:10.43.74.73<0>
gpu-q-49:1203806:1203806 [3] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gpu-q-49:1203806:1203806 [3] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gpu-q-49:1203806:1203806 [3] NCCL INFO NET/Plugin: Using internal network plugin.
gpu-q-49:1203806:1204159 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
gpu-q-49:1203806:1204159 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-49:1203806:1204159 [3] NCCL INFO NCCL_IB_HCA set to mlx5
gpu-q-49:1203806:1204159 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB eno8303:10.43.74.73<0>
gpu-q-49:1203806:1204159 [3] NCCL INFO Using non-device net plugin version 0
gpu-q-49:1203806:1204159 [3] NCCL INFO Using network IB
gpu-q-49:1203806:1204159 [3] NCCL INFO ncclCommInitRank comm 0x5573a3eb8540 rank 15 nranks 16 cudaDev 3 nvmlDev 3 busId c1000 commId 0xab369c58f444f4f9 - Init START
gpu-q-49:1203806:1204159 [3] NCCL INFO Setting affinity for GPU 3 to ffff0000,00000000,00000000
gpu-q-49:1203806:1204159 [3] NCCL INFO NVLS multicast support is not available on dev 3
gpu-q-49:1203806:1204159 [3] NCCL INFO comm 0x5573a3eb8540 rank 15 nRanks 16 nNodes 4 localRanks 4 localRank 3 MNNVL 0
gpu-q-49:1203806:1204159 [3] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] -1/-1/-1->15->14 [2] 12/-1/-1->15->14 [3] 13/-1/-1->15->11 [4] -1/-1/-1->15->14 [5] -1/-1/-1->15->14 [6] 12/-1/-1->15->14 [7] 13/7/-1->15->-1
gpu-q-49:1203806:1204159 [3] NCCL INFO P2P Chunksize set to 131072
gpu-q-49:1203806:1204159 [3] NCCL INFO Channel 00/0 : 15[3] -> 0[0] [send] via NET/IB/0
gpu-q-49:1203806:1204159 [3] NCCL INFO Channel 01/0 : 15[3] -> 0[0] [send] via NET/IB/1
gpu-q-49:1203806:1204159 [3] NCCL INFO Channel 04/0 : 15[3] -> 0[0] [send] via NET/IB/0
gpu-q-49:1203806:1204159 [3] NCCL INFO Channel 05/0 : 15[3] -> 0[0] [send] via NET/IB/1
gpu-q-49:1203806:1204159 [3] NCCL INFO Channel 02/0 : 15[3] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203806:1204159 [3] NCCL INFO Channel 03/0 : 15[3] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203806:1204159 [3] NCCL INFO Channel 06/0 : 15[3] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203806:1204159 [3] NCCL INFO Channel 07/0 : 15[3] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203806:1204159 [3] NCCL INFO Connected all rings
gpu-q-49:1203806:1204159 [3] NCCL INFO Channel 03/0 : 11[3] -> 15[3] [receive] via NET/IB/1
gpu-q-49:1203806:1204159 [3] NCCL INFO Channel 07/0 : 7[3] -> 15[3] [receive] via NET/IB/1
gpu-q-49:1203806:1204159 [3] NCCL INFO Channel 07/0 : 15[3] -> 7[3] [send] via NET/IB/1
gpu-q-49:1203806:1204159 [3] NCCL INFO Channel 03/0 : 15[3] -> 11[3] [send] via NET/IB/1
gpu-q-49:1203806:1204159 [3] NCCL INFO Channel 02/0 : 15[3] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203806:1204159 [3] NCCL INFO Channel 06/0 : 15[3] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203806:1204159 [3] NCCL INFO Channel 00/0 : 15[3] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203806:1204159 [3] NCCL INFO Channel 01/0 : 15[3] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203806:1204159 [3] NCCL INFO Channel 02/0 : 15[3] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203806:1204159 [3] NCCL INFO Channel 04/0 : 15[3] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203806:1204159 [3] NCCL INFO Channel 05/0 : 15[3] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203806:1204159 [3] NCCL INFO Channel 06/0 : 15[3] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203806:1204159 [3] NCCL INFO Connected all trees
gpu-q-49:1203806:1204159 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-49:1203806:1204159 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-9:206473:206473 [1] NCCL INFO cudaDriverVersion 12040
gpu-q-9:206473:206473 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-9:206473:206473 [1] NCCL INFO Bootstrap : Using eno8303:10.43.74.9<0>
gpu-q-9:206473:206473 [1] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gpu-q-9:206473:206473 [1] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gpu-q-9:206473:206473 [1] NCCL INFO NET/Plugin: Using internal network plugin.
gpu-q-9:206473:206834 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
gpu-q-9:206473:206834 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
gpu-q-9:206473:206834 [1] NCCL INFO NCCL_IB_HCA set to mlx5
gpu-q-9:206473:206834 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_3:1/IB [RO]; OOB eno8303:10.43.74.9<0>
gpu-q-9:206473:206834 [1] NCCL INFO Using non-device net plugin version 0
gpu-q-9:206473:206834 [1] NCCL INFO Using network IB
gpu-q-9:206473:206834 [1] NCCL INFO ncclCommInitRank comm 0x5631f2e2dc00 rank 1 nranks 16 cudaDev 1 nvmlDev 1 busId 41000 commId 0xab369c58f444f4f9 - Init START
gpu-q-9:206473:206834 [1] NCCL INFO Setting affinity for GPU 1 to ffff0000
gpu-q-9:206473:206834 [1] NCCL INFO NVLS multicast support is not available on dev 1
gpu-q-9:206473:206834 [1] NCCL INFO comm 0x5631f2e2dc00 rank 1 nRanks 16 nNodes 4 localRanks 4 localRank 1 MNNVL 0
gpu-q-9:206473:206834 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] 2/-1/-1->1->3 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] 2/-1/-1->1->3
gpu-q-9:206473:206834 [1] NCCL INFO P2P Chunksize set to 131072
gpu-q-9:206473:206834 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206473:206834 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206473:206834 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206473:206834 [1] NCCL INFO Channel 05/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206473:206834 [1] NCCL INFO Channel 02/0 : 1[1] -> 6[2] [send] via NET/IB/2
gpu-q-9:206473:206834 [1] NCCL INFO Channel 03/0 : 1[1] -> 6[2] [send] via NET/IB/0
gpu-q-9:206473:206834 [1] NCCL INFO Channel 06/0 : 1[1] -> 6[2] [send] via NET/IB/2
gpu-q-9:206473:206834 [1] NCCL INFO Channel 07/0 : 1[1] -> 6[2] [send] via NET/IB/0
gpu-q-9:206473:206834 [1] NCCL INFO Connected all rings
gpu-q-9:206473:206834 [1] NCCL INFO Channel 03/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206473:206834 [1] NCCL INFO Channel 07/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206473:206834 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206473:206834 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206473:206834 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206473:206834 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206473:206834 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206473:206834 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206473:206834 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206473:206834 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206473:206834 [1] NCCL INFO Connected all trees
gpu-q-9:206473:206834 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-9:206473:206834 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-9:206473:206834 [1] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gpu-q-9:206473:206834 [1] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gpu-q-9:206473:206834 [1] NCCL INFO ncclCommInitRank comm 0x5631f2e2dc00 rank 1 nranks 16 cudaDev 1 nvmlDev 1 busId 41000 commId 0xab369c58f444f4f9 - Init COMPLETE
gpu-q-9:206473:206998 [1] NCCL INFO Using non-device net plugin version 0
gpu-q-9:206472:206832 [0] NCCL INFO Channel 04/0 : 4[0] -> 0[0] [receive] via NET/IB/0
gpu-q-9:206472:206832 [0] NCCL INFO Channel 05/0 : 4[0] -> 0[0] [receive] via NET/IB/1
gpu-q-9:206472:206832 [0] NCCL INFO Connected all trees
gpu-q-9:206472:206832 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-9:206472:206832 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-9:206472:206832 [0] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gpu-q-9:206472:206832 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gpu-q-9:206472:206832 [0] NCCL INFO ncclCommInitRank comm 0x565455965680 rank 0 nranks 16 cudaDev 0 nvmlDev 0 busId 1000 commId 0xab369c58f444f4f9 - Init COMPLETE
gpu-q-9:206472:206995 [0] NCCL INFO Using non-device net plugin version 0
gpu-q-9:206472:206995 [0] NCCL INFO Using network IB
gpu-q-9:206472:206995 [0] NCCL INFO ncclCommInitRank comm 0x56545988ee90 rank 0 nranks 16 cudaDev 0 nvmlDev 0 busId 1000 commId 0xf5599d8a92473923 - Init START
gpu-q-9:206472:206995 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000
gpu-q-9:206472:206995 [0] NCCL INFO NVLS multicast support is not available on dev 0
gpu-q-9:206472:206995 [0] NCCL INFO comm 0x56545988ee90 rank 0 nRanks 16 nNodes 4 localRanks 4 localRank 0 MNNVL 0
gpu-q-9:206472:206995 [0] NCCL INFO Channel 00/08 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
gpu-q-9:206472:206995 [0] NCCL INFO Channel 01/08 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
gpu-q-9:206472:206995 [0] NCCL INFO Channel 02/08 :    0   3   1   6   4   7   5  10   8  11   9  14  12  15  13   2
gpu-q-9:206472:206995 [0] NCCL INFO Channel 03/08 :    0   3   1   6   4   7   5  10   8  11   9  14  12  15  13   2
gpu-q-9:206472:206995 [0] NCCL INFO Channel 04/08 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
gpu-q-9:206472:206995 [0] NCCL INFO Channel 05/08 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
gpu-q-9:206472:206995 [0] NCCL INFO Channel 06/08 :    0   3   1   6   4   7   5  10   8  11   9  14  12  15  13   2
gpu-q-9:206472:206995 [0] NCCL INFO Channel 07/08 :    0   3   1   6   4   7   5  10   8  11   9  14  12  15  13   2
gpu-q-9:206472:206995 [0] NCCL INFO Trees [0] 1/8/-1->0->-1 [1] 1/8/-1->0->-1 [2] 1/-1/-1->0->3 [3] -1/-1/-1->0->2 [4] 1/-1/-1->0->4 [5] 1/-1/-1->0->4 [6] 1/-1/-1->0->3 [7] -1/-1/-1->0->2
gpu-q-9:206472:206995 [0] NCCL INFO P2P Chunksize set to 131072
gpu-q-9:206472:206995 [0] NCCL INFO Channel 00/0 : 15[3] -> 0[0] [receive] via NET/IB/0
gpu-q-9:206472:206995 [0] NCCL INFO Channel 01/0 : 15[3] -> 0[0] [receive] via NET/IB/1
gpu-q-9:206472:206995 [0] NCCL INFO Channel 04/0 : 15[3] -> 0[0] [receive] via NET/IB/0
gpu-q-9:206472:206995 [0] NCCL INFO Channel 05/0 : 15[3] -> 0[0] [receive] via NET/IB/1
gpu-q-9:206472:206995 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206472:206995 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206472:206995 [0] NCCL INFO Channel 04/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206472:206995 [0] NCCL INFO Channel 05/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206472:206995 [0] NCCL INFO Channel 02/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206472:206995 [0] NCCL INFO Channel 03/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206472:206995 [0] NCCL INFO Channel 06/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206472:206995 [0] NCCL INFO Channel 07/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206472:206995 [0] NCCL INFO Connected all rings
gpu-q-9:206472:206995 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206472:206995 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206472:206995 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206472:206995 [0] NCCL INFO Channel 07/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206472:206995 [0] NCCL INFO Channel 04/0 : 0[0] -> 4[0] [send] via NET/IB/0
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 01/0 : 12[0] -> 8[0] [receive] via NET/IB/1
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 04/0 : 8[0] -> 5[1] [send] via NET/IB/0
gpu-q-35:2680339:2680697 [0] NCCL INFO Channel 05/0 : 8[0] -> 5[1] [send] via NET/IB/1
gpu-q-35:2680339:2680697 [0] NCCL INFO Connected all trees
gpu-q-35:2680339:2680697 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-35:2680339:2680697 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-35:2680339:2680697 [0] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gpu-q-35:2680339:2680697 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gpu-q-35:2680339:2680697 [0] NCCL INFO ncclCommInitRank comm 0x55ccea88a700 rank 8 nranks 16 cudaDev 0 nvmlDev 0 busId 1000 commId 0xab369c58f444f4f9 - Init COMPLETE
gpu-q-35:2680339:2680855 [0] NCCL INFO Using non-device net plugin version 0
gpu-q-35:2680339:2680855 [0] NCCL INFO Using network IB
gpu-q-35:2680339:2680855 [0] NCCL INFO ncclCommInitRank comm 0x55ccee7a3f20 rank 8 nranks 16 cudaDev 0 nvmlDev 0 busId 1000 commId 0xf5599d8a92473923 - Init START
gpu-q-35:2680339:2680855 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000
gpu-q-35:2680339:2680855 [0] NCCL INFO NVLS multicast support is not available on dev 0
gpu-q-35:2680339:2680855 [0] NCCL INFO comm 0x55ccee7a3f20 rank 8 nRanks 16 nNodes 4 localRanks 4 localRank 0 MNNVL 0
gpu-q-35:2680339:2680855 [0] NCCL INFO Trees [0] 9/12/-1->8->0 [1] 9/12/-1->8->0 [2] 9/-1/-1->8->11 [3] -1/-1/-1->8->10 [4] 9/-1/-1->8->5 [5] 9/-1/-1->8->5 [6] 9/-1/-1->8->11 [7] -1/-1/-1->8->10
gpu-q-35:2680339:2680855 [0] NCCL INFO P2P Chunksize set to 131072
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 00/0 : 7[3] -> 8[0] [receive] via NET/IB/0
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 01/0 : 7[3] -> 8[0] [receive] via NET/IB/1
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 04/0 : 7[3] -> 8[0] [receive] via NET/IB/0
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 05/0 : 7[3] -> 8[0] [receive] via NET/IB/1
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 00/0 : 8[0] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 01/0 : 8[0] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 04/0 : 8[0] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 05/0 : 8[0] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 02/0 : 8[0] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 03/0 : 8[0] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 06/0 : 8[0] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 07/0 : 8[0] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680339:2680855 [0] NCCL INFO Connected all rings
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 02/0 : 8[0] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 06/0 : 8[0] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 03/0 : 8[0] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 07/0 : 8[0] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 04/0 : 5[1] -> 8[0] [receive] via NET/IB/0
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 05/0 : 5[1] -> 8[0] [receive] via NET/IB/1
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 00/0 : 8[0] -> 12[0] [send] via NET/IB/0
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 01/0 : 8[0] -> 12[0] [send] via NET/IB/1
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 00/0 : 0[0] -> 8[0] [receive] via NET/IB/0
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 01/0 : 0[0] -> 8[0] [receive] via NET/IB/1
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 00/0 : 8[0] -> 0[0] [send] via NET/IB/0
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 01/0 : 8[0] -> 0[0] [send] via NET/IB/1
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 00/0 : 12[0] -> 8[0] [receive] via NET/IB/0
gpu-q-29:272945:273307 [0] NCCL INFO Channel 04/0 : 4[0] -> 0[0] [send] via NET/IB/0
gpu-q-29:272945:273307 [0] NCCL INFO Channel 05/0 : 4[0] -> 0[0] [send] via NET/IB/1
gpu-q-29:272945:273307 [0] NCCL INFO Connected all trees
gpu-q-29:272945:273307 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-29:272945:273307 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-29:272945:273307 [0] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gpu-q-29:272945:273307 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gpu-q-29:272945:273307 [0] NCCL INFO ncclCommInitRank comm 0x5586e6932dc0 rank 4 nranks 16 cudaDev 0 nvmlDev 0 busId 1000 commId 0xab369c58f444f4f9 - Init COMPLETE
gpu-q-29:272945:273472 [0] NCCL INFO Using non-device net plugin version 0
gpu-q-29:272945:273472 [0] NCCL INFO Using network IB
gpu-q-29:272945:273472 [0] NCCL INFO ncclCommInitRank comm 0x5586ea84d9c0 rank 4 nranks 16 cudaDev 0 nvmlDev 0 busId 1000 commId 0xf5599d8a92473923 - Init START
gpu-q-29:272945:273472 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000
gpu-q-29:272945:273472 [0] NCCL INFO NVLS multicast support is not available on dev 0
gpu-q-29:272945:273472 [0] NCCL INFO comm 0x5586ea84d9c0 rank 4 nRanks 16 nNodes 4 localRanks 4 localRank 0 MNNVL 0
gpu-q-29:272945:273472 [0] NCCL INFO Trees [0] 5/-1/-1->4->9 [1] 5/-1/-1->4->9 [2] 5/-1/-1->4->7 [3] -1/-1/-1->4->6 [4] 5/0/-1->4->12 [5] 5/0/-1->4->12 [6] 5/-1/-1->4->7 [7] -1/-1/-1->4->6
gpu-q-29:272945:273472 [0] NCCL INFO P2P Chunksize set to 131072
gpu-q-29:272945:273472 [0] NCCL INFO Channel 00/0 : 3[3] -> 4[0] [receive] via NET/IB/0
gpu-q-29:272945:273472 [0] NCCL INFO Channel 01/0 : 3[3] -> 4[0] [receive] via NET/IB/1
gpu-q-29:272945:273472 [0] NCCL INFO Channel 04/0 : 3[3] -> 4[0] [receive] via NET/IB/0
gpu-q-29:272945:273472 [0] NCCL INFO Channel 05/0 : 3[3] -> 4[0] [receive] via NET/IB/1
gpu-q-29:272945:273472 [0] NCCL INFO Channel 00/0 : 4[0] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272945:273472 [0] NCCL INFO Channel 01/0 : 4[0] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272945:273472 [0] NCCL INFO Channel 04/0 : 4[0] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272945:273472 [0] NCCL INFO Channel 05/0 : 4[0] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272945:273472 [0] NCCL INFO Channel 02/0 : 4[0] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272945:273472 [0] NCCL INFO Channel 03/0 : 4[0] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272945:273472 [0] NCCL INFO Channel 06/0 : 4[0] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272945:273472 [0] NCCL INFO Channel 07/0 : 4[0] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272945:273472 [0] NCCL INFO Connected all rings
gpu-q-29:272945:273472 [0] NCCL INFO Channel 02/0 : 4[0] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272945:273472 [0] NCCL INFO Channel 06/0 : 4[0] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272945:273472 [0] NCCL INFO Channel 03/0 : 4[0] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272945:273472 [0] NCCL INFO Channel 07/0 : 4[0] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272945:273472 [0] NCCL INFO Channel 04/0 : 0[0] -> 4[0] [receive] via NET/IB/0
gpu-q-29:272945:273472 [0] NCCL INFO Channel 05/0 : 0[0] -> 4[0] [receive] via NET/IB/1
gpu-q-29:272945:273472 [0] NCCL INFO Channel 00/0 : 4[0] -> 9[1] [send] via NET/IB/0
gpu-q-29:272945:273472 [0] NCCL INFO Channel 01/0 : 4[0] -> 9[1] [send] via NET/IB/1
gpu-q-29:272945:273472 [0] NCCL INFO Channel 04/0 : 12[0] -> 4[0] [receive] via NET/IB/0
gpu-q-29:272945:273472 [0] NCCL INFO Channel 05/0 : 12[0] -> 4[0] [receive] via NET/IB/1
gpu-q-29:272945:273472 [0] NCCL INFO Channel 04/0 : 4[0] -> 12[0] [send] via NET/IB/0
gpu-q-29:272945:273472 [0] NCCL INFO Channel 05/0 : 4[0] -> 12[0] [send] via NET/IB/1
gpu-q-29:272945:273472 [0] NCCL INFO Channel 00/0 : 9[1] -> 4[0] [receive] via NET/IB/0
gpu-q-29:272945:273472 [0] NCCL INFO Channel 01/0 : 9[1] -> 4[0] [receive] via NET/IB/1
gpu-q-29:272945:273472 [0] NCCL INFO Channel 04/0 : 4[0] -> 0[0] [send] via NET/IB/0
gpu-q-35:2680341:2680698 [2] NCCL INFO Channel 07/0 : 10[2] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680341:2680698 [2] NCCL INFO Connected all trees
gpu-q-35:2680341:2680698 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-35:2680341:2680698 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-35:2680341:2680698 [2] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gpu-q-35:2680341:2680698 [2] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gpu-q-35:2680341:2680698 [2] NCCL INFO ncclCommInitRank comm 0x557ccb6f3980 rank 10 nranks 16 cudaDev 2 nvmlDev 2 busId 81000 commId 0xab369c58f444f4f9 - Init COMPLETE
gpu-q-35:2680341:2680857 [2] NCCL INFO Using non-device net plugin version 0
gpu-q-35:2680341:2680857 [2] NCCL INFO Using network IB
gpu-q-35:2680341:2680857 [2] NCCL INFO ncclCommInitRank comm 0x557cce50ec90 rank 10 nranks 16 cudaDev 2 nvmlDev 2 busId 81000 commId 0xf5599d8a92473923 - Init START
gpu-q-35:2680341:2680857 [2] NCCL INFO Setting affinity for GPU 2 to ffff0000,00000000,00000000,00000000
gpu-q-35:2680341:2680857 [2] NCCL INFO NVLS multicast support is not available on dev 2
gpu-q-35:2680341:2680857 [2] NCCL INFO comm 0x557cce50ec90 rank 10 nRanks 16 nNodes 4 localRanks 4 localRank 2 MNNVL 0
gpu-q-35:2680341:2680857 [2] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 11/-1/-1->10->9 [2] 11/14/-1->10->2 [3] 8/-1/-1->10->9 [4] 11/-1/-1->10->9 [5] 11/-1/-1->10->9 [6] 11/-1/-1->10->7 [7] 8/-1/-1->10->9
gpu-q-35:2680341:2680857 [2] NCCL INFO P2P Chunksize set to 131072
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 00/0 : 10[2] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 01/0 : 10[2] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 04/0 : 10[2] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 05/0 : 10[2] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 02/0 : 5[1] -> 10[2] [receive] via NET/IB/0
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 03/0 : 5[1] -> 10[2] [receive] via NET/IB/1
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 06/0 : 5[1] -> 10[2] [receive] via NET/IB/0
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 07/0 : 5[1] -> 10[2] [receive] via NET/IB/1
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 02/0 : 10[2] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 03/0 : 10[2] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 06/0 : 10[2] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 07/0 : 10[2] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680341:2680857 [2] NCCL INFO Connected all rings
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 02/0 : 10[2] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 06/0 : 10[2] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 06/0 : 7[3] -> 10[2] [receive] via NET/IB/0
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 02/0 : 10[2] -> 14[2] [send] via NET/IB/0
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 02/0 : 2[2] -> 10[2] [receive] via NET/IB/0
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 02/0 : 10[2] -> 2[2] [send] via NET/IB/0
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 02/0 : 14[2] -> 10[2] [receive] via NET/IB/0
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 06/0 : 10[2] -> 7[3] [send] via NET/IB/0
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 00/0 : 10[2] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 01/0 : 10[2] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 03/0 : 10[2] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 04/0 : 10[2] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 05/0 : 10[2] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680341:2680857 [2] NCCL INFO Channel 07/0 : 10[2] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680341:2680857 [2] NCCL INFO Connected all trees
gpu-q-35:2680342:2680700 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-35:2680342:2680700 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-35:2680342:2680700 [3] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gpu-q-35:2680342:2680700 [3] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gpu-q-35:2680342:2680700 [3] NCCL INFO ncclCommInitRank comm 0x55d745510980 rank 11 nranks 16 cudaDev 3 nvmlDev 3 busId c1000 commId 0xab369c58f444f4f9 - Init COMPLETE
gpu-q-35:2680342:2680858 [3] NCCL INFO Using non-device net plugin version 0
gpu-q-35:2680342:2680858 [3] NCCL INFO Using network IB
gpu-q-35:2680342:2680858 [3] NCCL INFO ncclCommInitRank comm 0x55d74830c8e0 rank 11 nranks 16 cudaDev 3 nvmlDev 3 busId c1000 commId 0xf5599d8a92473923 - Init START
gpu-q-35:2680342:2680858 [3] NCCL INFO Setting affinity for GPU 3 to ffff0000,00000000,00000000
gpu-q-35:2680342:2680858 [3] NCCL INFO NVLS multicast support is not available on dev 3
gpu-q-35:2680342:2680858 [3] NCCL INFO comm 0x55d74830c8e0 rank 11 nRanks 16 nNodes 4 localRanks 4 localRank 3 MNNVL 0
gpu-q-35:2680342:2680858 [3] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] -1/-1/-1->11->10 [2] 8/6/-1->11->10 [3] 9/15/-1->11->3 [4] -1/-1/-1->11->10 [5] -1/-1/-1->11->10 [6] 8/-1/-1->11->10 [7] 9/-1/-1->11->5
gpu-q-35:2680342:2680858 [3] NCCL INFO P2P Chunksize set to 131072
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 00/0 : 11[3] -> 12[0] [send] via NET/IB/0
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 01/0 : 11[3] -> 12[0] [send] via NET/IB/1
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 04/0 : 11[3] -> 12[0] [send] via NET/IB/0
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 05/0 : 11[3] -> 12[0] [send] via NET/IB/1
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 02/0 : 11[3] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 03/0 : 11[3] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 06/0 : 11[3] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 07/0 : 11[3] -> 9[1] via P2P/CUMEM/read
gpu-q-35:2680342:2680858 [3] NCCL INFO Connected all rings
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 03/0 : 11[3] -> 15[3] [send] via NET/IB/1
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 02/0 : 6[2] -> 11[3] [receive] via NET/IB/0
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 07/0 : 5[1] -> 11[3] [receive] via NET/IB/1
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 03/0 : 3[3] -> 11[3] [receive] via NET/IB/1
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 03/0 : 11[3] -> 3[3] [send] via NET/IB/1
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 07/0 : 11[3] -> 5[1] [send] via NET/IB/1
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 02/0 : 11[3] -> 6[2] [send] via NET/IB/0
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 03/0 : 15[3] -> 11[3] [receive] via NET/IB/1
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 02/0 : 11[3] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 06/0 : 11[3] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 00/0 : 11[3] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 01/0 : 11[3] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 02/0 : 11[3] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 04/0 : 11[3] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 05/0 : 11[3] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680342:2680858 [3] NCCL INFO Channel 06/0 : 11[3] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680342:2680858 [3] NCCL INFO Connected all trees
gpu-q-35:2680342:2680858 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-35:2680342:2680858 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-29:272947:273306 [2] NCCL INFO Connected all trees
gpu-q-29:272947:273306 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-29:272947:273306 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-29:272947:273306 [2] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gpu-q-29:272947:273306 [2] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gpu-q-29:272947:273306 [2] NCCL INFO ncclCommInitRank comm 0x5602f9b91000 rank 6 nranks 16 cudaDev 2 nvmlDev 2 busId 81000 commId 0xab369c58f444f4f9 - Init COMPLETE
gpu-q-29:272947:273469 [2] NCCL INFO Using non-device net plugin version 0
gpu-q-29:272947:273469 [2] NCCL INFO Using network IB
gpu-q-29:272947:273469 [2] NCCL INFO ncclCommInitRank comm 0x5602fc98ca80 rank 6 nranks 16 cudaDev 2 nvmlDev 2 busId 81000 commId 0xf5599d8a92473923 - Init START
gpu-q-29:272947:273469 [2] NCCL INFO Setting affinity for GPU 2 to ffff0000,00000000,00000000,00000000
gpu-q-29:272947:273469 [2] NCCL INFO NVLS multicast support is not available on dev 2
gpu-q-29:272947:273469 [2] NCCL INFO comm 0x5602fc98ca80 rank 6 nRanks 16 nNodes 4 localRanks 4 localRank 2 MNNVL 0
gpu-q-29:272947:273469 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->11 [3] 4/-1/-1->6->5 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/2/-1->6->14 [7] 4/-1/-1->6->5
gpu-q-29:272947:273469 [2] NCCL INFO P2P Chunksize set to 131072
gpu-q-29:272947:273469 [2] NCCL INFO Channel 00/0 : 6[2] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272947:273469 [2] NCCL INFO Channel 01/0 : 6[2] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272947:273469 [2] NCCL INFO Channel 04/0 : 6[2] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272947:273469 [2] NCCL INFO Channel 05/0 : 6[2] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272947:273469 [2] NCCL INFO Channel 02/0 : 1[1] -> 6[2] [receive] via NET/IB/2
gpu-q-29:272947:273469 [2] NCCL INFO Channel 03/0 : 1[1] -> 6[2] [receive] via NET/IB/0
gpu-q-29:272947:273469 [2] NCCL INFO Channel 06/0 : 1[1] -> 6[2] [receive] via NET/IB/2
gpu-q-29:272947:273469 [2] NCCL INFO Channel 07/0 : 1[1] -> 6[2] [receive] via NET/IB/0
gpu-q-29:272947:273469 [2] NCCL INFO Channel 02/0 : 6[2] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272947:273469 [2] NCCL INFO Channel 03/0 : 6[2] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272947:273469 [2] NCCL INFO Channel 06/0 : 6[2] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272947:273469 [2] NCCL INFO Channel 07/0 : 6[2] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272947:273469 [2] NCCL INFO Connected all rings
gpu-q-29:272947:273469 [2] NCCL INFO Channel 02/0 : 6[2] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272947:273469 [2] NCCL INFO Channel 06/0 : 6[2] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272947:273469 [2] NCCL INFO Channel 06/0 : 2[2] -> 6[2] [receive] via NET/IB/2
gpu-q-29:272947:273469 [2] NCCL INFO Channel 02/0 : 6[2] -> 11[3] [send] via NET/IB/2
gpu-q-29:272947:273469 [2] NCCL INFO Channel 06/0 : 14[2] -> 6[2] [receive] via NET/IB/2
gpu-q-29:272947:273469 [2] NCCL INFO Channel 06/0 : 6[2] -> 14[2] [send] via NET/IB/2
gpu-q-29:272947:273469 [2] NCCL INFO Channel 02/0 : 11[3] -> 6[2] [receive] via NET/IB/2
gpu-q-29:272947:273469 [2] NCCL INFO Channel 06/0 : 6[2] -> 2[2] [send] via NET/IB/2
gpu-q-29:272947:273469 [2] NCCL INFO Channel 00/0 : 6[2] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272947:273469 [2] NCCL INFO Channel 01/0 : 6[2] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272947:273469 [2] NCCL INFO Channel 03/0 : 6[2] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272947:273469 [2] NCCL INFO Channel 04/0 : 6[2] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272947:273469 [2] NCCL INFO Channel 05/0 : 6[2] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272947:273469 [2] NCCL INFO Channel 07/0 : 6[2] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272947:273469 [2] NCCL INFO Connected all trees
gpu-q-29:272947:273469 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-29:272947:273469 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-49:1203805:1204158 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-49:1203805:1204158 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-49:1203805:1204158 [2] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gpu-q-49:1203805:1204158 [2] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gpu-q-49:1203805:1204158 [2] NCCL INFO ncclCommInitRank comm 0x556b1db767c0 rank 14 nranks 16 cudaDev 2 nvmlDev 2 busId 81000 commId 0xab369c58f444f4f9 - Init COMPLETE
gpu-q-49:1203805:1204307 [2] NCCL INFO Using non-device net plugin version 0
gpu-q-49:1203805:1204307 [2] NCCL INFO Using network IB
gpu-q-49:1203805:1204307 [2] NCCL INFO ncclCommInitRank comm 0x556b20db2230 rank 14 nranks 16 cudaDev 2 nvmlDev 2 busId 81000 commId 0xf5599d8a92473923 - Init START
gpu-q-49:1203805:1204307 [2] NCCL INFO Setting affinity for GPU 2 to ffff0000,00000000,00000000,00000000
gpu-q-49:1203805:1204307 [2] NCCL INFO NVLS multicast support is not available on dev 2
gpu-q-49:1203805:1204307 [2] NCCL INFO comm 0x556b20db2230 rank 14 nRanks 16 nNodes 4 localRanks 4 localRank 2 MNNVL 0
gpu-q-49:1203805:1204307 [2] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13 [2] 15/-1/-1->14->10 [3] 12/-1/-1->14->13 [4] 15/-1/-1->14->13 [5] 15/-1/-1->14->13 [6] 15/6/-1->14->-1 [7] 12/-1/-1->14->13
gpu-q-49:1203805:1204307 [2] NCCL INFO P2P Chunksize set to 131072
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 00/0 : 14[2] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 01/0 : 14[2] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 04/0 : 14[2] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 05/0 : 14[2] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 02/0 : 9[1] -> 14[2] [receive] via NET/IB/0
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 03/0 : 9[1] -> 14[2] [receive] via NET/IB/1
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 06/0 : 9[1] -> 14[2] [receive] via NET/IB/0
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 07/0 : 9[1] -> 14[2] [receive] via NET/IB/1
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 02/0 : 14[2] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 03/0 : 14[2] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 06/0 : 14[2] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 07/0 : 14[2] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203805:1204307 [2] NCCL INFO Connected all rings
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 02/0 : 14[2] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 06/0 : 14[2] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 02/0 : 10[2] -> 14[2] [receive] via NET/IB/0
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 06/0 : 6[2] -> 14[2] [receive] via NET/IB/0
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 06/0 : 14[2] -> 6[2] [send] via NET/IB/0
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 02/0 : 14[2] -> 10[2] [send] via NET/IB/0
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 00/0 : 14[2] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 01/0 : 14[2] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 03/0 : 14[2] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 04/0 : 14[2] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 05/0 : 14[2] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203805:1204307 [2] NCCL INFO Channel 07/0 : 14[2] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203805:1204307 [2] NCCL INFO Connected all trees
gpu-q-49:1203805:1204307 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-49:1203805:1204307 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-49:1203803:1204157 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-49:1203803:1204157 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-49:1203803:1204157 [0] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gpu-q-49:1203803:1204157 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gpu-q-49:1203803:1204157 [0] NCCL INFO ncclCommInitRank comm 0x558a03ac4f80 rank 12 nranks 16 cudaDev 0 nvmlDev 0 busId 1000 commId 0xab369c58f444f4f9 - Init COMPLETE
gpu-q-49:1203803:1204308 [0] NCCL INFO Using non-device net plugin version 0
gpu-q-49:1203803:1204308 [0] NCCL INFO Using network IB
gpu-q-49:1203803:1204308 [0] NCCL INFO ncclCommInitRank comm 0x558a079fb5f0 rank 12 nranks 16 cudaDev 0 nvmlDev 0 busId 1000 commId 0xf5599d8a92473923 - Init START
gpu-q-49:1203803:1204308 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000
gpu-q-49:1203803:1204308 [0] NCCL INFO NVLS multicast support is not available on dev 0
gpu-q-49:1203803:1204308 [0] NCCL INFO comm 0x558a079fb5f0 rank 12 nRanks 16 nNodes 4 localRanks 4 localRank 0 MNNVL 0
gpu-q-49:1203803:1204308 [0] NCCL INFO Trees [0] 13/-1/-1->12->8 [1] 13/-1/-1->12->8 [2] 13/-1/-1->12->15 [3] -1/-1/-1->12->14 [4] 13/4/-1->12->-1 [5] 13/4/-1->12->-1 [6] 13/-1/-1->12->15 [7] -1/-1/-1->12->14
gpu-q-49:1203803:1204308 [0] NCCL INFO P2P Chunksize set to 131072
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 00/0 : 11[3] -> 12[0] [receive] via NET/IB/0
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 01/0 : 11[3] -> 12[0] [receive] via NET/IB/1
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 04/0 : 11[3] -> 12[0] [receive] via NET/IB/0
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 05/0 : 11[3] -> 12[0] [receive] via NET/IB/1
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 00/0 : 12[0] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 01/0 : 12[0] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 04/0 : 12[0] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 05/0 : 12[0] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 02/0 : 12[0] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 03/0 : 12[0] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 06/0 : 12[0] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 07/0 : 12[0] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203803:1204308 [0] NCCL INFO Connected all rings
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 02/0 : 12[0] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 06/0 : 12[0] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 03/0 : 12[0] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 07/0 : 12[0] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 00/0 : 8[0] -> 12[0] [receive] via NET/IB/0
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 01/0 : 8[0] -> 12[0] [receive] via NET/IB/1
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 04/0 : 4[0] -> 12[0] [receive] via NET/IB/0
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 05/0 : 4[0] -> 12[0] [receive] via NET/IB/1
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 04/0 : 12[0] -> 4[0] [send] via NET/IB/0
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 05/0 : 12[0] -> 4[0] [send] via NET/IB/1
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 00/0 : 12[0] -> 8[0] [send] via NET/IB/0
gpu-q-49:1203803:1204308 [0] NCCL INFO Channel 01/0 : 12[0] -> 8[0] [send] via NET/IB/1
gpu-q-49:1203803:1204308 [0] NCCL INFO Connected all trees
gpu-q-49:1203803:1204308 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-49:1203803:1204308 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]model.safetensors:   8%|â–Š         | 3.95M/46.8M [00:00<00:01, 30.3MB/s]model.safetensors:  15%|â–ˆâ–Œ        | 7.09M/46.8M [00:00<00:02, 15.8MB/s]model.safetensors:  23%|â–ˆâ–ˆâ–Ž       | 10.8M/46.8M [00:00<00:01, 21.2MB/s]model.safetensors:  34%|â–ˆâ–ˆâ–ˆâ–      | 16.0M/46.8M [00:00<00:01, 17.0MB/s]model.safetensors:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21.8M/46.8M [00:01<00:01, 22.0MB/s]model.safetensors:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24.5M/46.8M [00:01<00:01, 22.3MB/s]model.safetensors:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28.3M/46.8M [00:01<00:00, 23.8MB/s]model.safetensors:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32.0M/46.8M [00:01<00:00, 15.2MB/s]model.safetensors:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 38.0M/46.8M [00:01<00:00, 21.8MB/s]model.safetensors:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41.2M/46.8M [00:02<00:00, 20.7MB/s]model.safetensors:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44.1M/46.8M [00:02<00:00, 15.2MB/s]model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46.8M/46.8M [00:02<00:00, 16.5MB/s]
No files have been modified since last commit. Skipping to prevent empty commit.
bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt:   0%|          | 0.00/2.52M [00:00<?, ?B/s]
Upload 17 LFS files:   0%|          | 0/17 [00:00<?, ?it/s][A

bf16_zero_pp_rank_11_mp_rank_00_optim_states.pt:   0%|          | 0.00/2.52M [00:00<?, ?B/s][A[A


bf16_zero_pp_rank_13_mp_rank_00_optim_states.pt:   0%|          | 0.00/2.52M [00:00<?, ?B/s][A[A[A



bf16_zero_pp_rank_10_mp_rank_00_optim_states.pt:   0%|          | 0.00/2.52M [00:00<?, ?B/s][A[A[A[A




bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt:   0%|          | 0.00/2.52M [00:00<?, ?B/s][A[A[A[A[Abf16_zero_pp_rank_0_mp_rank_00_optim_states.pt:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1.43M/2.52M [00:00<00:00, 12.4MB/s]



bf16_zero_pp_rank_10_mp_rank_00_optim_states.pt:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.52M/2.52M [00:00<00:00, 13.5MB/s][A[A[A[A


bf16_zero_pp_rank_13_mp_rank_00_optim_states.pt:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1.72M/2.52M [00:00<00:00, 14.0MB/s][A[A[Abf16_zero_pp_rank_11_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.52M/2.52M [00:00<00:00, 3.75MB/s]
bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.52M/2.52M [00:00<00:00, 3.74MB/s]
bf16_zero_pp_rank_13_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.52M/2.52M [00:00<00:00, 3.30MB/s]


bf16_zero_pp_rank_14_mp_rank_00_optim_states.pt:   0%|          | 0.00/2.52M [00:00<?, ?B/s][A[A


bf16_zero_pp_rank_15_mp_rank_00_optim_states.pt:   0%|          | 0.00/2.52M [00:00<?, ?B/s][A[A[A




bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt:   0%|          | 0.00/2.52M [00:00<?, ?B/s][A[A[A[A[Abf16_zero_pp_rank_10_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.52M/2.52M [00:00<00:00, 2.64MB/s]
bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.52M/2.52M [00:00<00:00, 2.60MB/s]

Upload 17 LFS files:   6%|â–Œ         | 1/17 [00:01<00:18,  1.13s/it][Abf16_zero_pp_rank_2_mp_rank_00_optim_states.pt:   0%|          | 0.00/2.52M [00:00<?, ?B/s]



bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt:   0%|          | 0.00/2.52M [00:00<?, ?B/s][A[A[A[Abf16_zero_pp_rank_1_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.52M/2.52M [00:00<00:00, 8.88MB/s]





bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt:   0%|          | 0.00/2.52M [00:00<?, ?B/s][A[A[A[A[Abf16_zero_pp_rank_14_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.52M/2.52M [00:00<00:00, 4.05MB/s]
bf16_zero_pp_rank_15_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.52M/2.52M [00:00<00:00, 4.10MB/s]





bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2.44M/2.52M [00:00<00:00, 13.0MB/s][A[A[A[A[A
Upload 17 LFS files:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [00:01<00:02,  4.36it/s][A

bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt:   0%|          | 0.00/2.52M [00:00<?, ?B/s][A[A


bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt:   0%|          | 0.00/2.52M [00:00<?, ?B/s][A[A[Abf16_zero_pp_rank_4_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.52M/2.52M [00:00<00:00, 4.17MB/s]
bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.52M/2.52M [00:00<00:00, 2.77MB/s]
bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.52M/2.52M [00:00<00:00, 2.56MB/s]
bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt:   0%|          | 0.00/2.52M [00:00<?, ?B/s]bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.52M/2.52M [00:00<00:00, 4.05MB/s]


bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt:   0%|          | 0.00/2.52M [00:00<?, ?B/s][A[A
Upload 17 LFS files:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 9/17 [00:02<00:01,  4.50it/s][A



bf16_zero_pp_rank_9_mp_rank_00_optim_states.pt:   0%|          | 0.00/2.52M [00:00<?, ?B/s][A[A[A[Abf16_zero_pp_rank_6_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.52M/2.52M [00:00<00:00, 3.94MB/s]

Upload 17 LFS files:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:02<00:00,  6.23it/s][A


mp_rank_00_model_states.pt:   0%|          | 0.00/26.7M [00:00<?, ?B/s][A[A[Abf16_zero_pp_rank_8_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.52M/2.52M [00:00<00:00, 9.87MB/s]



mp_rank_00_model_states.pt:  17%|â–ˆâ–‹        | 4.62M/26.7M [00:00<00:00, 36.1MB/s][A[A[Abf16_zero_pp_rank_7_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.52M/2.52M [00:00<00:00, 4.05MB/s]



mp_rank_00_model_states.pt:  31%|â–ˆâ–ˆâ–ˆ       | 8.24M/26.7M [00:00<00:01, 17.6MB/s][A[A[A


mp_rank_00_model_states.pt:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 11.7M/26.7M [00:00<00:00, 21.4MB/s][A[A[A
Upload 17 LFS files:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/17 [00:03<00:00,  5.26it/s][Abf16_zero_pp_rank_9_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.52M/2.52M [00:00<00:00, 2.70MB/s]



mp_rank_00_model_states.pt:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16.0M/26.7M [00:00<00:00, 16.6MB/s][A[A[A
Upload 17 LFS files:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [00:03<00:00,  4.96it/s][Amp_rank_00_model_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26.7M/26.7M [00:01<00:00, 19.9MB/s]

Upload 17 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.90it/s][AUpload 17 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  4.24it/s]
2025-03-02 10:11:22,120 - INFO - Step 0 -- ðŸ“Š Evaluation Results
2025-03-02 10:11:22,121 - INFO - â””â”€â”€ paloma: 59435.05139917247
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: yw580 (pico-lm). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.7
wandb: Run data is saved locally in ./wandb/run-20250302_101123-dw3loq2r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pico-relora-tiny-1
wandb: â­ï¸ View project at https://wandb.ai/pico-lm/pico-relora
wandb: ðŸš€ View run at https://wandb.ai/pico-lm/pico-relora/runs/dw3loq2r
2025-03-02 10:11:30,587 - INFO - ==================================================
2025-03-02 10:11:30,587 - INFO - âœ¨ Training Configuration
2025-03-02 10:11:30,588 - INFO - ==================================================
2025-03-02 10:11:30,588 - INFO - Starting from step: 0
2025-03-02 10:11:30,588 - INFO - Model Setup:
2025-03-02 10:11:30,588 - INFO - â””â”€ Total Parameters: 11,682,144
2025-03-02 10:11:30,588 - INFO - â””â”€ Trainable Parameters: 10,060,128
2025-03-02 10:11:30,588 - INFO - â””â”€ Max seq len: 2048
2025-03-02 10:11:30,588 - INFO - Using ReLoRA!
2025-03-02 10:11:30,588 - INFO - â””â”€ Targeting modules: attention, swiglu
2025-03-02 10:11:30,588 - INFO - â””â”€ Reset frequency: 2000
2025-03-02 10:11:30,588 - INFO - â””â”€ LoRA Rank (r): 16
2025-03-02 10:11:30,589 - INFO - Distributed Setup:
2025-03-02 10:11:30,589 - INFO - â””â”€ Number of Devices: 16
2025-03-02 10:11:30,589 - INFO - â””â”€ Device Type: NVIDIA A100-SXM4-80GB
2025-03-02 10:11:30,589 - INFO - Batch Size Configuration:
2025-03-02 10:11:30,589 - INFO - â””â”€ Global Batch Size: 1024
2025-03-02 10:11:30,589 - INFO - â””â”€ Per Device Batch Size: 16
2025-03-02 10:11:30,589 - INFO - â””â”€ Gradient Accumulation Steps: 4
2025-03-02 10:11:30,589 - INFO - ==================================================
2025-03-02 10:11:31,592 - INFO - ðŸªœ Batch step - 0 -- sub batch step 0 -- lr 0.00e+00
/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/fabric.py:668: The `DeepSpeedStrategy` does not support skipping the gradient synchronization. Remove `.no_backward_sync()` from your code or choose a different strategy.
2025-03-02 10:11:37,587 - INFO - ðŸªœ Batch step - 0 -- sub batch step 1 -- lr 0.00e+00
2025-03-02 10:11:39,844 - INFO - ðŸªœ Batch step - 0 -- sub batch step 2 -- lr 0.00e+00
2025-03-02 10:11:42,051 - INFO - ðŸªœ Batch step - 0 -- sub batch step 3 -- lr 0.00e+00
2025-03-02 10:11:43,592 - INFO - Step 0 -- ðŸ”„ Training Metrics
2025-03-02 10:11:43,593 - INFO - â”œâ”€â”€ Loss: 11.0002
2025-03-02 10:11:43,593 - INFO - â”œâ”€â”€ Learning Rate: 0.00e+00
2025-03-02 10:11:43,593 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:11:43,594 - INFO - Step 0 -- ðŸ“ˆ Saving Learning Dynamics
gpu-q-9:206472:206995 [0] NCCL INFO Channel 05/0 : [2025-03-02 10:11:44,018] [WARNING] [engine.py:1244:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****
Saving the dataset (0/1 shards):   0%|          | 0/1024 [00:00<?, ? examples/s]Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:00<00:00, 25602.77 examples/s]Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:00<00:00, 25387.12 examples/s]
/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/huggingface_hub/hf_api.py:3889: UserWarning: It seems that you are about to commit a data file (learning_dynamics/train_data/data-00000-of-00001.arrow) to a model repository. You are sure this is intended? If you are trying to upload a dataset, please set `repo_type='dataset'` or `--repo-type=dataset` in a CLI.
  warnings.warn(
train_activations.pt:   0%|          | 0.00/12.2M [00:00<?, ?B/s]
Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s][A

data-00000-of-00001.arrow:   0%|          | 0.00/17.4M [00:00<?, ?B/s][A[A


train_weights.pt:   0%|          | 0.00/1.52M [00:00<?, ?B/s][A[A[A


train_weights.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.52M/1.52M [00:00<00:00, 13.7MB/s][A[A[A

data-00000-of-00001.arrow:  12%|â–ˆâ–        | 2.10M/17.4M [00:00<00:00, 15.6MB/s][A[Atrain_activations.pt:  13%|â–ˆâ–Ž        | 1.59M/12.2M [00:00<00:00, 10.9MB/s]train_activations.pt:  22%|â–ˆâ–ˆâ–       | 2.69M/12.2M [00:00<00:01, 9.50MB/s]

data-00000-of-00001.arrow:  21%|â–ˆâ–ˆ        | 3.65M/17.4M [00:00<00:01, 12.9MB/s][A[Atrain_activations.pt:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 7.21M/12.2M [00:00<00:00, 23.1MB/s]

data-00000-of-00001.arrow:  29%|â–ˆâ–ˆâ–Š       | 4.98M/17.4M [00:00<00:01, 11.2MB/s][A[A

data-00000-of-00001.arrow:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 8.63M/17.4M [00:00<00:00, 17.8MB/s][A[Atrain_activations.pt:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 10.9M/12.2M [00:00<00:00, 18.3MB/s]train_weights.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.52M/1.52M [00:00<00:00, 1.85MB/s]


data-00000-of-00001.arrow:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16.0M/17.4M [00:00<00:00, 18.9MB/s][A[Atrain_activations.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12.2M/12.2M [00:01<00:00, 9.68MB/s]

Upload 3 LFS files:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:02,  1.45s/it][Adata-00000-of-00001.arrow: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17.4M/17.4M [00:01<00:00, 10.0MB/s]

Upload 3 LFS files:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.14it/s][AUpload 3 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.56it/s]
[2025-03-02 10:12:01,308] [WARNING] [engine.py:1244:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****
Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]
val_activations.pt:   0%|          | 0.00/17.2M [00:00<?, ?B/s][A

val_weights.pt:   0%|          | 0.00/1.52M [00:00<?, ?B/s][A[A
val_activations.pt:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8.06M/17.2M [00:00<00:00, 80.6MB/s][A
val_activations.pt:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16.1M/17.2M [00:00<00:00, 35.7MB/s][Aval_activations.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17.2M/17.2M [00:00<00:00, 26.1MB/s]
val_weights.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.52M/1.52M [00:00<00:00, 1.85MB/s]
Upload 2 LFS files:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.09it/s]Upload 2 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  2.19it/s]Upload 2 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.90it/s]
2025-03-02 10:12:11,762 - INFO - ðŸªœ Batch step - 1 -- sub batch step 4 -- lr 1.50e-07
2025-03-02 10:12:13,928 - INFO - ðŸªœ Batch step - 1 -- sub batch step 5 -- lr 1.50e-07
2025-03-02 10:12:16,089 - INFO - ðŸªœ Batch step - 1 -- sub batch step 6 -- lr 1.50e-07
2025-03-02 10:12:18,597 - INFO - ðŸªœ Batch step - 1 -- sub batch step 7 -- lr 1.50e-07
2025-03-02 10:12:20,219 - INFO - Step 1 -- ðŸ”„ Training Metrics
2025-03-02 10:12:20,219 - INFO - â”œâ”€â”€ Loss: 10.9994
2025-03-02 10:12:20,219 - INFO - â”œâ”€â”€ Learning Rate: 1.50e-07
2025-03-02 10:12:20,219 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:12:20,889 - INFO - ðŸªœ Batch step - 2 -- sub batch step 8 -- lr 3.00e-07
2025-03-02 10:12:23,047 - INFO - ðŸªœ Batch step - 2 -- sub batch step 9 -- lr 3.00e-07
2025-03-02 10:12:25,204 - INFO - ðŸªœ Batch step - 2 -- sub batch step 10 -- lr 3.00e-07
2025-03-02 10:12:27,370 - INFO - ðŸªœ Batch step - 2 -- sub batch step 11 -- lr 3.00e-07
2025-03-02 10:12:28,948 - INFO - Step 2 -- ðŸ”„ Training Metrics
2025-03-02 10:12:28,949 - INFO - â”œâ”€â”€ Loss: 10.9997
2025-03-02 10:12:28,949 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-07
2025-03-02 10:12:28,949 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:12:29,623 - INFO - ðŸªœ Batch step - 3 -- sub batch step 12 -- lr 4.50e-07
2025-03-02 10:12:31,774 - INFO - ðŸªœ Batch step - 3 -- sub batch step 13 -- lr 4.50e-07
2025-03-02 10:12:33,933 - INFO - ðŸªœ Batch step - 3 -- sub batch step 14 -- lr 4.50e-07
2025-03-02 10:12:36,380 - INFO - ðŸªœ Batch step - 3 -- sub batch step 15 -- lr 4.50e-07
2025-03-02 10:12:38,202 - INFO - Step 3 -- ðŸ”„ Training Metrics
2025-03-02 10:12:38,202 - INFO - â”œâ”€â”€ Loss: 10.9978
2025-03-02 10:12:38,202 - INFO - â”œâ”€â”€ Learning Rate: 4.50e-07
2025-03-02 10:12:38,202 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:12:38,870 - INFO - ðŸªœ Batch step - 4 -- sub batch step 16 -- lr 6.00e-07
2025-03-02 10:12:41,027 - INFO - ðŸªœ Batch step - 4 -- sub batch step 17 -- lr 6.00e-07
2025-03-02 10:12:43,181 - INFO - ðŸªœ Batch step - 4 -- sub batch step 18 -- lr 6.00e-07
2025-03-02 10:12:45,353 - INFO - ðŸªœ Batch step - 4 -- sub batch step 19 -- lr 6.00e-07
2025-03-02 10:12:46,919 - INFO - Step 4 -- ðŸ”„ Training Metrics
2025-03-02 10:12:46,920 - INFO - â”œâ”€â”€ Loss: 10.9969
2025-03-02 10:12:46,920 - INFO - â”œâ”€â”€ Learning Rate: 6.00e-07
2025-03-02 10:12:46,920 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:12:47,592 - INFO - ðŸªœ Batch step - 5 -- sub batch step 20 -- lr 7.50e-07
2025-03-02 10:12:49,745 - INFO - ðŸªœ Batch step - 5 -- sub batch step 21 -- lr 7.50e-07
2025-03-02 10:12:51,903 - INFO - ðŸªœ Batch step - 5 -- sub batch step 22 -- lr 7.50e-07
2025-03-02 10:12:54,360 - INFO - ðŸªœ Batch step - 5 -- sub batch step 23 -- lr 7.50e-07
2025-03-02 10:12:56,017 - INFO - Step 5 -- ðŸ”„ Training Metrics
2025-03-02 10:12:56,017 - INFO - â”œâ”€â”€ Loss: 10.9996
2025-03-02 10:12:56,018 - INFO - â”œâ”€â”€ Learning Rate: 7.50e-07
2025-03-02 10:12:56,018 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:12:56,693 - INFO - ðŸªœ Batch step - 6 -- sub batch step 24 -- lr 9.00e-07
2025-03-02 10:12:58,849 - INFO - ðŸªœ Batch step - 6 -- sub batch step 25 -- lr 9.00e-07
2025-03-02 10:13:01,001 - INFO - ðŸªœ Batch step - 6 -- sub batch step 26 -- lr 9.00e-07
2025-03-02 10:13:03,168 - INFO - ðŸªœ Batch step - 6 -- sub batch step 27 -- lr 9.00e-07
2025-03-02 10:13:04,727 - INFO - Step 6 -- ðŸ”„ Training Metrics
2025-03-02 10:13:04,728 - INFO - â”œâ”€â”€ Loss: 10.9996
2025-03-02 10:13:04,728 - INFO - â”œâ”€â”€ Learning Rate: 9.00e-07
2025-03-02 10:13:04,728 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:13:05,396 - INFO - ðŸªœ Batch step - 7 -- sub batch step 28 -- lr 1.05e-06
2025-03-02 10:13:07,554 - INFO - ðŸªœ Batch step - 7 -- sub batch step 29 -- lr 1.05e-06
2025-03-02 10:13:09,709 - INFO - ðŸªœ Batch step - 7 -- sub batch step 30 -- lr 1.05e-06
2025-03-02 10:13:12,139 - INFO - ðŸªœ Batch step - 7 -- sub batch step 31 -- lr 1.05e-06
2025-03-02 10:13:13,902 - INFO - Step 7 -- ðŸ”„ Training Metrics
2025-03-02 10:13:13,902 - INFO - â”œâ”€â”€ Loss: 10.9994
2025-03-02 10:13:13,902 - INFO - â”œâ”€â”€ Learning Rate: 1.05e-06
2025-03-02 10:13:13,902 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:13:14,578 - INFO - ðŸªœ Batch step - 8 -- sub batch step 32 -- lr 1.20e-06
2025-03-02 10:13:16,727 - INFO - ðŸªœ Batch step - 8 -- sub batch step 33 -- lr 1.20e-06
2025-03-02 10:13:18,886 - INFO - ðŸªœ Batch step - 8 -- sub batch step 34 -- lr 1.20e-06
2025-03-02 10:13:21,055 - INFO - ðŸªœ Batch step - 8 -- sub batch step 35 -- lr 1.20e-06
2025-03-02 10:13:22,629 - INFO - Step 8 -- ðŸ”„ Training Metrics
2025-03-02 10:13:22,630 - INFO - â”œâ”€â”€ Loss: 10.9987
2025-03-02 10:13:22,630 - INFO - â”œâ”€â”€ Learning Rate: 1.20e-06
2025-03-02 10:13:22,630 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:13:23,298 - INFO - ðŸªœ Batch step - 9 -- sub batch step 36 -- lr 1.35e-06
2025-03-02 10:13:25,457 - INFO - ðŸªœ Batch step - 9 -- sub batch step 37 -- lr 1.35e-06
2025-03-02 10:13:27,613 - INFO - ðŸªœ Batch step - 9 -- sub batch step 38 -- lr 1.35e-06
2025-03-02 10:13:30,230 - INFO - ðŸªœ Batch step - 9 -- sub batch step 39 -- lr 1.35e-06
2025-03-02 10:13:31,851 - INFO - Step 9 -- ðŸ”„ Training Metrics
2025-03-02 10:13:31,851 - INFO - â”œâ”€â”€ Loss: 10.9990
2025-03-02 10:13:31,851 - INFO - â”œâ”€â”€ Learning Rate: 1.35e-06
2025-03-02 10:13:31,852 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:13:32,526 - INFO - ðŸªœ Batch step - 10 -- sub batch step 40 -- lr 1.50e-06
2025-03-02 10:13:34,677 - INFO - ðŸªœ Batch step - 10 -- sub batch step 41 -- lr 1.50e-06
2025-03-02 10:13:36,836 - INFO - ðŸªœ Batch step - 10 -- sub batch step 42 -- lr 1.50e-06
2025-03-02 10:13:39,005 - INFO - ðŸªœ Batch step - 10 -- sub batch step 43 -- lr 1.50e-06
2025-03-02 10:13:40,567 - INFO - Step 10 -- ðŸ”„ Training Metrics
2025-03-02 10:13:40,568 - INFO - â”œâ”€â”€ Loss: 10.9991
2025-03-02 10:13:40,568 - INFO - â”œâ”€â”€ Learning Rate: 1.50e-06
2025-03-02 10:13:40,568 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:13:41,241 - INFO - ðŸªœ Batch step - 11 -- sub batch step 44 -- lr 1.65e-06
2025-03-02 10:13:43,397 - INFO - ðŸªœ Batch step - 11 -- sub batch step 45 -- lr 1.65e-06
2025-03-02 10:13:46,011 - INFO - ðŸªœ Batch step - 11 -- sub batch step 46 -- lr 1.65e-06
2025-03-02 10:13:48,175 - INFO - ðŸªœ Batch step - 11 -- sub batch step 47 -- lr 1.65e-06
2025-03-02 10:13:49,796 - INFO - Step 11 -- ðŸ”„ Training Metrics
2025-03-02 10:13:49,797 - INFO - â”œâ”€â”€ Loss: 10.9988
2025-03-02 10:13:49,797 - INFO - â”œâ”€â”€ Learning Rate: 1.65e-06
2025-03-02 10:13:49,797 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:13:50,468 - INFO - ðŸªœ Batch step - 12 -- sub batch step 48 -- lr 1.80e-06
2025-03-02 10:13:52,632 - INFO - ðŸªœ Batch step - 12 -- sub batch step 49 -- lr 1.80e-06
2025-03-02 10:13:54,806 - INFO - ðŸªœ Batch step - 12 -- sub batch step 50 -- lr 1.80e-06
2025-03-02 10:13:56,963 - INFO - ðŸªœ Batch step - 12 -- sub batch step 51 -- lr 1.80e-06
2025-03-02 10:13:58,524 - INFO - Step 12 -- ðŸ”„ Training Metrics
2025-03-02 10:13:58,524 - INFO - â”œâ”€â”€ Loss: 10.9998
2025-03-02 10:13:58,524 - INFO - â”œâ”€â”€ Learning Rate: 1.80e-06
2025-03-02 10:13:58,525 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:13:59,202 - INFO - ðŸªœ Batch step - 13 -- sub batch step 52 -- lr 1.95e-06
2025-03-02 10:14:01,357 - INFO - ðŸªœ Batch step - 13 -- sub batch step 53 -- lr 1.95e-06
2025-03-02 10:14:04,191 - INFO - ðŸªœ Batch step - 13 -- sub batch step 54 -- lr 1.95e-06
2025-03-02 10:14:06,356 - INFO - ðŸªœ Batch step - 13 -- sub batch step 55 -- lr 1.95e-06
2025-03-02 10:14:07,850 - INFO - Step 13 -- ðŸ”„ Training Metrics
2025-03-02 10:14:07,850 - INFO - â”œâ”€â”€ Loss: 10.9990
2025-03-02 10:14:07,850 - INFO - â”œâ”€â”€ Learning Rate: 1.95e-06
2025-03-02 10:14:07,850 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:14:08,525 - INFO - ðŸªœ Batch step - 14 -- sub batch step 56 -- lr 2.10e-06
2025-03-02 10:14:10,686 - INFO - ðŸªœ Batch step - 14 -- sub batch step 57 -- lr 2.10e-06
2025-03-02 10:14:12,860 - INFO - ðŸªœ Batch step - 14 -- sub batch step 58 -- lr 2.10e-06
2025-03-02 10:14:15,025 - INFO - ðŸªœ Batch step - 14 -- sub batch step 59 -- lr 2.10e-06
2025-03-02 10:14:16,560 - INFO - Step 14 -- ðŸ”„ Training Metrics
2025-03-02 10:14:16,561 - INFO - â”œâ”€â”€ Loss: 10.9980
2025-03-02 10:14:16,561 - INFO - â”œâ”€â”€ Learning Rate: 2.10e-06
2025-03-02 10:14:16,561 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:14:17,238 - INFO - ðŸªœ Batch step - 15 -- sub batch step 60 -- lr 2.25e-06
2025-03-02 10:14:19,392 - INFO - ðŸªœ Batch step - 15 -- sub batch step 61 -- lr 2.25e-06
2025-03-02 10:14:21,867 - INFO - ðŸªœ Batch step - 15 -- sub batch step 62 -- lr 2.25e-06
2025-03-02 10:14:24,022 - INFO - ðŸªœ Batch step - 15 -- sub batch step 63 -- lr 2.25e-06
2025-03-02 10:14:25,868 - INFO - Step 15 -- ðŸ”„ Training Metrics
2025-03-02 10:14:25,868 - INFO - â”œâ”€â”€ Loss: 10.9982
2025-03-02 10:14:25,868 - INFO - â”œâ”€â”€ Learning Rate: 2.25e-06
2025-03-02 10:14:25,868 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:14:26,547 - INFO - ðŸªœ Batch step - 16 -- sub batch step 64 -- lr 2.40e-06
2025-03-02 10:14:28,704 - INFO - ðŸªœ Batch step - 16 -- sub batch step 65 -- lr 2.40e-06
2025-03-02 10:14:30,872 - INFO - ðŸªœ Batch step - 16 -- sub batch step 66 -- lr 2.40e-06
2025-03-02 10:14:33,032 - INFO - ðŸªœ Batch step - 16 -- sub batch step 67 -- lr 2.40e-06
2025-03-02 10:14:34,586 - INFO - Step 16 -- ðŸ”„ Training Metrics
2025-03-02 10:14:34,586 - INFO - â”œâ”€â”€ Loss: 10.9994
2025-03-02 10:14:34,586 - INFO - â”œâ”€â”€ Learning Rate: 2.40e-06
2025-03-02 10:14:34,586 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:14:35,255 - INFO - ðŸªœ Batch step - 17 -- sub batch step 68 -- lr 2.55e-06
2025-03-02 10:14:37,414 - INFO - ðŸªœ Batch step - 17 -- sub batch step 69 -- lr 2.55e-06
2025-03-02 10:14:39,833 - INFO - ðŸªœ Batch step - 17 -- sub batch step 70 -- lr 2.55e-06
2025-03-02 10:14:41,984 - INFO - ðŸªœ Batch step - 17 -- sub batch step 71 -- lr 2.55e-06
2025-03-02 10:14:43,975 - INFO - Step 17 -- ðŸ”„ Training Metrics
2025-03-02 10:14:43,975 - INFO - â”œâ”€â”€ Loss: 10.9988
2025-03-02 10:14:43,976 - INFO - â”œâ”€â”€ Learning Rate: 2.55e-06
2025-03-02 10:14:43,976 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:14:44,647 - INFO - ðŸªœ Batch step - 18 -- sub batch step 72 -- lr 2.70e-06
2025-03-02 10:14:46,803 - INFO - ðŸªœ Batch step - 18 -- sub batch step 73 -- lr 2.70e-06
2025-03-02 10:14:48,983 - INFO - ðŸªœ Batch step - 18 -- sub batch step 74 -- lr 2.70e-06
2025-03-02 10:14:51,142 - INFO - ðŸªœ Batch step - 18 -- sub batch step 75 -- lr 2.70e-06
2025-03-02 10:14:52,700 - INFO - Step 18 -- ðŸ”„ Training Metrics
2025-03-02 10:14:52,700 - INFO - â”œâ”€â”€ Loss: 10.9985
2025-03-02 10:14:52,700 - INFO - â”œâ”€â”€ Learning Rate: 2.70e-06
2025-03-02 10:14:52,701 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:14:53,369 - INFO - ðŸªœ Batch step - 19 -- sub batch step 76 -- lr 2.85e-06
2025-03-02 10:14:55,525 - INFO - ðŸªœ Batch step - 19 -- sub batch step 77 -- lr 2.85e-06
2025-03-02 10:14:57,813 - INFO - ðŸªœ Batch step - 19 -- sub batch step 78 -- lr 2.85e-06
2025-03-02 10:14:59,979 - INFO - ðŸªœ Batch step - 19 -- sub batch step 79 -- lr 2.85e-06
2025-03-02 10:15:01,516 - INFO - Step 19 -- ðŸ”„ Training Metrics
2025-03-02 10:15:01,517 - INFO - â”œâ”€â”€ Loss: 10.9981
2025-03-02 10:15:01,517 - INFO - â”œâ”€â”€ Learning Rate: 2.85e-06
2025-03-02 10:15:01,517 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:15:02,705 - INFO - ðŸªœ Batch step - 20 -- sub batch step 80 -- lr 3.00e-06
2025-03-02 10:15:04,866 - INFO - ðŸªœ Batch step - 20 -- sub batch step 81 -- lr 3.00e-06
2025-03-02 10:15:07,029 - INFO - ðŸªœ Batch step - 20 -- sub batch step 82 -- lr 3.00e-06
2025-03-02 10:15:09,202 - INFO - ðŸªœ Batch step - 20 -- sub batch step 83 -- lr 3.00e-06
2025-03-02 10:15:10,821 - INFO - Step 20 -- ðŸ”„ Training Metrics
2025-03-02 10:15:10,822 - INFO - â”œâ”€â”€ Loss: 10.9999
2025-03-02 10:15:10,822 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-06
2025-03-02 10:15:10,822 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:15:11,499 - INFO - ðŸªœ Batch step - 21 -- sub batch step 84 -- lr 3.15e-06
2025-03-02 10:15:13,657 - INFO - ðŸªœ Batch step - 21 -- sub batch step 85 -- lr 3.15e-06
2025-03-02 10:15:15,811 - INFO - ðŸªœ Batch step - 21 -- sub batch step 86 -- lr 3.15e-06
2025-03-02 10:15:18,336 - INFO - ðŸªœ Batch step - 21 -- sub batch step 87 -- lr 3.15e-06
2025-03-02 10:15:19,848 - INFO - Step 21 -- ðŸ”„ Training Metrics
2025-03-02 10:15:19,848 - INFO - â”œâ”€â”€ Loss: 10.9979
2025-03-02 10:15:19,849 - INFO - â”œâ”€â”€ Learning Rate: 3.15e-06
2025-03-02 10:15:19,849 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:15:20,531 - INFO - ðŸªœ Batch step - 22 -- sub batch step 88 -- lr 3.30e-06
2025-03-02 10:15:22,700 - INFO - ðŸªœ Batch step - 22 -- sub batch step 89 -- lr 3.30e-06
2025-03-02 10:15:24,868 - INFO - ðŸªœ Batch step - 22 -- sub batch step 90 -- lr 3.30e-06
2025-03-02 10:15:27,041 - INFO - ðŸªœ Batch step - 22 -- sub batch step 91 -- lr 3.30e-06
2025-03-02 10:15:28,565 - INFO - Step 22 -- ðŸ”„ Training Metrics
2025-03-02 10:15:28,566 - INFO - â”œâ”€â”€ Loss: 10.9990
2025-03-02 10:15:28,566 - INFO - â”œâ”€â”€ Learning Rate: 3.30e-06
2025-03-02 10:15:28,566 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:15:29,242 - INFO - ðŸªœ Batch step - 23 -- sub batch step 92 -- lr 3.45e-06
2025-03-02 10:15:31,399 - INFO - ðŸªœ Batch step - 23 -- sub batch step 93 -- lr 3.45e-06
2025-03-02 10:15:33,565 - INFO - ðŸªœ Batch step - 23 -- sub batch step 94 -- lr 3.45e-06
2025-03-02 10:15:36,022 - INFO - ðŸªœ Batch step - 23 -- sub batch step 95 -- lr 3.45e-06
2025-03-02 10:15:37,878 - INFO - Step 23 -- ðŸ”„ Training Metrics
2025-03-02 10:15:37,878 - INFO - â”œâ”€â”€ Loss: 10.9994
2025-03-02 10:15:37,878 - INFO - â”œâ”€â”€ Learning Rate: 3.45e-06
2025-03-02 10:15:37,878 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:15:38,552 - INFO - ðŸªœ Batch step - 24 -- sub batch step 96 -- lr 3.60e-06
2025-03-02 10:15:40,707 - INFO - ðŸªœ Batch step - 24 -- sub batch step 97 -- lr 3.60e-06
2025-03-02 10:15:42,857 - INFO - ðŸªœ Batch step - 24 -- sub batch step 98 -- lr 3.60e-06
2025-03-02 10:15:45,038 - INFO - ðŸªœ Batch step - 24 -- sub batch step 99 -- lr 3.60e-06
2025-03-02 10:15:46,592 - INFO - Step 24 -- ðŸ”„ Training Metrics
2025-03-02 10:15:46,592 - INFO - â”œâ”€â”€ Loss: 10.9994
2025-03-02 10:15:46,593 - INFO - â”œâ”€â”€ Learning Rate: 3.60e-06
2025-03-02 10:15:46,593 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:15:47,278 - INFO - ðŸªœ Batch step - 25 -- sub batch step 100 -- lr 3.75e-06
2025-03-02 10:15:49,436 - INFO - ðŸªœ Batch step - 25 -- sub batch step 101 -- lr 3.75e-06
2025-03-02 10:15:51,598 - INFO - ðŸªœ Batch step - 25 -- sub batch step 102 -- lr 3.75e-06
2025-03-02 10:15:54,250 - INFO - ðŸªœ Batch step - 25 -- sub batch step 103 -- lr 3.75e-06
2025-03-02 10:15:55,739 - INFO - Step 25 -- ðŸ”„ Training Metrics
2025-03-02 10:15:55,739 - INFO - â”œâ”€â”€ Loss: 10.9996
2025-03-02 10:15:55,739 - INFO - â”œâ”€â”€ Learning Rate: 3.75e-06
2025-03-02 10:15:55,740 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:15:56,419 - INFO - ðŸªœ Batch step - 26 -- sub batch step 104 -- lr 3.90e-06
2025-03-02 10:15:58,579 - INFO - ðŸªœ Batch step - 26 -- sub batch step 105 -- lr 3.90e-06
2025-03-02 10:16:00,734 - INFO - ðŸªœ Batch step - 26 -- sub batch step 106 -- lr 3.90e-06
2025-03-02 10:16:02,915 - INFO - ðŸªœ Batch step - 26 -- sub batch step 107 -- lr 3.90e-06
2025-03-02 10:16:04,457 - INFO - Step 26 -- ðŸ”„ Training Metrics
2025-03-02 10:16:04,458 - INFO - â”œâ”€â”€ Loss: 10.9987
2025-03-02 10:16:04,458 - INFO - â”œâ”€â”€ Learning Rate: 3.90e-06
2025-03-02 10:16:04,458 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:16:05,133 - INFO - ðŸªœ Batch step - 27 -- sub batch step 108 -- lr 4.05e-06
2025-03-02 10:16:07,298 - INFO - ðŸªœ Batch step - 27 -- sub batch step 109 -- lr 4.05e-06
2025-03-02 10:16:09,458 - INFO - ðŸªœ Batch step - 27 -- sub batch step 110 -- lr 4.05e-06
2025-03-02 10:16:12,090 - INFO - ðŸªœ Batch step - 27 -- sub batch step 111 -- lr 4.05e-06
2025-03-02 10:16:13,716 - INFO - Step 27 -- ðŸ”„ Training Metrics
2025-03-02 10:16:13,716 - INFO - â”œâ”€â”€ Loss: 10.9986
2025-03-02 10:16:13,716 - INFO - â”œâ”€â”€ Learning Rate: 4.05e-06
2025-03-02 10:16:13,716 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:16:14,395 - INFO - ðŸªœ Batch step - 28 -- sub batch step 112 -- lr 4.20e-06
2025-03-02 10:16:16,548 - INFO - ðŸªœ Batch step - 28 -- sub batch step 113 -- lr 4.20e-06
2025-03-02 10:16:18,712 - INFO - ðŸªœ Batch step - 28 -- sub batch step 114 -- lr 4.20e-06
2025-03-02 10:16:20,889 - INFO - ðŸªœ Batch step - 28 -- sub batch step 115 -- lr 4.20e-06
2025-03-02 10:16:22,438 - INFO - Step 28 -- ðŸ”„ Training Metrics
2025-03-02 10:16:22,438 - INFO - â”œâ”€â”€ Loss: 10.9991
2025-03-02 10:16:22,438 - INFO - â”œâ”€â”€ Learning Rate: 4.20e-06
2025-03-02 10:16:22,438 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:16:23,112 - INFO - ðŸªœ Batch step - 29 -- sub batch step 116 -- lr 4.35e-06
2025-03-02 10:16:25,270 - INFO - ðŸªœ Batch step - 29 -- sub batch step 117 -- lr 4.35e-06
2025-03-02 10:16:27,427 - INFO - ðŸªœ Batch step - 29 -- sub batch step 118 -- lr 4.35e-06
2025-03-02 10:16:29,851 - INFO - ðŸªœ Batch step - 29 -- sub batch step 119 -- lr 4.35e-06
2025-03-02 10:16:31,624 - INFO - Step 29 -- ðŸ”„ Training Metrics
2025-03-02 10:16:31,625 - INFO - â”œâ”€â”€ Loss: 10.9989
2025-03-02 10:16:31,625 - INFO - â”œâ”€â”€ Learning Rate: 4.35e-06
2025-03-02 10:16:31,625 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:16:32,305 - INFO - ðŸªœ Batch step - 30 -- sub batch step 120 -- lr 4.50e-06
2025-03-02 10:16:34,463 - INFO - ðŸªœ Batch step - 30 -- sub batch step 121 -- lr 4.50e-06
2025-03-02 10:16:36,629 - INFO - ðŸªœ Batch step - 30 -- sub batch step 122 -- lr 4.50e-06
2025-03-02 10:16:38,808 - INFO - ðŸªœ Batch step - 30 -- sub batch step 123 -- lr 4.50e-06
2025-03-02 10:16:40,352 - INFO - Step 30 -- ðŸ”„ Training Metrics
2025-03-02 10:16:40,352 - INFO - â”œâ”€â”€ Loss: 10.9991
2025-03-02 10:16:40,352 - INFO - â”œâ”€â”€ Learning Rate: 4.50e-06
2025-03-02 10:16:40,352 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:16:41,034 - INFO - ðŸªœ Batch step - 31 -- sub batch step 124 -- lr 4.65e-06
2025-03-02 10:16:43,195 - INFO - ðŸªœ Batch step - 31 -- sub batch step 125 -- lr 4.65e-06
2025-03-02 10:16:45,833 - INFO - ðŸªœ Batch step - 31 -- sub batch step 126 -- lr 4.65e-06
2025-03-02 10:16:47,989 - INFO - ðŸªœ Batch step - 31 -- sub batch step 127 -- lr 4.65e-06
2025-03-02 10:16:49,537 - INFO - Step 31 -- ðŸ”„ Training Metrics
2025-03-02 10:16:49,537 - INFO - â”œâ”€â”€ Loss: 10.9999
2025-03-02 10:16:49,537 - INFO - â”œâ”€â”€ Learning Rate: 4.65e-06
2025-03-02 10:16:49,538 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:16:50,211 - INFO - ðŸªœ Batch step - 32 -- sub batch step 128 -- lr 4.80e-06
2025-03-02 10:16:52,376 - INFO - ðŸªœ Batch step - 32 -- sub batch step 129 -- lr 4.80e-06
2025-03-02 10:16:54,554 - INFO - ðŸªœ Batch step - 32 -- sub batch step 130 -- lr 4.80e-06
2025-03-02 10:16:56,708 - INFO - ðŸªœ Batch step - 32 -- sub batch step 131 -- lr 4.80e-06
2025-03-02 10:16:58,253 - INFO - Step 32 -- ðŸ”„ Training Metrics
2025-03-02 10:16:58,253 - INFO - â”œâ”€â”€ Loss: 10.9994
2025-03-02 10:16:58,253 - INFO - â”œâ”€â”€ Learning Rate: 4.80e-06
2025-03-02 10:16:58,253 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:16:58,931 - INFO - ðŸªœ Batch step - 33 -- sub batch step 132 -- lr 4.95e-06
2025-03-02 10:17:01,086 - INFO - ðŸªœ Batch step - 33 -- sub batch step 133 -- lr 4.95e-06
2025-03-02 10:17:03,796 - INFO - ðŸªœ Batch step - 33 -- sub batch step 134 -- lr 4.95e-06
2025-03-02 10:17:05,955 - INFO - ðŸªœ Batch step - 33 -- sub batch step 135 -- lr 4.95e-06
2025-03-02 10:17:07,532 - INFO - Step 33 -- ðŸ”„ Training Metrics
2025-03-02 10:17:07,532 - INFO - â”œâ”€â”€ Loss: 10.9979
2025-03-02 10:17:07,532 - INFO - â”œâ”€â”€ Learning Rate: 4.95e-06
2025-03-02 10:17:07,532 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:17:08,203 - INFO - ðŸªœ Batch step - 34 -- sub batch step 136 -- lr 5.10e-06
2025-03-02 10:17:10,360 - INFO - ðŸªœ Batch step - 34 -- sub batch step 137 -- lr 5.10e-06
2025-03-02 10:17:12,535 - INFO - ðŸªœ Batch step - 34 -- sub batch step 138 -- lr 5.10e-06
2025-03-02 10:17:14,698 - INFO - ðŸªœ Batch step - 34 -- sub batch step 139 -- lr 5.10e-06
2025-03-02 10:17:16,238 - INFO - Step 34 -- ðŸ”„ Training Metrics
2025-03-02 10:17:16,239 - INFO - â”œâ”€â”€ Loss: 11.0001
2025-03-02 10:17:16,239 - INFO - â”œâ”€â”€ Learning Rate: 5.10e-06
2025-03-02 10:17:16,239 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:17:16,916 - INFO - ðŸªœ Batch step - 35 -- sub batch step 140 -- lr 5.25e-06
2025-03-02 10:17:19,074 - INFO - ðŸªœ Batch step - 35 -- sub batch step 141 -- lr 5.25e-06
2025-03-02 10:17:21,759 - INFO - ðŸªœ Batch step - 35 -- sub batch step 142 -- lr 5.25e-06
2025-03-02 10:17:23,911 - INFO - ðŸªœ Batch step - 35 -- sub batch step 143 -- lr 5.25e-06
2025-03-02 10:17:25,608 - INFO - Step 35 -- ðŸ”„ Training Metrics
2025-03-02 10:17:25,609 - INFO - â”œâ”€â”€ Loss: 10.9986
2025-03-02 10:17:25,609 - INFO - â”œâ”€â”€ Learning Rate: 5.25e-06
2025-03-02 10:17:25,609 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:17:26,290 - INFO - ðŸªœ Batch step - 36 -- sub batch step 144 -- lr 5.40e-06
2025-03-02 10:17:28,447 - INFO - ðŸªœ Batch step - 36 -- sub batch step 145 -- lr 5.40e-06
2025-03-02 10:17:30,618 - INFO - ðŸªœ Batch step - 36 -- sub batch step 146 -- lr 5.40e-06
2025-03-02 10:17:32,784 - INFO - ðŸªœ Batch step - 36 -- sub batch step 147 -- lr 5.40e-06
2025-03-02 10:17:34,329 - INFO - Step 36 -- ðŸ”„ Training Metrics
2025-03-02 10:17:34,330 - INFO - â”œâ”€â”€ Loss: 10.9983
2025-03-02 10:17:34,330 - INFO - â”œâ”€â”€ Learning Rate: 5.40e-06
2025-03-02 10:17:34,330 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:17:35,007 - INFO - ðŸªœ Batch step - 37 -- sub batch step 148 -- lr 5.55e-06
2025-03-02 10:17:37,171 - INFO - ðŸªœ Batch step - 37 -- sub batch step 149 -- lr 5.55e-06
2025-03-02 10:17:39,857 - INFO - ðŸªœ Batch step - 37 -- sub batch step 150 -- lr 5.55e-06
2025-03-02 10:17:42,011 - INFO - ðŸªœ Batch step - 37 -- sub batch step 151 -- lr 5.55e-06
2025-03-02 10:17:43,673 - INFO - Step 37 -- ðŸ”„ Training Metrics
2025-03-02 10:17:43,674 - INFO - â”œâ”€â”€ Loss: 10.9995
2025-03-02 10:17:43,674 - INFO - â”œâ”€â”€ Learning Rate: 5.55e-06
2025-03-02 10:17:43,674 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:17:44,353 - INFO - ðŸªœ Batch step - 38 -- sub batch step 152 -- lr 5.70e-06
2025-03-02 10:17:46,505 - INFO - ðŸªœ Batch step - 38 -- sub batch step 153 -- lr 5.70e-06
2025-03-02 10:17:48,684 - INFO - ðŸªœ Batch step - 38 -- sub batch step 154 -- lr 5.70e-06
2025-03-02 10:17:50,848 - INFO - ðŸªœ Batch step - 38 -- sub batch step 155 -- lr 5.70e-06
2025-03-02 10:17:52,385 - INFO - Step 38 -- ðŸ”„ Training Metrics
2025-03-02 10:17:52,386 - INFO - â”œâ”€â”€ Loss: 10.9970
2025-03-02 10:17:52,386 - INFO - â”œâ”€â”€ Learning Rate: 5.70e-06
2025-03-02 10:17:52,386 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:17:53,058 - INFO - ðŸªœ Batch step - 39 -- sub batch step 156 -- lr 5.85e-06
2025-03-02 10:17:55,217 - INFO - ðŸªœ Batch step - 39 -- sub batch step 157 -- lr 5.85e-06
2025-03-02 10:17:57,576 - INFO - ðŸªœ Batch step - 39 -- sub batch step 158 -- lr 5.85e-06
2025-03-02 10:17:59,735 - INFO - ðŸªœ Batch step - 39 -- sub batch step 159 -- lr 5.85e-06
2025-03-02 10:18:01,223 - INFO - Step 39 -- ðŸ”„ Training Metrics
2025-03-02 10:18:01,223 - INFO - â”œâ”€â”€ Loss: 10.9991
2025-03-02 10:18:01,223 - INFO - â”œâ”€â”€ Learning Rate: 5.85e-06
2025-03-02 10:18:01,223 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:18:02,447 - INFO - ðŸªœ Batch step - 40 -- sub batch step 160 -- lr 6.00e-06
2025-03-02 10:18:04,605 - INFO - ðŸªœ Batch step - 40 -- sub batch step 161 -- lr 6.00e-06
2025-03-02 10:18:06,776 - INFO - ðŸªœ Batch step - 40 -- sub batch step 162 -- lr 6.00e-06
2025-03-02 10:18:08,960 - INFO - ðŸªœ Batch step - 40 -- sub batch step 163 -- lr 6.00e-06
2025-03-02 10:18:10,616 - INFO - Step 40 -- ðŸ”„ Training Metrics
2025-03-02 10:18:10,617 - INFO - â”œâ”€â”€ Loss: 10.9987
2025-03-02 10:18:10,617 - INFO - â”œâ”€â”€ Learning Rate: 6.00e-06
2025-03-02 10:18:10,617 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:18:11,299 - INFO - ðŸªœ Batch step - 41 -- sub batch step 164 -- lr 6.15e-06
2025-03-02 10:18:13,465 - INFO - ðŸªœ Batch step - 41 -- sub batch step 165 -- lr 6.15e-06
2025-03-02 10:18:15,622 - INFO - ðŸªœ Batch step - 41 -- sub batch step 166 -- lr 6.15e-06
2025-03-02 10:18:18,124 - INFO - ðŸªœ Batch step - 41 -- sub batch step 167 -- lr 6.15e-06
2025-03-02 10:18:20,066 - INFO - Step 41 -- ðŸ”„ Training Metrics
2025-03-02 10:18:20,066 - INFO - â”œâ”€â”€ Loss: 10.9984
2025-03-02 10:18:20,066 - INFO - â”œâ”€â”€ Learning Rate: 6.15e-06
2025-03-02 10:18:20,066 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:18:20,742 - INFO - ðŸªœ Batch step - 42 -- sub batch step 168 -- lr 6.30e-06
2025-03-02 10:18:22,904 - INFO - ðŸªœ Batch step - 42 -- sub batch step 169 -- lr 6.30e-06
2025-03-02 10:18:25,066 - INFO - ðŸªœ Batch step - 42 -- sub batch step 170 -- lr 6.30e-06
2025-03-02 10:18:27,241 - INFO - ðŸªœ Batch step - 42 -- sub batch step 171 -- lr 6.30e-06
2025-03-02 10:18:28,789 - INFO - Step 42 -- ðŸ”„ Training Metrics
2025-03-02 10:18:28,789 - INFO - â”œâ”€â”€ Loss: 10.9965
2025-03-02 10:18:28,790 - INFO - â”œâ”€â”€ Learning Rate: 6.30e-06
2025-03-02 10:18:28,790 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:18:29,470 - INFO - ðŸªœ Batch step - 43 -- sub batch step 172 -- lr 6.45e-06
2025-03-02 10:18:31,626 - INFO - ðŸªœ Batch step - 43 -- sub batch step 173 -- lr 6.45e-06
2025-03-02 10:18:33,790 - INFO - ðŸªœ Batch step - 43 -- sub batch step 174 -- lr 6.45e-06
2025-03-02 10:18:36,613 - INFO - ðŸªœ Batch step - 43 -- sub batch step 175 -- lr 6.45e-06
2025-03-02 10:18:38,213 - INFO - Step 43 -- ðŸ”„ Training Metrics
2025-03-02 10:18:38,214 - INFO - â”œâ”€â”€ Loss: 10.9976
2025-03-02 10:18:38,214 - INFO - â”œâ”€â”€ Learning Rate: 6.45e-06
2025-03-02 10:18:38,214 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:18:38,890 - INFO - ðŸªœ Batch step - 44 -- sub batch step 176 -- lr 6.60e-06
2025-03-02 10:18:41,047 - INFO - ðŸªœ Batch step - 44 -- sub batch step 177 -- lr 6.60e-06
2025-03-02 10:18:43,203 - INFO - ðŸªœ Batch step - 44 -- sub batch step 178 -- lr 6.60e-06
2025-03-02 10:18:45,384 - INFO - ðŸªœ Batch step - 44 -- sub batch step 179 -- lr 6.60e-06
2025-03-02 10:18:46,940 - INFO - Step 44 -- ðŸ”„ Training Metrics
2025-03-02 10:18:46,940 - INFO - â”œâ”€â”€ Loss: 10.9977
2025-03-02 10:18:46,940 - INFO - â”œâ”€â”€ Learning Rate: 6.60e-06
2025-03-02 10:18:46,941 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:18:47,620 - INFO - ðŸªœ Batch step - 45 -- sub batch step 180 -- lr 6.75e-06
2025-03-02 10:18:49,774 - INFO - ðŸªœ Batch step - 45 -- sub batch step 181 -- lr 6.75e-06
2025-03-02 10:18:51,940 - INFO - ðŸªœ Batch step - 45 -- sub batch step 182 -- lr 6.75e-06
2025-03-02 10:18:54,408 - INFO - ðŸªœ Batch step - 45 -- sub batch step 183 -- lr 6.75e-06
2025-03-02 10:18:56,158 - INFO - Step 45 -- ðŸ”„ Training Metrics
2025-03-02 10:18:56,158 - INFO - â”œâ”€â”€ Loss: 10.9976
2025-03-02 10:18:56,158 - INFO - â”œâ”€â”€ Learning Rate: 6.75e-06
2025-03-02 10:18:56,158 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:18:56,838 - INFO - ðŸªœ Batch step - 46 -- sub batch step 184 -- lr 6.90e-06
2025-03-02 10:18:58,996 - INFO - ðŸªœ Batch step - 46 -- sub batch step 185 -- lr 6.90e-06
2025-03-02 10:19:01,144 - INFO - ðŸªœ Batch step - 46 -- sub batch step 186 -- lr 6.90e-06
2025-03-02 10:19:03,321 - INFO - ðŸªœ Batch step - 46 -- sub batch step 187 -- lr 6.90e-06
2025-03-02 10:19:04,887 - INFO - Step 46 -- ðŸ”„ Training Metrics
2025-03-02 10:19:04,887 - INFO - â”œâ”€â”€ Loss: 10.9971
2025-03-02 10:19:04,887 - INFO - â”œâ”€â”€ Learning Rate: 6.90e-06
2025-03-02 10:19:04,888 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:19:05,560 - INFO - ðŸªœ Batch step - 47 -- sub batch step 188 -- lr 7.05e-06
2025-03-02 10:19:07,724 - INFO - ðŸªœ Batch step - 47 -- sub batch step 189 -- lr 7.05e-06
2025-03-02 10:19:09,885 - INFO - ðŸªœ Batch step - 47 -- sub batch step 190 -- lr 7.05e-06
2025-03-02 10:19:12,677 - INFO - ðŸªœ Batch step - 47 -- sub batch step 191 -- lr 7.05e-06
2025-03-02 10:19:14,172 - INFO - Step 47 -- ðŸ”„ Training Metrics
2025-03-02 10:19:14,172 - INFO - â”œâ”€â”€ Loss: 10.9974
2025-03-02 10:19:14,172 - INFO - â”œâ”€â”€ Learning Rate: 7.05e-06
2025-03-02 10:19:14,172 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:19:14,849 - INFO - ðŸªœ Batch step - 48 -- sub batch step 192 -- lr 7.20e-06
2025-03-02 10:19:17,003 - INFO - ðŸªœ Batch step - 48 -- sub batch step 193 -- lr 7.20e-06
2025-03-02 10:19:19,164 - INFO - ðŸªœ Batch step - 48 -- sub batch step 194 -- lr 7.20e-06
2025-03-02 10:19:21,340 - INFO - ðŸªœ Batch step - 48 -- sub batch step 195 -- lr 7.20e-06
2025-03-02 10:19:22,899 - INFO - Step 48 -- ðŸ”„ Training Metrics
2025-03-02 10:19:22,899 - INFO - â”œâ”€â”€ Loss: 10.9971
2025-03-02 10:19:22,899 - INFO - â”œâ”€â”€ Learning Rate: 7.20e-06
2025-03-02 10:19:22,899 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:19:23,572 - INFO - ðŸªœ Batch step - 49 -- sub batch step 196 -- lr 7.35e-06
2025-03-02 10:19:25,732 - INFO - ðŸªœ Batch step - 49 -- sub batch step 197 -- lr 7.35e-06
2025-03-02 10:19:27,887 - INFO - ðŸªœ Batch step - 49 -- sub batch step 198 -- lr 7.35e-06
2025-03-02 10:19:30,479 - INFO - ðŸªœ Batch step - 49 -- sub batch step 199 -- lr 7.35e-06
2025-03-02 10:19:32,174 - INFO - Step 49 -- ðŸ”„ Training Metrics
2025-03-02 10:19:32,174 - INFO - â”œâ”€â”€ Loss: 10.9972
2025-03-02 10:19:32,174 - INFO - â”œâ”€â”€ Learning Rate: 7.35e-06
2025-03-02 10:19:32,174 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:19:32,855 - INFO - ðŸªœ Batch step - 50 -- sub batch step 200 -- lr 7.50e-06
2025-03-02 10:19:35,010 - INFO - ðŸªœ Batch step - 50 -- sub batch step 201 -- lr 7.50e-06
2025-03-02 10:19:37,171 - INFO - ðŸªœ Batch step - 50 -- sub batch step 202 -- lr 7.50e-06
2025-03-02 10:19:39,341 - INFO - ðŸªœ Batch step - 50 -- sub batch step 203 -- lr 7.50e-06
2025-03-02 10:19:40,885 - INFO - Step 50 -- ðŸ”„ Training Metrics
2025-03-02 10:19:40,885 - INFO - â”œâ”€â”€ Loss: 10.9951
2025-03-02 10:19:40,885 - INFO - â”œâ”€â”€ Learning Rate: 7.50e-06
2025-03-02 10:19:40,886 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:19:41,558 - INFO - ðŸªœ Batch step - 51 -- sub batch step 204 -- lr 7.65e-06
2025-03-02 10:19:43,717 - INFO - ðŸªœ Batch step - 51 -- sub batch step 205 -- lr 7.65e-06
2025-03-02 10:19:46,379 - INFO - ðŸªœ Batch step - 51 -- sub batch step 206 -- lr 7.65e-06
2025-03-02 10:19:48,541 - INFO - ðŸªœ Batch step - 51 -- sub batch step 207 -- lr 7.65e-06
2025-03-02 10:19:50,091 - INFO - Step 51 -- ðŸ”„ Training Metrics
2025-03-02 10:19:50,091 - INFO - â”œâ”€â”€ Loss: 10.9971
2025-03-02 10:19:50,092 - INFO - â”œâ”€â”€ Learning Rate: 7.65e-06
2025-03-02 10:19:50,092 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:19:50,759 - INFO - ðŸªœ Batch step - 52 -- sub batch step 208 -- lr 7.80e-06
2025-03-02 10:19:52,919 - INFO - ðŸªœ Batch step - 52 -- sub batch step 209 -- lr 7.80e-06
2025-03-02 10:19:55,093 - INFO - ðŸªœ Batch step - 52 -- sub batch step 210 -- lr 7.80e-06
2025-03-02 10:19:57,248 - INFO - ðŸªœ Batch step - 52 -- sub batch step 211 -- lr 7.80e-06
2025-03-02 10:19:58,810 - INFO - Step 52 -- ðŸ”„ Training Metrics
2025-03-02 10:19:58,810 - INFO - â”œâ”€â”€ Loss: 10.9979
2025-03-02 10:19:58,810 - INFO - â”œâ”€â”€ Learning Rate: 7.80e-06
2025-03-02 10:19:58,810 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:19:59,487 - INFO - ðŸªœ Batch step - 53 -- sub batch step 212 -- lr 7.95e-06
2025-03-02 10:20:01,640 - INFO - ðŸªœ Batch step - 53 -- sub batch step 213 -- lr 7.95e-06
2025-03-02 10:20:04,214 - INFO - ðŸªœ Batch step - 53 -- sub batch step 214 -- lr 7.95e-06
2025-03-02 10:20:06,373 - INFO - ðŸªœ Batch step - 53 -- sub batch step 215 -- lr 7.95e-06
2025-03-02 10:20:08,180 - INFO - Step 53 -- ðŸ”„ Training Metrics
2025-03-02 10:20:08,180 - INFO - â”œâ”€â”€ Loss: 10.9971
2025-03-02 10:20:08,180 - INFO - â”œâ”€â”€ Learning Rate: 7.95e-06
2025-03-02 10:20:08,180 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:20:08,850 - INFO - ðŸªœ Batch step - 54 -- sub batch step 216 -- lr 8.10e-06
2025-03-02 10:20:11,004 - INFO - ðŸªœ Batch step - 54 -- sub batch step 217 -- lr 8.10e-06
2025-03-02 10:20:13,177 - INFO - ðŸªœ Batch step - 54 -- sub batch step 218 -- lr 8.10e-06
2025-03-02 10:20:15,338 - INFO - ðŸªœ Batch step - 54 -- sub batch step 219 -- lr 8.10e-06
2025-03-02 10:20:16,903 - INFO - Step 54 -- ðŸ”„ Training Metrics
2025-03-02 10:20:16,903 - INFO - â”œâ”€â”€ Loss: 10.9967
2025-03-02 10:20:16,903 - INFO - â”œâ”€â”€ Learning Rate: 8.10e-06
2025-03-02 10:20:16,903 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:20:17,576 - INFO - ðŸªœ Batch step - 55 -- sub batch step 220 -- lr 8.25e-06
2025-03-02 10:20:19,730 - INFO - ðŸªœ Batch step - 55 -- sub batch step 221 -- lr 8.25e-06
2025-03-02 10:20:22,112 - INFO - ðŸªœ Batch step - 55 -- sub batch step 222 -- lr 8.25e-06
2025-03-02 10:20:24,266 - INFO - ðŸªœ Batch step - 55 -- sub batch step 223 -- lr 8.25e-06
2025-03-02 10:20:26,178 - INFO - Step 55 -- ðŸ”„ Training Metrics
2025-03-02 10:20:26,179 - INFO - â”œâ”€â”€ Loss: 10.9972
2025-03-02 10:20:26,179 - INFO - â”œâ”€â”€ Learning Rate: 8.25e-06
2025-03-02 10:20:26,179 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:20:26,851 - INFO - ðŸªœ Batch step - 56 -- sub batch step 224 -- lr 8.40e-06
2025-03-02 10:20:29,007 - INFO - ðŸªœ Batch step - 56 -- sub batch step 225 -- lr 8.40e-06
2025-03-02 10:20:31,175 - INFO - ðŸªœ Batch step - 56 -- sub batch step 226 -- lr 8.40e-06
2025-03-02 10:20:33,333 - INFO - ðŸªœ Batch step - 56 -- sub batch step 227 -- lr 8.40e-06
2025-03-02 10:20:34,905 - INFO - Step 56 -- ðŸ”„ Training Metrics
2025-03-02 10:20:34,905 - INFO - â”œâ”€â”€ Loss: 10.9960
2025-03-02 10:20:34,905 - INFO - â”œâ”€â”€ Learning Rate: 8.40e-06
2025-03-02 10:20:34,906 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:20:35,572 - INFO - ðŸªœ Batch step - 57 -- sub batch step 228 -- lr 8.55e-06
2025-03-02 10:20:37,731 - INFO - ðŸªœ Batch step - 57 -- sub batch step 229 -- lr 8.55e-06
2025-03-02 10:20:40,530 - INFO - ðŸªœ Batch step - 57 -- sub batch step 230 -- lr 8.55e-06
2025-03-02 10:20:42,686 - INFO - ðŸªœ Batch step - 57 -- sub batch step 231 -- lr 8.55e-06
2025-03-02 10:20:44,179 - INFO - Step 57 -- ðŸ”„ Training Metrics
2025-03-02 10:20:44,180 - INFO - â”œâ”€â”€ Loss: 10.9973
2025-03-02 10:20:44,180 - INFO - â”œâ”€â”€ Learning Rate: 8.55e-06
2025-03-02 10:20:44,180 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:20:44,854 - INFO - ðŸªœ Batch step - 58 -- sub batch step 232 -- lr 8.70e-06
2025-03-02 10:20:47,005 - INFO - ðŸªœ Batch step - 58 -- sub batch step 233 -- lr 8.70e-06
2025-03-02 10:20:49,180 - INFO - ðŸªœ Batch step - 58 -- sub batch step 234 -- lr 8.70e-06
2025-03-02 10:20:51,339 - INFO - ðŸªœ Batch step - 58 -- sub batch step 235 -- lr 8.70e-06
2025-03-02 10:20:52,903 - INFO - Step 58 -- ðŸ”„ Training Metrics
2025-03-02 10:20:52,903 - INFO - â”œâ”€â”€ Loss: 10.9946
2025-03-02 10:20:52,903 - INFO - â”œâ”€â”€ Learning Rate: 8.70e-06
2025-03-02 10:20:52,903 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:20:53,570 - INFO - ðŸªœ Batch step - 59 -- sub batch step 236 -- lr 8.85e-06
2025-03-02 10:20:55,729 - INFO - ðŸªœ Batch step - 59 -- sub batch step 237 -- lr 8.85e-06
2025-03-02 10:20:58,007 - INFO - ðŸªœ Batch step - 59 -- sub batch step 238 -- lr 8.85e-06
2025-03-02 10:21:00,168 - INFO - ðŸªœ Batch step - 59 -- sub batch step 239 -- lr 8.85e-06
2025-03-02 10:21:01,826 - INFO - Step 59 -- ðŸ”„ Training Metrics
2025-03-02 10:21:01,827 - INFO - â”œâ”€â”€ Loss: 10.9948
2025-03-02 10:21:01,827 - INFO - â”œâ”€â”€ Learning Rate: 8.85e-06
2025-03-02 10:21:01,827 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:21:02,924 - INFO - ðŸªœ Batch step - 60 -- sub batch step 240 -- lr 9.00e-06
2025-03-02 10:21:05,083 - INFO - ðŸªœ Batch step - 60 -- sub batch step 241 -- lr 9.00e-06
2025-03-02 10:21:07,246 - INFO - ðŸªœ Batch step - 60 -- sub batch step 242 -- lr 9.00e-06
2025-03-02 10:21:09,423 - INFO - ðŸªœ Batch step - 60 -- sub batch step 243 -- lr 9.00e-06
2025-03-02 10:21:11,116 - INFO - Step 60 -- ðŸ”„ Training Metrics
2025-03-02 10:21:11,117 - INFO - â”œâ”€â”€ Loss: 10.9928
2025-03-02 10:21:11,117 - INFO - â”œâ”€â”€ Learning Rate: 9.00e-06
2025-03-02 10:21:11,117 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:21:11,804 - INFO - ðŸªœ Batch step - 61 -- sub batch step 244 -- lr 9.15e-06
2025-03-02 10:21:13,972 - INFO - ðŸªœ Batch step - 61 -- sub batch step 245 -- lr 9.15e-06
2025-03-02 10:21:16,131 - INFO - ðŸªœ Batch step - 61 -- sub batch step 246 -- lr 9.15e-06
2025-03-02 10:21:18,567 - INFO - ðŸªœ Batch step - 61 -- sub batch step 247 -- lr 9.15e-06
2025-03-02 10:21:20,232 - INFO - Step 61 -- ðŸ”„ Training Metrics
2025-03-02 10:21:20,233 - INFO - â”œâ”€â”€ Loss: 10.9939
2025-03-02 10:21:20,233 - INFO - â”œâ”€â”€ Learning Rate: 9.15e-06
2025-03-02 10:21:20,233 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:21:20,901 - INFO - ðŸªœ Batch step - 62 -- sub batch step 248 -- lr 9.30e-06
2025-03-02 10:21:23,063 - INFO - ðŸªœ Batch step - 62 -- sub batch step 249 -- lr 9.30e-06
2025-03-02 10:21:25,222 - INFO - ðŸªœ Batch step - 62 -- sub batch step 250 -- lr 9.30e-06
2025-03-02 10:21:27,396 - INFO - ðŸªœ Batch step - 62 -- sub batch step 251 -- lr 9.30e-06
2025-03-02 10:21:28,955 - INFO - Step 62 -- ðŸ”„ Training Metrics
2025-03-02 10:21:28,956 - INFO - â”œâ”€â”€ Loss: 10.9933
2025-03-02 10:21:28,956 - INFO - â”œâ”€â”€ Learning Rate: 9.30e-06
2025-03-02 10:21:28,956 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:21:29,635 - INFO - ðŸªœ Batch step - 63 -- sub batch step 252 -- lr 9.45e-06
2025-03-02 10:21:31,787 - INFO - ðŸªœ Batch step - 63 -- sub batch step 253 -- lr 9.45e-06
2025-03-02 10:21:33,947 - INFO - ðŸªœ Batch step - 63 -- sub batch step 254 -- lr 9.45e-06
2025-03-02 10:21:36,591 - INFO - ðŸªœ Batch step - 63 -- sub batch step 255 -- lr 9.45e-06
2025-03-02 10:21:38,188 - INFO - Step 63 -- ðŸ”„ Training Metrics
2025-03-02 10:21:38,188 - INFO - â”œâ”€â”€ Loss: 10.9938
2025-03-02 10:21:38,188 - INFO - â”œâ”€â”€ Learning Rate: 9.45e-06
2025-03-02 10:21:38,189 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:21:38,859 - INFO - ðŸªœ Batch step - 64 -- sub batch step 256 -- lr 9.60e-06
2025-03-02 10:21:41,019 - INFO - ðŸªœ Batch step - 64 -- sub batch step 257 -- lr 9.60e-06
2025-03-02 10:21:43,172 - INFO - ðŸªœ Batch step - 64 -- sub batch step 258 -- lr 9.60e-06
2025-03-02 10:21:45,346 - INFO - ðŸªœ Batch step - 64 -- sub batch step 259 -- lr 9.60e-06
2025-03-02 10:21:46,907 - INFO - Step 64 -- ðŸ”„ Training Metrics
2025-03-02 10:21:46,908 - INFO - â”œâ”€â”€ Loss: 10.9928
2025-03-02 10:21:46,908 - INFO - â”œâ”€â”€ Learning Rate: 9.60e-06
2025-03-02 10:21:46,908 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:21:47,583 - INFO - ðŸªœ Batch step - 65 -- sub batch step 260 -- lr 9.75e-06
2025-03-02 10:21:49,734 - INFO - ðŸªœ Batch step - 65 -- sub batch step 261 -- lr 9.75e-06
2025-03-02 10:21:51,894 - INFO - ðŸªœ Batch step - 65 -- sub batch step 262 -- lr 9.75e-06
2025-03-02 10:21:54,721 - INFO - ðŸªœ Batch step - 65 -- sub batch step 263 -- lr 9.75e-06
2025-03-02 10:21:56,214 - INFO - Step 65 -- ðŸ”„ Training Metrics
2025-03-02 10:21:56,215 - INFO - â”œâ”€â”€ Loss: 10.9927
2025-03-02 10:21:56,215 - INFO - â”œâ”€â”€ Learning Rate: 9.75e-06
2025-03-02 10:21:56,215 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:21:56,888 - INFO - ðŸªœ Batch step - 66 -- sub batch step 264 -- lr 9.90e-06
2025-03-02 10:21:59,047 - INFO - ðŸªœ Batch step - 66 -- sub batch step 265 -- lr 9.90e-06
2025-03-02 10:22:01,201 - INFO - ðŸªœ Batch step - 66 -- sub batch step 266 -- lr 9.90e-06
2025-03-02 10:22:03,380 - INFO - ðŸªœ Batch step - 66 -- sub batch step 267 -- lr 9.90e-06
2025-03-02 10:22:04,949 - INFO - Step 66 -- ðŸ”„ Training Metrics
2025-03-02 10:22:04,950 - INFO - â”œâ”€â”€ Loss: 10.9928
2025-03-02 10:22:04,950 - INFO - â”œâ”€â”€ Learning Rate: 9.90e-06
2025-03-02 10:22:04,950 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:22:05,618 - INFO - ðŸªœ Batch step - 67 -- sub batch step 268 -- lr 1.01e-05
2025-03-02 10:22:07,778 - INFO - ðŸªœ Batch step - 67 -- sub batch step 269 -- lr 1.01e-05
2025-03-02 10:22:09,937 - INFO - ðŸªœ Batch step - 67 -- sub batch step 270 -- lr 1.01e-05
2025-03-02 10:22:12,781 - INFO - ðŸªœ Batch step - 67 -- sub batch step 271 -- lr 1.01e-05
2025-03-02 10:22:14,269 - INFO - Step 67 -- ðŸ”„ Training Metrics
2025-03-02 10:22:14,269 - INFO - â”œâ”€â”€ Loss: 10.9923
2025-03-02 10:22:14,269 - INFO - â”œâ”€â”€ Learning Rate: 1.01e-05
2025-03-02 10:22:14,270 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:22:14,943 - INFO - ðŸªœ Batch step - 68 -- sub batch step 272 -- lr 1.02e-05
2025-03-02 10:22:17,093 - INFO - ðŸªœ Batch step - 68 -- sub batch step 273 -- lr 1.02e-05
2025-03-02 10:22:19,251 - INFO - ðŸªœ Batch step - 68 -- sub batch step 274 -- lr 1.02e-05
2025-03-02 10:22:21,429 - INFO - ðŸªœ Batch step - 68 -- sub batch step 275 -- lr 1.02e-05
2025-03-02 10:22:22,995 - INFO - Step 68 -- ðŸ”„ Training Metrics
2025-03-02 10:22:22,996 - INFO - â”œâ”€â”€ Loss: 10.9918
2025-03-02 10:22:22,996 - INFO - â”œâ”€â”€ Learning Rate: 1.02e-05
2025-03-02 10:22:22,996 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:22:23,666 - INFO - ðŸªœ Batch step - 69 -- sub batch step 276 -- lr 1.03e-05
2025-03-02 10:22:25,823 - INFO - ðŸªœ Batch step - 69 -- sub batch step 277 -- lr 1.03e-05
2025-03-02 10:22:27,976 - INFO - ðŸªœ Batch step - 69 -- sub batch step 278 -- lr 1.03e-05
2025-03-02 10:22:30,705 - INFO - ðŸªœ Batch step - 69 -- sub batch step 279 -- lr 1.03e-05
2025-03-02 10:22:32,234 - INFO - Step 69 -- ðŸ”„ Training Metrics
2025-03-02 10:22:32,235 - INFO - â”œâ”€â”€ Loss: 10.9912
2025-03-02 10:22:32,235 - INFO - â”œâ”€â”€ Learning Rate: 1.03e-05
2025-03-02 10:22:32,235 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:22:32,912 - INFO - ðŸªœ Batch step - 70 -- sub batch step 280 -- lr 1.05e-05
2025-03-02 10:22:35,063 - INFO - ðŸªœ Batch step - 70 -- sub batch step 281 -- lr 1.05e-05
2025-03-02 10:22:37,221 - INFO - ðŸªœ Batch step - 70 -- sub batch step 282 -- lr 1.05e-05
2025-03-02 10:22:39,398 - INFO - ðŸªœ Batch step - 70 -- sub batch step 283 -- lr 1.05e-05
2025-03-02 10:22:40,955 - INFO - Step 70 -- ðŸ”„ Training Metrics
2025-03-02 10:22:40,955 - INFO - â”œâ”€â”€ Loss: 10.9916
2025-03-02 10:22:40,955 - INFO - â”œâ”€â”€ Learning Rate: 1.05e-05
2025-03-02 10:22:40,955 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:22:41,630 - INFO - ðŸªœ Batch step - 71 -- sub batch step 284 -- lr 1.06e-05
2025-03-02 10:22:43,785 - INFO - ðŸªœ Batch step - 71 -- sub batch step 285 -- lr 1.06e-05
2025-03-02 10:22:46,194 - INFO - ðŸªœ Batch step - 71 -- sub batch step 286 -- lr 1.06e-05
2025-03-02 10:22:48,349 - INFO - ðŸªœ Batch step - 71 -- sub batch step 287 -- lr 1.06e-05
2025-03-02 10:22:50,150 - INFO - Step 71 -- ðŸ”„ Training Metrics
2025-03-02 10:22:50,150 - INFO - â”œâ”€â”€ Loss: 10.9918
2025-03-02 10:22:50,151 - INFO - â”œâ”€â”€ Learning Rate: 1.06e-05
2025-03-02 10:22:50,151 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:22:50,820 - INFO - ðŸªœ Batch step - 72 -- sub batch step 288 -- lr 1.08e-05
2025-03-02 10:22:52,980 - INFO - ðŸªœ Batch step - 72 -- sub batch step 289 -- lr 1.08e-05
2025-03-02 10:22:55,153 - INFO - ðŸªœ Batch step - 72 -- sub batch step 290 -- lr 1.08e-05
2025-03-02 10:22:57,302 - INFO - ðŸªœ Batch step - 72 -- sub batch step 291 -- lr 1.08e-05
2025-03-02 10:22:58,867 - INFO - Step 72 -- ðŸ”„ Training Metrics
2025-03-02 10:22:58,867 - INFO - â”œâ”€â”€ Loss: 10.9906
2025-03-02 10:22:58,867 - INFO - â”œâ”€â”€ Learning Rate: 1.08e-05
2025-03-02 10:22:58,867 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:22:59,541 - INFO - ðŸªœ Batch step - 73 -- sub batch step 292 -- lr 1.09e-05
2025-03-02 10:23:01,694 - INFO - ðŸªœ Batch step - 73 -- sub batch step 293 -- lr 1.09e-05
2025-03-02 10:23:04,323 - INFO - ðŸªœ Batch step - 73 -- sub batch step 294 -- lr 1.09e-05
2025-03-02 10:23:06,482 - INFO - ðŸªœ Batch step - 73 -- sub batch step 295 -- lr 1.09e-05
2025-03-02 10:23:08,154 - INFO - Step 73 -- ðŸ”„ Training Metrics
2025-03-02 10:23:08,154 - INFO - â”œâ”€â”€ Loss: 10.9911
2025-03-02 10:23:08,155 - INFO - â”œâ”€â”€ Learning Rate: 1.09e-05
2025-03-02 10:23:08,155 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:23:08,823 - INFO - ðŸªœ Batch step - 74 -- sub batch step 296 -- lr 1.11e-05
2025-03-02 10:23:10,979 - INFO - ðŸªœ Batch step - 74 -- sub batch step 297 -- lr 1.11e-05
2025-03-02 10:23:13,151 - INFO - ðŸªœ Batch step - 74 -- sub batch step 298 -- lr 1.11e-05
2025-03-02 10:23:15,306 - INFO - ðŸªœ Batch step - 74 -- sub batch step 299 -- lr 1.11e-05
2025-03-02 10:23:16,892 - INFO - Step 74 -- ðŸ”„ Training Metrics
2025-03-02 10:23:16,892 - INFO - â”œâ”€â”€ Loss: 10.9904
2025-03-02 10:23:16,892 - INFO - â”œâ”€â”€ Learning Rate: 1.11e-05
2025-03-02 10:23:16,893 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:23:17,566 - INFO - ðŸªœ Batch step - 75 -- sub batch step 300 -- lr 1.12e-05
2025-03-02 10:23:19,721 - INFO - ðŸªœ Batch step - 75 -- sub batch step 301 -- lr 1.12e-05
2025-03-02 10:23:22,578 - INFO - ðŸªœ Batch step - 75 -- sub batch step 302 -- lr 1.12e-05
2025-03-02 10:23:24,729 - INFO - ðŸªœ Batch step - 75 -- sub batch step 303 -- lr 1.12e-05
2025-03-02 10:23:26,231 - INFO - Step 75 -- ðŸ”„ Training Metrics
2025-03-02 10:23:26,232 - INFO - â”œâ”€â”€ Loss: 10.9891
2025-03-02 10:23:26,232 - INFO - â”œâ”€â”€ Learning Rate: 1.12e-05
2025-03-02 10:23:26,232 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:23:26,905 - INFO - ðŸªœ Batch step - 76 -- sub batch step 304 -- lr 1.14e-05
2025-03-02 10:23:29,061 - INFO - ðŸªœ Batch step - 76 -- sub batch step 305 -- lr 1.14e-05
2025-03-02 10:23:31,233 - INFO - ðŸªœ Batch step - 76 -- sub batch step 306 -- lr 1.14e-05
2025-03-02 10:23:33,397 - INFO - ðŸªœ Batch step - 76 -- sub batch step 307 -- lr 1.14e-05
2025-03-02 10:23:34,963 - INFO - Step 76 -- ðŸ”„ Training Metrics
2025-03-02 10:23:34,964 - INFO - â”œâ”€â”€ Loss: 10.9886
2025-03-02 10:23:34,964 - INFO - â”œâ”€â”€ Learning Rate: 1.14e-05
2025-03-02 10:23:34,964 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:23:35,634 - INFO - ðŸªœ Batch step - 77 -- sub batch step 308 -- lr 1.15e-05
2025-03-02 10:23:37,792 - INFO - ðŸªœ Batch step - 77 -- sub batch step 309 -- lr 1.15e-05
2025-03-02 10:23:40,515 - INFO - ðŸªœ Batch step - 77 -- sub batch step 310 -- lr 1.15e-05
2025-03-02 10:23:42,671 - INFO - ðŸªœ Batch step - 77 -- sub batch step 311 -- lr 1.15e-05
2025-03-02 10:23:44,352 - INFO - Step 77 -- ðŸ”„ Training Metrics
2025-03-02 10:23:44,352 - INFO - â”œâ”€â”€ Loss: 10.9912
2025-03-02 10:23:44,352 - INFO - â”œâ”€â”€ Learning Rate: 1.15e-05
2025-03-02 10:23:44,352 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:23:45,025 - INFO - ðŸªœ Batch step - 78 -- sub batch step 312 -- lr 1.17e-05
2025-03-02 10:23:47,178 - INFO - ðŸªœ Batch step - 78 -- sub batch step 313 -- lr 1.17e-05
2025-03-02 10:23:49,356 - INFO - ðŸªœ Batch step - 78 -- sub batch step 314 -- lr 1.17e-05
2025-03-02 10:23:51,516 - INFO - ðŸªœ Batch step - 78 -- sub batch step 315 -- lr 1.17e-05
2025-03-02 10:23:53,079 - INFO - Step 78 -- ðŸ”„ Training Metrics
2025-03-02 10:23:53,079 - INFO - â”œâ”€â”€ Loss: 10.9883
2025-03-02 10:23:53,079 - INFO - â”œâ”€â”€ Learning Rate: 1.17e-05
2025-03-02 10:23:53,079 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:23:53,748 - INFO - ðŸªœ Batch step - 79 -- sub batch step 316 -- lr 1.18e-05
2025-03-02 10:23:55,910 - INFO - ðŸªœ Batch step - 79 -- sub batch step 317 -- lr 1.18e-05
2025-03-02 10:23:58,246 - INFO - ðŸªœ Batch step - 79 -- sub batch step 318 -- lr 1.18e-05
2025-03-02 10:24:00,414 - INFO - ðŸªœ Batch step - 79 -- sub batch step 319 -- lr 1.18e-05
2025-03-02 10:24:02,140 - INFO - Step 79 -- ðŸ”„ Training Metrics
2025-03-02 10:24:02,140 - INFO - â”œâ”€â”€ Loss: 10.9881
2025-03-02 10:24:02,140 - INFO - â”œâ”€â”€ Learning Rate: 1.18e-05
2025-03-02 10:24:02,140 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:24:03,395 - INFO - ðŸªœ Batch step - 80 -- sub batch step 320 -- lr 1.20e-05
2025-03-02 10:24:05,553 - INFO - ðŸªœ Batch step - 80 -- sub batch step 321 -- lr 1.20e-05
2025-03-02 10:24:07,714 - INFO - ðŸªœ Batch step - 80 -- sub batch step 322 -- lr 1.20e-05
2025-03-02 10:24:09,888 - INFO - ðŸªœ Batch step - 80 -- sub batch step 323 -- lr 1.20e-05
2025-03-02 10:24:11,446 - INFO - Step 80 -- ðŸ”„ Training Metrics
2025-03-02 10:24:11,446 - INFO - â”œâ”€â”€ Loss: 10.9888
2025-03-02 10:24:11,446 - INFO - â”œâ”€â”€ Learning Rate: 1.20e-05
2025-03-02 10:24:11,447 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:24:12,124 - INFO - ðŸªœ Batch step - 81 -- sub batch step 324 -- lr 1.21e-05
2025-03-02 10:24:14,283 - INFO - ðŸªœ Batch step - 81 -- sub batch step 325 -- lr 1.21e-05
2025-03-02 10:24:16,434 - INFO - ðŸªœ Batch step - 81 -- sub batch step 326 -- lr 1.21e-05
2025-03-02 10:24:19,056 - INFO - ðŸªœ Batch step - 81 -- sub batch step 327 -- lr 1.21e-05
2025-03-02 10:24:20,549 - INFO - Step 81 -- ðŸ”„ Training Metrics
2025-03-02 10:24:20,550 - INFO - â”œâ”€â”€ Loss: 10.9889
2025-03-02 10:24:20,550 - INFO - â”œâ”€â”€ Learning Rate: 1.21e-05
2025-03-02 10:24:20,550 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:24:21,225 - INFO - ðŸªœ Batch step - 82 -- sub batch step 328 -- lr 1.23e-05
2025-03-02 10:24:23,394 - INFO - ðŸªœ Batch step - 82 -- sub batch step 329 -- lr 1.23e-05
2025-03-02 10:24:25,552 - INFO - ðŸªœ Batch step - 82 -- sub batch step 330 -- lr 1.23e-05
2025-03-02 10:24:27,726 - INFO - ðŸªœ Batch step - 82 -- sub batch step 331 -- lr 1.23e-05
2025-03-02 10:24:29,263 - INFO - Step 82 -- ðŸ”„ Training Metrics
2025-03-02 10:24:29,264 - INFO - â”œâ”€â”€ Loss: 10.9890
2025-03-02 10:24:29,264 - INFO - â”œâ”€â”€ Learning Rate: 1.23e-05
2025-03-02 10:24:29,264 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:24:29,944 - INFO - ðŸªœ Batch step - 83 -- sub batch step 332 -- lr 1.24e-05
2025-03-02 10:24:32,102 - INFO - ðŸªœ Batch step - 83 -- sub batch step 333 -- lr 1.24e-05
2025-03-02 10:24:34,265 - INFO - ðŸªœ Batch step - 83 -- sub batch step 334 -- lr 1.24e-05
2025-03-02 10:24:36,896 - INFO - ðŸªœ Batch step - 83 -- sub batch step 335 -- lr 1.24e-05
2025-03-02 10:24:38,561 - INFO - Step 83 -- ðŸ”„ Training Metrics
2025-03-02 10:24:38,562 - INFO - â”œâ”€â”€ Loss: 10.9886
2025-03-02 10:24:38,562 - INFO - â”œâ”€â”€ Learning Rate: 1.24e-05
2025-03-02 10:24:38,562 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:24:39,243 - INFO - ðŸªœ Batch step - 84 -- sub batch step 336 -- lr 1.26e-05
2025-03-02 10:24:41,401 - INFO - ðŸªœ Batch step - 84 -- sub batch step 337 -- lr 1.26e-05
2025-03-02 10:24:43,554 - INFO - ðŸªœ Batch step - 84 -- sub batch step 338 -- lr 1.26e-05
2025-03-02 10:24:45,739 - INFO - ðŸªœ Batch step - 84 -- sub batch step 339 -- lr 1.26e-05
2025-03-02 10:24:47,281 - INFO - Step 84 -- ðŸ”„ Training Metrics
2025-03-02 10:24:47,282 - INFO - â”œâ”€â”€ Loss: 10.9892
2025-03-02 10:24:47,282 - INFO - â”œâ”€â”€ Learning Rate: 1.26e-05
2025-03-02 10:24:47,282 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:24:47,967 - INFO - ðŸªœ Batch step - 85 -- sub batch step 340 -- lr 1.27e-05
2025-03-02 10:24:50,119 - INFO - ðŸªœ Batch step - 85 -- sub batch step 341 -- lr 1.27e-05
2025-03-02 10:24:52,282 - INFO - ðŸªœ Batch step - 85 -- sub batch step 342 -- lr 1.27e-05
2025-03-02 10:24:54,887 - INFO - ðŸªœ Batch step - 85 -- sub batch step 343 -- lr 1.27e-05
2025-03-02 10:24:56,540 - INFO - Step 85 -- ðŸ”„ Training Metrics
2025-03-02 10:24:56,540 - INFO - â”œâ”€â”€ Loss: 10.9887
2025-03-02 10:24:56,540 - INFO - â”œâ”€â”€ Learning Rate: 1.27e-05
2025-03-02 10:24:56,541 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:24:57,219 - INFO - ðŸªœ Batch step - 86 -- sub batch step 344 -- lr 1.29e-05
2025-03-02 10:24:59,380 - INFO - ðŸªœ Batch step - 86 -- sub batch step 345 -- lr 1.29e-05
2025-03-02 10:25:01,532 - INFO - ðŸªœ Batch step - 86 -- sub batch step 346 -- lr 1.29e-05
2025-03-02 10:25:03,712 - INFO - ðŸªœ Batch step - 86 -- sub batch step 347 -- lr 1.29e-05
2025-03-02 10:25:05,263 - INFO - Step 86 -- ðŸ”„ Training Metrics
2025-03-02 10:25:05,263 - INFO - â”œâ”€â”€ Loss: 10.9875
2025-03-02 10:25:05,264 - INFO - â”œâ”€â”€ Learning Rate: 1.29e-05
2025-03-02 10:25:05,264 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:25:05,937 - INFO - ðŸªœ Batch step - 87 -- sub batch step 348 -- lr 1.30e-05
2025-03-02 10:25:08,099 - INFO - ðŸªœ Batch step - 87 -- sub batch step 349 -- lr 1.30e-05
2025-03-02 10:25:10,257 - INFO - ðŸªœ Batch step - 87 -- sub batch step 350 -- lr 1.30e-05
2025-03-02 10:25:13,001 - INFO - ðŸªœ Batch step - 87 -- sub batch step 351 -- lr 1.30e-05
2025-03-02 10:25:14,824 - INFO - Step 87 -- ðŸ”„ Training Metrics
2025-03-02 10:25:14,825 - INFO - â”œâ”€â”€ Loss: 10.9870
2025-03-02 10:25:14,825 - INFO - â”œâ”€â”€ Learning Rate: 1.30e-05
2025-03-02 10:25:14,825 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:25:15,508 - INFO - ðŸªœ Batch step - 88 -- sub batch step 352 -- lr 1.32e-05
2025-03-02 10:25:17,665 - INFO - ðŸªœ Batch step - 88 -- sub batch step 353 -- lr 1.32e-05
2025-03-02 10:25:19,829 - INFO - ðŸªœ Batch step - 88 -- sub batch step 354 -- lr 1.32e-05
2025-03-02 10:25:22,014 - INFO - ðŸªœ Batch step - 88 -- sub batch step 355 -- lr 1.32e-05
2025-03-02 10:25:23,537 - INFO - Step 88 -- ðŸ”„ Training Metrics
2025-03-02 10:25:23,538 - INFO - â”œâ”€â”€ Loss: 10.9866
2025-03-02 10:25:23,538 - INFO - â”œâ”€â”€ Learning Rate: 1.32e-05
2025-03-02 10:25:23,538 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:25:24,211 - INFO - ðŸªœ Batch step - 89 -- sub batch step 356 -- lr 1.33e-05
2025-03-02 10:25:26,373 - INFO - ðŸªœ Batch step - 89 -- sub batch step 357 -- lr 1.33e-05
2025-03-02 10:25:28,532 - INFO - ðŸªœ Batch step - 89 -- sub batch step 358 -- lr 1.33e-05
2025-03-02 10:25:31,251 - INFO - ðŸªœ Batch step - 89 -- sub batch step 359 -- lr 1.33e-05
2025-03-02 10:25:32,754 - INFO - Step 89 -- ðŸ”„ Training Metrics
2025-03-02 10:25:32,755 - INFO - â”œâ”€â”€ Loss: 10.9871
2025-03-02 10:25:32,755 - INFO - â”œâ”€â”€ Learning Rate: 1.33e-05
2025-03-02 10:25:32,755 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:25:33,435 - INFO - ðŸªœ Batch step - 90 -- sub batch step 360 -- lr 1.35e-05
2025-03-02 10:25:35,592 - INFO - ðŸªœ Batch step - 90 -- sub batch step 361 -- lr 1.35e-05
2025-03-02 10:25:37,756 - INFO - ðŸªœ Batch step - 90 -- sub batch step 362 -- lr 1.35e-05
2025-03-02 10:25:39,939 - INFO - ðŸªœ Batch step - 90 -- sub batch step 363 -- lr 1.35e-05
2025-03-02 10:25:41,465 - INFO - Step 90 -- ðŸ”„ Training Metrics
2025-03-02 10:25:41,466 - INFO - â”œâ”€â”€ Loss: 10.9873
2025-03-02 10:25:41,466 - INFO - â”œâ”€â”€ Learning Rate: 1.35e-05
2025-03-02 10:25:41,466 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:25:42,152 - INFO - ðŸªœ Batch step - 91 -- sub batch step 364 -- lr 1.36e-05
2025-03-02 10:25:44,319 - INFO - ðŸªœ Batch step - 91 -- sub batch step 365 -- lr 1.36e-05
2025-03-02 10:25:46,738 - INFO - ðŸªœ Batch step - 91 -- sub batch step 366 -- lr 1.36e-05
2025-03-02 10:25:48,921 - INFO - ðŸªœ Batch step - 91 -- sub batch step 367 -- lr 1.36e-05
2025-03-02 10:25:50,643 - INFO - Step 91 -- ðŸ”„ Training Metrics
2025-03-02 10:25:50,644 - INFO - â”œâ”€â”€ Loss: 10.9869
2025-03-02 10:25:50,644 - INFO - â”œâ”€â”€ Learning Rate: 1.36e-05
2025-03-02 10:25:50,644 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:25:51,317 - INFO - ðŸªœ Batch step - 92 -- sub batch step 368 -- lr 1.38e-05
2025-03-02 10:25:53,483 - INFO - ðŸªœ Batch step - 92 -- sub batch step 369 -- lr 1.38e-05
2025-03-02 10:25:55,660 - INFO - ðŸªœ Batch step - 92 -- sub batch step 370 -- lr 1.38e-05
2025-03-02 10:25:57,813 - INFO - ðŸªœ Batch step - 92 -- sub batch step 371 -- lr 1.38e-05
2025-03-02 10:25:59,362 - INFO - Step 92 -- ðŸ”„ Training Metrics
2025-03-02 10:25:59,363 - INFO - â”œâ”€â”€ Loss: 10.9875
2025-03-02 10:25:59,363 - INFO - â”œâ”€â”€ Learning Rate: 1.38e-05
2025-03-02 10:25:59,363 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:26:00,041 - INFO - ðŸªœ Batch step - 93 -- sub batch step 372 -- lr 1.39e-05
2025-03-02 10:26:02,196 - INFO - ðŸªœ Batch step - 93 -- sub batch step 373 -- lr 1.39e-05
2025-03-02 10:26:05,010 - INFO - ðŸªœ Batch step - 93 -- sub batch step 374 -- lr 1.39e-05
2025-03-02 10:26:07,175 - INFO - ðŸªœ Batch step - 93 -- sub batch step 375 -- lr 1.39e-05
2025-03-02 10:26:08,669 - INFO - Step 93 -- ðŸ”„ Training Metrics
2025-03-02 10:26:08,669 - INFO - â”œâ”€â”€ Loss: 10.9874
2025-03-02 10:26:08,669 - INFO - â”œâ”€â”€ Learning Rate: 1.39e-05
2025-03-02 10:26:08,669 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:26:09,354 - INFO - ðŸªœ Batch step - 94 -- sub batch step 376 -- lr 1.41e-05
2025-03-02 10:26:11,512 - INFO - ðŸªœ Batch step - 94 -- sub batch step 377 -- lr 1.41e-05
2025-03-02 10:26:13,688 - INFO - ðŸªœ Batch step - 94 -- sub batch step 378 -- lr 1.41e-05
2025-03-02 10:26:15,851 - INFO - ðŸªœ Batch step - 94 -- sub batch step 379 -- lr 1.41e-05
2025-03-02 10:26:17,393 - INFO - Step 94 -- ðŸ”„ Training Metrics
2025-03-02 10:26:17,393 - INFO - â”œâ”€â”€ Loss: 10.9868
2025-03-02 10:26:17,394 - INFO - â”œâ”€â”€ Learning Rate: 1.41e-05
2025-03-02 10:26:17,394 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:26:18,075 - INFO - ðŸªœ Batch step - 95 -- sub batch step 380 -- lr 1.42e-05
2025-03-02 10:26:20,233 - INFO - ðŸªœ Batch step - 95 -- sub batch step 381 -- lr 1.42e-05
2025-03-02 10:26:22,968 - INFO - ðŸªœ Batch step - 95 -- sub batch step 382 -- lr 1.42e-05
2025-03-02 10:26:25,131 - INFO - ðŸªœ Batch step - 95 -- sub batch step 383 -- lr 1.42e-05
2025-03-02 10:26:26,633 - INFO - Step 95 -- ðŸ”„ Training Metrics
2025-03-02 10:26:26,634 - INFO - â”œâ”€â”€ Loss: 10.9862
2025-03-02 10:26:26,634 - INFO - â”œâ”€â”€ Learning Rate: 1.42e-05
2025-03-02 10:26:26,634 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:26:27,316 - INFO - ðŸªœ Batch step - 96 -- sub batch step 384 -- lr 1.44e-05
2025-03-02 10:26:29,475 - INFO - ðŸªœ Batch step - 96 -- sub batch step 385 -- lr 1.44e-05
2025-03-02 10:26:31,651 - INFO - ðŸªœ Batch step - 96 -- sub batch step 386 -- lr 1.44e-05
2025-03-02 10:26:33,811 - INFO - ðŸªœ Batch step - 96 -- sub batch step 387 -- lr 1.44e-05
2025-03-02 10:26:35,351 - INFO - Step 96 -- ðŸ”„ Training Metrics
2025-03-02 10:26:35,351 - INFO - â”œâ”€â”€ Loss: 10.9856
2025-03-02 10:26:35,351 - INFO - â”œâ”€â”€ Learning Rate: 1.44e-05
2025-03-02 10:26:35,352 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:26:36,024 - INFO - ðŸªœ Batch step - 97 -- sub batch step 388 -- lr 1.45e-05
2025-03-02 10:26:38,194 - INFO - ðŸªœ Batch step - 97 -- sub batch step 389 -- lr 1.45e-05
2025-03-02 10:26:40,839 - INFO - ðŸªœ Batch step - 97 -- sub batch step 390 -- lr 1.45e-05
2025-03-02 10:26:42,996 - INFO - ðŸªœ Batch step - 97 -- sub batch step 391 -- lr 1.45e-05
2025-03-02 10:26:44,632 - INFO - Step 97 -- ðŸ”„ Training Metrics
2025-03-02 10:26:44,633 - INFO - â”œâ”€â”€ Loss: 10.9858
2025-03-02 10:26:44,633 - INFO - â”œâ”€â”€ Learning Rate: 1.45e-05
2025-03-02 10:26:44,633 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:26:45,312 - INFO - ðŸªœ Batch step - 98 -- sub batch step 392 -- lr 1.47e-05
2025-03-02 10:26:47,465 - INFO - ðŸªœ Batch step - 98 -- sub batch step 393 -- lr 1.47e-05
2025-03-02 10:26:49,652 - INFO - ðŸªœ Batch step - 98 -- sub batch step 394 -- lr 1.47e-05
2025-03-02 10:26:51,814 - INFO - ðŸªœ Batch step - 98 -- sub batch step 395 -- lr 1.47e-05
2025-03-02 10:26:53,353 - INFO - Step 98 -- ðŸ”„ Training Metrics
2025-03-02 10:26:53,353 - INFO - â”œâ”€â”€ Loss: 10.9849
2025-03-02 10:26:53,353 - INFO - â”œâ”€â”€ Learning Rate: 1.47e-05
2025-03-02 10:26:53,353 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:26:54,028 - INFO - ðŸªœ Batch step - 99 -- sub batch step 396 -- lr 1.49e-05
2025-03-02 10:26:56,190 - INFO - ðŸªœ Batch step - 99 -- sub batch step 397 -- lr 1.49e-05
2025-03-02 10:26:58,478 - INFO - ðŸªœ Batch step - 99 -- sub batch step 398 -- lr 1.49e-05
2025-03-02 10:27:00,645 - INFO - ðŸªœ Batch step - 99 -- sub batch step 399 -- lr 1.49e-05
2025-03-02 10:27:02,211 - INFO - Step 99 -- ðŸ”„ Training Metrics
2025-03-02 10:27:02,212 - INFO - â”œâ”€â”€ Loss: 10.9845
2025-03-02 10:27:02,212 - INFO - â”œâ”€â”€ Learning Rate: 1.49e-05
2025-03-02 10:27:02,212 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:27:03,593 - INFO - ðŸªœ Batch step - 100 -- sub batch step 400 -- lr 1.50e-05
2025-03-02 10:27:05,761 - INFO - ðŸªœ Batch step - 100 -- sub batch step 401 -- lr 1.50e-05
2025-03-02 10:27:07,934 - INFO - ðŸªœ Batch step - 100 -- sub batch step 402 -- lr 1.50e-05
2025-03-02 10:27:10,123 - INFO - ðŸªœ Batch step - 100 -- sub batch step 403 -- lr 1.50e-05
2025-03-02 10:27:11,615 - INFO - Step 100 -- ðŸ”„ Training Metrics
2025-03-02 10:27:11,615 - INFO - â”œâ”€â”€ Loss: 10.9846
2025-03-02 10:27:11,615 - INFO - â”œâ”€â”€ Learning Rate: 1.50e-05
2025-03-02 10:27:11,615 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:27:12,292 - INFO - ðŸªœ Batch step - 101 -- sub batch step 404 -- lr 1.51e-05
2025-03-02 10:27:14,458 - INFO - ðŸªœ Batch step - 101 -- sub batch step 405 -- lr 1.51e-05
2025-03-02 10:27:16,613 - INFO - ðŸªœ Batch step - 101 -- sub batch step 406 -- lr 1.51e-05
2025-03-02 10:27:19,240 - INFO - ðŸªœ Batch step - 101 -- sub batch step 407 -- lr 1.51e-05
2025-03-02 10:27:20,972 - INFO - Step 101 -- ðŸ”„ Training Metrics
2025-03-02 10:27:20,972 - INFO - â”œâ”€â”€ Loss: 10.9847
2025-03-02 10:27:20,972 - INFO - â”œâ”€â”€ Learning Rate: 1.51e-05
2025-03-02 10:27:20,972 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:27:21,641 - INFO - ðŸªœ Batch step - 102 -- sub batch step 408 -- lr 1.53e-05
2025-03-02 10:27:23,807 - INFO - ðŸªœ Batch step - 102 -- sub batch step 409 -- lr 1.53e-05
2025-03-02 10:27:25,971 - INFO - ðŸªœ Batch step - 102 -- sub batch step 410 -- lr 1.53e-05
2025-03-02 10:27:28,150 - INFO - ðŸªœ Batch step - 102 -- sub batch step 411 -- lr 1.53e-05
2025-03-02 10:27:29,707 - INFO - Step 102 -- ðŸ”„ Training Metrics
2025-03-02 10:27:29,707 - INFO - â”œâ”€â”€ Loss: 10.9837
2025-03-02 10:27:29,707 - INFO - â”œâ”€â”€ Learning Rate: 1.53e-05
2025-03-02 10:27:29,707 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:27:30,388 - INFO - ðŸªœ Batch step - 103 -- sub batch step 412 -- lr 1.54e-05
2025-03-02 10:27:32,546 - INFO - ðŸªœ Batch step - 103 -- sub batch step 413 -- lr 1.54e-05
2025-03-02 10:27:34,713 - INFO - ðŸªœ Batch step - 103 -- sub batch step 414 -- lr 1.54e-05
2025-03-02 10:27:37,371 - INFO - ðŸªœ Batch step - 103 -- sub batch step 415 -- lr 1.54e-05
2025-03-02 10:27:38,912 - INFO - Step 103 -- ðŸ”„ Training Metrics
2025-03-02 10:27:38,912 - INFO - â”œâ”€â”€ Loss: 10.9809
2025-03-02 10:27:38,913 - INFO - â”œâ”€â”€ Learning Rate: 1.54e-05
2025-03-02 10:27:38,913 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:27:39,586 - INFO - ðŸªœ Batch step - 104 -- sub batch step 416 -- lr 1.56e-05
2025-03-02 10:27:41,752 - INFO - ðŸªœ Batch step - 104 -- sub batch step 417 -- lr 1.56e-05
2025-03-02 10:27:43,913 - INFO - ðŸªœ Batch step - 104 -- sub batch step 418 -- lr 1.56e-05
2025-03-02 10:27:46,105 - INFO - ðŸªœ Batch step - 104 -- sub batch step 419 -- lr 1.56e-05
2025-03-02 10:27:47,646 - INFO - Step 104 -- ðŸ”„ Training Metrics
2025-03-02 10:27:47,646 - INFO - â”œâ”€â”€ Loss: 10.9831
2025-03-02 10:27:47,646 - INFO - â”œâ”€â”€ Learning Rate: 1.56e-05
2025-03-02 10:27:47,647 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:27:48,324 - INFO - ðŸªœ Batch step - 105 -- sub batch step 420 -- lr 1.57e-05
2025-03-02 10:27:50,484 - INFO - ðŸªœ Batch step - 105 -- sub batch step 421 -- lr 1.57e-05
2025-03-02 10:27:52,647 - INFO - ðŸªœ Batch step - 105 -- sub batch step 422 -- lr 1.57e-05
2025-03-02 10:27:55,460 - INFO - ðŸªœ Batch step - 105 -- sub batch step 423 -- lr 1.57e-05
2025-03-02 10:27:57,012 - INFO - Step 105 -- ðŸ”„ Training Metrics
2025-03-02 10:27:57,012 - INFO - â”œâ”€â”€ Loss: 10.9825
2025-03-02 10:27:57,012 - INFO - â”œâ”€â”€ Learning Rate: 1.57e-05
2025-03-02 10:27:57,012 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:27:57,686 - INFO - ðŸªœ Batch step - 106 -- sub batch step 424 -- lr 1.59e-05
2025-03-02 10:27:59,849 - INFO - ðŸªœ Batch step - 106 -- sub batch step 425 -- lr 1.59e-05
2025-03-02 10:28:02,005 - INFO - ðŸªœ Batch step - 106 -- sub batch step 426 -- lr 1.59e-05
2025-03-02 10:28:04,186 - INFO - ðŸªœ Batch step - 106 -- sub batch step 427 -- lr 1.59e-05
2025-03-02 10:28:05,747 - INFO - Step 106 -- ðŸ”„ Training Metrics
2025-03-02 10:28:05,747 - INFO - â”œâ”€â”€ Loss: 10.9810
2025-03-02 10:28:05,747 - INFO - â”œâ”€â”€ Learning Rate: 1.59e-05
2025-03-02 10:28:05,747 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:28:06,419 - INFO - ðŸªœ Batch step - 107 -- sub batch step 428 -- lr 1.60e-05
2025-03-02 10:28:08,585 - INFO - ðŸªœ Batch step - 107 -- sub batch step 429 -- lr 1.60e-05
2025-03-02 10:28:10,746 - INFO - ðŸªœ Batch step - 107 -- sub batch step 430 -- lr 1.60e-05
2025-03-02 10:28:13,103 - INFO - ðŸªœ Batch step - 107 -- sub batch step 431 -- lr 1.60e-05
2025-03-02 10:28:15,028 - INFO - Step 107 -- ðŸ”„ Training Metrics
2025-03-02 10:28:15,029 - INFO - â”œâ”€â”€ Loss: 10.9820
2025-03-02 10:28:15,029 - INFO - â”œâ”€â”€ Learning Rate: 1.60e-05
2025-03-02 10:28:15,029 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:28:15,707 - INFO - ðŸªœ Batch step - 108 -- sub batch step 432 -- lr 1.62e-05
2025-03-02 10:28:17,866 - INFO - ðŸªœ Batch step - 108 -- sub batch step 433 -- lr 1.62e-05
2025-03-02 10:28:20,034 - INFO - ðŸªœ Batch step - 108 -- sub batch step 434 -- lr 1.62e-05
2025-03-02 10:28:22,220 - INFO - ðŸªœ Batch step - 108 -- sub batch step 435 -- lr 1.62e-05
2025-03-02 10:28:23,790 - INFO - Step 108 -- ðŸ”„ Training Metrics
2025-03-02 10:28:23,790 - INFO - â”œâ”€â”€ Loss: 10.9810
2025-03-02 10:28:23,790 - INFO - â”œâ”€â”€ Learning Rate: 1.62e-05
2025-03-02 10:28:23,791 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:28:24,465 - INFO - ðŸªœ Batch step - 109 -- sub batch step 436 -- lr 1.63e-05
2025-03-02 10:28:26,626 - INFO - ðŸªœ Batch step - 109 -- sub batch step 437 -- lr 1.63e-05
2025-03-02 10:28:28,779 - INFO - ðŸªœ Batch step - 109 -- sub batch step 438 -- lr 1.63e-05
2025-03-02 10:28:31,210 - INFO - ðŸªœ Batch step - 109 -- sub batch step 439 -- lr 1.63e-05
2025-03-02 10:28:32,999 - INFO - Step 109 -- ðŸ”„ Training Metrics
2025-03-02 10:28:33,000 - INFO - â”œâ”€â”€ Loss: 10.9801
2025-03-02 10:28:33,000 - INFO - â”œâ”€â”€ Learning Rate: 1.63e-05
2025-03-02 10:28:33,000 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:28:33,680 - INFO - ðŸªœ Batch step - 110 -- sub batch step 440 -- lr 1.65e-05
2025-03-02 10:28:35,837 - INFO - ðŸªœ Batch step - 110 -- sub batch step 441 -- lr 1.65e-05
2025-03-02 10:28:38,001 - INFO - ðŸªœ Batch step - 110 -- sub batch step 442 -- lr 1.65e-05
2025-03-02 10:28:40,173 - INFO - ðŸªœ Batch step - 110 -- sub batch step 443 -- lr 1.65e-05
2025-03-02 10:28:41,725 - INFO - Step 110 -- ðŸ”„ Training Metrics
2025-03-02 10:28:41,725 - INFO - â”œâ”€â”€ Loss: 10.9806
2025-03-02 10:28:41,726 - INFO - â”œâ”€â”€ Learning Rate: 1.65e-05
2025-03-02 10:28:41,726 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:28:42,408 - INFO - ðŸªœ Batch step - 111 -- sub batch step 444 -- lr 1.66e-05
2025-03-02 10:28:44,570 - INFO - ðŸªœ Batch step - 111 -- sub batch step 445 -- lr 1.66e-05
2025-03-02 10:28:47,173 - INFO - ðŸªœ Batch step - 111 -- sub batch step 446 -- lr 1.66e-05
2025-03-02 10:28:49,332 - INFO - ðŸªœ Batch step - 111 -- sub batch step 447 -- lr 1.66e-05
2025-03-02 10:28:51,005 - INFO - Step 111 -- ðŸ”„ Training Metrics
2025-03-02 10:28:51,005 - INFO - â”œâ”€â”€ Loss: 10.9788
2025-03-02 10:28:51,005 - INFO - â”œâ”€â”€ Learning Rate: 1.66e-05
2025-03-02 10:28:51,005 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:28:51,682 - INFO - ðŸªœ Batch step - 112 -- sub batch step 448 -- lr 1.68e-05
2025-03-02 10:28:53,844 - INFO - ðŸªœ Batch step - 112 -- sub batch step 449 -- lr 1.68e-05
2025-03-02 10:28:56,022 - INFO - ðŸªœ Batch step - 112 -- sub batch step 450 -- lr 1.68e-05
2025-03-02 10:28:58,175 - INFO - ðŸªœ Batch step - 112 -- sub batch step 451 -- lr 1.68e-05
2025-03-02 10:28:59,739 - INFO - Step 112 -- ðŸ”„ Training Metrics
2025-03-02 10:28:59,739 - INFO - â”œâ”€â”€ Loss: 10.9786
2025-03-02 10:28:59,739 - INFO - â”œâ”€â”€ Learning Rate: 1.68e-05
2025-03-02 10:28:59,739 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:29:00,424 - INFO - ðŸªœ Batch step - 113 -- sub batch step 452 -- lr 1.69e-05
2025-03-02 10:29:02,580 - INFO - ðŸªœ Batch step - 113 -- sub batch step 453 -- lr 1.69e-05
2025-03-02 10:29:05,287 - INFO - ðŸªœ Batch step - 113 -- sub batch step 454 -- lr 1.69e-05
2025-03-02 10:29:07,456 - INFO - ðŸªœ Batch step - 113 -- sub batch step 455 -- lr 1.69e-05
2025-03-02 10:29:08,951 - INFO - Step 113 -- ðŸ”„ Training Metrics
2025-03-02 10:29:08,951 - INFO - â”œâ”€â”€ Loss: 10.9801
2025-03-02 10:29:08,951 - INFO - â”œâ”€â”€ Learning Rate: 1.69e-05
2025-03-02 10:29:08,951 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:29:09,630 - INFO - ðŸªœ Batch step - 114 -- sub batch step 456 -- lr 1.71e-05
2025-03-02 10:29:11,788 - INFO - ðŸªœ Batch step - 114 -- sub batch step 457 -- lr 1.71e-05
2025-03-02 10:29:13,966 - INFO - ðŸªœ Batch step - 114 -- sub batch step 458 -- lr 1.71e-05
2025-03-02 10:29:16,128 - INFO - ðŸªœ Batch step - 114 -- sub batch step 459 -- lr 1.71e-05
2025-03-02 10:29:17,688 - INFO - Step 114 -- ðŸ”„ Training Metrics
2025-03-02 10:29:17,688 - INFO - â”œâ”€â”€ Loss: 10.9793
2025-03-02 10:29:17,688 - INFO - â”œâ”€â”€ Learning Rate: 1.71e-05
2025-03-02 10:29:17,688 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:29:18,373 - INFO - ðŸªœ Batch step - 115 -- sub batch step 460 -- lr 1.72e-05
2025-03-02 10:29:20,533 - INFO - ðŸªœ Batch step - 115 -- sub batch step 461 -- lr 1.72e-05
2025-03-02 10:29:23,233 - INFO - ðŸªœ Batch step - 115 -- sub batch step 462 -- lr 1.72e-05
2025-03-02 10:29:25,388 - INFO - ðŸªœ Batch step - 115 -- sub batch step 463 -- lr 1.72e-05
2025-03-02 10:29:27,015 - INFO - Step 115 -- ðŸ”„ Training Metrics
2025-03-02 10:29:27,015 - INFO - â”œâ”€â”€ Loss: 10.9777
2025-03-02 10:29:27,015 - INFO - â”œâ”€â”€ Learning Rate: 1.72e-05
2025-03-02 10:29:27,015 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:29:27,694 - INFO - ðŸªœ Batch step - 116 -- sub batch step 464 -- lr 1.74e-05
2025-03-02 10:29:29,858 - INFO - ðŸªœ Batch step - 116 -- sub batch step 465 -- lr 1.74e-05
2025-03-02 10:29:32,033 - INFO - ðŸªœ Batch step - 116 -- sub batch step 466 -- lr 1.74e-05
2025-03-02 10:29:34,193 - INFO - ðŸªœ Batch step - 116 -- sub batch step 467 -- lr 1.74e-05
2025-03-02 10:29:35,751 - INFO - Step 116 -- ðŸ”„ Training Metrics
2025-03-02 10:29:35,752 - INFO - â”œâ”€â”€ Loss: 10.9791
2025-03-02 10:29:35,752 - INFO - â”œâ”€â”€ Learning Rate: 1.74e-05
2025-03-02 10:29:35,752 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:29:36,422 - INFO - ðŸªœ Batch step - 117 -- sub batch step 468 -- lr 1.75e-05
2025-03-02 10:29:38,588 - INFO - ðŸªœ Batch step - 117 -- sub batch step 469 -- lr 1.75e-05
2025-03-02 10:29:41,283 - INFO - ðŸªœ Batch step - 117 -- sub batch step 470 -- lr 1.75e-05
2025-03-02 10:29:43,438 - INFO - ðŸªœ Batch step - 117 -- sub batch step 471 -- lr 1.75e-05
2025-03-02 10:29:44,925 - INFO - Step 117 -- ðŸ”„ Training Metrics
2025-03-02 10:29:44,926 - INFO - â”œâ”€â”€ Loss: 10.9779
2025-03-02 10:29:44,926 - INFO - â”œâ”€â”€ Learning Rate: 1.75e-05
2025-03-02 10:29:44,926 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:29:45,608 - INFO - ðŸªœ Batch step - 118 -- sub batch step 472 -- lr 1.77e-05
2025-03-02 10:29:47,763 - INFO - ðŸªœ Batch step - 118 -- sub batch step 473 -- lr 1.77e-05
2025-03-02 10:29:49,946 - INFO - ðŸªœ Batch step - 118 -- sub batch step 474 -- lr 1.77e-05
2025-03-02 10:29:52,103 - INFO - ðŸªœ Batch step - 118 -- sub batch step 475 -- lr 1.77e-05
2025-03-02 10:29:53,658 - INFO - Step 118 -- ðŸ”„ Training Metrics
2025-03-02 10:29:53,658 - INFO - â”œâ”€â”€ Loss: 10.9785
2025-03-02 10:29:53,658 - INFO - â”œâ”€â”€ Learning Rate: 1.77e-05
2025-03-02 10:29:53,658 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:29:54,332 - INFO - ðŸªœ Batch step - 119 -- sub batch step 476 -- lr 1.78e-05
2025-03-02 10:29:56,491 - INFO - ðŸªœ Batch step - 119 -- sub batch step 477 -- lr 1.78e-05
2025-03-02 10:29:58,771 - INFO - ðŸªœ Batch step - 119 -- sub batch step 478 -- lr 1.78e-05
2025-03-02 10:30:00,934 - INFO - ðŸªœ Batch step - 119 -- sub batch step 479 -- lr 1.78e-05
2025-03-02 10:30:02,490 - INFO - Step 119 -- ðŸ”„ Training Metrics
2025-03-02 10:30:02,490 - INFO - â”œâ”€â”€ Loss: 10.9790
2025-03-02 10:30:02,490 - INFO - â”œâ”€â”€ Learning Rate: 1.78e-05
2025-03-02 10:30:02,490 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:30:03,878 - INFO - ðŸªœ Batch step - 120 -- sub batch step 480 -- lr 1.80e-05
2025-03-02 10:30:06,030 - INFO - ðŸªœ Batch step - 120 -- sub batch step 481 -- lr 1.80e-05
2025-03-02 10:30:08,190 - INFO - ðŸªœ Batch step - 120 -- sub batch step 482 -- lr 1.80e-05
2025-03-02 10:30:10,369 - INFO - ðŸªœ Batch step - 120 -- sub batch step 483 -- lr 1.80e-05
2025-03-02 10:30:11,856 - INFO - Step 120 -- ðŸ”„ Training Metrics
2025-03-02 10:30:11,856 - INFO - â”œâ”€â”€ Loss: 10.9767
2025-03-02 10:30:11,857 - INFO - â”œâ”€â”€ Learning Rate: 1.80e-05
2025-03-02 10:30:11,857 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:30:12,539 - INFO - ðŸªœ Batch step - 121 -- sub batch step 484 -- lr 1.81e-05
2025-03-02 10:30:14,700 - INFO - ðŸªœ Batch step - 121 -- sub batch step 485 -- lr 1.81e-05
2025-03-02 10:30:16,856 - INFO - ðŸªœ Batch step - 121 -- sub batch step 486 -- lr 1.81e-05
2025-03-02 10:30:19,349 - INFO - ðŸªœ Batch step - 121 -- sub batch step 487 -- lr 1.81e-05
2025-03-02 10:30:21,165 - INFO - Step 121 -- ðŸ”„ Training Metrics
2025-03-02 10:30:21,165 - INFO - â”œâ”€â”€ Loss: 10.9767
2025-03-02 10:30:21,165 - INFO - â”œâ”€â”€ Learning Rate: 1.81e-05
2025-03-02 10:30:21,165 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:30:21,834 - INFO - ðŸªœ Batch step - 122 -- sub batch step 488 -- lr 1.83e-05
2025-03-02 10:30:23,995 - INFO - ðŸªœ Batch step - 122 -- sub batch step 489 -- lr 1.83e-05
2025-03-02 10:30:26,160 - INFO - ðŸªœ Batch step - 122 -- sub batch step 490 -- lr 1.83e-05
2025-03-02 10:30:28,337 - INFO - ðŸªœ Batch step - 122 -- sub batch step 491 -- lr 1.83e-05
2025-03-02 10:30:29,891 - INFO - Step 122 -- ðŸ”„ Training Metrics
2025-03-02 10:30:29,892 - INFO - â”œâ”€â”€ Loss: 10.9757
2025-03-02 10:30:29,892 - INFO - â”œâ”€â”€ Learning Rate: 1.83e-05
2025-03-02 10:30:29,892 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:30:30,574 - INFO - ðŸªœ Batch step - 123 -- sub batch step 492 -- lr 1.84e-05
2025-03-02 10:30:32,728 - INFO - ðŸªœ Batch step - 123 -- sub batch step 493 -- lr 1.84e-05
2025-03-02 10:30:34,892 - INFO - ðŸªœ Batch step - 123 -- sub batch step 494 -- lr 1.84e-05
2025-03-02 10:30:37,484 - INFO - ðŸªœ Batch step - 123 -- sub batch step 495 -- lr 1.84e-05
2025-03-02 10:30:39,187 - INFO - Step 123 -- ðŸ”„ Training Metrics
2025-03-02 10:30:39,187 - INFO - â”œâ”€â”€ Loss: 10.9760
2025-03-02 10:30:39,187 - INFO - â”œâ”€â”€ Learning Rate: 1.84e-05
2025-03-02 10:30:39,188 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:30:39,861 - INFO - ðŸªœ Batch step - 124 -- sub batch step 496 -- lr 1.86e-05
2025-03-02 10:30:42,022 - INFO - ðŸªœ Batch step - 124 -- sub batch step 497 -- lr 1.86e-05
2025-03-02 10:30:44,180 - INFO - ðŸªœ Batch step - 124 -- sub batch step 498 -- lr 1.86e-05
2025-03-02 10:30:46,359 - INFO - ðŸªœ Batch step - 124 -- sub batch step 499 -- lr 1.86e-05
2025-03-02 10:30:47,932 - INFO - Step 124 -- ðŸ”„ Training Metrics
2025-03-02 10:30:47,932 - INFO - â”œâ”€â”€ Loss: 10.9754
2025-03-02 10:30:47,932 - INFO - â”œâ”€â”€ Learning Rate: 1.86e-05
2025-03-02 10:30:47,932 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:30:48,610 - INFO - ðŸªœ Batch step - 125 -- sub batch step 500 -- lr 1.87e-05
2025-03-02 10:30:50,765 - INFO - ðŸªœ Batch step - 125 -- sub batch step 501 -- lr 1.87e-05
2025-03-02 10:30:52,927 - INFO - ðŸªœ Batch step - 125 -- sub batch step 502 -- lr 1.87e-05
2025-03-02 10:30:55,390 - INFO - ðŸªœ Batch step - 125 -- sub batch step 503 -- lr 1.87e-05
2025-03-02 10:30:57,244 - INFO - Step 125 -- ðŸ”„ Training Metrics
2025-03-02 10:30:57,244 - INFO - â”œâ”€â”€ Loss: 10.9754
2025-03-02 10:30:57,244 - INFO - â”œâ”€â”€ Learning Rate: 1.87e-05
2025-03-02 10:30:57,244 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:30:57,921 - INFO - ðŸªœ Batch step - 126 -- sub batch step 504 -- lr 1.89e-05
2025-03-02 10:31:00,079 - INFO - ðŸªœ Batch step - 126 -- sub batch step 505 -- lr 1.89e-05
2025-03-02 10:31:02,236 - INFO - ðŸªœ Batch step - 126 -- sub batch step 506 -- lr 1.89e-05
2025-03-02 10:31:04,416 - INFO - ðŸªœ Batch step - 126 -- sub batch step 507 -- lr 1.89e-05
2025-03-02 10:31:05,980 - INFO - Step 126 -- ðŸ”„ Training Metrics
2025-03-02 10:31:05,981 - INFO - â”œâ”€â”€ Loss: 10.9750
2025-03-02 10:31:05,981 - INFO - â”œâ”€â”€ Learning Rate: 1.89e-05
2025-03-02 10:31:05,981 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:31:06,653 - INFO - ðŸªœ Batch step - 127 -- sub batch step 508 -- lr 1.90e-05
2025-03-02 10:31:08,817 - INFO - ðŸªœ Batch step - 127 -- sub batch step 509 -- lr 1.90e-05
2025-03-02 10:31:10,975 - INFO - ðŸªœ Batch step - 127 -- sub batch step 510 -- lr 1.90e-05
2025-03-02 10:31:13,336 - INFO - ðŸªœ Batch step - 127 -- sub batch step 511 -- lr 1.90e-05
2025-03-02 10:31:15,267 - INFO - Step 127 -- ðŸ”„ Training Metrics
2025-03-02 10:31:15,267 - INFO - â”œâ”€â”€ Loss: 10.9759
2025-03-02 10:31:15,267 - INFO - â”œâ”€â”€ Learning Rate: 1.90e-05
2025-03-02 10:31:15,267 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:31:15,944 - INFO - ðŸªœ Batch step - 128 -- sub batch step 512 -- lr 1.92e-05
2025-03-02 10:31:18,100 - INFO - ðŸªœ Batch step - 128 -- sub batch step 513 -- lr 1.92e-05
2025-03-02 10:31:20,259 - INFO - ðŸªœ Batch step - 128 -- sub batch step 514 -- lr 1.92e-05
2025-03-02 10:31:22,441 - INFO - ðŸªœ Batch step - 128 -- sub batch step 515 -- lr 1.92e-05
2025-03-02 10:31:23,997 - INFO - Step 128 -- ðŸ”„ Training Metrics
2025-03-02 10:31:23,997 - INFO - â”œâ”€â”€ Loss: 10.9757
2025-03-02 10:31:23,997 - INFO - â”œâ”€â”€ Learning Rate: 1.92e-05
2025-03-02 10:31:23,998 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:31:24,668 - INFO - ðŸªœ Batch step - 129 -- sub batch step 516 -- lr 1.93e-05
2025-03-02 10:31:26,826 - INFO - ðŸªœ Batch step - 129 -- sub batch step 517 -- lr 1.93e-05
2025-03-02 10:31:28,981 - INFO - ðŸªœ Batch step - 129 -- sub batch step 518 -- lr 1.93e-05
2025-03-02 10:31:31,571 - INFO - ðŸªœ Batch step - 129 -- sub batch step 519 -- lr 1.93e-05
2025-03-02 10:31:33,477 - INFO - Step 129 -- ðŸ”„ Training Metrics
2025-03-02 10:31:33,477 - INFO - â”œâ”€â”€ Loss: 10.9733
2025-03-02 10:31:33,477 - INFO - â”œâ”€â”€ Learning Rate: 1.93e-05
2025-03-02 10:31:33,477 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:31:34,156 - INFO - ðŸªœ Batch step - 130 -- sub batch step 520 -- lr 1.95e-05
2025-03-02 10:31:36,311 - INFO - ðŸªœ Batch step - 130 -- sub batch step 521 -- lr 1.95e-05
2025-03-02 10:31:38,466 - INFO - ðŸªœ Batch step - 130 -- sub batch step 522 -- lr 1.95e-05
2025-03-02 10:31:40,638 - INFO - ðŸªœ Batch step - 130 -- sub batch step 523 -- lr 1.95e-05
2025-03-02 10:31:42,203 - INFO - Step 130 -- ðŸ”„ Training Metrics
2025-03-02 10:31:42,204 - INFO - â”œâ”€â”€ Loss: 10.9740
2025-03-02 10:31:42,204 - INFO - â”œâ”€â”€ Learning Rate: 1.95e-05
2025-03-02 10:31:42,204 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:31:42,879 - INFO - ðŸªœ Batch step - 131 -- sub batch step 524 -- lr 1.96e-05
2025-03-02 10:31:45,033 - INFO - ðŸªœ Batch step - 131 -- sub batch step 525 -- lr 1.96e-05
2025-03-02 10:31:47,454 - INFO - ðŸªœ Batch step - 131 -- sub batch step 526 -- lr 1.96e-05
2025-03-02 10:31:49,617 - INFO - ðŸªœ Batch step - 131 -- sub batch step 527 -- lr 1.96e-05
2025-03-02 10:31:51,576 - INFO - Step 131 -- ðŸ”„ Training Metrics
2025-03-02 10:31:51,576 - INFO - â”œâ”€â”€ Loss: 10.9710
2025-03-02 10:31:51,576 - INFO - â”œâ”€â”€ Learning Rate: 1.96e-05
2025-03-02 10:31:51,576 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:31:52,246 - INFO - ðŸªœ Batch step - 132 -- sub batch step 528 -- lr 1.98e-05
2025-03-02 10:31:54,408 - INFO - ðŸªœ Batch step - 132 -- sub batch step 529 -- lr 1.98e-05
2025-03-02 10:31:56,588 - INFO - ðŸªœ Batch step - 132 -- sub batch step 530 -- lr 1.98e-05
2025-03-02 10:31:58,743 - INFO - ðŸªœ Batch step - 132 -- sub batch step 531 -- lr 1.98e-05
2025-03-02 10:32:00,301 - INFO - Step 132 -- ðŸ”„ Training Metrics
2025-03-02 10:32:00,301 - INFO - â”œâ”€â”€ Loss: 10.9736
2025-03-02 10:32:00,301 - INFO - â”œâ”€â”€ Learning Rate: 1.98e-05
2025-03-02 10:32:00,301 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:32:00,976 - INFO - ðŸªœ Batch step - 133 -- sub batch step 532 -- lr 2.00e-05
2025-03-02 10:32:03,132 - INFO - ðŸªœ Batch step - 133 -- sub batch step 533 -- lr 2.00e-05
2025-03-02 10:32:05,842 - INFO - ðŸªœ Batch step - 133 -- sub batch step 534 -- lr 2.00e-05
2025-03-02 10:32:07,997 - INFO - ðŸªœ Batch step - 133 -- sub batch step 535 -- lr 2.00e-05
2025-03-02 10:32:09,701 - INFO - Step 133 -- ðŸ”„ Training Metrics
2025-03-02 10:32:09,701 - INFO - â”œâ”€â”€ Loss: 10.9719
2025-03-02 10:32:09,702 - INFO - â”œâ”€â”€ Learning Rate: 2.00e-05
2025-03-02 10:32:09,702 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:32:10,373 - INFO - ðŸªœ Batch step - 134 -- sub batch step 536 -- lr 2.01e-05
2025-03-02 10:32:12,529 - INFO - ðŸªœ Batch step - 134 -- sub batch step 537 -- lr 2.01e-05
2025-03-02 10:32:14,704 - INFO - ðŸªœ Batch step - 134 -- sub batch step 538 -- lr 2.01e-05
2025-03-02 10:32:16,863 - INFO - ðŸªœ Batch step - 134 -- sub batch step 539 -- lr 2.01e-05
2025-03-02 10:32:18,431 - INFO - Step 134 -- ðŸ”„ Training Metrics
2025-03-02 10:32:18,431 - INFO - â”œâ”€â”€ Loss: 10.9703
2025-03-02 10:32:18,431 - INFO - â”œâ”€â”€ Learning Rate: 2.01e-05
2025-03-02 10:32:18,432 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:32:19,110 - INFO - ðŸªœ Batch step - 135 -- sub batch step 540 -- lr 2.03e-05
2025-03-02 10:32:21,260 - INFO - ðŸªœ Batch step - 135 -- sub batch step 541 -- lr 2.03e-05
2025-03-02 10:32:23,945 - INFO - ðŸªœ Batch step - 135 -- sub batch step 542 -- lr 2.03e-05
2025-03-02 10:32:26,103 - INFO - ðŸªœ Batch step - 135 -- sub batch step 543 -- lr 2.03e-05
2025-03-02 10:32:27,814 - INFO - Step 135 -- ðŸ”„ Training Metrics
2025-03-02 10:32:27,815 - INFO - â”œâ”€â”€ Loss: 10.9714
2025-03-02 10:32:27,815 - INFO - â”œâ”€â”€ Learning Rate: 2.03e-05
2025-03-02 10:32:27,815 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:32:28,491 - INFO - ðŸªœ Batch step - 136 -- sub batch step 544 -- lr 2.04e-05
2025-03-02 10:32:30,650 - INFO - ðŸªœ Batch step - 136 -- sub batch step 545 -- lr 2.04e-05
2025-03-02 10:32:32,818 - INFO - ðŸªœ Batch step - 136 -- sub batch step 546 -- lr 2.04e-05
2025-03-02 10:32:34,978 - INFO - ðŸªœ Batch step - 136 -- sub batch step 547 -- lr 2.04e-05
2025-03-02 10:32:36,550 - INFO - Step 136 -- ðŸ”„ Training Metrics
2025-03-02 10:32:36,550 - INFO - â”œâ”€â”€ Loss: 10.9712
2025-03-02 10:32:36,550 - INFO - â”œâ”€â”€ Learning Rate: 2.04e-05
2025-03-02 10:32:36,550 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:32:37,221 - INFO - ðŸªœ Batch step - 137 -- sub batch step 548 -- lr 2.06e-05
2025-03-02 10:32:39,380 - INFO - ðŸªœ Batch step - 137 -- sub batch step 549 -- lr 2.06e-05
2025-03-02 10:32:41,796 - INFO - ðŸªœ Batch step - 137 -- sub batch step 550 -- lr 2.06e-05
2025-03-02 10:32:43,956 - INFO - ðŸªœ Batch step - 137 -- sub batch step 551 -- lr 2.06e-05
2025-03-02 10:32:45,910 - INFO - Step 137 -- ðŸ”„ Training Metrics
2025-03-02 10:32:45,910 - INFO - â”œâ”€â”€ Loss: 10.9696
2025-03-02 10:32:45,910 - INFO - â”œâ”€â”€ Learning Rate: 2.06e-05
2025-03-02 10:32:45,910 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:32:46,586 - INFO - ðŸªœ Batch step - 138 -- sub batch step 552 -- lr 2.07e-05
2025-03-02 10:32:48,736 - INFO - ðŸªœ Batch step - 138 -- sub batch step 553 -- lr 2.07e-05
2025-03-02 10:32:50,914 - INFO - ðŸªœ Batch step - 138 -- sub batch step 554 -- lr 2.07e-05
2025-03-02 10:32:53,079 - INFO - ðŸªœ Batch step - 138 -- sub batch step 555 -- lr 2.07e-05
2025-03-02 10:32:54,633 - INFO - Step 138 -- ðŸ”„ Training Metrics
2025-03-02 10:32:54,634 - INFO - â”œâ”€â”€ Loss: 10.9688
2025-03-02 10:32:54,634 - INFO - â”œâ”€â”€ Learning Rate: 2.07e-05
2025-03-02 10:32:54,634 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:32:55,305 - INFO - ðŸªœ Batch step - 139 -- sub batch step 556 -- lr 2.08e-05
2025-03-02 10:32:57,467 - INFO - ðŸªœ Batch step - 139 -- sub batch step 557 -- lr 2.08e-05
2025-03-02 10:32:59,749 - INFO - ðŸªœ Batch step - 139 -- sub batch step 558 -- lr 2.08e-05
2025-03-02 10:33:01,911 - INFO - ðŸªœ Batch step - 139 -- sub batch step 559 -- lr 2.08e-05
2025-03-02 10:33:03,462 - INFO - Step 139 -- ðŸ”„ Training Metrics
2025-03-02 10:33:03,463 - INFO - â”œâ”€â”€ Loss: 10.9686
2025-03-02 10:33:03,463 - INFO - â”œâ”€â”€ Learning Rate: 2.08e-05
2025-03-02 10:33:03,463 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:33:04,676 - INFO - ðŸªœ Batch step - 140 -- sub batch step 560 -- lr 2.10e-05
2025-03-02 10:33:06,839 - INFO - ðŸªœ Batch step - 140 -- sub batch step 561 -- lr 2.10e-05
2025-03-02 10:33:09,005 - INFO - ðŸªœ Batch step - 140 -- sub batch step 562 -- lr 2.10e-05
2025-03-02 10:33:11,183 - INFO - ðŸªœ Batch step - 140 -- sub batch step 563 -- lr 2.10e-05
2025-03-02 10:33:12,795 - INFO - Step 140 -- ðŸ”„ Training Metrics
2025-03-02 10:33:12,795 - INFO - â”œâ”€â”€ Loss: 10.9688
2025-03-02 10:33:12,795 - INFO - â”œâ”€â”€ Learning Rate: 2.10e-05
2025-03-02 10:33:12,795 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:33:13,470 - INFO - ðŸªœ Batch step - 141 -- sub batch step 564 -- lr 2.11e-05
2025-03-02 10:33:15,631 - INFO - ðŸªœ Batch step - 141 -- sub batch step 565 -- lr 2.11e-05
2025-03-02 10:33:17,787 - INFO - ðŸªœ Batch step - 141 -- sub batch step 566 -- lr 2.11e-05
2025-03-02 10:33:20,215 - INFO - ðŸªœ Batch step - 141 -- sub batch step 567 -- lr 2.11e-05
2025-03-02 10:33:22,166 - INFO - Step 141 -- ðŸ”„ Training Metrics
2025-03-02 10:33:22,166 - INFO - â”œâ”€â”€ Loss: 10.9677
2025-03-02 10:33:22,166 - INFO - â”œâ”€â”€ Learning Rate: 2.11e-05
2025-03-02 10:33:22,166 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:33:22,836 - INFO - ðŸªœ Batch step - 142 -- sub batch step 568 -- lr 2.13e-05
2025-03-02 10:33:24,997 - INFO - ðŸªœ Batch step - 142 -- sub batch step 569 -- lr 2.13e-05
2025-03-02 10:33:27,159 - INFO - ðŸªœ Batch step - 142 -- sub batch step 570 -- lr 2.13e-05
2025-03-02 10:33:29,333 - INFO - ðŸªœ Batch step - 142 -- sub batch step 571 -- lr 2.13e-05
2025-03-02 10:33:30,910 - INFO - Step 142 -- ðŸ”„ Training Metrics
2025-03-02 10:33:30,910 - INFO - â”œâ”€â”€ Loss: 10.9676
2025-03-02 10:33:30,910 - INFO - â”œâ”€â”€ Learning Rate: 2.13e-05
2025-03-02 10:33:30,910 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:33:31,586 - INFO - ðŸªœ Batch step - 143 -- sub batch step 572 -- lr 2.14e-05
2025-03-02 10:33:33,745 - INFO - ðŸªœ Batch step - 143 -- sub batch step 573 -- lr 2.14e-05
2025-03-02 10:33:35,905 - INFO - ðŸªœ Batch step - 143 -- sub batch step 574 -- lr 2.14e-05
2025-03-02 10:33:38,559 - INFO - ðŸªœ Batch step - 143 -- sub batch step 575 -- lr 2.14e-05
2025-03-02 10:33:40,290 - INFO - Step 143 -- ðŸ”„ Training Metrics
2025-03-02 10:33:40,291 - INFO - â”œâ”€â”€ Loss: 10.9678
2025-03-02 10:33:40,291 - INFO - â”œâ”€â”€ Learning Rate: 2.14e-05
2025-03-02 10:33:40,291 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:33:40,961 - INFO - ðŸªœ Batch step - 144 -- sub batch step 576 -- lr 2.16e-05
2025-03-02 10:33:43,120 - INFO - ðŸªœ Batch step - 144 -- sub batch step 577 -- lr 2.16e-05
2025-03-02 10:33:45,272 - INFO - ðŸªœ Batch step - 144 -- sub batch step 578 -- lr 2.16e-05
2025-03-02 10:33:47,451 - INFO - ðŸªœ Batch step - 144 -- sub batch step 579 -- lr 2.16e-05
2025-03-02 10:33:49,019 - INFO - Step 144 -- ðŸ”„ Training Metrics
2025-03-02 10:33:49,019 - INFO - â”œâ”€â”€ Loss: 10.9669
2025-03-02 10:33:49,019 - INFO - â”œâ”€â”€ Learning Rate: 2.16e-05
2025-03-02 10:33:49,019 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:33:49,696 - INFO - ðŸªœ Batch step - 145 -- sub batch step 580 -- lr 2.17e-05
2025-03-02 10:33:51,852 - INFO - ðŸªœ Batch step - 145 -- sub batch step 581 -- lr 2.17e-05
2025-03-02 10:33:54,016 - INFO - ðŸªœ Batch step - 145 -- sub batch step 582 -- lr 2.17e-05
2025-03-02 10:33:56,432 - INFO - ðŸªœ Batch step - 145 -- sub batch step 583 -- lr 2.17e-05
2025-03-02 10:33:58,204 - INFO - Step 145 -- ðŸ”„ Training Metrics
2025-03-02 10:33:58,204 - INFO - â”œâ”€â”€ Loss: 10.9683
2025-03-02 10:33:58,204 - INFO - â”œâ”€â”€ Learning Rate: 2.17e-05
2025-03-02 10:33:58,204 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:33:58,879 - INFO - ðŸªœ Batch step - 146 -- sub batch step 584 -- lr 2.19e-05
2025-03-02 10:34:01,035 - INFO - ðŸªœ Batch step - 146 -- sub batch step 585 -- lr 2.19e-05
2025-03-02 10:34:03,191 - INFO - ðŸªœ Batch step - 146 -- sub batch step 586 -- lr 2.19e-05
2025-03-02 10:34:05,371 - INFO - ðŸªœ Batch step - 146 -- sub batch step 587 -- lr 2.19e-05
2025-03-02 10:34:06,930 - INFO - Step 146 -- ðŸ”„ Training Metrics
2025-03-02 10:34:06,930 - INFO - â”œâ”€â”€ Loss: 10.9675
2025-03-02 10:34:06,930 - INFO - â”œâ”€â”€ Learning Rate: 2.19e-05
2025-03-02 10:34:06,930 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:34:07,602 - INFO - ðŸªœ Batch step - 147 -- sub batch step 588 -- lr 2.20e-05
2025-03-02 10:34:09,762 - INFO - ðŸªœ Batch step - 147 -- sub batch step 589 -- lr 2.20e-05
2025-03-02 10:34:11,924 - INFO - ðŸªœ Batch step - 147 -- sub batch step 590 -- lr 2.20e-05
2025-03-02 10:34:14,518 - INFO - ðŸªœ Batch step - 147 -- sub batch step 591 -- lr 2.20e-05
2025-03-02 10:34:16,098 - INFO - Step 147 -- ðŸ”„ Training Metrics
2025-03-02 10:34:16,098 - INFO - â”œâ”€â”€ Loss: 10.9658
2025-03-02 10:34:16,098 - INFO - â”œâ”€â”€ Learning Rate: 2.20e-05
2025-03-02 10:34:16,099 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:34:16,775 - INFO - ðŸªœ Batch step - 148 -- sub batch step 592 -- lr 2.22e-05
2025-03-02 10:34:18,930 - INFO - ðŸªœ Batch step - 148 -- sub batch step 593 -- lr 2.22e-05
2025-03-02 10:34:21,091 - INFO - ðŸªœ Batch step - 148 -- sub batch step 594 -- lr 2.22e-05
2025-03-02 10:34:23,275 - INFO - ðŸªœ Batch step - 148 -- sub batch step 595 -- lr 2.22e-05
2025-03-02 10:34:24,831 - INFO - Step 148 -- ðŸ”„ Training Metrics
2025-03-02 10:34:24,832 - INFO - â”œâ”€â”€ Loss: 10.9659
2025-03-02 10:34:24,832 - INFO - â”œâ”€â”€ Learning Rate: 2.22e-05
2025-03-02 10:34:24,832 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:34:25,506 - INFO - ðŸªœ Batch step - 149 -- sub batch step 596 -- lr 2.23e-05
2025-03-02 10:34:27,666 - INFO - ðŸªœ Batch step - 149 -- sub batch step 597 -- lr 2.23e-05
2025-03-02 10:34:29,822 - INFO - ðŸªœ Batch step - 149 -- sub batch step 598 -- lr 2.23e-05
2025-03-02 10:34:32,472 - INFO - ðŸªœ Batch step - 149 -- sub batch step 599 -- lr 2.23e-05
2025-03-02 10:34:34,139 - INFO - Step 149 -- ðŸ”„ Training Metrics
2025-03-02 10:34:34,139 - INFO - â”œâ”€â”€ Loss: 10.9650
2025-03-02 10:34:34,139 - INFO - â”œâ”€â”€ Learning Rate: 2.23e-05
2025-03-02 10:34:34,139 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:34:34,816 - INFO - ðŸªœ Batch step - 150 -- sub batch step 600 -- lr 2.25e-05
2025-03-02 10:34:36,972 - INFO - ðŸªœ Batch step - 150 -- sub batch step 601 -- lr 2.25e-05
2025-03-02 10:34:39,138 - INFO - ðŸªœ Batch step - 150 -- sub batch step 602 -- lr 2.25e-05
2025-03-02 10:34:41,310 - INFO - ðŸªœ Batch step - 150 -- sub batch step 603 -- lr 2.25e-05
2025-03-02 10:34:42,858 - INFO - Step 150 -- ðŸ”„ Training Metrics
2025-03-02 10:34:42,858 - INFO - â”œâ”€â”€ Loss: 10.9654
2025-03-02 10:34:42,858 - INFO - â”œâ”€â”€ Learning Rate: 2.25e-05
2025-03-02 10:34:42,858 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:34:43,535 - INFO - ðŸªœ Batch step - 151 -- sub batch step 604 -- lr 2.26e-05
2025-03-02 10:34:45,694 - INFO - ðŸªœ Batch step - 151 -- sub batch step 605 -- lr 2.26e-05
2025-03-02 10:34:48,419 - INFO - ðŸªœ Batch step - 151 -- sub batch step 606 -- lr 2.26e-05
2025-03-02 10:34:50,578 - INFO - ðŸªœ Batch step - 151 -- sub batch step 607 -- lr 2.26e-05
2025-03-02 10:34:52,069 - INFO - Step 151 -- ðŸ”„ Training Metrics
2025-03-02 10:34:52,069 - INFO - â”œâ”€â”€ Loss: 10.9636
2025-03-02 10:34:52,070 - INFO - â”œâ”€â”€ Learning Rate: 2.26e-05
2025-03-02 10:34:52,070 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:34:52,742 - INFO - ðŸªœ Batch step - 152 -- sub batch step 608 -- lr 2.28e-05
2025-03-02 10:34:54,906 - INFO - ðŸªœ Batch step - 152 -- sub batch step 609 -- lr 2.28e-05
2025-03-02 10:34:57,083 - INFO - ðŸªœ Batch step - 152 -- sub batch step 610 -- lr 2.28e-05
2025-03-02 10:34:59,237 - INFO - ðŸªœ Batch step - 152 -- sub batch step 611 -- lr 2.28e-05
2025-03-02 10:35:00,795 - INFO - Step 152 -- ðŸ”„ Training Metrics
2025-03-02 10:35:00,796 - INFO - â”œâ”€â”€ Loss: 10.9641
2025-03-02 10:35:00,796 - INFO - â”œâ”€â”€ Learning Rate: 2.28e-05
2025-03-02 10:35:00,796 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:35:01,475 - INFO - ðŸªœ Batch step - 153 -- sub batch step 612 -- lr 2.29e-05
2025-03-02 10:35:03,626 - INFO - ðŸªœ Batch step - 153 -- sub batch step 613 -- lr 2.29e-05
2025-03-02 10:35:06,059 - INFO - ðŸªœ Batch step - 153 -- sub batch step 614 -- lr 2.29e-05
2025-03-02 10:35:08,222 - INFO - ðŸªœ Batch step - 153 -- sub batch step 615 -- lr 2.29e-05
2025-03-02 10:35:10,132 - INFO - Step 153 -- ðŸ”„ Training Metrics
2025-03-02 10:35:10,132 - INFO - â”œâ”€â”€ Loss: 10.9629
2025-03-02 10:35:10,132 - INFO - â”œâ”€â”€ Learning Rate: 2.29e-05
2025-03-02 10:35:10,133 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:35:10,805 - INFO - ðŸªœ Batch step - 154 -- sub batch step 616 -- lr 2.31e-05
2025-03-02 10:35:12,966 - INFO - ðŸªœ Batch step - 154 -- sub batch step 617 -- lr 2.31e-05
2025-03-02 10:35:15,140 - INFO - ðŸªœ Batch step - 154 -- sub batch step 618 -- lr 2.31e-05
2025-03-02 10:35:17,303 - INFO - ðŸªœ Batch step - 154 -- sub batch step 619 -- lr 2.31e-05
2025-03-02 10:35:18,862 - INFO - Step 154 -- ðŸ”„ Training Metrics
2025-03-02 10:35:18,862 - INFO - â”œâ”€â”€ Loss: 10.9616
2025-03-02 10:35:18,862 - INFO - â”œâ”€â”€ Learning Rate: 2.31e-05
2025-03-02 10:35:18,862 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:35:19,544 - INFO - ðŸªœ Batch step - 155 -- sub batch step 620 -- lr 2.32e-05
2025-03-02 10:35:21,694 - INFO - ðŸªœ Batch step - 155 -- sub batch step 621 -- lr 2.32e-05
2025-03-02 10:35:24,100 - INFO - ðŸªœ Batch step - 155 -- sub batch step 622 -- lr 2.32e-05
2025-03-02 10:35:26,255 - INFO - ðŸªœ Batch step - 155 -- sub batch step 623 -- lr 2.32e-05
2025-03-02 10:35:28,036 - INFO - Step 155 -- ðŸ”„ Training Metrics
2025-03-02 10:35:28,036 - INFO - â”œâ”€â”€ Loss: 10.9614
2025-03-02 10:35:28,036 - INFO - â”œâ”€â”€ Learning Rate: 2.32e-05
2025-03-02 10:35:28,036 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:35:28,712 - INFO - ðŸªœ Batch step - 156 -- sub batch step 624 -- lr 2.34e-05
2025-03-02 10:35:30,869 - INFO - ðŸªœ Batch step - 156 -- sub batch step 625 -- lr 2.34e-05
2025-03-02 10:35:33,044 - INFO - ðŸªœ Batch step - 156 -- sub batch step 626 -- lr 2.34e-05
2025-03-02 10:35:35,204 - INFO - ðŸªœ Batch step - 156 -- sub batch step 627 -- lr 2.34e-05
2025-03-02 10:35:36,764 - INFO - Step 156 -- ðŸ”„ Training Metrics
2025-03-02 10:35:36,764 - INFO - â”œâ”€â”€ Loss: 10.9624
2025-03-02 10:35:36,764 - INFO - â”œâ”€â”€ Learning Rate: 2.34e-05
2025-03-02 10:35:36,765 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:35:37,437 - INFO - ðŸªœ Batch step - 157 -- sub batch step 628 -- lr 2.35e-05
2025-03-02 10:35:39,598 - INFO - ðŸªœ Batch step - 157 -- sub batch step 629 -- lr 2.35e-05
2025-03-02 10:35:42,439 - INFO - ðŸªœ Batch step - 157 -- sub batch step 630 -- lr 2.35e-05
2025-03-02 10:35:44,594 - INFO - ðŸªœ Batch step - 157 -- sub batch step 631 -- lr 2.35e-05
2025-03-02 10:35:46,144 - INFO - Step 157 -- ðŸ”„ Training Metrics
2025-03-02 10:35:46,145 - INFO - â”œâ”€â”€ Loss: 10.9605
2025-03-02 10:35:46,145 - INFO - â”œâ”€â”€ Learning Rate: 2.35e-05
2025-03-02 10:35:46,145 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:35:46,821 - INFO - ðŸªœ Batch step - 158 -- sub batch step 632 -- lr 2.37e-05
2025-03-02 10:35:48,978 - INFO - ðŸªœ Batch step - 158 -- sub batch step 633 -- lr 2.37e-05
2025-03-02 10:35:51,159 - INFO - ðŸªœ Batch step - 158 -- sub batch step 634 -- lr 2.37e-05
2025-03-02 10:35:53,321 - INFO - ðŸªœ Batch step - 158 -- sub batch step 635 -- lr 2.37e-05
2025-03-02 10:35:54,877 - INFO - Step 158 -- ðŸ”„ Training Metrics
2025-03-02 10:35:54,877 - INFO - â”œâ”€â”€ Loss: 10.9606
2025-03-02 10:35:54,877 - INFO - â”œâ”€â”€ Learning Rate: 2.37e-05
2025-03-02 10:35:54,877 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:35:55,549 - INFO - ðŸªœ Batch step - 159 -- sub batch step 636 -- lr 2.38e-05
2025-03-02 10:35:57,709 - INFO - ðŸªœ Batch step - 159 -- sub batch step 637 -- lr 2.38e-05
2025-03-02 10:35:59,992 - INFO - ðŸªœ Batch step - 159 -- sub batch step 638 -- lr 2.38e-05
2025-03-02 10:36:02,155 - INFO - ðŸªœ Batch step - 159 -- sub batch step 639 -- lr 2.38e-05
2025-03-02 10:36:03,725 - INFO - Step 159 -- ðŸ”„ Training Metrics
2025-03-02 10:36:03,725 - INFO - â”œâ”€â”€ Loss: 10.9596
2025-03-02 10:36:03,725 - INFO - â”œâ”€â”€ Learning Rate: 2.38e-05
2025-03-02 10:36:03,725 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:36:04,947 - INFO - ðŸªœ Batch step - 160 -- sub batch step 640 -- lr 2.40e-05
2025-03-02 10:36:07,102 - INFO - ðŸªœ Batch step - 160 -- sub batch step 641 -- lr 2.40e-05
2025-03-02 10:36:09,261 - INFO - ðŸªœ Batch step - 160 -- sub batch step 642 -- lr 2.40e-05
2025-03-02 10:36:11,432 - INFO - ðŸªœ Batch step - 160 -- sub batch step 643 -- lr 2.40e-05
2025-03-02 10:36:12,980 - INFO - Step 160 -- ðŸ”„ Training Metrics
2025-03-02 10:36:12,980 - INFO - â”œâ”€â”€ Loss: 10.9602
2025-03-02 10:36:12,980 - INFO - â”œâ”€â”€ Learning Rate: 2.40e-05
2025-03-02 10:36:12,980 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:36:13,661 - INFO - ðŸªœ Batch step - 161 -- sub batch step 644 -- lr 2.41e-05
2025-03-02 10:36:15,826 - INFO - ðŸªœ Batch step - 161 -- sub batch step 645 -- lr 2.41e-05
2025-03-02 10:36:17,983 - INFO - ðŸªœ Batch step - 161 -- sub batch step 646 -- lr 2.41e-05
2025-03-02 10:36:20,379 - INFO - ðŸªœ Batch step - 161 -- sub batch step 647 -- lr 2.41e-05
2025-03-02 10:36:22,284 - INFO - Step 161 -- ðŸ”„ Training Metrics
2025-03-02 10:36:22,285 - INFO - â”œâ”€â”€ Loss: 10.9588
2025-03-02 10:36:22,285 - INFO - â”œâ”€â”€ Learning Rate: 2.41e-05
2025-03-02 10:36:22,285 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:36:22,954 - INFO - ðŸªœ Batch step - 162 -- sub batch step 648 -- lr 2.43e-05
2025-03-02 10:36:25,118 - INFO - ðŸªœ Batch step - 162 -- sub batch step 649 -- lr 2.43e-05
2025-03-02 10:36:27,275 - INFO - ðŸªœ Batch step - 162 -- sub batch step 650 -- lr 2.43e-05
2025-03-02 10:36:29,452 - INFO - ðŸªœ Batch step - 162 -- sub batch step 651 -- lr 2.43e-05
2025-03-02 10:36:31,017 - INFO - Step 162 -- ðŸ”„ Training Metrics
2025-03-02 10:36:31,017 - INFO - â”œâ”€â”€ Loss: 10.9577
2025-03-02 10:36:31,017 - INFO - â”œâ”€â”€ Learning Rate: 2.43e-05
2025-03-02 10:36:31,017 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:36:31,694 - INFO - ðŸªœ Batch step - 163 -- sub batch step 652 -- lr 2.44e-05
2025-03-02 10:36:33,847 - INFO - ðŸªœ Batch step - 163 -- sub batch step 653 -- lr 2.44e-05
2025-03-02 10:36:36,010 - INFO - ðŸªœ Batch step - 163 -- sub batch step 654 -- lr 2.44e-05
2025-03-02 10:36:38,702 - INFO - ðŸªœ Batch step - 163 -- sub batch step 655 -- lr 2.44e-05
2025-03-02 10:36:40,249 - INFO - Step 163 -- ðŸ”„ Training Metrics
2025-03-02 10:36:40,249 - INFO - â”œâ”€â”€ Loss: 10.9573
2025-03-02 10:36:40,249 - INFO - â”œâ”€â”€ Learning Rate: 2.44e-05
2025-03-02 10:36:40,249 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:36:40,919 - INFO - ðŸªœ Batch step - 164 -- sub batch step 656 -- lr 2.46e-05
2025-03-02 10:36:43,077 - INFO - ðŸªœ Batch step - 164 -- sub batch step 657 -- lr 2.46e-05
2025-03-02 10:36:45,230 - INFO - ðŸªœ Batch step - 164 -- sub batch step 658 -- lr 2.46e-05
2025-03-02 10:36:47,415 - INFO - ðŸªœ Batch step - 164 -- sub batch step 659 -- lr 2.46e-05
2025-03-02 10:36:48,967 - INFO - Step 164 -- ðŸ”„ Training Metrics
2025-03-02 10:36:48,968 - INFO - â”œâ”€â”€ Loss: 10.9575
2025-03-02 10:36:48,968 - INFO - â”œâ”€â”€ Learning Rate: 2.46e-05
2025-03-02 10:36:48,968 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:36:49,645 - INFO - ðŸªœ Batch step - 165 -- sub batch step 660 -- lr 2.47e-05
2025-03-02 10:36:51,801 - INFO - ðŸªœ Batch step - 165 -- sub batch step 661 -- lr 2.47e-05
2025-03-02 10:36:53,959 - INFO - ðŸªœ Batch step - 165 -- sub batch step 662 -- lr 2.47e-05
2025-03-02 10:36:56,644 - INFO - ðŸªœ Batch step - 165 -- sub batch step 663 -- lr 2.47e-05
2025-03-02 10:36:58,262 - INFO - Step 165 -- ðŸ”„ Training Metrics
2025-03-02 10:36:58,263 - INFO - â”œâ”€â”€ Loss: 10.9556
2025-03-02 10:36:58,263 - INFO - â”œâ”€â”€ Learning Rate: 2.47e-05
2025-03-02 10:36:58,263 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:36:58,942 - INFO - ðŸªœ Batch step - 166 -- sub batch step 664 -- lr 2.49e-05
2025-03-02 10:37:01,102 - INFO - ðŸªœ Batch step - 166 -- sub batch step 665 -- lr 2.49e-05
2025-03-02 10:37:03,258 - INFO - ðŸªœ Batch step - 166 -- sub batch step 666 -- lr 2.49e-05
2025-03-02 10:37:05,438 - INFO - ðŸªœ Batch step - 166 -- sub batch step 667 -- lr 2.49e-05
2025-03-02 10:37:07,001 - INFO - Step 166 -- ðŸ”„ Training Metrics
2025-03-02 10:37:07,001 - INFO - â”œâ”€â”€ Loss: 10.9553
2025-03-02 10:37:07,001 - INFO - â”œâ”€â”€ Learning Rate: 2.49e-05
2025-03-02 10:37:07,001 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:37:07,674 - INFO - ðŸªœ Batch step - 167 -- sub batch step 668 -- lr 2.50e-05
2025-03-02 10:37:09,838 - INFO - ðŸªœ Batch step - 167 -- sub batch step 669 -- lr 2.50e-05
2025-03-02 10:37:12,000 - INFO - ðŸªœ Batch step - 167 -- sub batch step 670 -- lr 2.50e-05
2025-03-02 10:37:14,631 - INFO - ðŸªœ Batch step - 167 -- sub batch step 671 -- lr 2.50e-05
2025-03-02 10:37:16,239 - INFO - Step 167 -- ðŸ”„ Training Metrics
2025-03-02 10:37:16,239 - INFO - â”œâ”€â”€ Loss: 10.9546
2025-03-02 10:37:16,239 - INFO - â”œâ”€â”€ Learning Rate: 2.50e-05
2025-03-02 10:37:16,239 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:37:16,918 - INFO - ðŸªœ Batch step - 168 -- sub batch step 672 -- lr 2.52e-05
2025-03-02 10:37:19,079 - INFO - ðŸªœ Batch step - 168 -- sub batch step 673 -- lr 2.52e-05
2025-03-02 10:37:21,236 - INFO - ðŸªœ Batch step - 168 -- sub batch step 674 -- lr 2.52e-05
2025-03-02 10:37:23,413 - INFO - ðŸªœ Batch step - 168 -- sub batch step 675 -- lr 2.52e-05
2025-03-02 10:37:24,974 - INFO - Step 168 -- ðŸ”„ Training Metrics
2025-03-02 10:37:24,974 - INFO - â”œâ”€â”€ Loss: 10.9541
2025-03-02 10:37:24,974 - INFO - â”œâ”€â”€ Learning Rate: 2.52e-05
2025-03-02 10:37:24,974 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:37:25,642 - INFO - ðŸªœ Batch step - 169 -- sub batch step 676 -- lr 2.53e-05
2025-03-02 10:37:27,800 - INFO - ðŸªœ Batch step - 169 -- sub batch step 677 -- lr 2.53e-05
2025-03-02 10:37:29,954 - INFO - ðŸªœ Batch step - 169 -- sub batch step 678 -- lr 2.53e-05
2025-03-02 10:37:32,628 - INFO - ðŸªœ Batch step - 169 -- sub batch step 679 -- lr 2.53e-05
2025-03-02 10:37:34,193 - INFO - Step 169 -- ðŸ”„ Training Metrics
2025-03-02 10:37:34,193 - INFO - â”œâ”€â”€ Loss: 10.9542
2025-03-02 10:37:34,193 - INFO - â”œâ”€â”€ Learning Rate: 2.53e-05
2025-03-02 10:37:34,193 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:37:34,866 - INFO - ðŸªœ Batch step - 170 -- sub batch step 680 -- lr 2.55e-05
2025-03-02 10:37:37,020 - INFO - ðŸªœ Batch step - 170 -- sub batch step 681 -- lr 2.55e-05
2025-03-02 10:37:39,178 - INFO - ðŸªœ Batch step - 170 -- sub batch step 682 -- lr 2.55e-05
2025-03-02 10:37:41,348 - INFO - ðŸªœ Batch step - 170 -- sub batch step 683 -- lr 2.55e-05
2025-03-02 10:37:42,919 - INFO - Step 170 -- ðŸ”„ Training Metrics
2025-03-02 10:37:42,919 - INFO - â”œâ”€â”€ Loss: 10.9518
2025-03-02 10:37:42,920 - INFO - â”œâ”€â”€ Learning Rate: 2.55e-05
2025-03-02 10:37:42,920 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:37:43,593 - INFO - ðŸªœ Batch step - 171 -- sub batch step 684 -- lr 2.57e-05
2025-03-02 10:37:45,746 - INFO - ðŸªœ Batch step - 171 -- sub batch step 685 -- lr 2.57e-05
2025-03-02 10:37:48,189 - INFO - ðŸªœ Batch step - 171 -- sub batch step 686 -- lr 2.57e-05
2025-03-02 10:37:50,348 - INFO - ðŸªœ Batch step - 171 -- sub batch step 687 -- lr 2.57e-05
2025-03-02 10:37:52,124 - INFO - Step 171 -- ðŸ”„ Training Metrics
2025-03-02 10:37:52,125 - INFO - â”œâ”€â”€ Loss: 10.9521
2025-03-02 10:37:52,125 - INFO - â”œâ”€â”€ Learning Rate: 2.57e-05
2025-03-02 10:37:52,125 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:37:52,789 - INFO - ðŸªœ Batch step - 172 -- sub batch step 688 -- lr 2.58e-05
2025-03-02 10:37:54,947 - INFO - ðŸªœ Batch step - 172 -- sub batch step 689 -- lr 2.58e-05
2025-03-02 10:37:57,127 - INFO - ðŸªœ Batch step - 172 -- sub batch step 690 -- lr 2.58e-05
2025-03-02 10:37:59,282 - INFO - ðŸªœ Batch step - 172 -- sub batch step 691 -- lr 2.58e-05
2025-03-02 10:38:00,855 - INFO - Step 172 -- ðŸ”„ Training Metrics
2025-03-02 10:38:00,856 - INFO - â”œâ”€â”€ Loss: 10.9520
2025-03-02 10:38:00,856 - INFO - â”œâ”€â”€ Learning Rate: 2.58e-05
2025-03-02 10:38:00,856 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:38:01,535 - INFO - ðŸªœ Batch step - 173 -- sub batch step 692 -- lr 2.59e-05
2025-03-02 10:38:03,688 - INFO - ðŸªœ Batch step - 173 -- sub batch step 693 -- lr 2.59e-05
2025-03-02 10:38:06,064 - INFO - ðŸªœ Batch step - 173 -- sub batch step 694 -- lr 2.59e-05
2025-03-02 10:38:08,222 - INFO - ðŸªœ Batch step - 173 -- sub batch step 695 -- lr 2.59e-05
2025-03-02 10:38:10,242 - INFO - Step 173 -- ðŸ”„ Training Metrics
2025-03-02 10:38:10,242 - INFO - â”œâ”€â”€ Loss: 10.9518
2025-03-02 10:38:10,242 - INFO - â”œâ”€â”€ Learning Rate: 2.59e-05
2025-03-02 10:38:10,242 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:38:10,911 - INFO - ðŸªœ Batch step - 174 -- sub batch step 696 -- lr 2.61e-05
2025-03-02 10:38:13,072 - INFO - ðŸªœ Batch step - 174 -- sub batch step 697 -- lr 2.61e-05
2025-03-02 10:38:15,245 - INFO - ðŸªœ Batch step - 174 -- sub batch step 698 -- lr 2.61e-05
2025-03-02 10:38:17,406 - INFO - ðŸªœ Batch step - 174 -- sub batch step 699 -- lr 2.61e-05
2025-03-02 10:38:18,974 - INFO - Step 174 -- ðŸ”„ Training Metrics
2025-03-02 10:38:18,974 - INFO - â”œâ”€â”€ Loss: 10.9504
2025-03-02 10:38:18,974 - INFO - â”œâ”€â”€ Learning Rate: 2.61e-05
2025-03-02 10:38:18,974 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:38:19,649 - INFO - ðŸªœ Batch step - 175 -- sub batch step 700 -- lr 2.62e-05
2025-03-02 10:38:21,797 - INFO - ðŸªœ Batch step - 175 -- sub batch step 701 -- lr 2.62e-05
2025-03-02 10:38:24,172 - INFO - ðŸªœ Batch step - 175 -- sub batch step 702 -- lr 2.62e-05
2025-03-02 10:38:26,326 - INFO - ðŸªœ Batch step - 175 -- sub batch step 703 -- lr 2.62e-05
2025-03-02 10:38:28,210 - INFO - Step 175 -- ðŸ”„ Training Metrics
2025-03-02 10:38:28,210 - INFO - â”œâ”€â”€ Loss: 10.9481
2025-03-02 10:38:28,211 - INFO - â”œâ”€â”€ Learning Rate: 2.62e-05
2025-03-02 10:38:28,211 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:38:28,886 - INFO - ðŸªœ Batch step - 176 -- sub batch step 704 -- lr 2.64e-05
2025-03-02 10:38:31,036 - INFO - ðŸªœ Batch step - 176 -- sub batch step 705 -- lr 2.64e-05
2025-03-02 10:38:33,204 - INFO - ðŸªœ Batch step - 176 -- sub batch step 706 -- lr 2.64e-05
2025-03-02 10:38:35,361 - INFO - ðŸªœ Batch step - 176 -- sub batch step 707 -- lr 2.64e-05
2025-03-02 10:38:36,938 - INFO - Step 176 -- ðŸ”„ Training Metrics
2025-03-02 10:38:36,939 - INFO - â”œâ”€â”€ Loss: 10.9482
2025-03-02 10:38:36,939 - INFO - â”œâ”€â”€ Learning Rate: 2.64e-05
2025-03-02 10:38:36,939 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:38:37,604 - INFO - ðŸªœ Batch step - 177 -- sub batch step 708 -- lr 2.65e-05
2025-03-02 10:38:39,763 - INFO - ðŸªœ Batch step - 177 -- sub batch step 709 -- lr 2.65e-05
2025-03-02 10:38:42,119 - INFO - ðŸªœ Batch step - 177 -- sub batch step 710 -- lr 2.65e-05
2025-03-02 10:38:44,271 - INFO - ðŸªœ Batch step - 177 -- sub batch step 711 -- lr 2.65e-05
2025-03-02 10:38:46,223 - INFO - Step 177 -- ðŸ”„ Training Metrics
2025-03-02 10:38:46,224 - INFO - â”œâ”€â”€ Loss: 10.9475
2025-03-02 10:38:46,224 - INFO - â”œâ”€â”€ Learning Rate: 2.65e-05
2025-03-02 10:38:46,224 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:38:46,898 - INFO - ðŸªœ Batch step - 178 -- sub batch step 712 -- lr 2.67e-05
2025-03-02 10:38:49,048 - INFO - ðŸªœ Batch step - 178 -- sub batch step 713 -- lr 2.67e-05
2025-03-02 10:38:51,225 - INFO - ðŸªœ Batch step - 178 -- sub batch step 714 -- lr 2.67e-05
2025-03-02 10:38:53,383 - INFO - ðŸªœ Batch step - 178 -- sub batch step 715 -- lr 2.67e-05
2025-03-02 10:38:54,955 - INFO - Step 178 -- ðŸ”„ Training Metrics
2025-03-02 10:38:54,955 - INFO - â”œâ”€â”€ Loss: 10.9464
2025-03-02 10:38:54,955 - INFO - â”œâ”€â”€ Learning Rate: 2.67e-05
2025-03-02 10:38:54,955 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:38:55,620 - INFO - ðŸªœ Batch step - 179 -- sub batch step 716 -- lr 2.68e-05
2025-03-02 10:38:57,777 - INFO - ðŸªœ Batch step - 179 -- sub batch step 717 -- lr 2.68e-05
2025-03-02 10:39:00,131 - INFO - ðŸªœ Batch step - 179 -- sub batch step 718 -- lr 2.68e-05
2025-03-02 10:39:02,288 - INFO - ðŸªœ Batch step - 179 -- sub batch step 719 -- lr 2.68e-05
2025-03-02 10:39:03,877 - INFO - Step 179 -- ðŸ”„ Training Metrics
2025-03-02 10:39:03,877 - INFO - â”œâ”€â”€ Loss: 10.9471
2025-03-02 10:39:03,878 - INFO - â”œâ”€â”€ Learning Rate: 2.68e-05
2025-03-02 10:39:03,878 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:39:05,102 - INFO - ðŸªœ Batch step - 180 -- sub batch step 720 -- lr 2.70e-05
2025-03-02 10:39:07,260 - INFO - ðŸªœ Batch step - 180 -- sub batch step 721 -- lr 2.70e-05
2025-03-02 10:39:09,429 - INFO - ðŸªœ Batch step - 180 -- sub batch step 722 -- lr 2.70e-05
2025-03-02 10:39:11,613 - INFO - ðŸªœ Batch step - 180 -- sub batch step 723 -- lr 2.70e-05
2025-03-02 10:39:13,280 - INFO - Step 180 -- ðŸ”„ Training Metrics
2025-03-02 10:39:13,280 - INFO - â”œâ”€â”€ Loss: 10.9486
2025-03-02 10:39:13,280 - INFO - â”œâ”€â”€ Learning Rate: 2.70e-05
2025-03-02 10:39:13,280 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:39:13,962 - INFO - ðŸªœ Batch step - 181 -- sub batch step 724 -- lr 2.71e-05
2025-03-02 10:39:16,126 - INFO - ðŸªœ Batch step - 181 -- sub batch step 725 -- lr 2.71e-05
2025-03-02 10:39:18,280 - INFO - ðŸªœ Batch step - 181 -- sub batch step 726 -- lr 2.71e-05
2025-03-02 10:39:21,094 - INFO - ðŸªœ Batch step - 181 -- sub batch step 727 -- lr 2.71e-05
2025-03-02 10:39:22,591 - INFO - Step 181 -- ðŸ”„ Training Metrics
2025-03-02 10:39:22,591 - INFO - â”œâ”€â”€ Loss: 10.9467
2025-03-02 10:39:22,592 - INFO - â”œâ”€â”€ Learning Rate: 2.71e-05
2025-03-02 10:39:22,592 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:39:23,261 - INFO - ðŸªœ Batch step - 182 -- sub batch step 728 -- lr 2.73e-05
2025-03-02 10:39:25,419 - INFO - ðŸªœ Batch step - 182 -- sub batch step 729 -- lr 2.73e-05
2025-03-02 10:39:27,577 - INFO - ðŸªœ Batch step - 182 -- sub batch step 730 -- lr 2.73e-05
2025-03-02 10:39:29,750 - INFO - ðŸªœ Batch step - 182 -- sub batch step 731 -- lr 2.73e-05
2025-03-02 10:39:31,338 - INFO - Step 182 -- ðŸ”„ Training Metrics
2025-03-02 10:39:31,338 - INFO - â”œâ”€â”€ Loss: 10.9457
2025-03-02 10:39:31,338 - INFO - â”œâ”€â”€ Learning Rate: 2.73e-05
2025-03-02 10:39:31,338 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:39:32,011 - INFO - ðŸªœ Batch step - 183 -- sub batch step 732 -- lr 2.74e-05
2025-03-02 10:39:34,164 - INFO - ðŸªœ Batch step - 183 -- sub batch step 733 -- lr 2.74e-05
2025-03-02 10:39:36,319 - INFO - ðŸªœ Batch step - 183 -- sub batch step 734 -- lr 2.74e-05
2025-03-02 10:39:39,028 - INFO - ðŸªœ Batch step - 183 -- sub batch step 735 -- lr 2.74e-05
2025-03-02 10:39:40,642 - INFO - Step 183 -- ðŸ”„ Training Metrics
2025-03-02 10:39:40,642 - INFO - â”œâ”€â”€ Loss: 10.9452
2025-03-02 10:39:40,642 - INFO - â”œâ”€â”€ Learning Rate: 2.74e-05
2025-03-02 10:39:40,642 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:39:41,310 - INFO - ðŸªœ Batch step - 184 -- sub batch step 736 -- lr 2.76e-05
2025-03-02 10:39:43,470 - INFO - ðŸªœ Batch step - 184 -- sub batch step 737 -- lr 2.76e-05
2025-03-02 10:39:45,624 - INFO - ðŸªœ Batch step - 184 -- sub batch step 738 -- lr 2.76e-05
2025-03-02 10:39:47,802 - INFO - ðŸªœ Batch step - 184 -- sub batch step 739 -- lr 2.76e-05
2025-03-02 10:39:49,379 - INFO - Step 184 -- ðŸ”„ Training Metrics
2025-03-02 10:39:49,380 - INFO - â”œâ”€â”€ Loss: 10.9451
2025-03-02 10:39:49,380 - INFO - â”œâ”€â”€ Learning Rate: 2.76e-05
2025-03-02 10:39:49,380 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:39:50,063 - INFO - ðŸªœ Batch step - 185 -- sub batch step 740 -- lr 2.77e-05
2025-03-02 10:39:52,218 - INFO - ðŸªœ Batch step - 185 -- sub batch step 741 -- lr 2.77e-05
2025-03-02 10:39:54,378 - INFO - ðŸªœ Batch step - 185 -- sub batch step 742 -- lr 2.77e-05
2025-03-02 10:39:57,042 - INFO - ðŸªœ Batch step - 185 -- sub batch step 743 -- lr 2.77e-05
2025-03-02 10:39:58,684 - INFO - Step 185 -- ðŸ”„ Training Metrics
2025-03-02 10:39:58,685 - INFO - â”œâ”€â”€ Loss: 10.9458
2025-03-02 10:39:58,685 - INFO - â”œâ”€â”€ Learning Rate: 2.77e-05
2025-03-02 10:39:58,685 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:39:59,362 - INFO - ðŸªœ Batch step - 186 -- sub batch step 744 -- lr 2.79e-05
2025-03-02 10:40:01,520 - INFO - ðŸªœ Batch step - 186 -- sub batch step 745 -- lr 2.79e-05
2025-03-02 10:40:03,676 - INFO - ðŸªœ Batch step - 186 -- sub batch step 746 -- lr 2.79e-05
2025-03-02 10:40:05,854 - INFO - ðŸªœ Batch step - 186 -- sub batch step 747 -- lr 2.79e-05
2025-03-02 10:40:07,429 - INFO - Step 186 -- ðŸ”„ Training Metrics
2025-03-02 10:40:07,429 - INFO - â”œâ”€â”€ Loss: 10.9438
2025-03-02 10:40:07,429 - INFO - â”œâ”€â”€ Learning Rate: 2.79e-05
2025-03-02 10:40:07,429 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:40:08,097 - INFO - ðŸªœ Batch step - 187 -- sub batch step 748 -- lr 2.80e-05
2025-03-02 10:40:10,254 - INFO - ðŸªœ Batch step - 187 -- sub batch step 749 -- lr 2.80e-05
2025-03-02 10:40:12,412 - INFO - ðŸªœ Batch step - 187 -- sub batch step 750 -- lr 2.80e-05
2025-03-02 10:40:14,790 - INFO - ðŸªœ Batch step - 187 -- sub batch step 751 -- lr 2.80e-05
2025-03-02 10:40:16,808 - INFO - Step 187 -- ðŸ”„ Training Metrics
2025-03-02 10:40:16,808 - INFO - â”œâ”€â”€ Loss: 10.9429
2025-03-02 10:40:16,808 - INFO - â”œâ”€â”€ Learning Rate: 2.80e-05
2025-03-02 10:40:16,808 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:40:17,484 - INFO - ðŸªœ Batch step - 188 -- sub batch step 752 -- lr 2.82e-05
2025-03-02 10:40:19,641 - INFO - ðŸªœ Batch step - 188 -- sub batch step 753 -- lr 2.82e-05
2025-03-02 10:40:21,803 - INFO - ðŸªœ Batch step - 188 -- sub batch step 754 -- lr 2.82e-05
2025-03-02 10:40:23,986 - INFO - ðŸªœ Batch step - 188 -- sub batch step 755 -- lr 2.82e-05
2025-03-02 10:40:25,550 - INFO - Step 188 -- ðŸ”„ Training Metrics
2025-03-02 10:40:25,550 - INFO - â”œâ”€â”€ Loss: 10.9419
2025-03-02 10:40:25,551 - INFO - â”œâ”€â”€ Learning Rate: 2.82e-05
2025-03-02 10:40:25,551 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:40:26,220 - INFO - ðŸªœ Batch step - 189 -- sub batch step 756 -- lr 2.83e-05
2025-03-02 10:40:28,385 - INFO - ðŸªœ Batch step - 189 -- sub batch step 757 -- lr 2.83e-05
2025-03-02 10:40:30,545 - INFO - ðŸªœ Batch step - 189 -- sub batch step 758 -- lr 2.83e-05
2025-03-02 10:40:33,275 - INFO - ðŸªœ Batch step - 189 -- sub batch step 759 -- lr 2.83e-05
2025-03-02 10:40:35,576 - INFO - Step 189 -- ðŸ”„ Training Metrics
2025-03-02 10:40:35,577 - INFO - â”œâ”€â”€ Loss: 10.9424
2025-03-02 10:40:35,577 - INFO - â”œâ”€â”€ Learning Rate: 2.83e-05
2025-03-02 10:40:35,577 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:40:36,249 - INFO - ðŸªœ Batch step - 190 -- sub batch step 760 -- lr 2.85e-05
2025-03-02 10:40:38,403 - INFO - ðŸªœ Batch step - 190 -- sub batch step 761 -- lr 2.85e-05
2025-03-02 10:40:40,563 - INFO - ðŸªœ Batch step - 190 -- sub batch step 762 -- lr 2.85e-05
2025-03-02 10:40:42,741 - INFO - ðŸªœ Batch step - 190 -- sub batch step 763 -- lr 2.85e-05
2025-03-02 10:40:44,308 - INFO - Step 190 -- ðŸ”„ Training Metrics
2025-03-02 10:40:44,308 - INFO - â”œâ”€â”€ Loss: 10.9414
2025-03-02 10:40:44,308 - INFO - â”œâ”€â”€ Learning Rate: 2.85e-05
2025-03-02 10:40:44,309 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:40:44,987 - INFO - ðŸªœ Batch step - 191 -- sub batch step 764 -- lr 2.86e-05
2025-03-02 10:40:47,147 - INFO - ðŸªœ Batch step - 191 -- sub batch step 765 -- lr 2.86e-05
2025-03-02 10:40:49,871 - INFO - ðŸªœ Batch step - 191 -- sub batch step 766 -- lr 2.86e-05
2025-03-02 10:40:52,030 - INFO - ðŸªœ Batch step - 191 -- sub batch step 767 -- lr 2.86e-05
2025-03-02 10:40:53,578 - INFO - Step 191 -- ðŸ”„ Training Metrics
2025-03-02 10:40:53,578 - INFO - â”œâ”€â”€ Loss: 10.9402
2025-03-02 10:40:53,578 - INFO - â”œâ”€â”€ Learning Rate: 2.86e-05
2025-03-02 10:40:53,578 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:40:54,252 - INFO - ðŸªœ Batch step - 192 -- sub batch step 768 -- lr 2.88e-05
2025-03-02 10:40:56,422 - INFO - ðŸªœ Batch step - 192 -- sub batch step 769 -- lr 2.88e-05
2025-03-02 10:40:58,610 - INFO - ðŸªœ Batch step - 192 -- sub batch step 770 -- lr 2.88e-05
2025-03-02 10:41:00,766 - INFO - ðŸªœ Batch step - 192 -- sub batch step 771 -- lr 2.88e-05
2025-03-02 10:41:02,311 - INFO - Step 192 -- ðŸ”„ Training Metrics
2025-03-02 10:41:02,312 - INFO - â”œâ”€â”€ Loss: 10.9399
2025-03-02 10:41:02,312 - INFO - â”œâ”€â”€ Learning Rate: 2.88e-05
2025-03-02 10:41:02,312 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:41:02,993 - INFO - ðŸªœ Batch step - 193 -- sub batch step 772 -- lr 2.89e-05
2025-03-02 10:41:05,153 - INFO - ðŸªœ Batch step - 193 -- sub batch step 773 -- lr 2.89e-05
2025-03-02 10:41:07,544 - INFO - ðŸªœ Batch step - 193 -- sub batch step 774 -- lr 2.89e-05
2025-03-02 10:41:09,706 - INFO - ðŸªœ Batch step - 193 -- sub batch step 775 -- lr 2.89e-05
2025-03-02 10:41:11,648 - INFO - Step 193 -- ðŸ”„ Training Metrics
2025-03-02 10:41:11,648 - INFO - â”œâ”€â”€ Loss: 10.9385
2025-03-02 10:41:11,648 - INFO - â”œâ”€â”€ Learning Rate: 2.89e-05
2025-03-02 10:41:11,648 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:41:12,319 - INFO - ðŸªœ Batch step - 194 -- sub batch step 776 -- lr 2.91e-05
2025-03-02 10:41:14,478 - INFO - ðŸªœ Batch step - 194 -- sub batch step 777 -- lr 2.91e-05
2025-03-02 10:41:16,652 - INFO - ðŸªœ Batch step - 194 -- sub batch step 778 -- lr 2.91e-05
2025-03-02 10:41:18,816 - INFO - ðŸªœ Batch step - 194 -- sub batch step 779 -- lr 2.91e-05
2025-03-02 10:41:20,385 - INFO - Step 194 -- ðŸ”„ Training Metrics
2025-03-02 10:41:20,385 - INFO - â”œâ”€â”€ Loss: 10.9381
2025-03-02 10:41:20,385 - INFO - â”œâ”€â”€ Learning Rate: 2.91e-05
2025-03-02 10:41:20,386 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:41:21,062 - INFO - ðŸªœ Batch step - 195 -- sub batch step 780 -- lr 2.92e-05
2025-03-02 10:41:23,215 - INFO - ðŸªœ Batch step - 195 -- sub batch step 781 -- lr 2.92e-05
2025-03-02 10:41:25,592 - INFO - ðŸªœ Batch step - 195 -- sub batch step 782 -- lr 2.92e-05
2025-03-02 10:41:27,749 - INFO - ðŸªœ Batch step - 195 -- sub batch step 783 -- lr 2.92e-05
2025-03-02 10:41:29,583 - INFO - Step 195 -- ðŸ”„ Training Metrics
2025-03-02 10:41:29,583 - INFO - â”œâ”€â”€ Loss: 10.9383
2025-03-02 10:41:29,583 - INFO - â”œâ”€â”€ Learning Rate: 2.92e-05
2025-03-02 10:41:29,583 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:41:30,261 - INFO - ðŸªœ Batch step - 196 -- sub batch step 784 -- lr 2.94e-05
2025-03-02 10:41:32,431 - INFO - ðŸªœ Batch step - 196 -- sub batch step 785 -- lr 2.94e-05
2025-03-02 10:41:34,600 - INFO - ðŸªœ Batch step - 196 -- sub batch step 786 -- lr 2.94e-05
2025-03-02 10:41:36,757 - INFO - ðŸªœ Batch step - 196 -- sub batch step 787 -- lr 2.94e-05
2025-03-02 10:41:38,315 - INFO - Step 196 -- ðŸ”„ Training Metrics
2025-03-02 10:41:38,315 - INFO - â”œâ”€â”€ Loss: 10.9380
2025-03-02 10:41:38,315 - INFO - â”œâ”€â”€ Learning Rate: 2.94e-05
2025-03-02 10:41:38,315 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:41:38,986 - INFO - ðŸªœ Batch step - 197 -- sub batch step 788 -- lr 2.95e-05
2025-03-02 10:41:41,145 - INFO - ðŸªœ Batch step - 197 -- sub batch step 789 -- lr 2.95e-05
2025-03-02 10:41:43,840 - INFO - ðŸªœ Batch step - 197 -- sub batch step 790 -- lr 2.95e-05
2025-03-02 10:41:45,997 - INFO - ðŸªœ Batch step - 197 -- sub batch step 791 -- lr 2.95e-05
2025-03-02 10:41:47,510 - INFO - Step 197 -- ðŸ”„ Training Metrics
2025-03-02 10:41:47,510 - INFO - â”œâ”€â”€ Loss: 10.9362
2025-03-02 10:41:47,510 - INFO - â”œâ”€â”€ Learning Rate: 2.95e-05
2025-03-02 10:41:47,510 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:41:48,181 - INFO - ðŸªœ Batch step - 198 -- sub batch step 792 -- lr 2.97e-05
2025-03-02 10:41:50,339 - INFO - ðŸªœ Batch step - 198 -- sub batch step 793 -- lr 2.97e-05
2025-03-02 10:41:52,521 - INFO - ðŸªœ Batch step - 198 -- sub batch step 794 -- lr 2.97e-05
2025-03-02 10:41:54,682 - INFO - ðŸªœ Batch step - 198 -- sub batch step 795 -- lr 2.97e-05
2025-03-02 10:41:56,245 - INFO - Step 198 -- ðŸ”„ Training Metrics
2025-03-02 10:41:56,245 - INFO - â”œâ”€â”€ Loss: 10.9358
2025-03-02 10:41:56,246 - INFO - â”œâ”€â”€ Learning Rate: 2.97e-05
2025-03-02 10:41:56,246 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:41:56,916 - INFO - ðŸªœ Batch step - 199 -- sub batch step 796 -- lr 2.99e-05
2025-03-02 10:41:59,076 - INFO - ðŸªœ Batch step - 199 -- sub batch step 797 -- lr 2.99e-05
2025-03-02 10:42:01,482 - INFO - ðŸªœ Batch step - 199 -- sub batch step 798 -- lr 2.99e-05
2025-03-02 10:42:03,641 - INFO - ðŸªœ Batch step - 199 -- sub batch step 799 -- lr 2.99e-05
2025-03-02 10:42:05,128 - INFO - Step 199 -- ðŸ”„ Training Metrics
2025-03-02 10:42:05,128 - INFO - â”œâ”€â”€ Loss: 10.9353
2025-03-02 10:42:05,128 - INFO - â”œâ”€â”€ Learning Rate: 2.99e-05
2025-03-02 10:42:05,128 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:42:06,259 - INFO - ðŸªœ Batch step - 200 -- sub batch step 800 -- lr 3.00e-05
2025-03-02 10:42:08,412 - INFO - ðŸªœ Batch step - 200 -- sub batch step 801 -- lr 3.00e-05
2025-03-02 10:42:10,573 - INFO - ðŸªœ Batch step - 200 -- sub batch step 802 -- lr 3.00e-05
2025-03-02 10:42:12,746 - INFO - ðŸªœ Batch step - 200 -- sub batch step 803 -- lr 3.00e-05
2025-03-02 10:42:14,487 - INFO - Step 200 -- ðŸ”„ Training Metrics
2025-03-02 10:42:14,487 - INFO - â”œâ”€â”€ Loss: 10.9352
2025-03-02 10:42:14,487 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-05
2025-03-02 10:42:14,487 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:42:15,161 - INFO - ðŸªœ Batch step - 201 -- sub batch step 804 -- lr 3.01e-05
2025-03-02 10:42:17,320 - INFO - ðŸªœ Batch step - 201 -- sub batch step 805 -- lr 3.01e-05
2025-03-02 10:42:19,474 - INFO - ðŸªœ Batch step - 201 -- sub batch step 806 -- lr 3.01e-05
2025-03-02 10:42:21,894 - INFO - ðŸªœ Batch step - 201 -- sub batch step 807 -- lr 3.01e-05
2025-03-02 10:42:23,776 - INFO - Step 201 -- ðŸ”„ Training Metrics
2025-03-02 10:42:23,776 - INFO - â”œâ”€â”€ Loss: 10.9360
2025-03-02 10:42:23,776 - INFO - â”œâ”€â”€ Learning Rate: 3.01e-05
2025-03-02 10:42:23,776 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:42:24,447 - INFO - ðŸªœ Batch step - 202 -- sub batch step 808 -- lr 3.03e-05
2025-03-02 10:42:26,610 - INFO - ðŸªœ Batch step - 202 -- sub batch step 809 -- lr 3.03e-05
2025-03-02 10:42:28,770 - INFO - ðŸªœ Batch step - 202 -- sub batch step 810 -- lr 3.03e-05
2025-03-02 10:42:30,945 - INFO - ðŸªœ Batch step - 202 -- sub batch step 811 -- lr 3.03e-05
2025-03-02 10:42:32,515 - INFO - Step 202 -- ðŸ”„ Training Metrics
2025-03-02 10:42:32,515 - INFO - â”œâ”€â”€ Loss: 10.9354
2025-03-02 10:42:32,516 - INFO - â”œâ”€â”€ Learning Rate: 3.03e-05
2025-03-02 10:42:32,516 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:42:33,187 - INFO - ðŸªœ Batch step - 203 -- sub batch step 812 -- lr 3.04e-05
2025-03-02 10:42:35,342 - INFO - ðŸªœ Batch step - 203 -- sub batch step 813 -- lr 3.04e-05
2025-03-02 10:42:37,501 - INFO - ðŸªœ Batch step - 203 -- sub batch step 814 -- lr 3.04e-05
2025-03-02 10:42:40,239 - INFO - ðŸªœ Batch step - 203 -- sub batch step 815 -- lr 3.04e-05
2025-03-02 10:42:41,726 - INFO - Step 203 -- ðŸ”„ Training Metrics
2025-03-02 10:42:41,727 - INFO - â”œâ”€â”€ Loss: 10.9339
2025-03-02 10:42:41,727 - INFO - â”œâ”€â”€ Learning Rate: 3.04e-05
2025-03-02 10:42:41,727 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:42:42,399 - INFO - ðŸªœ Batch step - 204 -- sub batch step 816 -- lr 3.06e-05
2025-03-02 10:42:44,556 - INFO - ðŸªœ Batch step - 204 -- sub batch step 817 -- lr 3.06e-05
2025-03-02 10:42:46,717 - INFO - ðŸªœ Batch step - 204 -- sub batch step 818 -- lr 3.06e-05
2025-03-02 10:42:48,904 - INFO - ðŸªœ Batch step - 204 -- sub batch step 819 -- lr 3.06e-05
2025-03-02 10:42:50,456 - INFO - Step 204 -- ðŸ”„ Training Metrics
2025-03-02 10:42:50,456 - INFO - â”œâ”€â”€ Loss: 10.9347
2025-03-02 10:42:50,456 - INFO - â”œâ”€â”€ Learning Rate: 3.06e-05
2025-03-02 10:42:50,456 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:42:51,132 - INFO - ðŸªœ Batch step - 205 -- sub batch step 820 -- lr 3.07e-05
2025-03-02 10:42:53,287 - INFO - ðŸªœ Batch step - 205 -- sub batch step 821 -- lr 3.07e-05
2025-03-02 10:42:55,450 - INFO - ðŸªœ Batch step - 205 -- sub batch step 822 -- lr 3.07e-05
2025-03-02 10:42:58,088 - INFO - ðŸªœ Batch step - 205 -- sub batch step 823 -- lr 3.07e-05
2025-03-02 10:42:59,727 - INFO - Step 205 -- ðŸ”„ Training Metrics
2025-03-02 10:42:59,727 - INFO - â”œâ”€â”€ Loss: 10.9325
2025-03-02 10:42:59,727 - INFO - â”œâ”€â”€ Learning Rate: 3.07e-05
2025-03-02 10:42:59,727 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:43:00,404 - INFO - ðŸªœ Batch step - 206 -- sub batch step 824 -- lr 3.09e-05
2025-03-02 10:43:02,560 - INFO - ðŸªœ Batch step - 206 -- sub batch step 825 -- lr 3.09e-05
2025-03-02 10:43:04,719 - INFO - ðŸªœ Batch step - 206 -- sub batch step 826 -- lr 3.09e-05
2025-03-02 10:43:06,901 - INFO - ðŸªœ Batch step - 206 -- sub batch step 827 -- lr 3.09e-05
2025-03-02 10:43:08,470 - INFO - Step 206 -- ðŸ”„ Training Metrics
2025-03-02 10:43:08,470 - INFO - â”œâ”€â”€ Loss: 10.9323
2025-03-02 10:43:08,470 - INFO - â”œâ”€â”€ Learning Rate: 3.09e-05
2025-03-02 10:43:08,470 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:43:09,138 - INFO - ðŸªœ Batch step - 207 -- sub batch step 828 -- lr 3.10e-05
2025-03-02 10:43:11,295 - INFO - ðŸªœ Batch step - 207 -- sub batch step 829 -- lr 3.10e-05
2025-03-02 10:43:13,454 - INFO - ðŸªœ Batch step - 207 -- sub batch step 830 -- lr 3.10e-05
2025-03-02 10:43:16,093 - INFO - ðŸªœ Batch step - 207 -- sub batch step 831 -- lr 3.10e-05
2025-03-02 10:43:17,775 - INFO - Step 207 -- ðŸ”„ Training Metrics
2025-03-02 10:43:17,775 - INFO - â”œâ”€â”€ Loss: 10.9307
2025-03-02 10:43:17,776 - INFO - â”œâ”€â”€ Learning Rate: 3.10e-05
2025-03-02 10:43:17,776 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:43:18,452 - INFO - ðŸªœ Batch step - 208 -- sub batch step 832 -- lr 3.12e-05
2025-03-02 10:43:20,608 - INFO - ðŸªœ Batch step - 208 -- sub batch step 833 -- lr 3.12e-05
2025-03-02 10:43:22,768 - INFO - ðŸªœ Batch step - 208 -- sub batch step 834 -- lr 3.12e-05
2025-03-02 10:43:24,946 - INFO - ðŸªœ Batch step - 208 -- sub batch step 835 -- lr 3.12e-05
2025-03-02 10:43:26,521 - INFO - Step 208 -- ðŸ”„ Training Metrics
2025-03-02 10:43:26,522 - INFO - â”œâ”€â”€ Loss: 10.9312
2025-03-02 10:43:26,522 - INFO - â”œâ”€â”€ Learning Rate: 3.12e-05
2025-03-02 10:43:26,522 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:43:27,188 - INFO - ðŸªœ Batch step - 209 -- sub batch step 836 -- lr 3.13e-05
2025-03-02 10:43:29,350 - INFO - ðŸªœ Batch step - 209 -- sub batch step 837 -- lr 3.13e-05
2025-03-02 10:43:31,504 - INFO - ðŸªœ Batch step - 209 -- sub batch step 838 -- lr 3.13e-05
2025-03-02 10:43:34,227 - INFO - ðŸªœ Batch step - 209 -- sub batch step 839 -- lr 3.13e-05
2025-03-02 10:43:35,713 - INFO - Step 209 -- ðŸ”„ Training Metrics
2025-03-02 10:43:35,714 - INFO - â”œâ”€â”€ Loss: 10.9286
2025-03-02 10:43:35,714 - INFO - â”œâ”€â”€ Learning Rate: 3.13e-05
2025-03-02 10:43:35,714 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:43:36,386 - INFO - ðŸªœ Batch step - 210 -- sub batch step 840 -- lr 3.15e-05
2025-03-02 10:43:38,544 - INFO - ðŸªœ Batch step - 210 -- sub batch step 841 -- lr 3.15e-05
2025-03-02 10:43:40,702 - INFO - ðŸªœ Batch step - 210 -- sub batch step 842 -- lr 3.15e-05
2025-03-02 10:43:42,873 - INFO - ðŸªœ Batch step - 210 -- sub batch step 843 -- lr 3.15e-05
2025-03-02 10:43:44,436 - INFO - Step 210 -- ðŸ”„ Training Metrics
2025-03-02 10:43:44,437 - INFO - â”œâ”€â”€ Loss: 10.9281
2025-03-02 10:43:44,437 - INFO - â”œâ”€â”€ Learning Rate: 3.15e-05
2025-03-02 10:43:44,437 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:43:45,111 - INFO - ðŸªœ Batch step - 211 -- sub batch step 844 -- lr 3.16e-05
2025-03-02 10:43:47,266 - INFO - ðŸªœ Batch step - 211 -- sub batch step 845 -- lr 3.16e-05
2025-03-02 10:43:49,948 - INFO - ðŸªœ Batch step - 211 -- sub batch step 846 -- lr 3.16e-05
2025-03-02 10:43:52,105 - INFO - ðŸªœ Batch step - 211 -- sub batch step 847 -- lr 3.16e-05
2025-03-02 10:43:53,622 - INFO - Step 211 -- ðŸ”„ Training Metrics
2025-03-02 10:43:53,622 - INFO - â”œâ”€â”€ Loss: 10.9279
2025-03-02 10:43:53,622 - INFO - â”œâ”€â”€ Learning Rate: 3.16e-05
2025-03-02 10:43:53,622 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:43:54,289 - INFO - ðŸªœ Batch step - 212 -- sub batch step 848 -- lr 3.18e-05
2025-03-02 10:43:56,444 - INFO - ðŸªœ Batch step - 212 -- sub batch step 849 -- lr 3.18e-05
2025-03-02 10:43:58,627 - INFO - ðŸªœ Batch step - 212 -- sub batch step 850 -- lr 3.18e-05
2025-03-02 10:44:00,780 - INFO - ðŸªœ Batch step - 212 -- sub batch step 851 -- lr 3.18e-05
2025-03-02 10:44:02,361 - INFO - Step 212 -- ðŸ”„ Training Metrics
2025-03-02 10:44:02,362 - INFO - â”œâ”€â”€ Loss: 10.9279
2025-03-02 10:44:02,362 - INFO - â”œâ”€â”€ Learning Rate: 3.18e-05
2025-03-02 10:44:02,362 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:44:03,035 - INFO - ðŸªœ Batch step - 213 -- sub batch step 852 -- lr 3.19e-05
2025-03-02 10:44:05,185 - INFO - ðŸªœ Batch step - 213 -- sub batch step 853 -- lr 3.19e-05
2025-03-02 10:44:07,884 - INFO - ðŸªœ Batch step - 213 -- sub batch step 854 -- lr 3.19e-05
2025-03-02 10:44:10,043 - INFO - ðŸªœ Batch step - 213 -- sub batch step 855 -- lr 3.19e-05
2025-03-02 10:44:11,550 - INFO - Step 213 -- ðŸ”„ Training Metrics
2025-03-02 10:44:11,550 - INFO - â”œâ”€â”€ Loss: 10.9259
2025-03-02 10:44:11,550 - INFO - â”œâ”€â”€ Learning Rate: 3.19e-05
2025-03-02 10:44:11,550 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:44:12,215 - INFO - ðŸªœ Batch step - 214 -- sub batch step 856 -- lr 3.21e-05
2025-03-02 10:44:14,373 - INFO - ðŸªœ Batch step - 214 -- sub batch step 857 -- lr 3.21e-05
2025-03-02 10:44:16,546 - INFO - ðŸªœ Batch step - 214 -- sub batch step 858 -- lr 3.21e-05
2025-03-02 10:44:18,701 - INFO - ðŸªœ Batch step - 214 -- sub batch step 859 -- lr 3.21e-05
2025-03-02 10:44:20,287 - INFO - Step 214 -- ðŸ”„ Training Metrics
2025-03-02 10:44:20,287 - INFO - â”œâ”€â”€ Loss: 10.9267
2025-03-02 10:44:20,287 - INFO - â”œâ”€â”€ Learning Rate: 3.21e-05
2025-03-02 10:44:20,287 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:44:20,960 - INFO - ðŸªœ Batch step - 215 -- sub batch step 860 -- lr 3.22e-05
2025-03-02 10:44:23,113 - INFO - ðŸªœ Batch step - 215 -- sub batch step 861 -- lr 3.22e-05
2025-03-02 10:44:25,699 - INFO - ðŸªœ Batch step - 215 -- sub batch step 862 -- lr 3.22e-05
2025-03-02 10:44:27,852 - INFO - ðŸªœ Batch step - 215 -- sub batch step 863 -- lr 3.22e-05
2025-03-02 10:44:29,559 - INFO - Step 215 -- ðŸ”„ Training Metrics
2025-03-02 10:44:29,560 - INFO - â”œâ”€â”€ Loss: 10.9257
2025-03-02 10:44:29,560 - INFO - â”œâ”€â”€ Learning Rate: 3.22e-05
2025-03-02 10:44:29,560 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:44:30,234 - INFO - ðŸªœ Batch step - 216 -- sub batch step 864 -- lr 3.24e-05
2025-03-02 10:44:32,391 - INFO - ðŸªœ Batch step - 216 -- sub batch step 865 -- lr 3.24e-05
2025-03-02 10:44:34,564 - INFO - ðŸªœ Batch step - 216 -- sub batch step 866 -- lr 3.24e-05
2025-03-02 10:44:36,724 - INFO - ðŸªœ Batch step - 216 -- sub batch step 867 -- lr 3.24e-05
2025-03-02 10:44:38,298 - INFO - Step 216 -- ðŸ”„ Training Metrics
2025-03-02 10:44:38,298 - INFO - â”œâ”€â”€ Loss: 10.9251
2025-03-02 10:44:38,298 - INFO - â”œâ”€â”€ Learning Rate: 3.24e-05
2025-03-02 10:44:38,298 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:44:38,966 - INFO - ðŸªœ Batch step - 217 -- sub batch step 868 -- lr 3.25e-05
2025-03-02 10:44:41,126 - INFO - ðŸªœ Batch step - 217 -- sub batch step 869 -- lr 3.25e-05
2025-03-02 10:44:43,990 - INFO - ðŸªœ Batch step - 217 -- sub batch step 870 -- lr 3.25e-05
2025-03-02 10:44:46,145 - INFO - ðŸªœ Batch step - 217 -- sub batch step 871 -- lr 3.25e-05
2025-03-02 10:44:47,640 - INFO - Step 217 -- ðŸ”„ Training Metrics
2025-03-02 10:44:47,640 - INFO - â”œâ”€â”€ Loss: 10.9253
2025-03-02 10:44:47,640 - INFO - â”œâ”€â”€ Learning Rate: 3.25e-05
2025-03-02 10:44:47,640 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:44:48,313 - INFO - ðŸªœ Batch step - 218 -- sub batch step 872 -- lr 3.27e-05
2025-03-02 10:44:50,470 - INFO - ðŸªœ Batch step - 218 -- sub batch step 873 -- lr 3.27e-05
2025-03-02 10:44:52,647 - INFO - ðŸªœ Batch step - 218 -- sub batch step 874 -- lr 3.27e-05
2025-03-02 10:44:54,807 - INFO - ðŸªœ Batch step - 218 -- sub batch step 875 -- lr 3.27e-05
2025-03-02 10:44:56,382 - INFO - Step 218 -- ðŸ”„ Training Metrics
2025-03-02 10:44:56,382 - INFO - â”œâ”€â”€ Loss: 10.9238
2025-03-02 10:44:56,382 - INFO - â”œâ”€â”€ Learning Rate: 3.27e-05
2025-03-02 10:44:56,382 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:44:57,051 - INFO - ðŸªœ Batch step - 219 -- sub batch step 876 -- lr 3.28e-05
2025-03-02 10:44:59,205 - INFO - ðŸªœ Batch step - 219 -- sub batch step 877 -- lr 3.28e-05
2025-03-02 10:45:01,487 - INFO - ðŸªœ Batch step - 219 -- sub batch step 878 -- lr 3.28e-05
2025-03-02 10:45:03,649 - INFO - ðŸªœ Batch step - 219 -- sub batch step 879 -- lr 3.28e-05
2025-03-02 10:45:05,286 - INFO - Step 219 -- ðŸ”„ Training Metrics
2025-03-02 10:45:05,286 - INFO - â”œâ”€â”€ Loss: 10.9230
2025-03-02 10:45:05,287 - INFO - â”œâ”€â”€ Learning Rate: 3.28e-05
2025-03-02 10:45:05,287 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:45:06,488 - INFO - ðŸªœ Batch step - 220 -- sub batch step 880 -- lr 3.30e-05
2025-03-02 10:45:08,645 - INFO - ðŸªœ Batch step - 220 -- sub batch step 881 -- lr 3.30e-05
2025-03-02 10:45:10,808 - INFO - ðŸªœ Batch step - 220 -- sub batch step 882 -- lr 3.30e-05
2025-03-02 10:45:12,992 - INFO - ðŸªœ Batch step - 220 -- sub batch step 883 -- lr 3.30e-05
2025-03-02 10:45:14,641 - INFO - Step 220 -- ðŸ”„ Training Metrics
2025-03-02 10:45:14,642 - INFO - â”œâ”€â”€ Loss: 10.9212
2025-03-02 10:45:14,642 - INFO - â”œâ”€â”€ Learning Rate: 3.30e-05
2025-03-02 10:45:14,642 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:45:15,321 - INFO - ðŸªœ Batch step - 221 -- sub batch step 884 -- lr 3.31e-05
2025-03-02 10:45:17,478 - INFO - ðŸªœ Batch step - 221 -- sub batch step 885 -- lr 3.31e-05
2025-03-02 10:45:19,638 - INFO - ðŸªœ Batch step - 221 -- sub batch step 886 -- lr 3.31e-05
2025-03-02 10:45:22,123 - INFO - ðŸªœ Batch step - 221 -- sub batch step 887 -- lr 3.31e-05
2025-03-02 10:45:23,959 - INFO - Step 221 -- ðŸ”„ Training Metrics
2025-03-02 10:45:23,959 - INFO - â”œâ”€â”€ Loss: 10.9200
2025-03-02 10:45:23,960 - INFO - â”œâ”€â”€ Learning Rate: 3.31e-05
2025-03-02 10:45:23,960 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:45:24,628 - INFO - ðŸªœ Batch step - 222 -- sub batch step 888 -- lr 3.33e-05
2025-03-02 10:45:26,790 - INFO - ðŸªœ Batch step - 222 -- sub batch step 889 -- lr 3.33e-05
2025-03-02 10:45:28,951 - INFO - ðŸªœ Batch step - 222 -- sub batch step 890 -- lr 3.33e-05
2025-03-02 10:45:31,129 - INFO - ðŸªœ Batch step - 222 -- sub batch step 891 -- lr 3.33e-05
2025-03-02 10:45:32,705 - INFO - Step 222 -- ðŸ”„ Training Metrics
2025-03-02 10:45:32,706 - INFO - â”œâ”€â”€ Loss: 10.9218
2025-03-02 10:45:32,706 - INFO - â”œâ”€â”€ Learning Rate: 3.33e-05
2025-03-02 10:45:32,706 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:45:33,379 - INFO - ðŸªœ Batch step - 223 -- sub batch step 892 -- lr 3.34e-05
2025-03-02 10:45:35,534 - INFO - ðŸªœ Batch step - 223 -- sub batch step 893 -- lr 3.34e-05
2025-03-02 10:45:37,694 - INFO - ðŸªœ Batch step - 223 -- sub batch step 894 -- lr 3.34e-05
2025-03-02 10:45:40,377 - INFO - ðŸªœ Batch step - 223 -- sub batch step 895 -- lr 3.34e-05
2025-03-02 10:45:42,116 - INFO - Step 223 -- ðŸ”„ Training Metrics
2025-03-02 10:45:42,116 - INFO - â”œâ”€â”€ Loss: 10.9181
2025-03-02 10:45:42,116 - INFO - â”œâ”€â”€ Learning Rate: 3.34e-05
2025-03-02 10:45:42,117 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:45:42,786 - INFO - ðŸªœ Batch step - 224 -- sub batch step 896 -- lr 3.36e-05
2025-03-02 10:45:44,946 - INFO - ðŸªœ Batch step - 224 -- sub batch step 897 -- lr 3.36e-05
2025-03-02 10:45:47,106 - INFO - ðŸªœ Batch step - 224 -- sub batch step 898 -- lr 3.36e-05
2025-03-02 10:45:49,287 - INFO - ðŸªœ Batch step - 224 -- sub batch step 899 -- lr 3.36e-05
2025-03-02 10:45:50,854 - INFO - Step 224 -- ðŸ”„ Training Metrics
2025-03-02 10:45:50,854 - INFO - â”œâ”€â”€ Loss: 10.9196
2025-03-02 10:45:50,854 - INFO - â”œâ”€â”€ Learning Rate: 3.36e-05
2025-03-02 10:45:50,854 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:45:51,530 - INFO - ðŸªœ Batch step - 225 -- sub batch step 900 -- lr 3.38e-05
2025-03-02 10:45:53,687 - INFO - ðŸªœ Batch step - 225 -- sub batch step 901 -- lr 3.38e-05
2025-03-02 10:45:55,851 - INFO - ðŸªœ Batch step - 225 -- sub batch step 902 -- lr 3.38e-05
2025-03-02 10:45:58,247 - INFO - ðŸªœ Batch step - 225 -- sub batch step 903 -- lr 3.38e-05
2025-03-02 10:46:00,224 - INFO - Step 225 -- ðŸ”„ Training Metrics
2025-03-02 10:46:00,224 - INFO - â”œâ”€â”€ Loss: 10.9177
2025-03-02 10:46:00,225 - INFO - â”œâ”€â”€ Learning Rate: 3.38e-05
2025-03-02 10:46:00,225 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:46:00,902 - INFO - ðŸªœ Batch step - 226 -- sub batch step 904 -- lr 3.39e-05
2025-03-02 10:46:03,066 - INFO - ðŸªœ Batch step - 226 -- sub batch step 905 -- lr 3.39e-05
2025-03-02 10:46:05,217 - INFO - ðŸªœ Batch step - 226 -- sub batch step 906 -- lr 3.39e-05
2025-03-02 10:46:07,419 - INFO - ðŸªœ Batch step - 226 -- sub batch step 907 -- lr 3.39e-05
2025-03-02 10:46:08,967 - INFO - Step 226 -- ðŸ”„ Training Metrics
2025-03-02 10:46:08,967 - INFO - â”œâ”€â”€ Loss: 10.9175
2025-03-02 10:46:08,967 - INFO - â”œâ”€â”€ Learning Rate: 3.39e-05
2025-03-02 10:46:08,967 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:46:09,634 - INFO - ðŸªœ Batch step - 227 -- sub batch step 908 -- lr 3.41e-05
2025-03-02 10:46:11,795 - INFO - ðŸªœ Batch step - 227 -- sub batch step 909 -- lr 3.41e-05
2025-03-02 10:46:13,952 - INFO - ðŸªœ Batch step - 227 -- sub batch step 910 -- lr 3.41e-05
2025-03-02 10:46:16,410 - INFO - ðŸªœ Batch step - 227 -- sub batch step 911 -- lr 3.41e-05
2025-03-02 10:46:18,352 - INFO - Step 227 -- ðŸ”„ Training Metrics
2025-03-02 10:46:18,353 - INFO - â”œâ”€â”€ Loss: 10.9154
2025-03-02 10:46:18,353 - INFO - â”œâ”€â”€ Learning Rate: 3.41e-05
2025-03-02 10:46:18,353 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:46:19,027 - INFO - ðŸªœ Batch step - 228 -- sub batch step 912 -- lr 3.42e-05
2025-03-02 10:46:21,181 - INFO - ðŸªœ Batch step - 228 -- sub batch step 913 -- lr 3.42e-05
2025-03-02 10:46:23,342 - INFO - ðŸªœ Batch step - 228 -- sub batch step 914 -- lr 3.42e-05
2025-03-02 10:46:25,527 - INFO - ðŸªœ Batch step - 228 -- sub batch step 915 -- lr 3.42e-05
2025-03-02 10:46:27,087 - INFO - Step 228 -- ðŸ”„ Training Metrics
2025-03-02 10:46:27,087 - INFO - â”œâ”€â”€ Loss: 10.9169
2025-03-02 10:46:27,087 - INFO - â”œâ”€â”€ Learning Rate: 3.42e-05
2025-03-02 10:46:27,088 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:46:27,758 - INFO - ðŸªœ Batch step - 229 -- sub batch step 916 -- lr 3.44e-05
2025-03-02 10:46:29,917 - INFO - ðŸªœ Batch step - 229 -- sub batch step 917 -- lr 3.44e-05
2025-03-02 10:46:32,073 - INFO - ðŸªœ Batch step - 229 -- sub batch step 918 -- lr 3.44e-05
2025-03-02 10:46:34,561 - INFO - ðŸªœ Batch step - 229 -- sub batch step 919 -- lr 3.44e-05
2025-03-02 10:46:36,405 - INFO - Step 229 -- ðŸ”„ Training Metrics
2025-03-02 10:46:36,405 - INFO - â”œâ”€â”€ Loss: 10.9145
2025-03-02 10:46:36,405 - INFO - â”œâ”€â”€ Learning Rate: 3.44e-05
2025-03-02 10:46:36,405 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:46:37,081 - INFO - ðŸªœ Batch step - 230 -- sub batch step 920 -- lr 3.45e-05
2025-03-02 10:46:39,236 - INFO - ðŸªœ Batch step - 230 -- sub batch step 921 -- lr 3.45e-05
2025-03-02 10:46:41,397 - INFO - ðŸªœ Batch step - 230 -- sub batch step 922 -- lr 3.45e-05
2025-03-02 10:46:43,568 - INFO - ðŸªœ Batch step - 230 -- sub batch step 923 -- lr 3.45e-05
2025-03-02 10:46:45,129 - INFO - Step 230 -- ðŸ”„ Training Metrics
2025-03-02 10:46:45,129 - INFO - â”œâ”€â”€ Loss: 10.9138
2025-03-02 10:46:45,129 - INFO - â”œâ”€â”€ Learning Rate: 3.45e-05
2025-03-02 10:46:45,129 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:46:45,805 - INFO - ðŸªœ Batch step - 231 -- sub batch step 924 -- lr 3.47e-05
2025-03-02 10:46:47,958 - INFO - ðŸªœ Batch step - 231 -- sub batch step 925 -- lr 3.47e-05
2025-03-02 10:46:50,682 - INFO - ðŸªœ Batch step - 231 -- sub batch step 926 -- lr 3.47e-05
2025-03-02 10:46:52,839 - INFO - ðŸªœ Batch step - 231 -- sub batch step 927 -- lr 3.47e-05
2025-03-02 10:46:54,350 - INFO - Step 231 -- ðŸ”„ Training Metrics
2025-03-02 10:46:54,351 - INFO - â”œâ”€â”€ Loss: 10.9128
2025-03-02 10:46:54,351 - INFO - â”œâ”€â”€ Learning Rate: 3.47e-05
2025-03-02 10:46:54,351 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:46:55,015 - INFO - ðŸªœ Batch step - 232 -- sub batch step 928 -- lr 3.48e-05
2025-03-02 10:46:57,173 - INFO - ðŸªœ Batch step - 232 -- sub batch step 929 -- lr 3.48e-05
2025-03-02 10:46:59,352 - INFO - ðŸªœ Batch step - 232 -- sub batch step 930 -- lr 3.48e-05
2025-03-02 10:47:01,503 - INFO - ðŸªœ Batch step - 232 -- sub batch step 931 -- lr 3.48e-05
2025-03-02 10:47:03,092 - INFO - Step 232 -- ðŸ”„ Training Metrics
2025-03-02 10:47:03,092 - INFO - â”œâ”€â”€ Loss: 10.9118
2025-03-02 10:47:03,092 - INFO - â”œâ”€â”€ Learning Rate: 3.48e-05
2025-03-02 10:47:03,092 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:47:03,764 - INFO - ðŸªœ Batch step - 233 -- sub batch step 932 -- lr 3.49e-05
2025-03-02 10:47:05,916 - INFO - ðŸªœ Batch step - 233 -- sub batch step 933 -- lr 3.49e-05
2025-03-02 10:47:08,656 - INFO - ðŸªœ Batch step - 233 -- sub batch step 934 -- lr 3.49e-05
2025-03-02 10:47:10,816 - INFO - ðŸªœ Batch step - 233 -- sub batch step 935 -- lr 3.49e-05
2025-03-02 10:47:12,402 - INFO - Step 233 -- ðŸ”„ Training Metrics
2025-03-02 10:47:12,402 - INFO - â”œâ”€â”€ Loss: 10.9120
2025-03-02 10:47:12,402 - INFO - â”œâ”€â”€ Learning Rate: 3.49e-05
2025-03-02 10:47:12,402 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:47:13,069 - INFO - ðŸªœ Batch step - 234 -- sub batch step 936 -- lr 3.51e-05
2025-03-02 10:47:15,225 - INFO - ðŸªœ Batch step - 234 -- sub batch step 937 -- lr 3.51e-05
2025-03-02 10:47:17,401 - INFO - ðŸªœ Batch step - 234 -- sub batch step 938 -- lr 3.51e-05
2025-03-02 10:47:19,560 - INFO - ðŸªœ Batch step - 234 -- sub batch step 939 -- lr 3.51e-05
2025-03-02 10:47:21,149 - INFO - Step 234 -- ðŸ”„ Training Metrics
2025-03-02 10:47:21,149 - INFO - â”œâ”€â”€ Loss: 10.9113
2025-03-02 10:47:21,149 - INFO - â”œâ”€â”€ Learning Rate: 3.51e-05
2025-03-02 10:47:21,149 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:47:21,822 - INFO - ðŸªœ Batch step - 235 -- sub batch step 940 -- lr 3.52e-05
2025-03-02 10:47:23,976 - INFO - ðŸªœ Batch step - 235 -- sub batch step 941 -- lr 3.52e-05
2025-03-02 10:47:26,377 - INFO - ðŸªœ Batch step - 235 -- sub batch step 942 -- lr 3.52e-05
2025-03-02 10:47:28,534 - INFO - ðŸªœ Batch step - 235 -- sub batch step 943 -- lr 3.52e-05
2025-03-02 10:47:30,339 - INFO - Step 235 -- ðŸ”„ Training Metrics
2025-03-02 10:47:30,340 - INFO - â”œâ”€â”€ Loss: 10.9100
2025-03-02 10:47:30,340 - INFO - â”œâ”€â”€ Learning Rate: 3.52e-05
2025-03-02 10:47:30,340 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:47:31,013 - INFO - ðŸªœ Batch step - 236 -- sub batch step 944 -- lr 3.54e-05
2025-03-02 10:47:33,170 - INFO - ðŸªœ Batch step - 236 -- sub batch step 945 -- lr 3.54e-05
2025-03-02 10:47:35,346 - INFO - ðŸªœ Batch step - 236 -- sub batch step 946 -- lr 3.54e-05
2025-03-02 10:47:37,504 - INFO - ðŸªœ Batch step - 236 -- sub batch step 947 -- lr 3.54e-05
2025-03-02 10:47:39,076 - INFO - Step 236 -- ðŸ”„ Training Metrics
2025-03-02 10:47:39,076 - INFO - â”œâ”€â”€ Loss: 10.9099
2025-03-02 10:47:39,076 - INFO - â”œâ”€â”€ Learning Rate: 3.54e-05
2025-03-02 10:47:39,076 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:47:39,746 - INFO - ðŸªœ Batch step - 237 -- sub batch step 948 -- lr 3.55e-05
2025-03-02 10:47:41,903 - INFO - ðŸªœ Batch step - 237 -- sub batch step 949 -- lr 3.55e-05
2025-03-02 10:47:44,275 - INFO - ðŸªœ Batch step - 237 -- sub batch step 950 -- lr 3.55e-05
2025-03-02 10:47:46,431 - INFO - ðŸªœ Batch step - 237 -- sub batch step 951 -- lr 3.55e-05
2025-03-02 10:47:48,467 - INFO - Step 237 -- ðŸ”„ Training Metrics
2025-03-02 10:47:48,467 - INFO - â”œâ”€â”€ Loss: 10.9088
2025-03-02 10:47:48,467 - INFO - â”œâ”€â”€ Learning Rate: 3.55e-05
2025-03-02 10:47:48,467 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:47:49,142 - INFO - ðŸªœ Batch step - 238 -- sub batch step 952 -- lr 3.57e-05
2025-03-02 10:47:51,297 - INFO - ðŸªœ Batch step - 238 -- sub batch step 953 -- lr 3.57e-05
2025-03-02 10:47:53,474 - INFO - ðŸªœ Batch step - 238 -- sub batch step 954 -- lr 3.57e-05
2025-03-02 10:47:55,631 - INFO - ðŸªœ Batch step - 238 -- sub batch step 955 -- lr 3.57e-05
2025-03-02 10:47:57,203 - INFO - Step 238 -- ðŸ”„ Training Metrics
2025-03-02 10:47:57,203 - INFO - â”œâ”€â”€ Loss: 10.9089
2025-03-02 10:47:57,203 - INFO - â”œâ”€â”€ Learning Rate: 3.57e-05
2025-03-02 10:47:57,203 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:47:57,868 - INFO - ðŸªœ Batch step - 239 -- sub batch step 956 -- lr 3.58e-05
2025-03-02 10:48:00,026 - INFO - ðŸªœ Batch step - 239 -- sub batch step 957 -- lr 3.58e-05
2025-03-02 10:48:02,305 - INFO - ðŸªœ Batch step - 239 -- sub batch step 958 -- lr 3.58e-05
2025-03-02 10:48:04,462 - INFO - ðŸªœ Batch step - 239 -- sub batch step 959 -- lr 3.58e-05
2025-03-02 10:48:06,060 - INFO - Step 239 -- ðŸ”„ Training Metrics
2025-03-02 10:48:06,061 - INFO - â”œâ”€â”€ Loss: 10.9060
2025-03-02 10:48:06,061 - INFO - â”œâ”€â”€ Learning Rate: 3.58e-05
2025-03-02 10:48:06,061 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:48:07,289 - INFO - ðŸªœ Batch step - 240 -- sub batch step 960 -- lr 3.60e-05
2025-03-02 10:48:09,438 - INFO - ðŸªœ Batch step - 240 -- sub batch step 961 -- lr 3.60e-05
2025-03-02 10:48:11,591 - INFO - ðŸªœ Batch step - 240 -- sub batch step 962 -- lr 3.60e-05
2025-03-02 10:48:13,757 - INFO - ðŸªœ Batch step - 240 -- sub batch step 963 -- lr 3.60e-05
2025-03-02 10:48:15,387 - INFO - Step 240 -- ðŸ”„ Training Metrics
2025-03-02 10:48:15,387 - INFO - â”œâ”€â”€ Loss: 10.9066
2025-03-02 10:48:15,387 - INFO - â”œâ”€â”€ Learning Rate: 3.60e-05
2025-03-02 10:48:15,388 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:48:16,059 - INFO - ðŸªœ Batch step - 241 -- sub batch step 964 -- lr 3.61e-05
2025-03-02 10:48:18,220 - INFO - ðŸªœ Batch step - 241 -- sub batch step 965 -- lr 3.61e-05
2025-03-02 10:48:20,372 - INFO - ðŸªœ Batch step - 241 -- sub batch step 966 -- lr 3.61e-05
2025-03-02 10:48:22,975 - INFO - ðŸªœ Batch step - 241 -- sub batch step 967 -- lr 3.61e-05
2025-03-02 10:48:24,722 - INFO - Step 241 -- ðŸ”„ Training Metrics
2025-03-02 10:48:24,722 - INFO - â”œâ”€â”€ Loss: 10.9064
2025-03-02 10:48:24,722 - INFO - â”œâ”€â”€ Learning Rate: 3.61e-05
2025-03-02 10:48:24,722 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:48:25,390 - INFO - ðŸªœ Batch step - 242 -- sub batch step 968 -- lr 3.63e-05
2025-03-02 10:48:27,550 - INFO - ðŸªœ Batch step - 242 -- sub batch step 969 -- lr 3.63e-05
2025-03-02 10:48:29,708 - INFO - ðŸªœ Batch step - 242 -- sub batch step 970 -- lr 3.63e-05
2025-03-02 10:48:31,882 - INFO - ðŸªœ Batch step - 242 -- sub batch step 971 -- lr 3.63e-05
2025-03-02 10:48:33,455 - INFO - Step 242 -- ðŸ”„ Training Metrics
2025-03-02 10:48:33,456 - INFO - â”œâ”€â”€ Loss: 10.9043
2025-03-02 10:48:33,456 - INFO - â”œâ”€â”€ Learning Rate: 3.63e-05
2025-03-02 10:48:33,456 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:48:34,131 - INFO - ðŸªœ Batch step - 243 -- sub batch step 972 -- lr 3.64e-05
2025-03-02 10:48:36,288 - INFO - ðŸªœ Batch step - 243 -- sub batch step 973 -- lr 3.64e-05
2025-03-02 10:48:38,446 - INFO - ðŸªœ Batch step - 243 -- sub batch step 974 -- lr 3.64e-05
2025-03-02 10:48:41,063 - INFO - ðŸªœ Batch step - 243 -- sub batch step 975 -- lr 3.64e-05
2025-03-02 10:48:42,756 - INFO - Step 243 -- ðŸ”„ Training Metrics
2025-03-02 10:48:42,757 - INFO - â”œâ”€â”€ Loss: 10.9044
2025-03-02 10:48:42,757 - INFO - â”œâ”€â”€ Learning Rate: 3.64e-05
2025-03-02 10:48:42,757 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:48:43,424 - INFO - ðŸªœ Batch step - 244 -- sub batch step 976 -- lr 3.66e-05
2025-03-02 10:48:45,584 - INFO - ðŸªœ Batch step - 244 -- sub batch step 977 -- lr 3.66e-05
2025-03-02 10:48:47,737 - INFO - ðŸªœ Batch step - 244 -- sub batch step 978 -- lr 3.66e-05
2025-03-02 10:48:49,915 - INFO - ðŸªœ Batch step - 244 -- sub batch step 979 -- lr 3.66e-05
2025-03-02 10:48:51,492 - INFO - Step 244 -- ðŸ”„ Training Metrics
2025-03-02 10:48:51,492 - INFO - â”œâ”€â”€ Loss: 10.9029
2025-03-02 10:48:51,492 - INFO - â”œâ”€â”€ Learning Rate: 3.66e-05
2025-03-02 10:48:51,492 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:48:52,165 - INFO - ðŸªœ Batch step - 245 -- sub batch step 980 -- lr 3.67e-05
2025-03-02 10:48:54,315 - INFO - ðŸªœ Batch step - 245 -- sub batch step 981 -- lr 3.67e-05
2025-03-02 10:48:56,472 - INFO - ðŸªœ Batch step - 245 -- sub batch step 982 -- lr 3.67e-05
2025-03-02 10:48:59,142 - INFO - ðŸªœ Batch step - 245 -- sub batch step 983 -- lr 3.67e-05
2025-03-02 10:49:00,797 - INFO - Step 245 -- ðŸ”„ Training Metrics
2025-03-02 10:49:00,797 - INFO - â”œâ”€â”€ Loss: 10.9014
2025-03-02 10:49:00,797 - INFO - â”œâ”€â”€ Learning Rate: 3.67e-05
2025-03-02 10:49:00,797 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:49:01,470 - INFO - ðŸªœ Batch step - 246 -- sub batch step 984 -- lr 3.69e-05
2025-03-02 10:49:03,624 - INFO - ðŸªœ Batch step - 246 -- sub batch step 985 -- lr 3.69e-05
2025-03-02 10:49:05,775 - INFO - ðŸªœ Batch step - 246 -- sub batch step 986 -- lr 3.69e-05
2025-03-02 10:49:07,953 - INFO - ðŸªœ Batch step - 246 -- sub batch step 987 -- lr 3.69e-05
2025-03-02 10:49:09,533 - INFO - Step 246 -- ðŸ”„ Training Metrics
2025-03-02 10:49:09,534 - INFO - â”œâ”€â”€ Loss: 10.9027
2025-03-02 10:49:09,534 - INFO - â”œâ”€â”€ Learning Rate: 3.69e-05
2025-03-02 10:49:09,534 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:49:10,199 - INFO - ðŸªœ Batch step - 247 -- sub batch step 988 -- lr 3.70e-05
2025-03-02 10:49:12,354 - INFO - ðŸªœ Batch step - 247 -- sub batch step 989 -- lr 3.70e-05
2025-03-02 10:49:14,509 - INFO - ðŸªœ Batch step - 247 -- sub batch step 990 -- lr 3.70e-05
2025-03-02 10:49:17,163 - INFO - ðŸªœ Batch step - 247 -- sub batch step 991 -- lr 3.70e-05
2025-03-02 10:49:19,073 - INFO - Step 247 -- ðŸ”„ Training Metrics
2025-03-02 10:49:19,074 - INFO - â”œâ”€â”€ Loss: 10.9013
2025-03-02 10:49:19,074 - INFO - â”œâ”€â”€ Learning Rate: 3.70e-05
2025-03-02 10:49:19,074 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:49:19,747 - INFO - ðŸªœ Batch step - 248 -- sub batch step 992 -- lr 3.72e-05
2025-03-02 10:49:21,899 - INFO - ðŸªœ Batch step - 248 -- sub batch step 993 -- lr 3.72e-05
2025-03-02 10:49:24,057 - INFO - ðŸªœ Batch step - 248 -- sub batch step 994 -- lr 3.72e-05
2025-03-02 10:49:26,236 - INFO - ðŸªœ Batch step - 248 -- sub batch step 995 -- lr 3.72e-05
2025-03-02 10:49:27,811 - INFO - Step 248 -- ðŸ”„ Training Metrics
2025-03-02 10:49:27,811 - INFO - â”œâ”€â”€ Loss: 10.9006
2025-03-02 10:49:27,811 - INFO - â”œâ”€â”€ Learning Rate: 3.72e-05
2025-03-02 10:49:27,811 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:49:28,476 - INFO - ðŸªœ Batch step - 249 -- sub batch step 996 -- lr 3.73e-05
2025-03-02 10:49:30,634 - INFO - ðŸªœ Batch step - 249 -- sub batch step 997 -- lr 3.73e-05
2025-03-02 10:49:32,785 - INFO - ðŸªœ Batch step - 249 -- sub batch step 998 -- lr 3.73e-05
2025-03-02 10:49:35,218 - INFO - ðŸªœ Batch step - 249 -- sub batch step 999 -- lr 3.73e-05
2025-03-02 10:49:37,182 - INFO - Step 249 -- ðŸ”„ Training Metrics
2025-03-02 10:49:37,182 - INFO - â”œâ”€â”€ Loss: 10.8995
2025-03-02 10:49:37,182 - INFO - â”œâ”€â”€ Learning Rate: 3.73e-05
2025-03-02 10:49:37,182 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:49:37,856 - INFO - ðŸªœ Batch step - 250 -- sub batch step 1000 -- lr 3.75e-05
2025-03-02 10:49:40,006 - INFO - ðŸªœ Batch step - 250 -- sub batch step 1001 -- lr 3.75e-05
2025-03-02 10:49:42,163 - INFO - ðŸªœ Batch step - 250 -- sub batch step 1002 -- lr 3.75e-05
2025-03-02 10:49:44,332 - INFO - ðŸªœ Batch step - 250 -- sub batch step 1003 -- lr 3.75e-05
2025-03-02 10:49:45,908 - INFO - Step 250 -- ðŸ”„ Training Metrics
2025-03-02 10:49:45,908 - INFO - â”œâ”€â”€ Loss: 10.8975
2025-03-02 10:49:45,908 - INFO - â”œâ”€â”€ Learning Rate: 3.75e-05
2025-03-02 10:49:45,908 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:49:46,582 - INFO - ðŸªœ Batch step - 251 -- sub batch step 1004 -- lr 3.76e-05
2025-03-02 10:49:48,736 - INFO - ðŸªœ Batch step - 251 -- sub batch step 1005 -- lr 3.76e-05
2025-03-02 10:49:51,384 - INFO - ðŸªœ Batch step - 251 -- sub batch step 1006 -- lr 3.76e-05
2025-03-02 10:49:53,541 - INFO - ðŸªœ Batch step - 251 -- sub batch step 1007 -- lr 3.76e-05
2025-03-02 10:49:55,548 - INFO - Step 251 -- ðŸ”„ Training Metrics
2025-03-02 10:49:55,549 - INFO - â”œâ”€â”€ Loss: 10.8996
2025-03-02 10:49:55,549 - INFO - â”œâ”€â”€ Learning Rate: 3.76e-05
2025-03-02 10:49:55,549 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:49:56,216 - INFO - ðŸªœ Batch step - 252 -- sub batch step 1008 -- lr 3.78e-05
2025-03-02 10:49:58,372 - INFO - ðŸªœ Batch step - 252 -- sub batch step 1009 -- lr 3.78e-05
2025-03-02 10:50:00,551 - INFO - ðŸªœ Batch step - 252 -- sub batch step 1010 -- lr 3.78e-05
2025-03-02 10:50:02,704 - INFO - ðŸªœ Batch step - 252 -- sub batch step 1011 -- lr 3.78e-05
2025-03-02 10:50:04,283 - INFO - Step 252 -- ðŸ”„ Training Metrics
2025-03-02 10:50:04,283 - INFO - â”œâ”€â”€ Loss: 10.8979
2025-03-02 10:50:04,283 - INFO - â”œâ”€â”€ Learning Rate: 3.78e-05
2025-03-02 10:50:04,283 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:50:04,954 - INFO - ðŸªœ Batch step - 253 -- sub batch step 1012 -- lr 3.79e-05
2025-03-02 10:50:07,105 - INFO - ðŸªœ Batch step - 253 -- sub batch step 1013 -- lr 3.79e-05
2025-03-02 10:50:09,829 - INFO - ðŸªœ Batch step - 253 -- sub batch step 1014 -- lr 3.79e-05
2025-03-02 10:50:11,994 - INFO - ðŸªœ Batch step - 253 -- sub batch step 1015 -- lr 3.79e-05
2025-03-02 10:50:13,562 - INFO - Step 253 -- ðŸ”„ Training Metrics
2025-03-02 10:50:13,562 - INFO - â”œâ”€â”€ Loss: 10.8965
2025-03-02 10:50:13,562 - INFO - â”œâ”€â”€ Learning Rate: 3.79e-05
2025-03-02 10:50:13,562 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:50:14,233 - INFO - ðŸªœ Batch step - 254 -- sub batch step 1016 -- lr 3.81e-05
2025-03-02 10:50:16,393 - INFO - ðŸªœ Batch step - 254 -- sub batch step 1017 -- lr 3.81e-05
2025-03-02 10:50:18,569 - INFO - ðŸªœ Batch step - 254 -- sub batch step 1018 -- lr 3.81e-05
2025-03-02 10:50:20,735 - INFO - ðŸªœ Batch step - 254 -- sub batch step 1019 -- lr 3.81e-05
2025-03-02 10:50:22,290 - INFO - Step 254 -- ðŸ”„ Training Metrics
2025-03-02 10:50:22,291 - INFO - â”œâ”€â”€ Loss: 10.8949
2025-03-02 10:50:22,291 - INFO - â”œâ”€â”€ Learning Rate: 3.81e-05
2025-03-02 10:50:22,291 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:50:22,968 - INFO - ðŸªœ Batch step - 255 -- sub batch step 1020 -- lr 3.82e-05
2025-03-02 10:50:25,116 - INFO - ðŸªœ Batch step - 255 -- sub batch step 1021 -- lr 3.82e-05
2025-03-02 10:50:27,895 - INFO - ðŸªœ Batch step - 255 -- sub batch step 1022 -- lr 3.82e-05
2025-03-02 10:50:30,041 - INFO - ðŸªœ Batch step - 255 -- sub batch step 1023 -- lr 3.82e-05
2025-03-02 10:50:31,541 - INFO - Step 255 -- ðŸ”„ Training Metrics
2025-03-02 10:50:31,541 - INFO - â”œâ”€â”€ Loss: 10.8939
2025-03-02 10:50:31,541 - INFO - â”œâ”€â”€ Learning Rate: 3.82e-05
2025-03-02 10:50:31,541 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:50:32,214 - INFO - ðŸªœ Batch step - 256 -- sub batch step 1024 -- lr 3.84e-05
2025-03-02 10:50:34,371 - INFO - ðŸªœ Batch step - 256 -- sub batch step 1025 -- lr 3.84e-05
2025-03-02 10:50:36,543 - INFO - ðŸªœ Batch step - 256 -- sub batch step 1026 -- lr 3.84e-05
2025-03-02 10:50:38,703 - INFO - ðŸªœ Batch step - 256 -- sub batch step 1027 -- lr 3.84e-05
2025-03-02 10:50:40,270 - INFO - Step 256 -- ðŸ”„ Training Metrics
2025-03-02 10:50:40,270 - INFO - â”œâ”€â”€ Loss: 10.8938
2025-03-02 10:50:40,270 - INFO - â”œâ”€â”€ Learning Rate: 3.84e-05
2025-03-02 10:50:40,270 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:50:40,936 - INFO - ðŸªœ Batch step - 257 -- sub batch step 1028 -- lr 3.85e-05
2025-03-02 10:50:43,093 - INFO - ðŸªœ Batch step - 257 -- sub batch step 1029 -- lr 3.85e-05
2025-03-02 10:50:45,635 - INFO - ðŸªœ Batch step - 257 -- sub batch step 1030 -- lr 3.85e-05
2025-03-02 10:50:47,785 - INFO - ðŸªœ Batch step - 257 -- sub batch step 1031 -- lr 3.85e-05
2025-03-02 10:50:49,473 - INFO - Step 257 -- ðŸ”„ Training Metrics
2025-03-02 10:50:49,473 - INFO - â”œâ”€â”€ Loss: 10.8934
2025-03-02 10:50:49,473 - INFO - â”œâ”€â”€ Learning Rate: 3.85e-05
2025-03-02 10:50:49,473 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:50:50,150 - INFO - ðŸªœ Batch step - 258 -- sub batch step 1032 -- lr 3.87e-05
2025-03-02 10:50:52,299 - INFO - ðŸªœ Batch step - 258 -- sub batch step 1033 -- lr 3.87e-05
2025-03-02 10:50:54,477 - INFO - ðŸªœ Batch step - 258 -- sub batch step 1034 -- lr 3.87e-05
2025-03-02 10:50:56,632 - INFO - ðŸªœ Batch step - 258 -- sub batch step 1035 -- lr 3.87e-05
2025-03-02 10:50:58,208 - INFO - Step 258 -- ðŸ”„ Training Metrics
2025-03-02 10:50:58,208 - INFO - â”œâ”€â”€ Loss: 10.8915
2025-03-02 10:50:58,208 - INFO - â”œâ”€â”€ Learning Rate: 3.87e-05
2025-03-02 10:50:58,208 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:50:58,872 - INFO - ðŸªœ Batch step - 259 -- sub batch step 1036 -- lr 3.88e-05
2025-03-02 10:51:01,029 - INFO - ðŸªœ Batch step - 259 -- sub batch step 1037 -- lr 3.88e-05
2025-03-02 10:51:03,528 - INFO - ðŸªœ Batch step - 259 -- sub batch step 1038 -- lr 3.88e-05
2025-03-02 10:51:05,689 - INFO - ðŸªœ Batch step - 259 -- sub batch step 1039 -- lr 3.88e-05
2025-03-02 10:51:07,182 - INFO - Step 259 -- ðŸ”„ Training Metrics
2025-03-02 10:51:07,182 - INFO - â”œâ”€â”€ Loss: 10.8899
2025-03-02 10:51:07,182 - INFO - â”œâ”€â”€ Learning Rate: 3.88e-05
2025-03-02 10:51:07,182 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:51:08,391 - INFO - ðŸªœ Batch step - 260 -- sub batch step 1040 -- lr 3.90e-05
2025-03-02 10:51:10,553 - INFO - ðŸªœ Batch step - 260 -- sub batch step 1041 -- lr 3.90e-05
2025-03-02 10:51:12,715 - INFO - ðŸªœ Batch step - 260 -- sub batch step 1042 -- lr 3.90e-05
2025-03-02 10:51:14,893 - INFO - ðŸªœ Batch step - 260 -- sub batch step 1043 -- lr 3.90e-05
2025-03-02 10:51:17,198 - INFO - Step 260 -- ðŸ”„ Training Metrics
2025-03-02 10:51:17,199 - INFO - â”œâ”€â”€ Loss: 10.8915
2025-03-02 10:51:17,199 - INFO - â”œâ”€â”€ Learning Rate: 3.90e-05
2025-03-02 10:51:17,199 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:51:17,876 - INFO - ðŸªœ Batch step - 261 -- sub batch step 1044 -- lr 3.91e-05
2025-03-02 10:51:20,028 - INFO - ðŸªœ Batch step - 261 -- sub batch step 1045 -- lr 3.91e-05
2025-03-02 10:51:22,185 - INFO - ðŸªœ Batch step - 261 -- sub batch step 1046 -- lr 3.91e-05
2025-03-02 10:51:24,844 - INFO - ðŸªœ Batch step - 261 -- sub batch step 1047 -- lr 3.91e-05
2025-03-02 10:51:26,335 - INFO - Step 261 -- ðŸ”„ Training Metrics
2025-03-02 10:51:26,336 - INFO - â”œâ”€â”€ Loss: 10.8890
2025-03-02 10:51:26,336 - INFO - â”œâ”€â”€ Learning Rate: 3.91e-05
2025-03-02 10:51:26,336 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:51:27,003 - INFO - ðŸªœ Batch step - 262 -- sub batch step 1048 -- lr 3.93e-05
2025-03-02 10:51:29,164 - INFO - ðŸªœ Batch step - 262 -- sub batch step 1049 -- lr 3.93e-05
2025-03-02 10:51:31,324 - INFO - ðŸªœ Batch step - 262 -- sub batch step 1050 -- lr 3.93e-05
2025-03-02 10:51:33,504 - INFO - ðŸªœ Batch step - 262 -- sub batch step 1051 -- lr 3.93e-05
2025-03-02 10:51:35,067 - INFO - Step 262 -- ðŸ”„ Training Metrics
2025-03-02 10:51:35,067 - INFO - â”œâ”€â”€ Loss: 10.8887
2025-03-02 10:51:35,067 - INFO - â”œâ”€â”€ Learning Rate: 3.93e-05
2025-03-02 10:51:35,067 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:51:35,751 - INFO - ðŸªœ Batch step - 263 -- sub batch step 1052 -- lr 3.94e-05
2025-03-02 10:51:37,907 - INFO - ðŸªœ Batch step - 263 -- sub batch step 1053 -- lr 3.94e-05
2025-03-02 10:51:40,060 - INFO - ðŸªœ Batch step - 263 -- sub batch step 1054 -- lr 3.94e-05
2025-03-02 10:51:42,700 - INFO - ðŸªœ Batch step - 263 -- sub batch step 1055 -- lr 3.94e-05
2025-03-02 10:51:44,268 - INFO - Step 263 -- ðŸ”„ Training Metrics
2025-03-02 10:51:44,268 - INFO - â”œâ”€â”€ Loss: 10.8866
2025-03-02 10:51:44,268 - INFO - â”œâ”€â”€ Learning Rate: 3.94e-05
2025-03-02 10:51:44,269 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:51:44,940 - INFO - ðŸªœ Batch step - 264 -- sub batch step 1056 -- lr 3.96e-05
2025-03-02 10:51:47,093 - INFO - ðŸªœ Batch step - 264 -- sub batch step 1057 -- lr 3.96e-05
2025-03-02 10:51:49,248 - INFO - ðŸªœ Batch step - 264 -- sub batch step 1058 -- lr 3.96e-05
2025-03-02 10:51:51,426 - INFO - ðŸªœ Batch step - 264 -- sub batch step 1059 -- lr 3.96e-05
2025-03-02 10:51:52,997 - INFO - Step 264 -- ðŸ”„ Training Metrics
2025-03-02 10:51:52,997 - INFO - â”œâ”€â”€ Loss: 10.8868
2025-03-02 10:51:52,997 - INFO - â”œâ”€â”€ Learning Rate: 3.96e-05
2025-03-02 10:51:52,998 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:51:53,673 - INFO - ðŸªœ Batch step - 265 -- sub batch step 1060 -- lr 3.97e-05
2025-03-02 10:51:55,824 - INFO - ðŸªœ Batch step - 265 -- sub batch step 1061 -- lr 3.97e-05
2025-03-02 10:51:57,984 - INFO - ðŸªœ Batch step - 265 -- sub batch step 1062 -- lr 3.97e-05
2025-03-02 10:52:00,722 - INFO - ðŸªœ Batch step - 265 -- sub batch step 1063 -- lr 3.97e-05
2025-03-02 10:52:02,245 - INFO - Step 265 -- ðŸ”„ Training Metrics
2025-03-02 10:52:02,246 - INFO - â”œâ”€â”€ Loss: 10.8856
2025-03-02 10:52:02,246 - INFO - â”œâ”€â”€ Learning Rate: 3.97e-05
2025-03-02 10:52:02,246 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:52:02,922 - INFO - ðŸªœ Batch step - 266 -- sub batch step 1064 -- lr 3.99e-05
2025-03-02 10:52:05,076 - INFO - ðŸªœ Batch step - 266 -- sub batch step 1065 -- lr 3.99e-05
2025-03-02 10:52:07,226 - INFO - ðŸªœ Batch step - 266 -- sub batch step 1066 -- lr 3.99e-05
2025-03-02 10:52:09,401 - INFO - ðŸªœ Batch step - 266 -- sub batch step 1067 -- lr 3.99e-05
2025-03-02 10:52:10,977 - INFO - Step 266 -- ðŸ”„ Training Metrics
2025-03-02 10:52:10,977 - INFO - â”œâ”€â”€ Loss: 10.8863
2025-03-02 10:52:10,977 - INFO - â”œâ”€â”€ Learning Rate: 3.99e-05
2025-03-02 10:52:10,977 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:52:11,646 - INFO - ðŸªœ Batch step - 267 -- sub batch step 1068 -- lr 4.00e-05
2025-03-02 10:52:13,808 - INFO - ðŸªœ Batch step - 267 -- sub batch step 1069 -- lr 4.00e-05
2025-03-02 10:52:15,962 - INFO - ðŸªœ Batch step - 267 -- sub batch step 1070 -- lr 4.00e-05
2025-03-02 10:52:18,414 - INFO - ðŸªœ Batch step - 267 -- sub batch step 1071 -- lr 4.00e-05
2025-03-02 10:52:20,160 - INFO - Step 267 -- ðŸ”„ Training Metrics
2025-03-02 10:52:20,160 - INFO - â”œâ”€â”€ Loss: 10.8839
2025-03-02 10:52:20,161 - INFO - â”œâ”€â”€ Learning Rate: 4.00e-05
2025-03-02 10:52:20,161 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:52:20,836 - INFO - ðŸªœ Batch step - 268 -- sub batch step 1072 -- lr 4.02e-05
2025-03-02 10:52:22,984 - INFO - ðŸªœ Batch step - 268 -- sub batch step 1073 -- lr 4.02e-05
2025-03-02 10:52:25,144 - INFO - ðŸªœ Batch step - 268 -- sub batch step 1074 -- lr 4.02e-05
2025-03-02 10:52:27,321 - INFO - ðŸªœ Batch step - 268 -- sub batch step 1075 -- lr 4.02e-05
2025-03-02 10:52:28,900 - INFO - Step 268 -- ðŸ”„ Training Metrics
2025-03-02 10:52:28,901 - INFO - â”œâ”€â”€ Loss: 10.8824
2025-03-02 10:52:28,901 - INFO - â”œâ”€â”€ Learning Rate: 4.02e-05
2025-03-02 10:52:28,901 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:52:29,569 - INFO - ðŸªœ Batch step - 269 -- sub batch step 1076 -- lr 4.03e-05
2025-03-02 10:52:31,730 - INFO - ðŸªœ Batch step - 269 -- sub batch step 1077 -- lr 4.03e-05
2025-03-02 10:52:33,884 - INFO - ðŸªœ Batch step - 269 -- sub batch step 1078 -- lr 4.03e-05
2025-03-02 10:52:36,288 - INFO - ðŸªœ Batch step - 269 -- sub batch step 1079 -- lr 4.03e-05
2025-03-02 10:52:38,231 - INFO - Step 269 -- ðŸ”„ Training Metrics
2025-03-02 10:52:38,231 - INFO - â”œâ”€â”€ Loss: 10.8823
2025-03-02 10:52:38,231 - INFO - â”œâ”€â”€ Learning Rate: 4.03e-05
2025-03-02 10:52:38,232 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:52:38,908 - INFO - ðŸªœ Batch step - 270 -- sub batch step 1080 -- lr 4.05e-05
2025-03-02 10:52:41,059 - INFO - ðŸªœ Batch step - 270 -- sub batch step 1081 -- lr 4.05e-05
2025-03-02 10:52:43,219 - INFO - ðŸªœ Batch step - 270 -- sub batch step 1082 -- lr 4.05e-05
2025-03-02 10:52:45,392 - INFO - ðŸªœ Batch step - 270 -- sub batch step 1083 -- lr 4.05e-05
2025-03-02 10:52:46,946 - INFO - Step 270 -- ðŸ”„ Training Metrics
2025-03-02 10:52:46,947 - INFO - â”œâ”€â”€ Loss: 10.8803
2025-03-02 10:52:46,947 - INFO - â”œâ”€â”€ Learning Rate: 4.05e-05
2025-03-02 10:52:46,947 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:52:47,622 - INFO - ðŸªœ Batch step - 271 -- sub batch step 1084 -- lr 4.06e-05
2025-03-02 10:52:49,781 - INFO - ðŸªœ Batch step - 271 -- sub batch step 1085 -- lr 4.06e-05
2025-03-02 10:52:52,501 - INFO - ðŸªœ Batch step - 271 -- sub batch step 1086 -- lr 4.06e-05
2025-03-02 10:52:54,661 - INFO - ðŸªœ Batch step - 271 -- sub batch step 1087 -- lr 4.06e-05
2025-03-02 10:52:56,314 - INFO - Step 271 -- ðŸ”„ Training Metrics
2025-03-02 10:52:56,315 - INFO - â”œâ”€â”€ Loss: 10.8817
2025-03-02 10:52:56,315 - INFO - â”œâ”€â”€ Learning Rate: 4.06e-05
2025-03-02 10:52:56,315 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:52:56,990 - INFO - ðŸªœ Batch step - 272 -- sub batch step 1088 -- lr 4.08e-05
2025-03-02 10:52:59,145 - INFO - ðŸªœ Batch step - 272 -- sub batch step 1089 -- lr 4.08e-05
2025-03-02 10:53:01,324 - INFO - ðŸªœ Batch step - 272 -- sub batch step 1090 -- lr 4.08e-05
2025-03-02 10:53:03,482 - INFO - ðŸªœ Batch step - 272 -- sub batch step 1091 -- lr 4.08e-05
2025-03-02 10:53:05,040 - INFO - Step 272 -- ðŸ”„ Training Metrics
2025-03-02 10:53:05,040 - INFO - â”œâ”€â”€ Loss: 10.8807
2025-03-02 10:53:05,041 - INFO - â”œâ”€â”€ Learning Rate: 4.08e-05
2025-03-02 10:53:05,041 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:53:05,720 - INFO - ðŸªœ Batch step - 273 -- sub batch step 1092 -- lr 4.09e-05
2025-03-02 10:53:07,871 - INFO - ðŸªœ Batch step - 273 -- sub batch step 1093 -- lr 4.09e-05
2025-03-02 10:53:10,524 - INFO - ðŸªœ Batch step - 273 -- sub batch step 1094 -- lr 4.09e-05
2025-03-02 10:53:12,679 - INFO - ðŸªœ Batch step - 273 -- sub batch step 1095 -- lr 4.09e-05
2025-03-02 10:53:14,339 - INFO - Step 273 -- ðŸ”„ Training Metrics
2025-03-02 10:53:14,340 - INFO - â”œâ”€â”€ Loss: 10.8793
2025-03-02 10:53:14,340 - INFO - â”œâ”€â”€ Learning Rate: 4.09e-05
2025-03-02 10:53:14,340 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:53:15,013 - INFO - ðŸªœ Batch step - 274 -- sub batch step 1096 -- lr 4.11e-05
2025-03-02 10:53:17,167 - INFO - ðŸªœ Batch step - 274 -- sub batch step 1097 -- lr 4.11e-05
2025-03-02 10:53:19,341 - INFO - ðŸªœ Batch step - 274 -- sub batch step 1098 -- lr 4.11e-05
2025-03-02 10:53:21,504 - INFO - ðŸªœ Batch step - 274 -- sub batch step 1099 -- lr 4.11e-05
2025-03-02 10:53:23,065 - INFO - Step 274 -- ðŸ”„ Training Metrics
2025-03-02 10:53:23,065 - INFO - â”œâ”€â”€ Loss: 10.8788
2025-03-02 10:53:23,065 - INFO - â”œâ”€â”€ Learning Rate: 4.11e-05
2025-03-02 10:53:23,065 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:53:23,740 - INFO - ðŸªœ Batch step - 275 -- sub batch step 1100 -- lr 4.12e-05
2025-03-02 10:53:25,893 - INFO - ðŸªœ Batch step - 275 -- sub batch step 1101 -- lr 4.12e-05
2025-03-02 10:53:28,564 - INFO - ðŸªœ Batch step - 275 -- sub batch step 1102 -- lr 4.12e-05
2025-03-02 10:53:30,720 - INFO - ðŸªœ Batch step - 275 -- sub batch step 1103 -- lr 4.12e-05
2025-03-02 10:53:32,386 - INFO - Step 275 -- ðŸ”„ Training Metrics
2025-03-02 10:53:32,386 - INFO - â”œâ”€â”€ Loss: 10.8781
2025-03-02 10:53:32,387 - INFO - â”œâ”€â”€ Learning Rate: 4.12e-05
2025-03-02 10:53:32,387 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:53:33,064 - INFO - ðŸªœ Batch step - 276 -- sub batch step 1104 -- lr 4.14e-05
2025-03-02 10:53:35,221 - INFO - ðŸªœ Batch step - 276 -- sub batch step 1105 -- lr 4.14e-05
2025-03-02 10:53:37,387 - INFO - ðŸªœ Batch step - 276 -- sub batch step 1106 -- lr 4.14e-05
2025-03-02 10:53:39,546 - INFO - ðŸªœ Batch step - 276 -- sub batch step 1107 -- lr 4.14e-05
2025-03-02 10:53:41,114 - INFO - Step 276 -- ðŸ”„ Training Metrics
2025-03-02 10:53:41,114 - INFO - â”œâ”€â”€ Loss: 10.8745
2025-03-02 10:53:41,114 - INFO - â”œâ”€â”€ Learning Rate: 4.14e-05
2025-03-02 10:53:41,114 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:53:41,781 - INFO - ðŸªœ Batch step - 277 -- sub batch step 1108 -- lr 4.16e-05
2025-03-02 10:53:43,935 - INFO - ðŸªœ Batch step - 277 -- sub batch step 1109 -- lr 4.16e-05
2025-03-02 10:53:46,596 - INFO - ðŸªœ Batch step - 277 -- sub batch step 1110 -- lr 4.16e-05
2025-03-02 10:53:48,748 - INFO - ðŸªœ Batch step - 277 -- sub batch step 1111 -- lr 4.16e-05
2025-03-02 10:53:51,141 - INFO - Step 277 -- ðŸ”„ Training Metrics
2025-03-02 10:53:51,142 - INFO - â”œâ”€â”€ Loss: 10.8755
2025-03-02 10:53:51,142 - INFO - â”œâ”€â”€ Learning Rate: 4.16e-05
2025-03-02 10:53:51,142 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:53:51,815 - INFO - ðŸªœ Batch step - 278 -- sub batch step 1112 -- lr 4.17e-05
2025-03-02 10:53:53,963 - INFO - ðŸªœ Batch step - 278 -- sub batch step 1113 -- lr 4.17e-05
2025-03-02 10:53:56,145 - INFO - ðŸªœ Batch step - 278 -- sub batch step 1114 -- lr 4.17e-05
2025-03-02 10:53:58,310 - INFO - ðŸªœ Batch step - 278 -- sub batch step 1115 -- lr 4.17e-05
2025-03-02 10:53:59,874 - INFO - Step 278 -- ðŸ”„ Training Metrics
2025-03-02 10:53:59,874 - INFO - â”œâ”€â”€ Loss: 10.8747
2025-03-02 10:53:59,874 - INFO - â”œâ”€â”€ Learning Rate: 4.17e-05
2025-03-02 10:53:59,874 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:54:00,548 - INFO - ðŸªœ Batch step - 279 -- sub batch step 1116 -- lr 4.19e-05
2025-03-02 10:54:02,706 - INFO - ðŸªœ Batch step - 279 -- sub batch step 1117 -- lr 4.19e-05
2025-03-02 10:54:04,989 - INFO - ðŸªœ Batch step - 279 -- sub batch step 1118 -- lr 4.19e-05
2025-03-02 10:54:07,149 - INFO - ðŸªœ Batch step - 279 -- sub batch step 1119 -- lr 4.19e-05
2025-03-02 10:54:08,712 - INFO - Step 279 -- ðŸ”„ Training Metrics
2025-03-02 10:54:08,712 - INFO - â”œâ”€â”€ Loss: 10.8736
2025-03-02 10:54:08,712 - INFO - â”œâ”€â”€ Learning Rate: 4.19e-05
2025-03-02 10:54:08,712 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:54:09,951 - INFO - ðŸªœ Batch step - 280 -- sub batch step 1120 -- lr 4.20e-05
2025-03-02 10:54:12,110 - INFO - ðŸªœ Batch step - 280 -- sub batch step 1121 -- lr 4.20e-05
2025-03-02 10:54:14,274 - INFO - ðŸªœ Batch step - 280 -- sub batch step 1122 -- lr 4.20e-05
2025-03-02 10:54:16,452 - INFO - ðŸªœ Batch step - 280 -- sub batch step 1123 -- lr 4.20e-05
2025-03-02 10:54:18,012 - INFO - Step 280 -- ðŸ”„ Training Metrics
2025-03-02 10:54:18,012 - INFO - â”œâ”€â”€ Loss: 10.8715
2025-03-02 10:54:18,013 - INFO - â”œâ”€â”€ Learning Rate: 4.20e-05
2025-03-02 10:54:18,013 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:54:18,687 - INFO - ðŸªœ Batch step - 281 -- sub batch step 1124 -- lr 4.22e-05
2025-03-02 10:54:20,841 - INFO - ðŸªœ Batch step - 281 -- sub batch step 1125 -- lr 4.22e-05
2025-03-02 10:54:22,989 - INFO - ðŸªœ Batch step - 281 -- sub batch step 1126 -- lr 4.22e-05
2025-03-02 10:54:25,496 - INFO - ðŸªœ Batch step - 281 -- sub batch step 1127 -- lr 4.22e-05
2025-03-02 10:54:27,287 - INFO - Step 281 -- ðŸ”„ Training Metrics
2025-03-02 10:54:27,288 - INFO - â”œâ”€â”€ Loss: 10.8709
2025-03-02 10:54:27,288 - INFO - â”œâ”€â”€ Learning Rate: 4.22e-05
2025-03-02 10:54:27,288 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:54:27,959 - INFO - ðŸªœ Batch step - 282 -- sub batch step 1128 -- lr 4.23e-05
2025-03-02 10:54:30,125 - INFO - ðŸªœ Batch step - 282 -- sub batch step 1129 -- lr 4.23e-05
2025-03-02 10:54:32,290 - INFO - ðŸªœ Batch step - 282 -- sub batch step 1130 -- lr 4.23e-05
2025-03-02 10:54:34,464 - INFO - ðŸªœ Batch step - 282 -- sub batch step 1131 -- lr 4.23e-05
2025-03-02 10:54:36,016 - INFO - Step 282 -- ðŸ”„ Training Metrics
2025-03-02 10:54:36,016 - INFO - â”œâ”€â”€ Loss: 10.8691
2025-03-02 10:54:36,016 - INFO - â”œâ”€â”€ Learning Rate: 4.23e-05
2025-03-02 10:54:36,016 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:54:36,691 - INFO - ðŸªœ Batch step - 283 -- sub batch step 1132 -- lr 4.24e-05
2025-03-02 10:54:38,843 - INFO - ðŸªœ Batch step - 283 -- sub batch step 1133 -- lr 4.24e-05
2025-03-02 10:54:40,999 - INFO - ðŸªœ Batch step - 283 -- sub batch step 1134 -- lr 4.24e-05
2025-03-02 10:54:43,637 - INFO - ðŸªœ Batch step - 283 -- sub batch step 1135 -- lr 4.24e-05
2025-03-02 10:54:45,383 - INFO - Step 283 -- ðŸ”„ Training Metrics
2025-03-02 10:54:45,383 - INFO - â”œâ”€â”€ Loss: 10.8680
2025-03-02 10:54:45,383 - INFO - â”œâ”€â”€ Learning Rate: 4.24e-05
2025-03-02 10:54:45,383 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:54:46,055 - INFO - ðŸªœ Batch step - 284 -- sub batch step 1136 -- lr 4.26e-05
2025-03-02 10:54:48,209 - INFO - ðŸªœ Batch step - 284 -- sub batch step 1137 -- lr 4.26e-05
2025-03-02 10:54:50,367 - INFO - ðŸªœ Batch step - 284 -- sub batch step 1138 -- lr 4.26e-05
2025-03-02 10:54:52,546 - INFO - ðŸªœ Batch step - 284 -- sub batch step 1139 -- lr 4.26e-05
2025-03-02 10:54:54,107 - INFO - Step 284 -- ðŸ”„ Training Metrics
2025-03-02 10:54:54,108 - INFO - â”œâ”€â”€ Loss: 10.8684
2025-03-02 10:54:54,108 - INFO - â”œâ”€â”€ Learning Rate: 4.26e-05
2025-03-02 10:54:54,108 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:54:54,781 - INFO - ðŸªœ Batch step - 285 -- sub batch step 1140 -- lr 4.27e-05
2025-03-02 10:54:56,935 - INFO - ðŸªœ Batch step - 285 -- sub batch step 1141 -- lr 4.27e-05
2025-03-02 10:54:59,114 - INFO - ðŸªœ Batch step - 285 -- sub batch step 1142 -- lr 4.27e-05
2025-03-02 10:55:01,799 - INFO - ðŸªœ Batch step - 285 -- sub batch step 1143 -- lr 4.27e-05
2025-03-02 10:55:03,683 - INFO - Step 285 -- ðŸ”„ Training Metrics
2025-03-02 10:55:03,684 - INFO - â”œâ”€â”€ Loss: 10.8693
2025-03-02 10:55:03,684 - INFO - â”œâ”€â”€ Learning Rate: 4.27e-05
2025-03-02 10:55:03,684 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:55:04,367 - INFO - ðŸªœ Batch step - 286 -- sub batch step 1144 -- lr 4.29e-05
2025-03-02 10:55:06,526 - INFO - ðŸªœ Batch step - 286 -- sub batch step 1145 -- lr 4.29e-05
2025-03-02 10:55:08,684 - INFO - ðŸªœ Batch step - 286 -- sub batch step 1146 -- lr 4.29e-05
2025-03-02 10:55:10,865 - INFO - ðŸªœ Batch step - 286 -- sub batch step 1147 -- lr 4.29e-05
2025-03-02 10:55:12,407 - INFO - Step 286 -- ðŸ”„ Training Metrics
2025-03-02 10:55:12,407 - INFO - â”œâ”€â”€ Loss: 10.8663
2025-03-02 10:55:12,407 - INFO - â”œâ”€â”€ Learning Rate: 4.29e-05
2025-03-02 10:55:12,407 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:55:13,079 - INFO - ðŸªœ Batch step - 287 -- sub batch step 1148 -- lr 4.30e-05
2025-03-02 10:55:15,235 - INFO - ðŸªœ Batch step - 287 -- sub batch step 1149 -- lr 4.30e-05
2025-03-02 10:55:17,395 - INFO - ðŸªœ Batch step - 287 -- sub batch step 1150 -- lr 4.30e-05
2025-03-02 10:55:20,075 - INFO - ðŸªœ Batch step - 287 -- sub batch step 1151 -- lr 4.30e-05
2025-03-02 10:55:21,738 - INFO - Step 287 -- ðŸ”„ Training Metrics
2025-03-02 10:55:21,738 - INFO - â”œâ”€â”€ Loss: 10.8673
2025-03-02 10:55:21,738 - INFO - â”œâ”€â”€ Learning Rate: 4.30e-05
2025-03-02 10:55:21,738 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:55:22,411 - INFO - ðŸªœ Batch step - 288 -- sub batch step 1152 -- lr 4.32e-05
2025-03-02 10:55:24,563 - INFO - ðŸªœ Batch step - 288 -- sub batch step 1153 -- lr 4.32e-05
2025-03-02 10:55:26,721 - INFO - ðŸªœ Batch step - 288 -- sub batch step 1154 -- lr 4.32e-05
2025-03-02 10:55:28,908 - INFO - ðŸªœ Batch step - 288 -- sub batch step 1155 -- lr 4.32e-05
2025-03-02 10:55:30,480 - INFO - Step 288 -- ðŸ”„ Training Metrics
2025-03-02 10:55:30,481 - INFO - â”œâ”€â”€ Loss: 10.8646
2025-03-02 10:55:30,481 - INFO - â”œâ”€â”€ Learning Rate: 4.32e-05
2025-03-02 10:55:30,481 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:55:31,155 - INFO - ðŸªœ Batch step - 289 -- sub batch step 1156 -- lr 4.33e-05
2025-03-02 10:55:33,318 - INFO - ðŸªœ Batch step - 289 -- sub batch step 1157 -- lr 4.33e-05
2025-03-02 10:55:35,470 - INFO - ðŸªœ Batch step - 289 -- sub batch step 1158 -- lr 4.33e-05
2025-03-02 10:55:37,861 - INFO - ðŸªœ Batch step - 289 -- sub batch step 1159 -- lr 4.33e-05
2025-03-02 10:55:39,920 - INFO - Step 289 -- ðŸ”„ Training Metrics
2025-03-02 10:55:39,920 - INFO - â”œâ”€â”€ Loss: 10.8651
2025-03-02 10:55:39,920 - INFO - â”œâ”€â”€ Learning Rate: 4.33e-05
2025-03-02 10:55:39,921 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:55:40,599 - INFO - ðŸªœ Batch step - 290 -- sub batch step 1160 -- lr 4.35e-05
2025-03-02 10:55:42,748 - INFO - ðŸªœ Batch step - 290 -- sub batch step 1161 -- lr 4.35e-05
2025-03-02 10:55:44,906 - INFO - ðŸªœ Batch step - 290 -- sub batch step 1162 -- lr 4.35e-05
2025-03-02 10:55:47,071 - INFO - ðŸªœ Batch step - 290 -- sub batch step 1163 -- lr 4.35e-05
2025-03-02 10:55:48,658 - INFO - Step 290 -- ðŸ”„ Training Metrics
2025-03-02 10:55:48,658 - INFO - â”œâ”€â”€ Loss: 10.8638
2025-03-02 10:55:48,659 - INFO - â”œâ”€â”€ Learning Rate: 4.35e-05
2025-03-02 10:55:48,659 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:55:49,336 - INFO - ðŸªœ Batch step - 291 -- sub batch step 1164 -- lr 4.36e-05
2025-03-02 10:55:51,490 - INFO - ðŸªœ Batch step - 291 -- sub batch step 1165 -- lr 4.36e-05
2025-03-02 10:55:53,889 - INFO - ðŸªœ Batch step - 291 -- sub batch step 1166 -- lr 4.36e-05
2025-03-02 10:55:56,049 - INFO - ðŸªœ Batch step - 291 -- sub batch step 1167 -- lr 4.36e-05
2025-03-02 10:55:57,959 - INFO - Step 291 -- ðŸ”„ Training Metrics
2025-03-02 10:55:57,959 - INFO - â”œâ”€â”€ Loss: 10.8627
2025-03-02 10:55:57,959 - INFO - â”œâ”€â”€ Learning Rate: 4.36e-05
2025-03-02 10:55:57,959 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:55:58,630 - INFO - ðŸªœ Batch step - 292 -- sub batch step 1168 -- lr 4.38e-05
2025-03-02 10:56:00,794 - INFO - ðŸªœ Batch step - 292 -- sub batch step 1169 -- lr 4.38e-05
2025-03-02 10:56:02,971 - INFO - ðŸªœ Batch step - 292 -- sub batch step 1170 -- lr 4.38e-05
2025-03-02 10:56:05,121 - INFO - ðŸªœ Batch step - 292 -- sub batch step 1171 -- lr 4.38e-05
2025-03-02 10:56:06,693 - INFO - Step 292 -- ðŸ”„ Training Metrics
2025-03-02 10:56:06,693 - INFO - â”œâ”€â”€ Loss: 10.8619
2025-03-02 10:56:06,693 - INFO - â”œâ”€â”€ Learning Rate: 4.38e-05
2025-03-02 10:56:06,693 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:56:07,372 - INFO - ðŸªœ Batch step - 293 -- sub batch step 1172 -- lr 4.39e-05
2025-03-02 10:56:09,522 - INFO - ðŸªœ Batch step - 293 -- sub batch step 1173 -- lr 4.39e-05
2025-03-02 10:56:12,112 - INFO - ðŸªœ Batch step - 293 -- sub batch step 1174 -- lr 4.39e-05
2025-03-02 10:56:14,271 - INFO - ðŸªœ Batch step - 293 -- sub batch step 1175 -- lr 4.39e-05
2025-03-02 10:56:16,050 - INFO - Step 293 -- ðŸ”„ Training Metrics
2025-03-02 10:56:16,050 - INFO - â”œâ”€â”€ Loss: 10.8611
2025-03-02 10:56:16,050 - INFO - â”œâ”€â”€ Learning Rate: 4.39e-05
2025-03-02 10:56:16,050 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:56:16,719 - INFO - ðŸªœ Batch step - 294 -- sub batch step 1176 -- lr 4.41e-05
2025-03-02 10:56:18,876 - INFO - ðŸªœ Batch step - 294 -- sub batch step 1177 -- lr 4.41e-05
2025-03-02 10:56:21,040 - INFO - ðŸªœ Batch step - 294 -- sub batch step 1178 -- lr 4.41e-05
2025-03-02 10:56:23,200 - INFO - ðŸªœ Batch step - 294 -- sub batch step 1179 -- lr 4.41e-05
2025-03-02 10:56:24,778 - INFO - Step 294 -- ðŸ”„ Training Metrics
2025-03-02 10:56:24,778 - INFO - â”œâ”€â”€ Loss: 10.8586
2025-03-02 10:56:24,778 - INFO - â”œâ”€â”€ Learning Rate: 4.41e-05
2025-03-02 10:56:24,778 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:56:25,451 - INFO - ðŸªœ Batch step - 295 -- sub batch step 1180 -- lr 4.42e-05
2025-03-02 10:56:27,606 - INFO - ðŸªœ Batch step - 295 -- sub batch step 1181 -- lr 4.42e-05
2025-03-02 10:56:30,281 - INFO - ðŸªœ Batch step - 295 -- sub batch step 1182 -- lr 4.42e-05
2025-03-02 10:56:32,428 - INFO - ðŸªœ Batch step - 295 -- sub batch step 1183 -- lr 4.42e-05
2025-03-02 10:56:34,054 - INFO - Step 295 -- ðŸ”„ Training Metrics
2025-03-02 10:56:34,054 - INFO - â”œâ”€â”€ Loss: 10.8583
2025-03-02 10:56:34,054 - INFO - â”œâ”€â”€ Learning Rate: 4.42e-05
2025-03-02 10:56:34,054 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:56:34,731 - INFO - ðŸªœ Batch step - 296 -- sub batch step 1184 -- lr 4.44e-05
2025-03-02 10:56:36,882 - INFO - ðŸªœ Batch step - 296 -- sub batch step 1185 -- lr 4.44e-05
2025-03-02 10:56:39,049 - INFO - ðŸªœ Batch step - 296 -- sub batch step 1186 -- lr 4.44e-05
2025-03-02 10:56:41,205 - INFO - ðŸªœ Batch step - 296 -- sub batch step 1187 -- lr 4.44e-05
2025-03-02 10:56:42,797 - INFO - Step 296 -- ðŸ”„ Training Metrics
2025-03-02 10:56:42,798 - INFO - â”œâ”€â”€ Loss: 10.8564
2025-03-02 10:56:42,798 - INFO - â”œâ”€â”€ Learning Rate: 4.44e-05
2025-03-02 10:56:42,798 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:56:43,466 - INFO - ðŸªœ Batch step - 297 -- sub batch step 1188 -- lr 4.45e-05
2025-03-02 10:56:45,623 - INFO - ðŸªœ Batch step - 297 -- sub batch step 1189 -- lr 4.45e-05
2025-03-02 10:56:48,274 - INFO - ðŸªœ Batch step - 297 -- sub batch step 1190 -- lr 4.45e-05
2025-03-02 10:56:50,435 - INFO - ðŸªœ Batch step - 297 -- sub batch step 1191 -- lr 4.45e-05
2025-03-02 10:56:52,105 - INFO - Step 297 -- ðŸ”„ Training Metrics
2025-03-02 10:56:52,105 - INFO - â”œâ”€â”€ Loss: 10.8567
2025-03-02 10:56:52,105 - INFO - â”œâ”€â”€ Learning Rate: 4.45e-05
2025-03-02 10:56:52,105 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:56:52,782 - INFO - ðŸªœ Batch step - 298 -- sub batch step 1192 -- lr 4.47e-05
2025-03-02 10:56:54,931 - INFO - ðŸªœ Batch step - 298 -- sub batch step 1193 -- lr 4.47e-05
2025-03-02 10:56:57,107 - INFO - ðŸªœ Batch step - 298 -- sub batch step 1194 -- lr 4.47e-05
2025-03-02 10:56:59,259 - INFO - ðŸªœ Batch step - 298 -- sub batch step 1195 -- lr 4.47e-05
2025-03-02 10:57:00,849 - INFO - Step 298 -- ðŸ”„ Training Metrics
2025-03-02 10:57:00,849 - INFO - â”œâ”€â”€ Loss: 10.8576
2025-03-02 10:57:00,849 - INFO - â”œâ”€â”€ Learning Rate: 4.47e-05
2025-03-02 10:57:00,849 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:57:01,515 - INFO - ðŸªœ Batch step - 299 -- sub batch step 1196 -- lr 4.48e-05
2025-03-02 10:57:03,671 - INFO - ðŸªœ Batch step - 299 -- sub batch step 1197 -- lr 4.48e-05
2025-03-02 10:57:05,946 - INFO - ðŸªœ Batch step - 299 -- sub batch step 1198 -- lr 4.48e-05
2025-03-02 10:57:08,107 - INFO - ðŸªœ Batch step - 299 -- sub batch step 1199 -- lr 4.48e-05
2025-03-02 10:57:09,692 - INFO - Step 299 -- ðŸ”„ Training Metrics
2025-03-02 10:57:09,692 - INFO - â”œâ”€â”€ Loss: 10.8560
2025-03-02 10:57:09,692 - INFO - â”œâ”€â”€ Learning Rate: 4.48e-05
2025-03-02 10:57:09,692 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:57:10,942 - INFO - ðŸªœ Batch step - 300 -- sub batch step 1200 -- lr 4.50e-05
2025-03-02 10:57:13,105 - INFO - ðŸªœ Batch step - 300 -- sub batch step 1201 -- lr 4.50e-05
2025-03-02 10:57:15,273 - INFO - ðŸªœ Batch step - 300 -- sub batch step 1202 -- lr 4.50e-05
2025-03-02 10:57:17,454 - INFO - ðŸªœ Batch step - 300 -- sub batch step 1203 -- lr 4.50e-05
2025-03-02 10:57:19,049 - INFO - Step 300 -- ðŸ”„ Training Metrics
2025-03-02 10:57:19,049 - INFO - â”œâ”€â”€ Loss: 10.8513
2025-03-02 10:57:19,049 - INFO - â”œâ”€â”€ Learning Rate: 4.50e-05
2025-03-02 10:57:19,049 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:57:19,727 - INFO - ðŸªœ Batch step - 301 -- sub batch step 1204 -- lr 4.51e-05
2025-03-02 10:57:21,883 - INFO - ðŸªœ Batch step - 301 -- sub batch step 1205 -- lr 4.51e-05
2025-03-02 10:57:24,031 - INFO - ðŸªœ Batch step - 301 -- sub batch step 1206 -- lr 4.51e-05
2025-03-02 10:57:26,846 - INFO - ðŸªœ Batch step - 301 -- sub batch step 1207 -- lr 4.51e-05
2025-03-02 10:57:28,565 - INFO - Step 301 -- ðŸ”„ Training Metrics
2025-03-02 10:57:28,565 - INFO - â”œâ”€â”€ Loss: 10.8503
2025-03-02 10:57:28,566 - INFO - â”œâ”€â”€ Learning Rate: 4.51e-05
2025-03-02 10:57:28,566 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:57:29,235 - INFO - ðŸªœ Batch step - 302 -- sub batch step 1208 -- lr 4.53e-05
2025-03-02 10:57:31,392 - INFO - ðŸªœ Batch step - 302 -- sub batch step 1209 -- lr 4.53e-05
2025-03-02 10:57:33,547 - INFO - ðŸªœ Batch step - 302 -- sub batch step 1210 -- lr 4.53e-05
2025-03-02 10:57:35,713 - INFO - ðŸªœ Batch step - 302 -- sub batch step 1211 -- lr 4.53e-05
2025-03-02 10:57:37,299 - INFO - Step 302 -- ðŸ”„ Training Metrics
2025-03-02 10:57:37,299 - INFO - â”œâ”€â”€ Loss: 10.8504
2025-03-02 10:57:37,299 - INFO - â”œâ”€â”€ Learning Rate: 4.53e-05
2025-03-02 10:57:37,299 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:57:37,972 - INFO - ðŸªœ Batch step - 303 -- sub batch step 1212 -- lr 4.54e-05
2025-03-02 10:57:40,123 - INFO - ðŸªœ Batch step - 303 -- sub batch step 1213 -- lr 4.54e-05
2025-03-02 10:57:42,281 - INFO - ðŸªœ Batch step - 303 -- sub batch step 1214 -- lr 4.54e-05
2025-03-02 10:57:45,120 - INFO - ðŸªœ Batch step - 303 -- sub batch step 1215 -- lr 4.54e-05
2025-03-02 10:57:46,612 - INFO - Step 303 -- ðŸ”„ Training Metrics
2025-03-02 10:57:46,612 - INFO - â”œâ”€â”€ Loss: 10.8495
2025-03-02 10:57:46,612 - INFO - â”œâ”€â”€ Learning Rate: 4.54e-05
2025-03-02 10:57:46,612 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:57:47,279 - INFO - ðŸªœ Batch step - 304 -- sub batch step 1216 -- lr 4.56e-05
2025-03-02 10:57:49,438 - INFO - ðŸªœ Batch step - 304 -- sub batch step 1217 -- lr 4.56e-05
2025-03-02 10:57:51,587 - INFO - ðŸªœ Batch step - 304 -- sub batch step 1218 -- lr 4.56e-05
2025-03-02 10:57:53,765 - INFO - ðŸªœ Batch step - 304 -- sub batch step 1219 -- lr 4.56e-05
2025-03-02 10:57:55,355 - INFO - Step 304 -- ðŸ”„ Training Metrics
2025-03-02 10:57:55,355 - INFO - â”œâ”€â”€ Loss: 10.8485
2025-03-02 10:57:55,355 - INFO - â”œâ”€â”€ Learning Rate: 4.56e-05
2025-03-02 10:57:55,355 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:57:56,034 - INFO - ðŸªœ Batch step - 305 -- sub batch step 1220 -- lr 4.57e-05
2025-03-02 10:57:58,186 - INFO - ðŸªœ Batch step - 305 -- sub batch step 1221 -- lr 4.57e-05
2025-03-02 10:58:00,343 - INFO - ðŸªœ Batch step - 305 -- sub batch step 1222 -- lr 4.57e-05
2025-03-02 10:58:02,936 - INFO - ðŸªœ Batch step - 305 -- sub batch step 1223 -- lr 4.57e-05
2025-03-02 10:58:04,486 - INFO - Step 305 -- ðŸ”„ Training Metrics
2025-03-02 10:58:04,487 - INFO - â”œâ”€â”€ Loss: 10.8491
2025-03-02 10:58:04,487 - INFO - â”œâ”€â”€ Learning Rate: 4.57e-05
2025-03-02 10:58:04,487 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:58:05,163 - INFO - ðŸªœ Batch step - 306 -- sub batch step 1224 -- lr 4.59e-05
2025-03-02 10:58:07,319 - INFO - ðŸªœ Batch step - 306 -- sub batch step 1225 -- lr 4.59e-05
2025-03-02 10:58:09,462 - INFO - ðŸªœ Batch step - 306 -- sub batch step 1226 -- lr 4.59e-05
2025-03-02 10:58:11,640 - INFO - ðŸªœ Batch step - 306 -- sub batch step 1227 -- lr 4.59e-05
2025-03-02 10:58:13,236 - INFO - Step 306 -- ðŸ”„ Training Metrics
2025-03-02 10:58:13,236 - INFO - â”œâ”€â”€ Loss: 10.8477
2025-03-02 10:58:13,236 - INFO - â”œâ”€â”€ Learning Rate: 4.59e-05
2025-03-02 10:58:13,236 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:58:13,903 - INFO - ðŸªœ Batch step - 307 -- sub batch step 1228 -- lr 4.60e-05
2025-03-02 10:58:16,067 - INFO - ðŸªœ Batch step - 307 -- sub batch step 1229 -- lr 4.60e-05
2025-03-02 10:58:18,222 - INFO - ðŸªœ Batch step - 307 -- sub batch step 1230 -- lr 4.60e-05
2025-03-02 10:58:20,659 - INFO - ðŸªœ Batch step - 307 -- sub batch step 1231 -- lr 4.60e-05
2025-03-02 10:58:22,383 - INFO - Step 307 -- ðŸ”„ Training Metrics
2025-03-02 10:58:22,383 - INFO - â”œâ”€â”€ Loss: 10.8459
2025-03-02 10:58:22,383 - INFO - â”œâ”€â”€ Learning Rate: 4.60e-05
2025-03-02 10:58:22,384 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:58:23,057 - INFO - ðŸªœ Batch step - 308 -- sub batch step 1232 -- lr 4.62e-05
2025-03-02 10:58:25,213 - INFO - ðŸªœ Batch step - 308 -- sub batch step 1233 -- lr 4.62e-05
2025-03-02 10:58:27,367 - INFO - ðŸªœ Batch step - 308 -- sub batch step 1234 -- lr 4.62e-05
2025-03-02 10:58:29,542 - INFO - ðŸªœ Batch step - 308 -- sub batch step 1235 -- lr 4.62e-05
2025-03-02 10:58:31,126 - INFO - Step 308 -- ðŸ”„ Training Metrics
2025-03-02 10:58:31,126 - INFO - â”œâ”€â”€ Loss: 10.8436
2025-03-02 10:58:31,127 - INFO - â”œâ”€â”€ Learning Rate: 4.62e-05
2025-03-02 10:58:31,127 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:58:31,795 - INFO - ðŸªœ Batch step - 309 -- sub batch step 1236 -- lr 4.63e-05
2025-03-02 10:58:33,954 - INFO - ðŸªœ Batch step - 309 -- sub batch step 1237 -- lr 4.63e-05
2025-03-02 10:58:36,101 - INFO - ðŸªœ Batch step - 309 -- sub batch step 1238 -- lr 4.63e-05
2025-03-02 10:58:38,909 - INFO - ðŸªœ Batch step - 309 -- sub batch step 1239 -- lr 4.63e-05
2025-03-02 10:58:40,401 - INFO - Step 309 -- ðŸ”„ Training Metrics
2025-03-02 10:58:40,401 - INFO - â”œâ”€â”€ Loss: 10.8426
2025-03-02 10:58:40,401 - INFO - â”œâ”€â”€ Learning Rate: 4.63e-05
2025-03-02 10:58:40,402 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:58:41,073 - INFO - ðŸªœ Batch step - 310 -- sub batch step 1240 -- lr 4.65e-05
2025-03-02 10:58:43,221 - INFO - ðŸªœ Batch step - 310 -- sub batch step 1241 -- lr 4.65e-05
2025-03-02 10:58:45,377 - INFO - ðŸªœ Batch step - 310 -- sub batch step 1242 -- lr 4.65e-05
2025-03-02 10:58:47,543 - INFO - ðŸªœ Batch step - 310 -- sub batch step 1243 -- lr 4.65e-05
2025-03-02 10:58:49,138 - INFO - Step 310 -- ðŸ”„ Training Metrics
2025-03-02 10:58:49,138 - INFO - â”œâ”€â”€ Loss: 10.8437
2025-03-02 10:58:49,138 - INFO - â”œâ”€â”€ Learning Rate: 4.65e-05
2025-03-02 10:58:49,138 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:58:49,813 - INFO - ðŸªœ Batch step - 311 -- sub batch step 1244 -- lr 4.66e-05
2025-03-02 10:58:51,965 - INFO - ðŸªœ Batch step - 311 -- sub batch step 1245 -- lr 4.66e-05
2025-03-02 10:58:54,652 - INFO - ðŸªœ Batch step - 311 -- sub batch step 1246 -- lr 4.66e-05
2025-03-02 10:58:56,813 - INFO - ðŸªœ Batch step - 311 -- sub batch step 1247 -- lr 4.66e-05
2025-03-02 10:58:58,366 - INFO - Step 311 -- ðŸ”„ Training Metrics
2025-03-02 10:58:58,367 - INFO - â”œâ”€â”€ Loss: 10.8416
2025-03-02 10:58:58,367 - INFO - â”œâ”€â”€ Learning Rate: 4.66e-05
2025-03-02 10:58:58,367 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:58:59,032 - INFO - ðŸªœ Batch step - 312 -- sub batch step 1248 -- lr 4.68e-05
2025-03-02 10:59:01,184 - INFO - ðŸªœ Batch step - 312 -- sub batch step 1249 -- lr 4.68e-05
2025-03-02 10:59:03,358 - INFO - ðŸªœ Batch step - 312 -- sub batch step 1250 -- lr 4.68e-05
2025-03-02 10:59:05,507 - INFO - ðŸªœ Batch step - 312 -- sub batch step 1251 -- lr 4.68e-05
2025-03-02 10:59:07,106 - INFO - Step 312 -- ðŸ”„ Training Metrics
2025-03-02 10:59:07,107 - INFO - â”œâ”€â”€ Loss: 10.8407
2025-03-02 10:59:07,107 - INFO - â”œâ”€â”€ Learning Rate: 4.68e-05
2025-03-02 10:59:07,107 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:59:07,780 - INFO - ðŸªœ Batch step - 313 -- sub batch step 1252 -- lr 4.69e-05
2025-03-02 10:59:09,928 - INFO - ðŸªœ Batch step - 313 -- sub batch step 1253 -- lr 4.69e-05
2025-03-02 10:59:12,563 - INFO - ðŸªœ Batch step - 313 -- sub batch step 1254 -- lr 4.69e-05
2025-03-02 10:59:14,720 - INFO - ðŸªœ Batch step - 313 -- sub batch step 1255 -- lr 4.69e-05
2025-03-02 10:59:16,384 - INFO - Step 313 -- ðŸ”„ Training Metrics
2025-03-02 10:59:16,384 - INFO - â”œâ”€â”€ Loss: 10.8402
2025-03-02 10:59:16,385 - INFO - â”œâ”€â”€ Learning Rate: 4.69e-05
2025-03-02 10:59:16,385 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:59:17,053 - INFO - ðŸªœ Batch step - 314 -- sub batch step 1256 -- lr 4.71e-05
2025-03-02 10:59:19,206 - INFO - ðŸªœ Batch step - 314 -- sub batch step 1257 -- lr 4.71e-05
2025-03-02 10:59:21,373 - INFO - ðŸªœ Batch step - 314 -- sub batch step 1258 -- lr 4.71e-05
2025-03-02 10:59:23,526 - INFO - ðŸªœ Batch step - 314 -- sub batch step 1259 -- lr 4.71e-05
2025-03-02 10:59:25,124 - INFO - Step 314 -- ðŸ”„ Training Metrics
2025-03-02 10:59:25,124 - INFO - â”œâ”€â”€ Loss: 10.8382
2025-03-02 10:59:25,124 - INFO - â”œâ”€â”€ Learning Rate: 4.71e-05
2025-03-02 10:59:25,124 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:59:25,803 - INFO - ðŸªœ Batch step - 315 -- sub batch step 1260 -- lr 4.72e-05
2025-03-02 10:59:27,953 - INFO - ðŸªœ Batch step - 315 -- sub batch step 1261 -- lr 4.72e-05
2025-03-02 10:59:30,363 - INFO - ðŸªœ Batch step - 315 -- sub batch step 1262 -- lr 4.72e-05
2025-03-02 10:59:32,510 - INFO - ðŸªœ Batch step - 315 -- sub batch step 1263 -- lr 4.72e-05
2025-03-02 10:59:34,480 - INFO - Step 315 -- ðŸ”„ Training Metrics
2025-03-02 10:59:34,480 - INFO - â”œâ”€â”€ Loss: 10.8383
2025-03-02 10:59:34,480 - INFO - â”œâ”€â”€ Learning Rate: 4.72e-05
2025-03-02 10:59:34,481 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:59:35,156 - INFO - ðŸªœ Batch step - 316 -- sub batch step 1264 -- lr 4.74e-05
2025-03-02 10:59:37,312 - INFO - ðŸªœ Batch step - 316 -- sub batch step 1265 -- lr 4.74e-05
2025-03-02 10:59:39,482 - INFO - ðŸªœ Batch step - 316 -- sub batch step 1266 -- lr 4.74e-05
2025-03-02 10:59:41,638 - INFO - ðŸªœ Batch step - 316 -- sub batch step 1267 -- lr 4.74e-05
2025-03-02 10:59:43,225 - INFO - Step 316 -- ðŸ”„ Training Metrics
2025-03-02 10:59:43,226 - INFO - â”œâ”€â”€ Loss: 10.8364
2025-03-02 10:59:43,226 - INFO - â”œâ”€â”€ Learning Rate: 4.74e-05
2025-03-02 10:59:43,226 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:59:43,897 - INFO - ðŸªœ Batch step - 317 -- sub batch step 1268 -- lr 4.75e-05
2025-03-02 10:59:46,057 - INFO - ðŸªœ Batch step - 317 -- sub batch step 1269 -- lr 4.75e-05
2025-03-02 10:59:48,728 - INFO - ðŸªœ Batch step - 317 -- sub batch step 1270 -- lr 4.75e-05
2025-03-02 10:59:50,880 - INFO - ðŸªœ Batch step - 317 -- sub batch step 1271 -- lr 4.75e-05
2025-03-02 10:59:52,367 - INFO - Step 317 -- ðŸ”„ Training Metrics
2025-03-02 10:59:52,368 - INFO - â”œâ”€â”€ Loss: 10.8365
2025-03-02 10:59:52,368 - INFO - â”œâ”€â”€ Learning Rate: 4.75e-05
2025-03-02 10:59:52,368 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 10:59:53,042 - INFO - ðŸªœ Batch step - 318 -- sub batch step 1272 -- lr 4.77e-05
2025-03-02 10:59:55,192 - INFO - ðŸªœ Batch step - 318 -- sub batch step 1273 -- lr 4.77e-05
2025-03-02 10:59:57,365 - INFO - ðŸªœ Batch step - 318 -- sub batch step 1274 -- lr 4.77e-05
2025-03-02 10:59:59,521 - INFO - ðŸªœ Batch step - 318 -- sub batch step 1275 -- lr 4.77e-05
2025-03-02 11:00:01,118 - INFO - Step 318 -- ðŸ”„ Training Metrics
2025-03-02 11:00:01,118 - INFO - â”œâ”€â”€ Loss: 10.8355
2025-03-02 11:00:01,118 - INFO - â”œâ”€â”€ Learning Rate: 4.77e-05
2025-03-02 11:00:01,119 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:00:01,785 - INFO - ðŸªœ Batch step - 319 -- sub batch step 1276 -- lr 4.78e-05
2025-03-02 11:00:03,942 - INFO - ðŸªœ Batch step - 319 -- sub batch step 1277 -- lr 4.78e-05
2025-03-02 11:00:06,296 - INFO - ðŸªœ Batch step - 319 -- sub batch step 1278 -- lr 4.78e-05
2025-03-02 11:00:08,448 - INFO - ðŸªœ Batch step - 319 -- sub batch step 1279 -- lr 4.78e-05
2025-03-02 11:00:10,087 - INFO - Step 319 -- ðŸ”„ Training Metrics
2025-03-02 11:00:10,088 - INFO - â”œâ”€â”€ Loss: 10.8349
2025-03-02 11:00:10,088 - INFO - â”œâ”€â”€ Learning Rate: 4.78e-05
2025-03-02 11:00:10,088 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:00:11,340 - INFO - ðŸªœ Batch step - 320 -- sub batch step 1280 -- lr 4.80e-05
2025-03-02 11:00:13,494 - INFO - ðŸªœ Batch step - 320 -- sub batch step 1281 -- lr 4.80e-05
2025-03-02 11:00:15,650 - INFO - ðŸªœ Batch step - 320 -- sub batch step 1282 -- lr 4.80e-05
2025-03-02 11:00:17,823 - INFO - ðŸªœ Batch step - 320 -- sub batch step 1283 -- lr 4.80e-05
2025-03-02 11:00:19,576 - INFO - Step 320 -- ðŸ”„ Training Metrics
2025-03-02 11:00:19,576 - INFO - â”œâ”€â”€ Loss: 10.8322
2025-03-02 11:00:19,576 - INFO - â”œâ”€â”€ Learning Rate: 4.80e-05
2025-03-02 11:00:19,576 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:00:20,250 - INFO - ðŸªœ Batch step - 321 -- sub batch step 1284 -- lr 4.81e-05
2025-03-02 11:00:22,404 - INFO - ðŸªœ Batch step - 321 -- sub batch step 1285 -- lr 4.81e-05
2025-03-02 11:00:24,551 - INFO - ðŸªœ Batch step - 321 -- sub batch step 1286 -- lr 4.81e-05
2025-03-02 11:00:27,139 - INFO - ðŸªœ Batch step - 321 -- sub batch step 1287 -- lr 4.81e-05
2025-03-02 11:00:28,743 - INFO - Step 321 -- ðŸ”„ Training Metrics
2025-03-02 11:00:28,743 - INFO - â”œâ”€â”€ Loss: 10.8319
2025-03-02 11:00:28,743 - INFO - â”œâ”€â”€ Learning Rate: 4.81e-05
2025-03-02 11:00:28,744 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:00:29,409 - INFO - ðŸªœ Batch step - 322 -- sub batch step 1288 -- lr 4.83e-05
2025-03-02 11:00:31,563 - INFO - ðŸªœ Batch step - 322 -- sub batch step 1289 -- lr 4.83e-05
2025-03-02 11:00:33,714 - INFO - ðŸªœ Batch step - 322 -- sub batch step 1290 -- lr 4.83e-05
2025-03-02 11:00:35,885 - INFO - ðŸªœ Batch step - 322 -- sub batch step 1291 -- lr 4.83e-05
2025-03-02 11:00:37,485 - INFO - Step 322 -- ðŸ”„ Training Metrics
2025-03-02 11:00:37,485 - INFO - â”œâ”€â”€ Loss: 10.8311
2025-03-02 11:00:37,486 - INFO - â”œâ”€â”€ Learning Rate: 4.83e-05
2025-03-02 11:00:37,486 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:00:38,158 - INFO - ðŸªœ Batch step - 323 -- sub batch step 1292 -- lr 4.84e-05
2025-03-02 11:00:40,306 - INFO - ðŸªœ Batch step - 323 -- sub batch step 1293 -- lr 4.84e-05
2025-03-02 11:00:42,457 - INFO - ðŸªœ Batch step - 323 -- sub batch step 1294 -- lr 4.84e-05
2025-03-02 11:00:44,816 - INFO - ðŸªœ Batch step - 323 -- sub batch step 1295 -- lr 4.84e-05
2025-03-02 11:00:46,649 - INFO - Step 323 -- ðŸ”„ Training Metrics
2025-03-02 11:00:46,649 - INFO - â”œâ”€â”€ Loss: 10.8292
2025-03-02 11:00:46,649 - INFO - â”œâ”€â”€ Learning Rate: 4.84e-05
2025-03-02 11:00:46,649 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:00:47,316 - INFO - ðŸªœ Batch step - 324 -- sub batch step 1296 -- lr 4.86e-05
2025-03-02 11:00:49,469 - INFO - ðŸªœ Batch step - 324 -- sub batch step 1297 -- lr 4.86e-05
2025-03-02 11:00:51,618 - INFO - ðŸªœ Batch step - 324 -- sub batch step 1298 -- lr 4.86e-05
2025-03-02 11:00:53,792 - INFO - ðŸªœ Batch step - 324 -- sub batch step 1299 -- lr 4.86e-05
2025-03-02 11:00:55,377 - INFO - Step 324 -- ðŸ”„ Training Metrics
2025-03-02 11:00:55,377 - INFO - â”œâ”€â”€ Loss: 10.8286
2025-03-02 11:00:55,377 - INFO - â”œâ”€â”€ Learning Rate: 4.86e-05
2025-03-02 11:00:55,377 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:00:56,052 - INFO - ðŸªœ Batch step - 325 -- sub batch step 1300 -- lr 4.87e-05
2025-03-02 11:00:58,199 - INFO - ðŸªœ Batch step - 325 -- sub batch step 1301 -- lr 4.87e-05
2025-03-02 11:01:00,352 - INFO - ðŸªœ Batch step - 325 -- sub batch step 1302 -- lr 4.87e-05
2025-03-02 11:01:02,712 - INFO - ðŸªœ Batch step - 325 -- sub batch step 1303 -- lr 4.87e-05
2025-03-02 11:01:04,639 - INFO - Step 325 -- ðŸ”„ Training Metrics
2025-03-02 11:01:04,639 - INFO - â”œâ”€â”€ Loss: 10.8276
2025-03-02 11:01:04,639 - INFO - â”œâ”€â”€ Learning Rate: 4.87e-05
2025-03-02 11:01:04,639 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:01:05,313 - INFO - ðŸªœ Batch step - 326 -- sub batch step 1304 -- lr 4.89e-05
2025-03-02 11:01:07,464 - INFO - ðŸªœ Batch step - 326 -- sub batch step 1305 -- lr 4.89e-05
2025-03-02 11:01:09,612 - INFO - ðŸªœ Batch step - 326 -- sub batch step 1306 -- lr 4.89e-05
2025-03-02 11:01:11,787 - INFO - ðŸªœ Batch step - 326 -- sub batch step 1307 -- lr 4.89e-05
2025-03-02 11:01:13,388 - INFO - Step 326 -- ðŸ”„ Training Metrics
2025-03-02 11:01:13,389 - INFO - â”œâ”€â”€ Loss: 10.8262
2025-03-02 11:01:13,389 - INFO - â”œâ”€â”€ Learning Rate: 4.89e-05
2025-03-02 11:01:13,389 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:01:14,054 - INFO - ðŸªœ Batch step - 327 -- sub batch step 1308 -- lr 4.90e-05
2025-03-02 11:01:16,206 - INFO - ðŸªœ Batch step - 327 -- sub batch step 1309 -- lr 4.90e-05
2025-03-02 11:01:18,358 - INFO - ðŸªœ Batch step - 327 -- sub batch step 1310 -- lr 4.90e-05
2025-03-02 11:01:20,978 - INFO - ðŸªœ Batch step - 327 -- sub batch step 1311 -- lr 4.90e-05
2025-03-02 11:01:22,577 - INFO - Step 327 -- ðŸ”„ Training Metrics
2025-03-02 11:01:22,577 - INFO - â”œâ”€â”€ Loss: 10.8237
2025-03-02 11:01:22,577 - INFO - â”œâ”€â”€ Learning Rate: 4.90e-05
2025-03-02 11:01:22,578 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:01:23,250 - INFO - ðŸªœ Batch step - 328 -- sub batch step 1312 -- lr 4.92e-05
2025-03-02 11:01:25,398 - INFO - ðŸªœ Batch step - 328 -- sub batch step 1313 -- lr 4.92e-05
2025-03-02 11:01:27,551 - INFO - ðŸªœ Batch step - 328 -- sub batch step 1314 -- lr 4.92e-05
2025-03-02 11:01:29,725 - INFO - ðŸªœ Batch step - 328 -- sub batch step 1315 -- lr 4.92e-05
2025-03-02 11:01:31,324 - INFO - Step 328 -- ðŸ”„ Training Metrics
2025-03-02 11:01:31,324 - INFO - â”œâ”€â”€ Loss: 10.8218
2025-03-02 11:01:31,324 - INFO - â”œâ”€â”€ Learning Rate: 4.92e-05
2025-03-02 11:01:31,324 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:01:31,991 - INFO - ðŸªœ Batch step - 329 -- sub batch step 1316 -- lr 4.94e-05
2025-03-02 11:01:34,140 - INFO - ðŸªœ Batch step - 329 -- sub batch step 1317 -- lr 4.94e-05
2025-03-02 11:01:36,288 - INFO - ðŸªœ Batch step - 329 -- sub batch step 1318 -- lr 4.94e-05
2025-03-02 11:01:39,013 - INFO - ðŸªœ Batch step - 329 -- sub batch step 1319 -- lr 4.94e-05
2025-03-02 11:01:40,676 - INFO - Step 329 -- ðŸ”„ Training Metrics
2025-03-02 11:01:40,676 - INFO - â”œâ”€â”€ Loss: 10.8216
2025-03-02 11:01:40,676 - INFO - â”œâ”€â”€ Learning Rate: 4.94e-05
2025-03-02 11:01:40,676 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:01:41,353 - INFO - ðŸªœ Batch step - 330 -- sub batch step 1320 -- lr 4.95e-05
2025-03-02 11:01:43,500 - INFO - ðŸªœ Batch step - 330 -- sub batch step 1321 -- lr 4.95e-05
2025-03-02 11:01:45,653 - INFO - ðŸªœ Batch step - 330 -- sub batch step 1322 -- lr 4.95e-05
2025-03-02 11:01:47,818 - INFO - ðŸªœ Batch step - 330 -- sub batch step 1323 -- lr 4.95e-05
2025-03-02 11:01:49,401 - INFO - Step 330 -- ðŸ”„ Training Metrics
2025-03-02 11:01:49,401 - INFO - â”œâ”€â”€ Loss: 10.8205
2025-03-02 11:01:49,401 - INFO - â”œâ”€â”€ Learning Rate: 4.95e-05
2025-03-02 11:01:49,401 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:01:50,076 - INFO - ðŸªœ Batch step - 331 -- sub batch step 1324 -- lr 4.97e-05
2025-03-02 11:01:52,228 - INFO - ðŸªœ Batch step - 331 -- sub batch step 1325 -- lr 4.97e-05
2025-03-02 11:01:55,052 - INFO - ðŸªœ Batch step - 331 -- sub batch step 1326 -- lr 4.97e-05
2025-03-02 11:01:57,213 - INFO - ðŸªœ Batch step - 331 -- sub batch step 1327 -- lr 4.97e-05
2025-03-02 11:01:58,717 - INFO - Step 331 -- ðŸ”„ Training Metrics
2025-03-02 11:01:58,717 - INFO - â”œâ”€â”€ Loss: 10.8173
2025-03-02 11:01:58,717 - INFO - â”œâ”€â”€ Learning Rate: 4.97e-05
2025-03-02 11:01:58,717 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:01:59,386 - INFO - ðŸªœ Batch step - 332 -- sub batch step 1328 -- lr 4.98e-05
2025-03-02 11:02:01,540 - INFO - ðŸªœ Batch step - 332 -- sub batch step 1329 -- lr 4.98e-05
2025-03-02 11:02:03,714 - INFO - ðŸªœ Batch step - 332 -- sub batch step 1330 -- lr 4.98e-05
2025-03-02 11:02:05,861 - INFO - ðŸªœ Batch step - 332 -- sub batch step 1331 -- lr 4.98e-05
2025-03-02 11:02:07,454 - INFO - Step 332 -- ðŸ”„ Training Metrics
2025-03-02 11:02:07,454 - INFO - â”œâ”€â”€ Loss: 10.8212
2025-03-02 11:02:07,454 - INFO - â”œâ”€â”€ Learning Rate: 4.98e-05
2025-03-02 11:02:07,455 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:02:08,130 - INFO - ðŸªœ Batch step - 333 -- sub batch step 1332 -- lr 5.00e-05
2025-03-02 11:02:10,279 - INFO - ðŸªœ Batch step - 333 -- sub batch step 1333 -- lr 5.00e-05
2025-03-02 11:02:12,883 - INFO - ðŸªœ Batch step - 333 -- sub batch step 1334 -- lr 5.00e-05
2025-03-02 11:02:15,043 - INFO - ðŸªœ Batch step - 333 -- sub batch step 1335 -- lr 5.00e-05
2025-03-02 11:02:16,722 - INFO - Step 333 -- ðŸ”„ Training Metrics
2025-03-02 11:02:16,723 - INFO - â”œâ”€â”€ Loss: 10.8186
2025-03-02 11:02:16,723 - INFO - â”œâ”€â”€ Learning Rate: 5.00e-05
2025-03-02 11:02:16,723 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:02:17,389 - INFO - ðŸªœ Batch step - 334 -- sub batch step 1336 -- lr 5.01e-05
2025-03-02 11:02:19,543 - INFO - ðŸªœ Batch step - 334 -- sub batch step 1337 -- lr 5.01e-05
2025-03-02 11:02:21,711 - INFO - ðŸªœ Batch step - 334 -- sub batch step 1338 -- lr 5.01e-05
2025-03-02 11:02:23,865 - INFO - ðŸªœ Batch step - 334 -- sub batch step 1339 -- lr 5.01e-05
2025-03-02 11:02:25,461 - INFO - Step 334 -- ðŸ”„ Training Metrics
2025-03-02 11:02:25,462 - INFO - â”œâ”€â”€ Loss: 10.8159
2025-03-02 11:02:25,462 - INFO - â”œâ”€â”€ Learning Rate: 5.01e-05
2025-03-02 11:02:25,462 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:02:26,133 - INFO - ðŸªœ Batch step - 335 -- sub batch step 1340 -- lr 5.03e-05
2025-03-02 11:02:28,281 - INFO - ðŸªœ Batch step - 335 -- sub batch step 1341 -- lr 5.03e-05
2025-03-02 11:02:30,958 - INFO - ðŸªœ Batch step - 335 -- sub batch step 1342 -- lr 5.03e-05
2025-03-02 11:02:33,111 - INFO - ðŸªœ Batch step - 335 -- sub batch step 1343 -- lr 5.03e-05
2025-03-02 11:02:34,602 - INFO - Step 335 -- ðŸ”„ Training Metrics
2025-03-02 11:02:34,603 - INFO - â”œâ”€â”€ Loss: 10.8155
2025-03-02 11:02:34,603 - INFO - â”œâ”€â”€ Learning Rate: 5.03e-05
2025-03-02 11:02:34,603 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:02:35,274 - INFO - ðŸªœ Batch step - 336 -- sub batch step 1344 -- lr 5.04e-05
2025-03-02 11:02:37,427 - INFO - ðŸªœ Batch step - 336 -- sub batch step 1345 -- lr 5.04e-05
2025-03-02 11:02:39,594 - INFO - ðŸªœ Batch step - 336 -- sub batch step 1346 -- lr 5.04e-05
2025-03-02 11:02:41,746 - INFO - ðŸªœ Batch step - 336 -- sub batch step 1347 -- lr 5.04e-05
2025-03-02 11:02:43,351 - INFO - Step 336 -- ðŸ”„ Training Metrics
2025-03-02 11:02:43,351 - INFO - â”œâ”€â”€ Loss: 10.8134
2025-03-02 11:02:43,351 - INFO - â”œâ”€â”€ Learning Rate: 5.04e-05
2025-03-02 11:02:43,351 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:02:44,015 - INFO - ðŸªœ Batch step - 337 -- sub batch step 1348 -- lr 5.06e-05
2025-03-02 11:02:46,166 - INFO - ðŸªœ Batch step - 337 -- sub batch step 1349 -- lr 5.06e-05
2025-03-02 11:02:48,835 - INFO - ðŸªœ Batch step - 337 -- sub batch step 1350 -- lr 5.06e-05
2025-03-02 11:02:50,986 - INFO - ðŸªœ Batch step - 337 -- sub batch step 1351 -- lr 5.06e-05
2025-03-02 11:02:52,737 - INFO - Step 337 -- ðŸ”„ Training Metrics
2025-03-02 11:02:52,737 - INFO - â”œâ”€â”€ Loss: 10.8116
2025-03-02 11:02:52,737 - INFO - â”œâ”€â”€ Learning Rate: 5.06e-05
2025-03-02 11:02:52,738 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:02:53,411 - INFO - ðŸªœ Batch step - 338 -- sub batch step 1352 -- lr 5.07e-05
2025-03-02 11:02:55,558 - INFO - ðŸªœ Batch step - 338 -- sub batch step 1353 -- lr 5.07e-05
2025-03-02 11:02:57,731 - INFO - ðŸªœ Batch step - 338 -- sub batch step 1354 -- lr 5.07e-05
2025-03-02 11:02:59,884 - INFO - ðŸªœ Batch step - 338 -- sub batch step 1355 -- lr 5.07e-05
2025-03-02 11:03:01,484 - INFO - Step 338 -- ðŸ”„ Training Metrics
2025-03-02 11:03:01,484 - INFO - â”œâ”€â”€ Loss: 10.8127
2025-03-02 11:03:01,485 - INFO - â”œâ”€â”€ Learning Rate: 5.07e-05
2025-03-02 11:03:01,485 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:03:02,151 - INFO - ðŸªœ Batch step - 339 -- sub batch step 1356 -- lr 5.08e-05
2025-03-02 11:03:04,306 - INFO - ðŸªœ Batch step - 339 -- sub batch step 1357 -- lr 5.08e-05
2025-03-02 11:03:06,586 - INFO - ðŸªœ Batch step - 339 -- sub batch step 1358 -- lr 5.08e-05
2025-03-02 11:03:08,739 - INFO - ðŸªœ Batch step - 339 -- sub batch step 1359 -- lr 5.08e-05
2025-03-02 11:03:10,413 - INFO - Step 339 -- ðŸ”„ Training Metrics
2025-03-02 11:03:10,413 - INFO - â”œâ”€â”€ Loss: 10.8103
2025-03-02 11:03:10,413 - INFO - â”œâ”€â”€ Learning Rate: 5.08e-05
2025-03-02 11:03:10,413 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:03:11,619 - INFO - ðŸªœ Batch step - 340 -- sub batch step 1360 -- lr 5.10e-05
2025-03-02 11:03:13,779 - INFO - ðŸªœ Batch step - 340 -- sub batch step 1361 -- lr 5.10e-05
2025-03-02 11:03:15,944 - INFO - ðŸªœ Batch step - 340 -- sub batch step 1362 -- lr 5.10e-05
2025-03-02 11:03:18,121 - INFO - ðŸªœ Batch step - 340 -- sub batch step 1363 -- lr 5.10e-05
2025-03-02 11:03:19,753 - INFO - Step 340 -- ðŸ”„ Training Metrics
2025-03-02 11:03:19,753 - INFO - â”œâ”€â”€ Loss: 10.8081
2025-03-02 11:03:19,754 - INFO - â”œâ”€â”€ Learning Rate: 5.10e-05
2025-03-02 11:03:19,754 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:03:20,430 - INFO - ðŸªœ Batch step - 341 -- sub batch step 1364 -- lr 5.11e-05
2025-03-02 11:03:22,586 - INFO - ðŸªœ Batch step - 341 -- sub batch step 1365 -- lr 5.11e-05
2025-03-02 11:03:24,737 - INFO - ðŸªœ Batch step - 341 -- sub batch step 1366 -- lr 5.11e-05
2025-03-02 11:03:27,182 - INFO - ðŸªœ Batch step - 341 -- sub batch step 1367 -- lr 5.11e-05
2025-03-02 11:03:29,160 - INFO - Step 341 -- ðŸ”„ Training Metrics
2025-03-02 11:03:29,161 - INFO - â”œâ”€â”€ Loss: 10.8095
2025-03-02 11:03:29,161 - INFO - â”œâ”€â”€ Learning Rate: 5.11e-05
2025-03-02 11:03:29,161 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:03:29,827 - INFO - ðŸªœ Batch step - 342 -- sub batch step 1368 -- lr 5.13e-05
2025-03-02 11:03:31,980 - INFO - ðŸªœ Batch step - 342 -- sub batch step 1369 -- lr 5.13e-05
2025-03-02 11:03:34,132 - INFO - ðŸªœ Batch step - 342 -- sub batch step 1370 -- lr 5.13e-05
2025-03-02 11:03:36,301 - INFO - ðŸªœ Batch step - 342 -- sub batch step 1371 -- lr 5.13e-05
2025-03-02 11:03:37,893 - INFO - Step 342 -- ðŸ”„ Training Metrics
2025-03-02 11:03:37,893 - INFO - â”œâ”€â”€ Loss: 10.8059
2025-03-02 11:03:37,894 - INFO - â”œâ”€â”€ Learning Rate: 5.13e-05
2025-03-02 11:03:37,894 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:03:38,563 - INFO - ðŸªœ Batch step - 343 -- sub batch step 1372 -- lr 5.14e-05
2025-03-02 11:03:40,710 - INFO - ðŸªœ Batch step - 343 -- sub batch step 1373 -- lr 5.14e-05
2025-03-02 11:03:42,864 - INFO - ðŸªœ Batch step - 343 -- sub batch step 1374 -- lr 5.14e-05
2025-03-02 11:03:45,342 - INFO - ðŸªœ Batch step - 343 -- sub batch step 1375 -- lr 5.14e-05
2025-03-02 11:03:47,297 - INFO - Step 343 -- ðŸ”„ Training Metrics
2025-03-02 11:03:47,297 - INFO - â”œâ”€â”€ Loss: 10.8034
2025-03-02 11:03:47,297 - INFO - â”œâ”€â”€ Learning Rate: 5.14e-05
2025-03-02 11:03:47,297 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:03:47,966 - INFO - ðŸªœ Batch step - 344 -- sub batch step 1376 -- lr 5.16e-05
2025-03-02 11:03:50,136 - INFO - ðŸªœ Batch step - 344 -- sub batch step 1377 -- lr 5.16e-05
2025-03-02 11:03:52,283 - INFO - ðŸªœ Batch step - 344 -- sub batch step 1378 -- lr 5.16e-05
2025-03-02 11:03:54,458 - INFO - ðŸªœ Batch step - 344 -- sub batch step 1379 -- lr 5.16e-05
2025-03-02 11:03:56,034 - INFO - Step 344 -- ðŸ”„ Training Metrics
2025-03-02 11:03:56,034 - INFO - â”œâ”€â”€ Loss: 10.8033
2025-03-02 11:03:56,034 - INFO - â”œâ”€â”€ Learning Rate: 5.16e-05
2025-03-02 11:03:56,034 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:03:56,707 - INFO - ðŸªœ Batch step - 345 -- sub batch step 1380 -- lr 5.17e-05
2025-03-02 11:03:58,854 - INFO - ðŸªœ Batch step - 345 -- sub batch step 1381 -- lr 5.17e-05
2025-03-02 11:04:01,009 - INFO - ðŸªœ Batch step - 345 -- sub batch step 1382 -- lr 5.17e-05
2025-03-02 11:04:03,432 - INFO - ðŸªœ Batch step - 345 -- sub batch step 1383 -- lr 5.17e-05
2025-03-02 11:04:05,411 - INFO - Step 345 -- ðŸ”„ Training Metrics
2025-03-02 11:04:05,412 - INFO - â”œâ”€â”€ Loss: 10.8031
2025-03-02 11:04:05,412 - INFO - â”œâ”€â”€ Learning Rate: 5.17e-05
2025-03-02 11:04:05,412 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:04:06,084 - INFO - ðŸªœ Batch step - 346 -- sub batch step 1384 -- lr 5.19e-05
2025-03-02 11:04:08,238 - INFO - ðŸªœ Batch step - 346 -- sub batch step 1385 -- lr 5.19e-05
2025-03-02 11:04:10,388 - INFO - ðŸªœ Batch step - 346 -- sub batch step 1386 -- lr 5.19e-05
2025-03-02 11:04:12,562 - INFO - ðŸªœ Batch step - 346 -- sub batch step 1387 -- lr 5.19e-05
2025-03-02 11:04:14,148 - INFO - Step 346 -- ðŸ”„ Training Metrics
2025-03-02 11:04:14,148 - INFO - â”œâ”€â”€ Loss: 10.8003
2025-03-02 11:04:14,148 - INFO - â”œâ”€â”€ Learning Rate: 5.19e-05
2025-03-02 11:04:14,148 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:04:14,814 - INFO - ðŸªœ Batch step - 347 -- sub batch step 1388 -- lr 5.20e-05
2025-03-02 11:04:16,965 - INFO - ðŸªœ Batch step - 347 -- sub batch step 1389 -- lr 5.20e-05
2025-03-02 11:04:19,118 - INFO - ðŸªœ Batch step - 347 -- sub batch step 1390 -- lr 5.20e-05
2025-03-02 11:04:21,684 - INFO - ðŸªœ Batch step - 347 -- sub batch step 1391 -- lr 5.20e-05
2025-03-02 11:04:23,508 - INFO - Step 347 -- ðŸ”„ Training Metrics
2025-03-02 11:04:23,508 - INFO - â”œâ”€â”€ Loss: 10.8005
2025-03-02 11:04:23,508 - INFO - â”œâ”€â”€ Learning Rate: 5.20e-05
2025-03-02 11:04:23,508 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:04:24,180 - INFO - ðŸªœ Batch step - 348 -- sub batch step 1392 -- lr 5.22e-05
2025-03-02 11:04:26,325 - INFO - ðŸªœ Batch step - 348 -- sub batch step 1393 -- lr 5.22e-05
2025-03-02 11:04:28,477 - INFO - ðŸªœ Batch step - 348 -- sub batch step 1394 -- lr 5.22e-05
2025-03-02 11:04:30,647 - INFO - ðŸªœ Batch step - 348 -- sub batch step 1395 -- lr 5.22e-05
2025-03-02 11:04:32,247 - INFO - Step 348 -- ðŸ”„ Training Metrics
2025-03-02 11:04:32,247 - INFO - â”œâ”€â”€ Loss: 10.7998
2025-03-02 11:04:32,247 - INFO - â”œâ”€â”€ Learning Rate: 5.22e-05
2025-03-02 11:04:32,247 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:04:32,914 - INFO - ðŸªœ Batch step - 349 -- sub batch step 1396 -- lr 5.23e-05
2025-03-02 11:04:35,065 - INFO - ðŸªœ Batch step - 349 -- sub batch step 1397 -- lr 5.23e-05
2025-03-02 11:04:37,209 - INFO - ðŸªœ Batch step - 349 -- sub batch step 1398 -- lr 5.23e-05
2025-03-02 11:04:39,617 - INFO - ðŸªœ Batch step - 349 -- sub batch step 1399 -- lr 5.23e-05
2025-03-02 11:04:41,608 - INFO - Step 349 -- ðŸ”„ Training Metrics
2025-03-02 11:04:41,608 - INFO - â”œâ”€â”€ Loss: 10.7995
2025-03-02 11:04:41,608 - INFO - â”œâ”€â”€ Learning Rate: 5.23e-05
2025-03-02 11:04:41,608 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:04:42,277 - INFO - ðŸªœ Batch step - 350 -- sub batch step 1400 -- lr 5.25e-05
2025-03-02 11:04:44,421 - INFO - ðŸªœ Batch step - 350 -- sub batch step 1401 -- lr 5.25e-05
2025-03-02 11:04:46,571 - INFO - ðŸªœ Batch step - 350 -- sub batch step 1402 -- lr 5.25e-05
2025-03-02 11:04:48,734 - INFO - ðŸªœ Batch step - 350 -- sub batch step 1403 -- lr 5.25e-05
2025-03-02 11:04:50,335 - INFO - Step 350 -- ðŸ”„ Training Metrics
2025-03-02 11:04:50,335 - INFO - â”œâ”€â”€ Loss: 10.7965
2025-03-02 11:04:50,335 - INFO - â”œâ”€â”€ Learning Rate: 5.25e-05
2025-03-02 11:04:50,335 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:04:51,005 - INFO - ðŸªœ Batch step - 351 -- sub batch step 1404 -- lr 5.26e-05
2025-03-02 11:04:53,157 - INFO - ðŸªœ Batch step - 351 -- sub batch step 1405 -- lr 5.26e-05
2025-03-02 11:04:55,997 - INFO - ðŸªœ Batch step - 351 -- sub batch step 1406 -- lr 5.26e-05
2025-03-02 11:04:58,153 - INFO - ðŸªœ Batch step - 351 -- sub batch step 1407 -- lr 5.26e-05
2025-03-02 11:04:59,651 - INFO - Step 351 -- ðŸ”„ Training Metrics
2025-03-02 11:04:59,651 - INFO - â”œâ”€â”€ Loss: 10.7962
2025-03-02 11:04:59,651 - INFO - â”œâ”€â”€ Learning Rate: 5.26e-05
2025-03-02 11:04:59,652 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:05:00,321 - INFO - ðŸªœ Batch step - 352 -- sub batch step 1408 -- lr 5.28e-05
2025-03-02 11:05:02,473 - INFO - ðŸªœ Batch step - 352 -- sub batch step 1409 -- lr 5.28e-05
2025-03-02 11:05:04,640 - INFO - ðŸªœ Batch step - 352 -- sub batch step 1410 -- lr 5.28e-05
2025-03-02 11:05:06,787 - INFO - ðŸªœ Batch step - 352 -- sub batch step 1411 -- lr 5.28e-05
2025-03-02 11:05:08,378 - INFO - Step 352 -- ðŸ”„ Training Metrics
2025-03-02 11:05:08,378 - INFO - â”œâ”€â”€ Loss: 10.7932
2025-03-02 11:05:08,378 - INFO - â”œâ”€â”€ Learning Rate: 5.28e-05
2025-03-02 11:05:08,378 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:05:09,053 - INFO - ðŸªœ Batch step - 353 -- sub batch step 1412 -- lr 5.29e-05
2025-03-02 11:05:11,196 - INFO - ðŸªœ Batch step - 353 -- sub batch step 1413 -- lr 5.29e-05
2025-03-02 11:05:13,936 - INFO - ðŸªœ Batch step - 353 -- sub batch step 1414 -- lr 5.29e-05
2025-03-02 11:05:16,096 - INFO - ðŸªœ Batch step - 353 -- sub batch step 1415 -- lr 5.29e-05
2025-03-02 11:05:17,607 - INFO - Step 353 -- ðŸ”„ Training Metrics
2025-03-02 11:05:17,607 - INFO - â”œâ”€â”€ Loss: 10.7932
2025-03-02 11:05:17,608 - INFO - â”œâ”€â”€ Learning Rate: 5.29e-05
2025-03-02 11:05:17,608 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:05:18,276 - INFO - ðŸªœ Batch step - 354 -- sub batch step 1416 -- lr 5.31e-05
2025-03-02 11:05:20,433 - INFO - ðŸªœ Batch step - 354 -- sub batch step 1417 -- lr 5.31e-05
2025-03-02 11:05:22,595 - INFO - ðŸªœ Batch step - 354 -- sub batch step 1418 -- lr 5.31e-05
2025-03-02 11:05:24,746 - INFO - ðŸªœ Batch step - 354 -- sub batch step 1419 -- lr 5.31e-05
2025-03-02 11:05:26,326 - INFO - Step 354 -- ðŸ”„ Training Metrics
2025-03-02 11:05:26,326 - INFO - â”œâ”€â”€ Loss: 10.7927
2025-03-02 11:05:26,327 - INFO - â”œâ”€â”€ Learning Rate: 5.31e-05
2025-03-02 11:05:26,327 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:05:27,003 - INFO - ðŸªœ Batch step - 355 -- sub batch step 1420 -- lr 5.32e-05
2025-03-02 11:05:29,147 - INFO - ðŸªœ Batch step - 355 -- sub batch step 1421 -- lr 5.32e-05
2025-03-02 11:05:31,854 - INFO - ðŸªœ Batch step - 355 -- sub batch step 1422 -- lr 5.32e-05
2025-03-02 11:05:34,000 - INFO - ðŸªœ Batch step - 355 -- sub batch step 1423 -- lr 5.32e-05
2025-03-02 11:05:35,561 - INFO - Step 355 -- ðŸ”„ Training Metrics
2025-03-02 11:05:35,562 - INFO - â”œâ”€â”€ Loss: 10.7864
2025-03-02 11:05:35,562 - INFO - â”œâ”€â”€ Learning Rate: 5.32e-05
2025-03-02 11:05:35,562 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:05:36,235 - INFO - ðŸªœ Batch step - 356 -- sub batch step 1424 -- lr 5.34e-05
2025-03-02 11:05:38,387 - INFO - ðŸªœ Batch step - 356 -- sub batch step 1425 -- lr 5.34e-05
2025-03-02 11:05:40,552 - INFO - ðŸªœ Batch step - 356 -- sub batch step 1426 -- lr 5.34e-05
2025-03-02 11:05:42,701 - INFO - ðŸªœ Batch step - 356 -- sub batch step 1427 -- lr 5.34e-05
2025-03-02 11:05:44,289 - INFO - Step 356 -- ðŸ”„ Training Metrics
2025-03-02 11:05:44,289 - INFO - â”œâ”€â”€ Loss: 10.7877
2025-03-02 11:05:44,290 - INFO - â”œâ”€â”€ Learning Rate: 5.34e-05
2025-03-02 11:05:44,290 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:05:44,957 - INFO - ðŸªœ Batch step - 357 -- sub batch step 1428 -- lr 5.35e-05
2025-03-02 11:05:47,110 - INFO - ðŸªœ Batch step - 357 -- sub batch step 1429 -- lr 5.35e-05
2025-03-02 11:05:49,790 - INFO - ðŸªœ Batch step - 357 -- sub batch step 1430 -- lr 5.35e-05
2025-03-02 11:05:51,940 - INFO - ðŸªœ Batch step - 357 -- sub batch step 1431 -- lr 5.35e-05
2025-03-02 11:05:53,472 - INFO - Step 357 -- ðŸ”„ Training Metrics
2025-03-02 11:05:53,472 - INFO - â”œâ”€â”€ Loss: 10.7868
2025-03-02 11:05:53,472 - INFO - â”œâ”€â”€ Learning Rate: 5.35e-05
2025-03-02 11:05:53,472 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:05:54,147 - INFO - ðŸªœ Batch step - 358 -- sub batch step 1432 -- lr 5.37e-05
2025-03-02 11:05:56,295 - INFO - ðŸªœ Batch step - 358 -- sub batch step 1433 -- lr 5.37e-05
2025-03-02 11:05:58,465 - INFO - ðŸªœ Batch step - 358 -- sub batch step 1434 -- lr 5.37e-05
2025-03-02 11:06:00,622 - INFO - ðŸªœ Batch step - 358 -- sub batch step 1435 -- lr 5.37e-05
2025-03-02 11:06:02,208 - INFO - Step 358 -- ðŸ”„ Training Metrics
2025-03-02 11:06:02,208 - INFO - â”œâ”€â”€ Loss: 10.7867
2025-03-02 11:06:02,208 - INFO - â”œâ”€â”€ Learning Rate: 5.37e-05
2025-03-02 11:06:02,208 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:06:02,876 - INFO - ðŸªœ Batch step - 359 -- sub batch step 1436 -- lr 5.38e-05
2025-03-02 11:06:05,030 - INFO - ðŸªœ Batch step - 359 -- sub batch step 1437 -- lr 5.38e-05
2025-03-02 11:06:07,309 - INFO - ðŸªœ Batch step - 359 -- sub batch step 1438 -- lr 5.38e-05
2025-03-02 11:06:09,461 - INFO - ðŸªœ Batch step - 359 -- sub batch step 1439 -- lr 5.38e-05
2025-03-02 11:06:11,044 - INFO - Step 359 -- ðŸ”„ Training Metrics
2025-03-02 11:06:11,045 - INFO - â”œâ”€â”€ Loss: 10.7844
2025-03-02 11:06:11,045 - INFO - â”œâ”€â”€ Learning Rate: 5.38e-05
2025-03-02 11:06:11,045 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:06:12,429 - INFO - ðŸªœ Batch step - 360 -- sub batch step 1440 -- lr 5.40e-05
2025-03-02 11:06:14,593 - INFO - ðŸªœ Batch step - 360 -- sub batch step 1441 -- lr 5.40e-05
2025-03-02 11:06:16,753 - INFO - ðŸªœ Batch step - 360 -- sub batch step 1442 -- lr 5.40e-05
2025-03-02 11:06:18,927 - INFO - ðŸªœ Batch step - 360 -- sub batch step 1443 -- lr 5.40e-05
2025-03-02 11:06:20,459 - INFO - Step 360 -- ðŸ”„ Training Metrics
2025-03-02 11:06:20,459 - INFO - â”œâ”€â”€ Loss: 10.7844
2025-03-02 11:06:20,460 - INFO - â”œâ”€â”€ Learning Rate: 5.40e-05
2025-03-02 11:06:20,460 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:06:21,137 - INFO - ðŸªœ Batch step - 361 -- sub batch step 1444 -- lr 5.41e-05
2025-03-02 11:06:23,299 - INFO - ðŸªœ Batch step - 361 -- sub batch step 1445 -- lr 5.41e-05
2025-03-02 11:06:25,451 - INFO - ðŸªœ Batch step - 361 -- sub batch step 1446 -- lr 5.41e-05
2025-03-02 11:06:27,959 - INFO - ðŸªœ Batch step - 361 -- sub batch step 1447 -- lr 5.41e-05
2025-03-02 11:06:29,511 - INFO - Step 361 -- ðŸ”„ Training Metrics
2025-03-02 11:06:29,511 - INFO - â”œâ”€â”€ Loss: 10.7804
2025-03-02 11:06:29,511 - INFO - â”œâ”€â”€ Learning Rate: 5.41e-05
2025-03-02 11:06:29,511 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:06:30,182 - INFO - ðŸªœ Batch step - 362 -- sub batch step 1448 -- lr 5.43e-05
2025-03-02 11:06:32,345 - INFO - ðŸªœ Batch step - 362 -- sub batch step 1449 -- lr 5.43e-05
2025-03-02 11:06:34,504 - INFO - ðŸªœ Batch step - 362 -- sub batch step 1450 -- lr 5.43e-05
2025-03-02 11:06:36,683 - INFO - ðŸªœ Batch step - 362 -- sub batch step 1451 -- lr 5.43e-05
2025-03-02 11:06:38,256 - INFO - Step 362 -- ðŸ”„ Training Metrics
2025-03-02 11:06:38,256 - INFO - â”œâ”€â”€ Loss: 10.7813
2025-03-02 11:06:38,256 - INFO - â”œâ”€â”€ Learning Rate: 5.43e-05
2025-03-02 11:06:38,256 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:06:38,933 - INFO - ðŸªœ Batch step - 363 -- sub batch step 1452 -- lr 5.44e-05
2025-03-02 11:06:41,087 - INFO - ðŸªœ Batch step - 363 -- sub batch step 1453 -- lr 5.44e-05
2025-03-02 11:06:43,247 - INFO - ðŸªœ Batch step - 363 -- sub batch step 1454 -- lr 5.44e-05
2025-03-02 11:06:45,913 - INFO - ðŸªœ Batch step - 363 -- sub batch step 1455 -- lr 5.44e-05
2025-03-02 11:06:47,550 - INFO - Step 363 -- ðŸ”„ Training Metrics
2025-03-02 11:06:47,551 - INFO - â”œâ”€â”€ Loss: 10.7803
2025-03-02 11:06:47,551 - INFO - â”œâ”€â”€ Learning Rate: 5.44e-05
2025-03-02 11:06:47,551 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:06:48,223 - INFO - ðŸªœ Batch step - 364 -- sub batch step 1456 -- lr 5.46e-05
2025-03-02 11:06:50,382 - INFO - ðŸªœ Batch step - 364 -- sub batch step 1457 -- lr 5.46e-05
2025-03-02 11:06:52,531 - INFO - ðŸªœ Batch step - 364 -- sub batch step 1458 -- lr 5.46e-05
2025-03-02 11:06:54,703 - INFO - ðŸªœ Batch step - 364 -- sub batch step 1459 -- lr 5.46e-05
2025-03-02 11:06:56,313 - INFO - Step 364 -- ðŸ”„ Training Metrics
2025-03-02 11:06:56,313 - INFO - â”œâ”€â”€ Loss: 10.7780
2025-03-02 11:06:56,313 - INFO - â”œâ”€â”€ Learning Rate: 5.46e-05
2025-03-02 11:06:56,314 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:06:56,986 - INFO - ðŸªœ Batch step - 365 -- sub batch step 1460 -- lr 5.47e-05
2025-03-02 11:06:59,138 - INFO - ðŸªœ Batch step - 365 -- sub batch step 1461 -- lr 5.47e-05
2025-03-02 11:07:01,292 - INFO - ðŸªœ Batch step - 365 -- sub batch step 1462 -- lr 5.47e-05
2025-03-02 11:07:03,740 - INFO - ðŸªœ Batch step - 365 -- sub batch step 1463 -- lr 5.47e-05
2025-03-02 11:07:05,601 - INFO - Step 365 -- ðŸ”„ Training Metrics
2025-03-02 11:07:05,601 - INFO - â”œâ”€â”€ Loss: 10.7747
2025-03-02 11:07:05,602 - INFO - â”œâ”€â”€ Learning Rate: 5.47e-05
2025-03-02 11:07:05,602 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:07:06,272 - INFO - ðŸªœ Batch step - 366 -- sub batch step 1464 -- lr 5.49e-05
2025-03-02 11:07:08,425 - INFO - ðŸªœ Batch step - 366 -- sub batch step 1465 -- lr 5.49e-05
2025-03-02 11:07:10,572 - INFO - ðŸªœ Batch step - 366 -- sub batch step 1466 -- lr 5.49e-05
2025-03-02 11:07:12,742 - INFO - ðŸªœ Batch step - 366 -- sub batch step 1467 -- lr 5.49e-05
2025-03-02 11:07:14,364 - INFO - Step 366 -- ðŸ”„ Training Metrics
2025-03-02 11:07:14,365 - INFO - â”œâ”€â”€ Loss: 10.7757
2025-03-02 11:07:14,365 - INFO - â”œâ”€â”€ Learning Rate: 5.49e-05
2025-03-02 11:07:14,365 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:07:15,032 - INFO - ðŸªœ Batch step - 367 -- sub batch step 1468 -- lr 5.50e-05
2025-03-02 11:07:17,189 - INFO - ðŸªœ Batch step - 367 -- sub batch step 1469 -- lr 5.50e-05
2025-03-02 11:07:19,340 - INFO - ðŸªœ Batch step - 367 -- sub batch step 1470 -- lr 5.50e-05
2025-03-02 11:07:21,740 - INFO - ðŸªœ Batch step - 367 -- sub batch step 1471 -- lr 5.50e-05
2025-03-02 11:07:23,652 - INFO - Step 367 -- ðŸ”„ Training Metrics
2025-03-02 11:07:23,653 - INFO - â”œâ”€â”€ Loss: 10.7740
2025-03-02 11:07:23,653 - INFO - â”œâ”€â”€ Learning Rate: 5.50e-05
2025-03-02 11:07:23,653 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:07:24,328 - INFO - ðŸªœ Batch step - 368 -- sub batch step 1472 -- lr 5.52e-05
2025-03-02 11:07:26,473 - INFO - ðŸªœ Batch step - 368 -- sub batch step 1473 -- lr 5.52e-05
2025-03-02 11:07:28,627 - INFO - ðŸªœ Batch step - 368 -- sub batch step 1474 -- lr 5.52e-05
2025-03-02 11:07:30,798 - INFO - ðŸªœ Batch step - 368 -- sub batch step 1475 -- lr 5.52e-05
2025-03-02 11:07:32,394 - INFO - Step 368 -- ðŸ”„ Training Metrics
2025-03-02 11:07:32,394 - INFO - â”œâ”€â”€ Loss: 10.7709
2025-03-02 11:07:32,394 - INFO - â”œâ”€â”€ Learning Rate: 5.52e-05
2025-03-02 11:07:32,395 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:07:33,063 - INFO - ðŸªœ Batch step - 369 -- sub batch step 1476 -- lr 5.53e-05
2025-03-02 11:07:35,217 - INFO - ðŸªœ Batch step - 369 -- sub batch step 1477 -- lr 5.53e-05
2025-03-02 11:07:37,365 - INFO - ðŸªœ Batch step - 369 -- sub batch step 1478 -- lr 5.53e-05
2025-03-02 11:07:39,729 - INFO - ðŸªœ Batch step - 369 -- sub batch step 1479 -- lr 5.53e-05
2025-03-02 11:07:41,669 - INFO - Step 369 -- ðŸ”„ Training Metrics
2025-03-02 11:07:41,669 - INFO - â”œâ”€â”€ Loss: 10.7730
2025-03-02 11:07:41,669 - INFO - â”œâ”€â”€ Learning Rate: 5.53e-05
2025-03-02 11:07:41,670 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:07:42,344 - INFO - ðŸªœ Batch step - 370 -- sub batch step 1480 -- lr 5.55e-05
2025-03-02 11:07:44,491 - INFO - ðŸªœ Batch step - 370 -- sub batch step 1481 -- lr 5.55e-05
2025-03-02 11:07:46,643 - INFO - ðŸªœ Batch step - 370 -- sub batch step 1482 -- lr 5.55e-05
2025-03-02 11:07:48,807 - INFO - ðŸªœ Batch step - 370 -- sub batch step 1483 -- lr 5.55e-05
2025-03-02 11:07:50,387 - INFO - Step 370 -- ðŸ”„ Training Metrics
2025-03-02 11:07:50,388 - INFO - â”œâ”€â”€ Loss: 10.7694
2025-03-02 11:07:50,388 - INFO - â”œâ”€â”€ Learning Rate: 5.55e-05
2025-03-02 11:07:50,388 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:07:51,060 - INFO - ðŸªœ Batch step - 371 -- sub batch step 1484 -- lr 5.56e-05
2025-03-02 11:07:53,211 - INFO - ðŸªœ Batch step - 371 -- sub batch step 1485 -- lr 5.56e-05
2025-03-02 11:07:55,557 - INFO - ðŸªœ Batch step - 371 -- sub batch step 1486 -- lr 5.56e-05
2025-03-02 11:07:57,713 - INFO - ðŸªœ Batch step - 371 -- sub batch step 1487 -- lr 5.56e-05
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: b6c518f6-482a-496d-8222-97e45c149651)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00018-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 11:08:10,537 - INFO - Step 371 -- ðŸ”„ Training Metrics
2025-03-02 11:08:10,538 - INFO - â”œâ”€â”€ Loss: 10.7669
2025-03-02 11:08:10,538 - INFO - â”œâ”€â”€ Learning Rate: 5.56e-05
2025-03-02 11:08:10,538 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:08:11,203 - INFO - ðŸªœ Batch step - 372 -- sub batch step 1488 -- lr 5.58e-05
2025-03-02 11:08:13,357 - INFO - ðŸªœ Batch step - 372 -- sub batch step 1489 -- lr 5.58e-05
2025-03-02 11:08:15,524 - INFO - ðŸªœ Batch step - 372 -- sub batch step 1490 -- lr 5.58e-05
2025-03-02 11:08:17,670 - INFO - ðŸªœ Batch step - 372 -- sub batch step 1491 -- lr 5.58e-05
2025-03-02 11:08:19,266 - INFO - Step 372 -- ðŸ”„ Training Metrics
2025-03-02 11:08:19,267 - INFO - â”œâ”€â”€ Loss: 10.7691
2025-03-02 11:08:19,267 - INFO - â”œâ”€â”€ Learning Rate: 5.58e-05
2025-03-02 11:08:19,267 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:08:19,938 - INFO - ðŸªœ Batch step - 373 -- sub batch step 1492 -- lr 5.59e-05
2025-03-02 11:08:22,084 - INFO - ðŸªœ Batch step - 373 -- sub batch step 1493 -- lr 5.59e-05
2025-03-02 11:08:24,433 - INFO - ðŸªœ Batch step - 373 -- sub batch step 1494 -- lr 5.59e-05
2025-03-02 11:08:26,583 - INFO - ðŸªœ Batch step - 373 -- sub batch step 1495 -- lr 5.59e-05
2025-03-02 11:08:28,785 - INFO - Step 373 -- ðŸ”„ Training Metrics
2025-03-02 11:08:28,785 - INFO - â”œâ”€â”€ Loss: 10.7663
2025-03-02 11:08:28,786 - INFO - â”œâ”€â”€ Learning Rate: 5.59e-05
2025-03-02 11:08:28,786 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:08:29,452 - INFO - ðŸªœ Batch step - 374 -- sub batch step 1496 -- lr 5.61e-05
2025-03-02 11:08:31,602 - INFO - ðŸªœ Batch step - 374 -- sub batch step 1497 -- lr 5.61e-05
2025-03-02 11:08:33,764 - INFO - ðŸªœ Batch step - 374 -- sub batch step 1498 -- lr 5.61e-05
2025-03-02 11:08:35,916 - INFO - ðŸªœ Batch step - 374 -- sub batch step 1499 -- lr 5.61e-05
2025-03-02 11:08:37,518 - INFO - Step 374 -- ðŸ”„ Training Metrics
2025-03-02 11:08:37,518 - INFO - â”œâ”€â”€ Loss: 10.7630
2025-03-02 11:08:37,518 - INFO - â”œâ”€â”€ Learning Rate: 5.61e-05
2025-03-02 11:08:37,518 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:08:38,193 - INFO - ðŸªœ Batch step - 375 -- sub batch step 1500 -- lr 5.62e-05
2025-03-02 11:08:40,342 - INFO - ðŸªœ Batch step - 375 -- sub batch step 1501 -- lr 5.62e-05
2025-03-02 11:08:42,694 - INFO - ðŸªœ Batch step - 375 -- sub batch step 1502 -- lr 5.62e-05
2025-03-02 11:08:44,840 - INFO - ðŸªœ Batch step - 375 -- sub batch step 1503 -- lr 5.62e-05
2025-03-02 11:08:46,696 - INFO - Step 375 -- ðŸ”„ Training Metrics
2025-03-02 11:08:46,696 - INFO - â”œâ”€â”€ Loss: 10.7626
2025-03-02 11:08:46,696 - INFO - â”œâ”€â”€ Learning Rate: 5.62e-05
2025-03-02 11:08:46,697 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:08:47,368 - INFO - ðŸªœ Batch step - 376 -- sub batch step 1504 -- lr 5.64e-05
2025-03-02 11:08:49,517 - INFO - ðŸªœ Batch step - 376 -- sub batch step 1505 -- lr 5.64e-05
2025-03-02 11:08:51,678 - INFO - ðŸªœ Batch step - 376 -- sub batch step 1506 -- lr 5.64e-05
2025-03-02 11:08:53,826 - INFO - ðŸªœ Batch step - 376 -- sub batch step 1507 -- lr 5.64e-05
2025-03-02 11:08:55,427 - INFO - Step 376 -- ðŸ”„ Training Metrics
2025-03-02 11:08:55,428 - INFO - â”œâ”€â”€ Loss: 10.7580
2025-03-02 11:08:55,428 - INFO - â”œâ”€â”€ Learning Rate: 5.64e-05
2025-03-02 11:08:55,428 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:08:56,092 - INFO - ðŸªœ Batch step - 377 -- sub batch step 1508 -- lr 5.65e-05
2025-03-02 11:08:58,244 - INFO - ðŸªœ Batch step - 377 -- sub batch step 1509 -- lr 5.65e-05
2025-03-02 11:09:00,599 - INFO - ðŸªœ Batch step - 377 -- sub batch step 1510 -- lr 5.65e-05
2025-03-02 11:09:02,746 - INFO - ðŸªœ Batch step - 377 -- sub batch step 1511 -- lr 5.65e-05
2025-03-02 11:09:04,735 - INFO - Step 377 -- ðŸ”„ Training Metrics
2025-03-02 11:09:04,735 - INFO - â”œâ”€â”€ Loss: 10.7598
2025-03-02 11:09:04,735 - INFO - â”œâ”€â”€ Learning Rate: 5.65e-05
2025-03-02 11:09:04,735 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:09:05,411 - INFO - ðŸªœ Batch step - 378 -- sub batch step 1512 -- lr 5.67e-05
2025-03-02 11:09:07,557 - INFO - ðŸªœ Batch step - 378 -- sub batch step 1513 -- lr 5.67e-05
2025-03-02 11:09:09,722 - INFO - ðŸªœ Batch step - 378 -- sub batch step 1514 -- lr 5.67e-05
2025-03-02 11:09:11,871 - INFO - ðŸªœ Batch step - 378 -- sub batch step 1515 -- lr 5.67e-05
2025-03-02 11:09:13,468 - INFO - Step 378 -- ðŸ”„ Training Metrics
2025-03-02 11:09:13,469 - INFO - â”œâ”€â”€ Loss: 10.7555
2025-03-02 11:09:13,469 - INFO - â”œâ”€â”€ Learning Rate: 5.67e-05
2025-03-02 11:09:13,469 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:09:14,135 - INFO - ðŸªœ Batch step - 379 -- sub batch step 1516 -- lr 5.68e-05
2025-03-02 11:09:16,290 - INFO - ðŸªœ Batch step - 379 -- sub batch step 1517 -- lr 5.68e-05
2025-03-02 11:09:18,560 - INFO - ðŸªœ Batch step - 379 -- sub batch step 1518 -- lr 5.68e-05
2025-03-02 11:09:20,718 - INFO - ðŸªœ Batch step - 379 -- sub batch step 1519 -- lr 5.68e-05
2025-03-02 11:09:22,298 - INFO - Step 379 -- ðŸ”„ Training Metrics
2025-03-02 11:09:22,298 - INFO - â”œâ”€â”€ Loss: 10.7556
2025-03-02 11:09:22,298 - INFO - â”œâ”€â”€ Learning Rate: 5.68e-05
2025-03-02 11:09:22,299 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:09:23,577 - INFO - ðŸªœ Batch step - 380 -- sub batch step 1520 -- lr 5.70e-05
2025-03-02 11:09:25,739 - INFO - ðŸªœ Batch step - 380 -- sub batch step 1521 -- lr 5.70e-05
2025-03-02 11:09:27,905 - INFO - ðŸªœ Batch step - 380 -- sub batch step 1522 -- lr 5.70e-05
2025-03-02 11:09:30,080 - INFO - ðŸªœ Batch step - 380 -- sub batch step 1523 -- lr 5.70e-05
2025-03-02 11:09:31,655 - INFO - Step 380 -- ðŸ”„ Training Metrics
2025-03-02 11:09:31,656 - INFO - â”œâ”€â”€ Loss: 10.7556
2025-03-02 11:09:31,656 - INFO - â”œâ”€â”€ Learning Rate: 5.70e-05
2025-03-02 11:09:31,656 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:09:32,334 - INFO - ðŸªœ Batch step - 381 -- sub batch step 1524 -- lr 5.71e-05
2025-03-02 11:09:34,494 - INFO - ðŸªœ Batch step - 381 -- sub batch step 1525 -- lr 5.71e-05
2025-03-02 11:09:36,646 - INFO - ðŸªœ Batch step - 381 -- sub batch step 1526 -- lr 5.71e-05
2025-03-02 11:09:39,166 - INFO - ðŸªœ Batch step - 381 -- sub batch step 1527 -- lr 5.71e-05
2025-03-02 11:09:40,984 - INFO - Step 381 -- ðŸ”„ Training Metrics
2025-03-02 11:09:40,984 - INFO - â”œâ”€â”€ Loss: 10.7528
2025-03-02 11:09:40,985 - INFO - â”œâ”€â”€ Learning Rate: 5.71e-05
2025-03-02 11:09:40,985 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:09:41,653 - INFO - ðŸªœ Batch step - 382 -- sub batch step 1528 -- lr 5.73e-05
2025-03-02 11:09:43,811 - INFO - ðŸªœ Batch step - 382 -- sub batch step 1529 -- lr 5.73e-05
2025-03-02 11:09:45,971 - INFO - ðŸªœ Batch step - 382 -- sub batch step 1530 -- lr 5.73e-05
2025-03-02 11:09:48,145 - INFO - ðŸªœ Batch step - 382 -- sub batch step 1531 -- lr 5.73e-05
2025-03-02 11:09:49,729 - INFO - Step 382 -- ðŸ”„ Training Metrics
2025-03-02 11:09:49,729 - INFO - â”œâ”€â”€ Loss: 10.7509
2025-03-02 11:09:49,729 - INFO - â”œâ”€â”€ Learning Rate: 5.73e-05
2025-03-02 11:09:49,729 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:09:50,408 - INFO - ðŸªœ Batch step - 383 -- sub batch step 1532 -- lr 5.74e-05
2025-03-02 11:09:52,559 - INFO - ðŸªœ Batch step - 383 -- sub batch step 1533 -- lr 5.74e-05
2025-03-02 11:09:54,718 - INFO - ðŸªœ Batch step - 383 -- sub batch step 1534 -- lr 5.74e-05
2025-03-02 11:09:57,130 - INFO - ðŸªœ Batch step - 383 -- sub batch step 1535 -- lr 5.74e-05
2025-03-02 11:09:59,020 - INFO - Step 383 -- ðŸ”„ Training Metrics
2025-03-02 11:09:59,020 - INFO - â”œâ”€â”€ Loss: 10.7464
2025-03-02 11:09:59,020 - INFO - â”œâ”€â”€ Learning Rate: 5.74e-05
2025-03-02 11:09:59,020 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:09:59,687 - INFO - ðŸªœ Batch step - 384 -- sub batch step 1536 -- lr 5.76e-05
2025-03-02 11:10:01,851 - INFO - ðŸªœ Batch step - 384 -- sub batch step 1537 -- lr 5.76e-05
2025-03-02 11:10:04,002 - INFO - ðŸªœ Batch step - 384 -- sub batch step 1538 -- lr 5.76e-05
2025-03-02 11:10:06,181 - INFO - ðŸªœ Batch step - 384 -- sub batch step 1539 -- lr 5.76e-05
2025-03-02 11:10:07,747 - INFO - Step 384 -- ðŸ”„ Training Metrics
2025-03-02 11:10:07,747 - INFO - â”œâ”€â”€ Loss: 10.7516
2025-03-02 11:10:07,747 - INFO - â”œâ”€â”€ Learning Rate: 5.76e-05
2025-03-02 11:10:07,747 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:10:08,424 - INFO - ðŸªœ Batch step - 385 -- sub batch step 1540 -- lr 5.77e-05
2025-03-02 11:10:10,578 - INFO - ðŸªœ Batch step - 385 -- sub batch step 1541 -- lr 5.77e-05
2025-03-02 11:10:12,735 - INFO - ðŸªœ Batch step - 385 -- sub batch step 1542 -- lr 5.77e-05
2025-03-02 11:10:15,139 - INFO - ðŸªœ Batch step - 385 -- sub batch step 1543 -- lr 5.77e-05
2025-03-02 11:10:16,905 - INFO - Step 385 -- ðŸ”„ Training Metrics
2025-03-02 11:10:16,906 - INFO - â”œâ”€â”€ Loss: 10.7469
2025-03-02 11:10:16,906 - INFO - â”œâ”€â”€ Learning Rate: 5.77e-05
2025-03-02 11:10:16,906 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:10:17,635 - INFO - ðŸªœ Batch step - 386 -- sub batch step 1544 -- lr 5.79e-05
2025-03-02 11:10:19,789 - INFO - ðŸªœ Batch step - 386 -- sub batch step 1545 -- lr 5.79e-05
2025-03-02 11:10:21,934 - INFO - ðŸªœ Batch step - 386 -- sub batch step 1546 -- lr 5.79e-05
2025-03-02 11:10:24,104 - INFO - ðŸªœ Batch step - 386 -- sub batch step 1547 -- lr 5.79e-05
2025-03-02 11:10:25,693 - INFO - Step 386 -- ðŸ”„ Training Metrics
2025-03-02 11:10:25,694 - INFO - â”œâ”€â”€ Loss: 10.7475
2025-03-02 11:10:25,694 - INFO - â”œâ”€â”€ Learning Rate: 5.79e-05
2025-03-02 11:10:25,694 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:10:26,362 - INFO - ðŸªœ Batch step - 387 -- sub batch step 1548 -- lr 5.80e-05
2025-03-02 11:10:28,515 - INFO - ðŸªœ Batch step - 387 -- sub batch step 1549 -- lr 5.80e-05
2025-03-02 11:10:30,670 - INFO - ðŸªœ Batch step - 387 -- sub batch step 1550 -- lr 5.80e-05
2025-03-02 11:10:33,077 - INFO - ðŸªœ Batch step - 387 -- sub batch step 1551 -- lr 5.80e-05
2025-03-02 11:10:35,058 - INFO - Step 387 -- ðŸ”„ Training Metrics
2025-03-02 11:10:35,058 - INFO - â”œâ”€â”€ Loss: 10.7430
2025-03-02 11:10:35,058 - INFO - â”œâ”€â”€ Learning Rate: 5.80e-05
2025-03-02 11:10:35,058 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:10:35,734 - INFO - ðŸªœ Batch step - 388 -- sub batch step 1552 -- lr 5.82e-05
2025-03-02 11:10:37,884 - INFO - ðŸªœ Batch step - 388 -- sub batch step 1553 -- lr 5.82e-05
2025-03-02 11:10:40,042 - INFO - ðŸªœ Batch step - 388 -- sub batch step 1554 -- lr 5.82e-05
2025-03-02 11:10:42,218 - INFO - ðŸªœ Batch step - 388 -- sub batch step 1555 -- lr 5.82e-05
2025-03-02 11:10:43,793 - INFO - Step 388 -- ðŸ”„ Training Metrics
2025-03-02 11:10:43,794 - INFO - â”œâ”€â”€ Loss: 10.7439
2025-03-02 11:10:43,794 - INFO - â”œâ”€â”€ Learning Rate: 5.82e-05
2025-03-02 11:10:43,794 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:10:44,464 - INFO - ðŸªœ Batch step - 389 -- sub batch step 1556 -- lr 5.83e-05
2025-03-02 11:10:46,621 - INFO - ðŸªœ Batch step - 389 -- sub batch step 1557 -- lr 5.83e-05
2025-03-02 11:10:48,772 - INFO - ðŸªœ Batch step - 389 -- sub batch step 1558 -- lr 5.83e-05
2025-03-02 11:10:51,567 - INFO - ðŸªœ Batch step - 389 -- sub batch step 1559 -- lr 5.83e-05
2025-03-02 11:10:53,066 - INFO - Step 389 -- ðŸ”„ Training Metrics
2025-03-02 11:10:53,066 - INFO - â”œâ”€â”€ Loss: 10.7433
2025-03-02 11:10:53,066 - INFO - â”œâ”€â”€ Learning Rate: 5.83e-05
2025-03-02 11:10:53,066 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:10:53,744 - INFO - ðŸªœ Batch step - 390 -- sub batch step 1560 -- lr 5.85e-05
2025-03-02 11:10:55,896 - INFO - ðŸªœ Batch step - 390 -- sub batch step 1561 -- lr 5.85e-05
2025-03-02 11:10:58,055 - INFO - ðŸªœ Batch step - 390 -- sub batch step 1562 -- lr 5.85e-05
2025-03-02 11:11:00,222 - INFO - ðŸªœ Batch step - 390 -- sub batch step 1563 -- lr 5.85e-05
2025-03-02 11:11:01,812 - INFO - Step 390 -- ðŸ”„ Training Metrics
2025-03-02 11:11:01,812 - INFO - â”œâ”€â”€ Loss: 10.7371
2025-03-02 11:11:01,812 - INFO - â”œâ”€â”€ Learning Rate: 5.85e-05
2025-03-02 11:11:01,813 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:11:02,486 - INFO - ðŸªœ Batch step - 391 -- sub batch step 1564 -- lr 5.86e-05
2025-03-02 11:11:04,644 - INFO - ðŸªœ Batch step - 391 -- sub batch step 1565 -- lr 5.86e-05
2025-03-02 11:11:06,991 - INFO - ðŸªœ Batch step - 391 -- sub batch step 1566 -- lr 5.86e-05
2025-03-02 11:11:09,150 - INFO - ðŸªœ Batch step - 391 -- sub batch step 1567 -- lr 5.86e-05
2025-03-02 11:11:11,141 - INFO - Step 391 -- ðŸ”„ Training Metrics
2025-03-02 11:11:11,141 - INFO - â”œâ”€â”€ Loss: 10.7383
2025-03-02 11:11:11,141 - INFO - â”œâ”€â”€ Learning Rate: 5.86e-05
2025-03-02 11:11:11,141 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:11:11,809 - INFO - ðŸªœ Batch step - 392 -- sub batch step 1568 -- lr 5.88e-05
2025-03-02 11:11:13,966 - INFO - ðŸªœ Batch step - 392 -- sub batch step 1569 -- lr 5.88e-05
2025-03-02 11:11:16,141 - INFO - ðŸªœ Batch step - 392 -- sub batch step 1570 -- lr 5.88e-05
2025-03-02 11:11:18,290 - INFO - ðŸªœ Batch step - 392 -- sub batch step 1571 -- lr 5.88e-05
2025-03-02 11:11:19,878 - INFO - Step 392 -- ðŸ”„ Training Metrics
2025-03-02 11:11:19,878 - INFO - â”œâ”€â”€ Loss: 10.7374
2025-03-02 11:11:19,878 - INFO - â”œâ”€â”€ Learning Rate: 5.88e-05
2025-03-02 11:11:19,879 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:11:20,554 - INFO - ðŸªœ Batch step - 393 -- sub batch step 1572 -- lr 5.89e-05
2025-03-02 11:11:22,705 - INFO - ðŸªœ Batch step - 393 -- sub batch step 1573 -- lr 5.89e-05
2025-03-02 11:11:25,486 - INFO - ðŸªœ Batch step - 393 -- sub batch step 1574 -- lr 5.89e-05
2025-03-02 11:11:27,646 - INFO - ðŸªœ Batch step - 393 -- sub batch step 1575 -- lr 5.89e-05
2025-03-02 11:11:29,616 - INFO - Step 393 -- ðŸ”„ Training Metrics
2025-03-02 11:11:29,617 - INFO - â”œâ”€â”€ Loss: 10.7374
2025-03-02 11:11:29,617 - INFO - â”œâ”€â”€ Learning Rate: 5.89e-05
2025-03-02 11:11:29,617 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:11:30,306 - INFO - ðŸªœ Batch step - 394 -- sub batch step 1576 -- lr 5.91e-05
2025-03-02 11:11:32,465 - INFO - ðŸªœ Batch step - 394 -- sub batch step 1577 -- lr 5.91e-05
2025-03-02 11:11:34,629 - INFO - ðŸªœ Batch step - 394 -- sub batch step 1578 -- lr 5.91e-05
2025-03-02 11:11:36,785 - INFO - ðŸªœ Batch step - 394 -- sub batch step 1579 -- lr 5.91e-05
2025-03-02 11:11:38,348 - INFO - Step 394 -- ðŸ”„ Training Metrics
2025-03-02 11:11:38,348 - INFO - â”œâ”€â”€ Loss: 10.7358
2025-03-02 11:11:38,349 - INFO - â”œâ”€â”€ Learning Rate: 5.91e-05
2025-03-02 11:11:38,349 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:11:39,027 - INFO - ðŸªœ Batch step - 395 -- sub batch step 1580 -- lr 5.92e-05
2025-03-02 11:11:41,181 - INFO - ðŸªœ Batch step - 395 -- sub batch step 1581 -- lr 5.92e-05
2025-03-02 11:11:43,865 - INFO - ðŸªœ Batch step - 395 -- sub batch step 1582 -- lr 5.92e-05
2025-03-02 11:11:46,018 - INFO - ðŸªœ Batch step - 395 -- sub batch step 1583 -- lr 5.92e-05
2025-03-02 11:11:47,586 - INFO - Step 395 -- ðŸ”„ Training Metrics
2025-03-02 11:11:47,586 - INFO - â”œâ”€â”€ Loss: 10.7333
2025-03-02 11:11:47,586 - INFO - â”œâ”€â”€ Learning Rate: 5.92e-05
2025-03-02 11:11:47,586 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:11:48,288 - INFO - ðŸªœ Batch step - 396 -- sub batch step 1584 -- lr 5.94e-05
2025-03-02 11:11:50,445 - INFO - ðŸªœ Batch step - 396 -- sub batch step 1585 -- lr 5.94e-05
2025-03-02 11:11:52,611 - INFO - ðŸªœ Batch step - 396 -- sub batch step 1586 -- lr 5.94e-05
2025-03-02 11:11:54,766 - INFO - ðŸªœ Batch step - 396 -- sub batch step 1587 -- lr 5.94e-05
2025-03-02 11:11:56,336 - INFO - Step 396 -- ðŸ”„ Training Metrics
2025-03-02 11:11:56,336 - INFO - â”œâ”€â”€ Loss: 10.7319
2025-03-02 11:11:56,336 - INFO - â”œâ”€â”€ Learning Rate: 5.94e-05
2025-03-02 11:11:56,336 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:11:57,007 - INFO - ðŸªœ Batch step - 397 -- sub batch step 1588 -- lr 5.95e-05
2025-03-02 11:11:59,160 - INFO - ðŸªœ Batch step - 397 -- sub batch step 1589 -- lr 5.95e-05
2025-03-02 11:12:01,604 - INFO - ðŸªœ Batch step - 397 -- sub batch step 1590 -- lr 5.95e-05
2025-03-02 11:12:03,756 - INFO - ðŸªœ Batch step - 397 -- sub batch step 1591 -- lr 5.95e-05
2025-03-02 11:12:05,614 - INFO - Step 397 -- ðŸ”„ Training Metrics
2025-03-02 11:12:05,614 - INFO - â”œâ”€â”€ Loss: 10.7299
2025-03-02 11:12:05,614 - INFO - â”œâ”€â”€ Learning Rate: 5.95e-05
2025-03-02 11:12:05,614 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:12:06,289 - INFO - ðŸªœ Batch step - 398 -- sub batch step 1592 -- lr 5.97e-05
2025-03-02 11:12:08,442 - INFO - ðŸªœ Batch step - 398 -- sub batch step 1593 -- lr 5.97e-05
2025-03-02 11:12:10,617 - INFO - ðŸªœ Batch step - 398 -- sub batch step 1594 -- lr 5.97e-05
2025-03-02 11:12:12,772 - INFO - ðŸªœ Batch step - 398 -- sub batch step 1595 -- lr 5.97e-05
2025-03-02 11:12:14,339 - INFO - Step 398 -- ðŸ”„ Training Metrics
2025-03-02 11:12:14,339 - INFO - â”œâ”€â”€ Loss: 10.7271
2025-03-02 11:12:14,339 - INFO - â”œâ”€â”€ Learning Rate: 5.97e-05
2025-03-02 11:12:14,340 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:12:15,008 - INFO - ðŸªœ Batch step - 399 -- sub batch step 1596 -- lr 5.98e-05
2025-03-02 11:12:17,165 - INFO - ðŸªœ Batch step - 399 -- sub batch step 1597 -- lr 5.98e-05
2025-03-02 11:12:19,441 - INFO - ðŸªœ Batch step - 399 -- sub batch step 1598 -- lr 5.98e-05
2025-03-02 11:12:21,593 - INFO - ðŸªœ Batch step - 399 -- sub batch step 1599 -- lr 5.98e-05
2025-03-02 11:12:23,399 - INFO - Step 399 -- ðŸ”„ Training Metrics
2025-03-02 11:12:23,400 - INFO - â”œâ”€â”€ Loss: 10.7273
2025-03-02 11:12:23,400 - INFO - â”œâ”€â”€ Learning Rate: 5.98e-05
2025-03-02 11:12:23,400 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:12:24,489 - INFO - ðŸªœ Batch step - 400 -- sub batch step 1600 -- lr 6.00e-05
2025-03-02 11:12:26,644 - INFO - ðŸªœ Batch step - 400 -- sub batch step 1601 -- lr 6.00e-05
2025-03-02 11:12:28,805 - INFO - ðŸªœ Batch step - 400 -- sub batch step 1602 -- lr 6.00e-05
2025-03-02 11:12:30,981 - INFO - ðŸªœ Batch step - 400 -- sub batch step 1603 -- lr 6.00e-05
2025-03-02 11:12:32,724 - INFO - Step 400 -- ðŸ”„ Training Metrics
2025-03-02 11:12:32,724 - INFO - â”œâ”€â”€ Loss: 10.7248
2025-03-02 11:12:32,724 - INFO - â”œâ”€â”€ Learning Rate: 6.00e-05
2025-03-02 11:12:32,724 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:12:33,405 - INFO - ðŸªœ Batch step - 401 -- sub batch step 1604 -- lr 6.01e-05
2025-03-02 11:12:35,567 - INFO - ðŸªœ Batch step - 401 -- sub batch step 1605 -- lr 6.01e-05
2025-03-02 11:12:37,716 - INFO - ðŸªœ Batch step - 401 -- sub batch step 1606 -- lr 6.01e-05
2025-03-02 11:12:40,422 - INFO - ðŸªœ Batch step - 401 -- sub batch step 1607 -- lr 6.01e-05
2025-03-02 11:12:41,980 - INFO - Step 401 -- ðŸ”„ Training Metrics
2025-03-02 11:12:41,980 - INFO - â”œâ”€â”€ Loss: 10.7224
2025-03-02 11:12:41,980 - INFO - â”œâ”€â”€ Learning Rate: 6.01e-05
2025-03-02 11:12:41,981 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:12:42,653 - INFO - ðŸªœ Batch step - 402 -- sub batch step 1608 -- lr 6.03e-05
2025-03-02 11:12:44,815 - INFO - ðŸªœ Batch step - 402 -- sub batch step 1609 -- lr 6.03e-05
2025-03-02 11:12:46,974 - INFO - ðŸªœ Batch step - 402 -- sub batch step 1610 -- lr 6.03e-05
2025-03-02 11:12:49,142 - INFO - ðŸªœ Batch step - 402 -- sub batch step 1611 -- lr 6.03e-05
2025-03-02 11:12:50,718 - INFO - Step 402 -- ðŸ”„ Training Metrics
2025-03-02 11:12:50,732 - INFO - â”œâ”€â”€ Loss: 10.7196
2025-03-02 11:12:50,733 - INFO - â”œâ”€â”€ Learning Rate: 6.03e-05
2025-03-02 11:12:50,733 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:12:51,407 - INFO - ðŸªœ Batch step - 403 -- sub batch step 1612 -- lr 6.04e-05
2025-03-02 11:12:53,563 - INFO - ðŸªœ Batch step - 403 -- sub batch step 1613 -- lr 6.04e-05
2025-03-02 11:12:55,749 - INFO - ðŸªœ Batch step - 403 -- sub batch step 1614 -- lr 6.04e-05
2025-03-02 11:12:58,356 - INFO - ðŸªœ Batch step - 403 -- sub batch step 1615 -- lr 6.04e-05
2025-03-02 11:12:59,937 - INFO - Step 403 -- ðŸ”„ Training Metrics
2025-03-02 11:12:59,937 - INFO - â”œâ”€â”€ Loss: 10.7188
2025-03-02 11:12:59,937 - INFO - â”œâ”€â”€ Learning Rate: 6.04e-05
2025-03-02 11:12:59,937 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:13:00,614 - INFO - ðŸªœ Batch step - 404 -- sub batch step 1616 -- lr 6.06e-05
2025-03-02 11:13:02,772 - INFO - ðŸªœ Batch step - 404 -- sub batch step 1617 -- lr 6.06e-05
2025-03-02 11:13:04,920 - INFO - ðŸªœ Batch step - 404 -- sub batch step 1618 -- lr 6.06e-05
2025-03-02 11:13:07,147 - INFO - ðŸªœ Batch step - 404 -- sub batch step 1619 -- lr 6.06e-05
2025-03-02 11:13:08,675 - INFO - Step 404 -- ðŸ”„ Training Metrics
2025-03-02 11:13:08,675 - INFO - â”œâ”€â”€ Loss: 10.7183
2025-03-02 11:13:08,676 - INFO - â”œâ”€â”€ Learning Rate: 6.06e-05
2025-03-02 11:13:08,676 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:13:09,353 - INFO - ðŸªœ Batch step - 405 -- sub batch step 1620 -- lr 6.07e-05
2025-03-02 11:13:11,512 - INFO - ðŸªœ Batch step - 405 -- sub batch step 1621 -- lr 6.07e-05
2025-03-02 11:13:13,672 - INFO - ðŸªœ Batch step - 405 -- sub batch step 1622 -- lr 6.07e-05
2025-03-02 11:13:16,286 - INFO - ðŸªœ Batch step - 405 -- sub batch step 1623 -- lr 6.07e-05
2025-03-02 11:13:17,946 - INFO - Step 405 -- ðŸ”„ Training Metrics
2025-03-02 11:13:17,947 - INFO - â”œâ”€â”€ Loss: 10.7174
2025-03-02 11:13:17,947 - INFO - â”œâ”€â”€ Learning Rate: 6.07e-05
2025-03-02 11:13:17,947 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:13:18,619 - INFO - ðŸªœ Batch step - 406 -- sub batch step 1624 -- lr 6.09e-05
2025-03-02 11:13:20,780 - INFO - ðŸªœ Batch step - 406 -- sub batch step 1625 -- lr 6.09e-05
2025-03-02 11:13:22,931 - INFO - ðŸªœ Batch step - 406 -- sub batch step 1626 -- lr 6.09e-05
2025-03-02 11:13:25,105 - INFO - ðŸªœ Batch step - 406 -- sub batch step 1627 -- lr 6.09e-05
2025-03-02 11:13:26,694 - INFO - Step 406 -- ðŸ”„ Training Metrics
2025-03-02 11:13:26,694 - INFO - â”œâ”€â”€ Loss: 10.7127
2025-03-02 11:13:26,695 - INFO - â”œâ”€â”€ Learning Rate: 6.09e-05
2025-03-02 11:13:26,695 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:13:27,370 - INFO - ðŸªœ Batch step - 407 -- sub batch step 1628 -- lr 6.10e-05
2025-03-02 11:13:29,524 - INFO - ðŸªœ Batch step - 407 -- sub batch step 1629 -- lr 6.10e-05
2025-03-02 11:13:31,683 - INFO - ðŸªœ Batch step - 407 -- sub batch step 1630 -- lr 6.10e-05
2025-03-02 11:13:34,033 - INFO - ðŸªœ Batch step - 407 -- sub batch step 1631 -- lr 6.10e-05
2025-03-02 11:13:35,890 - INFO - Step 407 -- ðŸ”„ Training Metrics
2025-03-02 11:13:35,890 - INFO - â”œâ”€â”€ Loss: 10.7144
2025-03-02 11:13:35,890 - INFO - â”œâ”€â”€ Learning Rate: 6.10e-05
2025-03-02 11:13:35,890 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:13:36,571 - INFO - ðŸªœ Batch step - 408 -- sub batch step 1632 -- lr 6.12e-05
2025-03-02 11:13:38,725 - INFO - ðŸªœ Batch step - 408 -- sub batch step 1633 -- lr 6.12e-05
2025-03-02 11:13:40,882 - INFO - ðŸªœ Batch step - 408 -- sub batch step 1634 -- lr 6.12e-05
2025-03-02 11:13:43,058 - INFO - ðŸªœ Batch step - 408 -- sub batch step 1635 -- lr 6.12e-05
2025-03-02 11:13:44,826 - INFO - Step 408 -- ðŸ”„ Training Metrics
2025-03-02 11:13:44,826 - INFO - â”œâ”€â”€ Loss: 10.7094
2025-03-02 11:13:44,826 - INFO - â”œâ”€â”€ Learning Rate: 6.12e-05
2025-03-02 11:13:44,826 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:13:45,671 - INFO - ðŸªœ Batch step - 409 -- sub batch step 1636 -- lr 6.13e-05
2025-03-02 11:13:47,833 - INFO - ðŸªœ Batch step - 409 -- sub batch step 1637 -- lr 6.13e-05
2025-03-02 11:13:49,987 - INFO - ðŸªœ Batch step - 409 -- sub batch step 1638 -- lr 6.13e-05
2025-03-02 11:13:52,850 - INFO - ðŸªœ Batch step - 409 -- sub batch step 1639 -- lr 6.13e-05
2025-03-02 11:13:54,344 - INFO - Step 409 -- ðŸ”„ Training Metrics
2025-03-02 11:13:54,344 - INFO - â”œâ”€â”€ Loss: 10.7103
2025-03-02 11:13:54,344 - INFO - â”œâ”€â”€ Learning Rate: 6.13e-05
2025-03-02 11:13:54,344 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:13:55,022 - INFO - ðŸªœ Batch step - 410 -- sub batch step 1640 -- lr 6.15e-05
2025-03-02 11:13:57,177 - INFO - ðŸªœ Batch step - 410 -- sub batch step 1641 -- lr 6.15e-05
2025-03-02 11:13:59,333 - INFO - ðŸªœ Batch step - 410 -- sub batch step 1642 -- lr 6.15e-05
2025-03-02 11:14:01,494 - INFO - ðŸªœ Batch step - 410 -- sub batch step 1643 -- lr 6.15e-05
2025-03-02 11:14:03,092 - INFO - Step 410 -- ðŸ”„ Training Metrics
2025-03-02 11:14:03,093 - INFO - â”œâ”€â”€ Loss: 10.7079
2025-03-02 11:14:03,093 - INFO - â”œâ”€â”€ Learning Rate: 6.15e-05
2025-03-02 11:14:03,093 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:14:03,800 - INFO - ðŸªœ Batch step - 411 -- sub batch step 1644 -- lr 6.16e-05
2025-03-02 11:14:05,957 - INFO - ðŸªœ Batch step - 411 -- sub batch step 1645 -- lr 6.16e-05
2025-03-02 11:14:08,587 - INFO - ðŸªœ Batch step - 411 -- sub batch step 1646 -- lr 6.16e-05
2025-03-02 11:14:10,745 - INFO - ðŸªœ Batch step - 411 -- sub batch step 1647 -- lr 6.16e-05
2025-03-02 11:14:12,472 - INFO - Step 411 -- ðŸ”„ Training Metrics
2025-03-02 11:14:12,472 - INFO - â”œâ”€â”€ Loss: 10.7068
2025-03-02 11:14:12,472 - INFO - â”œâ”€â”€ Learning Rate: 6.16e-05
2025-03-02 11:14:12,472 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:14:13,146 - INFO - ðŸªœ Batch step - 412 -- sub batch step 1648 -- lr 6.18e-05
2025-03-02 11:14:15,303 - INFO - ðŸªœ Batch step - 412 -- sub batch step 1649 -- lr 6.18e-05
2025-03-02 11:14:17,479 - INFO - ðŸªœ Batch step - 412 -- sub batch step 1650 -- lr 6.18e-05
2025-03-02 11:14:19,628 - INFO - ðŸªœ Batch step - 412 -- sub batch step 1651 -- lr 6.18e-05
2025-03-02 11:14:21,217 - INFO - Step 412 -- ðŸ”„ Training Metrics
2025-03-02 11:14:21,217 - INFO - â”œâ”€â”€ Loss: 10.7033
2025-03-02 11:14:21,217 - INFO - â”œâ”€â”€ Learning Rate: 6.18e-05
2025-03-02 11:14:21,217 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:14:21,895 - INFO - ðŸªœ Batch step - 413 -- sub batch step 1652 -- lr 6.19e-05
2025-03-02 11:14:24,046 - INFO - ðŸªœ Batch step - 413 -- sub batch step 1653 -- lr 6.19e-05
2025-03-02 11:14:26,677 - INFO - ðŸªœ Batch step - 413 -- sub batch step 1654 -- lr 6.19e-05
2025-03-02 11:14:28,838 - INFO - ðŸªœ Batch step - 413 -- sub batch step 1655 -- lr 6.19e-05
2025-03-02 11:14:30,822 - INFO - Step 413 -- ðŸ”„ Training Metrics
2025-03-02 11:14:30,822 - INFO - â”œâ”€â”€ Loss: 10.7033
2025-03-02 11:14:30,822 - INFO - â”œâ”€â”€ Learning Rate: 6.19e-05
2025-03-02 11:14:30,822 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:14:31,496 - INFO - ðŸªœ Batch step - 414 -- sub batch step 1656 -- lr 6.21e-05
2025-03-02 11:14:33,651 - INFO - ðŸªœ Batch step - 414 -- sub batch step 1657 -- lr 6.21e-05
2025-03-02 11:14:35,822 - INFO - ðŸªœ Batch step - 414 -- sub batch step 1658 -- lr 6.21e-05
2025-03-02 11:14:37,975 - INFO - ðŸªœ Batch step - 414 -- sub batch step 1659 -- lr 6.21e-05
2025-03-02 11:14:39,550 - INFO - Step 414 -- ðŸ”„ Training Metrics
2025-03-02 11:14:39,550 - INFO - â”œâ”€â”€ Loss: 10.7004
2025-03-02 11:14:39,550 - INFO - â”œâ”€â”€ Learning Rate: 6.21e-05
2025-03-02 11:14:39,550 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:14:40,227 - INFO - ðŸªœ Batch step - 415 -- sub batch step 1660 -- lr 6.22e-05
2025-03-02 11:14:42,376 - INFO - ðŸªœ Batch step - 415 -- sub batch step 1661 -- lr 6.22e-05
2025-03-02 11:14:44,856 - INFO - ðŸªœ Batch step - 415 -- sub batch step 1662 -- lr 6.22e-05
2025-03-02 11:14:47,012 - INFO - ðŸªœ Batch step - 415 -- sub batch step 1663 -- lr 6.22e-05
2025-03-02 11:14:48,897 - INFO - Step 415 -- ðŸ”„ Training Metrics
2025-03-02 11:14:48,898 - INFO - â”œâ”€â”€ Loss: 10.6990
2025-03-02 11:14:48,898 - INFO - â”œâ”€â”€ Learning Rate: 6.22e-05
2025-03-02 11:14:48,898 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:14:49,575 - INFO - ðŸªœ Batch step - 416 -- sub batch step 1664 -- lr 6.24e-05
2025-03-02 11:14:51,732 - INFO - ðŸªœ Batch step - 416 -- sub batch step 1665 -- lr 6.24e-05
2025-03-02 11:14:53,897 - INFO - ðŸªœ Batch step - 416 -- sub batch step 1666 -- lr 6.24e-05
2025-03-02 11:14:56,053 - INFO - ðŸªœ Batch step - 416 -- sub batch step 1667 -- lr 6.24e-05
2025-03-02 11:14:57,623 - INFO - Step 416 -- ðŸ”„ Training Metrics
2025-03-02 11:14:57,623 - INFO - â”œâ”€â”€ Loss: 10.6999
2025-03-02 11:14:57,623 - INFO - â”œâ”€â”€ Learning Rate: 6.24e-05
2025-03-02 11:14:57,623 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:14:58,295 - INFO - ðŸªœ Batch step - 417 -- sub batch step 1668 -- lr 6.25e-05
2025-03-02 11:15:00,454 - INFO - ðŸªœ Batch step - 417 -- sub batch step 1669 -- lr 6.25e-05
2025-03-02 11:15:03,262 - INFO - ðŸªœ Batch step - 417 -- sub batch step 1670 -- lr 6.25e-05
2025-03-02 11:15:05,412 - INFO - ðŸªœ Batch step - 417 -- sub batch step 1671 -- lr 6.25e-05
2025-03-02 11:15:06,906 - INFO - Step 417 -- ðŸ”„ Training Metrics
2025-03-02 11:15:06,906 - INFO - â”œâ”€â”€ Loss: 10.6955
2025-03-02 11:15:06,906 - INFO - â”œâ”€â”€ Learning Rate: 6.25e-05
2025-03-02 11:15:06,906 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:15:07,578 - INFO - ðŸªœ Batch step - 418 -- sub batch step 1672 -- lr 6.27e-05
2025-03-02 11:15:09,727 - INFO - ðŸªœ Batch step - 418 -- sub batch step 1673 -- lr 6.27e-05
2025-03-02 11:15:11,893 - INFO - ðŸªœ Batch step - 418 -- sub batch step 1674 -- lr 6.27e-05
2025-03-02 11:15:14,179 - INFO - ðŸªœ Batch step - 418 -- sub batch step 1675 -- lr 6.27e-05
2025-03-02 11:15:15,829 - INFO - Step 418 -- ðŸ”„ Training Metrics
2025-03-02 11:15:15,830 - INFO - â”œâ”€â”€ Loss: 10.6914
2025-03-02 11:15:15,830 - INFO - â”œâ”€â”€ Learning Rate: 6.27e-05
2025-03-02 11:15:15,830 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:15:16,593 - INFO - ðŸªœ Batch step - 419 -- sub batch step 1676 -- lr 6.28e-05
2025-03-02 11:15:18,744 - INFO - ðŸªœ Batch step - 419 -- sub batch step 1677 -- lr 6.28e-05
2025-03-02 11:15:21,018 - INFO - ðŸªœ Batch step - 419 -- sub batch step 1678 -- lr 6.28e-05
2025-03-02 11:15:23,179 - INFO - ðŸªœ Batch step - 419 -- sub batch step 1679 -- lr 6.28e-05
2025-03-02 11:15:24,798 - INFO - Step 419 -- ðŸ”„ Training Metrics
2025-03-02 11:15:24,798 - INFO - â”œâ”€â”€ Loss: 10.6939
2025-03-02 11:15:24,799 - INFO - â”œâ”€â”€ Learning Rate: 6.28e-05
2025-03-02 11:15:24,799 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:15:26,035 - INFO - ðŸªœ Batch step - 420 -- sub batch step 1680 -- lr 6.30e-05
2025-03-02 11:15:28,203 - INFO - ðŸªœ Batch step - 420 -- sub batch step 1681 -- lr 6.30e-05
2025-03-02 11:15:30,378 - INFO - ðŸªœ Batch step - 420 -- sub batch step 1682 -- lr 6.30e-05
2025-03-02 11:15:32,577 - INFO - ðŸªœ Batch step - 420 -- sub batch step 1683 -- lr 6.30e-05
2025-03-02 11:15:34,115 - INFO - Step 420 -- ðŸ”„ Training Metrics
2025-03-02 11:15:34,115 - INFO - â”œâ”€â”€ Loss: 10.6899
2025-03-02 11:15:34,116 - INFO - â”œâ”€â”€ Learning Rate: 6.30e-05
2025-03-02 11:15:34,116 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:15:34,802 - INFO - ðŸªœ Batch step - 421 -- sub batch step 1684 -- lr 6.31e-05
2025-03-02 11:15:36,973 - INFO - ðŸªœ Batch step - 421 -- sub batch step 1685 -- lr 6.31e-05
2025-03-02 11:15:39,135 - INFO - ðŸªœ Batch step - 421 -- sub batch step 1686 -- lr 6.31e-05
2025-03-02 11:15:41,617 - INFO - ðŸªœ Batch step - 421 -- sub batch step 1687 -- lr 6.31e-05
2025-03-02 11:15:43,264 - INFO - Step 421 -- ðŸ”„ Training Metrics
2025-03-02 11:15:43,265 - INFO - â”œâ”€â”€ Loss: 10.6940
2025-03-02 11:15:43,265 - INFO - â”œâ”€â”€ Learning Rate: 6.31e-05
2025-03-02 11:15:43,265 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:15:43,943 - INFO - ðŸªœ Batch step - 422 -- sub batch step 1688 -- lr 6.33e-05
2025-03-02 11:15:46,108 - INFO - ðŸªœ Batch step - 422 -- sub batch step 1689 -- lr 6.33e-05
2025-03-02 11:15:48,272 - INFO - ðŸªœ Batch step - 422 -- sub batch step 1690 -- lr 6.33e-05
2025-03-02 11:15:50,443 - INFO - ðŸªœ Batch step - 422 -- sub batch step 1691 -- lr 6.33e-05
2025-03-02 11:15:51,992 - INFO - Step 422 -- ðŸ”„ Training Metrics
2025-03-02 11:15:51,992 - INFO - â”œâ”€â”€ Loss: 10.6886
2025-03-02 11:15:51,992 - INFO - â”œâ”€â”€ Learning Rate: 6.33e-05
2025-03-02 11:15:51,992 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:15:52,668 - INFO - ðŸªœ Batch step - 423 -- sub batch step 1692 -- lr 6.34e-05
2025-03-02 11:15:54,820 - INFO - ðŸªœ Batch step - 423 -- sub batch step 1693 -- lr 6.34e-05
2025-03-02 11:15:56,973 - INFO - ðŸªœ Batch step - 423 -- sub batch step 1694 -- lr 6.34e-05
2025-03-02 11:15:59,557 - INFO - ðŸªœ Batch step - 423 -- sub batch step 1695 -- lr 6.34e-05
2025-03-02 11:16:01,149 - INFO - Step 423 -- ðŸ”„ Training Metrics
2025-03-02 11:16:01,149 - INFO - â”œâ”€â”€ Loss: 10.6834
2025-03-02 11:16:01,149 - INFO - â”œâ”€â”€ Learning Rate: 6.34e-05
2025-03-02 11:16:01,149 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:16:01,822 - INFO - ðŸªœ Batch step - 424 -- sub batch step 1696 -- lr 6.36e-05
2025-03-02 11:16:03,980 - INFO - ðŸªœ Batch step - 424 -- sub batch step 1697 -- lr 6.36e-05
2025-03-02 11:16:06,134 - INFO - ðŸªœ Batch step - 424 -- sub batch step 1698 -- lr 6.36e-05
2025-03-02 11:16:08,310 - INFO - ðŸªœ Batch step - 424 -- sub batch step 1699 -- lr 6.36e-05
2025-03-02 11:16:09,874 - INFO - Step 424 -- ðŸ”„ Training Metrics
2025-03-02 11:16:09,874 - INFO - â”œâ”€â”€ Loss: 10.6828
2025-03-02 11:16:09,874 - INFO - â”œâ”€â”€ Learning Rate: 6.36e-05
2025-03-02 11:16:09,874 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:16:10,551 - INFO - ðŸªœ Batch step - 425 -- sub batch step 1700 -- lr 6.37e-05
2025-03-02 11:16:12,705 - INFO - ðŸªœ Batch step - 425 -- sub batch step 1701 -- lr 6.37e-05
2025-03-02 11:16:14,868 - INFO - ðŸªœ Batch step - 425 -- sub batch step 1702 -- lr 6.37e-05
2025-03-02 11:16:17,269 - INFO - ðŸªœ Batch step - 425 -- sub batch step 1703 -- lr 6.37e-05
2025-03-02 11:16:19,238 - INFO - Step 425 -- ðŸ”„ Training Metrics
2025-03-02 11:16:19,239 - INFO - â”œâ”€â”€ Loss: 10.6845
2025-03-02 11:16:19,239 - INFO - â”œâ”€â”€ Learning Rate: 6.37e-05
2025-03-02 11:16:19,239 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:16:19,916 - INFO - ðŸªœ Batch step - 426 -- sub batch step 1704 -- lr 6.39e-05
2025-03-02 11:16:22,074 - INFO - ðŸªœ Batch step - 426 -- sub batch step 1705 -- lr 6.39e-05
2025-03-02 11:16:24,227 - INFO - ðŸªœ Batch step - 426 -- sub batch step 1706 -- lr 6.39e-05
2025-03-02 11:16:26,405 - INFO - ðŸªœ Batch step - 426 -- sub batch step 1707 -- lr 6.39e-05
2025-03-02 11:16:27,981 - INFO - Step 426 -- ðŸ”„ Training Metrics
2025-03-02 11:16:27,982 - INFO - â”œâ”€â”€ Loss: 10.6797
2025-03-02 11:16:27,982 - INFO - â”œâ”€â”€ Learning Rate: 6.39e-05
2025-03-02 11:16:27,982 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:16:28,656 - INFO - ðŸªœ Batch step - 427 -- sub batch step 1708 -- lr 6.40e-05
2025-03-02 11:16:30,812 - INFO - ðŸªœ Batch step - 427 -- sub batch step 1709 -- lr 6.40e-05
2025-03-02 11:16:32,967 - INFO - ðŸªœ Batch step - 427 -- sub batch step 1710 -- lr 6.40e-05
2025-03-02 11:16:35,818 - INFO - ðŸªœ Batch step - 427 -- sub batch step 1711 -- lr 6.40e-05
2025-03-02 11:16:37,312 - INFO - Step 427 -- ðŸ”„ Training Metrics
2025-03-02 11:16:37,312 - INFO - â”œâ”€â”€ Loss: 10.6757
2025-03-02 11:16:37,312 - INFO - â”œâ”€â”€ Learning Rate: 6.40e-05
2025-03-02 11:16:37,312 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:16:37,993 - INFO - ðŸªœ Batch step - 428 -- sub batch step 1712 -- lr 6.42e-05
2025-03-02 11:16:40,142 - INFO - ðŸªœ Batch step - 428 -- sub batch step 1713 -- lr 6.42e-05
2025-03-02 11:16:42,297 - INFO - ðŸªœ Batch step - 428 -- sub batch step 1714 -- lr 6.42e-05
2025-03-02 11:16:44,477 - INFO - ðŸªœ Batch step - 428 -- sub batch step 1715 -- lr 6.42e-05
2025-03-02 11:16:46,053 - INFO - Step 428 -- ðŸ”„ Training Metrics
2025-03-02 11:16:46,053 - INFO - â”œâ”€â”€ Loss: 10.6773
2025-03-02 11:16:46,054 - INFO - â”œâ”€â”€ Learning Rate: 6.42e-05
2025-03-02 11:16:46,054 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:16:46,725 - INFO - ðŸªœ Batch step - 429 -- sub batch step 1716 -- lr 6.43e-05
2025-03-02 11:16:48,880 - INFO - ðŸªœ Batch step - 429 -- sub batch step 1717 -- lr 6.43e-05
2025-03-02 11:16:51,031 - INFO - ðŸªœ Batch step - 429 -- sub batch step 1718 -- lr 6.43e-05
2025-03-02 11:16:53,680 - INFO - ðŸªœ Batch step - 429 -- sub batch step 1719 -- lr 6.43e-05
2025-03-02 11:16:55,182 - INFO - Step 429 -- ðŸ”„ Training Metrics
2025-03-02 11:16:55,182 - INFO - â”œâ”€â”€ Loss: 10.6722
2025-03-02 11:16:55,182 - INFO - â”œâ”€â”€ Learning Rate: 6.43e-05
2025-03-02 11:16:55,183 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:16:55,860 - INFO - ðŸªœ Batch step - 430 -- sub batch step 1720 -- lr 6.45e-05
2025-03-02 11:16:58,019 - INFO - ðŸªœ Batch step - 430 -- sub batch step 1721 -- lr 6.45e-05
2025-03-02 11:17:00,174 - INFO - ðŸªœ Batch step - 430 -- sub batch step 1722 -- lr 6.45e-05
2025-03-02 11:17:02,341 - INFO - ðŸªœ Batch step - 430 -- sub batch step 1723 -- lr 6.45e-05
2025-03-02 11:17:03,878 - INFO - Step 430 -- ðŸ”„ Training Metrics
2025-03-02 11:17:03,878 - INFO - â”œâ”€â”€ Loss: 10.6715
2025-03-02 11:17:03,879 - INFO - â”œâ”€â”€ Learning Rate: 6.45e-05
2025-03-02 11:17:03,879 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:17:04,554 - INFO - ðŸªœ Batch step - 431 -- sub batch step 1724 -- lr 6.46e-05
2025-03-02 11:17:06,709 - INFO - ðŸªœ Batch step - 431 -- sub batch step 1725 -- lr 6.46e-05
2025-03-02 11:17:09,351 - INFO - ðŸªœ Batch step - 431 -- sub batch step 1726 -- lr 6.46e-05
2025-03-02 11:17:11,506 - INFO - ðŸªœ Batch step - 431 -- sub batch step 1727 -- lr 6.46e-05
2025-03-02 11:17:13,031 - INFO - Step 431 -- ðŸ”„ Training Metrics
2025-03-02 11:17:13,032 - INFO - â”œâ”€â”€ Loss: 10.6708
2025-03-02 11:17:13,032 - INFO - â”œâ”€â”€ Learning Rate: 6.46e-05
2025-03-02 11:17:13,032 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:17:13,700 - INFO - ðŸªœ Batch step - 432 -- sub batch step 1728 -- lr 6.48e-05
2025-03-02 11:17:15,853 - INFO - ðŸªœ Batch step - 432 -- sub batch step 1729 -- lr 6.48e-05
2025-03-02 11:17:18,025 - INFO - ðŸªœ Batch step - 432 -- sub batch step 1730 -- lr 6.48e-05
2025-03-02 11:17:20,171 - INFO - ðŸªœ Batch step - 432 -- sub batch step 1731 -- lr 6.48e-05
2025-03-02 11:17:21,730 - INFO - Step 432 -- ðŸ”„ Training Metrics
2025-03-02 11:17:21,730 - INFO - â”œâ”€â”€ Loss: 10.6664
2025-03-02 11:17:21,730 - INFO - â”œâ”€â”€ Learning Rate: 6.48e-05
2025-03-02 11:17:21,730 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:17:22,403 - INFO - ðŸªœ Batch step - 433 -- sub batch step 1732 -- lr 6.49e-05
2025-03-02 11:17:24,552 - INFO - ðŸªœ Batch step - 433 -- sub batch step 1733 -- lr 6.49e-05
2025-03-02 11:17:27,366 - INFO - ðŸªœ Batch step - 433 -- sub batch step 1734 -- lr 6.49e-05
2025-03-02 11:17:29,526 - INFO - ðŸªœ Batch step - 433 -- sub batch step 1735 -- lr 6.49e-05
2025-03-02 11:17:31,020 - INFO - Step 433 -- ðŸ”„ Training Metrics
2025-03-02 11:17:31,021 - INFO - â”œâ”€â”€ Loss: 10.6670
2025-03-02 11:17:31,021 - INFO - â”œâ”€â”€ Learning Rate: 6.49e-05
2025-03-02 11:17:31,021 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:17:31,689 - INFO - ðŸªœ Batch step - 434 -- sub batch step 1736 -- lr 6.51e-05
2025-03-02 11:17:33,843 - INFO - ðŸªœ Batch step - 434 -- sub batch step 1737 -- lr 6.51e-05
2025-03-02 11:17:36,012 - INFO - ðŸªœ Batch step - 434 -- sub batch step 1738 -- lr 6.51e-05
2025-03-02 11:17:38,167 - INFO - ðŸªœ Batch step - 434 -- sub batch step 1739 -- lr 6.51e-05
2025-03-02 11:17:39,723 - INFO - Step 434 -- ðŸ”„ Training Metrics
2025-03-02 11:17:39,723 - INFO - â”œâ”€â”€ Loss: 10.6661
2025-03-02 11:17:39,723 - INFO - â”œâ”€â”€ Learning Rate: 6.51e-05
2025-03-02 11:17:39,723 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:17:40,397 - INFO - ðŸªœ Batch step - 435 -- sub batch step 1740 -- lr 6.53e-05
2025-03-02 11:17:42,547 - INFO - ðŸªœ Batch step - 435 -- sub batch step 1741 -- lr 6.53e-05
2025-03-02 11:17:45,161 - INFO - ðŸªœ Batch step - 435 -- sub batch step 1742 -- lr 6.53e-05
2025-03-02 11:17:47,309 - INFO - ðŸªœ Batch step - 435 -- sub batch step 1743 -- lr 6.53e-05
2025-03-02 11:17:48,874 - INFO - Step 435 -- ðŸ”„ Training Metrics
2025-03-02 11:17:48,874 - INFO - â”œâ”€â”€ Loss: 10.6619
2025-03-02 11:17:48,874 - INFO - â”œâ”€â”€ Learning Rate: 6.53e-05
2025-03-02 11:17:48,874 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:17:49,547 - INFO - ðŸªœ Batch step - 436 -- sub batch step 1744 -- lr 6.54e-05
2025-03-02 11:17:51,696 - INFO - ðŸªœ Batch step - 436 -- sub batch step 1745 -- lr 6.54e-05
2025-03-02 11:17:53,864 - INFO - ðŸªœ Batch step - 436 -- sub batch step 1746 -- lr 6.54e-05
2025-03-02 11:17:56,018 - INFO - ðŸªœ Batch step - 436 -- sub batch step 1747 -- lr 6.54e-05
2025-03-02 11:17:57,593 - INFO - Step 436 -- ðŸ”„ Training Metrics
2025-03-02 11:17:57,593 - INFO - â”œâ”€â”€ Loss: 10.6581
2025-03-02 11:17:57,593 - INFO - â”œâ”€â”€ Learning Rate: 6.54e-05
2025-03-02 11:17:57,593 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:17:58,264 - INFO - ðŸªœ Batch step - 437 -- sub batch step 1748 -- lr 6.55e-05
2025-03-02 11:18:00,419 - INFO - ðŸªœ Batch step - 437 -- sub batch step 1749 -- lr 6.55e-05
2025-03-02 11:18:02,825 - INFO - ðŸªœ Batch step - 437 -- sub batch step 1750 -- lr 6.55e-05
2025-03-02 11:18:04,970 - INFO - ðŸªœ Batch step - 437 -- sub batch step 1751 -- lr 6.55e-05
2025-03-02 11:18:06,900 - INFO - Step 437 -- ðŸ”„ Training Metrics
2025-03-02 11:18:06,901 - INFO - â”œâ”€â”€ Loss: 10.6617
2025-03-02 11:18:06,901 - INFO - â”œâ”€â”€ Learning Rate: 6.55e-05
2025-03-02 11:18:06,901 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:18:07,578 - INFO - ðŸªœ Batch step - 438 -- sub batch step 1752 -- lr 6.57e-05
2025-03-02 11:18:09,724 - INFO - ðŸªœ Batch step - 438 -- sub batch step 1753 -- lr 6.57e-05
2025-03-02 11:18:11,896 - INFO - ðŸªœ Batch step - 438 -- sub batch step 1754 -- lr 6.57e-05
2025-03-02 11:18:14,049 - INFO - ðŸªœ Batch step - 438 -- sub batch step 1755 -- lr 6.57e-05
2025-03-02 11:18:15,608 - INFO - Step 438 -- ðŸ”„ Training Metrics
2025-03-02 11:18:15,609 - INFO - â”œâ”€â”€ Loss: 10.6598
2025-03-02 11:18:15,609 - INFO - â”œâ”€â”€ Learning Rate: 6.57e-05
2025-03-02 11:18:15,609 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:18:16,276 - INFO - ðŸªœ Batch step - 439 -- sub batch step 1756 -- lr 6.58e-05
2025-03-02 11:18:18,430 - INFO - ðŸªœ Batch step - 439 -- sub batch step 1757 -- lr 6.58e-05
2025-03-02 11:18:20,710 - INFO - ðŸªœ Batch step - 439 -- sub batch step 1758 -- lr 6.58e-05
2025-03-02 11:18:22,861 - INFO - ðŸªœ Batch step - 439 -- sub batch step 1759 -- lr 6.58e-05
2025-03-02 11:18:24,409 - INFO - Step 439 -- ðŸ”„ Training Metrics
2025-03-02 11:18:24,409 - INFO - â”œâ”€â”€ Loss: 10.6549
2025-03-02 11:18:24,409 - INFO - â”œâ”€â”€ Learning Rate: 6.58e-05
2025-03-02 11:18:24,410 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:18:25,643 - INFO - ðŸªœ Batch step - 440 -- sub batch step 1760 -- lr 6.60e-05
2025-03-02 11:18:27,803 - INFO - ðŸªœ Batch step - 440 -- sub batch step 1761 -- lr 6.60e-05
2025-03-02 11:18:29,963 - INFO - ðŸªœ Batch step - 440 -- sub batch step 1762 -- lr 6.60e-05
2025-03-02 11:18:32,144 - INFO - ðŸªœ Batch step - 440 -- sub batch step 1763 -- lr 6.60e-05
2025-03-02 11:18:33,727 - INFO - Step 440 -- ðŸ”„ Training Metrics
2025-03-02 11:18:33,727 - INFO - â”œâ”€â”€ Loss: 10.6507
2025-03-02 11:18:33,727 - INFO - â”œâ”€â”€ Learning Rate: 6.60e-05
2025-03-02 11:18:33,727 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:18:34,405 - INFO - ðŸªœ Batch step - 441 -- sub batch step 1764 -- lr 6.61e-05
2025-03-02 11:18:36,566 - INFO - ðŸªœ Batch step - 441 -- sub batch step 1765 -- lr 6.61e-05
2025-03-02 11:18:38,714 - INFO - ðŸªœ Batch step - 441 -- sub batch step 1766 -- lr 6.61e-05
2025-03-02 11:18:42,084 - INFO - ðŸªœ Batch step - 441 -- sub batch step 1767 -- lr 6.61e-05
2025-03-02 11:18:43,778 - INFO - Step 441 -- ðŸ”„ Training Metrics
2025-03-02 11:18:43,779 - INFO - â”œâ”€â”€ Loss: 10.6489
2025-03-02 11:18:43,779 - INFO - â”œâ”€â”€ Learning Rate: 6.61e-05
2025-03-02 11:18:43,779 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:18:44,446 - INFO - ðŸªœ Batch step - 442 -- sub batch step 1768 -- lr 6.63e-05
2025-03-02 11:18:46,597 - INFO - ðŸªœ Batch step - 442 -- sub batch step 1769 -- lr 6.63e-05
2025-03-02 11:18:48,750 - INFO - ðŸªœ Batch step - 442 -- sub batch step 1770 -- lr 6.63e-05
2025-03-02 11:18:50,916 - INFO - ðŸªœ Batch step - 442 -- sub batch step 1771 -- lr 6.63e-05
2025-03-02 11:18:52,480 - INFO - Step 442 -- ðŸ”„ Training Metrics
2025-03-02 11:18:52,480 - INFO - â”œâ”€â”€ Loss: 10.6536
2025-03-02 11:18:52,480 - INFO - â”œâ”€â”€ Learning Rate: 6.63e-05
2025-03-02 11:18:52,480 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:18:53,156 - INFO - ðŸªœ Batch step - 443 -- sub batch step 1772 -- lr 6.64e-05
2025-03-02 11:18:55,303 - INFO - ðŸªœ Batch step - 443 -- sub batch step 1773 -- lr 6.64e-05
2025-03-02 11:18:57,458 - INFO - ðŸªœ Batch step - 443 -- sub batch step 1774 -- lr 6.64e-05
2025-03-02 11:19:00,090 - INFO - ðŸªœ Batch step - 443 -- sub batch step 1775 -- lr 6.64e-05
2025-03-02 11:19:01,752 - INFO - Step 443 -- ðŸ”„ Training Metrics
2025-03-02 11:19:01,752 - INFO - â”œâ”€â”€ Loss: 10.6501
2025-03-02 11:19:01,752 - INFO - â”œâ”€â”€ Learning Rate: 6.64e-05
2025-03-02 11:19:01,752 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:19:02,421 - INFO - ðŸªœ Batch step - 444 -- sub batch step 1776 -- lr 6.66e-05
2025-03-02 11:19:04,575 - INFO - ðŸªœ Batch step - 444 -- sub batch step 1777 -- lr 6.66e-05
2025-03-02 11:19:06,723 - INFO - ðŸªœ Batch step - 444 -- sub batch step 1778 -- lr 6.66e-05
2025-03-02 11:19:08,896 - INFO - ðŸªœ Batch step - 444 -- sub batch step 1779 -- lr 6.66e-05
2025-03-02 11:19:10,459 - INFO - Step 444 -- ðŸ”„ Training Metrics
2025-03-02 11:19:10,459 - INFO - â”œâ”€â”€ Loss: 10.6460
2025-03-02 11:19:10,459 - INFO - â”œâ”€â”€ Learning Rate: 6.66e-05
2025-03-02 11:19:10,459 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:19:11,133 - INFO - ðŸªœ Batch step - 445 -- sub batch step 1780 -- lr 6.67e-05
2025-03-02 11:19:13,281 - INFO - ðŸªœ Batch step - 445 -- sub batch step 1781 -- lr 6.67e-05
2025-03-02 11:19:15,437 - INFO - ðŸªœ Batch step - 445 -- sub batch step 1782 -- lr 6.67e-05
2025-03-02 11:19:18,230 - INFO - ðŸªœ Batch step - 445 -- sub batch step 1783 -- lr 6.67e-05
2025-03-02 11:19:19,742 - INFO - Step 445 -- ðŸ”„ Training Metrics
2025-03-02 11:19:19,742 - INFO - â”œâ”€â”€ Loss: 10.6455
2025-03-02 11:19:19,743 - INFO - â”œâ”€â”€ Learning Rate: 6.67e-05
2025-03-02 11:19:19,743 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:19:20,418 - INFO - ðŸªœ Batch step - 446 -- sub batch step 1784 -- lr 6.69e-05
2025-03-02 11:19:22,574 - INFO - ðŸªœ Batch step - 446 -- sub batch step 1785 -- lr 6.69e-05
2025-03-02 11:19:24,723 - INFO - ðŸªœ Batch step - 446 -- sub batch step 1786 -- lr 6.69e-05
2025-03-02 11:19:26,896 - INFO - ðŸªœ Batch step - 446 -- sub batch step 1787 -- lr 6.69e-05
2025-03-02 11:19:28,442 - INFO - Step 446 -- ðŸ”„ Training Metrics
2025-03-02 11:19:28,442 - INFO - â”œâ”€â”€ Loss: 10.6397
2025-03-02 11:19:28,442 - INFO - â”œâ”€â”€ Learning Rate: 6.69e-05
2025-03-02 11:19:28,442 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:19:29,111 - INFO - ðŸªœ Batch step - 447 -- sub batch step 1788 -- lr 6.70e-05
2025-03-02 11:19:31,268 - INFO - ðŸªœ Batch step - 447 -- sub batch step 1789 -- lr 6.70e-05
2025-03-02 11:19:33,421 - INFO - ðŸªœ Batch step - 447 -- sub batch step 1790 -- lr 6.70e-05
2025-03-02 11:19:36,050 - INFO - ðŸªœ Batch step - 447 -- sub batch step 1791 -- lr 6.70e-05
2025-03-02 11:19:37,736 - INFO - Step 447 -- ðŸ”„ Training Metrics
2025-03-02 11:19:37,736 - INFO - â”œâ”€â”€ Loss: 10.6384
2025-03-02 11:19:37,736 - INFO - â”œâ”€â”€ Learning Rate: 6.70e-05
2025-03-02 11:19:37,736 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:19:38,411 - INFO - ðŸªœ Batch step - 448 -- sub batch step 1792 -- lr 6.72e-05
2025-03-02 11:19:40,559 - INFO - ðŸªœ Batch step - 448 -- sub batch step 1793 -- lr 6.72e-05
2025-03-02 11:19:42,711 - INFO - ðŸªœ Batch step - 448 -- sub batch step 1794 -- lr 6.72e-05
2025-03-02 11:19:44,886 - INFO - ðŸªœ Batch step - 448 -- sub batch step 1795 -- lr 6.72e-05
2025-03-02 11:19:46,447 - INFO - Step 448 -- ðŸ”„ Training Metrics
2025-03-02 11:19:46,447 - INFO - â”œâ”€â”€ Loss: 10.6425
2025-03-02 11:19:46,447 - INFO - â”œâ”€â”€ Learning Rate: 6.72e-05
2025-03-02 11:19:46,447 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:19:47,116 - INFO - ðŸªœ Batch step - 449 -- sub batch step 1796 -- lr 6.73e-05
2025-03-02 11:19:49,271 - INFO - ðŸªœ Batch step - 449 -- sub batch step 1797 -- lr 6.73e-05
2025-03-02 11:19:51,417 - INFO - ðŸªœ Batch step - 449 -- sub batch step 1798 -- lr 6.73e-05
2025-03-02 11:19:53,842 - INFO - ðŸªœ Batch step - 449 -- sub batch step 1799 -- lr 6.73e-05
2025-03-02 11:19:55,787 - INFO - Step 449 -- ðŸ”„ Training Metrics
2025-03-02 11:19:55,787 - INFO - â”œâ”€â”€ Loss: 10.6379
2025-03-02 11:19:55,787 - INFO - â”œâ”€â”€ Learning Rate: 6.73e-05
2025-03-02 11:19:55,787 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:19:56,461 - INFO - ðŸªœ Batch step - 450 -- sub batch step 1800 -- lr 6.75e-05
2025-03-02 11:19:58,613 - INFO - ðŸªœ Batch step - 450 -- sub batch step 1801 -- lr 6.75e-05
2025-03-02 11:20:00,767 - INFO - ðŸªœ Batch step - 450 -- sub batch step 1802 -- lr 6.75e-05
2025-03-02 11:20:02,930 - INFO - ðŸªœ Batch step - 450 -- sub batch step 1803 -- lr 6.75e-05
2025-03-02 11:20:04,478 - INFO - Step 450 -- ðŸ”„ Training Metrics
2025-03-02 11:20:04,478 - INFO - â”œâ”€â”€ Loss: 10.6322
2025-03-02 11:20:04,478 - INFO - â”œâ”€â”€ Learning Rate: 6.75e-05
2025-03-02 11:20:04,478 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:20:05,153 - INFO - ðŸªœ Batch step - 451 -- sub batch step 1804 -- lr 6.76e-05
2025-03-02 11:20:07,306 - INFO - ðŸªœ Batch step - 451 -- sub batch step 1805 -- lr 6.76e-05
2025-03-02 11:20:09,993 - INFO - ðŸªœ Batch step - 451 -- sub batch step 1806 -- lr 6.76e-05
2025-03-02 11:20:12,157 - INFO - ðŸªœ Batch step - 451 -- sub batch step 1807 -- lr 6.76e-05
2025-03-02 11:20:13,697 - INFO - Step 451 -- ðŸ”„ Training Metrics
2025-03-02 11:20:13,698 - INFO - â”œâ”€â”€ Loss: 10.6338
2025-03-02 11:20:13,698 - INFO - â”œâ”€â”€ Learning Rate: 6.76e-05
2025-03-02 11:20:13,698 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:20:14,367 - INFO - ðŸªœ Batch step - 452 -- sub batch step 1808 -- lr 6.78e-05
2025-03-02 11:20:16,527 - INFO - ðŸªœ Batch step - 452 -- sub batch step 1809 -- lr 6.78e-05
2025-03-02 11:20:18,703 - INFO - ðŸªœ Batch step - 452 -- sub batch step 1810 -- lr 6.78e-05
2025-03-02 11:20:20,851 - INFO - ðŸªœ Batch step - 452 -- sub batch step 1811 -- lr 6.78e-05
2025-03-02 11:20:22,394 - INFO - Step 452 -- ðŸ”„ Training Metrics
2025-03-02 11:20:22,394 - INFO - â”œâ”€â”€ Loss: 10.6272
2025-03-02 11:20:22,394 - INFO - â”œâ”€â”€ Learning Rate: 6.78e-05
2025-03-02 11:20:22,395 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:20:23,071 - INFO - ðŸªœ Batch step - 453 -- sub batch step 1812 -- lr 6.79e-05
2025-03-02 11:20:25,221 - INFO - ðŸªœ Batch step - 453 -- sub batch step 1813 -- lr 6.79e-05
2025-03-02 11:20:27,907 - INFO - ðŸªœ Batch step - 453 -- sub batch step 1814 -- lr 6.79e-05
2025-03-02 11:20:30,066 - INFO - ðŸªœ Batch step - 453 -- sub batch step 1815 -- lr 6.79e-05
2025-03-02 11:20:31,710 - INFO - Step 453 -- ðŸ”„ Training Metrics
2025-03-02 11:20:31,711 - INFO - â”œâ”€â”€ Loss: 10.6308
2025-03-02 11:20:31,711 - INFO - â”œâ”€â”€ Learning Rate: 6.79e-05
2025-03-02 11:20:31,711 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:20:32,379 - INFO - ðŸªœ Batch step - 454 -- sub batch step 1816 -- lr 6.81e-05
2025-03-02 11:20:34,534 - INFO - ðŸªœ Batch step - 454 -- sub batch step 1817 -- lr 6.81e-05
2025-03-02 11:20:36,700 - INFO - ðŸªœ Batch step - 454 -- sub batch step 1818 -- lr 6.81e-05
2025-03-02 11:20:38,856 - INFO - ðŸªœ Batch step - 454 -- sub batch step 1819 -- lr 6.81e-05
2025-03-02 11:20:40,397 - INFO - Step 454 -- ðŸ”„ Training Metrics
2025-03-02 11:20:40,398 - INFO - â”œâ”€â”€ Loss: 10.6252
2025-03-02 11:20:40,398 - INFO - â”œâ”€â”€ Learning Rate: 6.81e-05
2025-03-02 11:20:40,398 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:20:41,073 - INFO - ðŸªœ Batch step - 455 -- sub batch step 1820 -- lr 6.82e-05
2025-03-02 11:20:43,225 - INFO - ðŸªœ Batch step - 455 -- sub batch step 1821 -- lr 6.82e-05
2025-03-02 11:20:45,919 - INFO - ðŸªœ Batch step - 455 -- sub batch step 1822 -- lr 6.82e-05
2025-03-02 11:20:48,076 - INFO - ðŸªœ Batch step - 455 -- sub batch step 1823 -- lr 6.82e-05
2025-03-02 11:20:49,591 - INFO - Step 455 -- ðŸ”„ Training Metrics
2025-03-02 11:20:49,591 - INFO - â”œâ”€â”€ Loss: 10.6283
2025-03-02 11:20:49,591 - INFO - â”œâ”€â”€ Learning Rate: 6.82e-05
2025-03-02 11:20:49,591 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:20:50,267 - INFO - ðŸªœ Batch step - 456 -- sub batch step 1824 -- lr 6.84e-05
2025-03-02 11:20:52,424 - INFO - ðŸªœ Batch step - 456 -- sub batch step 1825 -- lr 6.84e-05
2025-03-02 11:20:54,594 - INFO - ðŸªœ Batch step - 456 -- sub batch step 1826 -- lr 6.84e-05
2025-03-02 11:20:56,749 - INFO - ðŸªœ Batch step - 456 -- sub batch step 1827 -- lr 6.84e-05
2025-03-02 11:20:58,277 - INFO - Step 456 -- ðŸ”„ Training Metrics
2025-03-02 11:20:58,278 - INFO - â”œâ”€â”€ Loss: 10.6206
2025-03-02 11:20:58,278 - INFO - â”œâ”€â”€ Learning Rate: 6.84e-05
2025-03-02 11:20:58,278 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:20:58,945 - INFO - ðŸªœ Batch step - 457 -- sub batch step 1828 -- lr 6.85e-05
2025-03-02 11:21:01,106 - INFO - ðŸªœ Batch step - 457 -- sub batch step 1829 -- lr 6.85e-05
2025-03-02 11:21:03,701 - INFO - ðŸªœ Batch step - 457 -- sub batch step 1830 -- lr 6.85e-05
2025-03-02 11:21:05,850 - INFO - ðŸªœ Batch step - 457 -- sub batch step 1831 -- lr 6.85e-05
2025-03-02 11:21:07,615 - INFO - Step 457 -- ðŸ”„ Training Metrics
2025-03-02 11:21:07,616 - INFO - â”œâ”€â”€ Loss: 10.6184
2025-03-02 11:21:07,616 - INFO - â”œâ”€â”€ Learning Rate: 6.85e-05
2025-03-02 11:21:07,616 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:21:08,289 - INFO - ðŸªœ Batch step - 458 -- sub batch step 1832 -- lr 6.87e-05
2025-03-02 11:21:10,439 - INFO - ðŸªœ Batch step - 458 -- sub batch step 1833 -- lr 6.87e-05
2025-03-02 11:21:12,616 - INFO - ðŸªœ Batch step - 458 -- sub batch step 1834 -- lr 6.87e-05
2025-03-02 11:21:14,772 - INFO - ðŸªœ Batch step - 458 -- sub batch step 1835 -- lr 6.87e-05
2025-03-02 11:21:16,311 - INFO - Step 458 -- ðŸ”„ Training Metrics
2025-03-02 11:21:16,311 - INFO - â”œâ”€â”€ Loss: 10.6165
2025-03-02 11:21:16,311 - INFO - â”œâ”€â”€ Learning Rate: 6.87e-05
2025-03-02 11:21:16,311 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:21:16,977 - INFO - ðŸªœ Batch step - 459 -- sub batch step 1836 -- lr 6.88e-05
2025-03-02 11:21:19,134 - INFO - ðŸªœ Batch step - 459 -- sub batch step 1837 -- lr 6.88e-05
2025-03-02 11:21:21,488 - INFO - ðŸªœ Batch step - 459 -- sub batch step 1838 -- lr 6.88e-05
2025-03-02 11:21:23,648 - INFO - ðŸªœ Batch step - 459 -- sub batch step 1839 -- lr 6.88e-05
2025-03-02 11:21:25,141 - INFO - Step 459 -- ðŸ”„ Training Metrics
2025-03-02 11:21:25,141 - INFO - â”œâ”€â”€ Loss: 10.6156
2025-03-02 11:21:25,141 - INFO - â”œâ”€â”€ Learning Rate: 6.88e-05
2025-03-02 11:21:25,142 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:21:26,256 - INFO - ðŸªœ Batch step - 460 -- sub batch step 1840 -- lr 6.90e-05
2025-03-02 11:21:28,418 - INFO - ðŸªœ Batch step - 460 -- sub batch step 1841 -- lr 6.90e-05
2025-03-02 11:21:30,586 - INFO - ðŸªœ Batch step - 460 -- sub batch step 1842 -- lr 6.90e-05
2025-03-02 11:21:32,766 - INFO - ðŸªœ Batch step - 460 -- sub batch step 1843 -- lr 6.90e-05
2025-03-02 11:21:34,653 - INFO - Step 460 -- ðŸ”„ Training Metrics
2025-03-02 11:21:34,653 - INFO - â”œâ”€â”€ Loss: 10.6168
2025-03-02 11:21:34,653 - INFO - â”œâ”€â”€ Learning Rate: 6.90e-05
2025-03-02 11:21:34,653 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:21:35,329 - INFO - ðŸªœ Batch step - 461 -- sub batch step 1844 -- lr 6.92e-05
2025-03-02 11:21:37,489 - INFO - ðŸªœ Batch step - 461 -- sub batch step 1845 -- lr 6.92e-05
2025-03-02 11:21:39,642 - INFO - ðŸªœ Batch step - 461 -- sub batch step 1846 -- lr 6.92e-05
2025-03-02 11:21:42,105 - INFO - ðŸªœ Batch step - 461 -- sub batch step 1847 -- lr 6.92e-05
2025-03-02 11:21:43,999 - INFO - Step 461 -- ðŸ”„ Training Metrics
2025-03-02 11:21:43,999 - INFO - â”œâ”€â”€ Loss: 10.6113
2025-03-02 11:21:43,999 - INFO - â”œâ”€â”€ Learning Rate: 6.92e-05
2025-03-02 11:21:44,000 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:21:44,667 - INFO - ðŸªœ Batch step - 462 -- sub batch step 1848 -- lr 6.93e-05
2025-03-02 11:21:46,823 - INFO - ðŸªœ Batch step - 462 -- sub batch step 1849 -- lr 6.93e-05
2025-03-02 11:21:48,977 - INFO - ðŸªœ Batch step - 462 -- sub batch step 1850 -- lr 6.93e-05
2025-03-02 11:21:51,144 - INFO - ðŸªœ Batch step - 462 -- sub batch step 1851 -- lr 6.93e-05
2025-03-02 11:21:52,692 - INFO - Step 462 -- ðŸ”„ Training Metrics
2025-03-02 11:21:52,692 - INFO - â”œâ”€â”€ Loss: 10.6070
2025-03-02 11:21:52,692 - INFO - â”œâ”€â”€ Learning Rate: 6.93e-05
2025-03-02 11:21:52,693 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:21:53,363 - INFO - ðŸªœ Batch step - 463 -- sub batch step 1852 -- lr 6.94e-05
2025-03-02 11:21:55,511 - INFO - ðŸªœ Batch step - 463 -- sub batch step 1853 -- lr 6.94e-05
2025-03-02 11:21:57,663 - INFO - ðŸªœ Batch step - 463 -- sub batch step 1854 -- lr 6.94e-05
2025-03-02 11:22:00,056 - INFO - ðŸªœ Batch step - 463 -- sub batch step 1855 -- lr 6.94e-05
2025-03-02 11:22:01,800 - INFO - Step 463 -- ðŸ”„ Training Metrics
2025-03-02 11:22:01,800 - INFO - â”œâ”€â”€ Loss: 10.6046
2025-03-02 11:22:01,800 - INFO - â”œâ”€â”€ Learning Rate: 6.94e-05
2025-03-02 11:22:01,800 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:22:02,469 - INFO - ðŸªœ Batch step - 464 -- sub batch step 1856 -- lr 6.96e-05
2025-03-02 11:22:04,627 - INFO - ðŸªœ Batch step - 464 -- sub batch step 1857 -- lr 6.96e-05
2025-03-02 11:22:06,772 - INFO - ðŸªœ Batch step - 464 -- sub batch step 1858 -- lr 6.96e-05
2025-03-02 11:22:08,945 - INFO - ðŸªœ Batch step - 464 -- sub batch step 1859 -- lr 6.96e-05
2025-03-02 11:22:10,488 - INFO - Step 464 -- ðŸ”„ Training Metrics
2025-03-02 11:22:10,488 - INFO - â”œâ”€â”€ Loss: 10.6058
2025-03-02 11:22:10,488 - INFO - â”œâ”€â”€ Learning Rate: 6.96e-05
2025-03-02 11:22:10,488 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:22:11,161 - INFO - ðŸªœ Batch step - 465 -- sub batch step 1860 -- lr 6.98e-05
2025-03-02 11:22:13,311 - INFO - ðŸªœ Batch step - 465 -- sub batch step 1861 -- lr 6.98e-05
2025-03-02 11:22:15,465 - INFO - ðŸªœ Batch step - 465 -- sub batch step 1862 -- lr 6.98e-05
2025-03-02 11:22:17,937 - INFO - ðŸªœ Batch step - 465 -- sub batch step 1863 -- lr 6.98e-05
2025-03-02 11:22:19,631 - INFO - Step 465 -- ðŸ”„ Training Metrics
2025-03-02 11:22:19,631 - INFO - â”œâ”€â”€ Loss: 10.6004
2025-03-02 11:22:19,631 - INFO - â”œâ”€â”€ Learning Rate: 6.98e-05
2025-03-02 11:22:19,631 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:22:20,306 - INFO - ðŸªœ Batch step - 466 -- sub batch step 1864 -- lr 6.99e-05
2025-03-02 11:22:22,461 - INFO - ðŸªœ Batch step - 466 -- sub batch step 1865 -- lr 6.99e-05
2025-03-02 11:22:24,610 - INFO - ðŸªœ Batch step - 466 -- sub batch step 1866 -- lr 6.99e-05
2025-03-02 11:22:26,784 - INFO - ðŸªœ Batch step - 466 -- sub batch step 1867 -- lr 6.99e-05
2025-03-02 11:22:28,327 - INFO - Step 466 -- ðŸ”„ Training Metrics
2025-03-02 11:22:28,327 - INFO - â”œâ”€â”€ Loss: 10.5985
2025-03-02 11:22:28,327 - INFO - â”œâ”€â”€ Learning Rate: 6.99e-05
2025-03-02 11:22:28,327 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:22:28,993 - INFO - ðŸªœ Batch step - 467 -- sub batch step 1868 -- lr 7.00e-05
2025-03-02 11:22:31,150 - INFO - ðŸªœ Batch step - 467 -- sub batch step 1869 -- lr 7.00e-05
2025-03-02 11:22:33,302 - INFO - ðŸªœ Batch step - 467 -- sub batch step 1870 -- lr 7.00e-05
2025-03-02 11:22:36,098 - INFO - ðŸªœ Batch step - 467 -- sub batch step 1871 -- lr 7.00e-05
2025-03-02 11:22:37,635 - INFO - Step 467 -- ðŸ”„ Training Metrics
2025-03-02 11:22:37,636 - INFO - â”œâ”€â”€ Loss: 10.5986
2025-03-02 11:22:37,636 - INFO - â”œâ”€â”€ Learning Rate: 7.00e-05
2025-03-02 11:22:37,636 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:22:38,315 - INFO - ðŸªœ Batch step - 468 -- sub batch step 1872 -- lr 7.02e-05
2025-03-02 11:22:40,466 - INFO - ðŸªœ Batch step - 468 -- sub batch step 1873 -- lr 7.02e-05
2025-03-02 11:22:42,617 - INFO - ðŸªœ Batch step - 468 -- sub batch step 1874 -- lr 7.02e-05
2025-03-02 11:22:44,786 - INFO - ðŸªœ Batch step - 468 -- sub batch step 1875 -- lr 7.02e-05
2025-03-02 11:22:46,325 - INFO - Step 468 -- ðŸ”„ Training Metrics
2025-03-02 11:22:46,325 - INFO - â”œâ”€â”€ Loss: 10.5945
2025-03-02 11:22:46,325 - INFO - â”œâ”€â”€ Learning Rate: 7.02e-05
2025-03-02 11:22:46,325 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:22:46,998 - INFO - ðŸªœ Batch step - 469 -- sub batch step 1876 -- lr 7.03e-05
2025-03-02 11:22:49,151 - INFO - ðŸªœ Batch step - 469 -- sub batch step 1877 -- lr 7.03e-05
2025-03-02 11:22:51,301 - INFO - ðŸªœ Batch step - 469 -- sub batch step 1878 -- lr 7.03e-05
2025-03-02 11:22:53,952 - INFO - ðŸªœ Batch step - 469 -- sub batch step 1879 -- lr 7.03e-05
2025-03-02 11:22:55,502 - INFO - Step 469 -- ðŸ”„ Training Metrics
2025-03-02 11:22:55,503 - INFO - â”œâ”€â”€ Loss: 10.5892
2025-03-02 11:22:55,503 - INFO - â”œâ”€â”€ Learning Rate: 7.03e-05
2025-03-02 11:22:55,503 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:22:56,177 - INFO - ðŸªœ Batch step - 470 -- sub batch step 1880 -- lr 7.05e-05
2025-03-02 11:22:58,330 - INFO - ðŸªœ Batch step - 470 -- sub batch step 1881 -- lr 7.05e-05
2025-03-02 11:23:00,487 - INFO - ðŸªœ Batch step - 470 -- sub batch step 1882 -- lr 7.05e-05
2025-03-02 11:23:02,655 - INFO - ðŸªœ Batch step - 470 -- sub batch step 1883 -- lr 7.05e-05
2025-03-02 11:23:04,179 - INFO - Step 470 -- ðŸ”„ Training Metrics
2025-03-02 11:23:04,179 - INFO - â”œâ”€â”€ Loss: 10.5881
2025-03-02 11:23:04,179 - INFO - â”œâ”€â”€ Learning Rate: 7.05e-05
2025-03-02 11:23:04,179 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:23:04,854 - INFO - ðŸªœ Batch step - 471 -- sub batch step 1884 -- lr 7.06e-05
2025-03-02 11:23:07,008 - INFO - ðŸªœ Batch step - 471 -- sub batch step 1885 -- lr 7.06e-05
2025-03-02 11:23:09,447 - INFO - ðŸªœ Batch step - 471 -- sub batch step 1886 -- lr 7.06e-05
2025-03-02 11:23:11,598 - INFO - ðŸªœ Batch step - 471 -- sub batch step 1887 -- lr 7.06e-05
2025-03-02 11:23:13,450 - INFO - Step 471 -- ðŸ”„ Training Metrics
2025-03-02 11:23:13,451 - INFO - â”œâ”€â”€ Loss: 10.5913
2025-03-02 11:23:13,451 - INFO - â”œâ”€â”€ Learning Rate: 7.06e-05
2025-03-02 11:23:13,451 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:23:14,119 - INFO - ðŸªœ Batch step - 472 -- sub batch step 1888 -- lr 7.08e-05
2025-03-02 11:23:16,280 - INFO - ðŸªœ Batch step - 472 -- sub batch step 1889 -- lr 7.08e-05
2025-03-02 11:23:18,453 - INFO - ðŸªœ Batch step - 472 -- sub batch step 1890 -- lr 7.08e-05
2025-03-02 11:23:20,604 - INFO - ðŸªœ Batch step - 472 -- sub batch step 1891 -- lr 7.08e-05
2025-03-02 11:23:22,130 - INFO - Step 472 -- ðŸ”„ Training Metrics
2025-03-02 11:23:22,130 - INFO - â”œâ”€â”€ Loss: 10.5819
2025-03-02 11:23:22,130 - INFO - â”œâ”€â”€ Learning Rate: 7.08e-05
2025-03-02 11:23:22,130 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:23:22,805 - INFO - ðŸªœ Batch step - 473 -- sub batch step 1892 -- lr 7.09e-05
2025-03-02 11:23:24,957 - INFO - ðŸªœ Batch step - 473 -- sub batch step 1893 -- lr 7.09e-05
2025-03-02 11:23:27,603 - INFO - ðŸªœ Batch step - 473 -- sub batch step 1894 -- lr 7.09e-05
2025-03-02 11:23:29,766 - INFO - ðŸªœ Batch step - 473 -- sub batch step 1895 -- lr 7.09e-05
2025-03-02 11:23:31,462 - INFO - Step 473 -- ðŸ”„ Training Metrics
2025-03-02 11:23:31,463 - INFO - â”œâ”€â”€ Loss: 10.5804
2025-03-02 11:23:31,463 - INFO - â”œâ”€â”€ Learning Rate: 7.09e-05
2025-03-02 11:23:31,463 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:23:32,135 - INFO - ðŸªœ Batch step - 474 -- sub batch step 1896 -- lr 7.11e-05
2025-03-02 11:23:34,293 - INFO - ðŸªœ Batch step - 474 -- sub batch step 1897 -- lr 7.11e-05
2025-03-02 11:23:36,462 - INFO - ðŸªœ Batch step - 474 -- sub batch step 1898 -- lr 7.11e-05
2025-03-02 11:23:38,618 - INFO - ðŸªœ Batch step - 474 -- sub batch step 1899 -- lr 7.11e-05
2025-03-02 11:23:40,147 - INFO - Step 474 -- ðŸ”„ Training Metrics
2025-03-02 11:23:40,147 - INFO - â”œâ”€â”€ Loss: 10.5840
2025-03-02 11:23:40,148 - INFO - â”œâ”€â”€ Learning Rate: 7.11e-05
2025-03-02 11:23:40,148 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:23:40,826 - INFO - ðŸªœ Batch step - 475 -- sub batch step 1900 -- lr 7.12e-05
2025-03-02 11:23:42,976 - INFO - ðŸªœ Batch step - 475 -- sub batch step 1901 -- lr 7.12e-05
2025-03-02 11:23:45,784 - INFO - ðŸªœ Batch step - 475 -- sub batch step 1902 -- lr 7.12e-05
2025-03-02 11:23:47,936 - INFO - ðŸªœ Batch step - 475 -- sub batch step 1903 -- lr 7.12e-05
2025-03-02 11:23:49,427 - INFO - Step 475 -- ðŸ”„ Training Metrics
2025-03-02 11:23:49,427 - INFO - â”œâ”€â”€ Loss: 10.5834
2025-03-02 11:23:49,427 - INFO - â”œâ”€â”€ Learning Rate: 7.12e-05
2025-03-02 11:23:49,427 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:23:50,105 - INFO - ðŸªœ Batch step - 476 -- sub batch step 1904 -- lr 7.14e-05
2025-03-02 11:23:52,258 - INFO - ðŸªœ Batch step - 476 -- sub batch step 1905 -- lr 7.14e-05
2025-03-02 11:23:54,424 - INFO - ðŸªœ Batch step - 476 -- sub batch step 1906 -- lr 7.14e-05
2025-03-02 11:23:56,581 - INFO - ðŸªœ Batch step - 476 -- sub batch step 1907 -- lr 7.14e-05
2025-03-02 11:23:58,138 - INFO - Step 476 -- ðŸ”„ Training Metrics
2025-03-02 11:23:58,139 - INFO - â”œâ”€â”€ Loss: 10.5726
2025-03-02 11:23:58,139 - INFO - â”œâ”€â”€ Learning Rate: 7.14e-05
2025-03-02 11:23:58,139 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:23:58,808 - INFO - ðŸªœ Batch step - 477 -- sub batch step 1908 -- lr 7.15e-05
2025-03-02 11:24:00,969 - INFO - ðŸªœ Batch step - 477 -- sub batch step 1909 -- lr 7.15e-05
2025-03-02 11:24:03,772 - INFO - ðŸªœ Batch step - 477 -- sub batch step 1910 -- lr 7.15e-05
2025-03-02 11:24:05,924 - INFO - ðŸªœ Batch step - 477 -- sub batch step 1911 -- lr 7.15e-05
2025-03-02 11:24:07,417 - INFO - Step 477 -- ðŸ”„ Training Metrics
2025-03-02 11:24:07,417 - INFO - â”œâ”€â”€ Loss: 10.5780
2025-03-02 11:24:07,417 - INFO - â”œâ”€â”€ Learning Rate: 7.15e-05
2025-03-02 11:24:07,417 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:24:08,093 - INFO - ðŸªœ Batch step - 478 -- sub batch step 1912 -- lr 7.17e-05
2025-03-02 11:24:10,244 - INFO - ðŸªœ Batch step - 478 -- sub batch step 1913 -- lr 7.17e-05
2025-03-02 11:24:12,418 - INFO - ðŸªœ Batch step - 478 -- sub batch step 1914 -- lr 7.17e-05
2025-03-02 11:24:14,571 - INFO - ðŸªœ Batch step - 478 -- sub batch step 1915 -- lr 7.17e-05
2025-03-02 11:24:16,123 - INFO - Step 478 -- ðŸ”„ Training Metrics
2025-03-02 11:24:16,124 - INFO - â”œâ”€â”€ Loss: 10.5755
2025-03-02 11:24:16,124 - INFO - â”œâ”€â”€ Learning Rate: 7.17e-05
2025-03-02 11:24:16,124 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:24:16,793 - INFO - ðŸªœ Batch step - 479 -- sub batch step 1916 -- lr 7.18e-05
2025-03-02 11:24:18,953 - INFO - ðŸªœ Batch step - 479 -- sub batch step 1917 -- lr 7.18e-05
2025-03-02 11:24:21,227 - INFO - ðŸªœ Batch step - 479 -- sub batch step 1918 -- lr 7.18e-05
2025-03-02 11:24:23,380 - INFO - ðŸªœ Batch step - 479 -- sub batch step 1919 -- lr 7.18e-05
2025-03-02 11:24:24,965 - INFO - Step 479 -- ðŸ”„ Training Metrics
2025-03-02 11:24:24,965 - INFO - â”œâ”€â”€ Loss: 10.5681
2025-03-02 11:24:24,965 - INFO - â”œâ”€â”€ Learning Rate: 7.18e-05
2025-03-02 11:24:24,965 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:24:26,057 - INFO - ðŸªœ Batch step - 480 -- sub batch step 1920 -- lr 7.20e-05
2025-03-02 11:24:28,211 - INFO - ðŸªœ Batch step - 480 -- sub batch step 1921 -- lr 7.20e-05
2025-03-02 11:24:30,368 - INFO - ðŸªœ Batch step - 480 -- sub batch step 1922 -- lr 7.20e-05
2025-03-02 11:24:32,539 - INFO - ðŸªœ Batch step - 480 -- sub batch step 1923 -- lr 7.20e-05
2025-03-02 11:24:34,582 - INFO - Step 480 -- ðŸ”„ Training Metrics
2025-03-02 11:24:34,582 - INFO - â”œâ”€â”€ Loss: 10.5662
2025-03-02 11:24:34,582 - INFO - â”œâ”€â”€ Learning Rate: 7.20e-05
2025-03-02 11:24:34,582 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:24:35,260 - INFO - ðŸªœ Batch step - 481 -- sub batch step 1924 -- lr 7.21e-05
2025-03-02 11:24:37,419 - INFO - ðŸªœ Batch step - 481 -- sub batch step 1925 -- lr 7.21e-05
2025-03-02 11:24:39,576 - INFO - ðŸªœ Batch step - 481 -- sub batch step 1926 -- lr 7.21e-05
2025-03-02 11:24:42,080 - INFO - ðŸªœ Batch step - 481 -- sub batch step 1927 -- lr 7.21e-05
2025-03-02 11:24:43,656 - INFO - Step 481 -- ðŸ”„ Training Metrics
2025-03-02 11:24:43,656 - INFO - â”œâ”€â”€ Loss: 10.5628
2025-03-02 11:24:43,656 - INFO - â”œâ”€â”€ Learning Rate: 7.21e-05
2025-03-02 11:24:43,657 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:24:44,332 - INFO - ðŸªœ Batch step - 482 -- sub batch step 1928 -- lr 7.23e-05
2025-03-02 11:24:46,490 - INFO - ðŸªœ Batch step - 482 -- sub batch step 1929 -- lr 7.23e-05
2025-03-02 11:24:48,649 - INFO - ðŸªœ Batch step - 482 -- sub batch step 1930 -- lr 7.23e-05
2025-03-02 11:24:50,821 - INFO - ðŸªœ Batch step - 482 -- sub batch step 1931 -- lr 7.23e-05
2025-03-02 11:24:52,365 - INFO - Step 482 -- ðŸ”„ Training Metrics
2025-03-02 11:24:52,365 - INFO - â”œâ”€â”€ Loss: 10.5684
2025-03-02 11:24:52,366 - INFO - â”œâ”€â”€ Learning Rate: 7.23e-05
2025-03-02 11:24:52,366 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:24:53,046 - INFO - ðŸªœ Batch step - 483 -- sub batch step 1932 -- lr 7.24e-05
2025-03-02 11:24:55,199 - INFO - ðŸªœ Batch step - 483 -- sub batch step 1933 -- lr 7.24e-05
2025-03-02 11:24:57,356 - INFO - ðŸªœ Batch step - 483 -- sub batch step 1934 -- lr 7.24e-05
2025-03-02 11:24:59,756 - INFO - ðŸªœ Batch step - 483 -- sub batch step 1935 -- lr 7.24e-05
2025-03-02 11:25:01,642 - INFO - Step 483 -- ðŸ”„ Training Metrics
2025-03-02 11:25:01,642 - INFO - â”œâ”€â”€ Loss: 10.5598
2025-03-02 11:25:01,642 - INFO - â”œâ”€â”€ Learning Rate: 7.24e-05
2025-03-02 11:25:01,642 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:25:02,316 - INFO - ðŸªœ Batch step - 484 -- sub batch step 1936 -- lr 7.26e-05
2025-03-02 11:25:04,473 - INFO - ðŸªœ Batch step - 484 -- sub batch step 1937 -- lr 7.26e-05
2025-03-02 11:25:06,623 - INFO - ðŸªœ Batch step - 484 -- sub batch step 1938 -- lr 7.26e-05
2025-03-02 11:25:08,789 - INFO - ðŸªœ Batch step - 484 -- sub batch step 1939 -- lr 7.26e-05
2025-03-02 11:25:10,339 - INFO - Step 484 -- ðŸ”„ Training Metrics
2025-03-02 11:25:10,340 - INFO - â”œâ”€â”€ Loss: 10.5571
2025-03-02 11:25:10,340 - INFO - â”œâ”€â”€ Learning Rate: 7.26e-05
2025-03-02 11:25:10,340 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:25:11,017 - INFO - ðŸªœ Batch step - 485 -- sub batch step 1940 -- lr 7.27e-05
2025-03-02 11:25:13,169 - INFO - ðŸªœ Batch step - 485 -- sub batch step 1941 -- lr 7.27e-05
2025-03-02 11:25:15,326 - INFO - ðŸªœ Batch step - 485 -- sub batch step 1942 -- lr 7.27e-05
2025-03-02 11:25:18,124 - INFO - ðŸªœ Batch step - 485 -- sub batch step 1943 -- lr 7.27e-05
2025-03-02 11:25:19,616 - INFO - Step 485 -- ðŸ”„ Training Metrics
2025-03-02 11:25:19,616 - INFO - â”œâ”€â”€ Loss: 10.5565
2025-03-02 11:25:19,616 - INFO - â”œâ”€â”€ Learning Rate: 7.27e-05
2025-03-02 11:25:19,616 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:25:20,295 - INFO - ðŸªœ Batch step - 486 -- sub batch step 1944 -- lr 7.29e-05
2025-03-02 11:25:22,454 - INFO - ðŸªœ Batch step - 486 -- sub batch step 1945 -- lr 7.29e-05
2025-03-02 11:25:24,606 - INFO - ðŸªœ Batch step - 486 -- sub batch step 1946 -- lr 7.29e-05
2025-03-02 11:25:26,780 - INFO - ðŸªœ Batch step - 486 -- sub batch step 1947 -- lr 7.29e-05
2025-03-02 11:25:28,312 - INFO - Step 486 -- ðŸ”„ Training Metrics
2025-03-02 11:25:28,313 - INFO - â”œâ”€â”€ Loss: 10.5518
2025-03-02 11:25:28,313 - INFO - â”œâ”€â”€ Learning Rate: 7.29e-05
2025-03-02 11:25:28,313 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:25:28,985 - INFO - ðŸªœ Batch step - 487 -- sub batch step 1948 -- lr 7.30e-05
2025-03-02 11:25:31,147 - INFO - ðŸªœ Batch step - 487 -- sub batch step 1949 -- lr 7.30e-05
2025-03-02 11:25:33,303 - INFO - ðŸªœ Batch step - 487 -- sub batch step 1950 -- lr 7.30e-05
2025-03-02 11:25:35,964 - INFO - ðŸªœ Batch step - 487 -- sub batch step 1951 -- lr 7.30e-05
2025-03-02 11:25:37,493 - INFO - Step 487 -- ðŸ”„ Training Metrics
2025-03-02 11:25:37,493 - INFO - â”œâ”€â”€ Loss: 10.5468
2025-03-02 11:25:37,493 - INFO - â”œâ”€â”€ Learning Rate: 7.30e-05
2025-03-02 11:25:37,494 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:25:38,171 - INFO - ðŸªœ Batch step - 488 -- sub batch step 1952 -- lr 7.32e-05
2025-03-02 11:25:40,326 - INFO - ðŸªœ Batch step - 488 -- sub batch step 1953 -- lr 7.32e-05
2025-03-02 11:25:42,487 - INFO - ðŸªœ Batch step - 488 -- sub batch step 1954 -- lr 7.32e-05
2025-03-02 11:25:44,660 - INFO - ðŸªœ Batch step - 488 -- sub batch step 1955 -- lr 7.32e-05
2025-03-02 11:25:46,192 - INFO - Step 488 -- ðŸ”„ Training Metrics
2025-03-02 11:25:46,192 - INFO - â”œâ”€â”€ Loss: 10.5511
2025-03-02 11:25:46,192 - INFO - â”œâ”€â”€ Learning Rate: 7.32e-05
2025-03-02 11:25:46,192 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:25:46,864 - INFO - ðŸªœ Batch step - 489 -- sub batch step 1956 -- lr 7.33e-05
2025-03-02 11:25:49,023 - INFO - ðŸªœ Batch step - 489 -- sub batch step 1957 -- lr 7.33e-05
2025-03-02 11:25:51,174 - INFO - ðŸªœ Batch step - 489 -- sub batch step 1958 -- lr 7.33e-05
2025-03-02 11:25:53,548 - INFO - ðŸªœ Batch step - 489 -- sub batch step 1959 -- lr 7.33e-05
2025-03-02 11:25:55,381 - INFO - Step 489 -- ðŸ”„ Training Metrics
2025-03-02 11:25:55,381 - INFO - â”œâ”€â”€ Loss: 10.5459
2025-03-02 11:25:55,381 - INFO - â”œâ”€â”€ Learning Rate: 7.33e-05
2025-03-02 11:25:55,381 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:25:56,059 - INFO - ðŸªœ Batch step - 490 -- sub batch step 1960 -- lr 7.35e-05
2025-03-02 11:25:58,212 - INFO - ðŸªœ Batch step - 490 -- sub batch step 1961 -- lr 7.35e-05
2025-03-02 11:26:00,370 - INFO - ðŸªœ Batch step - 490 -- sub batch step 1962 -- lr 7.35e-05
2025-03-02 11:26:02,543 - INFO - ðŸªœ Batch step - 490 -- sub batch step 1963 -- lr 7.35e-05
2025-03-02 11:26:04,098 - INFO - Step 490 -- ðŸ”„ Training Metrics
2025-03-02 11:26:04,099 - INFO - â”œâ”€â”€ Loss: 10.5443
2025-03-02 11:26:04,099 - INFO - â”œâ”€â”€ Learning Rate: 7.35e-05
2025-03-02 11:26:04,099 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:26:04,778 - INFO - ðŸªœ Batch step - 491 -- sub batch step 1964 -- lr 7.36e-05
2025-03-02 11:26:06,939 - INFO - ðŸªœ Batch step - 491 -- sub batch step 1965 -- lr 7.36e-05
2025-03-02 11:26:09,299 - INFO - ðŸªœ Batch step - 491 -- sub batch step 1966 -- lr 7.36e-05
2025-03-02 11:26:11,464 - INFO - ðŸªœ Batch step - 491 -- sub batch step 1967 -- lr 7.36e-05
2025-03-02 11:26:13,450 - INFO - Step 491 -- ðŸ”„ Training Metrics
2025-03-02 11:26:13,450 - INFO - â”œâ”€â”€ Loss: 10.5418
2025-03-02 11:26:13,450 - INFO - â”œâ”€â”€ Learning Rate: 7.36e-05
2025-03-02 11:26:13,451 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:26:14,126 - INFO - ðŸªœ Batch step - 492 -- sub batch step 1968 -- lr 7.38e-05
2025-03-02 11:26:16,284 - INFO - ðŸªœ Batch step - 492 -- sub batch step 1969 -- lr 7.38e-05
2025-03-02 11:26:18,460 - INFO - ðŸªœ Batch step - 492 -- sub batch step 1970 -- lr 7.38e-05
2025-03-02 11:26:20,609 - INFO - ðŸªœ Batch step - 492 -- sub batch step 1971 -- lr 7.38e-05
2025-03-02 11:26:22,163 - INFO - Step 492 -- ðŸ”„ Training Metrics
2025-03-02 11:26:22,163 - INFO - â”œâ”€â”€ Loss: 10.5395
2025-03-02 11:26:22,163 - INFO - â”œâ”€â”€ Learning Rate: 7.38e-05
2025-03-02 11:26:22,163 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:26:22,838 - INFO - ðŸªœ Batch step - 493 -- sub batch step 1972 -- lr 7.39e-05
2025-03-02 11:26:24,986 - INFO - ðŸªœ Batch step - 493 -- sub batch step 1973 -- lr 7.39e-05
2025-03-02 11:26:27,618 - INFO - ðŸªœ Batch step - 493 -- sub batch step 1974 -- lr 7.39e-05
2025-03-02 11:26:29,775 - INFO - ðŸªœ Batch step - 493 -- sub batch step 1975 -- lr 7.39e-05
2025-03-02 11:26:31,380 - INFO - Step 493 -- ðŸ”„ Training Metrics
2025-03-02 11:26:31,380 - INFO - â”œâ”€â”€ Loss: 10.5406
2025-03-02 11:26:31,380 - INFO - â”œâ”€â”€ Learning Rate: 7.39e-05
2025-03-02 11:26:31,380 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:26:32,050 - INFO - ðŸªœ Batch step - 494 -- sub batch step 1976 -- lr 7.41e-05
2025-03-02 11:26:34,202 - INFO - ðŸªœ Batch step - 494 -- sub batch step 1977 -- lr 7.41e-05
2025-03-02 11:26:36,370 - INFO - ðŸªœ Batch step - 494 -- sub batch step 1978 -- lr 7.41e-05
2025-03-02 11:26:38,525 - INFO - ðŸªœ Batch step - 494 -- sub batch step 1979 -- lr 7.41e-05
2025-03-02 11:26:40,096 - INFO - Step 494 -- ðŸ”„ Training Metrics
2025-03-02 11:26:40,096 - INFO - â”œâ”€â”€ Loss: 10.5341
2025-03-02 11:26:40,096 - INFO - â”œâ”€â”€ Learning Rate: 7.41e-05
2025-03-02 11:26:40,096 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:26:40,774 - INFO - ðŸªœ Batch step - 495 -- sub batch step 1980 -- lr 7.42e-05
2025-03-02 11:26:42,923 - INFO - ðŸªœ Batch step - 495 -- sub batch step 1981 -- lr 7.42e-05
2025-03-02 11:26:45,595 - INFO - ðŸªœ Batch step - 495 -- sub batch step 1982 -- lr 7.42e-05
2025-03-02 11:26:47,752 - INFO - ðŸªœ Batch step - 495 -- sub batch step 1983 -- lr 7.42e-05
2025-03-02 11:26:49,371 - INFO - Step 495 -- ðŸ”„ Training Metrics
2025-03-02 11:26:49,371 - INFO - â”œâ”€â”€ Loss: 10.5315
2025-03-02 11:26:49,371 - INFO - â”œâ”€â”€ Learning Rate: 7.42e-05
2025-03-02 11:26:49,371 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:26:50,047 - INFO - ðŸªœ Batch step - 496 -- sub batch step 1984 -- lr 7.44e-05
2025-03-02 11:26:52,204 - INFO - ðŸªœ Batch step - 496 -- sub batch step 1985 -- lr 7.44e-05
2025-03-02 11:26:54,371 - INFO - ðŸªœ Batch step - 496 -- sub batch step 1986 -- lr 7.44e-05
2025-03-02 11:26:56,529 - INFO - ðŸªœ Batch step - 496 -- sub batch step 1987 -- lr 7.44e-05
2025-03-02 11:26:58,082 - INFO - Step 496 -- ðŸ”„ Training Metrics
2025-03-02 11:26:58,083 - INFO - â”œâ”€â”€ Loss: 10.5299
2025-03-02 11:26:58,083 - INFO - â”œâ”€â”€ Learning Rate: 7.44e-05
2025-03-02 11:26:58,083 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:26:58,753 - INFO - ðŸªœ Batch step - 497 -- sub batch step 1988 -- lr 7.45e-05
2025-03-02 11:27:00,918 - INFO - ðŸªœ Batch step - 497 -- sub batch step 1989 -- lr 7.45e-05
2025-03-02 11:27:03,602 - INFO - ðŸªœ Batch step - 497 -- sub batch step 1990 -- lr 7.45e-05
2025-03-02 11:27:05,759 - INFO - ðŸªœ Batch step - 497 -- sub batch step 1991 -- lr 7.45e-05
2025-03-02 11:27:07,313 - INFO - Step 497 -- ðŸ”„ Training Metrics
2025-03-02 11:27:07,313 - INFO - â”œâ”€â”€ Loss: 10.5334
2025-03-02 11:27:07,313 - INFO - â”œâ”€â”€ Learning Rate: 7.45e-05
2025-03-02 11:27:07,313 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:27:07,991 - INFO - ðŸªœ Batch step - 498 -- sub batch step 1992 -- lr 7.47e-05
2025-03-02 11:27:10,141 - INFO - ðŸªœ Batch step - 498 -- sub batch step 1993 -- lr 7.47e-05
2025-03-02 11:27:12,311 - INFO - ðŸªœ Batch step - 498 -- sub batch step 1994 -- lr 7.47e-05
2025-03-02 11:27:14,463 - INFO - ðŸªœ Batch step - 498 -- sub batch step 1995 -- lr 7.47e-05
2025-03-02 11:27:16,018 - INFO - Step 498 -- ðŸ”„ Training Metrics
2025-03-02 11:27:16,018 - INFO - â”œâ”€â”€ Loss: 10.5288
2025-03-02 11:27:16,018 - INFO - â”œâ”€â”€ Learning Rate: 7.47e-05
2025-03-02 11:27:16,018 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:27:16,686 - INFO - ðŸªœ Batch step - 499 -- sub batch step 1996 -- lr 7.48e-05
2025-03-02 11:27:18,844 - INFO - ðŸªœ Batch step - 499 -- sub batch step 1997 -- lr 7.48e-05
2025-03-02 11:27:21,132 - INFO - ðŸªœ Batch step - 499 -- sub batch step 1998 -- lr 7.48e-05
2025-03-02 11:27:23,288 - INFO - ðŸªœ Batch step - 499 -- sub batch step 1999 -- lr 7.48e-05
2025-03-02 11:27:24,914 - INFO - Step 499 -- ðŸ”„ Training Metrics
2025-03-02 11:27:24,914 - INFO - â”œâ”€â”€ Loss: 10.5173
2025-03-02 11:27:24,914 - INFO - â”œâ”€â”€ Learning Rate: 7.48e-05
2025-03-02 11:27:24,914 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:27:26,171 - INFO - ðŸªœ Batch step - 500 -- sub batch step 2000 -- lr 7.50e-05
2025-03-02 11:27:28,321 - INFO - ðŸªœ Batch step - 500 -- sub batch step 2001 -- lr 7.50e-05
2025-03-02 11:27:30,481 - INFO - ðŸªœ Batch step - 500 -- sub batch step 2002 -- lr 7.50e-05
2025-03-02 11:27:32,655 - INFO - ðŸªœ Batch step - 500 -- sub batch step 2003 -- lr 7.50e-05
2025-03-02 11:27:34,203 - INFO - Step 500 -- ðŸ”„ Training Metrics
2025-03-02 11:27:34,204 - INFO - â”œâ”€â”€ Loss: 10.5213
2025-03-02 11:27:34,204 - INFO - â”œâ”€â”€ Learning Rate: 7.50e-05
2025-03-02 11:27:34,204 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:27:34,882 - INFO - ðŸªœ Batch step - 501 -- sub batch step 2004 -- lr 7.51e-05
2025-03-02 11:27:37,041 - INFO - ðŸªœ Batch step - 501 -- sub batch step 2005 -- lr 7.51e-05
2025-03-02 11:27:39,193 - INFO - ðŸªœ Batch step - 501 -- sub batch step 2006 -- lr 7.51e-05
2025-03-02 11:27:41,650 - INFO - ðŸªœ Batch step - 501 -- sub batch step 2007 -- lr 7.51e-05
2025-03-02 11:27:43,350 - INFO - Step 501 -- ðŸ”„ Training Metrics
2025-03-02 11:27:43,350 - INFO - â”œâ”€â”€ Loss: 10.5168
2025-03-02 11:27:43,350 - INFO - â”œâ”€â”€ Learning Rate: 7.51e-05
2025-03-02 11:27:43,350 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:27:44,018 - INFO - ðŸªœ Batch step - 502 -- sub batch step 2008 -- lr 7.53e-05
2025-03-02 11:27:46,172 - INFO - ðŸªœ Batch step - 502 -- sub batch step 2009 -- lr 7.53e-05
2025-03-02 11:27:48,328 - INFO - ðŸªœ Batch step - 502 -- sub batch step 2010 -- lr 7.53e-05
2025-03-02 11:27:50,496 - INFO - ðŸªœ Batch step - 502 -- sub batch step 2011 -- lr 7.53e-05
2025-03-02 11:27:52,048 - INFO - Step 502 -- ðŸ”„ Training Metrics
2025-03-02 11:27:52,048 - INFO - â”œâ”€â”€ Loss: 10.5130
2025-03-02 11:27:52,048 - INFO - â”œâ”€â”€ Learning Rate: 7.53e-05
2025-03-02 11:27:52,048 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:27:52,721 - INFO - ðŸªœ Batch step - 503 -- sub batch step 2012 -- lr 7.54e-05
2025-03-02 11:27:54,870 - INFO - ðŸªœ Batch step - 503 -- sub batch step 2013 -- lr 7.54e-05
2025-03-02 11:27:57,022 - INFO - ðŸªœ Batch step - 503 -- sub batch step 2014 -- lr 7.54e-05
2025-03-02 11:27:59,647 - INFO - ðŸªœ Batch step - 503 -- sub batch step 2015 -- lr 7.54e-05
2025-03-02 11:28:01,248 - INFO - Step 503 -- ðŸ”„ Training Metrics
2025-03-02 11:28:01,248 - INFO - â”œâ”€â”€ Loss: 10.5136
2025-03-02 11:28:01,248 - INFO - â”œâ”€â”€ Learning Rate: 7.54e-05
2025-03-02 11:28:01,248 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:28:01,917 - INFO - ðŸªœ Batch step - 504 -- sub batch step 2016 -- lr 7.56e-05
2025-03-02 11:28:04,074 - INFO - ðŸªœ Batch step - 504 -- sub batch step 2017 -- lr 7.56e-05
2025-03-02 11:28:06,221 - INFO - ðŸªœ Batch step - 504 -- sub batch step 2018 -- lr 7.56e-05
2025-03-02 11:28:08,391 - INFO - ðŸªœ Batch step - 504 -- sub batch step 2019 -- lr 7.56e-05
2025-03-02 11:28:09,929 - INFO - Step 504 -- ðŸ”„ Training Metrics
2025-03-02 11:28:09,929 - INFO - â”œâ”€â”€ Loss: 10.5116
2025-03-02 11:28:09,929 - INFO - â”œâ”€â”€ Learning Rate: 7.56e-05
2025-03-02 11:28:09,929 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:28:10,606 - INFO - ðŸªœ Batch step - 505 -- sub batch step 2020 -- lr 7.57e-05
2025-03-02 11:28:12,762 - INFO - ðŸªœ Batch step - 505 -- sub batch step 2021 -- lr 7.57e-05
2025-03-02 11:28:14,919 - INFO - ðŸªœ Batch step - 505 -- sub batch step 2022 -- lr 7.57e-05
2025-03-02 11:28:17,358 - INFO - ðŸªœ Batch step - 505 -- sub batch step 2023 -- lr 7.57e-05
2025-03-02 11:28:19,095 - INFO - Step 505 -- ðŸ”„ Training Metrics
2025-03-02 11:28:19,095 - INFO - â”œâ”€â”€ Loss: 10.5020
2025-03-02 11:28:19,095 - INFO - â”œâ”€â”€ Learning Rate: 7.57e-05
2025-03-02 11:28:19,096 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:28:19,772 - INFO - ðŸªœ Batch step - 506 -- sub batch step 2024 -- lr 7.59e-05
2025-03-02 11:28:21,925 - INFO - ðŸªœ Batch step - 506 -- sub batch step 2025 -- lr 7.59e-05
2025-03-02 11:28:24,077 - INFO - ðŸªœ Batch step - 506 -- sub batch step 2026 -- lr 7.59e-05
2025-03-02 11:28:26,253 - INFO - ðŸªœ Batch step - 506 -- sub batch step 2027 -- lr 7.59e-05
2025-03-02 11:28:27,782 - INFO - Step 506 -- ðŸ”„ Training Metrics
2025-03-02 11:28:27,783 - INFO - â”œâ”€â”€ Loss: 10.5019
2025-03-02 11:28:27,783 - INFO - â”œâ”€â”€ Learning Rate: 7.59e-05
2025-03-02 11:28:27,783 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:28:28,452 - INFO - ðŸªœ Batch step - 507 -- sub batch step 2028 -- lr 7.60e-05
2025-03-02 11:28:30,614 - INFO - ðŸªœ Batch step - 507 -- sub batch step 2029 -- lr 7.60e-05
2025-03-02 11:28:32,770 - INFO - ðŸªœ Batch step - 507 -- sub batch step 2030 -- lr 7.60e-05
2025-03-02 11:28:35,173 - INFO - ðŸªœ Batch step - 507 -- sub batch step 2031 -- lr 7.60e-05
2025-03-02 11:28:37,095 - INFO - Step 507 -- ðŸ”„ Training Metrics
2025-03-02 11:28:37,095 - INFO - â”œâ”€â”€ Loss: 10.5002
2025-03-02 11:28:37,095 - INFO - â”œâ”€â”€ Learning Rate: 7.60e-05
2025-03-02 11:28:37,096 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:28:37,770 - INFO - ðŸªœ Batch step - 508 -- sub batch step 2032 -- lr 7.62e-05
2025-03-02 11:28:39,919 - INFO - ðŸªœ Batch step - 508 -- sub batch step 2033 -- lr 7.62e-05
2025-03-02 11:28:42,074 - INFO - ðŸªœ Batch step - 508 -- sub batch step 2034 -- lr 7.62e-05
2025-03-02 11:28:44,243 - INFO - ðŸªœ Batch step - 508 -- sub batch step 2035 -- lr 7.62e-05
2025-03-02 11:28:45,783 - INFO - Step 508 -- ðŸ”„ Training Metrics
2025-03-02 11:28:45,783 - INFO - â”œâ”€â”€ Loss: 10.4996
2025-03-02 11:28:45,784 - INFO - â”œâ”€â”€ Learning Rate: 7.62e-05
2025-03-02 11:28:45,784 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:28:46,459 - INFO - ðŸªœ Batch step - 509 -- sub batch step 2036 -- lr 7.63e-05
2025-03-02 11:28:48,618 - INFO - ðŸªœ Batch step - 509 -- sub batch step 2037 -- lr 7.63e-05
2025-03-02 11:28:50,768 - INFO - ðŸªœ Batch step - 509 -- sub batch step 2038 -- lr 7.63e-05
2025-03-02 11:28:53,467 - INFO - ðŸªœ Batch step - 509 -- sub batch step 2039 -- lr 7.63e-05
2025-03-02 11:28:54,984 - INFO - Step 509 -- ðŸ”„ Training Metrics
2025-03-02 11:28:54,984 - INFO - â”œâ”€â”€ Loss: 10.4942
2025-03-02 11:28:54,984 - INFO - â”œâ”€â”€ Learning Rate: 7.63e-05
2025-03-02 11:28:54,985 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:28:55,661 - INFO - ðŸªœ Batch step - 510 -- sub batch step 2040 -- lr 7.65e-05
2025-03-02 11:28:57,812 - INFO - ðŸªœ Batch step - 510 -- sub batch step 2041 -- lr 7.65e-05
2025-03-02 11:28:59,970 - INFO - ðŸªœ Batch step - 510 -- sub batch step 2042 -- lr 7.65e-05
2025-03-02 11:29:02,138 - INFO - ðŸªœ Batch step - 510 -- sub batch step 2043 -- lr 7.65e-05
2025-03-02 11:29:03,661 - INFO - Step 510 -- ðŸ”„ Training Metrics
2025-03-02 11:29:03,661 - INFO - â”œâ”€â”€ Loss: 10.4973
2025-03-02 11:29:03,661 - INFO - â”œâ”€â”€ Learning Rate: 7.65e-05
2025-03-02 11:29:03,661 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:29:04,337 - INFO - ðŸªœ Batch step - 511 -- sub batch step 2044 -- lr 7.66e-05
2025-03-02 11:29:06,491 - INFO - ðŸªœ Batch step - 511 -- sub batch step 2045 -- lr 7.66e-05
2025-03-02 11:29:09,156 - INFO - ðŸªœ Batch step - 511 -- sub batch step 2046 -- lr 7.66e-05
2025-03-02 11:29:11,312 - INFO - ðŸªœ Batch step - 511 -- sub batch step 2047 -- lr 7.66e-05
2025-03-02 11:29:12,882 - INFO - Step 511 -- ðŸ”„ Training Metrics
2025-03-02 11:29:12,882 - INFO - â”œâ”€â”€ Loss: 10.4876
2025-03-02 11:29:12,882 - INFO - â”œâ”€â”€ Learning Rate: 7.66e-05
2025-03-02 11:29:12,882 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:29:13,548 - INFO - ðŸªœ Batch step - 512 -- sub batch step 2048 -- lr 7.68e-05
2025-03-02 11:29:15,704 - INFO - ðŸªœ Batch step - 512 -- sub batch step 2049 -- lr 7.68e-05
2025-03-02 11:29:17,875 - INFO - ðŸªœ Batch step - 512 -- sub batch step 2050 -- lr 7.68e-05
2025-03-02 11:29:20,026 - INFO - ðŸªœ Batch step - 512 -- sub batch step 2051 -- lr 7.68e-05
2025-03-02 11:29:21,561 - INFO - Step 512 -- ðŸ”„ Training Metrics
2025-03-02 11:29:21,562 - INFO - â”œâ”€â”€ Loss: 10.4879
2025-03-02 11:29:21,562 - INFO - â”œâ”€â”€ Learning Rate: 7.68e-05
2025-03-02 11:29:21,562 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:29:22,233 - INFO - ðŸªœ Batch step - 513 -- sub batch step 2052 -- lr 7.70e-05
2025-03-02 11:29:24,380 - INFO - ðŸªœ Batch step - 513 -- sub batch step 2053 -- lr 7.70e-05
2025-03-02 11:29:27,020 - INFO - ðŸªœ Batch step - 513 -- sub batch step 2054 -- lr 7.70e-05
2025-03-02 11:29:29,182 - INFO - ðŸªœ Batch step - 513 -- sub batch step 2055 -- lr 7.70e-05
2025-03-02 11:29:30,894 - INFO - Step 513 -- ðŸ”„ Training Metrics
2025-03-02 11:29:30,894 - INFO - â”œâ”€â”€ Loss: 10.4873
2025-03-02 11:29:30,894 - INFO - â”œâ”€â”€ Learning Rate: 7.70e-05
2025-03-02 11:29:30,894 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:29:31,563 - INFO - ðŸªœ Batch step - 514 -- sub batch step 2056 -- lr 7.71e-05
2025-03-02 11:29:33,715 - INFO - ðŸªœ Batch step - 514 -- sub batch step 2057 -- lr 7.71e-05
2025-03-02 11:29:35,880 - INFO - ðŸªœ Batch step - 514 -- sub batch step 2058 -- lr 7.71e-05
2025-03-02 11:29:38,034 - INFO - ðŸªœ Batch step - 514 -- sub batch step 2059 -- lr 7.71e-05
2025-03-02 11:29:39,574 - INFO - Step 514 -- ðŸ”„ Training Metrics
2025-03-02 11:29:39,574 - INFO - â”œâ”€â”€ Loss: 10.4802
2025-03-02 11:29:39,574 - INFO - â”œâ”€â”€ Learning Rate: 7.71e-05
2025-03-02 11:29:39,574 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:29:40,246 - INFO - ðŸªœ Batch step - 515 -- sub batch step 2060 -- lr 7.72e-05
2025-03-02 11:29:42,396 - INFO - ðŸªœ Batch step - 515 -- sub batch step 2061 -- lr 7.72e-05
2025-03-02 11:29:45,093 - INFO - ðŸªœ Batch step - 515 -- sub batch step 2062 -- lr 7.72e-05
2025-03-02 11:29:47,241 - INFO - ðŸªœ Batch step - 515 -- sub batch step 2063 -- lr 7.72e-05
2025-03-02 11:29:48,880 - INFO - Step 515 -- ðŸ”„ Training Metrics
2025-03-02 11:29:48,880 - INFO - â”œâ”€â”€ Loss: 10.4806
2025-03-02 11:29:48,880 - INFO - â”œâ”€â”€ Learning Rate: 7.72e-05
2025-03-02 11:29:48,880 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:29:49,555 - INFO - ðŸªœ Batch step - 516 -- sub batch step 2064 -- lr 7.74e-05
2025-03-02 11:29:51,708 - INFO - ðŸªœ Batch step - 516 -- sub batch step 2065 -- lr 7.74e-05
2025-03-02 11:29:53,871 - INFO - ðŸªœ Batch step - 516 -- sub batch step 2066 -- lr 7.74e-05
2025-03-02 11:29:56,023 - INFO - ðŸªœ Batch step - 516 -- sub batch step 2067 -- lr 7.74e-05
2025-03-02 11:29:57,568 - INFO - Step 516 -- ðŸ”„ Training Metrics
2025-03-02 11:29:57,569 - INFO - â”œâ”€â”€ Loss: 10.4735
2025-03-02 11:29:57,569 - INFO - â”œâ”€â”€ Learning Rate: 7.74e-05
2025-03-02 11:29:57,569 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:29:58,233 - INFO - ðŸªœ Batch step - 517 -- sub batch step 2068 -- lr 7.76e-05
2025-03-02 11:30:00,385 - INFO - ðŸªœ Batch step - 517 -- sub batch step 2069 -- lr 7.76e-05
2025-03-02 11:30:03,229 - INFO - ðŸªœ Batch step - 517 -- sub batch step 2070 -- lr 7.76e-05
2025-03-02 11:30:05,385 - INFO - ðŸªœ Batch step - 517 -- sub batch step 2071 -- lr 7.76e-05
2025-03-02 11:30:07,277 - INFO - Step 517 -- ðŸ”„ Training Metrics
2025-03-02 11:30:07,278 - INFO - â”œâ”€â”€ Loss: 10.4802
2025-03-02 11:30:07,278 - INFO - â”œâ”€â”€ Learning Rate: 7.76e-05
2025-03-02 11:30:07,278 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:30:07,953 - INFO - ðŸªœ Batch step - 518 -- sub batch step 2072 -- lr 7.77e-05
2025-03-02 11:30:10,100 - INFO - ðŸªœ Batch step - 518 -- sub batch step 2073 -- lr 7.77e-05
2025-03-02 11:30:12,269 - INFO - ðŸªœ Batch step - 518 -- sub batch step 2074 -- lr 7.77e-05
2025-03-02 11:30:14,424 - INFO - ðŸªœ Batch step - 518 -- sub batch step 2075 -- lr 7.77e-05
2025-03-02 11:30:15,953 - INFO - Step 518 -- ðŸ”„ Training Metrics
2025-03-02 11:30:15,953 - INFO - â”œâ”€â”€ Loss: 10.4683
2025-03-02 11:30:15,953 - INFO - â”œâ”€â”€ Learning Rate: 7.77e-05
2025-03-02 11:30:15,953 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:30:16,622 - INFO - ðŸªœ Batch step - 519 -- sub batch step 2076 -- lr 7.78e-05
2025-03-02 11:30:18,777 - INFO - ðŸªœ Batch step - 519 -- sub batch step 2077 -- lr 7.78e-05
2025-03-02 11:30:21,062 - INFO - ðŸªœ Batch step - 519 -- sub batch step 2078 -- lr 7.78e-05
2025-03-02 11:30:23,216 - INFO - ðŸªœ Batch step - 519 -- sub batch step 2079 -- lr 7.78e-05
2025-03-02 11:30:24,861 - INFO - Step 519 -- ðŸ”„ Training Metrics
2025-03-02 11:30:24,861 - INFO - â”œâ”€â”€ Loss: 10.4686
2025-03-02 11:30:24,861 - INFO - â”œâ”€â”€ Learning Rate: 7.78e-05
2025-03-02 11:30:24,862 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:30:33,794 - INFO - ðŸªœ Batch step - 520 -- sub batch step 2080 -- lr 7.80e-05
2025-03-02 11:30:35,947 - INFO - ðŸªœ Batch step - 520 -- sub batch step 2081 -- lr 7.80e-05
2025-03-02 11:30:38,100 - INFO - ðŸªœ Batch step - 520 -- sub batch step 2082 -- lr 7.80e-05
2025-03-02 11:30:40,272 - INFO - ðŸªœ Batch step - 520 -- sub batch step 2083 -- lr 7.80e-05
2025-03-02 11:30:41,826 - INFO - Step 520 -- ðŸ”„ Training Metrics
2025-03-02 11:30:41,827 - INFO - â”œâ”€â”€ Loss: 10.4604
2025-03-02 11:30:41,827 - INFO - â”œâ”€â”€ Learning Rate: 7.80e-05
2025-03-02 11:30:41,827 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:30:42,502 - INFO - ðŸªœ Batch step - 521 -- sub batch step 2084 -- lr 7.82e-05
2025-03-02 11:30:44,662 - INFO - ðŸªœ Batch step - 521 -- sub batch step 2085 -- lr 7.82e-05
2025-03-02 11:30:46,813 - INFO - ðŸªœ Batch step - 521 -- sub batch step 2086 -- lr 7.82e-05
2025-03-02 11:30:49,307 - INFO - ðŸªœ Batch step - 521 -- sub batch step 2087 -- lr 7.82e-05
2025-03-02 11:30:50,956 - INFO - Step 521 -- ðŸ”„ Training Metrics
2025-03-02 11:30:50,956 - INFO - â”œâ”€â”€ Loss: 10.4563
2025-03-02 11:30:50,956 - INFO - â”œâ”€â”€ Learning Rate: 7.82e-05
2025-03-02 11:30:50,956 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:30:51,625 - INFO - ðŸªœ Batch step - 522 -- sub batch step 2088 -- lr 7.83e-05
2025-03-02 11:30:53,785 - INFO - ðŸªœ Batch step - 522 -- sub batch step 2089 -- lr 7.83e-05
2025-03-02 11:30:55,938 - INFO - ðŸªœ Batch step - 522 -- sub batch step 2090 -- lr 7.83e-05
2025-03-02 11:30:58,112 - INFO - ðŸªœ Batch step - 522 -- sub batch step 2091 -- lr 7.83e-05
2025-03-02 11:30:59,654 - INFO - Step 522 -- ðŸ”„ Training Metrics
2025-03-02 11:30:59,654 - INFO - â”œâ”€â”€ Loss: 10.4629
2025-03-02 11:30:59,654 - INFO - â”œâ”€â”€ Learning Rate: 7.83e-05
2025-03-02 11:30:59,655 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:31:00,333 - INFO - ðŸªœ Batch step - 523 -- sub batch step 2092 -- lr 7.84e-05
2025-03-02 11:31:02,484 - INFO - ðŸªœ Batch step - 523 -- sub batch step 2093 -- lr 7.84e-05
2025-03-02 11:31:04,639 - INFO - ðŸªœ Batch step - 523 -- sub batch step 2094 -- lr 7.84e-05
2025-03-02 11:31:07,016 - INFO - ðŸªœ Batch step - 523 -- sub batch step 2095 -- lr 7.84e-05
2025-03-02 11:31:08,931 - INFO - Step 523 -- ðŸ”„ Training Metrics
2025-03-02 11:31:08,932 - INFO - â”œâ”€â”€ Loss: 10.4544
2025-03-02 11:31:08,932 - INFO - â”œâ”€â”€ Learning Rate: 7.84e-05
2025-03-02 11:31:08,932 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:31:09,601 - INFO - ðŸªœ Batch step - 524 -- sub batch step 2096 -- lr 7.86e-05
2025-03-02 11:31:11,763 - INFO - ðŸªœ Batch step - 524 -- sub batch step 2097 -- lr 7.86e-05
2025-03-02 11:31:13,912 - INFO - ðŸªœ Batch step - 524 -- sub batch step 2098 -- lr 7.86e-05
2025-03-02 11:31:16,095 - INFO - ðŸªœ Batch step - 524 -- sub batch step 2099 -- lr 7.86e-05
2025-03-02 11:31:17,639 - INFO - Step 524 -- ðŸ”„ Training Metrics
2025-03-02 11:31:17,640 - INFO - â”œâ”€â”€ Loss: 10.4534
2025-03-02 11:31:17,640 - INFO - â”œâ”€â”€ Learning Rate: 7.86e-05
2025-03-02 11:31:17,640 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:31:18,318 - INFO - ðŸªœ Batch step - 525 -- sub batch step 2100 -- lr 7.87e-05
2025-03-02 11:31:20,471 - INFO - ðŸªœ Batch step - 525 -- sub batch step 2101 -- lr 7.87e-05
2025-03-02 11:31:22,625 - INFO - ðŸªœ Batch step - 525 -- sub batch step 2102 -- lr 7.87e-05
2025-03-02 11:31:25,288 - INFO - ðŸªœ Batch step - 525 -- sub batch step 2103 -- lr 7.87e-05
2025-03-02 11:31:26,981 - INFO - Step 525 -- ðŸ”„ Training Metrics
2025-03-02 11:31:26,981 - INFO - â”œâ”€â”€ Loss: 10.4492
2025-03-02 11:31:26,981 - INFO - â”œâ”€â”€ Learning Rate: 7.87e-05
2025-03-02 11:31:26,981 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:31:27,657 - INFO - ðŸªœ Batch step - 526 -- sub batch step 2104 -- lr 7.89e-05
2025-03-02 11:31:29,813 - INFO - ðŸªœ Batch step - 526 -- sub batch step 2105 -- lr 7.89e-05
2025-03-02 11:31:31,960 - INFO - ðŸªœ Batch step - 526 -- sub batch step 2106 -- lr 7.89e-05
2025-03-02 11:31:34,131 - INFO - ðŸªœ Batch step - 526 -- sub batch step 2107 -- lr 7.89e-05
2025-03-02 11:31:35,676 - INFO - Step 526 -- ðŸ”„ Training Metrics
2025-03-02 11:31:35,676 - INFO - â”œâ”€â”€ Loss: 10.4519
2025-03-02 11:31:35,676 - INFO - â”œâ”€â”€ Learning Rate: 7.89e-05
2025-03-02 11:31:35,677 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:31:36,342 - INFO - ðŸªœ Batch step - 527 -- sub batch step 2108 -- lr 7.90e-05
2025-03-02 11:31:38,499 - INFO - ðŸªœ Batch step - 527 -- sub batch step 2109 -- lr 7.90e-05
2025-03-02 11:31:40,655 - INFO - ðŸªœ Batch step - 527 -- sub batch step 2110 -- lr 7.90e-05
2025-03-02 11:31:43,328 - INFO - ðŸªœ Batch step - 527 -- sub batch step 2111 -- lr 7.90e-05
2025-03-02 11:31:45,010 - INFO - Step 527 -- ðŸ”„ Training Metrics
2025-03-02 11:31:45,011 - INFO - â”œâ”€â”€ Loss: 10.4463
2025-03-02 11:31:45,011 - INFO - â”œâ”€â”€ Learning Rate: 7.90e-05
2025-03-02 11:31:45,011 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:31:45,687 - INFO - ðŸªœ Batch step - 528 -- sub batch step 2112 -- lr 7.92e-05
2025-03-02 11:31:47,836 - INFO - ðŸªœ Batch step - 528 -- sub batch step 2113 -- lr 7.92e-05
2025-03-02 11:31:49,988 - INFO - ðŸªœ Batch step - 528 -- sub batch step 2114 -- lr 7.92e-05
2025-03-02 11:31:52,161 - INFO - ðŸªœ Batch step - 528 -- sub batch step 2115 -- lr 7.92e-05
2025-03-02 11:31:53,712 - INFO - Step 528 -- ðŸ”„ Training Metrics
2025-03-02 11:31:53,713 - INFO - â”œâ”€â”€ Loss: 10.4391
2025-03-02 11:31:53,713 - INFO - â”œâ”€â”€ Learning Rate: 7.92e-05
2025-03-02 11:31:53,713 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:31:54,382 - INFO - ðŸªœ Batch step - 529 -- sub batch step 2116 -- lr 7.93e-05
2025-03-02 11:31:56,541 - INFO - ðŸªœ Batch step - 529 -- sub batch step 2117 -- lr 7.93e-05
2025-03-02 11:31:58,687 - INFO - ðŸªœ Batch step - 529 -- sub batch step 2118 -- lr 7.93e-05
2025-03-02 11:32:01,403 - INFO - ðŸªœ Batch step - 529 -- sub batch step 2119 -- lr 7.93e-05
2025-03-02 11:32:03,008 - INFO - Step 529 -- ðŸ”„ Training Metrics
2025-03-02 11:32:03,009 - INFO - â”œâ”€â”€ Loss: 10.4398
2025-03-02 11:32:03,009 - INFO - â”œâ”€â”€ Learning Rate: 7.93e-05
2025-03-02 11:32:03,009 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:32:03,682 - INFO - ðŸªœ Batch step - 530 -- sub batch step 2120 -- lr 7.95e-05
2025-03-02 11:32:05,828 - INFO - ðŸªœ Batch step - 530 -- sub batch step 2121 -- lr 7.95e-05
2025-03-02 11:32:07,980 - INFO - ðŸªœ Batch step - 530 -- sub batch step 2122 -- lr 7.95e-05
2025-03-02 11:32:10,146 - INFO - ðŸªœ Batch step - 530 -- sub batch step 2123 -- lr 7.95e-05
2025-03-02 11:32:11,700 - INFO - Step 530 -- ðŸ”„ Training Metrics
2025-03-02 11:32:11,701 - INFO - â”œâ”€â”€ Loss: 10.4354
2025-03-02 11:32:11,701 - INFO - â”œâ”€â”€ Learning Rate: 7.95e-05
2025-03-02 11:32:11,701 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:32:12,378 - INFO - ðŸªœ Batch step - 531 -- sub batch step 2124 -- lr 7.96e-05
2025-03-02 11:32:14,532 - INFO - ðŸªœ Batch step - 531 -- sub batch step 2125 -- lr 7.96e-05
2025-03-02 11:32:17,205 - INFO - ðŸªœ Batch step - 531 -- sub batch step 2126 -- lr 7.96e-05
2025-03-02 11:32:19,366 - INFO - ðŸªœ Batch step - 531 -- sub batch step 2127 -- lr 7.96e-05
2025-03-02 11:32:21,495 - INFO - Step 531 -- ðŸ”„ Training Metrics
2025-03-02 11:32:21,496 - INFO - â”œâ”€â”€ Loss: 10.4374
2025-03-02 11:32:21,496 - INFO - â”œâ”€â”€ Learning Rate: 7.96e-05
2025-03-02 11:32:21,496 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:32:22,160 - INFO - ðŸªœ Batch step - 532 -- sub batch step 2128 -- lr 7.98e-05
2025-03-02 11:32:24,314 - INFO - ðŸªœ Batch step - 532 -- sub batch step 2129 -- lr 7.98e-05
2025-03-02 11:32:26,487 - INFO - ðŸªœ Batch step - 532 -- sub batch step 2130 -- lr 7.98e-05
2025-03-02 11:32:28,636 - INFO - ðŸªœ Batch step - 532 -- sub batch step 2131 -- lr 7.98e-05
2025-03-02 11:32:30,194 - INFO - Step 532 -- ðŸ”„ Training Metrics
2025-03-02 11:32:30,195 - INFO - â”œâ”€â”€ Loss: 10.4325
2025-03-02 11:32:30,195 - INFO - â”œâ”€â”€ Learning Rate: 7.98e-05
2025-03-02 11:32:30,195 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:32:30,872 - INFO - ðŸªœ Batch step - 533 -- sub batch step 2132 -- lr 7.99e-05
2025-03-02 11:32:33,019 - INFO - ðŸªœ Batch step - 533 -- sub batch step 2133 -- lr 7.99e-05
2025-03-02 11:32:35,670 - INFO - ðŸªœ Batch step - 533 -- sub batch step 2134 -- lr 7.99e-05
2025-03-02 11:32:37,821 - INFO - ðŸªœ Batch step - 533 -- sub batch step 2135 -- lr 7.99e-05
2025-03-02 11:32:39,502 - INFO - Step 533 -- ðŸ”„ Training Metrics
2025-03-02 11:32:39,502 - INFO - â”œâ”€â”€ Loss: 10.4311
2025-03-02 11:32:39,502 - INFO - â”œâ”€â”€ Learning Rate: 7.99e-05
2025-03-02 11:32:39,503 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:32:40,173 - INFO - ðŸªœ Batch step - 534 -- sub batch step 2136 -- lr 8.01e-05
2025-03-02 11:32:42,323 - INFO - ðŸªœ Batch step - 534 -- sub batch step 2137 -- lr 8.01e-05
2025-03-02 11:32:44,489 - INFO - ðŸªœ Batch step - 534 -- sub batch step 2138 -- lr 8.01e-05
2025-03-02 11:32:46,639 - INFO - ðŸªœ Batch step - 534 -- sub batch step 2139 -- lr 8.01e-05
2025-03-02 11:32:48,198 - INFO - Step 534 -- ðŸ”„ Training Metrics
2025-03-02 11:32:48,199 - INFO - â”œâ”€â”€ Loss: 10.4271
2025-03-02 11:32:48,199 - INFO - â”œâ”€â”€ Learning Rate: 8.01e-05
2025-03-02 11:32:48,199 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:32:48,867 - INFO - ðŸªœ Batch step - 535 -- sub batch step 2140 -- lr 8.02e-05
2025-03-02 11:32:51,018 - INFO - ðŸªœ Batch step - 535 -- sub batch step 2141 -- lr 8.02e-05
2025-03-02 11:32:53,624 - INFO - ðŸªœ Batch step - 535 -- sub batch step 2142 -- lr 8.02e-05
2025-03-02 11:32:55,777 - INFO - ðŸªœ Batch step - 535 -- sub batch step 2143 -- lr 8.02e-05
2025-03-02 11:32:57,694 - INFO - Step 535 -- ðŸ”„ Training Metrics
2025-03-02 11:32:57,694 - INFO - â”œâ”€â”€ Loss: 10.4208
2025-03-02 11:32:57,694 - INFO - â”œâ”€â”€ Learning Rate: 8.02e-05
2025-03-02 11:32:57,694 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:32:58,368 - INFO - ðŸªœ Batch step - 536 -- sub batch step 2144 -- lr 8.04e-05
2025-03-02 11:33:00,519 - INFO - ðŸªœ Batch step - 536 -- sub batch step 2145 -- lr 8.04e-05
2025-03-02 11:33:02,684 - INFO - ðŸªœ Batch step - 536 -- sub batch step 2146 -- lr 8.04e-05
2025-03-02 11:33:04,837 - INFO - ðŸªœ Batch step - 536 -- sub batch step 2147 -- lr 8.04e-05
2025-03-02 11:33:06,399 - INFO - Step 536 -- ðŸ”„ Training Metrics
2025-03-02 11:33:06,399 - INFO - â”œâ”€â”€ Loss: 10.4146
2025-03-02 11:33:06,399 - INFO - â”œâ”€â”€ Learning Rate: 8.04e-05
2025-03-02 11:33:06,399 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:33:07,062 - INFO - ðŸªœ Batch step - 537 -- sub batch step 2148 -- lr 8.05e-05
2025-03-02 11:33:09,219 - INFO - ðŸªœ Batch step - 537 -- sub batch step 2149 -- lr 8.05e-05
2025-03-02 11:33:11,909 - INFO - ðŸªœ Batch step - 537 -- sub batch step 2150 -- lr 8.05e-05
2025-03-02 11:33:14,054 - INFO - ðŸªœ Batch step - 537 -- sub batch step 2151 -- lr 8.05e-05
2025-03-02 11:33:15,645 - INFO - Step 537 -- ðŸ”„ Training Metrics
2025-03-02 11:33:15,645 - INFO - â”œâ”€â”€ Loss: 10.4201
2025-03-02 11:33:15,645 - INFO - â”œâ”€â”€ Learning Rate: 8.05e-05
2025-03-02 11:33:15,645 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:33:16,322 - INFO - ðŸªœ Batch step - 538 -- sub batch step 2152 -- lr 8.07e-05
2025-03-02 11:33:18,469 - INFO - ðŸªœ Batch step - 538 -- sub batch step 2153 -- lr 8.07e-05
2025-03-02 11:33:20,638 - INFO - ðŸªœ Batch step - 538 -- sub batch step 2154 -- lr 8.07e-05
2025-03-02 11:33:22,789 - INFO - ðŸªœ Batch step - 538 -- sub batch step 2155 -- lr 8.07e-05
2025-03-02 11:33:24,336 - INFO - Step 538 -- ðŸ”„ Training Metrics
2025-03-02 11:33:24,336 - INFO - â”œâ”€â”€ Loss: 10.4107
2025-03-02 11:33:24,336 - INFO - â”œâ”€â”€ Learning Rate: 8.07e-05
2025-03-02 11:33:24,336 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:33:25,001 - INFO - ðŸªœ Batch step - 539 -- sub batch step 2156 -- lr 8.09e-05
2025-03-02 11:33:27,156 - INFO - ðŸªœ Batch step - 539 -- sub batch step 2157 -- lr 8.09e-05
2025-03-02 11:33:29,588 - INFO - ðŸªœ Batch step - 539 -- sub batch step 2158 -- lr 8.09e-05
2025-03-02 11:33:31,742 - INFO - ðŸªœ Batch step - 539 -- sub batch step 2159 -- lr 8.09e-05
2025-03-02 11:33:33,234 - INFO - Step 539 -- ðŸ”„ Training Metrics
2025-03-02 11:33:33,234 - INFO - â”œâ”€â”€ Loss: 10.4042
2025-03-02 11:33:33,234 - INFO - â”œâ”€â”€ Learning Rate: 8.09e-05
2025-03-02 11:33:33,235 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:33:34,475 - INFO - ðŸªœ Batch step - 540 -- sub batch step 2160 -- lr 8.10e-05
2025-03-02 11:33:36,629 - INFO - ðŸªœ Batch step - 540 -- sub batch step 2161 -- lr 8.10e-05
2025-03-02 11:33:38,793 - INFO - ðŸªœ Batch step - 540 -- sub batch step 2162 -- lr 8.10e-05
2025-03-02 11:33:40,975 - INFO - ðŸªœ Batch step - 540 -- sub batch step 2163 -- lr 8.10e-05
2025-03-02 11:33:42,652 - INFO - Step 540 -- ðŸ”„ Training Metrics
2025-03-02 11:33:42,652 - INFO - â”œâ”€â”€ Loss: 10.4067
2025-03-02 11:33:42,653 - INFO - â”œâ”€â”€ Learning Rate: 8.10e-05
2025-03-02 11:33:42,653 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:33:43,332 - INFO - ðŸªœ Batch step - 541 -- sub batch step 2164 -- lr 8.11e-05
2025-03-02 11:33:45,494 - INFO - ðŸªœ Batch step - 541 -- sub batch step 2165 -- lr 8.11e-05
2025-03-02 11:33:47,649 - INFO - ðŸªœ Batch step - 541 -- sub batch step 2166 -- lr 8.11e-05
2025-03-02 11:33:50,218 - INFO - ðŸªœ Batch step - 541 -- sub batch step 2167 -- lr 8.11e-05
2025-03-02 11:33:52,959 - INFO - Step 541 -- ðŸ”„ Training Metrics
2025-03-02 11:33:52,959 - INFO - â”œâ”€â”€ Loss: 10.4061
2025-03-02 11:33:52,959 - INFO - â”œâ”€â”€ Learning Rate: 8.11e-05
2025-03-02 11:33:52,960 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:33:53,623 - INFO - ðŸªœ Batch step - 542 -- sub batch step 2168 -- lr 8.13e-05
2025-03-02 11:33:55,787 - INFO - ðŸªœ Batch step - 542 -- sub batch step 2169 -- lr 8.13e-05
2025-03-02 11:33:57,942 - INFO - ðŸªœ Batch step - 542 -- sub batch step 2170 -- lr 8.13e-05
2025-03-02 11:34:00,116 - INFO - ðŸªœ Batch step - 542 -- sub batch step 2171 -- lr 8.13e-05
2025-03-02 11:34:01,645 - INFO - Step 542 -- ðŸ”„ Training Metrics
2025-03-02 11:34:01,646 - INFO - â”œâ”€â”€ Loss: 10.3981
2025-03-02 11:34:01,646 - INFO - â”œâ”€â”€ Learning Rate: 8.13e-05
2025-03-02 11:34:01,646 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:34:02,321 - INFO - ðŸªœ Batch step - 543 -- sub batch step 2172 -- lr 8.15e-05
2025-03-02 11:34:04,472 - INFO - ðŸªœ Batch step - 543 -- sub batch step 2173 -- lr 8.15e-05
2025-03-02 11:34:06,627 - INFO - ðŸªœ Batch step - 543 -- sub batch step 2174 -- lr 8.15e-05
2025-03-02 11:34:09,117 - INFO - ðŸªœ Batch step - 543 -- sub batch step 2175 -- lr 8.15e-05
2025-03-02 11:34:11,140 - INFO - Step 543 -- ðŸ”„ Training Metrics
2025-03-02 11:34:11,140 - INFO - â”œâ”€â”€ Loss: 10.4084
2025-03-02 11:34:11,141 - INFO - â”œâ”€â”€ Learning Rate: 8.15e-05
2025-03-02 11:34:11,141 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:34:11,812 - INFO - ðŸªœ Batch step - 544 -- sub batch step 2176 -- lr 8.16e-05
2025-03-02 11:34:13,970 - INFO - ðŸªœ Batch step - 544 -- sub batch step 2177 -- lr 8.16e-05
2025-03-02 11:34:16,119 - INFO - ðŸªœ Batch step - 544 -- sub batch step 2178 -- lr 8.16e-05
2025-03-02 11:34:18,295 - INFO - ðŸªœ Batch step - 544 -- sub batch step 2179 -- lr 8.16e-05
2025-03-02 11:34:19,833 - INFO - Step 544 -- ðŸ”„ Training Metrics
2025-03-02 11:34:19,833 - INFO - â”œâ”€â”€ Loss: 10.3911
2025-03-02 11:34:19,833 - INFO - â”œâ”€â”€ Learning Rate: 8.16e-05
2025-03-02 11:34:19,834 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:34:20,510 - INFO - ðŸªœ Batch step - 545 -- sub batch step 2180 -- lr 8.17e-05
2025-03-02 11:34:22,661 - INFO - ðŸªœ Batch step - 545 -- sub batch step 2181 -- lr 8.17e-05
2025-03-02 11:34:24,819 - INFO - ðŸªœ Batch step - 545 -- sub batch step 2182 -- lr 8.17e-05
2025-03-02 11:34:27,495 - INFO - ðŸªœ Batch step - 545 -- sub batch step 2183 -- lr 8.17e-05
2025-03-02 11:34:29,150 - INFO - Step 545 -- ðŸ”„ Training Metrics
2025-03-02 11:34:29,150 - INFO - â”œâ”€â”€ Loss: 10.3913
2025-03-02 11:34:29,150 - INFO - â”œâ”€â”€ Learning Rate: 8.17e-05
2025-03-02 11:34:29,151 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:34:29,828 - INFO - ðŸªœ Batch step - 546 -- sub batch step 2184 -- lr 8.19e-05
2025-03-02 11:34:31,987 - INFO - ðŸªœ Batch step - 546 -- sub batch step 2185 -- lr 8.19e-05
2025-03-02 11:34:34,138 - INFO - ðŸªœ Batch step - 546 -- sub batch step 2186 -- lr 8.19e-05
2025-03-02 11:34:36,316 - INFO - ðŸªœ Batch step - 546 -- sub batch step 2187 -- lr 8.19e-05
2025-03-02 11:34:37,851 - INFO - Step 546 -- ðŸ”„ Training Metrics
2025-03-02 11:34:37,851 - INFO - â”œâ”€â”€ Loss: 10.3853
2025-03-02 11:34:37,851 - INFO - â”œâ”€â”€ Learning Rate: 8.19e-05
2025-03-02 11:34:37,851 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:34:38,525 - INFO - ðŸªœ Batch step - 547 -- sub batch step 2188 -- lr 8.21e-05
2025-03-02 11:34:40,686 - INFO - ðŸªœ Batch step - 547 -- sub batch step 2189 -- lr 8.21e-05
2025-03-02 11:34:42,840 - INFO - ðŸªœ Batch step - 547 -- sub batch step 2190 -- lr 8.21e-05
2025-03-02 11:34:45,595 - INFO - ðŸªœ Batch step - 547 -- sub batch step 2191 -- lr 8.21e-05
2025-03-02 11:34:47,089 - INFO - Step 547 -- ðŸ”„ Training Metrics
2025-03-02 11:34:47,089 - INFO - â”œâ”€â”€ Loss: 10.3799
2025-03-02 11:34:47,090 - INFO - â”œâ”€â”€ Learning Rate: 8.21e-05
2025-03-02 11:34:47,090 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:34:47,766 - INFO - ðŸªœ Batch step - 548 -- sub batch step 2192 -- lr 8.22e-05
2025-03-02 11:34:49,915 - INFO - ðŸªœ Batch step - 548 -- sub batch step 2193 -- lr 8.22e-05
2025-03-02 11:34:52,073 - INFO - ðŸªœ Batch step - 548 -- sub batch step 2194 -- lr 8.22e-05
2025-03-02 11:34:54,250 - INFO - ðŸªœ Batch step - 548 -- sub batch step 2195 -- lr 8.22e-05
2025-03-02 11:34:55,794 - INFO - Step 548 -- ðŸ”„ Training Metrics
2025-03-02 11:34:55,794 - INFO - â”œâ”€â”€ Loss: 10.3840
2025-03-02 11:34:55,794 - INFO - â”œâ”€â”€ Learning Rate: 8.22e-05
2025-03-02 11:34:55,794 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:34:56,461 - INFO - ðŸªœ Batch step - 549 -- sub batch step 2196 -- lr 8.23e-05
2025-03-02 11:34:58,618 - INFO - ðŸªœ Batch step - 549 -- sub batch step 2197 -- lr 8.23e-05
2025-03-02 11:35:00,772 - INFO - ðŸªœ Batch step - 549 -- sub batch step 2198 -- lr 8.23e-05
2025-03-02 11:35:03,172 - INFO - ðŸªœ Batch step - 549 -- sub batch step 2199 -- lr 8.23e-05
2025-03-02 11:35:04,963 - INFO - Step 549 -- ðŸ”„ Training Metrics
2025-03-02 11:35:04,964 - INFO - â”œâ”€â”€ Loss: 10.3785
2025-03-02 11:35:04,964 - INFO - â”œâ”€â”€ Learning Rate: 8.23e-05
2025-03-02 11:35:04,964 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:35:05,637 - INFO - ðŸªœ Batch step - 550 -- sub batch step 2200 -- lr 8.25e-05
2025-03-02 11:35:07,787 - INFO - ðŸªœ Batch step - 550 -- sub batch step 2201 -- lr 8.25e-05
2025-03-02 11:35:09,942 - INFO - ðŸªœ Batch step - 550 -- sub batch step 2202 -- lr 8.25e-05
2025-03-02 11:35:12,109 - INFO - ðŸªœ Batch step - 550 -- sub batch step 2203 -- lr 8.25e-05
2025-03-02 11:35:13,649 - INFO - Step 550 -- ðŸ”„ Training Metrics
2025-03-02 11:35:13,649 - INFO - â”œâ”€â”€ Loss: 10.3700
2025-03-02 11:35:13,649 - INFO - â”œâ”€â”€ Learning Rate: 8.25e-05
2025-03-02 11:35:13,649 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:35:14,322 - INFO - ðŸªœ Batch step - 551 -- sub batch step 2204 -- lr 8.27e-05
2025-03-02 11:35:16,477 - INFO - ðŸªœ Batch step - 551 -- sub batch step 2205 -- lr 8.27e-05
2025-03-02 11:35:18,886 - INFO - ðŸªœ Batch step - 551 -- sub batch step 2206 -- lr 8.27e-05
2025-03-02 11:35:21,055 - INFO - ðŸªœ Batch step - 551 -- sub batch step 2207 -- lr 8.27e-05
2025-03-02 11:35:22,802 - INFO - Step 551 -- ðŸ”„ Training Metrics
2025-03-02 11:35:22,802 - INFO - â”œâ”€â”€ Loss: 10.3744
2025-03-02 11:35:22,802 - INFO - â”œâ”€â”€ Learning Rate: 8.27e-05
2025-03-02 11:35:22,803 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:35:23,470 - INFO - ðŸªœ Batch step - 552 -- sub batch step 2208 -- lr 8.28e-05
2025-03-02 11:35:25,624 - INFO - ðŸªœ Batch step - 552 -- sub batch step 2209 -- lr 8.28e-05
2025-03-02 11:35:27,798 - INFO - ðŸªœ Batch step - 552 -- sub batch step 2210 -- lr 8.28e-05
2025-03-02 11:35:29,946 - INFO - ðŸªœ Batch step - 552 -- sub batch step 2211 -- lr 8.28e-05
2025-03-02 11:35:31,483 - INFO - Step 552 -- ðŸ”„ Training Metrics
2025-03-02 11:35:31,484 - INFO - â”œâ”€â”€ Loss: 10.3643
2025-03-02 11:35:31,484 - INFO - â”œâ”€â”€ Learning Rate: 8.28e-05
2025-03-02 11:35:31,484 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:35:32,159 - INFO - ðŸªœ Batch step - 553 -- sub batch step 2212 -- lr 8.29e-05
2025-03-02 11:35:34,311 - INFO - ðŸªœ Batch step - 553 -- sub batch step 2213 -- lr 8.29e-05
2025-03-02 11:35:37,060 - INFO - ðŸªœ Batch step - 553 -- sub batch step 2214 -- lr 8.29e-05
2025-03-02 11:35:39,216 - INFO - ðŸªœ Batch step - 553 -- sub batch step 2215 -- lr 8.29e-05
2025-03-02 11:35:40,774 - INFO - Step 553 -- ðŸ”„ Training Metrics
2025-03-02 11:35:40,775 - INFO - â”œâ”€â”€ Loss: 10.3651
2025-03-02 11:35:40,775 - INFO - â”œâ”€â”€ Learning Rate: 8.29e-05
2025-03-02 11:35:40,775 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:35:41,442 - INFO - ðŸªœ Batch step - 554 -- sub batch step 2216 -- lr 8.31e-05
2025-03-02 11:35:43,594 - INFO - ðŸªœ Batch step - 554 -- sub batch step 2217 -- lr 8.31e-05
2025-03-02 11:35:45,761 - INFO - ðŸªœ Batch step - 554 -- sub batch step 2218 -- lr 8.31e-05
2025-03-02 11:35:47,915 - INFO - ðŸªœ Batch step - 554 -- sub batch step 2219 -- lr 8.31e-05
2025-03-02 11:35:49,459 - INFO - Step 554 -- ðŸ”„ Training Metrics
2025-03-02 11:35:49,460 - INFO - â”œâ”€â”€ Loss: 10.3591
2025-03-02 11:35:49,460 - INFO - â”œâ”€â”€ Learning Rate: 8.31e-05
2025-03-02 11:35:49,460 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:35:50,135 - INFO - ðŸªœ Batch step - 555 -- sub batch step 2220 -- lr 8.33e-05
2025-03-02 11:35:52,286 - INFO - ðŸªœ Batch step - 555 -- sub batch step 2221 -- lr 8.33e-05
2025-03-02 11:35:55,002 - INFO - ðŸªœ Batch step - 555 -- sub batch step 2222 -- lr 8.33e-05
2025-03-02 11:35:57,158 - INFO - ðŸªœ Batch step - 555 -- sub batch step 2223 -- lr 8.33e-05
2025-03-02 11:36:01,953 - INFO - Step 555 -- ðŸ”„ Training Metrics
2025-03-02 11:36:01,954 - INFO - â”œâ”€â”€ Loss: 10.3616
2025-03-02 11:36:01,954 - INFO - â”œâ”€â”€ Learning Rate: 8.33e-05
2025-03-02 11:36:01,954 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:36:02,630 - INFO - ðŸªœ Batch step - 556 -- sub batch step 2224 -- lr 8.34e-05
2025-03-02 11:36:04,786 - INFO - ðŸªœ Batch step - 556 -- sub batch step 2225 -- lr 8.34e-05
2025-03-02 11:36:06,957 - INFO - ðŸªœ Batch step - 556 -- sub batch step 2226 -- lr 8.34e-05
2025-03-02 11:36:09,115 - INFO - ðŸªœ Batch step - 556 -- sub batch step 2227 -- lr 8.34e-05
2025-03-02 11:36:10,652 - INFO - Step 556 -- ðŸ”„ Training Metrics
2025-03-02 11:36:10,652 - INFO - â”œâ”€â”€ Loss: 10.3546
2025-03-02 11:36:10,652 - INFO - â”œâ”€â”€ Learning Rate: 8.34e-05
2025-03-02 11:36:10,652 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:36:11,318 - INFO - ðŸªœ Batch step - 557 -- sub batch step 2228 -- lr 8.35e-05
2025-03-02 11:36:13,479 - INFO - ðŸªœ Batch step - 557 -- sub batch step 2229 -- lr 8.35e-05
2025-03-02 11:36:16,176 - INFO - ðŸªœ Batch step - 557 -- sub batch step 2230 -- lr 8.35e-05
2025-03-02 11:36:18,322 - INFO - ðŸªœ Batch step - 557 -- sub batch step 2231 -- lr 8.35e-05
2025-03-02 11:36:19,860 - INFO - Step 557 -- ðŸ”„ Training Metrics
2025-03-02 11:36:19,860 - INFO - â”œâ”€â”€ Loss: 10.3490
2025-03-02 11:36:19,860 - INFO - â”œâ”€â”€ Learning Rate: 8.35e-05
2025-03-02 11:36:19,860 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:36:20,536 - INFO - ðŸªœ Batch step - 558 -- sub batch step 2232 -- lr 8.37e-05
2025-03-02 11:36:22,687 - INFO - ðŸªœ Batch step - 558 -- sub batch step 2233 -- lr 8.37e-05
2025-03-02 11:36:24,857 - INFO - ðŸªœ Batch step - 558 -- sub batch step 2234 -- lr 8.37e-05
2025-03-02 11:36:27,013 - INFO - ðŸªœ Batch step - 558 -- sub batch step 2235 -- lr 8.37e-05
2025-03-02 11:36:28,567 - INFO - Step 558 -- ðŸ”„ Training Metrics
2025-03-02 11:36:28,568 - INFO - â”œâ”€â”€ Loss: 10.3512
2025-03-02 11:36:28,568 - INFO - â”œâ”€â”€ Learning Rate: 8.37e-05
2025-03-02 11:36:28,568 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:36:29,236 - INFO - ðŸªœ Batch step - 559 -- sub batch step 2236 -- lr 8.39e-05
2025-03-02 11:36:31,397 - INFO - ðŸªœ Batch step - 559 -- sub batch step 2237 -- lr 8.39e-05
2025-03-02 11:36:33,812 - INFO - ðŸªœ Batch step - 559 -- sub batch step 2238 -- lr 8.39e-05
2025-03-02 11:36:35,973 - INFO - ðŸªœ Batch step - 559 -- sub batch step 2239 -- lr 8.39e-05
2025-03-02 11:36:37,708 - INFO - Step 559 -- ðŸ”„ Training Metrics
2025-03-02 11:36:37,709 - INFO - â”œâ”€â”€ Loss: 10.3450
2025-03-02 11:36:37,709 - INFO - â”œâ”€â”€ Learning Rate: 8.39e-05
2025-03-02 11:36:37,709 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:36:39,003 - INFO - ðŸªœ Batch step - 560 -- sub batch step 2240 -- lr 8.40e-05
2025-03-02 11:36:41,155 - INFO - ðŸªœ Batch step - 560 -- sub batch step 2241 -- lr 8.40e-05
2025-03-02 11:36:43,310 - INFO - ðŸªœ Batch step - 560 -- sub batch step 2242 -- lr 8.40e-05
2025-03-02 11:36:45,478 - INFO - ðŸªœ Batch step - 560 -- sub batch step 2243 -- lr 8.40e-05
2025-03-02 11:36:47,032 - INFO - Step 560 -- ðŸ”„ Training Metrics
2025-03-02 11:36:47,032 - INFO - â”œâ”€â”€ Loss: 10.3376
2025-03-02 11:36:47,032 - INFO - â”œâ”€â”€ Learning Rate: 8.40e-05
2025-03-02 11:36:47,032 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:36:47,710 - INFO - ðŸªœ Batch step - 561 -- sub batch step 2244 -- lr 8.41e-05
2025-03-02 11:36:49,867 - INFO - ðŸªœ Batch step - 561 -- sub batch step 2245 -- lr 8.41e-05
2025-03-02 11:36:52,015 - INFO - ðŸªœ Batch step - 561 -- sub batch step 2246 -- lr 8.41e-05
2025-03-02 11:36:54,566 - INFO - ðŸªœ Batch step - 561 -- sub batch step 2247 -- lr 8.41e-05
2025-03-02 11:36:56,285 - INFO - Step 561 -- ðŸ”„ Training Metrics
2025-03-02 11:36:56,285 - INFO - â”œâ”€â”€ Loss: 10.3480
2025-03-02 11:36:56,285 - INFO - â”œâ”€â”€ Learning Rate: 8.41e-05
2025-03-02 11:36:56,285 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:36:56,954 - INFO - ðŸªœ Batch step - 562 -- sub batch step 2248 -- lr 8.43e-05
2025-03-02 11:36:59,115 - INFO - ðŸªœ Batch step - 562 -- sub batch step 2249 -- lr 8.43e-05
2025-03-02 11:37:01,275 - INFO - ðŸªœ Batch step - 562 -- sub batch step 2250 -- lr 8.43e-05
2025-03-02 11:37:03,444 - INFO - ðŸªœ Batch step - 562 -- sub batch step 2251 -- lr 8.43e-05
2025-03-02 11:37:04,995 - INFO - Step 562 -- ðŸ”„ Training Metrics
2025-03-02 11:37:04,995 - INFO - â”œâ”€â”€ Loss: 10.3338
2025-03-02 11:37:04,995 - INFO - â”œâ”€â”€ Learning Rate: 8.43e-05
2025-03-02 11:37:04,995 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:37:05,669 - INFO - ðŸªœ Batch step - 563 -- sub batch step 2252 -- lr 8.44e-05
2025-03-02 11:37:07,819 - INFO - ðŸªœ Batch step - 563 -- sub batch step 2253 -- lr 8.44e-05
2025-03-02 11:37:09,971 - INFO - ðŸªœ Batch step - 563 -- sub batch step 2254 -- lr 8.44e-05
2025-03-02 11:37:12,663 - INFO - ðŸªœ Batch step - 563 -- sub batch step 2255 -- lr 8.44e-05
2025-03-02 11:37:14,254 - INFO - Step 563 -- ðŸ”„ Training Metrics
2025-03-02 11:37:14,254 - INFO - â”œâ”€â”€ Loss: 10.3227
2025-03-02 11:37:14,254 - INFO - â”œâ”€â”€ Learning Rate: 8.44e-05
2025-03-02 11:37:14,254 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:37:14,923 - INFO - ðŸªœ Batch step - 564 -- sub batch step 2256 -- lr 8.46e-05
2025-03-02 11:37:17,079 - INFO - ðŸªœ Batch step - 564 -- sub batch step 2257 -- lr 8.46e-05
2025-03-02 11:37:19,226 - INFO - ðŸªœ Batch step - 564 -- sub batch step 2258 -- lr 8.46e-05
2025-03-02 11:37:21,395 - INFO - ðŸªœ Batch step - 564 -- sub batch step 2259 -- lr 8.46e-05
2025-03-02 11:37:22,947 - INFO - Step 564 -- ðŸ”„ Training Metrics
2025-03-02 11:37:22,948 - INFO - â”œâ”€â”€ Loss: 10.3266
2025-03-02 11:37:22,948 - INFO - â”œâ”€â”€ Learning Rate: 8.46e-05
2025-03-02 11:37:22,948 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:37:23,623 - INFO - ðŸªœ Batch step - 565 -- sub batch step 2260 -- lr 8.47e-05
2025-03-02 11:37:25,770 - INFO - ðŸªœ Batch step - 565 -- sub batch step 2261 -- lr 8.47e-05
2025-03-02 11:37:27,926 - INFO - ðŸªœ Batch step - 565 -- sub batch step 2262 -- lr 8.47e-05
2025-03-02 11:37:30,606 - INFO - ðŸªœ Batch step - 565 -- sub batch step 2263 -- lr 8.47e-05
2025-03-02 11:37:32,242 - INFO - Step 565 -- ðŸ”„ Training Metrics
2025-03-02 11:37:32,242 - INFO - â”œâ”€â”€ Loss: 10.3251
2025-03-02 11:37:32,242 - INFO - â”œâ”€â”€ Learning Rate: 8.47e-05
2025-03-02 11:37:32,242 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:37:32,918 - INFO - ðŸªœ Batch step - 566 -- sub batch step 2264 -- lr 8.49e-05
2025-03-02 11:37:35,075 - INFO - ðŸªœ Batch step - 566 -- sub batch step 2265 -- lr 8.49e-05
2025-03-02 11:37:37,230 - INFO - ðŸªœ Batch step - 566 -- sub batch step 2266 -- lr 8.49e-05
2025-03-02 11:37:39,407 - INFO - ðŸªœ Batch step - 566 -- sub batch step 2267 -- lr 8.49e-05
2025-03-02 11:37:40,935 - INFO - Step 566 -- ðŸ”„ Training Metrics
2025-03-02 11:37:40,936 - INFO - â”œâ”€â”€ Loss: 10.3260
2025-03-02 11:37:40,936 - INFO - â”œâ”€â”€ Learning Rate: 8.49e-05
2025-03-02 11:37:40,936 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:37:41,605 - INFO - ðŸªœ Batch step - 567 -- sub batch step 2268 -- lr 8.50e-05
2025-03-02 11:37:43,768 - INFO - ðŸªœ Batch step - 567 -- sub batch step 2269 -- lr 8.50e-05
2025-03-02 11:37:45,927 - INFO - ðŸªœ Batch step - 567 -- sub batch step 2270 -- lr 8.50e-05
2025-03-02 11:37:48,553 - INFO - ðŸªœ Batch step - 567 -- sub batch step 2271 -- lr 8.50e-05
2025-03-02 11:37:50,262 - INFO - Step 567 -- ðŸ”„ Training Metrics
2025-03-02 11:37:50,263 - INFO - â”œâ”€â”€ Loss: 10.3098
2025-03-02 11:37:50,263 - INFO - â”œâ”€â”€ Learning Rate: 8.50e-05
2025-03-02 11:37:50,263 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:37:50,943 - INFO - ðŸªœ Batch step - 568 -- sub batch step 2272 -- lr 8.52e-05
2025-03-02 11:37:53,096 - INFO - ðŸªœ Batch step - 568 -- sub batch step 2273 -- lr 8.52e-05
2025-03-02 11:37:55,250 - INFO - ðŸªœ Batch step - 568 -- sub batch step 2274 -- lr 8.52e-05
2025-03-02 11:37:57,428 - INFO - ðŸªœ Batch step - 568 -- sub batch step 2275 -- lr 8.52e-05
2025-03-02 11:37:58,965 - INFO - Step 568 -- ðŸ”„ Training Metrics
2025-03-02 11:37:58,965 - INFO - â”œâ”€â”€ Loss: 10.3206
2025-03-02 11:37:58,965 - INFO - â”œâ”€â”€ Learning Rate: 8.52e-05
2025-03-02 11:37:58,965 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:37:59,640 - INFO - ðŸªœ Batch step - 569 -- sub batch step 2276 -- lr 8.53e-05
2025-03-02 11:38:01,802 - INFO - ðŸªœ Batch step - 569 -- sub batch step 2277 -- lr 8.53e-05
2025-03-02 11:38:03,958 - INFO - ðŸªœ Batch step - 569 -- sub batch step 2278 -- lr 8.53e-05
2025-03-02 11:38:06,567 - INFO - ðŸªœ Batch step - 569 -- sub batch step 2279 -- lr 8.53e-05
2025-03-02 11:38:08,311 - INFO - Step 569 -- ðŸ”„ Training Metrics
2025-03-02 11:38:08,311 - INFO - â”œâ”€â”€ Loss: 10.3097
2025-03-02 11:38:08,311 - INFO - â”œâ”€â”€ Learning Rate: 8.53e-05
2025-03-02 11:38:08,311 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:38:08,996 - INFO - ðŸªœ Batch step - 570 -- sub batch step 2280 -- lr 8.55e-05
2025-03-02 11:38:11,155 - INFO - ðŸªœ Batch step - 570 -- sub batch step 2281 -- lr 8.55e-05
2025-03-02 11:38:13,317 - INFO - ðŸªœ Batch step - 570 -- sub batch step 2282 -- lr 8.55e-05
2025-03-02 11:38:15,483 - INFO - ðŸªœ Batch step - 570 -- sub batch step 2283 -- lr 8.55e-05
2025-03-02 11:38:16,996 - INFO - Step 570 -- ðŸ”„ Training Metrics
2025-03-02 11:38:16,996 - INFO - â”œâ”€â”€ Loss: 10.3061
2025-03-02 11:38:16,996 - INFO - â”œâ”€â”€ Learning Rate: 8.55e-05
2025-03-02 11:38:16,996 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:38:17,678 - INFO - ðŸªœ Batch step - 571 -- sub batch step 2284 -- lr 8.56e-05
2025-03-02 11:38:19,839 - INFO - ðŸªœ Batch step - 571 -- sub batch step 2285 -- lr 8.56e-05
2025-03-02 11:38:22,529 - INFO - ðŸªœ Batch step - 571 -- sub batch step 2286 -- lr 8.56e-05
2025-03-02 11:38:24,689 - INFO - ðŸªœ Batch step - 571 -- sub batch step 2287 -- lr 8.56e-05
2025-03-02 11:38:26,178 - INFO - Step 571 -- ðŸ”„ Training Metrics
2025-03-02 11:38:26,179 - INFO - â”œâ”€â”€ Loss: 10.3050
2025-03-02 11:38:26,179 - INFO - â”œâ”€â”€ Learning Rate: 8.56e-05
2025-03-02 11:38:26,179 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:38:26,849 - INFO - ðŸªœ Batch step - 572 -- sub batch step 2288 -- lr 8.58e-05
2025-03-02 11:38:29,004 - INFO - ðŸªœ Batch step - 572 -- sub batch step 2289 -- lr 8.58e-05
2025-03-02 11:38:31,185 - INFO - ðŸªœ Batch step - 572 -- sub batch step 2290 -- lr 8.58e-05
2025-03-02 11:38:33,332 - INFO - ðŸªœ Batch step - 572 -- sub batch step 2291 -- lr 8.58e-05
2025-03-02 11:38:34,860 - INFO - Step 572 -- ðŸ”„ Training Metrics
2025-03-02 11:38:34,860 - INFO - â”œâ”€â”€ Loss: 10.2928
2025-03-02 11:38:34,860 - INFO - â”œâ”€â”€ Learning Rate: 8.58e-05
2025-03-02 11:38:34,861 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:38:35,534 - INFO - ðŸªœ Batch step - 573 -- sub batch step 2292 -- lr 8.59e-05
2025-03-02 11:38:37,689 - INFO - ðŸªœ Batch step - 573 -- sub batch step 2293 -- lr 8.59e-05
2025-03-02 11:38:40,048 - INFO - ðŸªœ Batch step - 573 -- sub batch step 2294 -- lr 8.59e-05
2025-03-02 11:38:42,203 - INFO - ðŸªœ Batch step - 573 -- sub batch step 2295 -- lr 8.59e-05
2025-03-02 11:38:44,194 - INFO - Step 573 -- ðŸ”„ Training Metrics
2025-03-02 11:38:44,195 - INFO - â”œâ”€â”€ Loss: 10.2943
2025-03-02 11:38:44,195 - INFO - â”œâ”€â”€ Learning Rate: 8.59e-05
2025-03-02 11:38:44,195 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:38:44,868 - INFO - ðŸªœ Batch step - 574 -- sub batch step 2296 -- lr 8.61e-05
2025-03-02 11:38:47,024 - INFO - ðŸªœ Batch step - 574 -- sub batch step 2297 -- lr 8.61e-05
2025-03-02 11:38:49,190 - INFO - ðŸªœ Batch step - 574 -- sub batch step 2298 -- lr 8.61e-05
2025-03-02 11:38:51,340 - INFO - ðŸªœ Batch step - 574 -- sub batch step 2299 -- lr 8.61e-05
2025-03-02 11:38:52,876 - INFO - Step 574 -- ðŸ”„ Training Metrics
2025-03-02 11:38:52,876 - INFO - â”œâ”€â”€ Loss: 10.2910
2025-03-02 11:38:52,876 - INFO - â”œâ”€â”€ Learning Rate: 8.61e-05
2025-03-02 11:38:52,876 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:38:53,550 - INFO - ðŸªœ Batch step - 575 -- sub batch step 2300 -- lr 8.62e-05
2025-03-02 11:38:55,698 - INFO - ðŸªœ Batch step - 575 -- sub batch step 2301 -- lr 8.62e-05
2025-03-02 11:38:58,380 - INFO - ðŸªœ Batch step - 575 -- sub batch step 2302 -- lr 8.62e-05
2025-03-02 11:39:00,528 - INFO - ðŸªœ Batch step - 575 -- sub batch step 2303 -- lr 8.62e-05
2025-03-02 11:39:02,170 - INFO - Step 575 -- ðŸ”„ Training Metrics
2025-03-02 11:39:02,170 - INFO - â”œâ”€â”€ Loss: 10.2891
2025-03-02 11:39:02,170 - INFO - â”œâ”€â”€ Learning Rate: 8.62e-05
2025-03-02 11:39:02,170 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:39:02,845 - INFO - ðŸªœ Batch step - 576 -- sub batch step 2304 -- lr 8.64e-05
2025-03-02 11:39:04,998 - INFO - ðŸªœ Batch step - 576 -- sub batch step 2305 -- lr 8.64e-05
2025-03-02 11:39:07,168 - INFO - ðŸªœ Batch step - 576 -- sub batch step 2306 -- lr 8.64e-05
2025-03-02 11:39:09,316 - INFO - ðŸªœ Batch step - 576 -- sub batch step 2307 -- lr 8.64e-05
2025-03-02 11:39:10,857 - INFO - Step 576 -- ðŸ”„ Training Metrics
2025-03-02 11:39:10,858 - INFO - â”œâ”€â”€ Loss: 10.2821
2025-03-02 11:39:10,858 - INFO - â”œâ”€â”€ Learning Rate: 8.64e-05
2025-03-02 11:39:10,858 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:39:11,522 - INFO - ðŸªœ Batch step - 577 -- sub batch step 2308 -- lr 8.65e-05
2025-03-02 11:39:13,677 - INFO - ðŸªœ Batch step - 577 -- sub batch step 2309 -- lr 8.65e-05
2025-03-02 11:39:16,053 - INFO - ðŸªœ Batch step - 577 -- sub batch step 2310 -- lr 8.65e-05
2025-03-02 11:39:18,206 - INFO - ðŸªœ Batch step - 577 -- sub batch step 2311 -- lr 8.65e-05
2025-03-02 11:39:20,036 - INFO - Step 577 -- ðŸ”„ Training Metrics
2025-03-02 11:39:20,037 - INFO - â”œâ”€â”€ Loss: 10.2810
2025-03-02 11:39:20,037 - INFO - â”œâ”€â”€ Learning Rate: 8.65e-05
2025-03-02 11:39:20,037 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:39:20,713 - INFO - ðŸªœ Batch step - 578 -- sub batch step 2312 -- lr 8.67e-05
2025-03-02 11:39:22,860 - INFO - ðŸªœ Batch step - 578 -- sub batch step 2313 -- lr 8.67e-05
2025-03-02 11:39:25,030 - INFO - ðŸªœ Batch step - 578 -- sub batch step 2314 -- lr 8.67e-05
2025-03-02 11:39:27,185 - INFO - ðŸªœ Batch step - 578 -- sub batch step 2315 -- lr 8.67e-05
2025-03-02 11:39:28,726 - INFO - Step 578 -- ðŸ”„ Training Metrics
2025-03-02 11:39:28,727 - INFO - â”œâ”€â”€ Loss: 10.2805
2025-03-02 11:39:28,727 - INFO - â”œâ”€â”€ Learning Rate: 8.67e-05
2025-03-02 11:39:28,727 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:39:29,395 - INFO - ðŸªœ Batch step - 579 -- sub batch step 2316 -- lr 8.68e-05
2025-03-02 11:39:31,545 - INFO - ðŸªœ Batch step - 579 -- sub batch step 2317 -- lr 8.68e-05
2025-03-02 11:39:33,816 - INFO - ðŸªœ Batch step - 579 -- sub batch step 2318 -- lr 8.68e-05
2025-03-02 11:39:35,967 - INFO - ðŸªœ Batch step - 579 -- sub batch step 2319 -- lr 8.68e-05
2025-03-02 11:39:37,623 - INFO - Step 579 -- ðŸ”„ Training Metrics
2025-03-02 11:39:37,623 - INFO - â”œâ”€â”€ Loss: 10.2757
2025-03-02 11:39:37,623 - INFO - â”œâ”€â”€ Learning Rate: 8.68e-05
2025-03-02 11:39:37,623 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:39:38,741 - INFO - ðŸªœ Batch step - 580 -- sub batch step 2320 -- lr 8.70e-05
2025-03-02 11:39:40,907 - INFO - ðŸªœ Batch step - 580 -- sub batch step 2321 -- lr 8.70e-05
2025-03-02 11:39:43,072 - INFO - ðŸªœ Batch step - 580 -- sub batch step 2322 -- lr 8.70e-05
2025-03-02 11:39:45,250 - INFO - ðŸªœ Batch step - 580 -- sub batch step 2323 -- lr 8.70e-05
2025-03-02 11:39:46,894 - INFO - Step 580 -- ðŸ”„ Training Metrics
2025-03-02 11:39:46,894 - INFO - â”œâ”€â”€ Loss: 10.2670
2025-03-02 11:39:46,894 - INFO - â”œâ”€â”€ Learning Rate: 8.70e-05
2025-03-02 11:39:46,895 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:39:47,568 - INFO - ðŸªœ Batch step - 581 -- sub batch step 2324 -- lr 8.71e-05
2025-03-02 11:39:49,724 - INFO - ðŸªœ Batch step - 581 -- sub batch step 2325 -- lr 8.71e-05
2025-03-02 11:39:51,873 - INFO - ðŸªœ Batch step - 581 -- sub batch step 2326 -- lr 8.71e-05
2025-03-02 11:39:54,328 - INFO - ðŸªœ Batch step - 581 -- sub batch step 2327 -- lr 8.71e-05
2025-03-02 11:39:56,189 - INFO - Step 581 -- ðŸ”„ Training Metrics
2025-03-02 11:39:56,189 - INFO - â”œâ”€â”€ Loss: 10.2627
2025-03-02 11:39:56,189 - INFO - â”œâ”€â”€ Learning Rate: 8.71e-05
2025-03-02 11:39:56,189 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:39:56,859 - INFO - ðŸªœ Batch step - 582 -- sub batch step 2328 -- lr 8.73e-05
2025-03-02 11:39:59,020 - INFO - ðŸªœ Batch step - 582 -- sub batch step 2329 -- lr 8.73e-05
2025-03-02 11:40:01,178 - INFO - ðŸªœ Batch step - 582 -- sub batch step 2330 -- lr 8.73e-05
2025-03-02 11:40:03,348 - INFO - ðŸªœ Batch step - 582 -- sub batch step 2331 -- lr 8.73e-05
2025-03-02 11:40:04,875 - INFO - Step 582 -- ðŸ”„ Training Metrics
2025-03-02 11:40:04,876 - INFO - â”œâ”€â”€ Loss: 10.2585
2025-03-02 11:40:04,876 - INFO - â”œâ”€â”€ Learning Rate: 8.73e-05
2025-03-02 11:40:04,876 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:40:05,549 - INFO - ðŸªœ Batch step - 583 -- sub batch step 2332 -- lr 8.74e-05
2025-03-02 11:40:07,696 - INFO - ðŸªœ Batch step - 583 -- sub batch step 2333 -- lr 8.74e-05
2025-03-02 11:40:09,850 - INFO - ðŸªœ Batch step - 583 -- sub batch step 2334 -- lr 8.74e-05
2025-03-02 11:40:12,292 - INFO - ðŸªœ Batch step - 583 -- sub batch step 2335 -- lr 8.74e-05
2025-03-02 11:40:14,070 - INFO - Step 583 -- ðŸ”„ Training Metrics
2025-03-02 11:40:14,071 - INFO - â”œâ”€â”€ Loss: 10.2600
2025-03-02 11:40:14,071 - INFO - â”œâ”€â”€ Learning Rate: 8.74e-05
2025-03-02 11:40:14,071 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:40:14,735 - INFO - ðŸªœ Batch step - 584 -- sub batch step 2336 -- lr 8.76e-05
2025-03-02 11:40:16,892 - INFO - ðŸªœ Batch step - 584 -- sub batch step 2337 -- lr 8.76e-05
2025-03-02 11:40:19,042 - INFO - ðŸªœ Batch step - 584 -- sub batch step 2338 -- lr 8.76e-05
2025-03-02 11:40:21,218 - INFO - ðŸªœ Batch step - 584 -- sub batch step 2339 -- lr 8.76e-05
2025-03-02 11:40:22,749 - INFO - Step 584 -- ðŸ”„ Training Metrics
2025-03-02 11:40:22,749 - INFO - â”œâ”€â”€ Loss: 10.2486
2025-03-02 11:40:22,749 - INFO - â”œâ”€â”€ Learning Rate: 8.76e-05
2025-03-02 11:40:22,749 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:40:23,419 - INFO - ðŸªœ Batch step - 585 -- sub batch step 2340 -- lr 8.77e-05
2025-03-02 11:40:25,563 - INFO - ðŸªœ Batch step - 585 -- sub batch step 2341 -- lr 8.77e-05
2025-03-02 11:40:27,713 - INFO - ðŸªœ Batch step - 585 -- sub batch step 2342 -- lr 8.77e-05
2025-03-02 11:40:30,239 - INFO - ðŸªœ Batch step - 585 -- sub batch step 2343 -- lr 8.77e-05
2025-03-02 11:40:31,997 - INFO - Step 585 -- ðŸ”„ Training Metrics
2025-03-02 11:40:31,998 - INFO - â”œâ”€â”€ Loss: 10.2488
2025-03-02 11:40:31,998 - INFO - â”œâ”€â”€ Learning Rate: 8.77e-05
2025-03-02 11:40:31,998 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:40:32,668 - INFO - ðŸªœ Batch step - 586 -- sub batch step 2344 -- lr 8.79e-05
2025-03-02 11:40:34,819 - INFO - ðŸªœ Batch step - 586 -- sub batch step 2345 -- lr 8.79e-05
2025-03-02 11:40:36,964 - INFO - ðŸªœ Batch step - 586 -- sub batch step 2346 -- lr 8.79e-05
2025-03-02 11:40:39,134 - INFO - ðŸªœ Batch step - 586 -- sub batch step 2347 -- lr 8.79e-05
2025-03-02 11:40:40,690 - INFO - Step 586 -- ðŸ”„ Training Metrics
2025-03-02 11:40:40,690 - INFO - â”œâ”€â”€ Loss: 10.2463
2025-03-02 11:40:40,690 - INFO - â”œâ”€â”€ Learning Rate: 8.79e-05
2025-03-02 11:40:40,690 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:40:41,353 - INFO - ðŸªœ Batch step - 587 -- sub batch step 2348 -- lr 8.80e-05
2025-03-02 11:40:43,506 - INFO - ðŸªœ Batch step - 587 -- sub batch step 2349 -- lr 8.80e-05
2025-03-02 11:40:45,655 - INFO - ðŸªœ Batch step - 587 -- sub batch step 2350 -- lr 8.80e-05
2025-03-02 11:40:48,288 - INFO - ðŸªœ Batch step - 587 -- sub batch step 2351 -- lr 8.80e-05
2025-03-02 11:40:49,941 - INFO - Step 587 -- ðŸ”„ Training Metrics
2025-03-02 11:40:49,942 - INFO - â”œâ”€â”€ Loss: 10.2400
2025-03-02 11:40:49,942 - INFO - â”œâ”€â”€ Learning Rate: 8.80e-05
2025-03-02 11:40:49,942 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:40:50,616 - INFO - ðŸªœ Batch step - 588 -- sub batch step 2352 -- lr 8.82e-05
2025-03-02 11:40:52,765 - INFO - ðŸªœ Batch step - 588 -- sub batch step 2353 -- lr 8.82e-05
2025-03-02 11:40:54,919 - INFO - ðŸªœ Batch step - 588 -- sub batch step 2354 -- lr 8.82e-05
2025-03-02 11:40:57,090 - INFO - ðŸªœ Batch step - 588 -- sub batch step 2355 -- lr 8.82e-05
2025-03-02 11:40:58,629 - INFO - Step 588 -- ðŸ”„ Training Metrics
2025-03-02 11:40:58,629 - INFO - â”œâ”€â”€ Loss: 10.2319
2025-03-02 11:40:58,629 - INFO - â”œâ”€â”€ Learning Rate: 8.82e-05
2025-03-02 11:40:58,630 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:40:59,299 - INFO - ðŸªœ Batch step - 589 -- sub batch step 2356 -- lr 8.83e-05
2025-03-02 11:41:01,453 - INFO - ðŸªœ Batch step - 589 -- sub batch step 2357 -- lr 8.83e-05
2025-03-02 11:41:03,598 - INFO - ðŸªœ Batch step - 589 -- sub batch step 2358 -- lr 8.83e-05
2025-03-02 11:41:06,209 - INFO - ðŸªœ Batch step - 589 -- sub batch step 2359 -- lr 8.83e-05
2025-03-02 11:41:07,879 - INFO - Step 589 -- ðŸ”„ Training Metrics
2025-03-02 11:41:07,879 - INFO - â”œâ”€â”€ Loss: 10.2399
2025-03-02 11:41:07,879 - INFO - â”œâ”€â”€ Learning Rate: 8.83e-05
2025-03-02 11:41:07,879 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:41:08,552 - INFO - ðŸªœ Batch step - 590 -- sub batch step 2360 -- lr 8.85e-05
2025-03-02 11:41:10,698 - INFO - ðŸªœ Batch step - 590 -- sub batch step 2361 -- lr 8.85e-05
2025-03-02 11:41:12,849 - INFO - ðŸªœ Batch step - 590 -- sub batch step 2362 -- lr 8.85e-05
2025-03-02 11:41:15,015 - INFO - ðŸªœ Batch step - 590 -- sub batch step 2363 -- lr 8.85e-05
2025-03-02 11:41:16,555 - INFO - Step 590 -- ðŸ”„ Training Metrics
2025-03-02 11:41:16,555 - INFO - â”œâ”€â”€ Loss: 10.2261
2025-03-02 11:41:16,555 - INFO - â”œâ”€â”€ Learning Rate: 8.85e-05
2025-03-02 11:41:16,555 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:41:17,227 - INFO - ðŸªœ Batch step - 591 -- sub batch step 2364 -- lr 8.86e-05
2025-03-02 11:41:19,380 - INFO - ðŸªœ Batch step - 591 -- sub batch step 2365 -- lr 8.86e-05
2025-03-02 11:41:22,069 - INFO - ðŸªœ Batch step - 591 -- sub batch step 2366 -- lr 8.86e-05
2025-03-02 11:41:24,223 - INFO - ðŸªœ Batch step - 591 -- sub batch step 2367 -- lr 8.86e-05
2025-03-02 11:41:25,739 - INFO - Step 591 -- ðŸ”„ Training Metrics
2025-03-02 11:41:25,739 - INFO - â”œâ”€â”€ Loss: 10.2323
2025-03-02 11:41:25,739 - INFO - â”œâ”€â”€ Learning Rate: 8.86e-05
2025-03-02 11:41:25,739 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:41:26,406 - INFO - ðŸªœ Batch step - 592 -- sub batch step 2368 -- lr 8.88e-05
2025-03-02 11:41:28,554 - INFO - ðŸªœ Batch step - 592 -- sub batch step 2369 -- lr 8.88e-05
2025-03-02 11:41:30,726 - INFO - ðŸªœ Batch step - 592 -- sub batch step 2370 -- lr 8.88e-05
2025-03-02 11:41:32,868 - INFO - ðŸªœ Batch step - 592 -- sub batch step 2371 -- lr 8.88e-05
2025-03-02 11:41:34,419 - INFO - Step 592 -- ðŸ”„ Training Metrics
2025-03-02 11:41:34,420 - INFO - â”œâ”€â”€ Loss: 10.2299
2025-03-02 11:41:34,420 - INFO - â”œâ”€â”€ Learning Rate: 8.88e-05
2025-03-02 11:41:34,420 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:41:35,092 - INFO - ðŸªœ Batch step - 593 -- sub batch step 2372 -- lr 8.89e-05
2025-03-02 11:41:37,235 - INFO - ðŸªœ Batch step - 593 -- sub batch step 2373 -- lr 8.89e-05
2025-03-02 11:41:39,864 - INFO - ðŸªœ Batch step - 593 -- sub batch step 2374 -- lr 8.89e-05
2025-03-02 11:41:42,025 - INFO - ðŸªœ Batch step - 593 -- sub batch step 2375 -- lr 8.89e-05
2025-03-02 11:41:43,918 - INFO - Step 593 -- ðŸ”„ Training Metrics
2025-03-02 11:41:43,918 - INFO - â”œâ”€â”€ Loss: 10.2171
2025-03-02 11:41:43,918 - INFO - â”œâ”€â”€ Learning Rate: 8.89e-05
2025-03-02 11:41:43,918 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:41:44,585 - INFO - ðŸªœ Batch step - 594 -- sub batch step 2376 -- lr 8.91e-05
2025-03-02 11:41:46,738 - INFO - ðŸªœ Batch step - 594 -- sub batch step 2377 -- lr 8.91e-05
2025-03-02 11:41:48,901 - INFO - ðŸªœ Batch step - 594 -- sub batch step 2378 -- lr 8.91e-05
2025-03-02 11:41:51,054 - INFO - ðŸªœ Batch step - 594 -- sub batch step 2379 -- lr 8.91e-05
2025-03-02 11:41:52,615 - INFO - Step 594 -- ðŸ”„ Training Metrics
2025-03-02 11:41:52,615 - INFO - â”œâ”€â”€ Loss: 10.2136
2025-03-02 11:41:52,616 - INFO - â”œâ”€â”€ Learning Rate: 8.91e-05
2025-03-02 11:41:52,616 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:41:53,293 - INFO - ðŸªœ Batch step - 595 -- sub batch step 2380 -- lr 8.92e-05
2025-03-02 11:41:55,446 - INFO - ðŸªœ Batch step - 595 -- sub batch step 2381 -- lr 8.92e-05
2025-03-02 11:41:57,957 - INFO - ðŸªœ Batch step - 595 -- sub batch step 2382 -- lr 8.92e-05
2025-03-02 11:42:00,103 - INFO - ðŸªœ Batch step - 595 -- sub batch step 2383 -- lr 8.92e-05
2025-03-02 11:42:01,909 - INFO - Step 595 -- ðŸ”„ Training Metrics
2025-03-02 11:42:01,909 - INFO - â”œâ”€â”€ Loss: 10.2228
2025-03-02 11:42:01,909 - INFO - â”œâ”€â”€ Learning Rate: 8.92e-05
2025-03-02 11:42:01,909 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:42:02,588 - INFO - ðŸªœ Batch step - 596 -- sub batch step 2384 -- lr 8.94e-05
2025-03-02 11:42:04,743 - INFO - ðŸªœ Batch step - 596 -- sub batch step 2385 -- lr 8.94e-05
2025-03-02 11:42:06,909 - INFO - ðŸªœ Batch step - 596 -- sub batch step 2386 -- lr 8.94e-05
2025-03-02 11:42:09,067 - INFO - ðŸªœ Batch step - 596 -- sub batch step 2387 -- lr 8.94e-05
2025-03-02 11:42:10,596 - INFO - Step 596 -- ðŸ”„ Training Metrics
2025-03-02 11:42:10,596 - INFO - â”œâ”€â”€ Loss: 10.2017
2025-03-02 11:42:10,596 - INFO - â”œâ”€â”€ Learning Rate: 8.94e-05
2025-03-02 11:42:10,596 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:42:11,265 - INFO - ðŸªœ Batch step - 597 -- sub batch step 2388 -- lr 8.95e-05
2025-03-02 11:42:13,423 - INFO - ðŸªœ Batch step - 597 -- sub batch step 2389 -- lr 8.95e-05
2025-03-02 11:42:16,196 - INFO - ðŸªœ Batch step - 597 -- sub batch step 2390 -- lr 8.95e-05
2025-03-02 11:42:18,353 - INFO - ðŸªœ Batch step - 597 -- sub batch step 2391 -- lr 8.95e-05
2025-03-02 11:42:19,844 - INFO - Step 597 -- ðŸ”„ Training Metrics
2025-03-02 11:42:19,844 - INFO - â”œâ”€â”€ Loss: 10.2030
2025-03-02 11:42:19,844 - INFO - â”œâ”€â”€ Learning Rate: 8.95e-05
2025-03-02 11:42:19,844 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:42:20,526 - INFO - ðŸªœ Batch step - 598 -- sub batch step 2392 -- lr 8.97e-05
2025-03-02 11:42:22,675 - INFO - ðŸªœ Batch step - 598 -- sub batch step 2393 -- lr 8.97e-05
2025-03-02 11:42:24,855 - INFO - ðŸªœ Batch step - 598 -- sub batch step 2394 -- lr 8.97e-05
2025-03-02 11:42:27,012 - INFO - ðŸªœ Batch step - 598 -- sub batch step 2395 -- lr 8.97e-05
2025-03-02 11:42:28,541 - INFO - Step 598 -- ðŸ”„ Training Metrics
2025-03-02 11:42:28,541 - INFO - â”œâ”€â”€ Loss: 10.1917
2025-03-02 11:42:28,541 - INFO - â”œâ”€â”€ Learning Rate: 8.97e-05
2025-03-02 11:42:28,542 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:42:29,214 - INFO - ðŸªœ Batch step - 599 -- sub batch step 2396 -- lr 8.98e-05
2025-03-02 11:42:31,375 - INFO - ðŸªœ Batch step - 599 -- sub batch step 2397 -- lr 8.98e-05
2025-03-02 11:42:33,796 - INFO - ðŸªœ Batch step - 599 -- sub batch step 2398 -- lr 8.98e-05
2025-03-02 11:42:35,959 - INFO - ðŸªœ Batch step - 599 -- sub batch step 2399 -- lr 8.98e-05
2025-03-02 11:42:37,475 - INFO - Step 599 -- ðŸ”„ Training Metrics
2025-03-02 11:42:37,475 - INFO - â”œâ”€â”€ Loss: 10.1996
2025-03-02 11:42:37,475 - INFO - â”œâ”€â”€ Learning Rate: 8.98e-05
2025-03-02 11:42:37,476 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:42:38,617 - INFO - ðŸªœ Batch step - 600 -- sub batch step 2400 -- lr 9.00e-05
2025-03-02 11:42:40,781 - INFO - ðŸªœ Batch step - 600 -- sub batch step 2401 -- lr 9.00e-05
2025-03-02 11:42:42,941 - INFO - ðŸªœ Batch step - 600 -- sub batch step 2402 -- lr 9.00e-05
2025-03-02 11:42:45,116 - INFO - ðŸªœ Batch step - 600 -- sub batch step 2403 -- lr 9.00e-05
2025-03-02 11:42:46,853 - INFO - Step 600 -- ðŸ”„ Training Metrics
2025-03-02 11:42:46,854 - INFO - â”œâ”€â”€ Loss: 10.1848
2025-03-02 11:42:46,854 - INFO - â”œâ”€â”€ Learning Rate: 9.00e-05
2025-03-02 11:42:46,854 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:42:47,534 - INFO - ðŸªœ Batch step - 601 -- sub batch step 2404 -- lr 9.01e-05
2025-03-02 11:42:49,693 - INFO - ðŸªœ Batch step - 601 -- sub batch step 2405 -- lr 9.01e-05
2025-03-02 11:42:51,844 - INFO - ðŸªœ Batch step - 601 -- sub batch step 2406 -- lr 9.01e-05
2025-03-02 11:42:54,342 - INFO - ðŸªœ Batch step - 601 -- sub batch step 2407 -- lr 9.01e-05
2025-03-02 11:42:56,081 - INFO - Step 601 -- ðŸ”„ Training Metrics
2025-03-02 11:42:56,081 - INFO - â”œâ”€â”€ Loss: 10.1820
2025-03-02 11:42:56,082 - INFO - â”œâ”€â”€ Learning Rate: 9.01e-05
2025-03-02 11:42:56,082 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:42:56,757 - INFO - ðŸªœ Batch step - 602 -- sub batch step 2408 -- lr 9.03e-05
2025-03-02 11:42:58,921 - INFO - ðŸªœ Batch step - 602 -- sub batch step 2409 -- lr 9.03e-05
2025-03-02 11:43:01,084 - INFO - ðŸªœ Batch step - 602 -- sub batch step 2410 -- lr 9.03e-05
2025-03-02 11:43:03,266 - INFO - ðŸªœ Batch step - 602 -- sub batch step 2411 -- lr 9.03e-05
2025-03-02 11:43:04,777 - INFO - Step 602 -- ðŸ”„ Training Metrics
2025-03-02 11:43:04,777 - INFO - â”œâ”€â”€ Loss: 10.1836
2025-03-02 11:43:04,778 - INFO - â”œâ”€â”€ Learning Rate: 9.03e-05
2025-03-02 11:43:04,778 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:43:05,456 - INFO - ðŸªœ Batch step - 603 -- sub batch step 2412 -- lr 9.04e-05
2025-03-02 11:43:07,611 - INFO - ðŸªœ Batch step - 603 -- sub batch step 2413 -- lr 9.04e-05
2025-03-02 11:43:09,770 - INFO - ðŸªœ Batch step - 603 -- sub batch step 2414 -- lr 9.04e-05
2025-03-02 11:43:12,419 - INFO - ðŸªœ Batch step - 603 -- sub batch step 2415 -- lr 9.04e-05
2025-03-02 11:43:13,991 - INFO - Step 603 -- ðŸ”„ Training Metrics
2025-03-02 11:43:13,991 - INFO - â”œâ”€â”€ Loss: 10.1698
2025-03-02 11:43:13,991 - INFO - â”œâ”€â”€ Learning Rate: 9.04e-05
2025-03-02 11:43:13,992 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:43:14,662 - INFO - ðŸªœ Batch step - 604 -- sub batch step 2416 -- lr 9.06e-05
2025-03-02 11:43:16,821 - INFO - ðŸªœ Batch step - 604 -- sub batch step 2417 -- lr 9.06e-05
2025-03-02 11:43:18,975 - INFO - ðŸªœ Batch step - 604 -- sub batch step 2418 -- lr 9.06e-05
2025-03-02 11:43:21,154 - INFO - ðŸªœ Batch step - 604 -- sub batch step 2419 -- lr 9.06e-05
2025-03-02 11:43:22,675 - INFO - Step 604 -- ðŸ”„ Training Metrics
2025-03-02 11:43:22,675 - INFO - â”œâ”€â”€ Loss: 10.1783
2025-03-02 11:43:22,675 - INFO - â”œâ”€â”€ Learning Rate: 9.06e-05
2025-03-02 11:43:22,675 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:43:23,352 - INFO - ðŸªœ Batch step - 605 -- sub batch step 2420 -- lr 9.07e-05
2025-03-02 11:43:25,503 - INFO - ðŸªœ Batch step - 605 -- sub batch step 2421 -- lr 9.07e-05
2025-03-02 11:43:27,657 - INFO - ðŸªœ Batch step - 605 -- sub batch step 2422 -- lr 9.07e-05
2025-03-02 11:43:30,461 - INFO - ðŸªœ Batch step - 605 -- sub batch step 2423 -- lr 9.07e-05
2025-03-02 11:43:31,953 - INFO - Step 605 -- ðŸ”„ Training Metrics
2025-03-02 11:43:31,954 - INFO - â”œâ”€â”€ Loss: 10.1662
2025-03-02 11:43:31,954 - INFO - â”œâ”€â”€ Learning Rate: 9.07e-05
2025-03-02 11:43:31,954 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:43:32,632 - INFO - ðŸªœ Batch step - 606 -- sub batch step 2424 -- lr 9.09e-05
2025-03-02 11:43:34,791 - INFO - ðŸªœ Batch step - 606 -- sub batch step 2425 -- lr 9.09e-05
2025-03-02 11:43:36,947 - INFO - ðŸªœ Batch step - 606 -- sub batch step 2426 -- lr 9.09e-05
2025-03-02 11:43:39,125 - INFO - ðŸªœ Batch step - 606 -- sub batch step 2427 -- lr 9.09e-05
2025-03-02 11:43:40,635 - INFO - Step 606 -- ðŸ”„ Training Metrics
2025-03-02 11:43:40,636 - INFO - â”œâ”€â”€ Loss: 10.1598
2025-03-02 11:43:40,636 - INFO - â”œâ”€â”€ Learning Rate: 9.09e-05
2025-03-02 11:43:40,636 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:43:41,313 - INFO - ðŸªœ Batch step - 607 -- sub batch step 2428 -- lr 9.10e-05
2025-03-02 11:43:43,471 - INFO - ðŸªœ Batch step - 607 -- sub batch step 2429 -- lr 9.10e-05
2025-03-02 11:43:45,629 - INFO - ðŸªœ Batch step - 607 -- sub batch step 2430 -- lr 9.10e-05
2025-03-02 11:43:48,277 - INFO - ðŸªœ Batch step - 607 -- sub batch step 2431 -- lr 9.10e-05
2025-03-02 11:43:49,885 - INFO - Step 607 -- ðŸ”„ Training Metrics
2025-03-02 11:43:49,886 - INFO - â”œâ”€â”€ Loss: 10.1646
2025-03-02 11:43:49,886 - INFO - â”œâ”€â”€ Learning Rate: 9.10e-05
2025-03-02 11:43:49,886 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:43:50,563 - INFO - ðŸªœ Batch step - 608 -- sub batch step 2432 -- lr 9.12e-05
2025-03-02 11:43:52,714 - INFO - ðŸªœ Batch step - 608 -- sub batch step 2433 -- lr 9.12e-05
2025-03-02 11:43:54,868 - INFO - ðŸªœ Batch step - 608 -- sub batch step 2434 -- lr 9.12e-05
2025-03-02 11:43:57,041 - INFO - ðŸªœ Batch step - 608 -- sub batch step 2435 -- lr 9.12e-05
2025-03-02 11:43:58,570 - INFO - Step 608 -- ðŸ”„ Training Metrics
2025-03-02 11:43:58,570 - INFO - â”œâ”€â”€ Loss: 10.1547
2025-03-02 11:43:58,570 - INFO - â”œâ”€â”€ Learning Rate: 9.12e-05
2025-03-02 11:43:58,570 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:43:59,240 - INFO - ðŸªœ Batch step - 609 -- sub batch step 2436 -- lr 9.13e-05
2025-03-02 11:44:01,397 - INFO - ðŸªœ Batch step - 609 -- sub batch step 2437 -- lr 9.13e-05
2025-03-02 11:44:03,543 - INFO - ðŸªœ Batch step - 609 -- sub batch step 2438 -- lr 9.13e-05
2025-03-02 11:44:05,919 - INFO - ðŸªœ Batch step - 609 -- sub batch step 2439 -- lr 9.13e-05
2025-03-02 11:44:07,813 - INFO - Step 609 -- ðŸ”„ Training Metrics
2025-03-02 11:44:07,813 - INFO - â”œâ”€â”€ Loss: 10.1473
2025-03-02 11:44:07,813 - INFO - â”œâ”€â”€ Learning Rate: 9.13e-05
2025-03-02 11:44:07,813 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:44:08,487 - INFO - ðŸªœ Batch step - 610 -- sub batch step 2440 -- lr 9.15e-05
2025-03-02 11:44:10,633 - INFO - ðŸªœ Batch step - 610 -- sub batch step 2441 -- lr 9.15e-05
2025-03-02 11:44:12,784 - INFO - ðŸªœ Batch step - 610 -- sub batch step 2442 -- lr 9.15e-05
2025-03-02 11:44:14,947 - INFO - ðŸªœ Batch step - 610 -- sub batch step 2443 -- lr 9.15e-05
2025-03-02 11:44:16,495 - INFO - Step 610 -- ðŸ”„ Training Metrics
2025-03-02 11:44:16,495 - INFO - â”œâ”€â”€ Loss: 10.1450
2025-03-02 11:44:16,495 - INFO - â”œâ”€â”€ Learning Rate: 9.15e-05
2025-03-02 11:44:16,495 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:44:17,173 - INFO - ðŸªœ Batch step - 611 -- sub batch step 2444 -- lr 9.16e-05
2025-03-02 11:44:19,330 - INFO - ðŸªœ Batch step - 611 -- sub batch step 2445 -- lr 9.16e-05
2025-03-02 11:44:21,726 - INFO - ðŸªœ Batch step - 611 -- sub batch step 2446 -- lr 9.16e-05
2025-03-02 11:44:23,880 - INFO - ðŸªœ Batch step - 611 -- sub batch step 2447 -- lr 9.16e-05
2025-03-02 11:44:25,838 - INFO - Step 611 -- ðŸ”„ Training Metrics
2025-03-02 11:44:25,839 - INFO - â”œâ”€â”€ Loss: 10.1426
2025-03-02 11:44:25,839 - INFO - â”œâ”€â”€ Learning Rate: 9.16e-05
2025-03-02 11:44:25,839 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:44:26,509 - INFO - ðŸªœ Batch step - 612 -- sub batch step 2448 -- lr 9.18e-05
2025-03-02 11:44:28,659 - INFO - ðŸªœ Batch step - 612 -- sub batch step 2449 -- lr 9.18e-05
2025-03-02 11:44:30,838 - INFO - ðŸªœ Batch step - 612 -- sub batch step 2450 -- lr 9.18e-05
2025-03-02 11:44:32,988 - INFO - ðŸªœ Batch step - 612 -- sub batch step 2451 -- lr 9.18e-05
2025-03-02 11:44:34,524 - INFO - Step 612 -- ðŸ”„ Training Metrics
2025-03-02 11:44:34,525 - INFO - â”œâ”€â”€ Loss: 10.1385
2025-03-02 11:44:34,525 - INFO - â”œâ”€â”€ Learning Rate: 9.18e-05
2025-03-02 11:44:34,525 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:44:35,200 - INFO - ðŸªœ Batch step - 613 -- sub batch step 2452 -- lr 9.19e-05
2025-03-02 11:44:37,348 - INFO - ðŸªœ Batch step - 613 -- sub batch step 2453 -- lr 9.19e-05
2025-03-02 11:44:40,148 - INFO - ðŸªœ Batch step - 613 -- sub batch step 2454 -- lr 9.19e-05
2025-03-02 11:44:42,317 - INFO - ðŸªœ Batch step - 613 -- sub batch step 2455 -- lr 9.19e-05
2025-03-02 11:44:43,858 - INFO - Step 613 -- ðŸ”„ Training Metrics
2025-03-02 11:44:43,859 - INFO - â”œâ”€â”€ Loss: 10.1299
2025-03-02 11:44:43,859 - INFO - â”œâ”€â”€ Learning Rate: 9.19e-05
2025-03-02 11:44:43,859 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:44:44,533 - INFO - ðŸªœ Batch step - 614 -- sub batch step 2456 -- lr 9.21e-05
2025-03-02 11:44:46,689 - INFO - ðŸªœ Batch step - 614 -- sub batch step 2457 -- lr 9.21e-05
2025-03-02 11:44:48,861 - INFO - ðŸªœ Batch step - 614 -- sub batch step 2458 -- lr 9.21e-05
2025-03-02 11:44:51,013 - INFO - ðŸªœ Batch step - 614 -- sub batch step 2459 -- lr 9.21e-05
2025-03-02 11:44:52,535 - INFO - Step 614 -- ðŸ”„ Training Metrics
2025-03-02 11:44:52,536 - INFO - â”œâ”€â”€ Loss: 10.1303
2025-03-02 11:44:52,536 - INFO - â”œâ”€â”€ Learning Rate: 9.21e-05
2025-03-02 11:44:52,536 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:44:53,210 - INFO - ðŸªœ Batch step - 615 -- sub batch step 2460 -- lr 9.22e-05
2025-03-02 11:44:55,362 - INFO - ðŸªœ Batch step - 615 -- sub batch step 2461 -- lr 9.22e-05
2025-03-02 11:44:58,021 - INFO - ðŸªœ Batch step - 615 -- sub batch step 2462 -- lr 9.22e-05
2025-03-02 11:45:00,181 - INFO - ðŸªœ Batch step - 615 -- sub batch step 2463 -- lr 9.22e-05
2025-03-02 11:45:01,780 - INFO - Step 615 -- ðŸ”„ Training Metrics
2025-03-02 11:45:01,781 - INFO - â”œâ”€â”€ Loss: 10.1302
2025-03-02 11:45:01,781 - INFO - â”œâ”€â”€ Learning Rate: 9.22e-05
2025-03-02 11:45:01,781 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:45:02,458 - INFO - ðŸªœ Batch step - 616 -- sub batch step 2464 -- lr 9.24e-05
2025-03-02 11:45:04,613 - INFO - ðŸªœ Batch step - 616 -- sub batch step 2465 -- lr 9.24e-05
2025-03-02 11:45:06,785 - INFO - ðŸªœ Batch step - 616 -- sub batch step 2466 -- lr 9.24e-05
2025-03-02 11:45:08,943 - INFO - ðŸªœ Batch step - 616 -- sub batch step 2467 -- lr 9.24e-05
2025-03-02 11:45:10,476 - INFO - Step 616 -- ðŸ”„ Training Metrics
2025-03-02 11:45:10,477 - INFO - â”œâ”€â”€ Loss: 10.1204
2025-03-02 11:45:10,477 - INFO - â”œâ”€â”€ Learning Rate: 9.24e-05
2025-03-02 11:45:10,477 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:45:11,146 - INFO - ðŸªœ Batch step - 617 -- sub batch step 2468 -- lr 9.25e-05
2025-03-02 11:45:13,304 - INFO - ðŸªœ Batch step - 617 -- sub batch step 2469 -- lr 9.25e-05
2025-03-02 11:45:15,967 - INFO - ðŸªœ Batch step - 617 -- sub batch step 2470 -- lr 9.25e-05
2025-03-02 11:45:18,114 - INFO - ðŸªœ Batch step - 617 -- sub batch step 2471 -- lr 9.25e-05
2025-03-02 11:45:19,643 - INFO - Step 617 -- ðŸ”„ Training Metrics
2025-03-02 11:45:19,643 - INFO - â”œâ”€â”€ Loss: 10.1211
2025-03-02 11:45:19,643 - INFO - â”œâ”€â”€ Learning Rate: 9.25e-05
2025-03-02 11:45:19,643 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:45:20,314 - INFO - ðŸªœ Batch step - 618 -- sub batch step 2472 -- lr 9.27e-05
2025-03-02 11:45:22,461 - INFO - ðŸªœ Batch step - 618 -- sub batch step 2473 -- lr 9.27e-05
2025-03-02 11:45:24,636 - INFO - ðŸªœ Batch step - 618 -- sub batch step 2474 -- lr 9.27e-05
2025-03-02 11:45:26,792 - INFO - ðŸªœ Batch step - 618 -- sub batch step 2475 -- lr 9.27e-05
2025-03-02 11:45:28,326 - INFO - Step 618 -- ðŸ”„ Training Metrics
2025-03-02 11:45:28,327 - INFO - â”œâ”€â”€ Loss: 10.1135
2025-03-02 11:45:28,327 - INFO - â”œâ”€â”€ Learning Rate: 9.27e-05
2025-03-02 11:45:28,327 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:45:28,993 - INFO - ðŸªœ Batch step - 619 -- sub batch step 2476 -- lr 9.28e-05
2025-03-02 11:45:31,147 - INFO - ðŸªœ Batch step - 619 -- sub batch step 2477 -- lr 9.28e-05
2025-03-02 11:45:33,428 - INFO - ðŸªœ Batch step - 619 -- sub batch step 2478 -- lr 9.28e-05
2025-03-02 11:45:35,580 - INFO - ðŸªœ Batch step - 619 -- sub batch step 2479 -- lr 9.28e-05
2025-03-02 11:45:37,110 - INFO - Step 619 -- ðŸ”„ Training Metrics
2025-03-02 11:45:37,110 - INFO - â”œâ”€â”€ Loss: 10.1118
2025-03-02 11:45:37,110 - INFO - â”œâ”€â”€ Learning Rate: 9.28e-05
2025-03-02 11:45:37,110 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:45:38,288 - INFO - ðŸªœ Batch step - 620 -- sub batch step 2480 -- lr 9.30e-05
2025-03-02 11:45:40,453 - INFO - ðŸªœ Batch step - 620 -- sub batch step 2481 -- lr 9.30e-05
2025-03-02 11:45:42,616 - INFO - ðŸªœ Batch step - 620 -- sub batch step 2482 -- lr 9.30e-05
2025-03-02 11:45:44,794 - INFO - ðŸªœ Batch step - 620 -- sub batch step 2483 -- lr 9.30e-05
2025-03-02 11:45:46,411 - INFO - Step 620 -- ðŸ”„ Training Metrics
2025-03-02 11:45:46,412 - INFO - â”œâ”€â”€ Loss: 10.1016
2025-03-02 11:45:46,412 - INFO - â”œâ”€â”€ Learning Rate: 9.30e-05
2025-03-02 11:45:46,412 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:45:47,087 - INFO - ðŸªœ Batch step - 621 -- sub batch step 2484 -- lr 9.31e-05
2025-03-02 11:45:49,240 - INFO - ðŸªœ Batch step - 621 -- sub batch step 2485 -- lr 9.31e-05
2025-03-02 11:45:51,388 - INFO - ðŸªœ Batch step - 621 -- sub batch step 2486 -- lr 9.31e-05
2025-03-02 11:45:53,860 - INFO - ðŸªœ Batch step - 621 -- sub batch step 2487 -- lr 9.31e-05
2025-03-02 11:45:55,545 - INFO - Step 621 -- ðŸ”„ Training Metrics
2025-03-02 11:45:55,545 - INFO - â”œâ”€â”€ Loss: 10.0995
2025-03-02 11:45:55,545 - INFO - â”œâ”€â”€ Learning Rate: 9.31e-05
2025-03-02 11:45:55,546 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:45:56,216 - INFO - ðŸªœ Batch step - 622 -- sub batch step 2488 -- lr 9.33e-05
2025-03-02 11:45:58,377 - INFO - ðŸªœ Batch step - 622 -- sub batch step 2489 -- lr 9.33e-05
2025-03-02 11:46:00,533 - INFO - ðŸªœ Batch step - 622 -- sub batch step 2490 -- lr 9.33e-05
2025-03-02 11:46:02,703 - INFO - ðŸªœ Batch step - 622 -- sub batch step 2491 -- lr 9.33e-05
2025-03-02 11:46:04,241 - INFO - Step 622 -- ðŸ”„ Training Metrics
2025-03-02 11:46:04,242 - INFO - â”œâ”€â”€ Loss: 10.1022
2025-03-02 11:46:04,242 - INFO - â”œâ”€â”€ Learning Rate: 9.33e-05
2025-03-02 11:46:04,242 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:46:04,917 - INFO - ðŸªœ Batch step - 623 -- sub batch step 2492 -- lr 9.34e-05
2025-03-02 11:46:07,064 - INFO - ðŸªœ Batch step - 623 -- sub batch step 2493 -- lr 9.34e-05
2025-03-02 11:46:09,221 - INFO - ðŸªœ Batch step - 623 -- sub batch step 2494 -- lr 9.34e-05
2025-03-02 11:46:11,908 - INFO - ðŸªœ Batch step - 623 -- sub batch step 2495 -- lr 9.34e-05
2025-03-02 11:46:13,463 - INFO - Step 623 -- ðŸ”„ Training Metrics
2025-03-02 11:46:13,464 - INFO - â”œâ”€â”€ Loss: 10.0978
2025-03-02 11:46:13,464 - INFO - â”œâ”€â”€ Learning Rate: 9.34e-05
2025-03-02 11:46:13,464 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:46:14,135 - INFO - ðŸªœ Batch step - 624 -- sub batch step 2496 -- lr 9.36e-05
2025-03-02 11:46:16,290 - INFO - ðŸªœ Batch step - 624 -- sub batch step 2497 -- lr 9.36e-05
2025-03-02 11:46:18,439 - INFO - ðŸªœ Batch step - 624 -- sub batch step 2498 -- lr 9.36e-05
2025-03-02 11:46:20,613 - INFO - ðŸªœ Batch step - 624 -- sub batch step 2499 -- lr 9.36e-05
2025-03-02 11:46:22,158 - INFO - Step 624 -- ðŸ”„ Training Metrics
2025-03-02 11:46:22,159 - INFO - â”œâ”€â”€ Loss: 10.0817
2025-03-02 11:46:22,159 - INFO - â”œâ”€â”€ Learning Rate: 9.36e-05
2025-03-02 11:46:22,159 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:46:22,831 - INFO - ðŸªœ Batch step - 625 -- sub batch step 2500 -- lr 9.37e-05
2025-03-02 11:46:24,987 - INFO - ðŸªœ Batch step - 625 -- sub batch step 2501 -- lr 9.37e-05
2025-03-02 11:46:27,136 - INFO - ðŸªœ Batch step - 625 -- sub batch step 2502 -- lr 9.37e-05
2025-03-02 11:46:29,495 - INFO - ðŸªœ Batch step - 625 -- sub batch step 2503 -- lr 9.37e-05
2025-03-02 11:46:31,474 - INFO - Step 625 -- ðŸ”„ Training Metrics
2025-03-02 11:46:31,474 - INFO - â”œâ”€â”€ Loss: 10.0849
2025-03-02 11:46:31,474 - INFO - â”œâ”€â”€ Learning Rate: 9.37e-05
2025-03-02 11:46:31,474 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:46:32,147 - INFO - ðŸªœ Batch step - 626 -- sub batch step 2504 -- lr 9.39e-05
2025-03-02 11:46:34,304 - INFO - ðŸªœ Batch step - 626 -- sub batch step 2505 -- lr 9.39e-05
2025-03-02 11:46:36,454 - INFO - ðŸªœ Batch step - 626 -- sub batch step 2506 -- lr 9.39e-05
2025-03-02 11:46:38,626 - INFO - ðŸªœ Batch step - 626 -- sub batch step 2507 -- lr 9.39e-05
2025-03-02 11:46:40,165 - INFO - Step 626 -- ðŸ”„ Training Metrics
2025-03-02 11:46:40,165 - INFO - â”œâ”€â”€ Loss: 10.0898
2025-03-02 11:46:40,165 - INFO - â”œâ”€â”€ Learning Rate: 9.39e-05
2025-03-02 11:46:40,165 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:46:40,835 - INFO - ðŸªœ Batch step - 627 -- sub batch step 2508 -- lr 9.40e-05
2025-03-02 11:46:42,996 - INFO - ðŸªœ Batch step - 627 -- sub batch step 2509 -- lr 9.40e-05
2025-03-02 11:46:45,150 - INFO - ðŸªœ Batch step - 627 -- sub batch step 2510 -- lr 9.40e-05
2025-03-02 11:46:47,503 - INFO - ðŸªœ Batch step - 627 -- sub batch step 2511 -- lr 9.40e-05
2025-03-02 11:46:49,478 - INFO - Step 627 -- ðŸ”„ Training Metrics
2025-03-02 11:46:49,479 - INFO - â”œâ”€â”€ Loss: 10.0813
2025-03-02 11:46:49,479 - INFO - â”œâ”€â”€ Learning Rate: 9.40e-05
2025-03-02 11:46:49,479 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:46:50,154 - INFO - ðŸªœ Batch step - 628 -- sub batch step 2512 -- lr 9.42e-05
2025-03-02 11:46:52,305 - INFO - ðŸªœ Batch step - 628 -- sub batch step 2513 -- lr 9.42e-05
2025-03-02 11:46:54,460 - INFO - ðŸªœ Batch step - 628 -- sub batch step 2514 -- lr 9.42e-05
2025-03-02 11:46:56,635 - INFO - ðŸªœ Batch step - 628 -- sub batch step 2515 -- lr 9.42e-05
2025-03-02 11:46:58,171 - INFO - Step 628 -- ðŸ”„ Training Metrics
2025-03-02 11:46:58,171 - INFO - â”œâ”€â”€ Loss: 10.0609
2025-03-02 11:46:58,171 - INFO - â”œâ”€â”€ Learning Rate: 9.42e-05
2025-03-02 11:46:58,171 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:46:58,842 - INFO - ðŸªœ Batch step - 629 -- sub batch step 2516 -- lr 9.43e-05
2025-03-02 11:47:00,999 - INFO - ðŸªœ Batch step - 629 -- sub batch step 2517 -- lr 9.43e-05
2025-03-02 11:47:03,146 - INFO - ðŸªœ Batch step - 629 -- sub batch step 2518 -- lr 9.43e-05
2025-03-02 11:47:05,957 - INFO - ðŸªœ Batch step - 629 -- sub batch step 2519 -- lr 9.43e-05
2025-03-02 11:47:07,451 - INFO - Step 629 -- ðŸ”„ Training Metrics
2025-03-02 11:47:07,451 - INFO - â”œâ”€â”€ Loss: 10.0614
2025-03-02 11:47:07,451 - INFO - â”œâ”€â”€ Learning Rate: 9.43e-05
2025-03-02 11:47:07,451 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:47:08,127 - INFO - ðŸªœ Batch step - 630 -- sub batch step 2520 -- lr 9.45e-05
2025-03-02 11:47:10,276 - INFO - ðŸªœ Batch step - 630 -- sub batch step 2521 -- lr 9.45e-05
2025-03-02 11:47:12,433 - INFO - ðŸªœ Batch step - 630 -- sub batch step 2522 -- lr 9.45e-05
2025-03-02 11:47:14,593 - INFO - ðŸªœ Batch step - 630 -- sub batch step 2523 -- lr 9.45e-05
2025-03-02 11:47:16,137 - INFO - Step 630 -- ðŸ”„ Training Metrics
2025-03-02 11:47:16,137 - INFO - â”œâ”€â”€ Loss: 10.0542
2025-03-02 11:47:16,137 - INFO - â”œâ”€â”€ Learning Rate: 9.45e-05
2025-03-02 11:47:16,138 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:47:16,808 - INFO - ðŸªœ Batch step - 631 -- sub batch step 2524 -- lr 9.46e-05
2025-03-02 11:47:18,960 - INFO - ðŸªœ Batch step - 631 -- sub batch step 2525 -- lr 9.46e-05
2025-03-02 11:47:21,855 - INFO - ðŸªœ Batch step - 631 -- sub batch step 2526 -- lr 9.46e-05
2025-03-02 11:47:24,007 - INFO - ðŸªœ Batch step - 631 -- sub batch step 2527 -- lr 9.46e-05
2025-03-02 11:47:25,500 - INFO - Step 631 -- ðŸ”„ Training Metrics
2025-03-02 11:47:25,501 - INFO - â”œâ”€â”€ Loss: 10.0581
2025-03-02 11:47:25,501 - INFO - â”œâ”€â”€ Learning Rate: 9.46e-05
2025-03-02 11:47:25,501 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:47:26,165 - INFO - ðŸªœ Batch step - 632 -- sub batch step 2528 -- lr 9.48e-05
2025-03-02 11:47:28,325 - INFO - ðŸªœ Batch step - 632 -- sub batch step 2529 -- lr 9.48e-05
2025-03-02 11:47:30,498 - INFO - ðŸªœ Batch step - 632 -- sub batch step 2530 -- lr 9.48e-05
2025-03-02 11:47:32,645 - INFO - ðŸªœ Batch step - 632 -- sub batch step 2531 -- lr 9.48e-05
2025-03-02 11:47:34,190 - INFO - Step 632 -- ðŸ”„ Training Metrics
2025-03-02 11:47:34,190 - INFO - â”œâ”€â”€ Loss: 10.0517
2025-03-02 11:47:34,190 - INFO - â”œâ”€â”€ Learning Rate: 9.48e-05
2025-03-02 11:47:34,191 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:47:34,862 - INFO - ðŸªœ Batch step - 633 -- sub batch step 2532 -- lr 9.49e-05
2025-03-02 11:47:37,014 - INFO - ðŸªœ Batch step - 633 -- sub batch step 2533 -- lr 9.49e-05
2025-03-02 11:47:39,822 - INFO - ðŸªœ Batch step - 633 -- sub batch step 2534 -- lr 9.49e-05
2025-03-02 11:47:41,986 - INFO - ðŸªœ Batch step - 633 -- sub batch step 2535 -- lr 9.49e-05
2025-03-02 11:47:43,478 - INFO - Step 633 -- ðŸ”„ Training Metrics
2025-03-02 11:47:43,479 - INFO - â”œâ”€â”€ Loss: 10.0458
2025-03-02 11:47:43,479 - INFO - â”œâ”€â”€ Learning Rate: 9.49e-05
2025-03-02 11:47:43,479 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:47:44,149 - INFO - ðŸªœ Batch step - 634 -- sub batch step 2536 -- lr 9.51e-05
2025-03-02 11:47:46,306 - INFO - ðŸªœ Batch step - 634 -- sub batch step 2537 -- lr 9.51e-05
2025-03-02 11:47:48,468 - INFO - ðŸªœ Batch step - 634 -- sub batch step 2538 -- lr 9.51e-05
2025-03-02 11:47:50,618 - INFO - ðŸªœ Batch step - 634 -- sub batch step 2539 -- lr 9.51e-05
2025-03-02 11:47:52,168 - INFO - Step 634 -- ðŸ”„ Training Metrics
2025-03-02 11:47:52,168 - INFO - â”œâ”€â”€ Loss: 10.0412
2025-03-02 11:47:52,168 - INFO - â”œâ”€â”€ Learning Rate: 9.51e-05
2025-03-02 11:47:52,168 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:47:52,842 - INFO - ðŸªœ Batch step - 635 -- sub batch step 2540 -- lr 9.52e-05
2025-03-02 11:47:54,997 - INFO - ðŸªœ Batch step - 635 -- sub batch step 2541 -- lr 9.52e-05
2025-03-02 11:47:57,397 - INFO - ðŸªœ Batch step - 635 -- sub batch step 2542 -- lr 9.52e-05
2025-03-02 11:47:59,546 - INFO - ðŸªœ Batch step - 635 -- sub batch step 2543 -- lr 9.52e-05
2025-03-02 11:48:01,307 - INFO - Step 635 -- ðŸ”„ Training Metrics
2025-03-02 11:48:01,307 - INFO - â”œâ”€â”€ Loss: 10.0404
2025-03-02 11:48:01,307 - INFO - â”œâ”€â”€ Learning Rate: 9.52e-05
2025-03-02 11:48:01,307 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:48:01,979 - INFO - ðŸªœ Batch step - 636 -- sub batch step 2544 -- lr 9.54e-05
2025-03-02 11:48:04,134 - INFO - ðŸªœ Batch step - 636 -- sub batch step 2545 -- lr 9.54e-05
2025-03-02 11:48:06,297 - INFO - ðŸªœ Batch step - 636 -- sub batch step 2546 -- lr 9.54e-05
2025-03-02 11:48:08,448 - INFO - ðŸªœ Batch step - 636 -- sub batch step 2547 -- lr 9.54e-05
2025-03-02 11:48:09,995 - INFO - Step 636 -- ðŸ”„ Training Metrics
2025-03-02 11:48:09,995 - INFO - â”œâ”€â”€ Loss: 10.0289
2025-03-02 11:48:09,995 - INFO - â”œâ”€â”€ Learning Rate: 9.54e-05
2025-03-02 11:48:09,995 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:48:10,661 - INFO - ðŸªœ Batch step - 637 -- sub batch step 2548 -- lr 9.55e-05
2025-03-02 11:48:12,817 - INFO - ðŸªœ Batch step - 637 -- sub batch step 2549 -- lr 9.55e-05
2025-03-02 11:48:15,540 - INFO - ðŸªœ Batch step - 637 -- sub batch step 2550 -- lr 9.55e-05
2025-03-02 11:48:17,690 - INFO - ðŸªœ Batch step - 637 -- sub batch step 2551 -- lr 9.55e-05
2025-03-02 11:48:19,182 - INFO - Step 637 -- ðŸ”„ Training Metrics
2025-03-02 11:48:19,182 - INFO - â”œâ”€â”€ Loss: 10.0152
2025-03-02 11:48:19,182 - INFO - â”œâ”€â”€ Learning Rate: 9.55e-05
2025-03-02 11:48:19,182 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:48:19,850 - INFO - ðŸªœ Batch step - 638 -- sub batch step 2552 -- lr 9.57e-05
2025-03-02 11:48:21,993 - INFO - ðŸªœ Batch step - 638 -- sub batch step 2553 -- lr 9.57e-05
2025-03-02 11:48:24,162 - INFO - ðŸªœ Batch step - 638 -- sub batch step 2554 -- lr 9.57e-05
2025-03-02 11:48:26,311 - INFO - ðŸªœ Batch step - 638 -- sub batch step 2555 -- lr 9.57e-05
2025-03-02 11:48:27,892 - INFO - Step 638 -- ðŸ”„ Training Metrics
2025-03-02 11:48:27,892 - INFO - â”œâ”€â”€ Loss: 10.0205
2025-03-02 11:48:27,892 - INFO - â”œâ”€â”€ Learning Rate: 9.57e-05
2025-03-02 11:48:27,892 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:48:28,554 - INFO - ðŸªœ Batch step - 639 -- sub batch step 2556 -- lr 9.58e-05
2025-03-02 11:48:30,705 - INFO - ðŸªœ Batch step - 639 -- sub batch step 2557 -- lr 9.58e-05
2025-03-02 11:48:32,984 - INFO - ðŸªœ Batch step - 639 -- sub batch step 2558 -- lr 9.58e-05
2025-03-02 11:48:35,134 - INFO - ðŸªœ Batch step - 639 -- sub batch step 2559 -- lr 9.58e-05
2025-03-02 11:48:36,940 - INFO - Step 639 -- ðŸ”„ Training Metrics
2025-03-02 11:48:36,940 - INFO - â”œâ”€â”€ Loss: 10.0225
2025-03-02 11:48:36,940 - INFO - â”œâ”€â”€ Learning Rate: 9.58e-05
2025-03-02 11:48:36,941 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:48:38,171 - INFO - ðŸªœ Batch step - 640 -- sub batch step 2560 -- lr 9.60e-05
2025-03-02 11:48:40,317 - INFO - ðŸªœ Batch step - 640 -- sub batch step 2561 -- lr 9.60e-05
2025-03-02 11:48:42,466 - INFO - ðŸªœ Batch step - 640 -- sub batch step 2562 -- lr 9.60e-05
2025-03-02 11:48:44,628 - INFO - ðŸªœ Batch step - 640 -- sub batch step 2563 -- lr 9.60e-05
2025-03-02 11:48:46,197 - INFO - Step 640 -- ðŸ”„ Training Metrics
2025-03-02 11:48:46,197 - INFO - â”œâ”€â”€ Loss: 10.0132
2025-03-02 11:48:46,197 - INFO - â”œâ”€â”€ Learning Rate: 9.60e-05
2025-03-02 11:48:46,197 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:48:46,867 - INFO - ðŸªœ Batch step - 641 -- sub batch step 2564 -- lr 9.61e-05
2025-03-02 11:48:49,017 - INFO - ðŸªœ Batch step - 641 -- sub batch step 2565 -- lr 9.61e-05
2025-03-02 11:48:51,163 - INFO - ðŸªœ Batch step - 641 -- sub batch step 2566 -- lr 9.61e-05
2025-03-02 11:48:53,637 - INFO - ðŸªœ Batch step - 641 -- sub batch step 2567 -- lr 9.61e-05
2025-03-02 11:48:55,242 - INFO - Step 641 -- ðŸ”„ Training Metrics
2025-03-02 11:48:55,243 - INFO - â”œâ”€â”€ Loss: 10.0035
2025-03-02 11:48:55,243 - INFO - â”œâ”€â”€ Learning Rate: 9.61e-05
2025-03-02 11:48:55,243 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:48:55,909 - INFO - ðŸªœ Batch step - 642 -- sub batch step 2568 -- lr 9.63e-05
2025-03-02 11:48:58,062 - INFO - ðŸªœ Batch step - 642 -- sub batch step 2569 -- lr 9.63e-05
2025-03-02 11:49:00,213 - INFO - ðŸªœ Batch step - 642 -- sub batch step 2570 -- lr 9.63e-05
2025-03-02 11:49:02,378 - INFO - ðŸªœ Batch step - 642 -- sub batch step 2571 -- lr 9.63e-05
2025-03-02 11:49:03,923 - INFO - Step 642 -- ðŸ”„ Training Metrics
2025-03-02 11:49:03,923 - INFO - â”œâ”€â”€ Loss: 10.0135
2025-03-02 11:49:03,923 - INFO - â”œâ”€â”€ Learning Rate: 9.63e-05
2025-03-02 11:49:03,923 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:49:04,595 - INFO - ðŸªœ Batch step - 643 -- sub batch step 2572 -- lr 9.64e-05
2025-03-02 11:49:06,744 - INFO - ðŸªœ Batch step - 643 -- sub batch step 2573 -- lr 9.64e-05
2025-03-02 11:49:08,899 - INFO - ðŸªœ Batch step - 643 -- sub batch step 2574 -- lr 9.64e-05
2025-03-02 11:49:11,356 - INFO - ðŸªœ Batch step - 643 -- sub batch step 2575 -- lr 9.64e-05
2025-03-02 11:49:13,103 - INFO - Step 643 -- ðŸ”„ Training Metrics
2025-03-02 11:49:13,103 - INFO - â”œâ”€â”€ Loss: 10.0008
2025-03-02 11:49:13,103 - INFO - â”œâ”€â”€ Learning Rate: 9.64e-05
2025-03-02 11:49:13,103 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:49:13,772 - INFO - ðŸªœ Batch step - 644 -- sub batch step 2576 -- lr 9.66e-05
2025-03-02 11:49:15,929 - INFO - ðŸªœ Batch step - 644 -- sub batch step 2577 -- lr 9.66e-05
2025-03-02 11:49:18,076 - INFO - ðŸªœ Batch step - 644 -- sub batch step 2578 -- lr 9.66e-05
2025-03-02 11:49:20,257 - INFO - ðŸªœ Batch step - 644 -- sub batch step 2579 -- lr 9.66e-05
2025-03-02 11:49:21,787 - INFO - Step 644 -- ðŸ”„ Training Metrics
2025-03-02 11:49:21,787 - INFO - â”œâ”€â”€ Loss: 9.9966
2025-03-02 11:49:21,787 - INFO - â”œâ”€â”€ Learning Rate: 9.66e-05
2025-03-02 11:49:21,787 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:49:22,461 - INFO - ðŸªœ Batch step - 645 -- sub batch step 2580 -- lr 9.67e-05
2025-03-02 11:49:24,611 - INFO - ðŸªœ Batch step - 645 -- sub batch step 2581 -- lr 9.67e-05
2025-03-02 11:49:26,762 - INFO - ðŸªœ Batch step - 645 -- sub batch step 2582 -- lr 9.67e-05
2025-03-02 11:49:29,439 - INFO - ðŸªœ Batch step - 645 -- sub batch step 2583 -- lr 9.67e-05
2025-03-02 11:49:31,068 - INFO - Step 645 -- ðŸ”„ Training Metrics
2025-03-02 11:49:31,068 - INFO - â”œâ”€â”€ Loss: 9.9879
2025-03-02 11:49:31,068 - INFO - â”œâ”€â”€ Learning Rate: 9.67e-05
2025-03-02 11:49:31,068 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:49:31,739 - INFO - ðŸªœ Batch step - 646 -- sub batch step 2584 -- lr 9.69e-05
2025-03-02 11:49:33,893 - INFO - ðŸªœ Batch step - 646 -- sub batch step 2585 -- lr 9.69e-05
2025-03-02 11:49:36,043 - INFO - ðŸªœ Batch step - 646 -- sub batch step 2586 -- lr 9.69e-05
2025-03-02 11:49:38,216 - INFO - ðŸªœ Batch step - 646 -- sub batch step 2587 -- lr 9.69e-05
2025-03-02 11:49:39,752 - INFO - Step 646 -- ðŸ”„ Training Metrics
2025-03-02 11:49:39,752 - INFO - â”œâ”€â”€ Loss: 9.9780
2025-03-02 11:49:39,752 - INFO - â”œâ”€â”€ Learning Rate: 9.69e-05
2025-03-02 11:49:39,753 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:49:40,418 - INFO - ðŸªœ Batch step - 647 -- sub batch step 2588 -- lr 9.71e-05
2025-03-02 11:49:42,573 - INFO - ðŸªœ Batch step - 647 -- sub batch step 2589 -- lr 9.71e-05
2025-03-02 11:49:44,729 - INFO - ðŸªœ Batch step - 647 -- sub batch step 2590 -- lr 9.71e-05
2025-03-02 11:49:47,092 - INFO - ðŸªœ Batch step - 647 -- sub batch step 2591 -- lr 9.71e-05
2025-03-02 11:49:49,070 - INFO - Step 647 -- ðŸ”„ Training Metrics
2025-03-02 11:49:49,070 - INFO - â”œâ”€â”€ Loss: 9.9761
2025-03-02 11:49:49,070 - INFO - â”œâ”€â”€ Learning Rate: 9.71e-05
2025-03-02 11:49:49,070 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:49:49,746 - INFO - ðŸªœ Batch step - 648 -- sub batch step 2592 -- lr 9.72e-05
2025-03-02 11:49:51,892 - INFO - ðŸªœ Batch step - 648 -- sub batch step 2593 -- lr 9.72e-05
2025-03-02 11:49:54,048 - INFO - ðŸªœ Batch step - 648 -- sub batch step 2594 -- lr 9.72e-05
2025-03-02 11:49:56,229 - INFO - ðŸªœ Batch step - 648 -- sub batch step 2595 -- lr 9.72e-05
2025-03-02 11:49:57,768 - INFO - Step 648 -- ðŸ”„ Training Metrics
2025-03-02 11:49:57,769 - INFO - â”œâ”€â”€ Loss: 9.9780
2025-03-02 11:49:57,769 - INFO - â”œâ”€â”€ Learning Rate: 9.72e-05
2025-03-02 11:49:57,769 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:49:58,440 - INFO - ðŸªœ Batch step - 649 -- sub batch step 2596 -- lr 9.73e-05
2025-03-02 11:50:00,593 - INFO - ðŸªœ Batch step - 649 -- sub batch step 2597 -- lr 9.73e-05
2025-03-02 11:50:02,744 - INFO - ðŸªœ Batch step - 649 -- sub batch step 2598 -- lr 9.73e-05
2025-03-02 11:50:05,431 - INFO - ðŸªœ Batch step - 649 -- sub batch step 2599 -- lr 9.73e-05
2025-03-02 11:50:06,974 - INFO - Step 649 -- ðŸ”„ Training Metrics
2025-03-02 11:50:06,974 - INFO - â”œâ”€â”€ Loss: 9.9656
2025-03-02 11:50:06,974 - INFO - â”œâ”€â”€ Learning Rate: 9.73e-05
2025-03-02 11:50:06,974 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:50:07,647 - INFO - ðŸªœ Batch step - 650 -- sub batch step 2600 -- lr 9.75e-05
2025-03-02 11:50:09,794 - INFO - ðŸªœ Batch step - 650 -- sub batch step 2601 -- lr 9.75e-05
2025-03-02 11:50:11,950 - INFO - ðŸªœ Batch step - 650 -- sub batch step 2602 -- lr 9.75e-05
2025-03-02 11:50:14,111 - INFO - ðŸªœ Batch step - 650 -- sub batch step 2603 -- lr 9.75e-05
2025-03-02 11:50:15,660 - INFO - Step 650 -- ðŸ”„ Training Metrics
2025-03-02 11:50:15,660 - INFO - â”œâ”€â”€ Loss: 9.9609
2025-03-02 11:50:15,660 - INFO - â”œâ”€â”€ Learning Rate: 9.75e-05
2025-03-02 11:50:15,660 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:50:16,338 - INFO - ðŸªœ Batch step - 651 -- sub batch step 2604 -- lr 9.76e-05
2025-03-02 11:50:18,493 - INFO - ðŸªœ Batch step - 651 -- sub batch step 2605 -- lr 9.76e-05
2025-03-02 11:50:20,894 - INFO - ðŸªœ Batch step - 651 -- sub batch step 2606 -- lr 9.76e-05
2025-03-02 11:50:23,047 - INFO - ðŸªœ Batch step - 651 -- sub batch step 2607 -- lr 9.76e-05
2025-03-02 11:50:24,827 - INFO - Step 651 -- ðŸ”„ Training Metrics
2025-03-02 11:50:24,828 - INFO - â”œâ”€â”€ Loss: 9.9587
2025-03-02 11:50:24,828 - INFO - â”œâ”€â”€ Learning Rate: 9.76e-05
2025-03-02 11:50:24,828 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:50:25,496 - INFO - ðŸªœ Batch step - 652 -- sub batch step 2608 -- lr 9.78e-05
2025-03-02 11:50:27,644 - INFO - ðŸªœ Batch step - 652 -- sub batch step 2609 -- lr 9.78e-05
2025-03-02 11:50:29,812 - INFO - ðŸªœ Batch step - 652 -- sub batch step 2610 -- lr 9.78e-05
2025-03-02 11:50:31,959 - INFO - ðŸªœ Batch step - 652 -- sub batch step 2611 -- lr 9.78e-05
2025-03-02 11:50:33,514 - INFO - Step 652 -- ðŸ”„ Training Metrics
2025-03-02 11:50:33,514 - INFO - â”œâ”€â”€ Loss: 9.9564
2025-03-02 11:50:33,515 - INFO - â”œâ”€â”€ Learning Rate: 9.78e-05
2025-03-02 11:50:33,515 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:50:34,185 - INFO - ðŸªœ Batch step - 653 -- sub batch step 2612 -- lr 9.79e-05
2025-03-02 11:50:36,333 - INFO - ðŸªœ Batch step - 653 -- sub batch step 2613 -- lr 9.79e-05
2025-03-02 11:50:38,983 - INFO - ðŸªœ Batch step - 653 -- sub batch step 2614 -- lr 9.79e-05
2025-03-02 11:50:41,136 - INFO - ðŸªœ Batch step - 653 -- sub batch step 2615 -- lr 9.79e-05
2025-03-02 11:50:42,859 - INFO - Step 653 -- ðŸ”„ Training Metrics
2025-03-02 11:50:42,859 - INFO - â”œâ”€â”€ Loss: 9.9538
2025-03-02 11:50:42,859 - INFO - â”œâ”€â”€ Learning Rate: 9.79e-05
2025-03-02 11:50:42,859 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:50:43,524 - INFO - ðŸªœ Batch step - 654 -- sub batch step 2616 -- lr 9.81e-05
2025-03-02 11:50:45,675 - INFO - ðŸªœ Batch step - 654 -- sub batch step 2617 -- lr 9.81e-05
2025-03-02 11:50:47,838 - INFO - ðŸªœ Batch step - 654 -- sub batch step 2618 -- lr 9.81e-05
2025-03-02 11:50:49,992 - INFO - ðŸªœ Batch step - 654 -- sub batch step 2619 -- lr 9.81e-05
2025-03-02 11:50:51,549 - INFO - Step 654 -- ðŸ”„ Training Metrics
2025-03-02 11:50:51,549 - INFO - â”œâ”€â”€ Loss: 9.9415
2025-03-02 11:50:51,549 - INFO - â”œâ”€â”€ Learning Rate: 9.81e-05
2025-03-02 11:50:51,549 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:50:52,219 - INFO - ðŸªœ Batch step - 655 -- sub batch step 2620 -- lr 9.82e-05
2025-03-02 11:50:54,368 - INFO - ðŸªœ Batch step - 655 -- sub batch step 2621 -- lr 9.82e-05
2025-03-02 11:50:56,886 - INFO - ðŸªœ Batch step - 655 -- sub batch step 2622 -- lr 9.82e-05
2025-03-02 11:50:59,036 - INFO - ðŸªœ Batch step - 655 -- sub batch step 2623 -- lr 9.82e-05
2025-03-02 11:51:00,828 - INFO - Step 655 -- ðŸ”„ Training Metrics
2025-03-02 11:51:00,828 - INFO - â”œâ”€â”€ Loss: 9.9350
2025-03-02 11:51:00,828 - INFO - â”œâ”€â”€ Learning Rate: 9.82e-05
2025-03-02 11:51:00,828 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:51:01,499 - INFO - ðŸªœ Batch step - 656 -- sub batch step 2624 -- lr 9.84e-05
2025-03-02 11:51:03,653 - INFO - ðŸªœ Batch step - 656 -- sub batch step 2625 -- lr 9.84e-05
2025-03-02 11:51:05,820 - INFO - ðŸªœ Batch step - 656 -- sub batch step 2626 -- lr 9.84e-05
2025-03-02 11:51:07,970 - INFO - ðŸªœ Batch step - 656 -- sub batch step 2627 -- lr 9.84e-05
2025-03-02 11:51:09,526 - INFO - Step 656 -- ðŸ”„ Training Metrics
2025-03-02 11:51:09,527 - INFO - â”œâ”€â”€ Loss: 9.9281
2025-03-02 11:51:09,527 - INFO - â”œâ”€â”€ Learning Rate: 9.84e-05
2025-03-02 11:51:09,527 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:51:10,194 - INFO - ðŸªœ Batch step - 657 -- sub batch step 2628 -- lr 9.85e-05
2025-03-02 11:51:12,346 - INFO - ðŸªœ Batch step - 657 -- sub batch step 2629 -- lr 9.85e-05
2025-03-02 11:51:14,729 - INFO - ðŸªœ Batch step - 657 -- sub batch step 2630 -- lr 9.85e-05
2025-03-02 11:51:16,881 - INFO - ðŸªœ Batch step - 657 -- sub batch step 2631 -- lr 9.85e-05
2025-03-02 11:51:18,742 - INFO - Step 657 -- ðŸ”„ Training Metrics
2025-03-02 11:51:18,743 - INFO - â”œâ”€â”€ Loss: 9.9213
2025-03-02 11:51:18,743 - INFO - â”œâ”€â”€ Learning Rate: 9.85e-05
2025-03-02 11:51:18,743 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:51:19,414 - INFO - ðŸªœ Batch step - 658 -- sub batch step 2632 -- lr 9.87e-05
2025-03-02 11:51:21,563 - INFO - ðŸªœ Batch step - 658 -- sub batch step 2633 -- lr 9.87e-05
2025-03-02 11:51:23,736 - INFO - ðŸªœ Batch step - 658 -- sub batch step 2634 -- lr 9.87e-05
2025-03-02 11:51:25,887 - INFO - ðŸªœ Batch step - 658 -- sub batch step 2635 -- lr 9.87e-05
2025-03-02 11:51:27,428 - INFO - Step 658 -- ðŸ”„ Training Metrics
2025-03-02 11:51:27,428 - INFO - â”œâ”€â”€ Loss: 9.9240
2025-03-02 11:51:27,428 - INFO - â”œâ”€â”€ Learning Rate: 9.87e-05
2025-03-02 11:51:27,429 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:51:28,094 - INFO - ðŸªœ Batch step - 659 -- sub batch step 2636 -- lr 9.88e-05
2025-03-02 11:51:30,252 - INFO - ðŸªœ Batch step - 659 -- sub batch step 2637 -- lr 9.88e-05
2025-03-02 11:51:32,551 - INFO - ðŸªœ Batch step - 659 -- sub batch step 2638 -- lr 9.88e-05
2025-03-02 11:51:34,704 - INFO - ðŸªœ Batch step - 659 -- sub batch step 2639 -- lr 9.88e-05
2025-03-02 11:51:36,222 - INFO - Step 659 -- ðŸ”„ Training Metrics
2025-03-02 11:51:36,222 - INFO - â”œâ”€â”€ Loss: 9.9133
2025-03-02 11:51:36,223 - INFO - â”œâ”€â”€ Learning Rate: 9.88e-05
2025-03-02 11:51:36,223 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:51:37,574 - INFO - ðŸªœ Batch step - 660 -- sub batch step 2640 -- lr 9.90e-05
2025-03-02 11:51:39,732 - INFO - ðŸªœ Batch step - 660 -- sub batch step 2641 -- lr 9.90e-05
2025-03-02 11:51:41,896 - INFO - ðŸªœ Batch step - 660 -- sub batch step 2642 -- lr 9.90e-05
2025-03-02 11:51:44,074 - INFO - ðŸªœ Batch step - 660 -- sub batch step 2643 -- lr 9.90e-05
2025-03-02 11:51:45,568 - INFO - Step 660 -- ðŸ”„ Training Metrics
2025-03-02 11:51:45,568 - INFO - â”œâ”€â”€ Loss: 9.9108
2025-03-02 11:51:45,568 - INFO - â”œâ”€â”€ Learning Rate: 9.90e-05
2025-03-02 11:51:45,569 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:51:46,244 - INFO - ðŸªœ Batch step - 661 -- sub batch step 2644 -- lr 9.91e-05
2025-03-02 11:51:48,400 - INFO - ðŸªœ Batch step - 661 -- sub batch step 2645 -- lr 9.91e-05
2025-03-02 11:51:50,553 - INFO - ðŸªœ Batch step - 661 -- sub batch step 2646 -- lr 9.91e-05
2025-03-02 11:51:53,035 - INFO - ðŸªœ Batch step - 661 -- sub batch step 2647 -- lr 9.91e-05
2025-03-02 11:51:54,845 - INFO - Step 661 -- ðŸ”„ Training Metrics
2025-03-02 11:51:54,846 - INFO - â”œâ”€â”€ Loss: 9.9024
2025-03-02 11:51:54,846 - INFO - â”œâ”€â”€ Learning Rate: 9.91e-05
2025-03-02 11:51:54,846 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:51:55,511 - INFO - ðŸªœ Batch step - 662 -- sub batch step 2648 -- lr 9.93e-05
2025-03-02 11:51:57,665 - INFO - ðŸªœ Batch step - 662 -- sub batch step 2649 -- lr 9.93e-05
2025-03-02 11:51:59,819 - INFO - ðŸªœ Batch step - 662 -- sub batch step 2650 -- lr 9.93e-05
2025-03-02 11:52:01,989 - INFO - ðŸªœ Batch step - 662 -- sub batch step 2651 -- lr 9.93e-05
2025-03-02 11:52:03,523 - INFO - Step 662 -- ðŸ”„ Training Metrics
2025-03-02 11:52:03,524 - INFO - â”œâ”€â”€ Loss: 9.8981
2025-03-02 11:52:03,524 - INFO - â”œâ”€â”€ Learning Rate: 9.93e-05
2025-03-02 11:52:03,524 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:52:04,194 - INFO - ðŸªœ Batch step - 663 -- sub batch step 2652 -- lr 9.94e-05
2025-03-02 11:52:06,342 - INFO - ðŸªœ Batch step - 663 -- sub batch step 2653 -- lr 9.94e-05
2025-03-02 11:52:08,493 - INFO - ðŸªœ Batch step - 663 -- sub batch step 2654 -- lr 9.94e-05
2025-03-02 11:52:11,145 - INFO - ðŸªœ Batch step - 663 -- sub batch step 2655 -- lr 9.94e-05
2025-03-02 11:52:12,634 - INFO - Step 663 -- ðŸ”„ Training Metrics
2025-03-02 11:52:12,634 - INFO - â”œâ”€â”€ Loss: 9.9028
2025-03-02 11:52:12,634 - INFO - â”œâ”€â”€ Learning Rate: 9.94e-05
2025-03-02 11:52:12,635 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:52:13,300 - INFO - ðŸªœ Batch step - 664 -- sub batch step 2656 -- lr 9.96e-05
2025-03-02 11:52:15,454 - INFO - ðŸªœ Batch step - 664 -- sub batch step 2657 -- lr 9.96e-05
2025-03-02 11:52:17,602 - INFO - ðŸªœ Batch step - 664 -- sub batch step 2658 -- lr 9.96e-05
2025-03-02 11:52:19,773 - INFO - ðŸªœ Batch step - 664 -- sub batch step 2659 -- lr 9.96e-05
2025-03-02 11:52:21,323 - INFO - Step 664 -- ðŸ”„ Training Metrics
2025-03-02 11:52:21,324 - INFO - â”œâ”€â”€ Loss: 9.8976
2025-03-02 11:52:21,324 - INFO - â”œâ”€â”€ Learning Rate: 9.96e-05
2025-03-02 11:52:21,324 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:52:21,994 - INFO - ðŸªœ Batch step - 665 -- sub batch step 2660 -- lr 9.97e-05
2025-03-02 11:52:24,139 - INFO - ðŸªœ Batch step - 665 -- sub batch step 2661 -- lr 9.97e-05
2025-03-02 11:52:26,289 - INFO - ðŸªœ Batch step - 665 -- sub batch step 2662 -- lr 9.97e-05
2025-03-02 11:52:28,933 - INFO - ðŸªœ Batch step - 665 -- sub batch step 2663 -- lr 9.97e-05
2025-03-02 11:52:30,546 - INFO - Step 665 -- ðŸ”„ Training Metrics
2025-03-02 11:52:30,546 - INFO - â”œâ”€â”€ Loss: 9.8795
2025-03-02 11:52:30,546 - INFO - â”œâ”€â”€ Learning Rate: 9.97e-05
2025-03-02 11:52:30,546 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:52:31,219 - INFO - ðŸªœ Batch step - 666 -- sub batch step 2664 -- lr 9.99e-05
2025-03-02 11:52:33,370 - INFO - ðŸªœ Batch step - 666 -- sub batch step 2665 -- lr 9.99e-05
2025-03-02 11:52:35,516 - INFO - ðŸªœ Batch step - 666 -- sub batch step 2666 -- lr 9.99e-05
2025-03-02 11:52:37,692 - INFO - ðŸªœ Batch step - 666 -- sub batch step 2667 -- lr 9.99e-05
2025-03-02 11:52:39,243 - INFO - Step 666 -- ðŸ”„ Training Metrics
2025-03-02 11:52:39,244 - INFO - â”œâ”€â”€ Loss: 9.8797
2025-03-02 11:52:39,244 - INFO - â”œâ”€â”€ Learning Rate: 9.99e-05
2025-03-02 11:52:39,244 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:52:39,910 - INFO - ðŸªœ Batch step - 667 -- sub batch step 2668 -- lr 1.00e-04
2025-03-02 11:52:42,061 - INFO - ðŸªœ Batch step - 667 -- sub batch step 2669 -- lr 1.00e-04
2025-03-02 11:52:44,213 - INFO - ðŸªœ Batch step - 667 -- sub batch step 2670 -- lr 1.00e-04
2025-03-02 11:52:47,034 - INFO - ðŸªœ Batch step - 667 -- sub batch step 2671 -- lr 1.00e-04
2025-03-02 11:52:48,526 - INFO - Step 667 -- ðŸ”„ Training Metrics
2025-03-02 11:52:48,526 - INFO - â”œâ”€â”€ Loss: 9.8700
2025-03-02 11:52:48,526 - INFO - â”œâ”€â”€ Learning Rate: 1.00e-04
2025-03-02 11:52:48,527 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:52:49,200 - INFO - ðŸªœ Batch step - 668 -- sub batch step 2672 -- lr 1.00e-04
2025-03-02 11:52:51,350 - INFO - ðŸªœ Batch step - 668 -- sub batch step 2673 -- lr 1.00e-04
2025-03-02 11:52:53,501 - INFO - ðŸªœ Batch step - 668 -- sub batch step 2674 -- lr 1.00e-04
2025-03-02 11:52:55,673 - INFO - ðŸªœ Batch step - 668 -- sub batch step 2675 -- lr 1.00e-04
2025-03-02 11:52:57,220 - INFO - Step 668 -- ðŸ”„ Training Metrics
2025-03-02 11:52:57,220 - INFO - â”œâ”€â”€ Loss: 9.8694
2025-03-02 11:52:57,220 - INFO - â”œâ”€â”€ Learning Rate: 1.00e-04
2025-03-02 11:52:57,220 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:52:57,886 - INFO - ðŸªœ Batch step - 669 -- sub batch step 2676 -- lr 1.00e-04
2025-03-02 11:53:00,044 - INFO - ðŸªœ Batch step - 669 -- sub batch step 2677 -- lr 1.00e-04
2025-03-02 11:53:02,193 - INFO - ðŸªœ Batch step - 669 -- sub batch step 2678 -- lr 1.00e-04
2025-03-02 11:53:05,022 - INFO - ðŸªœ Batch step - 669 -- sub batch step 2679 -- lr 1.00e-04
2025-03-02 11:53:06,514 - INFO - Step 669 -- ðŸ”„ Training Metrics
2025-03-02 11:53:06,515 - INFO - â”œâ”€â”€ Loss: 9.8726
2025-03-02 11:53:06,515 - INFO - â”œâ”€â”€ Learning Rate: 1.00e-04
2025-03-02 11:53:06,515 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:53:07,190 - INFO - ðŸªœ Batch step - 670 -- sub batch step 2680 -- lr 1.01e-04
2025-03-02 11:53:09,341 - INFO - ðŸªœ Batch step - 670 -- sub batch step 2681 -- lr 1.01e-04
2025-03-02 11:53:11,493 - INFO - ðŸªœ Batch step - 670 -- sub batch step 2682 -- lr 1.01e-04
2025-03-02 11:53:13,658 - INFO - ðŸªœ Batch step - 670 -- sub batch step 2683 -- lr 1.01e-04
2025-03-02 11:53:15,192 - INFO - Step 670 -- ðŸ”„ Training Metrics
2025-03-02 11:53:15,192 - INFO - â”œâ”€â”€ Loss: 9.8585
2025-03-02 11:53:15,192 - INFO - â”œâ”€â”€ Learning Rate: 1.01e-04
2025-03-02 11:53:15,192 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:53:15,866 - INFO - ðŸªœ Batch step - 671 -- sub batch step 2684 -- lr 1.01e-04
2025-03-02 11:53:18,020 - INFO - ðŸªœ Batch step - 671 -- sub batch step 2685 -- lr 1.01e-04
2025-03-02 11:53:20,419 - INFO - ðŸªœ Batch step - 671 -- sub batch step 2686 -- lr 1.01e-04
2025-03-02 11:53:22,578 - INFO - ðŸªœ Batch step - 671 -- sub batch step 2687 -- lr 1.01e-04
2025-03-02 11:53:24,430 - INFO - Step 671 -- ðŸ”„ Training Metrics
2025-03-02 11:53:24,431 - INFO - â”œâ”€â”€ Loss: 9.8419
2025-03-02 11:53:24,431 - INFO - â”œâ”€â”€ Learning Rate: 1.01e-04
2025-03-02 11:53:24,431 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:53:25,099 - INFO - ðŸªœ Batch step - 672 -- sub batch step 2688 -- lr 1.01e-04
2025-03-02 11:53:27,254 - INFO - ðŸªœ Batch step - 672 -- sub batch step 2689 -- lr 1.01e-04
2025-03-02 11:53:29,431 - INFO - ðŸªœ Batch step - 672 -- sub batch step 2690 -- lr 1.01e-04
2025-03-02 11:53:31,583 - INFO - ðŸªœ Batch step - 672 -- sub batch step 2691 -- lr 1.01e-04
2025-03-02 11:53:33,114 - INFO - Step 672 -- ðŸ”„ Training Metrics
2025-03-02 11:53:33,114 - INFO - â”œâ”€â”€ Loss: 9.8502
2025-03-02 11:53:33,114 - INFO - â”œâ”€â”€ Learning Rate: 1.01e-04
2025-03-02 11:53:33,114 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:53:33,786 - INFO - ðŸªœ Batch step - 673 -- sub batch step 2692 -- lr 1.01e-04
2025-03-02 11:53:35,937 - INFO - ðŸªœ Batch step - 673 -- sub batch step 2693 -- lr 1.01e-04
2025-03-02 11:53:38,802 - INFO - ðŸªœ Batch step - 673 -- sub batch step 2694 -- lr 1.01e-04
2025-03-02 11:53:40,961 - INFO - ðŸªœ Batch step - 673 -- sub batch step 2695 -- lr 1.01e-04
2025-03-02 11:53:42,816 - INFO - Step 673 -- ðŸ”„ Training Metrics
2025-03-02 11:53:42,817 - INFO - â”œâ”€â”€ Loss: 9.8429
2025-03-02 11:53:42,817 - INFO - â”œâ”€â”€ Learning Rate: 1.01e-04
2025-03-02 11:53:42,817 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:53:43,488 - INFO - ðŸªœ Batch step - 674 -- sub batch step 2696 -- lr 1.01e-04
2025-03-02 11:53:45,646 - INFO - ðŸªœ Batch step - 674 -- sub batch step 2697 -- lr 1.01e-04
2025-03-02 11:53:47,817 - INFO - ðŸªœ Batch step - 674 -- sub batch step 2698 -- lr 1.01e-04
2025-03-02 11:53:49,971 - INFO - ðŸªœ Batch step - 674 -- sub batch step 2699 -- lr 1.01e-04
2025-03-02 11:53:51,502 - INFO - Step 674 -- ðŸ”„ Training Metrics
2025-03-02 11:53:51,503 - INFO - â”œâ”€â”€ Loss: 9.8377
2025-03-02 11:53:51,503 - INFO - â”œâ”€â”€ Learning Rate: 1.01e-04
2025-03-02 11:53:51,503 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:53:52,179 - INFO - ðŸªœ Batch step - 675 -- sub batch step 2700 -- lr 1.01e-04
2025-03-02 11:53:54,327 - INFO - ðŸªœ Batch step - 675 -- sub batch step 2701 -- lr 1.01e-04
2025-03-02 11:53:56,693 - INFO - ðŸªœ Batch step - 675 -- sub batch step 2702 -- lr 1.01e-04
2025-03-02 11:53:58,846 - INFO - ðŸªœ Batch step - 675 -- sub batch step 2703 -- lr 1.01e-04
2025-03-02 11:54:00,725 - INFO - Step 675 -- ðŸ”„ Training Metrics
2025-03-02 11:54:00,725 - INFO - â”œâ”€â”€ Loss: 9.8357
2025-03-02 11:54:00,726 - INFO - â”œâ”€â”€ Learning Rate: 1.01e-04
2025-03-02 11:54:00,726 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:54:01,406 - INFO - ðŸªœ Batch step - 676 -- sub batch step 2704 -- lr 1.01e-04
2025-03-02 11:54:03,564 - INFO - ðŸªœ Batch step - 676 -- sub batch step 2705 -- lr 1.01e-04
2025-03-02 11:54:05,738 - INFO - ðŸªœ Batch step - 676 -- sub batch step 2706 -- lr 1.01e-04
2025-03-02 11:54:07,896 - INFO - ðŸªœ Batch step - 676 -- sub batch step 2707 -- lr 1.01e-04
2025-03-02 11:54:09,418 - INFO - Step 676 -- ðŸ”„ Training Metrics
2025-03-02 11:54:09,418 - INFO - â”œâ”€â”€ Loss: 9.8239
2025-03-02 11:54:09,419 - INFO - â”œâ”€â”€ Learning Rate: 1.01e-04
2025-03-02 11:54:09,419 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:54:10,088 - INFO - ðŸªœ Batch step - 677 -- sub batch step 2708 -- lr 1.02e-04
2025-03-02 11:54:12,243 - INFO - ðŸªœ Batch step - 677 -- sub batch step 2709 -- lr 1.02e-04
2025-03-02 11:54:14,967 - INFO - ðŸªœ Batch step - 677 -- sub batch step 2710 -- lr 1.02e-04
2025-03-02 11:54:17,122 - INFO - ðŸªœ Batch step - 677 -- sub batch step 2711 -- lr 1.02e-04
2025-03-02 11:54:18,668 - INFO - Step 677 -- ðŸ”„ Training Metrics
2025-03-02 11:54:18,669 - INFO - â”œâ”€â”€ Loss: 9.8129
2025-03-02 11:54:18,669 - INFO - â”œâ”€â”€ Learning Rate: 1.02e-04
2025-03-02 11:54:18,669 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:54:19,343 - INFO - ðŸªœ Batch step - 678 -- sub batch step 2712 -- lr 1.02e-04
2025-03-02 11:54:21,491 - INFO - ðŸªœ Batch step - 678 -- sub batch step 2713 -- lr 1.02e-04
2025-03-02 11:54:23,660 - INFO - ðŸªœ Batch step - 678 -- sub batch step 2714 -- lr 1.02e-04
2025-03-02 11:54:25,814 - INFO - ðŸªœ Batch step - 678 -- sub batch step 2715 -- lr 1.02e-04
2025-03-02 11:54:27,364 - INFO - Step 678 -- ðŸ”„ Training Metrics
2025-03-02 11:54:27,365 - INFO - â”œâ”€â”€ Loss: 9.8036
2025-03-02 11:54:27,365 - INFO - â”œâ”€â”€ Learning Rate: 1.02e-04
2025-03-02 11:54:27,365 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:54:28,033 - INFO - ðŸªœ Batch step - 679 -- sub batch step 2716 -- lr 1.02e-04
2025-03-02 11:54:30,188 - INFO - ðŸªœ Batch step - 679 -- sub batch step 2717 -- lr 1.02e-04
2025-03-02 11:54:32,472 - INFO - ðŸªœ Batch step - 679 -- sub batch step 2718 -- lr 1.02e-04
2025-03-02 11:54:34,626 - INFO - ðŸªœ Batch step - 679 -- sub batch step 2719 -- lr 1.02e-04
2025-03-02 11:54:36,153 - INFO - Step 679 -- ðŸ”„ Training Metrics
2025-03-02 11:54:36,153 - INFO - â”œâ”€â”€ Loss: 9.7977
2025-03-02 11:54:36,153 - INFO - â”œâ”€â”€ Learning Rate: 1.02e-04
2025-03-02 11:54:36,153 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:54:37,388 - INFO - ðŸªœ Batch step - 680 -- sub batch step 2720 -- lr 1.02e-04
2025-03-02 11:54:39,544 - INFO - ðŸªœ Batch step - 680 -- sub batch step 2721 -- lr 1.02e-04
2025-03-02 11:54:41,711 - INFO - ðŸªœ Batch step - 680 -- sub batch step 2722 -- lr 1.02e-04
2025-03-02 11:54:43,888 - INFO - ðŸªœ Batch step - 680 -- sub batch step 2723 -- lr 1.02e-04
2025-03-02 11:54:45,562 - INFO - Step 680 -- ðŸ”„ Training Metrics
2025-03-02 11:54:45,562 - INFO - â”œâ”€â”€ Loss: 9.8015
2025-03-02 11:54:45,562 - INFO - â”œâ”€â”€ Learning Rate: 1.02e-04
2025-03-02 11:54:45,562 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:54:46,239 - INFO - ðŸªœ Batch step - 681 -- sub batch step 2724 -- lr 1.02e-04
2025-03-02 11:54:48,399 - INFO - ðŸªœ Batch step - 681 -- sub batch step 2725 -- lr 1.02e-04
2025-03-02 11:54:50,548 - INFO - ðŸªœ Batch step - 681 -- sub batch step 2726 -- lr 1.02e-04
2025-03-02 11:54:53,032 - INFO - ðŸªœ Batch step - 681 -- sub batch step 2727 -- lr 1.02e-04
2025-03-02 11:54:54,808 - INFO - Step 681 -- ðŸ”„ Training Metrics
2025-03-02 11:54:54,809 - INFO - â”œâ”€â”€ Loss: 9.8080
2025-03-02 11:54:54,809 - INFO - â”œâ”€â”€ Learning Rate: 1.02e-04
2025-03-02 11:54:54,809 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:54:55,475 - INFO - ðŸªœ Batch step - 682 -- sub batch step 2728 -- lr 1.02e-04
2025-03-02 11:54:57,631 - INFO - ðŸªœ Batch step - 682 -- sub batch step 2729 -- lr 1.02e-04
2025-03-02 11:54:59,782 - INFO - ðŸªœ Batch step - 682 -- sub batch step 2730 -- lr 1.02e-04
2025-03-02 11:55:01,963 - INFO - ðŸªœ Batch step - 682 -- sub batch step 2731 -- lr 1.02e-04
2025-03-02 11:55:03,502 - INFO - Step 682 -- ðŸ”„ Training Metrics
2025-03-02 11:55:03,502 - INFO - â”œâ”€â”€ Loss: 9.7947
2025-03-02 11:55:03,502 - INFO - â”œâ”€â”€ Learning Rate: 1.02e-04
2025-03-02 11:55:03,503 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:55:04,178 - INFO - ðŸªœ Batch step - 683 -- sub batch step 2732 -- lr 1.02e-04
2025-03-02 11:55:06,329 - INFO - ðŸªœ Batch step - 683 -- sub batch step 2733 -- lr 1.02e-04
2025-03-02 11:55:08,487 - INFO - ðŸªœ Batch step - 683 -- sub batch step 2734 -- lr 1.02e-04
2025-03-02 11:55:10,856 - INFO - ðŸªœ Batch step - 683 -- sub batch step 2735 -- lr 1.02e-04
2025-03-02 11:55:12,631 - INFO - Step 683 -- ðŸ”„ Training Metrics
2025-03-02 11:55:12,631 - INFO - â”œâ”€â”€ Loss: 9.7823
2025-03-02 11:55:12,631 - INFO - â”œâ”€â”€ Learning Rate: 1.02e-04
2025-03-02 11:55:12,631 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:55:13,297 - INFO - ðŸªœ Batch step - 684 -- sub batch step 2736 -- lr 1.03e-04
2025-03-02 11:55:15,453 - INFO - ðŸªœ Batch step - 684 -- sub batch step 2737 -- lr 1.03e-04
2025-03-02 11:55:17,598 - INFO - ðŸªœ Batch step - 684 -- sub batch step 2738 -- lr 1.03e-04
2025-03-02 11:55:19,776 - INFO - ðŸªœ Batch step - 684 -- sub batch step 2739 -- lr 1.03e-04
2025-03-02 11:55:21,313 - INFO - Step 684 -- ðŸ”„ Training Metrics
2025-03-02 11:55:21,314 - INFO - â”œâ”€â”€ Loss: 9.7819
2025-03-02 11:55:21,314 - INFO - â”œâ”€â”€ Learning Rate: 1.03e-04
2025-03-02 11:55:21,314 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:55:21,984 - INFO - ðŸªœ Batch step - 685 -- sub batch step 2740 -- lr 1.03e-04
2025-03-02 11:55:24,130 - INFO - ðŸªœ Batch step - 685 -- sub batch step 2741 -- lr 1.03e-04
2025-03-02 11:55:26,282 - INFO - ðŸªœ Batch step - 685 -- sub batch step 2742 -- lr 1.03e-04
2025-03-02 11:55:29,069 - INFO - ðŸªœ Batch step - 685 -- sub batch step 2743 -- lr 1.03e-04
2025-03-02 11:55:30,617 - INFO - Step 685 -- ðŸ”„ Training Metrics
2025-03-02 11:55:30,617 - INFO - â”œâ”€â”€ Loss: 9.7739
2025-03-02 11:55:30,618 - INFO - â”œâ”€â”€ Learning Rate: 1.03e-04
2025-03-02 11:55:30,618 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:55:31,293 - INFO - ðŸªœ Batch step - 686 -- sub batch step 2744 -- lr 1.03e-04
2025-03-02 11:55:33,449 - INFO - ðŸªœ Batch step - 686 -- sub batch step 2745 -- lr 1.03e-04
2025-03-02 11:55:35,602 - INFO - ðŸªœ Batch step - 686 -- sub batch step 2746 -- lr 1.03e-04
2025-03-02 11:55:37,778 - INFO - ðŸªœ Batch step - 686 -- sub batch step 2747 -- lr 1.03e-04
2025-03-02 11:55:39,310 - INFO - Step 686 -- ðŸ”„ Training Metrics
2025-03-02 11:55:39,310 - INFO - â”œâ”€â”€ Loss: 9.7693
2025-03-02 11:55:39,310 - INFO - â”œâ”€â”€ Learning Rate: 1.03e-04
2025-03-02 11:55:39,310 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:55:39,978 - INFO - ðŸªœ Batch step - 687 -- sub batch step 2748 -- lr 1.03e-04
2025-03-02 11:55:42,130 - INFO - ðŸªœ Batch step - 687 -- sub batch step 2749 -- lr 1.03e-04
2025-03-02 11:55:44,284 - INFO - ðŸªœ Batch step - 687 -- sub batch step 2750 -- lr 1.03e-04
2025-03-02 11:55:46,896 - INFO - ðŸªœ Batch step - 687 -- sub batch step 2751 -- lr 1.03e-04
2025-03-02 11:55:48,586 - INFO - Step 687 -- ðŸ”„ Training Metrics
2025-03-02 11:55:48,586 - INFO - â”œâ”€â”€ Loss: 9.7774
2025-03-02 11:55:48,586 - INFO - â”œâ”€â”€ Learning Rate: 1.03e-04
2025-03-02 11:55:48,586 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:55:49,262 - INFO - ðŸªœ Batch step - 688 -- sub batch step 2752 -- lr 1.03e-04
2025-03-02 11:55:51,415 - INFO - ðŸªœ Batch step - 688 -- sub batch step 2753 -- lr 1.03e-04
2025-03-02 11:55:53,574 - INFO - ðŸªœ Batch step - 688 -- sub batch step 2754 -- lr 1.03e-04
2025-03-02 11:55:55,751 - INFO - ðŸªœ Batch step - 688 -- sub batch step 2755 -- lr 1.03e-04
2025-03-02 11:55:57,282 - INFO - Step 688 -- ðŸ”„ Training Metrics
2025-03-02 11:55:57,282 - INFO - â”œâ”€â”€ Loss: 9.7533
2025-03-02 11:55:57,282 - INFO - â”œâ”€â”€ Learning Rate: 1.03e-04
2025-03-02 11:55:57,282 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:55:57,947 - INFO - ðŸªœ Batch step - 689 -- sub batch step 2756 -- lr 1.03e-04
2025-03-02 11:56:00,102 - INFO - ðŸªœ Batch step - 689 -- sub batch step 2757 -- lr 1.03e-04
2025-03-02 11:56:02,250 - INFO - ðŸªœ Batch step - 689 -- sub batch step 2758 -- lr 1.03e-04
2025-03-02 11:56:04,880 - INFO - ðŸªœ Batch step - 689 -- sub batch step 2759 -- lr 1.03e-04
2025-03-02 11:56:06,372 - INFO - Step 689 -- ðŸ”„ Training Metrics
2025-03-02 11:56:06,373 - INFO - â”œâ”€â”€ Loss: 9.7591
2025-03-02 11:56:06,373 - INFO - â”œâ”€â”€ Learning Rate: 1.03e-04
2025-03-02 11:56:06,373 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:56:07,047 - INFO - ðŸªœ Batch step - 690 -- sub batch step 2760 -- lr 1.03e-04
2025-03-02 11:56:09,197 - INFO - ðŸªœ Batch step - 690 -- sub batch step 2761 -- lr 1.03e-04
2025-03-02 11:56:11,353 - INFO - ðŸªœ Batch step - 690 -- sub batch step 2762 -- lr 1.03e-04
2025-03-02 11:56:13,513 - INFO - ðŸªœ Batch step - 690 -- sub batch step 2763 -- lr 1.03e-04
2025-03-02 11:56:15,066 - INFO - Step 690 -- ðŸ”„ Training Metrics
2025-03-02 11:56:15,067 - INFO - â”œâ”€â”€ Loss: 9.7482
2025-03-02 11:56:15,067 - INFO - â”œâ”€â”€ Learning Rate: 1.03e-04
2025-03-02 11:56:15,067 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:56:15,739 - INFO - ðŸªœ Batch step - 691 -- sub batch step 2764 -- lr 1.04e-04
2025-03-02 11:56:17,895 - INFO - ðŸªœ Batch step - 691 -- sub batch step 2765 -- lr 1.04e-04
2025-03-02 11:56:20,267 - INFO - ðŸªœ Batch step - 691 -- sub batch step 2766 -- lr 1.04e-04
2025-03-02 11:56:22,432 - INFO - ðŸªœ Batch step - 691 -- sub batch step 2767 -- lr 1.04e-04
2025-03-02 11:56:24,392 - INFO - Step 691 -- ðŸ”„ Training Metrics
2025-03-02 11:56:24,392 - INFO - â”œâ”€â”€ Loss: 9.7317
2025-03-02 11:56:24,392 - INFO - â”œâ”€â”€ Learning Rate: 1.04e-04
2025-03-02 11:56:24,392 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:56:25,063 - INFO - ðŸªœ Batch step - 692 -- sub batch step 2768 -- lr 1.04e-04
2025-03-02 11:56:27,216 - INFO - ðŸªœ Batch step - 692 -- sub batch step 2769 -- lr 1.04e-04
2025-03-02 11:56:29,397 - INFO - ðŸªœ Batch step - 692 -- sub batch step 2770 -- lr 1.04e-04
2025-03-02 11:56:31,546 - INFO - ðŸªœ Batch step - 692 -- sub batch step 2771 -- lr 1.04e-04
2025-03-02 11:56:33,071 - INFO - Step 692 -- ðŸ”„ Training Metrics
2025-03-02 11:56:33,072 - INFO - â”œâ”€â”€ Loss: 9.7310
2025-03-02 11:56:33,072 - INFO - â”œâ”€â”€ Learning Rate: 1.04e-04
2025-03-02 11:56:33,072 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:56:33,744 - INFO - ðŸªœ Batch step - 693 -- sub batch step 2772 -- lr 1.04e-04
2025-03-02 11:56:35,891 - INFO - ðŸªœ Batch step - 693 -- sub batch step 2773 -- lr 1.04e-04
2025-03-02 11:56:38,330 - INFO - ðŸªœ Batch step - 693 -- sub batch step 2774 -- lr 1.04e-04
2025-03-02 11:56:40,485 - INFO - ðŸªœ Batch step - 693 -- sub batch step 2775 -- lr 1.04e-04
2025-03-02 11:56:42,459 - INFO - Step 693 -- ðŸ”„ Training Metrics
2025-03-02 11:56:42,459 - INFO - â”œâ”€â”€ Loss: 9.7231
2025-03-02 11:56:42,459 - INFO - â”œâ”€â”€ Learning Rate: 1.04e-04
2025-03-02 11:56:42,459 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:56:43,127 - INFO - ðŸªœ Batch step - 694 -- sub batch step 2776 -- lr 1.04e-04
2025-03-02 11:56:45,281 - INFO - ðŸªœ Batch step - 694 -- sub batch step 2777 -- lr 1.04e-04
2025-03-02 11:56:47,450 - INFO - ðŸªœ Batch step - 694 -- sub batch step 2778 -- lr 1.04e-04
2025-03-02 11:56:49,606 - INFO - ðŸªœ Batch step - 694 -- sub batch step 2779 -- lr 1.04e-04
2025-03-02 11:56:51,151 - INFO - Step 694 -- ðŸ”„ Training Metrics
2025-03-02 11:56:51,151 - INFO - â”œâ”€â”€ Loss: 9.7267
2025-03-02 11:56:51,152 - INFO - â”œâ”€â”€ Learning Rate: 1.04e-04
2025-03-02 11:56:51,152 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:56:51,825 - INFO - ðŸªœ Batch step - 695 -- sub batch step 2780 -- lr 1.04e-04
2025-03-02 11:56:53,973 - INFO - ðŸªœ Batch step - 695 -- sub batch step 2781 -- lr 1.04e-04
2025-03-02 11:56:56,650 - INFO - ðŸªœ Batch step - 695 -- sub batch step 2782 -- lr 1.04e-04
2025-03-02 11:56:58,801 - INFO - ðŸªœ Batch step - 695 -- sub batch step 2783 -- lr 1.04e-04
2025-03-02 11:57:00,409 - INFO - Step 695 -- ðŸ”„ Training Metrics
2025-03-02 11:57:00,409 - INFO - â”œâ”€â”€ Loss: 9.7159
2025-03-02 11:57:00,410 - INFO - â”œâ”€â”€ Learning Rate: 1.04e-04
2025-03-02 11:57:00,410 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:57:01,086 - INFO - ðŸªœ Batch step - 696 -- sub batch step 2784 -- lr 1.04e-04
2025-03-02 11:57:03,245 - INFO - ðŸªœ Batch step - 696 -- sub batch step 2785 -- lr 1.04e-04
2025-03-02 11:57:05,416 - INFO - ðŸªœ Batch step - 696 -- sub batch step 2786 -- lr 1.04e-04
2025-03-02 11:57:07,568 - INFO - ðŸªœ Batch step - 696 -- sub batch step 2787 -- lr 1.04e-04
2025-03-02 11:57:09,094 - INFO - Step 696 -- ðŸ”„ Training Metrics
2025-03-02 11:57:09,095 - INFO - â”œâ”€â”€ Loss: 9.7044
2025-03-02 11:57:09,095 - INFO - â”œâ”€â”€ Learning Rate: 1.04e-04
2025-03-02 11:57:09,095 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:57:09,763 - INFO - ðŸªœ Batch step - 697 -- sub batch step 2788 -- lr 1.05e-04
2025-03-02 11:57:11,915 - INFO - ðŸªœ Batch step - 697 -- sub batch step 2789 -- lr 1.05e-04
2025-03-02 11:57:14,541 - INFO - ðŸªœ Batch step - 697 -- sub batch step 2790 -- lr 1.05e-04
2025-03-02 11:57:16,700 - INFO - ðŸªœ Batch step - 697 -- sub batch step 2791 -- lr 1.05e-04
2025-03-02 11:57:18,322 - INFO - Step 697 -- ðŸ”„ Training Metrics
2025-03-02 11:57:18,322 - INFO - â”œâ”€â”€ Loss: 9.6942
2025-03-02 11:57:18,336 - INFO - â”œâ”€â”€ Learning Rate: 1.05e-04
2025-03-02 11:57:18,336 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:57:19,012 - INFO - ðŸªœ Batch step - 698 -- sub batch step 2792 -- lr 1.05e-04
2025-03-02 11:57:21,168 - INFO - ðŸªœ Batch step - 698 -- sub batch step 2793 -- lr 1.05e-04
2025-03-02 11:57:23,352 - INFO - ðŸªœ Batch step - 698 -- sub batch step 2794 -- lr 1.05e-04
2025-03-02 11:57:25,509 - INFO - ðŸªœ Batch step - 698 -- sub batch step 2795 -- lr 1.05e-04
2025-03-02 11:57:27,027 - INFO - Step 698 -- ðŸ”„ Training Metrics
2025-03-02 11:57:27,027 - INFO - â”œâ”€â”€ Loss: 9.7030
2025-03-02 11:57:27,027 - INFO - â”œâ”€â”€ Learning Rate: 1.05e-04
2025-03-02 11:57:27,027 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:57:27,701 - INFO - ðŸªœ Batch step - 699 -- sub batch step 2796 -- lr 1.05e-04
2025-03-02 11:57:29,858 - INFO - ðŸªœ Batch step - 699 -- sub batch step 2797 -- lr 1.05e-04
2025-03-02 11:57:32,141 - INFO - ðŸªœ Batch step - 699 -- sub batch step 2798 -- lr 1.05e-04
2025-03-02 11:57:34,295 - INFO - ðŸªœ Batch step - 699 -- sub batch step 2799 -- lr 1.05e-04
2025-03-02 11:57:35,885 - INFO - Step 699 -- ðŸ”„ Training Metrics
2025-03-02 11:57:35,885 - INFO - â”œâ”€â”€ Loss: 9.6833
2025-03-02 11:57:35,886 - INFO - â”œâ”€â”€ Learning Rate: 1.05e-04
2025-03-02 11:57:35,886 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:57:37,106 - INFO - ðŸªœ Batch step - 700 -- sub batch step 2800 -- lr 1.05e-04
2025-03-02 11:57:39,265 - INFO - ðŸªœ Batch step - 700 -- sub batch step 2801 -- lr 1.05e-04
2025-03-02 11:57:41,430 - INFO - ðŸªœ Batch step - 700 -- sub batch step 2802 -- lr 1.05e-04
2025-03-02 11:57:43,611 - INFO - ðŸªœ Batch step - 700 -- sub batch step 2803 -- lr 1.05e-04
2025-03-02 11:57:45,189 - INFO - Step 700 -- ðŸ”„ Training Metrics
2025-03-02 11:57:45,189 - INFO - â”œâ”€â”€ Loss: 9.6933
2025-03-02 11:57:45,189 - INFO - â”œâ”€â”€ Learning Rate: 1.05e-04
2025-03-02 11:57:45,190 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:57:45,875 - INFO - ðŸªœ Batch step - 701 -- sub batch step 2804 -- lr 1.05e-04
2025-03-02 11:57:48,039 - INFO - ðŸªœ Batch step - 701 -- sub batch step 2805 -- lr 1.05e-04
2025-03-02 11:57:50,199 - INFO - ðŸªœ Batch step - 701 -- sub batch step 2806 -- lr 1.05e-04
2025-03-02 11:57:52,629 - INFO - ðŸªœ Batch step - 701 -- sub batch step 2807 -- lr 1.05e-04
2025-03-02 11:57:54,510 - INFO - Step 701 -- ðŸ”„ Training Metrics
2025-03-02 11:57:54,510 - INFO - â”œâ”€â”€ Loss: 9.6826
2025-03-02 11:57:54,510 - INFO - â”œâ”€â”€ Learning Rate: 1.05e-04
2025-03-02 11:57:54,510 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:57:55,187 - INFO - ðŸªœ Batch step - 702 -- sub batch step 2808 -- lr 1.05e-04
2025-03-02 11:57:57,351 - INFO - ðŸªœ Batch step - 702 -- sub batch step 2809 -- lr 1.05e-04
2025-03-02 11:57:59,512 - INFO - ðŸªœ Batch step - 702 -- sub batch step 2810 -- lr 1.05e-04
2025-03-02 11:58:01,682 - INFO - ðŸªœ Batch step - 702 -- sub batch step 2811 -- lr 1.05e-04
2025-03-02 11:58:03,213 - INFO - Step 702 -- ðŸ”„ Training Metrics
2025-03-02 11:58:03,214 - INFO - â”œâ”€â”€ Loss: 9.6809
2025-03-02 11:58:03,214 - INFO - â”œâ”€â”€ Learning Rate: 1.05e-04
2025-03-02 11:58:03,214 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:58:03,890 - INFO - ðŸªœ Batch step - 703 -- sub batch step 2812 -- lr 1.05e-04
2025-03-02 11:58:06,039 - INFO - ðŸªœ Batch step - 703 -- sub batch step 2813 -- lr 1.05e-04
2025-03-02 11:58:08,188 - INFO - ðŸªœ Batch step - 703 -- sub batch step 2814 -- lr 1.05e-04
2025-03-02 11:58:10,564 - INFO - ðŸªœ Batch step - 703 -- sub batch step 2815 -- lr 1.05e-04
2025-03-02 11:58:12,527 - INFO - Step 703 -- ðŸ”„ Training Metrics
2025-03-02 11:58:12,527 - INFO - â”œâ”€â”€ Loss: 9.6753
2025-03-02 11:58:12,527 - INFO - â”œâ”€â”€ Learning Rate: 1.05e-04
2025-03-02 11:58:12,528 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:58:13,198 - INFO - ðŸªœ Batch step - 704 -- sub batch step 2816 -- lr 1.06e-04
2025-03-02 11:58:15,355 - INFO - ðŸªœ Batch step - 704 -- sub batch step 2817 -- lr 1.06e-04
2025-03-02 11:58:17,506 - INFO - ðŸªœ Batch step - 704 -- sub batch step 2818 -- lr 1.06e-04
2025-03-02 11:58:19,686 - INFO - ðŸªœ Batch step - 704 -- sub batch step 2819 -- lr 1.06e-04
2025-03-02 11:58:21,217 - INFO - Step 704 -- ðŸ”„ Training Metrics
2025-03-02 11:58:21,217 - INFO - â”œâ”€â”€ Loss: 9.6646
2025-03-02 11:58:21,217 - INFO - â”œâ”€â”€ Learning Rate: 1.06e-04
2025-03-02 11:58:21,217 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:58:21,896 - INFO - ðŸªœ Batch step - 705 -- sub batch step 2820 -- lr 1.06e-04
2025-03-02 11:58:24,049 - INFO - ðŸªœ Batch step - 705 -- sub batch step 2821 -- lr 1.06e-04
2025-03-02 11:58:26,206 - INFO - ðŸªœ Batch step - 705 -- sub batch step 2822 -- lr 1.06e-04
2025-03-02 11:58:28,573 - INFO - ðŸªœ Batch step - 705 -- sub batch step 2823 -- lr 1.06e-04
2025-03-02 11:58:30,535 - INFO - Step 705 -- ðŸ”„ Training Metrics
2025-03-02 11:58:30,535 - INFO - â”œâ”€â”€ Loss: 9.6574
2025-03-02 11:58:30,536 - INFO - â”œâ”€â”€ Learning Rate: 1.06e-04
2025-03-02 11:58:30,536 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:58:31,218 - INFO - ðŸªœ Batch step - 706 -- sub batch step 2824 -- lr 1.06e-04
2025-03-02 11:58:33,377 - INFO - ðŸªœ Batch step - 706 -- sub batch step 2825 -- lr 1.06e-04
2025-03-02 11:58:35,537 - INFO - ðŸªœ Batch step - 706 -- sub batch step 2826 -- lr 1.06e-04
2025-03-02 11:58:37,718 - INFO - ðŸªœ Batch step - 706 -- sub batch step 2827 -- lr 1.06e-04
2025-03-02 11:58:39,232 - INFO - Step 706 -- ðŸ”„ Training Metrics
2025-03-02 11:58:39,233 - INFO - â”œâ”€â”€ Loss: 9.6362
2025-03-02 11:58:39,233 - INFO - â”œâ”€â”€ Learning Rate: 1.06e-04
2025-03-02 11:58:39,233 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:58:39,907 - INFO - ðŸªœ Batch step - 707 -- sub batch step 2828 -- lr 1.06e-04
2025-03-02 11:58:42,072 - INFO - ðŸªœ Batch step - 707 -- sub batch step 2829 -- lr 1.06e-04
2025-03-02 11:58:44,232 - INFO - ðŸªœ Batch step - 707 -- sub batch step 2830 -- lr 1.06e-04
2025-03-02 11:58:47,031 - INFO - ðŸªœ Batch step - 707 -- sub batch step 2831 -- lr 1.06e-04
2025-03-02 11:58:48,523 - INFO - Step 707 -- ðŸ”„ Training Metrics
2025-03-02 11:58:48,523 - INFO - â”œâ”€â”€ Loss: 9.6483
2025-03-02 11:58:48,523 - INFO - â”œâ”€â”€ Learning Rate: 1.06e-04
2025-03-02 11:58:48,523 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:58:49,199 - INFO - ðŸªœ Batch step - 708 -- sub batch step 2832 -- lr 1.06e-04
2025-03-02 11:58:51,350 - INFO - ðŸªœ Batch step - 708 -- sub batch step 2833 -- lr 1.06e-04
2025-03-02 11:58:53,504 - INFO - ðŸªœ Batch step - 708 -- sub batch step 2834 -- lr 1.06e-04
2025-03-02 11:58:55,686 - INFO - ðŸªœ Batch step - 708 -- sub batch step 2835 -- lr 1.06e-04
2025-03-02 11:58:57,222 - INFO - Step 708 -- ðŸ”„ Training Metrics
2025-03-02 11:58:57,223 - INFO - â”œâ”€â”€ Loss: 9.6359
2025-03-02 11:58:57,223 - INFO - â”œâ”€â”€ Learning Rate: 1.06e-04
2025-03-02 11:58:57,223 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:58:57,894 - INFO - ðŸªœ Batch step - 709 -- sub batch step 2836 -- lr 1.06e-04
2025-03-02 11:59:00,051 - INFO - ðŸªœ Batch step - 709 -- sub batch step 2837 -- lr 1.06e-04
2025-03-02 11:59:02,200 - INFO - ðŸªœ Batch step - 709 -- sub batch step 2838 -- lr 1.06e-04
2025-03-02 11:59:04,586 - INFO - ðŸªœ Batch step - 709 -- sub batch step 2839 -- lr 1.06e-04
2025-03-02 11:59:06,445 - INFO - Step 709 -- ðŸ”„ Training Metrics
2025-03-02 11:59:06,445 - INFO - â”œâ”€â”€ Loss: 9.6213
2025-03-02 11:59:06,445 - INFO - â”œâ”€â”€ Learning Rate: 1.06e-04
2025-03-02 11:59:06,445 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:59:07,119 - INFO - ðŸªœ Batch step - 710 -- sub batch step 2840 -- lr 1.06e-04
2025-03-02 11:59:09,269 - INFO - ðŸªœ Batch step - 710 -- sub batch step 2841 -- lr 1.06e-04
2025-03-02 11:59:11,422 - INFO - ðŸªœ Batch step - 710 -- sub batch step 2842 -- lr 1.06e-04
2025-03-02 11:59:13,582 - INFO - ðŸªœ Batch step - 710 -- sub batch step 2843 -- lr 1.06e-04
2025-03-02 11:59:15,136 - INFO - Step 710 -- ðŸ”„ Training Metrics
2025-03-02 11:59:15,136 - INFO - â”œâ”€â”€ Loss: 9.6157
2025-03-02 11:59:15,136 - INFO - â”œâ”€â”€ Learning Rate: 1.06e-04
2025-03-02 11:59:15,136 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:59:15,810 - INFO - ðŸªœ Batch step - 711 -- sub batch step 2844 -- lr 1.07e-04
2025-03-02 11:59:17,965 - INFO - ðŸªœ Batch step - 711 -- sub batch step 2845 -- lr 1.07e-04
2025-03-02 11:59:20,330 - INFO - ðŸªœ Batch step - 711 -- sub batch step 2846 -- lr 1.07e-04
2025-03-02 11:59:22,491 - INFO - ðŸªœ Batch step - 711 -- sub batch step 2847 -- lr 1.07e-04
2025-03-02 11:59:24,483 - INFO - Step 711 -- ðŸ”„ Training Metrics
2025-03-02 11:59:24,483 - INFO - â”œâ”€â”€ Loss: 9.6090
2025-03-02 11:59:24,484 - INFO - â”œâ”€â”€ Learning Rate: 1.07e-04
2025-03-02 11:59:24,484 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:59:25,151 - INFO - ðŸªœ Batch step - 712 -- sub batch step 2848 -- lr 1.07e-04
2025-03-02 11:59:27,310 - INFO - ðŸªœ Batch step - 712 -- sub batch step 2849 -- lr 1.07e-04
2025-03-02 11:59:29,492 - INFO - ðŸªœ Batch step - 712 -- sub batch step 2850 -- lr 1.07e-04
2025-03-02 11:59:31,640 - INFO - ðŸªœ Batch step - 712 -- sub batch step 2851 -- lr 1.07e-04
2025-03-02 11:59:33,177 - INFO - Step 712 -- ðŸ”„ Training Metrics
2025-03-02 11:59:33,178 - INFO - â”œâ”€â”€ Loss: 9.6063
2025-03-02 11:59:33,178 - INFO - â”œâ”€â”€ Learning Rate: 1.07e-04
2025-03-02 11:59:33,178 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:59:33,854 - INFO - ðŸªœ Batch step - 713 -- sub batch step 2852 -- lr 1.07e-04
2025-03-02 11:59:36,002 - INFO - ðŸªœ Batch step - 713 -- sub batch step 2853 -- lr 1.07e-04
2025-03-02 11:59:38,943 - INFO - ðŸªœ Batch step - 713 -- sub batch step 2854 -- lr 1.07e-04
2025-03-02 11:59:41,104 - INFO - ðŸªœ Batch step - 713 -- sub batch step 2855 -- lr 1.07e-04
2025-03-02 11:59:42,599 - INFO - Step 713 -- ðŸ”„ Training Metrics
2025-03-02 11:59:42,599 - INFO - â”œâ”€â”€ Loss: 9.6108
2025-03-02 11:59:42,599 - INFO - â”œâ”€â”€ Learning Rate: 1.07e-04
2025-03-02 11:59:42,599 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:59:43,271 - INFO - ðŸªœ Batch step - 714 -- sub batch step 2856 -- lr 1.07e-04
2025-03-02 11:59:45,425 - INFO - ðŸªœ Batch step - 714 -- sub batch step 2857 -- lr 1.07e-04
2025-03-02 11:59:47,603 - INFO - ðŸªœ Batch step - 714 -- sub batch step 2858 -- lr 1.07e-04
2025-03-02 11:59:49,761 - INFO - ðŸªœ Batch step - 714 -- sub batch step 2859 -- lr 1.07e-04
2025-03-02 11:59:51,310 - INFO - Step 714 -- ðŸ”„ Training Metrics
2025-03-02 11:59:51,310 - INFO - â”œâ”€â”€ Loss: 9.6033
2025-03-02 11:59:51,310 - INFO - â”œâ”€â”€ Learning Rate: 1.07e-04
2025-03-02 11:59:51,310 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 11:59:51,989 - INFO - ðŸªœ Batch step - 715 -- sub batch step 2860 -- lr 1.07e-04
2025-03-02 11:59:54,139 - INFO - ðŸªœ Batch step - 715 -- sub batch step 2861 -- lr 1.07e-04
2025-03-02 11:59:56,600 - INFO - ðŸªœ Batch step - 715 -- sub batch step 2862 -- lr 1.07e-04
2025-03-02 11:59:58,752 - INFO - ðŸªœ Batch step - 715 -- sub batch step 2863 -- lr 1.07e-04
2025-03-02 12:00:00,639 - INFO - Step 715 -- ðŸ”„ Training Metrics
2025-03-02 12:00:00,639 - INFO - â”œâ”€â”€ Loss: 9.5893
2025-03-02 12:00:00,640 - INFO - â”œâ”€â”€ Learning Rate: 1.07e-04
2025-03-02 12:00:00,640 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:00:01,317 - INFO - ðŸªœ Batch step - 716 -- sub batch step 2864 -- lr 1.07e-04
2025-03-02 12:00:03,473 - INFO - ðŸªœ Batch step - 716 -- sub batch step 2865 -- lr 1.07e-04
2025-03-02 12:00:05,645 - INFO - ðŸªœ Batch step - 716 -- sub batch step 2866 -- lr 1.07e-04
2025-03-02 12:00:07,798 - INFO - ðŸªœ Batch step - 716 -- sub batch step 2867 -- lr 1.07e-04
2025-03-02 12:00:09,357 - INFO - Step 716 -- ðŸ”„ Training Metrics
2025-03-02 12:00:09,358 - INFO - â”œâ”€â”€ Loss: 9.5777
2025-03-02 12:00:09,358 - INFO - â”œâ”€â”€ Learning Rate: 1.07e-04
2025-03-02 12:00:09,358 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:00:10,024 - INFO - ðŸªœ Batch step - 717 -- sub batch step 2868 -- lr 1.08e-04
2025-03-02 12:00:12,187 - INFO - ðŸªœ Batch step - 717 -- sub batch step 2869 -- lr 1.08e-04
2025-03-02 12:00:14,879 - INFO - ðŸªœ Batch step - 717 -- sub batch step 2870 -- lr 1.08e-04
2025-03-02 12:00:17,033 - INFO - ðŸªœ Batch step - 717 -- sub batch step 2871 -- lr 1.08e-04
2025-03-02 12:00:18,561 - INFO - Step 717 -- ðŸ”„ Training Metrics
2025-03-02 12:00:18,561 - INFO - â”œâ”€â”€ Loss: 9.5850
2025-03-02 12:00:18,561 - INFO - â”œâ”€â”€ Learning Rate: 1.08e-04
2025-03-02 12:00:18,561 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:00:19,237 - INFO - ðŸªœ Batch step - 718 -- sub batch step 2872 -- lr 1.08e-04
2025-03-02 12:00:21,391 - INFO - ðŸªœ Batch step - 718 -- sub batch step 2873 -- lr 1.08e-04
2025-03-02 12:00:23,570 - INFO - ðŸªœ Batch step - 718 -- sub batch step 2874 -- lr 1.08e-04
2025-03-02 12:00:25,725 - INFO - ðŸªœ Batch step - 718 -- sub batch step 2875 -- lr 1.08e-04
2025-03-02 12:00:27,271 - INFO - Step 718 -- ðŸ”„ Training Metrics
2025-03-02 12:00:27,271 - INFO - â”œâ”€â”€ Loss: 9.5829
2025-03-02 12:00:27,271 - INFO - â”œâ”€â”€ Learning Rate: 1.08e-04
2025-03-02 12:00:27,272 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:00:27,943 - INFO - ðŸªœ Batch step - 719 -- sub batch step 2876 -- lr 1.08e-04
2025-03-02 12:00:30,099 - INFO - ðŸªœ Batch step - 719 -- sub batch step 2877 -- lr 1.08e-04
2025-03-02 12:00:32,385 - INFO - ðŸªœ Batch step - 719 -- sub batch step 2878 -- lr 1.08e-04
2025-03-02 12:00:34,536 - INFO - ðŸªœ Batch step - 719 -- sub batch step 2879 -- lr 1.08e-04
2025-03-02 12:00:36,113 - INFO - Step 719 -- ðŸ”„ Training Metrics
2025-03-02 12:00:36,113 - INFO - â”œâ”€â”€ Loss: 9.5652
2025-03-02 12:00:36,113 - INFO - â”œâ”€â”€ Learning Rate: 1.08e-04
2025-03-02 12:00:36,113 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:00:37,345 - INFO - ðŸªœ Batch step - 720 -- sub batch step 2880 -- lr 1.08e-04
2025-03-02 12:00:39,498 - INFO - ðŸªœ Batch step - 720 -- sub batch step 2881 -- lr 1.08e-04
2025-03-02 12:00:41,659 - INFO - ðŸªœ Batch step - 720 -- sub batch step 2882 -- lr 1.08e-04
2025-03-02 12:00:43,825 - INFO - ðŸªœ Batch step - 720 -- sub batch step 2883 -- lr 1.08e-04
2025-03-02 12:00:45,401 - INFO - Step 720 -- ðŸ”„ Training Metrics
2025-03-02 12:00:45,401 - INFO - â”œâ”€â”€ Loss: 9.5669
2025-03-02 12:00:45,401 - INFO - â”œâ”€â”€ Learning Rate: 1.08e-04
2025-03-02 12:00:45,401 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:00:46,080 - INFO - ðŸªœ Batch step - 721 -- sub batch step 2884 -- lr 1.08e-04
2025-03-02 12:00:48,237 - INFO - ðŸªœ Batch step - 721 -- sub batch step 2885 -- lr 1.08e-04
2025-03-02 12:00:50,390 - INFO - ðŸªœ Batch step - 721 -- sub batch step 2886 -- lr 1.08e-04
2025-03-02 12:00:52,811 - INFO - ðŸªœ Batch step - 721 -- sub batch step 2887 -- lr 1.08e-04
2025-03-02 12:00:54,625 - INFO - Step 721 -- ðŸ”„ Training Metrics
2025-03-02 12:00:54,626 - INFO - â”œâ”€â”€ Loss: 9.5553
2025-03-02 12:00:54,626 - INFO - â”œâ”€â”€ Learning Rate: 1.08e-04
2025-03-02 12:00:54,626 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:00:55,293 - INFO - ðŸªœ Batch step - 722 -- sub batch step 2888 -- lr 1.08e-04
2025-03-02 12:00:57,444 - INFO - ðŸªœ Batch step - 722 -- sub batch step 2889 -- lr 1.08e-04
2025-03-02 12:00:59,595 - INFO - ðŸªœ Batch step - 722 -- sub batch step 2890 -- lr 1.08e-04
2025-03-02 12:01:01,753 - INFO - ðŸªœ Batch step - 722 -- sub batch step 2891 -- lr 1.08e-04
2025-03-02 12:01:03,304 - INFO - Step 722 -- ðŸ”„ Training Metrics
2025-03-02 12:01:03,304 - INFO - â”œâ”€â”€ Loss: 9.5499
2025-03-02 12:01:03,304 - INFO - â”œâ”€â”€ Learning Rate: 1.08e-04
2025-03-02 12:01:03,304 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:01:03,978 - INFO - ðŸªœ Batch step - 723 -- sub batch step 2892 -- lr 1.08e-04
2025-03-02 12:01:06,126 - INFO - ðŸªœ Batch step - 723 -- sub batch step 2893 -- lr 1.08e-04
2025-03-02 12:01:08,284 - INFO - ðŸªœ Batch step - 723 -- sub batch step 2894 -- lr 1.08e-04
2025-03-02 12:01:10,662 - INFO - ðŸªœ Batch step - 723 -- sub batch step 2895 -- lr 1.08e-04
2025-03-02 12:01:12,616 - INFO - Step 723 -- ðŸ”„ Training Metrics
2025-03-02 12:01:12,616 - INFO - â”œâ”€â”€ Loss: 9.5448
2025-03-02 12:01:12,616 - INFO - â”œâ”€â”€ Learning Rate: 1.08e-04
2025-03-02 12:01:12,616 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:01:13,284 - INFO - ðŸªœ Batch step - 724 -- sub batch step 2896 -- lr 1.09e-04
2025-03-02 12:01:15,441 - INFO - ðŸªœ Batch step - 724 -- sub batch step 2897 -- lr 1.09e-04
2025-03-02 12:01:17,584 - INFO - ðŸªœ Batch step - 724 -- sub batch step 2898 -- lr 1.09e-04
2025-03-02 12:01:19,756 - INFO - ðŸªœ Batch step - 724 -- sub batch step 2899 -- lr 1.09e-04
2025-03-02 12:01:21,300 - INFO - Step 724 -- ðŸ”„ Training Metrics
2025-03-02 12:01:21,301 - INFO - â”œâ”€â”€ Loss: 9.5326
2025-03-02 12:01:21,301 - INFO - â”œâ”€â”€ Learning Rate: 1.09e-04
2025-03-02 12:01:21,301 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:01:21,973 - INFO - ðŸªœ Batch step - 725 -- sub batch step 2900 -- lr 1.09e-04
2025-03-02 12:01:24,121 - INFO - ðŸªœ Batch step - 725 -- sub batch step 2901 -- lr 1.09e-04
2025-03-02 12:01:26,273 - INFO - ðŸªœ Batch step - 725 -- sub batch step 2902 -- lr 1.09e-04
2025-03-02 12:01:28,629 - INFO - ðŸªœ Batch step - 725 -- sub batch step 2903 -- lr 1.09e-04
2025-03-02 12:01:30,613 - INFO - Step 725 -- ðŸ”„ Training Metrics
2025-03-02 12:01:30,613 - INFO - â”œâ”€â”€ Loss: 9.5310
2025-03-02 12:01:30,613 - INFO - â”œâ”€â”€ Learning Rate: 1.09e-04
2025-03-02 12:01:30,613 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:01:31,288 - INFO - ðŸªœ Batch step - 726 -- sub batch step 2904 -- lr 1.09e-04
2025-03-02 12:01:33,442 - INFO - ðŸªœ Batch step - 726 -- sub batch step 2905 -- lr 1.09e-04
2025-03-02 12:01:35,595 - INFO - ðŸªœ Batch step - 726 -- sub batch step 2906 -- lr 1.09e-04
2025-03-02 12:01:37,760 - INFO - ðŸªœ Batch step - 726 -- sub batch step 2907 -- lr 1.09e-04
2025-03-02 12:01:39,298 - INFO - Step 726 -- ðŸ”„ Training Metrics
2025-03-02 12:01:39,299 - INFO - â”œâ”€â”€ Loss: 9.5211
2025-03-02 12:01:39,299 - INFO - â”œâ”€â”€ Learning Rate: 1.09e-04
2025-03-02 12:01:39,299 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:01:39,968 - INFO - ðŸªœ Batch step - 727 -- sub batch step 2908 -- lr 1.09e-04
2025-03-02 12:01:42,126 - INFO - ðŸªœ Batch step - 727 -- sub batch step 2909 -- lr 1.09e-04
2025-03-02 12:01:44,281 - INFO - ðŸªœ Batch step - 727 -- sub batch step 2910 -- lr 1.09e-04
2025-03-02 12:01:46,676 - INFO - ðŸªœ Batch step - 727 -- sub batch step 2911 -- lr 1.09e-04
2025-03-02 12:01:48,586 - INFO - Step 727 -- ðŸ”„ Training Metrics
2025-03-02 12:01:48,586 - INFO - â”œâ”€â”€ Loss: 9.5290
2025-03-02 12:01:48,586 - INFO - â”œâ”€â”€ Learning Rate: 1.09e-04
2025-03-02 12:01:48,586 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:01:49,261 - INFO - ðŸªœ Batch step - 728 -- sub batch step 2912 -- lr 1.09e-04
2025-03-02 12:01:51,409 - INFO - ðŸªœ Batch step - 728 -- sub batch step 2913 -- lr 1.09e-04
2025-03-02 12:01:53,570 - INFO - ðŸªœ Batch step - 728 -- sub batch step 2914 -- lr 1.09e-04
2025-03-02 12:01:55,744 - INFO - ðŸªœ Batch step - 728 -- sub batch step 2915 -- lr 1.09e-04
2025-03-02 12:01:57,259 - INFO - Step 728 -- ðŸ”„ Training Metrics
2025-03-02 12:01:57,260 - INFO - â”œâ”€â”€ Loss: 9.5022
2025-03-02 12:01:57,260 - INFO - â”œâ”€â”€ Learning Rate: 1.09e-04
2025-03-02 12:01:57,260 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:01:57,931 - INFO - ðŸªœ Batch step - 729 -- sub batch step 2916 -- lr 1.09e-04
2025-03-02 12:02:00,087 - INFO - ðŸªœ Batch step - 729 -- sub batch step 2917 -- lr 1.09e-04
2025-03-02 12:02:02,238 - INFO - ðŸªœ Batch step - 729 -- sub batch step 2918 -- lr 1.09e-04
2025-03-02 12:02:05,355 - INFO - ðŸªœ Batch step - 729 -- sub batch step 2919 -- lr 1.09e-04
2025-03-02 12:02:06,848 - INFO - Step 729 -- ðŸ”„ Training Metrics
2025-03-02 12:02:06,848 - INFO - â”œâ”€â”€ Loss: 9.5133
2025-03-02 12:02:06,849 - INFO - â”œâ”€â”€ Learning Rate: 1.09e-04
2025-03-02 12:02:06,849 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:02:07,520 - INFO - ðŸªœ Batch step - 730 -- sub batch step 2920 -- lr 1.09e-04
2025-03-02 12:02:09,670 - INFO - ðŸªœ Batch step - 730 -- sub batch step 2921 -- lr 1.09e-04
2025-03-02 12:02:11,825 - INFO - ðŸªœ Batch step - 730 -- sub batch step 2922 -- lr 1.09e-04
2025-03-02 12:02:13,992 - INFO - ðŸªœ Batch step - 730 -- sub batch step 2923 -- lr 1.09e-04
2025-03-02 12:02:15,523 - INFO - Step 730 -- ðŸ”„ Training Metrics
2025-03-02 12:02:15,523 - INFO - â”œâ”€â”€ Loss: 9.5131
2025-03-02 12:02:15,523 - INFO - â”œâ”€â”€ Learning Rate: 1.09e-04
2025-03-02 12:02:15,523 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:02:16,200 - INFO - ðŸªœ Batch step - 731 -- sub batch step 2924 -- lr 1.10e-04
2025-03-02 12:02:18,356 - INFO - ðŸªœ Batch step - 731 -- sub batch step 2925 -- lr 1.10e-04
2025-03-02 12:02:20,988 - INFO - ðŸªœ Batch step - 731 -- sub batch step 2926 -- lr 1.10e-04
2025-03-02 12:02:23,143 - INFO - ðŸªœ Batch step - 731 -- sub batch step 2927 -- lr 1.10e-04
2025-03-02 12:02:24,795 - INFO - Step 731 -- ðŸ”„ Training Metrics
2025-03-02 12:02:24,796 - INFO - â”œâ”€â”€ Loss: 9.4851
2025-03-02 12:02:24,796 - INFO - â”œâ”€â”€ Learning Rate: 1.10e-04
2025-03-02 12:02:24,796 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:02:25,464 - INFO - ðŸªœ Batch step - 732 -- sub batch step 2928 -- lr 1.10e-04
2025-03-02 12:02:27,620 - INFO - ðŸªœ Batch step - 732 -- sub batch step 2929 -- lr 1.10e-04
2025-03-02 12:02:29,790 - INFO - ðŸªœ Batch step - 732 -- sub batch step 2930 -- lr 1.10e-04
2025-03-02 12:02:31,934 - INFO - ðŸªœ Batch step - 732 -- sub batch step 2931 -- lr 1.10e-04
2025-03-02 12:02:33,481 - INFO - Step 732 -- ðŸ”„ Training Metrics
2025-03-02 12:02:33,481 - INFO - â”œâ”€â”€ Loss: 9.4986
2025-03-02 12:02:33,481 - INFO - â”œâ”€â”€ Learning Rate: 1.10e-04
2025-03-02 12:02:33,481 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:02:34,154 - INFO - ðŸªœ Batch step - 733 -- sub batch step 2932 -- lr 1.10e-04
2025-03-02 12:02:36,297 - INFO - ðŸªœ Batch step - 733 -- sub batch step 2933 -- lr 1.10e-04
2025-03-02 12:02:38,951 - INFO - ðŸªœ Batch step - 733 -- sub batch step 2934 -- lr 1.10e-04
2025-03-02 12:02:41,101 - INFO - ðŸªœ Batch step - 733 -- sub batch step 2935 -- lr 1.10e-04
2025-03-02 12:02:42,628 - INFO - Step 733 -- ðŸ”„ Training Metrics
2025-03-02 12:02:42,628 - INFO - â”œâ”€â”€ Loss: 9.4830
2025-03-02 12:02:42,628 - INFO - â”œâ”€â”€ Learning Rate: 1.10e-04
2025-03-02 12:02:42,628 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:02:43,292 - INFO - ðŸªœ Batch step - 734 -- sub batch step 2936 -- lr 1.10e-04
2025-03-02 12:02:45,444 - INFO - ðŸªœ Batch step - 734 -- sub batch step 2937 -- lr 1.10e-04
2025-03-02 12:02:47,608 - INFO - ðŸªœ Batch step - 734 -- sub batch step 2938 -- lr 1.10e-04
2025-03-02 12:02:49,760 - INFO - ðŸªœ Batch step - 734 -- sub batch step 2939 -- lr 1.10e-04
2025-03-02 12:02:51,302 - INFO - Step 734 -- ðŸ”„ Training Metrics
2025-03-02 12:02:51,302 - INFO - â”œâ”€â”€ Loss: 9.4660
2025-03-02 12:02:51,302 - INFO - â”œâ”€â”€ Learning Rate: 1.10e-04
2025-03-02 12:02:51,302 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:02:51,975 - INFO - ðŸªœ Batch step - 735 -- sub batch step 2940 -- lr 1.10e-04
2025-03-02 12:02:54,124 - INFO - ðŸªœ Batch step - 735 -- sub batch step 2941 -- lr 1.10e-04
2025-03-02 12:02:56,834 - INFO - ðŸªœ Batch step - 735 -- sub batch step 2942 -- lr 1.10e-04
2025-03-02 12:02:58,987 - INFO - ðŸªœ Batch step - 735 -- sub batch step 2943 -- lr 1.10e-04
2025-03-02 12:03:00,525 - INFO - Step 735 -- ðŸ”„ Training Metrics
2025-03-02 12:03:00,526 - INFO - â”œâ”€â”€ Loss: 9.4671
2025-03-02 12:03:00,526 - INFO - â”œâ”€â”€ Learning Rate: 1.10e-04
2025-03-02 12:03:00,526 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:03:01,202 - INFO - ðŸªœ Batch step - 736 -- sub batch step 2944 -- lr 1.10e-04
2025-03-02 12:03:03,357 - INFO - ðŸªœ Batch step - 736 -- sub batch step 2945 -- lr 1.10e-04
2025-03-02 12:03:05,518 - INFO - ðŸªœ Batch step - 736 -- sub batch step 2946 -- lr 1.10e-04
2025-03-02 12:03:07,670 - INFO - ðŸªœ Batch step - 736 -- sub batch step 2947 -- lr 1.10e-04
2025-03-02 12:03:09,202 - INFO - Step 736 -- ðŸ”„ Training Metrics
2025-03-02 12:03:09,202 - INFO - â”œâ”€â”€ Loss: 9.4650
2025-03-02 12:03:09,202 - INFO - â”œâ”€â”€ Learning Rate: 1.10e-04
2025-03-02 12:03:09,202 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:03:09,869 - INFO - ðŸªœ Batch step - 737 -- sub batch step 2948 -- lr 1.11e-04
2025-03-02 12:03:12,022 - INFO - ðŸªœ Batch step - 737 -- sub batch step 2949 -- lr 1.11e-04
2025-03-02 12:03:14,787 - INFO - ðŸªœ Batch step - 737 -- sub batch step 2950 -- lr 1.11e-04
2025-03-02 12:03:16,943 - INFO - ðŸªœ Batch step - 737 -- sub batch step 2951 -- lr 1.11e-04
2025-03-02 12:03:18,434 - INFO - Step 737 -- ðŸ”„ Training Metrics
2025-03-02 12:03:18,435 - INFO - â”œâ”€â”€ Loss: 9.4639
2025-03-02 12:03:18,435 - INFO - â”œâ”€â”€ Learning Rate: 1.11e-04
2025-03-02 12:03:18,435 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:03:19,109 - INFO - ðŸªœ Batch step - 738 -- sub batch step 2952 -- lr 1.11e-04
2025-03-02 12:03:21,261 - INFO - ðŸªœ Batch step - 738 -- sub batch step 2953 -- lr 1.11e-04
2025-03-02 12:03:23,433 - INFO - ðŸªœ Batch step - 738 -- sub batch step 2954 -- lr 1.11e-04
2025-03-02 12:03:25,588 - INFO - ðŸªœ Batch step - 738 -- sub batch step 2955 -- lr 1.11e-04
2025-03-02 12:03:27,123 - INFO - Step 738 -- ðŸ”„ Training Metrics
2025-03-02 12:03:27,123 - INFO - â”œâ”€â”€ Loss: 9.4355
2025-03-02 12:03:27,123 - INFO - â”œâ”€â”€ Learning Rate: 1.11e-04
2025-03-02 12:03:27,123 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:03:27,793 - INFO - ðŸªœ Batch step - 739 -- sub batch step 2956 -- lr 1.11e-04
2025-03-02 12:03:29,947 - INFO - ðŸªœ Batch step - 739 -- sub batch step 2957 -- lr 1.11e-04
2025-03-02 12:03:32,236 - INFO - ðŸªœ Batch step - 739 -- sub batch step 2958 -- lr 1.11e-04
2025-03-02 12:03:34,388 - INFO - ðŸªœ Batch step - 739 -- sub batch step 2959 -- lr 1.11e-04
2025-03-02 12:03:36,088 - INFO - Step 739 -- ðŸ”„ Training Metrics
2025-03-02 12:03:36,089 - INFO - â”œâ”€â”€ Loss: 9.4267
2025-03-02 12:03:36,089 - INFO - â”œâ”€â”€ Learning Rate: 1.11e-04
2025-03-02 12:03:36,089 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:03:37,392 - INFO - ðŸªœ Batch step - 740 -- sub batch step 2960 -- lr 1.11e-04
2025-03-02 12:03:39,542 - INFO - ðŸªœ Batch step - 740 -- sub batch step 2961 -- lr 1.11e-04
2025-03-02 12:03:41,705 - INFO - ðŸªœ Batch step - 740 -- sub batch step 2962 -- lr 1.11e-04
2025-03-02 12:03:43,873 - INFO - ðŸªœ Batch step - 740 -- sub batch step 2963 -- lr 1.11e-04
2025-03-02 12:03:45,373 - INFO - Step 740 -- ðŸ”„ Training Metrics
2025-03-02 12:03:45,374 - INFO - â”œâ”€â”€ Loss: 9.4224
2025-03-02 12:03:45,374 - INFO - â”œâ”€â”€ Learning Rate: 1.11e-04
2025-03-02 12:03:45,374 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:03:46,052 - INFO - ðŸªœ Batch step - 741 -- sub batch step 2964 -- lr 1.11e-04
2025-03-02 12:03:48,209 - INFO - ðŸªœ Batch step - 741 -- sub batch step 2965 -- lr 1.11e-04
2025-03-02 12:03:50,362 - INFO - ðŸªœ Batch step - 741 -- sub batch step 2966 -- lr 1.11e-04
2025-03-02 12:03:53,164 - INFO - ðŸªœ Batch step - 741 -- sub batch step 2967 -- lr 1.11e-04
2025-03-02 12:03:54,656 - INFO - Step 741 -- ðŸ”„ Training Metrics
2025-03-02 12:03:54,656 - INFO - â”œâ”€â”€ Loss: 9.4255
2025-03-02 12:03:54,656 - INFO - â”œâ”€â”€ Learning Rate: 1.11e-04
2025-03-02 12:03:54,656 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:03:55,323 - INFO - ðŸªœ Batch step - 742 -- sub batch step 2968 -- lr 1.11e-04
2025-03-02 12:03:57,479 - INFO - ðŸªœ Batch step - 742 -- sub batch step 2969 -- lr 1.11e-04
2025-03-02 12:03:59,635 - INFO - ðŸªœ Batch step - 742 -- sub batch step 2970 -- lr 1.11e-04
2025-03-02 12:04:01,798 - INFO - ðŸªœ Batch step - 742 -- sub batch step 2971 -- lr 1.11e-04
2025-03-02 12:04:03,335 - INFO - Step 742 -- ðŸ”„ Training Metrics
2025-03-02 12:04:03,335 - INFO - â”œâ”€â”€ Loss: 9.4080
2025-03-02 12:04:03,336 - INFO - â”œâ”€â”€ Learning Rate: 1.11e-04
2025-03-02 12:04:03,336 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:04:04,007 - INFO - ðŸªœ Batch step - 743 -- sub batch step 2972 -- lr 1.11e-04
2025-03-02 12:04:06,156 - INFO - ðŸªœ Batch step - 743 -- sub batch step 2973 -- lr 1.11e-04
2025-03-02 12:04:08,306 - INFO - ðŸªœ Batch step - 743 -- sub batch step 2974 -- lr 1.11e-04
2025-03-02 12:04:10,781 - INFO - ðŸªœ Batch step - 743 -- sub batch step 2975 -- lr 1.11e-04
2025-03-02 12:04:12,534 - INFO - Step 743 -- ðŸ”„ Training Metrics
2025-03-02 12:04:12,534 - INFO - â”œâ”€â”€ Loss: 9.4100
2025-03-02 12:04:12,534 - INFO - â”œâ”€â”€ Learning Rate: 1.11e-04
2025-03-02 12:04:12,534 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:04:13,201 - INFO - ðŸªœ Batch step - 744 -- sub batch step 2976 -- lr 1.12e-04
2025-03-02 12:04:15,350 - INFO - ðŸªœ Batch step - 744 -- sub batch step 2977 -- lr 1.12e-04
2025-03-02 12:04:17,497 - INFO - ðŸªœ Batch step - 744 -- sub batch step 2978 -- lr 1.12e-04
2025-03-02 12:04:19,665 - INFO - ðŸªœ Batch step - 744 -- sub batch step 2979 -- lr 1.12e-04
2025-03-02 12:04:21,212 - INFO - Step 744 -- ðŸ”„ Training Metrics
2025-03-02 12:04:21,213 - INFO - â”œâ”€â”€ Loss: 9.4046
2025-03-02 12:04:21,213 - INFO - â”œâ”€â”€ Learning Rate: 1.12e-04
2025-03-02 12:04:21,213 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:04:21,883 - INFO - ðŸªœ Batch step - 745 -- sub batch step 2980 -- lr 1.12e-04
2025-03-02 12:04:24,033 - INFO - ðŸªœ Batch step - 745 -- sub batch step 2981 -- lr 1.12e-04
2025-03-02 12:04:26,185 - INFO - ðŸªœ Batch step - 745 -- sub batch step 2982 -- lr 1.12e-04
2025-03-02 12:04:29,012 - INFO - ðŸªœ Batch step - 745 -- sub batch step 2983 -- lr 1.12e-04
2025-03-02 12:04:30,502 - INFO - Step 745 -- ðŸ”„ Training Metrics
2025-03-02 12:04:30,502 - INFO - â”œâ”€â”€ Loss: 9.4045
2025-03-02 12:04:30,503 - INFO - â”œâ”€â”€ Learning Rate: 1.12e-04
2025-03-02 12:04:30,503 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:04:31,175 - INFO - ðŸªœ Batch step - 746 -- sub batch step 2984 -- lr 1.12e-04
2025-03-02 12:04:33,326 - INFO - ðŸªœ Batch step - 746 -- sub batch step 2985 -- lr 1.12e-04
2025-03-02 12:04:35,472 - INFO - ðŸªœ Batch step - 746 -- sub batch step 2986 -- lr 1.12e-04
2025-03-02 12:04:37,639 - INFO - ðŸªœ Batch step - 746 -- sub batch step 2987 -- lr 1.12e-04
2025-03-02 12:04:39,187 - INFO - Step 746 -- ðŸ”„ Training Metrics
2025-03-02 12:04:39,187 - INFO - â”œâ”€â”€ Loss: 9.3936
2025-03-02 12:04:39,187 - INFO - â”œâ”€â”€ Learning Rate: 1.12e-04
2025-03-02 12:04:39,187 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:04:39,854 - INFO - ðŸªœ Batch step - 747 -- sub batch step 2988 -- lr 1.12e-04
2025-03-02 12:04:42,010 - INFO - ðŸªœ Batch step - 747 -- sub batch step 2989 -- lr 1.12e-04
2025-03-02 12:04:44,162 - INFO - ðŸªœ Batch step - 747 -- sub batch step 2990 -- lr 1.12e-04
2025-03-02 12:04:46,840 - INFO - ðŸªœ Batch step - 747 -- sub batch step 2991 -- lr 1.12e-04
2025-03-02 12:04:48,333 - INFO - Step 747 -- ðŸ”„ Training Metrics
2025-03-02 12:04:48,333 - INFO - â”œâ”€â”€ Loss: 9.3877
2025-03-02 12:04:48,333 - INFO - â”œâ”€â”€ Learning Rate: 1.12e-04
2025-03-02 12:04:48,334 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:04:49,008 - INFO - ðŸªœ Batch step - 748 -- sub batch step 2992 -- lr 1.12e-04
2025-03-02 12:04:51,161 - INFO - ðŸªœ Batch step - 748 -- sub batch step 2993 -- lr 1.12e-04
2025-03-02 12:04:53,317 - INFO - ðŸªœ Batch step - 748 -- sub batch step 2994 -- lr 1.12e-04
2025-03-02 12:04:55,487 - INFO - ðŸªœ Batch step - 748 -- sub batch step 2995 -- lr 1.12e-04
2025-03-02 12:04:57,023 - INFO - Step 748 -- ðŸ”„ Training Metrics
2025-03-02 12:04:57,023 - INFO - â”œâ”€â”€ Loss: 9.3869
2025-03-02 12:04:57,023 - INFO - â”œâ”€â”€ Learning Rate: 1.12e-04
2025-03-02 12:04:57,023 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:04:57,693 - INFO - ðŸªœ Batch step - 749 -- sub batch step 2996 -- lr 1.12e-04
2025-03-02 12:04:59,849 - INFO - ðŸªœ Batch step - 749 -- sub batch step 2997 -- lr 1.12e-04
2025-03-02 12:05:01,999 - INFO - ðŸªœ Batch step - 749 -- sub batch step 2998 -- lr 1.12e-04
2025-03-02 12:05:04,379 - INFO - ðŸªœ Batch step - 749 -- sub batch step 2999 -- lr 1.12e-04
2025-03-02 12:05:06,156 - INFO - Step 749 -- ðŸ”„ Training Metrics
2025-03-02 12:05:06,157 - INFO - â”œâ”€â”€ Loss: 9.3843
2025-03-02 12:05:06,157 - INFO - â”œâ”€â”€ Learning Rate: 1.12e-04
2025-03-02 12:05:06,157 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:05:06,830 - INFO - ðŸªœ Batch step - 750 -- sub batch step 3000 -- lr 1.12e-04
2025-03-02 12:05:08,978 - INFO - ðŸªœ Batch step - 750 -- sub batch step 3001 -- lr 1.12e-04
2025-03-02 12:05:11,130 - INFO - ðŸªœ Batch step - 750 -- sub batch step 3002 -- lr 1.12e-04
2025-03-02 12:05:13,292 - INFO - ðŸªœ Batch step - 750 -- sub batch step 3003 -- lr 1.12e-04
2025-03-02 12:05:14,823 - INFO - Step 750 -- ðŸ”„ Training Metrics
2025-03-02 12:05:14,824 - INFO - â”œâ”€â”€ Loss: 9.3713
2025-03-02 12:05:14,824 - INFO - â”œâ”€â”€ Learning Rate: 1.12e-04
2025-03-02 12:05:14,824 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:05:15,496 - INFO - ðŸªœ Batch step - 751 -- sub batch step 3004 -- lr 1.13e-04
2025-03-02 12:05:17,648 - INFO - ðŸªœ Batch step - 751 -- sub batch step 3005 -- lr 1.13e-04
2025-03-02 12:05:20,505 - INFO - ðŸªœ Batch step - 751 -- sub batch step 3006 -- lr 1.13e-04
2025-03-02 12:05:22,664 - INFO - ðŸªœ Batch step - 751 -- sub batch step 3007 -- lr 1.13e-04
2025-03-02 12:05:24,156 - INFO - Step 751 -- ðŸ”„ Training Metrics
2025-03-02 12:05:24,156 - INFO - â”œâ”€â”€ Loss: 9.3550
2025-03-02 12:05:24,157 - INFO - â”œâ”€â”€ Learning Rate: 1.13e-04
2025-03-02 12:05:24,157 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:05:24,826 - INFO - ðŸªœ Batch step - 752 -- sub batch step 3008 -- lr 1.13e-04
2025-03-02 12:05:26,978 - INFO - ðŸªœ Batch step - 752 -- sub batch step 3009 -- lr 1.13e-04
2025-03-02 12:05:29,149 - INFO - ðŸªœ Batch step - 752 -- sub batch step 3010 -- lr 1.13e-04
2025-03-02 12:05:31,301 - INFO - ðŸªœ Batch step - 752 -- sub batch step 3011 -- lr 1.13e-04
2025-03-02 12:05:32,827 - INFO - Step 752 -- ðŸ”„ Training Metrics
2025-03-02 12:05:32,827 - INFO - â”œâ”€â”€ Loss: 9.3613
2025-03-02 12:05:32,827 - INFO - â”œâ”€â”€ Learning Rate: 1.13e-04
2025-03-02 12:05:32,827 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:05:33,502 - INFO - ðŸªœ Batch step - 753 -- sub batch step 3012 -- lr 1.13e-04
2025-03-02 12:05:35,650 - INFO - ðŸªœ Batch step - 753 -- sub batch step 3013 -- lr 1.13e-04
2025-03-02 12:05:38,264 - INFO - ðŸªœ Batch step - 753 -- sub batch step 3014 -- lr 1.13e-04
2025-03-02 12:05:40,420 - INFO - ðŸªœ Batch step - 753 -- sub batch step 3015 -- lr 1.13e-04
2025-03-02 12:05:42,297 - INFO - Step 753 -- ðŸ”„ Training Metrics
2025-03-02 12:05:42,297 - INFO - â”œâ”€â”€ Loss: 9.3275
2025-03-02 12:05:42,297 - INFO - â”œâ”€â”€ Learning Rate: 1.13e-04
2025-03-02 12:05:42,297 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:05:42,965 - INFO - ðŸªœ Batch step - 754 -- sub batch step 3016 -- lr 1.13e-04
2025-03-02 12:05:45,120 - INFO - ðŸªœ Batch step - 754 -- sub batch step 3017 -- lr 1.13e-04
2025-03-02 12:05:47,282 - INFO - ðŸªœ Batch step - 754 -- sub batch step 3018 -- lr 1.13e-04
2025-03-02 12:05:49,437 - INFO - ðŸªœ Batch step - 754 -- sub batch step 3019 -- lr 1.13e-04
2025-03-02 12:05:50,980 - INFO - Step 754 -- ðŸ”„ Training Metrics
2025-03-02 12:05:50,981 - INFO - â”œâ”€â”€ Loss: 9.3433
2025-03-02 12:05:50,981 - INFO - â”œâ”€â”€ Learning Rate: 1.13e-04
2025-03-02 12:05:50,981 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:05:51,654 - INFO - ðŸªœ Batch step - 755 -- sub batch step 3020 -- lr 1.13e-04
2025-03-02 12:05:53,800 - INFO - ðŸªœ Batch step - 755 -- sub batch step 3021 -- lr 1.13e-04
2025-03-02 12:05:56,608 - INFO - ðŸªœ Batch step - 755 -- sub batch step 3022 -- lr 1.13e-04
2025-03-02 12:05:58,760 - INFO - ðŸªœ Batch step - 755 -- sub batch step 3023 -- lr 1.13e-04
2025-03-02 12:06:00,251 - INFO - Step 755 -- ðŸ”„ Training Metrics
2025-03-02 12:06:00,251 - INFO - â”œâ”€â”€ Loss: 9.3448
2025-03-02 12:06:00,251 - INFO - â”œâ”€â”€ Learning Rate: 1.13e-04
2025-03-02 12:06:00,251 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:06:00,927 - INFO - ðŸªœ Batch step - 756 -- sub batch step 3024 -- lr 1.13e-04
2025-03-02 12:06:03,084 - INFO - ðŸªœ Batch step - 756 -- sub batch step 3025 -- lr 1.13e-04
2025-03-02 12:06:05,249 - INFO - ðŸªœ Batch step - 756 -- sub batch step 3026 -- lr 1.13e-04
2025-03-02 12:06:07,404 - INFO - ðŸªœ Batch step - 756 -- sub batch step 3027 -- lr 1.13e-04
2025-03-02 12:06:08,934 - INFO - Step 756 -- ðŸ”„ Training Metrics
2025-03-02 12:06:08,934 - INFO - â”œâ”€â”€ Loss: 9.3308
2025-03-02 12:06:08,934 - INFO - â”œâ”€â”€ Learning Rate: 1.13e-04
2025-03-02 12:06:08,934 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:06:09,629 - INFO - ðŸªœ Batch step - 757 -- sub batch step 3028 -- lr 1.14e-04
2025-03-02 12:06:11,786 - INFO - ðŸªœ Batch step - 757 -- sub batch step 3029 -- lr 1.14e-04
2025-03-02 12:06:14,736 - INFO - ðŸªœ Batch step - 757 -- sub batch step 3030 -- lr 1.14e-04
2025-03-02 12:06:16,891 - INFO - ðŸªœ Batch step - 757 -- sub batch step 3031 -- lr 1.14e-04
2025-03-02 12:06:18,383 - INFO - Step 757 -- ðŸ”„ Training Metrics
2025-03-02 12:06:18,383 - INFO - â”œâ”€â”€ Loss: 9.3183
2025-03-02 12:06:18,383 - INFO - â”œâ”€â”€ Learning Rate: 1.14e-04
2025-03-02 12:06:18,383 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:06:19,057 - INFO - ðŸªœ Batch step - 758 -- sub batch step 3032 -- lr 1.14e-04
2025-03-02 12:06:21,208 - INFO - ðŸªœ Batch step - 758 -- sub batch step 3033 -- lr 1.14e-04
2025-03-02 12:06:23,374 - INFO - ðŸªœ Batch step - 758 -- sub batch step 3034 -- lr 1.14e-04
2025-03-02 12:06:25,527 - INFO - ðŸªœ Batch step - 758 -- sub batch step 3035 -- lr 1.14e-04
2025-03-02 12:06:27,068 - INFO - Step 758 -- ðŸ”„ Training Metrics
2025-03-02 12:06:27,068 - INFO - â”œâ”€â”€ Loss: 9.3064
2025-03-02 12:06:27,068 - INFO - â”œâ”€â”€ Learning Rate: 1.14e-04
2025-03-02 12:06:27,068 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:06:27,736 - INFO - ðŸªœ Batch step - 759 -- sub batch step 3036 -- lr 1.14e-04
2025-03-02 12:06:29,890 - INFO - ðŸªœ Batch step - 759 -- sub batch step 3037 -- lr 1.14e-04
2025-03-02 12:06:32,175 - INFO - ðŸªœ Batch step - 759 -- sub batch step 3038 -- lr 1.14e-04
2025-03-02 12:06:34,329 - INFO - ðŸªœ Batch step - 759 -- sub batch step 3039 -- lr 1.14e-04
2025-03-02 12:06:35,953 - INFO - Step 759 -- ðŸ”„ Training Metrics
2025-03-02 12:06:35,953 - INFO - â”œâ”€â”€ Loss: 9.2971
2025-03-02 12:06:35,953 - INFO - â”œâ”€â”€ Learning Rate: 1.14e-04
2025-03-02 12:06:35,953 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:06:37,323 - INFO - ðŸªœ Batch step - 760 -- sub batch step 3040 -- lr 1.14e-04
2025-03-02 12:06:39,491 - INFO - ðŸªœ Batch step - 760 -- sub batch step 3041 -- lr 1.14e-04
2025-03-02 12:06:41,662 - INFO - ðŸªœ Batch step - 760 -- sub batch step 3042 -- lr 1.14e-04
2025-03-02 12:06:43,844 - INFO - ðŸªœ Batch step - 760 -- sub batch step 3043 -- lr 1.14e-04
2025-03-02 12:06:45,338 - INFO - Step 760 -- ðŸ”„ Training Metrics
2025-03-02 12:06:45,339 - INFO - â”œâ”€â”€ Loss: 9.2989
2025-03-02 12:06:45,339 - INFO - â”œâ”€â”€ Learning Rate: 1.14e-04
2025-03-02 12:06:45,339 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:06:46,017 - INFO - ðŸªœ Batch step - 761 -- sub batch step 3044 -- lr 1.14e-04
2025-03-02 12:06:48,181 - INFO - ðŸªœ Batch step - 761 -- sub batch step 3045 -- lr 1.14e-04
2025-03-02 12:06:50,334 - INFO - ðŸªœ Batch step - 761 -- sub batch step 3046 -- lr 1.14e-04
2025-03-02 12:06:53,153 - INFO - ðŸªœ Batch step - 761 -- sub batch step 3047 -- lr 1.14e-04
2025-03-02 12:06:54,650 - INFO - Step 761 -- ðŸ”„ Training Metrics
2025-03-02 12:06:54,650 - INFO - â”œâ”€â”€ Loss: 9.2962
2025-03-02 12:06:54,650 - INFO - â”œâ”€â”€ Learning Rate: 1.14e-04
2025-03-02 12:06:54,650 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:06:55,321 - INFO - ðŸªœ Batch step - 762 -- sub batch step 3048 -- lr 1.14e-04
2025-03-02 12:06:57,480 - INFO - ðŸªœ Batch step - 762 -- sub batch step 3049 -- lr 1.14e-04
2025-03-02 12:06:59,634 - INFO - ðŸªœ Batch step - 762 -- sub batch step 3050 -- lr 1.14e-04
2025-03-02 12:07:01,811 - INFO - ðŸªœ Batch step - 762 -- sub batch step 3051 -- lr 1.14e-04
2025-03-02 12:07:03,334 - INFO - Step 762 -- ðŸ”„ Training Metrics
2025-03-02 12:07:03,334 - INFO - â”œâ”€â”€ Loss: 9.2897
2025-03-02 12:07:03,334 - INFO - â”œâ”€â”€ Learning Rate: 1.14e-04
2025-03-02 12:07:03,334 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:07:04,012 - INFO - ðŸªœ Batch step - 763 -- sub batch step 3052 -- lr 1.14e-04
2025-03-02 12:07:06,163 - INFO - ðŸªœ Batch step - 763 -- sub batch step 3053 -- lr 1.14e-04
2025-03-02 12:07:08,321 - INFO - ðŸªœ Batch step - 763 -- sub batch step 3054 -- lr 1.14e-04
2025-03-02 12:07:10,962 - INFO - ðŸªœ Batch step - 763 -- sub batch step 3055 -- lr 1.14e-04
2025-03-02 12:07:12,808 - INFO - Step 763 -- ðŸ”„ Training Metrics
2025-03-02 12:07:12,808 - INFO - â”œâ”€â”€ Loss: 9.2690
2025-03-02 12:07:12,808 - INFO - â”œâ”€â”€ Learning Rate: 1.14e-04
2025-03-02 12:07:12,808 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:07:13,482 - INFO - ðŸªœ Batch step - 764 -- sub batch step 3056 -- lr 1.15e-04
2025-03-02 12:07:15,643 - INFO - ðŸªœ Batch step - 764 -- sub batch step 3057 -- lr 1.15e-04
2025-03-02 12:07:17,799 - INFO - ðŸªœ Batch step - 764 -- sub batch step 3058 -- lr 1.15e-04
2025-03-02 12:07:19,980 - INFO - ðŸªœ Batch step - 764 -- sub batch step 3059 -- lr 1.15e-04
2025-03-02 12:07:21,487 - INFO - Step 764 -- ðŸ”„ Training Metrics
2025-03-02 12:07:21,488 - INFO - â”œâ”€â”€ Loss: 9.2752
2025-03-02 12:07:21,488 - INFO - â”œâ”€â”€ Learning Rate: 1.15e-04
2025-03-02 12:07:21,488 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:07:22,163 - INFO - ðŸªœ Batch step - 765 -- sub batch step 3060 -- lr 1.15e-04
2025-03-02 12:07:24,315 - INFO - ðŸªœ Batch step - 765 -- sub batch step 3061 -- lr 1.15e-04
2025-03-02 12:07:26,473 - INFO - ðŸªœ Batch step - 765 -- sub batch step 3062 -- lr 1.15e-04
2025-03-02 12:07:28,902 - INFO - ðŸªœ Batch step - 765 -- sub batch step 3063 -- lr 1.15e-04
2025-03-02 12:07:30,809 - INFO - Step 765 -- ðŸ”„ Training Metrics
2025-03-02 12:07:30,809 - INFO - â”œâ”€â”€ Loss: 9.2699
2025-03-02 12:07:30,809 - INFO - â”œâ”€â”€ Learning Rate: 1.15e-04
2025-03-02 12:07:30,809 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:07:31,488 - INFO - ðŸªœ Batch step - 766 -- sub batch step 3064 -- lr 1.15e-04
2025-03-02 12:07:33,648 - INFO - ðŸªœ Batch step - 766 -- sub batch step 3065 -- lr 1.15e-04
2025-03-02 12:07:35,799 - INFO - ðŸªœ Batch step - 766 -- sub batch step 3066 -- lr 1.15e-04
2025-03-02 12:07:37,981 - INFO - ðŸªœ Batch step - 766 -- sub batch step 3067 -- lr 1.15e-04
2025-03-02 12:07:39,492 - INFO - Step 766 -- ðŸ”„ Training Metrics
2025-03-02 12:07:39,493 - INFO - â”œâ”€â”€ Loss: 9.2666
2025-03-02 12:07:39,493 - INFO - â”œâ”€â”€ Learning Rate: 1.15e-04
2025-03-02 12:07:39,493 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:07:40,165 - INFO - ðŸªœ Batch step - 767 -- sub batch step 3068 -- lr 1.15e-04
2025-03-02 12:07:42,325 - INFO - ðŸªœ Batch step - 767 -- sub batch step 3069 -- lr 1.15e-04
2025-03-02 12:07:44,488 - INFO - ðŸªœ Batch step - 767 -- sub batch step 3070 -- lr 1.15e-04
2025-03-02 12:07:47,146 - INFO - ðŸªœ Batch step - 767 -- sub batch step 3071 -- lr 1.15e-04
2025-03-02 12:07:48,647 - INFO - Step 767 -- ðŸ”„ Training Metrics
2025-03-02 12:07:48,648 - INFO - â”œâ”€â”€ Loss: 9.2487
2025-03-02 12:07:48,648 - INFO - â”œâ”€â”€ Learning Rate: 1.15e-04
2025-03-02 12:07:48,648 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:07:49,334 - INFO - ðŸªœ Batch step - 768 -- sub batch step 3072 -- lr 1.15e-04
2025-03-02 12:07:51,491 - INFO - ðŸªœ Batch step - 768 -- sub batch step 3073 -- lr 1.15e-04
2025-03-02 12:07:53,652 - INFO - ðŸªœ Batch step - 768 -- sub batch step 3074 -- lr 1.15e-04
2025-03-02 12:07:55,844 - INFO - ðŸªœ Batch step - 768 -- sub batch step 3075 -- lr 1.15e-04
2025-03-02 12:07:57,331 - INFO - Step 768 -- ðŸ”„ Training Metrics
2025-03-02 12:07:57,332 - INFO - â”œâ”€â”€ Loss: 9.2565
2025-03-02 12:07:57,332 - INFO - â”œâ”€â”€ Learning Rate: 1.15e-04
2025-03-02 12:07:57,332 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:07:58,007 - INFO - ðŸªœ Batch step - 769 -- sub batch step 3076 -- lr 1.15e-04
2025-03-02 12:08:00,168 - INFO - ðŸªœ Batch step - 769 -- sub batch step 3077 -- lr 1.15e-04
2025-03-02 12:08:02,323 - INFO - ðŸªœ Batch step - 769 -- sub batch step 3078 -- lr 1.15e-04
2025-03-02 12:08:04,711 - INFO - ðŸªœ Batch step - 769 -- sub batch step 3079 -- lr 1.15e-04
2025-03-02 12:08:06,789 - INFO - Step 769 -- ðŸ”„ Training Metrics
2025-03-02 12:08:06,789 - INFO - â”œâ”€â”€ Loss: 9.2316
2025-03-02 12:08:06,789 - INFO - â”œâ”€â”€ Learning Rate: 1.15e-04
2025-03-02 12:08:06,789 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:08:07,468 - INFO - ðŸªœ Batch step - 770 -- sub batch step 3080 -- lr 1.15e-04
2025-03-02 12:08:09,619 - INFO - ðŸªœ Batch step - 770 -- sub batch step 3081 -- lr 1.15e-04
2025-03-02 12:08:11,777 - INFO - ðŸªœ Batch step - 770 -- sub batch step 3082 -- lr 1.15e-04
2025-03-02 12:08:13,950 - INFO - ðŸªœ Batch step - 770 -- sub batch step 3083 -- lr 1.15e-04
2025-03-02 12:08:15,464 - INFO - Step 770 -- ðŸ”„ Training Metrics
2025-03-02 12:08:15,465 - INFO - â”œâ”€â”€ Loss: 9.2301
2025-03-02 12:08:15,465 - INFO - â”œâ”€â”€ Learning Rate: 1.15e-04
2025-03-02 12:08:15,465 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:08:16,144 - INFO - ðŸªœ Batch step - 771 -- sub batch step 3084 -- lr 1.16e-04
2025-03-02 12:08:18,298 - INFO - ðŸªœ Batch step - 771 -- sub batch step 3085 -- lr 1.16e-04
2025-03-02 12:08:20,912 - INFO - ðŸªœ Batch step - 771 -- sub batch step 3086 -- lr 1.16e-04
2025-03-02 12:08:23,070 - INFO - ðŸªœ Batch step - 771 -- sub batch step 3087 -- lr 1.16e-04
2025-03-02 12:08:24,857 - INFO - Step 771 -- ðŸ”„ Training Metrics
2025-03-02 12:08:24,857 - INFO - â”œâ”€â”€ Loss: 9.2407
2025-03-02 12:08:24,857 - INFO - â”œâ”€â”€ Learning Rate: 1.16e-04
2025-03-02 12:08:24,857 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:08:25,529 - INFO - ðŸªœ Batch step - 772 -- sub batch step 3088 -- lr 1.16e-04
2025-03-02 12:08:27,688 - INFO - ðŸªœ Batch step - 772 -- sub batch step 3089 -- lr 1.16e-04
2025-03-02 12:08:29,872 - INFO - ðŸªœ Batch step - 772 -- sub batch step 3090 -- lr 1.16e-04
2025-03-02 12:08:32,021 - INFO - ðŸªœ Batch step - 772 -- sub batch step 3091 -- lr 1.16e-04
2025-03-02 12:08:33,534 - INFO - Step 772 -- ðŸ”„ Training Metrics
2025-03-02 12:08:33,535 - INFO - â”œâ”€â”€ Loss: 9.2240
2025-03-02 12:08:33,535 - INFO - â”œâ”€â”€ Learning Rate: 1.16e-04
2025-03-02 12:08:33,535 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:08:34,215 - INFO - ðŸªœ Batch step - 773 -- sub batch step 3092 -- lr 1.16e-04
2025-03-02 12:08:36,372 - INFO - ðŸªœ Batch step - 773 -- sub batch step 3093 -- lr 1.16e-04
2025-03-02 12:08:38,737 - INFO - ðŸªœ Batch step - 773 -- sub batch step 3094 -- lr 1.16e-04
2025-03-02 12:08:40,897 - INFO - ðŸªœ Batch step - 773 -- sub batch step 3095 -- lr 1.16e-04
2025-03-02 12:08:42,776 - INFO - Step 773 -- ðŸ”„ Training Metrics
2025-03-02 12:08:42,776 - INFO - â”œâ”€â”€ Loss: 9.2197
2025-03-02 12:08:42,777 - INFO - â”œâ”€â”€ Learning Rate: 1.16e-04
2025-03-02 12:08:42,777 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:08:43,449 - INFO - ðŸªœ Batch step - 774 -- sub batch step 3096 -- lr 1.16e-04
2025-03-02 12:08:45,609 - INFO - ðŸªœ Batch step - 774 -- sub batch step 3097 -- lr 1.16e-04
2025-03-02 12:08:47,787 - INFO - ðŸªœ Batch step - 774 -- sub batch step 3098 -- lr 1.16e-04
2025-03-02 12:08:49,944 - INFO - ðŸªœ Batch step - 774 -- sub batch step 3099 -- lr 1.16e-04
2025-03-02 12:08:51,460 - INFO - Step 774 -- ðŸ”„ Training Metrics
2025-03-02 12:08:51,460 - INFO - â”œâ”€â”€ Loss: 9.2005
2025-03-02 12:08:51,460 - INFO - â”œâ”€â”€ Learning Rate: 1.16e-04
2025-03-02 12:08:51,460 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:08:52,134 - INFO - ðŸªœ Batch step - 775 -- sub batch step 3100 -- lr 1.16e-04
2025-03-02 12:08:54,287 - INFO - ðŸªœ Batch step - 775 -- sub batch step 3101 -- lr 1.16e-04
2025-03-02 12:08:56,762 - INFO - ðŸªœ Batch step - 775 -- sub batch step 3102 -- lr 1.16e-04
2025-03-02 12:08:58,922 - INFO - ðŸªœ Batch step - 775 -- sub batch step 3103 -- lr 1.16e-04
2025-03-02 12:09:00,896 - INFO - Step 775 -- ðŸ”„ Training Metrics
2025-03-02 12:09:00,897 - INFO - â”œâ”€â”€ Loss: 9.1932
2025-03-02 12:09:00,897 - INFO - â”œâ”€â”€ Learning Rate: 1.16e-04
2025-03-02 12:09:00,897 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:09:01,575 - INFO - ðŸªœ Batch step - 776 -- sub batch step 3104 -- lr 1.16e-04
2025-03-02 12:09:03,735 - INFO - ðŸªœ Batch step - 776 -- sub batch step 3105 -- lr 1.16e-04
2025-03-02 12:09:05,916 - INFO - ðŸªœ Batch step - 776 -- sub batch step 3106 -- lr 1.16e-04
2025-03-02 12:09:08,073 - INFO - ðŸªœ Batch step - 776 -- sub batch step 3107 -- lr 1.16e-04
2025-03-02 12:09:09,589 - INFO - Step 776 -- ðŸ”„ Training Metrics
2025-03-02 12:09:09,589 - INFO - â”œâ”€â”€ Loss: 9.1913
2025-03-02 12:09:09,589 - INFO - â”œâ”€â”€ Learning Rate: 1.16e-04
2025-03-02 12:09:09,589 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:09:10,260 - INFO - ðŸªœ Batch step - 777 -- sub batch step 3108 -- lr 1.17e-04
2025-03-02 12:09:12,417 - INFO - ðŸªœ Batch step - 777 -- sub batch step 3109 -- lr 1.17e-04
2025-03-02 12:09:15,246 - INFO - ðŸªœ Batch step - 777 -- sub batch step 3110 -- lr 1.17e-04
2025-03-02 12:09:17,406 - INFO - ðŸªœ Batch step - 777 -- sub batch step 3111 -- lr 1.17e-04
2025-03-02 12:09:18,947 - INFO - Step 777 -- ðŸ”„ Training Metrics
2025-03-02 12:09:18,947 - INFO - â”œâ”€â”€ Loss: 9.1770
2025-03-02 12:09:18,947 - INFO - â”œâ”€â”€ Learning Rate: 1.17e-04
2025-03-02 12:09:18,947 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:09:19,625 - INFO - ðŸªœ Batch step - 778 -- sub batch step 3112 -- lr 1.17e-04
2025-03-02 12:09:21,777 - INFO - ðŸªœ Batch step - 778 -- sub batch step 3113 -- lr 1.17e-04
2025-03-02 12:09:23,961 - INFO - ðŸªœ Batch step - 778 -- sub batch step 3114 -- lr 1.17e-04
2025-03-02 12:09:26,118 - INFO - ðŸªœ Batch step - 778 -- sub batch step 3115 -- lr 1.17e-04
2025-03-02 12:09:27,633 - INFO - Step 778 -- ðŸ”„ Training Metrics
2025-03-02 12:09:27,633 - INFO - â”œâ”€â”€ Loss: 9.1696
2025-03-02 12:09:27,633 - INFO - â”œâ”€â”€ Learning Rate: 1.17e-04
2025-03-02 12:09:27,633 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:09:28,301 - INFO - ðŸªœ Batch step - 779 -- sub batch step 3116 -- lr 1.17e-04
2025-03-02 12:09:30,462 - INFO - ðŸªœ Batch step - 779 -- sub batch step 3117 -- lr 1.17e-04
2025-03-02 12:09:32,747 - INFO - ðŸªœ Batch step - 779 -- sub batch step 3118 -- lr 1.17e-04
2025-03-02 12:09:34,904 - INFO - ðŸªœ Batch step - 779 -- sub batch step 3119 -- lr 1.17e-04
2025-03-02 12:09:36,486 - INFO - Step 779 -- ðŸ”„ Training Metrics
2025-03-02 12:09:36,486 - INFO - â”œâ”€â”€ Loss: 9.1922
2025-03-02 12:09:36,486 - INFO - â”œâ”€â”€ Learning Rate: 1.17e-04
2025-03-02 12:09:36,487 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:09:37,695 - INFO - ðŸªœ Batch step - 780 -- sub batch step 3120 -- lr 1.17e-04
2025-03-02 12:09:39,857 - INFO - ðŸªœ Batch step - 780 -- sub batch step 3121 -- lr 1.17e-04
2025-03-02 12:09:42,019 - INFO - ðŸªœ Batch step - 780 -- sub batch step 3122 -- lr 1.17e-04
2025-03-02 12:09:44,199 - INFO - ðŸªœ Batch step - 780 -- sub batch step 3123 -- lr 1.17e-04
2025-03-02 12:09:45,702 - INFO - Step 780 -- ðŸ”„ Training Metrics
2025-03-02 12:09:45,702 - INFO - â”œâ”€â”€ Loss: 9.1588
2025-03-02 12:09:45,703 - INFO - â”œâ”€â”€ Learning Rate: 1.17e-04
2025-03-02 12:09:45,703 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:09:46,383 - INFO - ðŸªœ Batch step - 781 -- sub batch step 3124 -- lr 1.17e-04
2025-03-02 12:09:48,543 - INFO - ðŸªœ Batch step - 781 -- sub batch step 3125 -- lr 1.17e-04
2025-03-02 12:09:50,700 - INFO - ðŸªœ Batch step - 781 -- sub batch step 3126 -- lr 1.17e-04
2025-03-02 12:09:53,131 - INFO - ðŸªœ Batch step - 781 -- sub batch step 3127 -- lr 1.17e-04
2025-03-02 12:09:54,785 - INFO - Step 781 -- ðŸ”„ Training Metrics
2025-03-02 12:09:54,785 - INFO - â”œâ”€â”€ Loss: 9.1537
2025-03-02 12:09:54,785 - INFO - â”œâ”€â”€ Learning Rate: 1.17e-04
2025-03-02 12:09:54,786 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:09:55,456 - INFO - ðŸªœ Batch step - 782 -- sub batch step 3128 -- lr 1.17e-04
2025-03-02 12:09:57,624 - INFO - ðŸªœ Batch step - 782 -- sub batch step 3129 -- lr 1.17e-04
2025-03-02 12:09:59,784 - INFO - ðŸªœ Batch step - 782 -- sub batch step 3130 -- lr 1.17e-04
2025-03-02 12:10:01,959 - INFO - ðŸªœ Batch step - 782 -- sub batch step 3131 -- lr 1.17e-04
2025-03-02 12:10:03,471 - INFO - Step 782 -- ðŸ”„ Training Metrics
2025-03-02 12:10:03,471 - INFO - â”œâ”€â”€ Loss: 9.1566
2025-03-02 12:10:03,472 - INFO - â”œâ”€â”€ Learning Rate: 1.17e-04
2025-03-02 12:10:03,472 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:10:04,152 - INFO - ðŸªœ Batch step - 783 -- sub batch step 3132 -- lr 1.17e-04
2025-03-02 12:10:06,306 - INFO - ðŸªœ Batch step - 783 -- sub batch step 3133 -- lr 1.17e-04
2025-03-02 12:10:08,472 - INFO - ðŸªœ Batch step - 783 -- sub batch step 3134 -- lr 1.17e-04
2025-03-02 12:10:11,055 - INFO - ðŸªœ Batch step - 783 -- sub batch step 3135 -- lr 1.17e-04
2025-03-02 12:10:12,708 - INFO - Step 783 -- ðŸ”„ Training Metrics
2025-03-02 12:10:12,708 - INFO - â”œâ”€â”€ Loss: 9.1415
2025-03-02 12:10:12,708 - INFO - â”œâ”€â”€ Learning Rate: 1.17e-04
2025-03-02 12:10:12,708 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:10:13,381 - INFO - ðŸªœ Batch step - 784 -- sub batch step 3136 -- lr 1.18e-04
2025-03-02 12:10:15,537 - INFO - ðŸªœ Batch step - 784 -- sub batch step 3137 -- lr 1.18e-04
2025-03-02 12:10:17,693 - INFO - ðŸªœ Batch step - 784 -- sub batch step 3138 -- lr 1.18e-04
2025-03-02 12:10:19,880 - INFO - ðŸªœ Batch step - 784 -- sub batch step 3139 -- lr 1.18e-04
2025-03-02 12:10:21,401 - INFO - Step 784 -- ðŸ”„ Training Metrics
2025-03-02 12:10:21,401 - INFO - â”œâ”€â”€ Loss: 9.1324
2025-03-02 12:10:21,402 - INFO - â”œâ”€â”€ Learning Rate: 1.18e-04
2025-03-02 12:10:21,402 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:10:22,079 - INFO - ðŸªœ Batch step - 785 -- sub batch step 3140 -- lr 1.18e-04
2025-03-02 12:10:24,227 - INFO - ðŸªœ Batch step - 785 -- sub batch step 3141 -- lr 1.18e-04
2025-03-02 12:10:26,386 - INFO - ðŸªœ Batch step - 785 -- sub batch step 3142 -- lr 1.18e-04
2025-03-02 12:10:28,985 - INFO - ðŸªœ Batch step - 785 -- sub batch step 3143 -- lr 1.18e-04
2025-03-02 12:10:30,733 - INFO - Step 785 -- ðŸ”„ Training Metrics
2025-03-02 12:10:30,734 - INFO - â”œâ”€â”€ Loss: 9.1437
2025-03-02 12:10:30,734 - INFO - â”œâ”€â”€ Learning Rate: 1.18e-04
2025-03-02 12:10:30,734 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:10:31,410 - INFO - ðŸªœ Batch step - 786 -- sub batch step 3144 -- lr 1.18e-04
2025-03-02 12:10:33,567 - INFO - ðŸªœ Batch step - 786 -- sub batch step 3145 -- lr 1.18e-04
2025-03-02 12:10:35,717 - INFO - ðŸªœ Batch step - 786 -- sub batch step 3146 -- lr 1.18e-04
2025-03-02 12:10:37,898 - INFO - ðŸªœ Batch step - 786 -- sub batch step 3147 -- lr 1.18e-04
2025-03-02 12:10:39,415 - INFO - Step 786 -- ðŸ”„ Training Metrics
2025-03-02 12:10:39,415 - INFO - â”œâ”€â”€ Loss: 9.1286
2025-03-02 12:10:39,415 - INFO - â”œâ”€â”€ Learning Rate: 1.18e-04
2025-03-02 12:10:39,415 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:10:40,087 - INFO - ðŸªœ Batch step - 787 -- sub batch step 3148 -- lr 1.18e-04
2025-03-02 12:10:42,247 - INFO - ðŸªœ Batch step - 787 -- sub batch step 3149 -- lr 1.18e-04
2025-03-02 12:10:44,401 - INFO - ðŸªœ Batch step - 787 -- sub batch step 3150 -- lr 1.18e-04
2025-03-02 12:10:47,028 - INFO - ðŸªœ Batch step - 787 -- sub batch step 3151 -- lr 1.18e-04
2025-03-02 12:10:48,661 - INFO - Step 787 -- ðŸ”„ Training Metrics
2025-03-02 12:10:48,662 - INFO - â”œâ”€â”€ Loss: 9.1218
2025-03-02 12:10:48,662 - INFO - â”œâ”€â”€ Learning Rate: 1.18e-04
2025-03-02 12:10:48,662 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:10:49,334 - INFO - ðŸªœ Batch step - 788 -- sub batch step 3152 -- lr 1.18e-04
2025-03-02 12:10:51,485 - INFO - ðŸªœ Batch step - 788 -- sub batch step 3153 -- lr 1.18e-04
2025-03-02 12:10:53,637 - INFO - ðŸªœ Batch step - 788 -- sub batch step 3154 -- lr 1.18e-04
2025-03-02 12:10:55,822 - INFO - ðŸªœ Batch step - 788 -- sub batch step 3155 -- lr 1.18e-04
2025-03-02 12:10:57,346 - INFO - Step 788 -- ðŸ”„ Training Metrics
2025-03-02 12:10:57,347 - INFO - â”œâ”€â”€ Loss: 9.1063
2025-03-02 12:10:57,347 - INFO - â”œâ”€â”€ Learning Rate: 1.18e-04
2025-03-02 12:10:57,347 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:10:58,022 - INFO - ðŸªœ Batch step - 789 -- sub batch step 3156 -- lr 1.18e-04
2025-03-02 12:11:00,178 - INFO - ðŸªœ Batch step - 789 -- sub batch step 3157 -- lr 1.18e-04
2025-03-02 12:11:02,332 - INFO - ðŸªœ Batch step - 789 -- sub batch step 3158 -- lr 1.18e-04
2025-03-02 12:11:05,141 - INFO - ðŸªœ Batch step - 789 -- sub batch step 3159 -- lr 1.18e-04
2025-03-02 12:11:06,635 - INFO - Step 789 -- ðŸ”„ Training Metrics
2025-03-02 12:11:06,635 - INFO - â”œâ”€â”€ Loss: 9.1032
2025-03-02 12:11:06,635 - INFO - â”œâ”€â”€ Learning Rate: 1.18e-04
2025-03-02 12:11:06,635 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:11:07,305 - INFO - ðŸªœ Batch step - 790 -- sub batch step 3160 -- lr 1.18e-04
2025-03-02 12:11:09,455 - INFO - ðŸªœ Batch step - 790 -- sub batch step 3161 -- lr 1.18e-04
2025-03-02 12:11:11,612 - INFO - ðŸªœ Batch step - 790 -- sub batch step 3162 -- lr 1.18e-04
2025-03-02 12:11:13,771 - INFO - ðŸªœ Batch step - 790 -- sub batch step 3163 -- lr 1.18e-04
2025-03-02 12:11:15,307 - INFO - Step 790 -- ðŸ”„ Training Metrics
2025-03-02 12:11:15,307 - INFO - â”œâ”€â”€ Loss: 9.0810
2025-03-02 12:11:15,307 - INFO - â”œâ”€â”€ Learning Rate: 1.18e-04
2025-03-02 12:11:15,307 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:11:15,984 - INFO - ðŸªœ Batch step - 791 -- sub batch step 3164 -- lr 1.19e-04
2025-03-02 12:11:18,137 - INFO - ðŸªœ Batch step - 791 -- sub batch step 3165 -- lr 1.19e-04
2025-03-02 12:11:20,522 - INFO - ðŸªœ Batch step - 791 -- sub batch step 3166 -- lr 1.19e-04
2025-03-02 12:11:22,685 - INFO - ðŸªœ Batch step - 791 -- sub batch step 3167 -- lr 1.19e-04
2025-03-02 12:11:24,443 - INFO - Step 791 -- ðŸ”„ Training Metrics
2025-03-02 12:11:24,444 - INFO - â”œâ”€â”€ Loss: 9.0855
2025-03-02 12:11:24,444 - INFO - â”œâ”€â”€ Learning Rate: 1.19e-04
2025-03-02 12:11:24,444 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:11:25,112 - INFO - ðŸªœ Batch step - 792 -- sub batch step 3168 -- lr 1.19e-04
2025-03-02 12:11:27,271 - INFO - ðŸªœ Batch step - 792 -- sub batch step 3169 -- lr 1.19e-04
2025-03-02 12:11:29,450 - INFO - ðŸªœ Batch step - 792 -- sub batch step 3170 -- lr 1.19e-04
2025-03-02 12:11:31,603 - INFO - ðŸªœ Batch step - 792 -- sub batch step 3171 -- lr 1.19e-04
2025-03-02 12:11:33,124 - INFO - Step 792 -- ðŸ”„ Training Metrics
2025-03-02 12:11:33,124 - INFO - â”œâ”€â”€ Loss: 9.0616
2025-03-02 12:11:33,124 - INFO - â”œâ”€â”€ Learning Rate: 1.19e-04
2025-03-02 12:11:33,124 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:11:33,798 - INFO - ðŸªœ Batch step - 793 -- sub batch step 3172 -- lr 1.19e-04
2025-03-02 12:11:35,944 - INFO - ðŸªœ Batch step - 793 -- sub batch step 3173 -- lr 1.19e-04
2025-03-02 12:11:38,362 - INFO - ðŸªœ Batch step - 793 -- sub batch step 3174 -- lr 1.19e-04
2025-03-02 12:11:40,520 - INFO - ðŸªœ Batch step - 793 -- sub batch step 3175 -- lr 1.19e-04
2025-03-02 12:11:42,481 - INFO - Step 793 -- ðŸ”„ Training Metrics
2025-03-02 12:11:42,482 - INFO - â”œâ”€â”€ Loss: 9.0503
2025-03-02 12:11:42,482 - INFO - â”œâ”€â”€ Learning Rate: 1.19e-04
2025-03-02 12:11:42,482 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:11:43,152 - INFO - ðŸªœ Batch step - 794 -- sub batch step 3176 -- lr 1.19e-04
2025-03-02 12:11:45,312 - INFO - ðŸªœ Batch step - 794 -- sub batch step 3177 -- lr 1.19e-04
2025-03-02 12:11:47,488 - INFO - ðŸªœ Batch step - 794 -- sub batch step 3178 -- lr 1.19e-04
2025-03-02 12:11:49,646 - INFO - ðŸªœ Batch step - 794 -- sub batch step 3179 -- lr 1.19e-04
2025-03-02 12:11:51,154 - INFO - Step 794 -- ðŸ”„ Training Metrics
2025-03-02 12:11:51,155 - INFO - â”œâ”€â”€ Loss: 9.0655
2025-03-02 12:11:51,155 - INFO - â”œâ”€â”€ Learning Rate: 1.19e-04
2025-03-02 12:11:51,155 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:11:51,828 - INFO - ðŸªœ Batch step - 795 -- sub batch step 3180 -- lr 1.19e-04
2025-03-02 12:11:53,976 - INFO - ðŸªœ Batch step - 795 -- sub batch step 3181 -- lr 1.19e-04
2025-03-02 12:11:56,827 - INFO - ðŸªœ Batch step - 795 -- sub batch step 3182 -- lr 1.19e-04
2025-03-02 12:11:58,982 - INFO - ðŸªœ Batch step - 795 -- sub batch step 3183 -- lr 1.19e-04
2025-03-02 12:12:00,705 - INFO - Step 795 -- ðŸ”„ Training Metrics
2025-03-02 12:12:00,706 - INFO - â”œâ”€â”€ Loss: 9.0448
2025-03-02 12:12:00,706 - INFO - â”œâ”€â”€ Learning Rate: 1.19e-04
2025-03-02 12:12:00,706 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:12:01,388 - INFO - ðŸªœ Batch step - 796 -- sub batch step 3184 -- lr 1.19e-04
2025-03-02 12:12:03,547 - INFO - ðŸªœ Batch step - 796 -- sub batch step 3185 -- lr 1.19e-04
2025-03-02 12:12:05,718 - INFO - ðŸªœ Batch step - 796 -- sub batch step 3186 -- lr 1.19e-04
2025-03-02 12:12:07,874 - INFO - ðŸªœ Batch step - 796 -- sub batch step 3187 -- lr 1.19e-04
2025-03-02 12:12:09,415 - INFO - Step 796 -- ðŸ”„ Training Metrics
2025-03-02 12:12:09,415 - INFO - â”œâ”€â”€ Loss: 9.0607
2025-03-02 12:12:09,415 - INFO - â”œâ”€â”€ Learning Rate: 1.19e-04
2025-03-02 12:12:09,416 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:12:10,082 - INFO - ðŸªœ Batch step - 797 -- sub batch step 3188 -- lr 1.20e-04
2025-03-02 12:12:12,240 - INFO - ðŸªœ Batch step - 797 -- sub batch step 3189 -- lr 1.20e-04
2025-03-02 12:12:14,925 - INFO - ðŸªœ Batch step - 797 -- sub batch step 3190 -- lr 1.20e-04
2025-03-02 12:12:17,074 - INFO - ðŸªœ Batch step - 797 -- sub batch step 3191 -- lr 1.20e-04
2025-03-02 12:12:18,642 - INFO - Step 797 -- ðŸ”„ Training Metrics
2025-03-02 12:12:18,642 - INFO - â”œâ”€â”€ Loss: 9.0661
2025-03-02 12:12:18,643 - INFO - â”œâ”€â”€ Learning Rate: 1.20e-04
2025-03-02 12:12:18,643 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:12:19,318 - INFO - ðŸªœ Batch step - 798 -- sub batch step 3192 -- lr 1.20e-04
2025-03-02 12:12:21,467 - INFO - ðŸªœ Batch step - 798 -- sub batch step 3193 -- lr 1.20e-04
2025-03-02 12:12:23,648 - INFO - ðŸªœ Batch step - 798 -- sub batch step 3194 -- lr 1.20e-04
2025-03-02 12:12:25,809 - INFO - ðŸªœ Batch step - 798 -- sub batch step 3195 -- lr 1.20e-04
2025-03-02 12:12:27,343 - INFO - Step 798 -- ðŸ”„ Training Metrics
2025-03-02 12:12:27,343 - INFO - â”œâ”€â”€ Loss: 9.0202
2025-03-02 12:12:27,344 - INFO - â”œâ”€â”€ Learning Rate: 1.20e-04
2025-03-02 12:12:27,344 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:12:28,017 - INFO - ðŸªœ Batch step - 799 -- sub batch step 3196 -- lr 1.20e-04
2025-03-02 12:12:30,174 - INFO - ðŸªœ Batch step - 799 -- sub batch step 3197 -- lr 1.20e-04
2025-03-02 12:12:32,457 - INFO - ðŸªœ Batch step - 799 -- sub batch step 3198 -- lr 1.20e-04
2025-03-02 12:12:34,613 - INFO - ðŸªœ Batch step - 799 -- sub batch step 3199 -- lr 1.20e-04
2025-03-02 12:12:36,127 - INFO - Step 799 -- ðŸ”„ Training Metrics
2025-03-02 12:12:36,127 - INFO - â”œâ”€â”€ Loss: 9.0304
2025-03-02 12:12:36,127 - INFO - â”œâ”€â”€ Learning Rate: 1.20e-04
2025-03-02 12:12:36,128 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:12:37,326 - INFO - ðŸªœ Batch step - 800 -- sub batch step 3200 -- lr 1.20e-04
2025-03-02 12:12:39,485 - INFO - ðŸªœ Batch step - 800 -- sub batch step 3201 -- lr 1.20e-04
2025-03-02 12:12:41,649 - INFO - ðŸªœ Batch step - 800 -- sub batch step 3202 -- lr 1.20e-04
2025-03-02 12:12:43,825 - INFO - ðŸªœ Batch step - 800 -- sub batch step 3203 -- lr 1.20e-04
2025-03-02 12:12:45,444 - INFO - Step 800 -- ðŸ”„ Training Metrics
2025-03-02 12:12:45,445 - INFO - â”œâ”€â”€ Loss: 9.0225
2025-03-02 12:12:45,445 - INFO - â”œâ”€â”€ Learning Rate: 1.20e-04
2025-03-02 12:12:45,445 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:12:46,118 - INFO - ðŸªœ Batch step - 801 -- sub batch step 3204 -- lr 1.20e-04
2025-03-02 12:12:48,272 - INFO - ðŸªœ Batch step - 801 -- sub batch step 3205 -- lr 1.20e-04
2025-03-02 12:12:50,420 - INFO - ðŸªœ Batch step - 801 -- sub batch step 3206 -- lr 1.20e-04
2025-03-02 12:12:52,829 - INFO - ðŸªœ Batch step - 801 -- sub batch step 3207 -- lr 1.20e-04
2025-03-02 12:12:54,661 - INFO - Step 801 -- ðŸ”„ Training Metrics
2025-03-02 12:12:54,661 - INFO - â”œâ”€â”€ Loss: 9.0256
2025-03-02 12:12:54,661 - INFO - â”œâ”€â”€ Learning Rate: 1.20e-04
2025-03-02 12:12:54,661 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:12:55,327 - INFO - ðŸªœ Batch step - 802 -- sub batch step 3208 -- lr 1.20e-04
2025-03-02 12:12:57,486 - INFO - ðŸªœ Batch step - 802 -- sub batch step 3209 -- lr 1.20e-04
2025-03-02 12:12:59,642 - INFO - ðŸªœ Batch step - 802 -- sub batch step 3210 -- lr 1.20e-04
2025-03-02 12:13:01,811 - INFO - ðŸªœ Batch step - 802 -- sub batch step 3211 -- lr 1.20e-04
2025-03-02 12:13:03,355 - INFO - Step 802 -- ðŸ”„ Training Metrics
2025-03-02 12:13:03,356 - INFO - â”œâ”€â”€ Loss: 9.0114
2025-03-02 12:13:03,356 - INFO - â”œâ”€â”€ Learning Rate: 1.20e-04
2025-03-02 12:13:03,356 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:13:04,035 - INFO - ðŸªœ Batch step - 803 -- sub batch step 3212 -- lr 1.20e-04
2025-03-02 12:13:06,187 - INFO - ðŸªœ Batch step - 803 -- sub batch step 3213 -- lr 1.20e-04
2025-03-02 12:13:08,342 - INFO - ðŸªœ Batch step - 803 -- sub batch step 3214 -- lr 1.20e-04
2025-03-02 12:13:10,720 - INFO - ðŸªœ Batch step - 803 -- sub batch step 3215 -- lr 1.20e-04
2025-03-02 12:13:12,686 - INFO - Step 803 -- ðŸ”„ Training Metrics
2025-03-02 12:13:12,686 - INFO - â”œâ”€â”€ Loss: 8.9997
2025-03-02 12:13:12,686 - INFO - â”œâ”€â”€ Learning Rate: 1.20e-04
2025-03-02 12:13:12,686 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:13:13,356 - INFO - ðŸªœ Batch step - 804 -- sub batch step 3216 -- lr 1.21e-04
2025-03-02 12:13:15,507 - INFO - ðŸªœ Batch step - 804 -- sub batch step 3217 -- lr 1.21e-04
2025-03-02 12:13:17,657 - INFO - ðŸªœ Batch step - 804 -- sub batch step 3218 -- lr 1.21e-04
2025-03-02 12:13:19,830 - INFO - ðŸªœ Batch step - 804 -- sub batch step 3219 -- lr 1.21e-04
2025-03-02 12:13:21,374 - INFO - Step 804 -- ðŸ”„ Training Metrics
2025-03-02 12:13:21,375 - INFO - â”œâ”€â”€ Loss: 9.0004
2025-03-02 12:13:21,375 - INFO - â”œâ”€â”€ Learning Rate: 1.21e-04
2025-03-02 12:13:21,375 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:13:22,047 - INFO - ðŸªœ Batch step - 805 -- sub batch step 3220 -- lr 1.21e-04
2025-03-02 12:13:24,197 - INFO - ðŸªœ Batch step - 805 -- sub batch step 3221 -- lr 1.21e-04
2025-03-02 12:13:26,351 - INFO - ðŸªœ Batch step - 805 -- sub batch step 3222 -- lr 1.21e-04
2025-03-02 12:13:28,993 - INFO - ðŸªœ Batch step - 805 -- sub batch step 3223 -- lr 1.21e-04
2025-03-02 12:13:30,618 - INFO - Step 805 -- ðŸ”„ Training Metrics
2025-03-02 12:13:30,619 - INFO - â”œâ”€â”€ Loss: 8.9786
2025-03-02 12:13:30,619 - INFO - â”œâ”€â”€ Learning Rate: 1.21e-04
2025-03-02 12:13:30,619 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:13:31,295 - INFO - ðŸªœ Batch step - 806 -- sub batch step 3224 -- lr 1.21e-04
2025-03-02 12:13:33,449 - INFO - ðŸªœ Batch step - 806 -- sub batch step 3225 -- lr 1.21e-04
2025-03-02 12:13:35,596 - INFO - ðŸªœ Batch step - 806 -- sub batch step 3226 -- lr 1.21e-04
2025-03-02 12:13:37,771 - INFO - ðŸªœ Batch step - 806 -- sub batch step 3227 -- lr 1.21e-04
2025-03-02 12:13:39,314 - INFO - Step 806 -- ðŸ”„ Training Metrics
2025-03-02 12:13:39,315 - INFO - â”œâ”€â”€ Loss: 8.9950
2025-03-02 12:13:39,315 - INFO - â”œâ”€â”€ Learning Rate: 1.21e-04
2025-03-02 12:13:39,315 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:13:39,983 - INFO - ðŸªœ Batch step - 807 -- sub batch step 3228 -- lr 1.21e-04
2025-03-02 12:13:42,137 - INFO - ðŸªœ Batch step - 807 -- sub batch step 3229 -- lr 1.21e-04
2025-03-02 12:13:44,290 - INFO - ðŸªœ Batch step - 807 -- sub batch step 3230 -- lr 1.21e-04
2025-03-02 12:13:47,096 - INFO - ðŸªœ Batch step - 807 -- sub batch step 3231 -- lr 1.21e-04
2025-03-02 12:13:48,588 - INFO - Step 807 -- ðŸ”„ Training Metrics
2025-03-02 12:13:48,588 - INFO - â”œâ”€â”€ Loss: 8.9743
2025-03-02 12:13:48,588 - INFO - â”œâ”€â”€ Learning Rate: 1.21e-04
2025-03-02 12:13:48,588 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:13:49,261 - INFO - ðŸªœ Batch step - 808 -- sub batch step 3232 -- lr 1.21e-04
2025-03-02 12:13:51,408 - INFO - ðŸªœ Batch step - 808 -- sub batch step 3233 -- lr 1.21e-04
2025-03-02 12:13:53,560 - INFO - ðŸªœ Batch step - 808 -- sub batch step 3234 -- lr 1.21e-04
2025-03-02 12:13:55,734 - INFO - ðŸªœ Batch step - 808 -- sub batch step 3235 -- lr 1.21e-04
2025-03-02 12:13:57,290 - INFO - Step 808 -- ðŸ”„ Training Metrics
2025-03-02 12:13:57,291 - INFO - â”œâ”€â”€ Loss: 8.9387
2025-03-02 12:13:57,291 - INFO - â”œâ”€â”€ Learning Rate: 1.21e-04
2025-03-02 12:13:57,291 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:13:57,958 - INFO - ðŸªœ Batch step - 809 -- sub batch step 3236 -- lr 1.21e-04
2025-03-02 12:14:00,112 - INFO - ðŸªœ Batch step - 809 -- sub batch step 3237 -- lr 1.21e-04
2025-03-02 12:14:02,258 - INFO - ðŸªœ Batch step - 809 -- sub batch step 3238 -- lr 1.21e-04
2025-03-02 12:14:04,872 - INFO - ðŸªœ Batch step - 809 -- sub batch step 3239 -- lr 1.21e-04
2025-03-02 12:14:06,425 - INFO - Step 809 -- ðŸ”„ Training Metrics
2025-03-02 12:14:06,425 - INFO - â”œâ”€â”€ Loss: 8.9692
2025-03-02 12:14:06,425 - INFO - â”œâ”€â”€ Learning Rate: 1.21e-04
2025-03-02 12:14:06,425 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:14:07,098 - INFO - ðŸªœ Batch step - 810 -- sub batch step 3240 -- lr 1.21e-04
2025-03-02 12:14:09,246 - INFO - ðŸªœ Batch step - 810 -- sub batch step 3241 -- lr 1.21e-04
2025-03-02 12:14:11,401 - INFO - ðŸªœ Batch step - 810 -- sub batch step 3242 -- lr 1.21e-04
2025-03-02 12:14:13,568 - INFO - ðŸªœ Batch step - 810 -- sub batch step 3243 -- lr 1.21e-04
2025-03-02 12:14:15,098 - INFO - Step 810 -- ðŸ”„ Training Metrics
2025-03-02 12:14:15,098 - INFO - â”œâ”€â”€ Loss: 8.9424
2025-03-02 12:14:15,098 - INFO - â”œâ”€â”€ Learning Rate: 1.21e-04
2025-03-02 12:14:15,098 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:14:15,771 - INFO - ðŸªœ Batch step - 811 -- sub batch step 3244 -- lr 1.22e-04
2025-03-02 12:14:17,925 - INFO - ðŸªœ Batch step - 811 -- sub batch step 3245 -- lr 1.22e-04
2025-03-02 12:14:20,571 - INFO - ðŸªœ Batch step - 811 -- sub batch step 3246 -- lr 1.22e-04
2025-03-02 12:14:22,722 - INFO - ðŸªœ Batch step - 811 -- sub batch step 3247 -- lr 1.22e-04
2025-03-02 12:14:24,681 - INFO - Step 811 -- ðŸ”„ Training Metrics
2025-03-02 12:14:24,681 - INFO - â”œâ”€â”€ Loss: 8.9420
2025-03-02 12:14:24,681 - INFO - â”œâ”€â”€ Learning Rate: 1.22e-04
2025-03-02 12:14:24,682 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:14:25,349 - INFO - ðŸªœ Batch step - 812 -- sub batch step 3248 -- lr 1.22e-04
2025-03-02 12:14:27,501 - INFO - ðŸªœ Batch step - 812 -- sub batch step 3249 -- lr 1.22e-04
2025-03-02 12:14:29,673 - INFO - ðŸªœ Batch step - 812 -- sub batch step 3250 -- lr 1.22e-04
2025-03-02 12:14:31,819 - INFO - ðŸªœ Batch step - 812 -- sub batch step 3251 -- lr 1.22e-04
2025-03-02 12:14:33,361 - INFO - Step 812 -- ðŸ”„ Training Metrics
2025-03-02 12:14:33,361 - INFO - â”œâ”€â”€ Loss: 8.9317
2025-03-02 12:14:33,361 - INFO - â”œâ”€â”€ Learning Rate: 1.22e-04
2025-03-02 12:14:33,361 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:14:34,033 - INFO - ðŸªœ Batch step - 813 -- sub batch step 3252 -- lr 1.22e-04
2025-03-02 12:14:36,178 - INFO - ðŸªœ Batch step - 813 -- sub batch step 3253 -- lr 1.22e-04
2025-03-02 12:14:39,004 - INFO - ðŸªœ Batch step - 813 -- sub batch step 3254 -- lr 1.22e-04
2025-03-02 12:14:41,165 - INFO - ðŸªœ Batch step - 813 -- sub batch step 3255 -- lr 1.22e-04
2025-03-02 12:14:42,657 - INFO - Step 813 -- ðŸ”„ Training Metrics
2025-03-02 12:14:42,658 - INFO - â”œâ”€â”€ Loss: 8.9188
2025-03-02 12:14:42,658 - INFO - â”œâ”€â”€ Learning Rate: 1.22e-04
2025-03-02 12:14:42,658 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:14:43,322 - INFO - ðŸªœ Batch step - 814 -- sub batch step 3256 -- lr 1.22e-04
2025-03-02 12:14:45,474 - INFO - ðŸªœ Batch step - 814 -- sub batch step 3257 -- lr 1.22e-04
2025-03-02 12:14:47,638 - INFO - ðŸªœ Batch step - 814 -- sub batch step 3258 -- lr 1.22e-04
2025-03-02 12:14:49,790 - INFO - ðŸªœ Batch step - 814 -- sub batch step 3259 -- lr 1.22e-04
2025-03-02 12:14:51,342 - INFO - Step 814 -- ðŸ”„ Training Metrics
2025-03-02 12:14:51,342 - INFO - â”œâ”€â”€ Loss: 8.9231
2025-03-02 12:14:51,342 - INFO - â”œâ”€â”€ Learning Rate: 1.22e-04
2025-03-02 12:14:51,342 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:14:52,013 - INFO - ðŸªœ Batch step - 815 -- sub batch step 3260 -- lr 1.22e-04
2025-03-02 12:14:54,161 - INFO - ðŸªœ Batch step - 815 -- sub batch step 3261 -- lr 1.22e-04
2025-03-02 12:14:56,538 - INFO - ðŸªœ Batch step - 815 -- sub batch step 3262 -- lr 1.22e-04
2025-03-02 12:14:58,687 - INFO - ðŸªœ Batch step - 815 -- sub batch step 3263 -- lr 1.22e-04
2025-03-02 12:15:00,662 - INFO - Step 815 -- ðŸ”„ Training Metrics
2025-03-02 12:15:00,662 - INFO - â”œâ”€â”€ Loss: 8.9284
2025-03-02 12:15:00,662 - INFO - â”œâ”€â”€ Learning Rate: 1.22e-04
2025-03-02 12:15:00,662 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:15:01,337 - INFO - ðŸªœ Batch step - 816 -- sub batch step 3264 -- lr 1.22e-04
2025-03-02 12:15:03,507 - INFO - ðŸªœ Batch step - 816 -- sub batch step 3265 -- lr 1.22e-04
2025-03-02 12:15:05,680 - INFO - ðŸªœ Batch step - 816 -- sub batch step 3266 -- lr 1.22e-04
2025-03-02 12:15:07,833 - INFO - ðŸªœ Batch step - 816 -- sub batch step 3267 -- lr 1.22e-04
2025-03-02 12:15:09,338 - INFO - Step 816 -- ðŸ”„ Training Metrics
2025-03-02 12:15:09,339 - INFO - â”œâ”€â”€ Loss: 8.9226
2025-03-02 12:15:09,339 - INFO - â”œâ”€â”€ Learning Rate: 1.22e-04
2025-03-02 12:15:09,339 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:15:10,009 - INFO - ðŸªœ Batch step - 817 -- sub batch step 3268 -- lr 1.23e-04
2025-03-02 12:15:12,167 - INFO - ðŸªœ Batch step - 817 -- sub batch step 3269 -- lr 1.23e-04
2025-03-02 12:15:14,881 - INFO - ðŸªœ Batch step - 817 -- sub batch step 3270 -- lr 1.23e-04
2025-03-02 12:15:17,029 - INFO - ðŸªœ Batch step - 817 -- sub batch step 3271 -- lr 1.23e-04
2025-03-02 12:15:18,537 - INFO - Step 817 -- ðŸ”„ Training Metrics
2025-03-02 12:15:18,537 - INFO - â”œâ”€â”€ Loss: 8.8928
2025-03-02 12:15:18,538 - INFO - â”œâ”€â”€ Learning Rate: 1.23e-04
2025-03-02 12:15:18,538 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:15:19,210 - INFO - ðŸªœ Batch step - 818 -- sub batch step 3272 -- lr 1.23e-04
2025-03-02 12:15:21,361 - INFO - ðŸªœ Batch step - 818 -- sub batch step 3273 -- lr 1.23e-04
2025-03-02 12:15:23,604 - INFO - ðŸªœ Batch step - 818 -- sub batch step 3274 -- lr 1.23e-04
2025-03-02 12:15:25,761 - INFO - ðŸªœ Batch step - 818 -- sub batch step 3275 -- lr 1.23e-04
2025-03-02 12:15:27,271 - INFO - Step 818 -- ðŸ”„ Training Metrics
2025-03-02 12:15:27,271 - INFO - â”œâ”€â”€ Loss: 8.8905
2025-03-02 12:15:27,272 - INFO - â”œâ”€â”€ Learning Rate: 1.23e-04
2025-03-02 12:15:27,272 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:15:27,941 - INFO - ðŸªœ Batch step - 819 -- sub batch step 3276 -- lr 1.23e-04
2025-03-02 12:15:30,098 - INFO - ðŸªœ Batch step - 819 -- sub batch step 3277 -- lr 1.23e-04
2025-03-02 12:15:32,381 - INFO - ðŸªœ Batch step - 819 -- sub batch step 3278 -- lr 1.23e-04
2025-03-02 12:15:34,539 - INFO - ðŸªœ Batch step - 819 -- sub batch step 3279 -- lr 1.23e-04
2025-03-02 12:15:36,141 - INFO - Step 819 -- ðŸ”„ Training Metrics
2025-03-02 12:15:36,141 - INFO - â”œâ”€â”€ Loss: 8.8920
2025-03-02 12:15:36,141 - INFO - â”œâ”€â”€ Learning Rate: 1.23e-04
2025-03-02 12:15:36,142 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:15:37,375 - INFO - ðŸªœ Batch step - 820 -- sub batch step 3280 -- lr 1.23e-04
2025-03-02 12:15:39,536 - INFO - ðŸªœ Batch step - 820 -- sub batch step 3281 -- lr 1.23e-04
2025-03-02 12:15:41,701 - INFO - ðŸªœ Batch step - 820 -- sub batch step 3282 -- lr 1.23e-04
2025-03-02 12:15:43,879 - INFO - ðŸªœ Batch step - 820 -- sub batch step 3283 -- lr 1.23e-04
2025-03-02 12:15:45,531 - INFO - Step 820 -- ðŸ”„ Training Metrics
2025-03-02 12:15:45,532 - INFO - â”œâ”€â”€ Loss: 8.8801
2025-03-02 12:15:45,532 - INFO - â”œâ”€â”€ Learning Rate: 1.23e-04
2025-03-02 12:15:45,532 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:15:46,208 - INFO - ðŸªœ Batch step - 821 -- sub batch step 3284 -- lr 1.23e-04
2025-03-02 12:15:48,364 - INFO - ðŸªœ Batch step - 821 -- sub batch step 3285 -- lr 1.23e-04
2025-03-02 12:15:50,514 - INFO - ðŸªœ Batch step - 821 -- sub batch step 3286 -- lr 1.23e-04
2025-03-02 12:15:52,981 - INFO - ðŸªœ Batch step - 821 -- sub batch step 3287 -- lr 1.23e-04
2025-03-02 12:15:55,045 - INFO - Step 821 -- ðŸ”„ Training Metrics
2025-03-02 12:15:55,045 - INFO - â”œâ”€â”€ Loss: 8.8725
2025-03-02 12:15:55,045 - INFO - â”œâ”€â”€ Learning Rate: 1.23e-04
2025-03-02 12:15:55,045 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:15:55,811 - INFO - ðŸªœ Batch step - 822 -- sub batch step 3288 -- lr 1.23e-04
2025-03-02 12:15:57,966 - INFO - ðŸªœ Batch step - 822 -- sub batch step 3289 -- lr 1.23e-04
2025-03-02 12:16:00,119 - INFO - ðŸªœ Batch step - 822 -- sub batch step 3290 -- lr 1.23e-04
2025-03-02 12:16:02,289 - INFO - ðŸªœ Batch step - 822 -- sub batch step 3291 -- lr 1.23e-04
2025-03-02 12:16:04,221 - INFO - Step 822 -- ðŸ”„ Training Metrics
2025-03-02 12:16:04,221 - INFO - â”œâ”€â”€ Loss: 8.8872
2025-03-02 12:16:04,221 - INFO - â”œâ”€â”€ Learning Rate: 1.23e-04
2025-03-02 12:16:04,221 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:16:04,894 - INFO - ðŸªœ Batch step - 823 -- sub batch step 3292 -- lr 1.23e-04
2025-03-02 12:16:07,050 - INFO - ðŸªœ Batch step - 823 -- sub batch step 3293 -- lr 1.23e-04
2025-03-02 12:16:09,203 - INFO - ðŸªœ Batch step - 823 -- sub batch step 3294 -- lr 1.23e-04
2025-03-02 12:16:11,826 - INFO - ðŸªœ Batch step - 823 -- sub batch step 3295 -- lr 1.23e-04
2025-03-02 12:16:13,482 - INFO - Step 823 -- ðŸ”„ Training Metrics
2025-03-02 12:16:13,482 - INFO - â”œâ”€â”€ Loss: 8.8755
2025-03-02 12:16:13,482 - INFO - â”œâ”€â”€ Learning Rate: 1.23e-04
2025-03-02 12:16:13,482 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:16:14,150 - INFO - ðŸªœ Batch step - 824 -- sub batch step 3296 -- lr 1.24e-04
2025-03-02 12:16:16,481 - INFO - ðŸªœ Batch step - 824 -- sub batch step 3297 -- lr 1.24e-04
2025-03-02 12:16:18,630 - INFO - ðŸªœ Batch step - 824 -- sub batch step 3298 -- lr 1.24e-04
2025-03-02 12:16:21,262 - INFO - ðŸªœ Batch step - 824 -- sub batch step 3299 -- lr 1.24e-04
2025-03-02 12:16:22,759 - INFO - Step 824 -- ðŸ”„ Training Metrics
2025-03-02 12:16:22,759 - INFO - â”œâ”€â”€ Loss: 8.8542
2025-03-02 12:16:22,760 - INFO - â”œâ”€â”€ Learning Rate: 1.24e-04
2025-03-02 12:16:22,760 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:16:23,454 - INFO - ðŸªœ Batch step - 825 -- sub batch step 3300 -- lr 1.24e-04
2025-03-02 12:16:25,600 - INFO - ðŸªœ Batch step - 825 -- sub batch step 3301 -- lr 1.24e-04
2025-03-02 12:16:27,772 - INFO - ðŸªœ Batch step - 825 -- sub batch step 3302 -- lr 1.24e-04
2025-03-02 12:16:30,506 - INFO - ðŸªœ Batch step - 825 -- sub batch step 3303 -- lr 1.24e-04
2025-03-02 12:16:33,575 - INFO - Step 825 -- ðŸ”„ Training Metrics
2025-03-02 12:16:33,575 - INFO - â”œâ”€â”€ Loss: 8.8220
2025-03-02 12:16:33,575 - INFO - â”œâ”€â”€ Learning Rate: 1.24e-04
2025-03-02 12:16:33,576 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:16:34,288 - INFO - ðŸªœ Batch step - 826 -- sub batch step 3304 -- lr 1.24e-04
2025-03-02 12:16:36,444 - INFO - ðŸªœ Batch step - 826 -- sub batch step 3305 -- lr 1.24e-04
2025-03-02 12:16:38,595 - INFO - ðŸªœ Batch step - 826 -- sub batch step 3306 -- lr 1.24e-04
2025-03-02 12:16:40,772 - INFO - ðŸªœ Batch step - 826 -- sub batch step 3307 -- lr 1.24e-04
2025-03-02 12:16:42,422 - INFO - Step 826 -- ðŸ”„ Training Metrics
2025-03-02 12:16:42,422 - INFO - â”œâ”€â”€ Loss: 8.8428
2025-03-02 12:16:42,423 - INFO - â”œâ”€â”€ Learning Rate: 1.24e-04
2025-03-02 12:16:42,423 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:16:43,091 - INFO - ðŸªœ Batch step - 827 -- sub batch step 3308 -- lr 1.24e-04
2025-03-02 12:16:45,246 - INFO - ðŸªœ Batch step - 827 -- sub batch step 3309 -- lr 1.24e-04
2025-03-02 12:16:47,410 - INFO - ðŸªœ Batch step - 827 -- sub batch step 3310 -- lr 1.24e-04
2025-03-02 12:16:50,226 - INFO - ðŸªœ Batch step - 827 -- sub batch step 3311 -- lr 1.24e-04
2025-03-02 12:16:51,719 - INFO - Step 827 -- ðŸ”„ Training Metrics
2025-03-02 12:16:51,719 - INFO - â”œâ”€â”€ Loss: 8.8502
2025-03-02 12:16:51,719 - INFO - â”œâ”€â”€ Learning Rate: 1.24e-04
2025-03-02 12:16:51,719 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:16:52,400 - INFO - ðŸªœ Batch step - 828 -- sub batch step 3312 -- lr 1.24e-04
2025-03-02 12:16:54,547 - INFO - ðŸªœ Batch step - 828 -- sub batch step 3313 -- lr 1.24e-04
2025-03-02 12:16:56,700 - INFO - ðŸªœ Batch step - 828 -- sub batch step 3314 -- lr 1.24e-04
2025-03-02 12:16:58,874 - INFO - ðŸªœ Batch step - 828 -- sub batch step 3315 -- lr 1.24e-04
2025-03-02 12:17:00,411 - INFO - Step 828 -- ðŸ”„ Training Metrics
2025-03-02 12:17:00,412 - INFO - â”œâ”€â”€ Loss: 8.8180
2025-03-02 12:17:00,412 - INFO - â”œâ”€â”€ Learning Rate: 1.24e-04
2025-03-02 12:17:00,412 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:17:01,083 - INFO - ðŸªœ Batch step - 829 -- sub batch step 3316 -- lr 1.24e-04
2025-03-02 12:17:03,237 - INFO - ðŸªœ Batch step - 829 -- sub batch step 3317 -- lr 1.24e-04
2025-03-02 12:17:05,386 - INFO - ðŸªœ Batch step - 829 -- sub batch step 3318 -- lr 1.24e-04
2025-03-02 12:17:08,033 - INFO - ðŸªœ Batch step - 829 -- sub batch step 3319 -- lr 1.24e-04
2025-03-02 12:17:09,739 - INFO - Step 829 -- ðŸ”„ Training Metrics
2025-03-02 12:17:09,739 - INFO - â”œâ”€â”€ Loss: 8.8162
2025-03-02 12:17:09,739 - INFO - â”œâ”€â”€ Learning Rate: 1.24e-04
2025-03-02 12:17:09,739 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:17:10,415 - INFO - ðŸªœ Batch step - 830 -- sub batch step 3320 -- lr 1.24e-04
2025-03-02 12:17:12,566 - INFO - ðŸªœ Batch step - 830 -- sub batch step 3321 -- lr 1.24e-04
2025-03-02 12:17:14,720 - INFO - ðŸªœ Batch step - 830 -- sub batch step 3322 -- lr 1.24e-04
2025-03-02 12:17:16,881 - INFO - ðŸªœ Batch step - 830 -- sub batch step 3323 -- lr 1.24e-04
2025-03-02 12:17:18,405 - INFO - Step 830 -- ðŸ”„ Training Metrics
2025-03-02 12:17:18,405 - INFO - â”œâ”€â”€ Loss: 8.8024
2025-03-02 12:17:18,405 - INFO - â”œâ”€â”€ Learning Rate: 1.24e-04
2025-03-02 12:17:18,405 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:17:19,082 - INFO - ðŸªœ Batch step - 831 -- sub batch step 3324 -- lr 1.25e-04
2025-03-02 12:17:21,239 - INFO - ðŸªœ Batch step - 831 -- sub batch step 3325 -- lr 1.25e-04
2025-03-02 12:17:23,938 - INFO - ðŸªœ Batch step - 831 -- sub batch step 3326 -- lr 1.25e-04
2025-03-02 12:17:26,094 - INFO - ðŸªœ Batch step - 831 -- sub batch step 3327 -- lr 1.25e-04
2025-03-02 12:17:27,598 - INFO - Step 831 -- ðŸ”„ Training Metrics
2025-03-02 12:17:27,599 - INFO - â”œâ”€â”€ Loss: 8.8266
2025-03-02 12:17:27,599 - INFO - â”œâ”€â”€ Learning Rate: 1.25e-04
2025-03-02 12:17:27,599 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:17:28,272 - INFO - ðŸªœ Batch step - 832 -- sub batch step 3328 -- lr 1.25e-04
2025-03-02 12:17:30,432 - INFO - ðŸªœ Batch step - 832 -- sub batch step 3329 -- lr 1.25e-04
2025-03-02 12:17:32,611 - INFO - ðŸªœ Batch step - 832 -- sub batch step 3330 -- lr 1.25e-04
2025-03-02 12:17:34,760 - INFO - ðŸªœ Batch step - 832 -- sub batch step 3331 -- lr 1.25e-04
2025-03-02 12:17:36,283 - INFO - Step 832 -- ðŸ”„ Training Metrics
2025-03-02 12:17:36,284 - INFO - â”œâ”€â”€ Loss: 8.7982
2025-03-02 12:17:36,284 - INFO - â”œâ”€â”€ Learning Rate: 1.25e-04
2025-03-02 12:17:36,284 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:17:36,960 - INFO - ðŸªœ Batch step - 833 -- sub batch step 3332 -- lr 1.25e-04
2025-03-02 12:17:39,109 - INFO - ðŸªœ Batch step - 833 -- sub batch step 3333 -- lr 1.25e-04
2025-03-02 12:17:41,529 - INFO - ðŸªœ Batch step - 833 -- sub batch step 3334 -- lr 1.25e-04
2025-03-02 12:17:43,685 - INFO - ðŸªœ Batch step - 833 -- sub batch step 3335 -- lr 1.25e-04
2025-03-02 12:17:45,522 - INFO - Step 833 -- ðŸ”„ Training Metrics
2025-03-02 12:17:45,523 - INFO - â”œâ”€â”€ Loss: 8.7917
2025-03-02 12:17:45,523 - INFO - â”œâ”€â”€ Learning Rate: 1.25e-04
2025-03-02 12:17:45,523 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:17:46,193 - INFO - ðŸªœ Batch step - 834 -- sub batch step 3336 -- lr 1.25e-04
2025-03-02 12:17:48,351 - INFO - ðŸªœ Batch step - 834 -- sub batch step 3337 -- lr 1.25e-04
2025-03-02 12:17:50,531 - INFO - ðŸªœ Batch step - 834 -- sub batch step 3338 -- lr 1.25e-04
2025-03-02 12:17:52,688 - INFO - ðŸªœ Batch step - 834 -- sub batch step 3339 -- lr 1.25e-04
2025-03-02 12:17:54,201 - INFO - Step 834 -- ðŸ”„ Training Metrics
2025-03-02 12:17:54,201 - INFO - â”œâ”€â”€ Loss: 8.8000
2025-03-02 12:17:54,202 - INFO - â”œâ”€â”€ Learning Rate: 1.25e-04
2025-03-02 12:17:54,202 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:17:54,879 - INFO - ðŸªœ Batch step - 835 -- sub batch step 3340 -- lr 1.25e-04
2025-03-02 12:17:57,030 - INFO - ðŸªœ Batch step - 835 -- sub batch step 3341 -- lr 1.25e-04
2025-03-02 12:17:59,442 - INFO - ðŸªœ Batch step - 835 -- sub batch step 3342 -- lr 1.25e-04
2025-03-02 12:18:01,601 - INFO - ðŸªœ Batch step - 835 -- sub batch step 3343 -- lr 1.25e-04
2025-03-02 12:18:03,574 - INFO - Step 835 -- ðŸ”„ Training Metrics
2025-03-02 12:18:03,574 - INFO - â”œâ”€â”€ Loss: 8.7701
2025-03-02 12:18:03,574 - INFO - â”œâ”€â”€ Learning Rate: 1.25e-04
2025-03-02 12:18:03,574 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:18:04,248 - INFO - ðŸªœ Batch step - 836 -- sub batch step 3344 -- lr 1.25e-04
2025-03-02 12:18:06,403 - INFO - ðŸªœ Batch step - 836 -- sub batch step 3345 -- lr 1.25e-04
2025-03-02 12:18:08,575 - INFO - ðŸªœ Batch step - 836 -- sub batch step 3346 -- lr 1.25e-04
2025-03-02 12:18:10,730 - INFO - ðŸªœ Batch step - 836 -- sub batch step 3347 -- lr 1.25e-04
2025-03-02 12:18:12,251 - INFO - Step 836 -- ðŸ”„ Training Metrics
2025-03-02 12:18:12,251 - INFO - â”œâ”€â”€ Loss: 8.7715
2025-03-02 12:18:12,251 - INFO - â”œâ”€â”€ Learning Rate: 1.25e-04
2025-03-02 12:18:12,251 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:18:12,918 - INFO - ðŸªœ Batch step - 837 -- sub batch step 3348 -- lr 1.26e-04
2025-03-02 12:18:15,073 - INFO - ðŸªœ Batch step - 837 -- sub batch step 3349 -- lr 1.26e-04
2025-03-02 12:18:17,970 - INFO - ðŸªœ Batch step - 837 -- sub batch step 3350 -- lr 1.26e-04
2025-03-02 12:18:20,119 - INFO - ðŸªœ Batch step - 837 -- sub batch step 3351 -- lr 1.26e-04
2025-03-02 12:18:21,615 - INFO - Step 837 -- ðŸ”„ Training Metrics
2025-03-02 12:18:21,615 - INFO - â”œâ”€â”€ Loss: 8.7576
2025-03-02 12:18:21,615 - INFO - â”œâ”€â”€ Learning Rate: 1.26e-04
2025-03-02 12:18:21,615 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:18:22,292 - INFO - ðŸªœ Batch step - 838 -- sub batch step 3352 -- lr 1.26e-04
2025-03-02 12:18:24,440 - INFO - ðŸªœ Batch step - 838 -- sub batch step 3353 -- lr 1.26e-04
2025-03-02 12:18:26,612 - INFO - ðŸªœ Batch step - 838 -- sub batch step 3354 -- lr 1.26e-04
2025-03-02 12:18:28,767 - INFO - ðŸªœ Batch step - 838 -- sub batch step 3355 -- lr 1.26e-04
2025-03-02 12:18:30,289 - INFO - Step 838 -- ðŸ”„ Training Metrics
2025-03-02 12:18:30,289 - INFO - â”œâ”€â”€ Loss: 8.7494
2025-03-02 12:18:30,289 - INFO - â”œâ”€â”€ Learning Rate: 1.26e-04
2025-03-02 12:18:30,289 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:18:30,962 - INFO - ðŸªœ Batch step - 839 -- sub batch step 3356 -- lr 1.26e-04
2025-03-02 12:18:33,119 - INFO - ðŸªœ Batch step - 839 -- sub batch step 3357 -- lr 1.26e-04
2025-03-02 12:18:35,400 - INFO - ðŸªœ Batch step - 839 -- sub batch step 3358 -- lr 1.26e-04
2025-03-02 12:18:37,555 - INFO - ðŸªœ Batch step - 839 -- sub batch step 3359 -- lr 1.26e-04
2025-03-02 12:18:39,073 - INFO - Step 839 -- ðŸ”„ Training Metrics
2025-03-02 12:18:39,073 - INFO - â”œâ”€â”€ Loss: 8.7479
2025-03-02 12:18:39,073 - INFO - â”œâ”€â”€ Learning Rate: 1.26e-04
2025-03-02 12:18:39,073 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:18:40,468 - INFO - ðŸªœ Batch step - 840 -- sub batch step 3360 -- lr 1.26e-04
2025-03-02 12:18:42,628 - INFO - ðŸªœ Batch step - 840 -- sub batch step 3361 -- lr 1.26e-04
2025-03-02 12:18:44,792 - INFO - ðŸªœ Batch step - 840 -- sub batch step 3362 -- lr 1.26e-04
2025-03-02 12:18:46,976 - INFO - ðŸªœ Batch step - 840 -- sub batch step 3363 -- lr 1.26e-04
2025-03-02 12:18:48,750 - INFO - Step 840 -- ðŸ”„ Training Metrics
2025-03-02 12:18:48,750 - INFO - â”œâ”€â”€ Loss: 8.7348
2025-03-02 12:18:48,750 - INFO - â”œâ”€â”€ Learning Rate: 1.26e-04
2025-03-02 12:18:48,751 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:18:49,481 - INFO - ðŸªœ Batch step - 841 -- sub batch step 3364 -- lr 1.26e-04
2025-03-02 12:18:51,642 - INFO - ðŸªœ Batch step - 841 -- sub batch step 3365 -- lr 1.26e-04
2025-03-02 12:18:53,798 - INFO - ðŸªœ Batch step - 841 -- sub batch step 3366 -- lr 1.26e-04
2025-03-02 12:18:56,678 - INFO - ðŸªœ Batch step - 841 -- sub batch step 3367 -- lr 1.26e-04
2025-03-02 12:18:58,175 - INFO - Step 841 -- ðŸ”„ Training Metrics
2025-03-02 12:18:58,176 - INFO - â”œâ”€â”€ Loss: 8.7174
2025-03-02 12:18:58,176 - INFO - â”œâ”€â”€ Learning Rate: 1.26e-04
2025-03-02 12:18:58,176 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:18:58,852 - INFO - ðŸªœ Batch step - 842 -- sub batch step 3368 -- lr 1.26e-04
2025-03-02 12:19:01,016 - INFO - ðŸªœ Batch step - 842 -- sub batch step 3369 -- lr 1.26e-04
2025-03-02 12:19:03,176 - INFO - ðŸªœ Batch step - 842 -- sub batch step 3370 -- lr 1.26e-04
2025-03-02 12:19:05,358 - INFO - ðŸªœ Batch step - 842 -- sub batch step 3371 -- lr 1.26e-04
2025-03-02 12:19:06,861 - INFO - Step 842 -- ðŸ”„ Training Metrics
2025-03-02 12:19:06,862 - INFO - â”œâ”€â”€ Loss: 8.7345
2025-03-02 12:19:06,862 - INFO - â”œâ”€â”€ Learning Rate: 1.26e-04
2025-03-02 12:19:06,862 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:19:07,538 - INFO - ðŸªœ Batch step - 843 -- sub batch step 3372 -- lr 1.26e-04
2025-03-02 12:19:09,690 - INFO - ðŸªœ Batch step - 843 -- sub batch step 3373 -- lr 1.26e-04
2025-03-02 12:19:11,847 - INFO - ðŸªœ Batch step - 843 -- sub batch step 3374 -- lr 1.26e-04
2025-03-02 12:19:14,477 - INFO - ðŸªœ Batch step - 843 -- sub batch step 3375 -- lr 1.26e-04
2025-03-02 12:19:16,248 - INFO - Step 843 -- ðŸ”„ Training Metrics
2025-03-02 12:19:16,248 - INFO - â”œâ”€â”€ Loss: 8.7328
2025-03-02 12:19:16,248 - INFO - â”œâ”€â”€ Learning Rate: 1.26e-04
2025-03-02 12:19:16,248 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:19:16,921 - INFO - ðŸªœ Batch step - 844 -- sub batch step 3376 -- lr 1.27e-04
2025-03-02 12:19:19,080 - INFO - ðŸªœ Batch step - 844 -- sub batch step 3377 -- lr 1.27e-04
2025-03-02 12:19:21,231 - INFO - ðŸªœ Batch step - 844 -- sub batch step 3378 -- lr 1.27e-04
2025-03-02 12:19:23,415 - INFO - ðŸªœ Batch step - 844 -- sub batch step 3379 -- lr 1.27e-04
2025-03-02 12:19:24,935 - INFO - Step 844 -- ðŸ”„ Training Metrics
2025-03-02 12:19:24,936 - INFO - â”œâ”€â”€ Loss: 8.7105
2025-03-02 12:19:24,936 - INFO - â”œâ”€â”€ Learning Rate: 1.27e-04
2025-03-02 12:19:24,936 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:19:25,614 - INFO - ðŸªœ Batch step - 845 -- sub batch step 3380 -- lr 1.27e-04
2025-03-02 12:19:27,763 - INFO - ðŸªœ Batch step - 845 -- sub batch step 3381 -- lr 1.27e-04
2025-03-02 12:19:29,919 - INFO - ðŸªœ Batch step - 845 -- sub batch step 3382 -- lr 1.27e-04
2025-03-02 12:19:32,756 - INFO - ðŸªœ Batch step - 845 -- sub batch step 3383 -- lr 1.27e-04
2025-03-02 12:19:35,133 - INFO - Step 845 -- ðŸ”„ Training Metrics
2025-03-02 12:19:35,133 - INFO - â”œâ”€â”€ Loss: 8.7057
2025-03-02 12:19:35,134 - INFO - â”œâ”€â”€ Learning Rate: 1.27e-04
2025-03-02 12:19:35,134 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:19:35,810 - INFO - ðŸªœ Batch step - 846 -- sub batch step 3384 -- lr 1.27e-04
2025-03-02 12:19:37,966 - INFO - ðŸªœ Batch step - 846 -- sub batch step 3385 -- lr 1.27e-04
2025-03-02 12:19:40,118 - INFO - ðŸªœ Batch step - 846 -- sub batch step 3386 -- lr 1.27e-04
2025-03-02 12:19:42,292 - INFO - ðŸªœ Batch step - 846 -- sub batch step 3387 -- lr 1.27e-04
2025-03-02 12:19:43,833 - INFO - Step 846 -- ðŸ”„ Training Metrics
2025-03-02 12:19:43,833 - INFO - â”œâ”€â”€ Loss: 8.6946
2025-03-02 12:19:43,833 - INFO - â”œâ”€â”€ Learning Rate: 1.27e-04
2025-03-02 12:19:43,834 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:19:44,501 - INFO - ðŸªœ Batch step - 847 -- sub batch step 3388 -- lr 1.27e-04
2025-03-02 12:19:46,665 - INFO - ðŸªœ Batch step - 847 -- sub batch step 3389 -- lr 1.27e-04
2025-03-02 12:19:48,823 - INFO - ðŸªœ Batch step - 847 -- sub batch step 3390 -- lr 1.27e-04
2025-03-02 12:19:51,455 - INFO - ðŸªœ Batch step - 847 -- sub batch step 3391 -- lr 1.27e-04
2025-03-02 12:19:52,944 - INFO - Step 847 -- ðŸ”„ Training Metrics
2025-03-02 12:19:52,944 - INFO - â”œâ”€â”€ Loss: 8.7010
2025-03-02 12:19:52,944 - INFO - â”œâ”€â”€ Learning Rate: 1.27e-04
2025-03-02 12:19:52,944 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:19:53,625 - INFO - ðŸªœ Batch step - 848 -- sub batch step 3392 -- lr 1.27e-04
2025-03-02 12:19:55,776 - INFO - ðŸªœ Batch step - 848 -- sub batch step 3393 -- lr 1.27e-04
2025-03-02 12:19:57,933 - INFO - ðŸªœ Batch step - 848 -- sub batch step 3394 -- lr 1.27e-04
2025-03-02 12:20:00,121 - INFO - ðŸªœ Batch step - 848 -- sub batch step 3395 -- lr 1.27e-04
2025-03-02 12:20:01,632 - INFO - Step 848 -- ðŸ”„ Training Metrics
2025-03-02 12:20:01,632 - INFO - â”œâ”€â”€ Loss: 8.6933
2025-03-02 12:20:01,632 - INFO - â”œâ”€â”€ Learning Rate: 1.27e-04
2025-03-02 12:20:01,632 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:20:02,309 - INFO - ðŸªœ Batch step - 849 -- sub batch step 3396 -- lr 1.27e-04
2025-03-02 12:20:04,472 - INFO - ðŸªœ Batch step - 849 -- sub batch step 3397 -- lr 1.27e-04
2025-03-02 12:20:06,628 - INFO - ðŸªœ Batch step - 849 -- sub batch step 3398 -- lr 1.27e-04
2025-03-02 12:20:09,229 - INFO - ðŸªœ Batch step - 849 -- sub batch step 3399 -- lr 1.27e-04
2025-03-02 12:20:10,880 - INFO - Step 849 -- ðŸ”„ Training Metrics
2025-03-02 12:20:10,881 - INFO - â”œâ”€â”€ Loss: 8.6453
2025-03-02 12:20:10,881 - INFO - â”œâ”€â”€ Learning Rate: 1.27e-04
2025-03-02 12:20:10,881 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:20:11,562 - INFO - ðŸªœ Batch step - 850 -- sub batch step 3400 -- lr 1.27e-04
2025-03-02 12:20:13,721 - INFO - ðŸªœ Batch step - 850 -- sub batch step 3401 -- lr 1.27e-04
2025-03-02 12:20:15,884 - INFO - ðŸªœ Batch step - 850 -- sub batch step 3402 -- lr 1.27e-04
2025-03-02 12:20:18,059 - INFO - ðŸªœ Batch step - 850 -- sub batch step 3403 -- lr 1.27e-04
2025-03-02 12:20:19,571 - INFO - Step 850 -- ðŸ”„ Training Metrics
2025-03-02 12:20:19,572 - INFO - â”œâ”€â”€ Loss: 8.6730
2025-03-02 12:20:19,572 - INFO - â”œâ”€â”€ Learning Rate: 1.27e-04
2025-03-02 12:20:19,572 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:20:20,297 - INFO - ðŸªœ Batch step - 851 -- sub batch step 3404 -- lr 1.28e-04
2025-03-02 12:20:22,461 - INFO - ðŸªœ Batch step - 851 -- sub batch step 3405 -- lr 1.28e-04
2025-03-02 12:20:25,056 - INFO - ðŸªœ Batch step - 851 -- sub batch step 3406 -- lr 1.28e-04
2025-03-02 12:20:27,222 - INFO - ðŸªœ Batch step - 851 -- sub batch step 3407 -- lr 1.28e-04
2025-03-02 12:20:28,778 - INFO - Step 851 -- ðŸ”„ Training Metrics
2025-03-02 12:20:28,778 - INFO - â”œâ”€â”€ Loss: 8.6834
2025-03-02 12:20:28,778 - INFO - â”œâ”€â”€ Learning Rate: 1.28e-04
2025-03-02 12:20:28,778 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:20:29,453 - INFO - ðŸªœ Batch step - 852 -- sub batch step 3408 -- lr 1.28e-04
2025-03-02 12:20:31,618 - INFO - ðŸªœ Batch step - 852 -- sub batch step 3409 -- lr 1.28e-04
2025-03-02 12:20:33,798 - INFO - ðŸªœ Batch step - 852 -- sub batch step 3410 -- lr 1.28e-04
2025-03-02 12:20:35,949 - INFO - ðŸªœ Batch step - 852 -- sub batch step 3411 -- lr 1.28e-04
2025-03-02 12:20:37,466 - INFO - Step 852 -- ðŸ”„ Training Metrics
2025-03-02 12:20:37,467 - INFO - â”œâ”€â”€ Loss: 8.6565
2025-03-02 12:20:37,467 - INFO - â”œâ”€â”€ Learning Rate: 1.28e-04
2025-03-02 12:20:37,467 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:20:38,144 - INFO - ðŸªœ Batch step - 853 -- sub batch step 3412 -- lr 1.28e-04
2025-03-02 12:20:40,293 - INFO - ðŸªœ Batch step - 853 -- sub batch step 3413 -- lr 1.28e-04
2025-03-02 12:20:43,009 - INFO - ðŸªœ Batch step - 853 -- sub batch step 3414 -- lr 1.28e-04
2025-03-02 12:20:45,165 - INFO - ðŸªœ Batch step - 853 -- sub batch step 3415 -- lr 1.28e-04
2025-03-02 12:20:46,656 - INFO - Step 853 -- ðŸ”„ Training Metrics
2025-03-02 12:20:46,656 - INFO - â”œâ”€â”€ Loss: 8.6579
2025-03-02 12:20:46,656 - INFO - â”œâ”€â”€ Learning Rate: 1.28e-04
2025-03-02 12:20:46,656 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:20:47,327 - INFO - ðŸªœ Batch step - 854 -- sub batch step 3416 -- lr 1.28e-04
2025-03-02 12:20:49,487 - INFO - ðŸªœ Batch step - 854 -- sub batch step 3417 -- lr 1.28e-04
2025-03-02 12:20:51,655 - INFO - ðŸªœ Batch step - 854 -- sub batch step 3418 -- lr 1.28e-04
2025-03-02 12:20:53,811 - INFO - ðŸªœ Batch step - 854 -- sub batch step 3419 -- lr 1.28e-04
2025-03-02 12:20:55,345 - INFO - Step 854 -- ðŸ”„ Training Metrics
2025-03-02 12:20:55,345 - INFO - â”œâ”€â”€ Loss: 8.6510
2025-03-02 12:20:55,345 - INFO - â”œâ”€â”€ Learning Rate: 1.28e-04
2025-03-02 12:20:55,345 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:20:56,016 - INFO - ðŸªœ Batch step - 855 -- sub batch step 3420 -- lr 1.28e-04
2025-03-02 12:20:58,170 - INFO - ðŸªœ Batch step - 855 -- sub batch step 3421 -- lr 1.28e-04
2025-03-02 12:21:00,818 - INFO - ðŸªœ Batch step - 855 -- sub batch step 3422 -- lr 1.28e-04
2025-03-02 12:21:02,970 - INFO - ðŸªœ Batch step - 855 -- sub batch step 3423 -- lr 1.28e-04
2025-03-02 12:21:04,529 - INFO - Step 855 -- ðŸ”„ Training Metrics
2025-03-02 12:21:04,529 - INFO - â”œâ”€â”€ Loss: 8.6527
2025-03-02 12:21:04,529 - INFO - â”œâ”€â”€ Learning Rate: 1.28e-04
2025-03-02 12:21:04,529 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:21:05,206 - INFO - ðŸªœ Batch step - 856 -- sub batch step 3424 -- lr 1.28e-04
2025-03-02 12:21:07,363 - INFO - ðŸªœ Batch step - 856 -- sub batch step 3425 -- lr 1.28e-04
2025-03-02 12:21:09,545 - INFO - ðŸªœ Batch step - 856 -- sub batch step 3426 -- lr 1.28e-04
2025-03-02 12:21:11,702 - INFO - ðŸªœ Batch step - 856 -- sub batch step 3427 -- lr 1.28e-04
2025-03-02 12:21:13,225 - INFO - Step 856 -- ðŸ”„ Training Metrics
2025-03-02 12:21:13,225 - INFO - â”œâ”€â”€ Loss: 8.6275
2025-03-02 12:21:13,226 - INFO - â”œâ”€â”€ Learning Rate: 1.28e-04
2025-03-02 12:21:13,226 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:21:13,895 - INFO - ðŸªœ Batch step - 857 -- sub batch step 3428 -- lr 1.29e-04
2025-03-02 12:21:16,059 - INFO - ðŸªœ Batch step - 857 -- sub batch step 3429 -- lr 1.29e-04
2025-03-02 12:21:18,824 - INFO - ðŸªœ Batch step - 857 -- sub batch step 3430 -- lr 1.29e-04
2025-03-02 12:21:20,978 - INFO - ðŸªœ Batch step - 857 -- sub batch step 3431 -- lr 1.29e-04
2025-03-02 12:21:22,468 - INFO - Step 857 -- ðŸ”„ Training Metrics
2025-03-02 12:21:22,468 - INFO - â”œâ”€â”€ Loss: 8.6222
2025-03-02 12:21:22,468 - INFO - â”œâ”€â”€ Learning Rate: 1.29e-04
2025-03-02 12:21:22,468 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:21:23,146 - INFO - ðŸªœ Batch step - 858 -- sub batch step 3432 -- lr 1.29e-04
2025-03-02 12:21:25,298 - INFO - ðŸªœ Batch step - 858 -- sub batch step 3433 -- lr 1.29e-04
2025-03-02 12:21:27,476 - INFO - ðŸªœ Batch step - 858 -- sub batch step 3434 -- lr 1.29e-04
2025-03-02 12:21:29,631 - INFO - ðŸªœ Batch step - 858 -- sub batch step 3435 -- lr 1.29e-04
2025-03-02 12:21:31,156 - INFO - Step 858 -- ðŸ”„ Training Metrics
2025-03-02 12:21:31,157 - INFO - â”œâ”€â”€ Loss: 8.6089
2025-03-02 12:21:31,157 - INFO - â”œâ”€â”€ Learning Rate: 1.29e-04
2025-03-02 12:21:31,157 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:21:31,828 - INFO - ðŸªœ Batch step - 859 -- sub batch step 3436 -- lr 1.29e-04
2025-03-02 12:21:33,983 - INFO - ðŸªœ Batch step - 859 -- sub batch step 3437 -- lr 1.29e-04
2025-03-02 12:21:36,312 - INFO - ðŸªœ Batch step - 859 -- sub batch step 3438 -- lr 1.29e-04
2025-03-02 12:21:38,471 - INFO - ðŸªœ Batch step - 859 -- sub batch step 3439 -- lr 1.29e-04
2025-03-02 12:21:40,120 - INFO - Step 859 -- ðŸ”„ Training Metrics
2025-03-02 12:21:40,121 - INFO - â”œâ”€â”€ Loss: 8.6016
2025-03-02 12:21:40,121 - INFO - â”œâ”€â”€ Learning Rate: 1.29e-04
2025-03-02 12:21:40,121 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:21:41,244 - INFO - ðŸªœ Batch step - 860 -- sub batch step 3440 -- lr 1.29e-04
2025-03-02 12:21:43,400 - INFO - ðŸªœ Batch step - 860 -- sub batch step 3441 -- lr 1.29e-04
2025-03-02 12:21:45,566 - INFO - ðŸªœ Batch step - 860 -- sub batch step 3442 -- lr 1.29e-04
2025-03-02 12:21:47,748 - INFO - ðŸªœ Batch step - 860 -- sub batch step 3443 -- lr 1.29e-04
2025-03-02 12:21:49,546 - INFO - Step 860 -- ðŸ”„ Training Metrics
2025-03-02 12:21:49,546 - INFO - â”œâ”€â”€ Loss: 8.6157
2025-03-02 12:21:49,546 - INFO - â”œâ”€â”€ Learning Rate: 1.29e-04
2025-03-02 12:21:49,547 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:21:50,224 - INFO - ðŸªœ Batch step - 861 -- sub batch step 3444 -- lr 1.29e-04
2025-03-02 12:21:52,383 - INFO - ðŸªœ Batch step - 861 -- sub batch step 3445 -- lr 1.29e-04
2025-03-02 12:21:54,535 - INFO - ðŸªœ Batch step - 861 -- sub batch step 3446 -- lr 1.29e-04
2025-03-02 12:21:56,975 - INFO - ðŸªœ Batch step - 861 -- sub batch step 3447 -- lr 1.29e-04
2025-03-02 12:21:58,728 - INFO - Step 861 -- ðŸ”„ Training Metrics
2025-03-02 12:21:58,728 - INFO - â”œâ”€â”€ Loss: 8.5871
2025-03-02 12:21:58,728 - INFO - â”œâ”€â”€ Learning Rate: 1.29e-04
2025-03-02 12:21:58,728 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:21:59,395 - INFO - ðŸªœ Batch step - 862 -- sub batch step 3448 -- lr 1.29e-04
2025-03-02 12:22:01,560 - INFO - ðŸªœ Batch step - 862 -- sub batch step 3449 -- lr 1.29e-04
2025-03-02 12:22:03,712 - INFO - ðŸªœ Batch step - 862 -- sub batch step 3450 -- lr 1.29e-04
2025-03-02 12:22:05,889 - INFO - ðŸªœ Batch step - 862 -- sub batch step 3451 -- lr 1.29e-04
2025-03-02 12:22:07,412 - INFO - Step 862 -- ðŸ”„ Training Metrics
2025-03-02 12:22:07,413 - INFO - â”œâ”€â”€ Loss: 8.6023
2025-03-02 12:22:07,413 - INFO - â”œâ”€â”€ Learning Rate: 1.29e-04
2025-03-02 12:22:07,413 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:22:08,090 - INFO - ðŸªœ Batch step - 863 -- sub batch step 3452 -- lr 1.29e-04
2025-03-02 12:22:10,243 - INFO - ðŸªœ Batch step - 863 -- sub batch step 3453 -- lr 1.29e-04
2025-03-02 12:22:12,398 - INFO - ðŸªœ Batch step - 863 -- sub batch step 3454 -- lr 1.29e-04
2025-03-02 12:22:14,785 - INFO - ðŸªœ Batch step - 863 -- sub batch step 3455 -- lr 1.29e-04
2025-03-02 12:22:16,624 - INFO - Step 863 -- ðŸ”„ Training Metrics
2025-03-02 12:22:16,624 - INFO - â”œâ”€â”€ Loss: 8.5780
2025-03-02 12:22:16,625 - INFO - â”œâ”€â”€ Learning Rate: 1.29e-04
2025-03-02 12:22:16,625 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:22:17,296 - INFO - ðŸªœ Batch step - 864 -- sub batch step 3456 -- lr 1.30e-04
2025-03-02 12:22:19,456 - INFO - ðŸªœ Batch step - 864 -- sub batch step 3457 -- lr 1.30e-04
2025-03-02 12:22:21,607 - INFO - ðŸªœ Batch step - 864 -- sub batch step 3458 -- lr 1.30e-04
2025-03-02 12:22:23,785 - INFO - ðŸªœ Batch step - 864 -- sub batch step 3459 -- lr 1.30e-04
2025-03-02 12:22:25,313 - INFO - Step 864 -- ðŸ”„ Training Metrics
2025-03-02 12:22:25,313 - INFO - â”œâ”€â”€ Loss: 8.5654
2025-03-02 12:22:25,313 - INFO - â”œâ”€â”€ Learning Rate: 1.30e-04
2025-03-02 12:22:25,313 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:22:25,991 - INFO - ðŸªœ Batch step - 865 -- sub batch step 3460 -- lr 1.30e-04
2025-03-02 12:22:28,146 - INFO - ðŸªœ Batch step - 865 -- sub batch step 3461 -- lr 1.30e-04
2025-03-02 12:22:30,306 - INFO - ðŸªœ Batch step - 865 -- sub batch step 3462 -- lr 1.30e-04
2025-03-02 12:22:33,111 - INFO - ðŸªœ Batch step - 865 -- sub batch step 3463 -- lr 1.30e-04
2025-03-02 12:22:34,619 - INFO - Step 865 -- ðŸ”„ Training Metrics
2025-03-02 12:22:34,619 - INFO - â”œâ”€â”€ Loss: 8.5617
2025-03-02 12:22:34,619 - INFO - â”œâ”€â”€ Learning Rate: 1.30e-04
2025-03-02 12:22:34,619 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:22:35,296 - INFO - ðŸªœ Batch step - 866 -- sub batch step 3464 -- lr 1.30e-04
2025-03-02 12:22:37,455 - INFO - ðŸªœ Batch step - 866 -- sub batch step 3465 -- lr 1.30e-04
2025-03-02 12:22:39,608 - INFO - ðŸªœ Batch step - 866 -- sub batch step 3466 -- lr 1.30e-04
2025-03-02 12:22:41,785 - INFO - ðŸªœ Batch step - 866 -- sub batch step 3467 -- lr 1.30e-04
2025-03-02 12:22:43,312 - INFO - Step 866 -- ðŸ”„ Training Metrics
2025-03-02 12:22:43,313 - INFO - â”œâ”€â”€ Loss: 8.5662
2025-03-02 12:22:43,313 - INFO - â”œâ”€â”€ Learning Rate: 1.30e-04
2025-03-02 12:22:43,313 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:22:43,984 - INFO - ðŸªœ Batch step - 867 -- sub batch step 3468 -- lr 1.30e-04
2025-03-02 12:22:46,148 - INFO - ðŸªœ Batch step - 867 -- sub batch step 3469 -- lr 1.30e-04
2025-03-02 12:22:48,304 - INFO - ðŸªœ Batch step - 867 -- sub batch step 3470 -- lr 1.30e-04
2025-03-02 12:22:50,658 - INFO - ðŸªœ Batch step - 867 -- sub batch step 3471 -- lr 1.30e-04
2025-03-02 12:22:52,548 - INFO - Step 867 -- ðŸ”„ Training Metrics
2025-03-02 12:22:52,548 - INFO - â”œâ”€â”€ Loss: 8.5630
2025-03-02 12:22:52,548 - INFO - â”œâ”€â”€ Learning Rate: 1.30e-04
2025-03-02 12:22:52,548 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:22:53,226 - INFO - ðŸªœ Batch step - 868 -- sub batch step 3472 -- lr 1.30e-04
2025-03-02 12:22:55,380 - INFO - ðŸªœ Batch step - 868 -- sub batch step 3473 -- lr 1.30e-04
2025-03-02 12:22:57,539 - INFO - ðŸªœ Batch step - 868 -- sub batch step 3474 -- lr 1.30e-04
2025-03-02 12:22:59,720 - INFO - ðŸªœ Batch step - 868 -- sub batch step 3475 -- lr 1.30e-04
2025-03-02 12:23:01,239 - INFO - Step 868 -- ðŸ”„ Training Metrics
2025-03-02 12:23:01,240 - INFO - â”œâ”€â”€ Loss: 8.5497
2025-03-02 12:23:01,240 - INFO - â”œâ”€â”€ Learning Rate: 1.30e-04
2025-03-02 12:23:01,240 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:23:01,910 - INFO - ðŸªœ Batch step - 869 -- sub batch step 3476 -- lr 1.30e-04
2025-03-02 12:23:04,071 - INFO - ðŸªœ Batch step - 869 -- sub batch step 3477 -- lr 1.30e-04
2025-03-02 12:23:06,225 - INFO - ðŸªœ Batch step - 869 -- sub batch step 3478 -- lr 1.30e-04
2025-03-02 12:23:09,112 - INFO - ðŸªœ Batch step - 869 -- sub batch step 3479 -- lr 1.30e-04
2025-03-02 12:23:10,605 - INFO - Step 869 -- ðŸ”„ Training Metrics
2025-03-02 12:23:10,605 - INFO - â”œâ”€â”€ Loss: 8.5562
2025-03-02 12:23:10,605 - INFO - â”œâ”€â”€ Learning Rate: 1.30e-04
2025-03-02 12:23:10,605 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:23:11,282 - INFO - ðŸªœ Batch step - 870 -- sub batch step 3480 -- lr 1.31e-04
2025-03-02 12:23:13,436 - INFO - ðŸªœ Batch step - 870 -- sub batch step 3481 -- lr 1.31e-04
2025-03-02 12:23:15,590 - INFO - ðŸªœ Batch step - 870 -- sub batch step 3482 -- lr 1.31e-04
2025-03-02 12:23:17,759 - INFO - ðŸªœ Batch step - 870 -- sub batch step 3483 -- lr 1.31e-04
2025-03-02 12:23:19,285 - INFO - Step 870 -- ðŸ”„ Training Metrics
2025-03-02 12:23:19,285 - INFO - â”œâ”€â”€ Loss: 8.5316
2025-03-02 12:23:19,285 - INFO - â”œâ”€â”€ Learning Rate: 1.31e-04
2025-03-02 12:23:19,285 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:23:19,960 - INFO - ðŸªœ Batch step - 871 -- sub batch step 3484 -- lr 1.31e-04
2025-03-02 12:23:22,118 - INFO - ðŸªœ Batch step - 871 -- sub batch step 3485 -- lr 1.31e-04
2025-03-02 12:23:24,794 - INFO - ðŸªœ Batch step - 871 -- sub batch step 3486 -- lr 1.31e-04
2025-03-02 12:23:26,948 - INFO - ðŸªœ Batch step - 871 -- sub batch step 3487 -- lr 1.31e-04
2025-03-02 12:23:28,506 - INFO - Step 871 -- ðŸ”„ Training Metrics
2025-03-02 12:23:28,507 - INFO - â”œâ”€â”€ Loss: 8.5106
2025-03-02 12:23:28,507 - INFO - â”œâ”€â”€ Learning Rate: 1.31e-04
2025-03-02 12:23:28,507 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:23:29,172 - INFO - ðŸªœ Batch step - 872 -- sub batch step 3488 -- lr 1.31e-04
2025-03-02 12:23:31,336 - INFO - ðŸªœ Batch step - 872 -- sub batch step 3489 -- lr 1.31e-04
2025-03-02 12:23:33,514 - INFO - ðŸªœ Batch step - 872 -- sub batch step 3490 -- lr 1.31e-04
2025-03-02 12:23:35,666 - INFO - ðŸªœ Batch step - 872 -- sub batch step 3491 -- lr 1.31e-04
2025-03-02 12:23:37,186 - INFO - Step 872 -- ðŸ”„ Training Metrics
2025-03-02 12:23:37,187 - INFO - â”œâ”€â”€ Loss: 8.5091
2025-03-02 12:23:37,187 - INFO - â”œâ”€â”€ Learning Rate: 1.31e-04
2025-03-02 12:23:37,187 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:23:37,865 - INFO - ðŸªœ Batch step - 873 -- sub batch step 3492 -- lr 1.31e-04
2025-03-02 12:23:40,021 - INFO - ðŸªœ Batch step - 873 -- sub batch step 3493 -- lr 1.31e-04
2025-03-02 12:23:42,731 - INFO - ðŸªœ Batch step - 873 -- sub batch step 3494 -- lr 1.31e-04
2025-03-02 12:23:44,887 - INFO - ðŸªœ Batch step - 873 -- sub batch step 3495 -- lr 1.31e-04
2025-03-02 12:23:46,440 - INFO - Step 873 -- ðŸ”„ Training Metrics
2025-03-02 12:23:46,440 - INFO - â”œâ”€â”€ Loss: 8.5166
2025-03-02 12:23:46,441 - INFO - â”œâ”€â”€ Learning Rate: 1.31e-04
2025-03-02 12:23:46,441 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:23:47,115 - INFO - ðŸªœ Batch step - 874 -- sub batch step 3496 -- lr 1.31e-04
2025-03-02 12:23:49,271 - INFO - ðŸªœ Batch step - 874 -- sub batch step 3497 -- lr 1.31e-04
2025-03-02 12:23:51,443 - INFO - ðŸªœ Batch step - 874 -- sub batch step 3498 -- lr 1.31e-04
2025-03-02 12:23:53,601 - INFO - ðŸªœ Batch step - 874 -- sub batch step 3499 -- lr 1.31e-04
2025-03-02 12:23:55,139 - INFO - Step 874 -- ðŸ”„ Training Metrics
2025-03-02 12:23:55,139 - INFO - â”œâ”€â”€ Loss: 8.4926
2025-03-02 12:23:55,139 - INFO - â”œâ”€â”€ Learning Rate: 1.31e-04
2025-03-02 12:23:55,139 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:23:55,816 - INFO - ðŸªœ Batch step - 875 -- sub batch step 3500 -- lr 1.31e-04
2025-03-02 12:23:57,967 - INFO - ðŸªœ Batch step - 875 -- sub batch step 3501 -- lr 1.31e-04
2025-03-02 12:24:00,592 - INFO - ðŸªœ Batch step - 875 -- sub batch step 3502 -- lr 1.31e-04
2025-03-02 12:24:02,762 - INFO - ðŸªœ Batch step - 875 -- sub batch step 3503 -- lr 1.31e-04
2025-03-02 12:24:04,259 - INFO - Step 875 -- ðŸ”„ Training Metrics
2025-03-02 12:24:04,259 - INFO - â”œâ”€â”€ Loss: 8.5164
2025-03-02 12:24:04,259 - INFO - â”œâ”€â”€ Learning Rate: 1.31e-04
2025-03-02 12:24:04,259 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:24:04,936 - INFO - ðŸªœ Batch step - 876 -- sub batch step 3504 -- lr 1.31e-04
2025-03-02 12:24:07,098 - INFO - ðŸªœ Batch step - 876 -- sub batch step 3505 -- lr 1.31e-04
2025-03-02 12:24:09,272 - INFO - ðŸªœ Batch step - 876 -- sub batch step 3506 -- lr 1.31e-04
2025-03-02 12:24:11,433 - INFO - ðŸªœ Batch step - 876 -- sub batch step 3507 -- lr 1.31e-04
2025-03-02 12:24:12,950 - INFO - Step 876 -- ðŸ”„ Training Metrics
2025-03-02 12:24:12,950 - INFO - â”œâ”€â”€ Loss: 8.4924
2025-03-02 12:24:12,950 - INFO - â”œâ”€â”€ Learning Rate: 1.31e-04
2025-03-02 12:24:12,950 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:24:13,625 - INFO - ðŸªœ Batch step - 877 -- sub batch step 3508 -- lr 1.32e-04
2025-03-02 12:24:15,788 - INFO - ðŸªœ Batch step - 877 -- sub batch step 3509 -- lr 1.32e-04
2025-03-02 12:24:18,412 - INFO - ðŸªœ Batch step - 877 -- sub batch step 3510 -- lr 1.32e-04
2025-03-02 12:24:20,566 - INFO - ðŸªœ Batch step - 877 -- sub batch step 3511 -- lr 1.32e-04
2025-03-02 12:24:22,304 - INFO - Step 877 -- ðŸ”„ Training Metrics
2025-03-02 12:24:22,305 - INFO - â”œâ”€â”€ Loss: 8.4953
2025-03-02 12:24:22,305 - INFO - â”œâ”€â”€ Learning Rate: 1.32e-04
2025-03-02 12:24:22,305 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:24:22,984 - INFO - ðŸªœ Batch step - 878 -- sub batch step 3512 -- lr 1.32e-04
2025-03-02 12:24:25,145 - INFO - ðŸªœ Batch step - 878 -- sub batch step 3513 -- lr 1.32e-04
2025-03-02 12:24:27,329 - INFO - ðŸªœ Batch step - 878 -- sub batch step 3514 -- lr 1.32e-04
2025-03-02 12:24:29,490 - INFO - ðŸªœ Batch step - 878 -- sub batch step 3515 -- lr 1.32e-04
2025-03-02 12:24:30,997 - INFO - Step 878 -- ðŸ”„ Training Metrics
2025-03-02 12:24:30,997 - INFO - â”œâ”€â”€ Loss: 8.4730
2025-03-02 12:24:30,997 - INFO - â”œâ”€â”€ Learning Rate: 1.32e-04
2025-03-02 12:24:30,997 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:24:31,676 - INFO - ðŸªœ Batch step - 879 -- sub batch step 3516 -- lr 1.32e-04
2025-03-02 12:24:33,841 - INFO - ðŸªœ Batch step - 879 -- sub batch step 3517 -- lr 1.32e-04
2025-03-02 12:24:36,129 - INFO - ðŸªœ Batch step - 879 -- sub batch step 3518 -- lr 1.32e-04
2025-03-02 12:24:38,295 - INFO - ðŸªœ Batch step - 879 -- sub batch step 3519 -- lr 1.32e-04
2025-03-02 12:24:40,041 - INFO - Step 879 -- ðŸ”„ Training Metrics
2025-03-02 12:24:40,042 - INFO - â”œâ”€â”€ Loss: 8.4685
2025-03-02 12:24:40,042 - INFO - â”œâ”€â”€ Learning Rate: 1.32e-04
2025-03-02 12:24:40,042 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:24:41,053 - INFO - ðŸªœ Batch step - 880 -- sub batch step 3520 -- lr 1.32e-04
2025-03-02 12:24:43,213 - INFO - ðŸªœ Batch step - 880 -- sub batch step 3521 -- lr 1.32e-04
2025-03-02 12:24:45,381 - INFO - ðŸªœ Batch step - 880 -- sub batch step 3522 -- lr 1.32e-04
2025-03-02 12:24:47,557 - INFO - ðŸªœ Batch step - 880 -- sub batch step 3523 -- lr 1.32e-04
2025-03-02 12:24:49,411 - INFO - Step 880 -- ðŸ”„ Training Metrics
2025-03-02 12:24:49,411 - INFO - â”œâ”€â”€ Loss: 8.4785
2025-03-02 12:24:49,411 - INFO - â”œâ”€â”€ Learning Rate: 1.32e-04
2025-03-02 12:24:49,411 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:24:50,097 - INFO - ðŸªœ Batch step - 881 -- sub batch step 3524 -- lr 1.32e-04
2025-03-02 12:24:52,255 - INFO - ðŸªœ Batch step - 881 -- sub batch step 3525 -- lr 1.32e-04
2025-03-02 12:24:54,410 - INFO - ðŸªœ Batch step - 881 -- sub batch step 3526 -- lr 1.32e-04
2025-03-02 12:24:56,844 - INFO - ðŸªœ Batch step - 881 -- sub batch step 3527 -- lr 1.32e-04
2025-03-02 12:24:58,707 - INFO - Step 881 -- ðŸ”„ Training Metrics
2025-03-02 12:24:58,707 - INFO - â”œâ”€â”€ Loss: 8.4444
2025-03-02 12:24:58,707 - INFO - â”œâ”€â”€ Learning Rate: 1.32e-04
2025-03-02 12:24:58,708 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:24:59,389 - INFO - ðŸªœ Batch step - 882 -- sub batch step 3528 -- lr 1.32e-04
2025-03-02 12:25:01,558 - INFO - ðŸªœ Batch step - 882 -- sub batch step 3529 -- lr 1.32e-04
2025-03-02 12:25:03,717 - INFO - ðŸªœ Batch step - 882 -- sub batch step 3530 -- lr 1.32e-04
2025-03-02 12:25:05,880 - INFO - ðŸªœ Batch step - 882 -- sub batch step 3531 -- lr 1.32e-04
2025-03-02 12:25:07,388 - INFO - Step 882 -- ðŸ”„ Training Metrics
2025-03-02 12:25:07,388 - INFO - â”œâ”€â”€ Loss: 8.4482
2025-03-02 12:25:07,388 - INFO - â”œâ”€â”€ Learning Rate: 1.32e-04
2025-03-02 12:25:07,388 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:25:08,065 - INFO - ðŸªœ Batch step - 883 -- sub batch step 3532 -- lr 1.32e-04
2025-03-02 12:25:10,213 - INFO - ðŸªœ Batch step - 883 -- sub batch step 3533 -- lr 1.32e-04
2025-03-02 12:25:12,376 - INFO - ðŸªœ Batch step - 883 -- sub batch step 3534 -- lr 1.32e-04
2025-03-02 12:25:15,173 - INFO - ðŸªœ Batch step - 883 -- sub batch step 3535 -- lr 1.32e-04
2025-03-02 12:25:16,769 - INFO - Step 883 -- ðŸ”„ Training Metrics
2025-03-02 12:25:16,769 - INFO - â”œâ”€â”€ Loss: 8.4412
2025-03-02 12:25:16,770 - INFO - â”œâ”€â”€ Learning Rate: 1.32e-04
2025-03-02 12:25:16,770 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:25:17,438 - INFO - ðŸªœ Batch step - 884 -- sub batch step 3536 -- lr 1.33e-04
2025-03-02 12:25:19,593 - INFO - ðŸªœ Batch step - 884 -- sub batch step 3537 -- lr 1.33e-04
2025-03-02 12:25:21,744 - INFO - ðŸªœ Batch step - 884 -- sub batch step 3538 -- lr 1.33e-04
2025-03-02 12:25:23,914 - INFO - ðŸªœ Batch step - 884 -- sub batch step 3539 -- lr 1.33e-04
2025-03-02 12:25:25,451 - INFO - Step 884 -- ðŸ”„ Training Metrics
2025-03-02 12:25:25,451 - INFO - â”œâ”€â”€ Loss: 8.4601
2025-03-02 12:25:25,451 - INFO - â”œâ”€â”€ Learning Rate: 1.33e-04
2025-03-02 12:25:25,451 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:25:26,123 - INFO - ðŸªœ Batch step - 885 -- sub batch step 3540 -- lr 1.33e-04
2025-03-02 12:25:28,273 - INFO - ðŸªœ Batch step - 885 -- sub batch step 3541 -- lr 1.33e-04
2025-03-02 12:25:30,428 - INFO - ðŸªœ Batch step - 885 -- sub batch step 3542 -- lr 1.33e-04
2025-03-02 12:25:33,124 - INFO - ðŸªœ Batch step - 885 -- sub batch step 3543 -- lr 1.33e-04
2025-03-02 12:25:34,636 - INFO - Step 885 -- ðŸ”„ Training Metrics
2025-03-02 12:25:34,636 - INFO - â”œâ”€â”€ Loss: 8.4456
2025-03-02 12:25:34,636 - INFO - â”œâ”€â”€ Learning Rate: 1.33e-04
2025-03-02 12:25:34,637 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:25:35,316 - INFO - ðŸªœ Batch step - 886 -- sub batch step 3544 -- lr 1.33e-04
2025-03-02 12:25:37,476 - INFO - ðŸªœ Batch step - 886 -- sub batch step 3545 -- lr 1.33e-04
2025-03-02 12:25:39,626 - INFO - ðŸªœ Batch step - 886 -- sub batch step 3546 -- lr 1.33e-04
2025-03-02 12:25:41,802 - INFO - ðŸªœ Batch step - 886 -- sub batch step 3547 -- lr 1.33e-04
2025-03-02 12:25:43,321 - INFO - Step 886 -- ðŸ”„ Training Metrics
2025-03-02 12:25:43,321 - INFO - â”œâ”€â”€ Loss: 8.4334
2025-03-02 12:25:43,321 - INFO - â”œâ”€â”€ Learning Rate: 1.33e-04
2025-03-02 12:25:43,321 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:25:43,994 - INFO - ðŸªœ Batch step - 887 -- sub batch step 3548 -- lr 1.33e-04
2025-03-02 12:25:46,156 - INFO - ðŸªœ Batch step - 887 -- sub batch step 3549 -- lr 1.33e-04
2025-03-02 12:25:48,315 - INFO - ðŸªœ Batch step - 887 -- sub batch step 3550 -- lr 1.33e-04
2025-03-02 12:25:50,699 - INFO - ðŸªœ Batch step - 887 -- sub batch step 3551 -- lr 1.33e-04
2025-03-02 12:25:52,771 - INFO - Step 887 -- ðŸ”„ Training Metrics
2025-03-02 12:25:52,771 - INFO - â”œâ”€â”€ Loss: 8.4353
2025-03-02 12:25:52,772 - INFO - â”œâ”€â”€ Learning Rate: 1.33e-04
2025-03-02 12:25:52,772 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:25:53,451 - INFO - ðŸªœ Batch step - 888 -- sub batch step 3552 -- lr 1.33e-04
2025-03-02 12:25:55,606 - INFO - ðŸªœ Batch step - 888 -- sub batch step 3553 -- lr 1.33e-04
2025-03-02 12:25:57,763 - INFO - ðŸªœ Batch step - 888 -- sub batch step 3554 -- lr 1.33e-04
2025-03-02 12:25:59,939 - INFO - ðŸªœ Batch step - 888 -- sub batch step 3555 -- lr 1.33e-04
2025-03-02 12:26:01,464 - INFO - Step 888 -- ðŸ”„ Training Metrics
2025-03-02 12:26:01,464 - INFO - â”œâ”€â”€ Loss: 8.4402
2025-03-02 12:26:01,464 - INFO - â”œâ”€â”€ Learning Rate: 1.33e-04
2025-03-02 12:26:01,465 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:26:02,137 - INFO - ðŸªœ Batch step - 889 -- sub batch step 3556 -- lr 1.33e-04
2025-03-02 12:26:04,296 - INFO - ðŸªœ Batch step - 889 -- sub batch step 3557 -- lr 1.33e-04
2025-03-02 12:26:06,446 - INFO - ðŸªœ Batch step - 889 -- sub batch step 3558 -- lr 1.33e-04
2025-03-02 12:26:09,123 - INFO - ðŸªœ Batch step - 889 -- sub batch step 3559 -- lr 1.33e-04
2025-03-02 12:26:10,702 - INFO - Step 889 -- ðŸ”„ Training Metrics
2025-03-02 12:26:10,702 - INFO - â”œâ”€â”€ Loss: 8.4041
2025-03-02 12:26:10,702 - INFO - â”œâ”€â”€ Learning Rate: 1.33e-04
2025-03-02 12:26:10,703 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:26:11,377 - INFO - ðŸªœ Batch step - 890 -- sub batch step 3560 -- lr 1.33e-04
2025-03-02 12:26:13,527 - INFO - ðŸªœ Batch step - 890 -- sub batch step 3561 -- lr 1.33e-04
2025-03-02 12:26:15,676 - INFO - ðŸªœ Batch step - 890 -- sub batch step 3562 -- lr 1.33e-04
2025-03-02 12:26:17,838 - INFO - ðŸªœ Batch step - 890 -- sub batch step 3563 -- lr 1.33e-04
2025-03-02 12:26:19,386 - INFO - Step 890 -- ðŸ”„ Training Metrics
2025-03-02 12:26:19,386 - INFO - â”œâ”€â”€ Loss: 8.4036
2025-03-02 12:26:19,386 - INFO - â”œâ”€â”€ Learning Rate: 1.33e-04
2025-03-02 12:26:19,387 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:26:20,063 - INFO - ðŸªœ Batch step - 891 -- sub batch step 3564 -- lr 1.34e-04
2025-03-02 12:26:22,217 - INFO - ðŸªœ Batch step - 891 -- sub batch step 3565 -- lr 1.34e-04
2025-03-02 12:26:24,891 - INFO - ðŸªœ Batch step - 891 -- sub batch step 3566 -- lr 1.34e-04
2025-03-02 12:26:27,049 - INFO - ðŸªœ Batch step - 891 -- sub batch step 3567 -- lr 1.34e-04
2025-03-02 12:26:28,587 - INFO - Step 891 -- ðŸ”„ Training Metrics
2025-03-02 12:26:28,587 - INFO - â”œâ”€â”€ Loss: 8.3843
2025-03-02 12:26:28,587 - INFO - â”œâ”€â”€ Learning Rate: 1.34e-04
2025-03-02 12:26:28,587 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:26:29,260 - INFO - ðŸªœ Batch step - 892 -- sub batch step 3568 -- lr 1.34e-04
2025-03-02 12:26:31,416 - INFO - ðŸªœ Batch step - 892 -- sub batch step 3569 -- lr 1.34e-04
2025-03-02 12:26:33,587 - INFO - ðŸªœ Batch step - 892 -- sub batch step 3570 -- lr 1.34e-04
2025-03-02 12:26:35,736 - INFO - ðŸªœ Batch step - 892 -- sub batch step 3571 -- lr 1.34e-04
2025-03-02 12:26:37,281 - INFO - Step 892 -- ðŸ”„ Training Metrics
2025-03-02 12:26:37,281 - INFO - â”œâ”€â”€ Loss: 8.4080
2025-03-02 12:26:37,281 - INFO - â”œâ”€â”€ Learning Rate: 1.34e-04
2025-03-02 12:26:37,281 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:26:37,957 - INFO - ðŸªœ Batch step - 893 -- sub batch step 3572 -- lr 1.34e-04
2025-03-02 12:26:40,106 - INFO - ðŸªœ Batch step - 893 -- sub batch step 3573 -- lr 1.34e-04
2025-03-02 12:26:42,747 - INFO - ðŸªœ Batch step - 893 -- sub batch step 3574 -- lr 1.34e-04
2025-03-02 12:26:44,905 - INFO - ðŸªœ Batch step - 893 -- sub batch step 3575 -- lr 1.34e-04
2025-03-02 12:26:46,483 - INFO - Step 893 -- ðŸ”„ Training Metrics
2025-03-02 12:26:46,483 - INFO - â”œâ”€â”€ Loss: 8.4038
2025-03-02 12:26:46,483 - INFO - â”œâ”€â”€ Learning Rate: 1.34e-04
2025-03-02 12:26:46,483 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:26:47,150 - INFO - ðŸªœ Batch step - 894 -- sub batch step 3576 -- lr 1.34e-04
2025-03-02 12:26:49,305 - INFO - ðŸªœ Batch step - 894 -- sub batch step 3577 -- lr 1.34e-04
2025-03-02 12:26:51,466 - INFO - ðŸªœ Batch step - 894 -- sub batch step 3578 -- lr 1.34e-04
2025-03-02 12:26:53,620 - INFO - ðŸªœ Batch step - 894 -- sub batch step 3579 -- lr 1.34e-04
2025-03-02 12:26:55,167 - INFO - Step 894 -- ðŸ”„ Training Metrics
2025-03-02 12:26:55,168 - INFO - â”œâ”€â”€ Loss: 8.3868
2025-03-02 12:26:55,168 - INFO - â”œâ”€â”€ Learning Rate: 1.34e-04
2025-03-02 12:26:55,168 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:26:55,840 - INFO - ðŸªœ Batch step - 895 -- sub batch step 3580 -- lr 1.34e-04
2025-03-02 12:26:57,990 - INFO - ðŸªœ Batch step - 895 -- sub batch step 3581 -- lr 1.34e-04
2025-03-02 12:27:00,794 - INFO - ðŸªœ Batch step - 895 -- sub batch step 3582 -- lr 1.34e-04
2025-03-02 12:27:02,947 - INFO - ðŸªœ Batch step - 895 -- sub batch step 3583 -- lr 1.34e-04
2025-03-02 12:27:04,439 - INFO - Step 895 -- ðŸ”„ Training Metrics
2025-03-02 12:27:04,439 - INFO - â”œâ”€â”€ Loss: 8.3751
2025-03-02 12:27:04,439 - INFO - â”œâ”€â”€ Learning Rate: 1.34e-04
2025-03-02 12:27:04,439 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:27:05,117 - INFO - ðŸªœ Batch step - 896 -- sub batch step 3584 -- lr 1.34e-04
2025-03-02 12:27:07,270 - INFO - ðŸªœ Batch step - 896 -- sub batch step 3585 -- lr 1.34e-04
2025-03-02 12:27:09,437 - INFO - ðŸªœ Batch step - 896 -- sub batch step 3586 -- lr 1.34e-04
2025-03-02 12:27:11,588 - INFO - ðŸªœ Batch step - 896 -- sub batch step 3587 -- lr 1.34e-04
2025-03-02 12:27:13,134 - INFO - Step 896 -- ðŸ”„ Training Metrics
2025-03-02 12:27:13,134 - INFO - â”œâ”€â”€ Loss: 8.3455
2025-03-02 12:27:13,134 - INFO - â”œâ”€â”€ Learning Rate: 1.34e-04
2025-03-02 12:27:13,134 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:27:13,800 - INFO - ðŸªœ Batch step - 897 -- sub batch step 3588 -- lr 1.35e-04
2025-03-02 12:27:15,951 - INFO - ðŸªœ Batch step - 897 -- sub batch step 3589 -- lr 1.35e-04
2025-03-02 12:27:18,611 - INFO - ðŸªœ Batch step - 897 -- sub batch step 3590 -- lr 1.35e-04
2025-03-02 12:27:20,759 - INFO - ðŸªœ Batch step - 897 -- sub batch step 3591 -- lr 1.35e-04
2025-03-02 12:27:22,272 - INFO - Step 897 -- ðŸ”„ Training Metrics
2025-03-02 12:27:22,273 - INFO - â”œâ”€â”€ Loss: 8.3637
2025-03-02 12:27:22,273 - INFO - â”œâ”€â”€ Learning Rate: 1.35e-04
2025-03-02 12:27:22,273 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:27:22,946 - INFO - ðŸªœ Batch step - 898 -- sub batch step 3592 -- lr 1.35e-04
2025-03-02 12:27:25,091 - INFO - ðŸªœ Batch step - 898 -- sub batch step 3593 -- lr 1.35e-04
2025-03-02 12:27:27,260 - INFO - ðŸªœ Batch step - 898 -- sub batch step 3594 -- lr 1.35e-04
2025-03-02 12:27:29,412 - INFO - ðŸªœ Batch step - 898 -- sub batch step 3595 -- lr 1.35e-04
2025-03-02 12:27:30,974 - INFO - Step 898 -- ðŸ”„ Training Metrics
2025-03-02 12:27:30,974 - INFO - â”œâ”€â”€ Loss: 8.3566
2025-03-02 12:27:30,974 - INFO - â”œâ”€â”€ Learning Rate: 1.35e-04
2025-03-02 12:27:30,974 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:27:31,644 - INFO - ðŸªœ Batch step - 899 -- sub batch step 3596 -- lr 1.35e-04
2025-03-02 12:27:33,797 - INFO - ðŸªœ Batch step - 899 -- sub batch step 3597 -- lr 1.35e-04
2025-03-02 12:27:36,075 - INFO - ðŸªœ Batch step - 899 -- sub batch step 3598 -- lr 1.35e-04
2025-03-02 12:27:38,225 - INFO - ðŸªœ Batch step - 899 -- sub batch step 3599 -- lr 1.35e-04
2025-03-02 12:27:39,828 - INFO - Step 899 -- ðŸ”„ Training Metrics
2025-03-02 12:27:39,828 - INFO - â”œâ”€â”€ Loss: 8.3640
2025-03-02 12:27:39,828 - INFO - â”œâ”€â”€ Learning Rate: 1.35e-04
2025-03-02 12:27:39,828 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:27:41,054 - INFO - ðŸªœ Batch step - 900 -- sub batch step 3600 -- lr 1.35e-04
2025-03-02 12:27:43,213 - INFO - ðŸªœ Batch step - 900 -- sub batch step 3601 -- lr 1.35e-04
2025-03-02 12:27:45,377 - INFO - ðŸªœ Batch step - 900 -- sub batch step 3602 -- lr 1.35e-04
2025-03-02 12:27:47,554 - INFO - ðŸªœ Batch step - 900 -- sub batch step 3603 -- lr 1.35e-04
2025-03-02 12:27:49,076 - INFO - Step 900 -- ðŸ”„ Training Metrics
2025-03-02 12:27:49,076 - INFO - â”œâ”€â”€ Loss: 8.3553
2025-03-02 12:27:49,076 - INFO - â”œâ”€â”€ Learning Rate: 1.35e-04
2025-03-02 12:27:49,076 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:27:49,752 - INFO - ðŸªœ Batch step - 901 -- sub batch step 3604 -- lr 1.35e-04
2025-03-02 12:27:51,905 - INFO - ðŸªœ Batch step - 901 -- sub batch step 3605 -- lr 1.35e-04
2025-03-02 12:27:54,056 - INFO - ðŸªœ Batch step - 901 -- sub batch step 3606 -- lr 1.35e-04
2025-03-02 12:27:56,695 - INFO - ðŸªœ Batch step - 901 -- sub batch step 3607 -- lr 1.35e-04
2025-03-02 12:27:58,313 - INFO - Step 901 -- ðŸ”„ Training Metrics
2025-03-02 12:27:58,313 - INFO - â”œâ”€â”€ Loss: 8.3223
2025-03-02 12:27:58,313 - INFO - â”œâ”€â”€ Learning Rate: 1.35e-04
2025-03-02 12:27:58,313 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:27:58,981 - INFO - ðŸªœ Batch step - 902 -- sub batch step 3608 -- lr 1.35e-04
2025-03-02 12:28:01,135 - INFO - ðŸªœ Batch step - 902 -- sub batch step 3609 -- lr 1.35e-04
2025-03-02 12:28:03,286 - INFO - ðŸªœ Batch step - 902 -- sub batch step 3610 -- lr 1.35e-04
2025-03-02 12:28:05,453 - INFO - ðŸªœ Batch step - 902 -- sub batch step 3611 -- lr 1.35e-04
2025-03-02 12:28:07,006 - INFO - Step 902 -- ðŸ”„ Training Metrics
2025-03-02 12:28:07,007 - INFO - â”œâ”€â”€ Loss: 8.3383
2025-03-02 12:28:07,007 - INFO - â”œâ”€â”€ Learning Rate: 1.35e-04
2025-03-02 12:28:07,007 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:28:07,685 - INFO - ðŸªœ Batch step - 903 -- sub batch step 3612 -- lr 1.35e-04
2025-03-02 12:28:09,832 - INFO - ðŸªœ Batch step - 903 -- sub batch step 3613 -- lr 1.35e-04
2025-03-02 12:28:11,985 - INFO - ðŸªœ Batch step - 903 -- sub batch step 3614 -- lr 1.35e-04
2025-03-02 12:28:14,618 - INFO - ðŸªœ Batch step - 903 -- sub batch step 3615 -- lr 1.35e-04
2025-03-02 12:28:16,253 - INFO - Step 903 -- ðŸ”„ Training Metrics
2025-03-02 12:28:16,253 - INFO - â”œâ”€â”€ Loss: 8.3433
2025-03-02 12:28:16,253 - INFO - â”œâ”€â”€ Learning Rate: 1.35e-04
2025-03-02 12:28:16,253 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:28:16,926 - INFO - ðŸªœ Batch step - 904 -- sub batch step 3616 -- lr 1.36e-04
2025-03-02 12:28:19,085 - INFO - ðŸªœ Batch step - 904 -- sub batch step 3617 -- lr 1.36e-04
2025-03-02 12:28:21,234 - INFO - ðŸªœ Batch step - 904 -- sub batch step 3618 -- lr 1.36e-04
2025-03-02 12:28:23,401 - INFO - ðŸªœ Batch step - 904 -- sub batch step 3619 -- lr 1.36e-04
2025-03-02 12:28:24,936 - INFO - Step 904 -- ðŸ”„ Training Metrics
2025-03-02 12:28:24,936 - INFO - â”œâ”€â”€ Loss: 8.3044
2025-03-02 12:28:24,936 - INFO - â”œâ”€â”€ Learning Rate: 1.36e-04
2025-03-02 12:28:24,936 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:28:25,616 - INFO - ðŸªœ Batch step - 905 -- sub batch step 3620 -- lr 1.36e-04
2025-03-02 12:28:27,768 - INFO - ðŸªœ Batch step - 905 -- sub batch step 3621 -- lr 1.36e-04
2025-03-02 12:28:29,921 - INFO - ðŸªœ Batch step - 905 -- sub batch step 3622 -- lr 1.36e-04
2025-03-02 12:28:32,277 - INFO - ðŸªœ Batch step - 905 -- sub batch step 3623 -- lr 1.36e-04
2025-03-02 12:28:34,190 - INFO - Step 905 -- ðŸ”„ Training Metrics
2025-03-02 12:28:34,190 - INFO - â”œâ”€â”€ Loss: 8.2924
2025-03-02 12:28:34,190 - INFO - â”œâ”€â”€ Learning Rate: 1.36e-04
2025-03-02 12:28:34,190 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:28:34,866 - INFO - ðŸªœ Batch step - 906 -- sub batch step 3624 -- lr 1.36e-04
2025-03-02 12:28:37,025 - INFO - ðŸªœ Batch step - 906 -- sub batch step 3625 -- lr 1.36e-04
2025-03-02 12:28:39,173 - INFO - ðŸªœ Batch step - 906 -- sub batch step 3626 -- lr 1.36e-04
2025-03-02 12:28:41,344 - INFO - ðŸªœ Batch step - 906 -- sub batch step 3627 -- lr 1.36e-04
2025-03-02 12:28:42,885 - INFO - Step 906 -- ðŸ”„ Training Metrics
2025-03-02 12:28:42,885 - INFO - â”œâ”€â”€ Loss: 8.3149
2025-03-02 12:28:42,885 - INFO - â”œâ”€â”€ Learning Rate: 1.36e-04
2025-03-02 12:28:42,885 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:28:43,552 - INFO - ðŸªœ Batch step - 907 -- sub batch step 3628 -- lr 1.36e-04
2025-03-02 12:28:45,705 - INFO - ðŸªœ Batch step - 907 -- sub batch step 3629 -- lr 1.36e-04
2025-03-02 12:28:47,861 - INFO - ðŸªœ Batch step - 907 -- sub batch step 3630 -- lr 1.36e-04
2025-03-02 12:28:50,466 - INFO - ðŸªœ Batch step - 907 -- sub batch step 3631 -- lr 1.36e-04
2025-03-02 12:28:52,200 - INFO - Step 907 -- ðŸ”„ Training Metrics
2025-03-02 12:28:52,201 - INFO - â”œâ”€â”€ Loss: 8.2993
2025-03-02 12:28:52,201 - INFO - â”œâ”€â”€ Learning Rate: 1.36e-04
2025-03-02 12:28:52,201 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:28:52,875 - INFO - ðŸªœ Batch step - 908 -- sub batch step 3632 -- lr 1.36e-04
2025-03-02 12:28:55,025 - INFO - ðŸªœ Batch step - 908 -- sub batch step 3633 -- lr 1.36e-04
2025-03-02 12:28:57,182 - INFO - ðŸªœ Batch step - 908 -- sub batch step 3634 -- lr 1.36e-04
2025-03-02 12:28:59,357 - INFO - ðŸªœ Batch step - 908 -- sub batch step 3635 -- lr 1.36e-04
2025-03-02 12:29:00,914 - INFO - Step 908 -- ðŸ”„ Training Metrics
2025-03-02 12:29:00,914 - INFO - â”œâ”€â”€ Loss: 8.2963
2025-03-02 12:29:00,914 - INFO - â”œâ”€â”€ Learning Rate: 1.36e-04
2025-03-02 12:29:00,914 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:29:01,588 - INFO - ðŸªœ Batch step - 909 -- sub batch step 3636 -- lr 1.36e-04
2025-03-02 12:29:03,742 - INFO - ðŸªœ Batch step - 909 -- sub batch step 3637 -- lr 1.36e-04
2025-03-02 12:29:05,895 - INFO - ðŸªœ Batch step - 909 -- sub batch step 3638 -- lr 1.36e-04
2025-03-02 12:29:08,571 - INFO - ðŸªœ Batch step - 909 -- sub batch step 3639 -- lr 1.36e-04
2025-03-02 12:29:10,157 - INFO - Step 909 -- ðŸ”„ Training Metrics
2025-03-02 12:29:10,158 - INFO - â”œâ”€â”€ Loss: 8.3080
2025-03-02 12:29:10,158 - INFO - â”œâ”€â”€ Learning Rate: 1.36e-04
2025-03-02 12:29:10,158 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:29:10,835 - INFO - ðŸªœ Batch step - 910 -- sub batch step 3640 -- lr 1.36e-04
2025-03-02 12:29:12,986 - INFO - ðŸªœ Batch step - 910 -- sub batch step 3641 -- lr 1.36e-04
2025-03-02 12:29:15,139 - INFO - ðŸªœ Batch step - 910 -- sub batch step 3642 -- lr 1.36e-04
2025-03-02 12:29:17,304 - INFO - ðŸªœ Batch step - 910 -- sub batch step 3643 -- lr 1.36e-04
2025-03-02 12:29:18,847 - INFO - Step 910 -- ðŸ”„ Training Metrics
2025-03-02 12:29:18,847 - INFO - â”œâ”€â”€ Loss: 8.2652
2025-03-02 12:29:18,847 - INFO - â”œâ”€â”€ Learning Rate: 1.36e-04
2025-03-02 12:29:18,847 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:29:19,521 - INFO - ðŸªœ Batch step - 911 -- sub batch step 3644 -- lr 1.37e-04
2025-03-02 12:29:21,682 - INFO - ðŸªœ Batch step - 911 -- sub batch step 3645 -- lr 1.37e-04
2025-03-02 12:29:24,344 - INFO - ðŸªœ Batch step - 911 -- sub batch step 3646 -- lr 1.37e-04
2025-03-02 12:29:26,509 - INFO - ðŸªœ Batch step - 911 -- sub batch step 3647 -- lr 1.37e-04
2025-03-02 12:29:28,091 - INFO - Step 911 -- ðŸ”„ Training Metrics
2025-03-02 12:29:28,092 - INFO - â”œâ”€â”€ Loss: 8.2799
2025-03-02 12:29:28,092 - INFO - â”œâ”€â”€ Learning Rate: 1.37e-04
2025-03-02 12:29:28,092 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:29:28,767 - INFO - ðŸªœ Batch step - 912 -- sub batch step 3648 -- lr 1.37e-04
2025-03-02 12:29:30,924 - INFO - ðŸªœ Batch step - 912 -- sub batch step 3649 -- lr 1.37e-04
2025-03-02 12:29:33,093 - INFO - ðŸªœ Batch step - 912 -- sub batch step 3650 -- lr 1.37e-04
2025-03-02 12:29:35,242 - INFO - ðŸªœ Batch step - 912 -- sub batch step 3651 -- lr 1.37e-04
2025-03-02 12:29:36,795 - INFO - Step 912 -- ðŸ”„ Training Metrics
2025-03-02 12:29:36,795 - INFO - â”œâ”€â”€ Loss: 8.2800
2025-03-02 12:29:36,796 - INFO - â”œâ”€â”€ Learning Rate: 1.37e-04
2025-03-02 12:29:36,796 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:29:37,473 - INFO - ðŸªœ Batch step - 913 -- sub batch step 3652 -- lr 1.37e-04
2025-03-02 12:29:39,627 - INFO - ðŸªœ Batch step - 913 -- sub batch step 3653 -- lr 1.37e-04
2025-03-02 12:29:42,230 - INFO - ðŸªœ Batch step - 913 -- sub batch step 3654 -- lr 1.37e-04
2025-03-02 12:29:44,385 - INFO - ðŸªœ Batch step - 913 -- sub batch step 3655 -- lr 1.37e-04
2025-03-02 12:29:46,048 - INFO - Step 913 -- ðŸ”„ Training Metrics
2025-03-02 12:29:46,048 - INFO - â”œâ”€â”€ Loss: 8.2600
2025-03-02 12:29:46,048 - INFO - â”œâ”€â”€ Learning Rate: 1.37e-04
2025-03-02 12:29:46,049 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:29:46,722 - INFO - ðŸªœ Batch step - 914 -- sub batch step 3656 -- lr 1.37e-04
2025-03-02 12:29:48,883 - INFO - ðŸªœ Batch step - 914 -- sub batch step 3657 -- lr 1.37e-04
2025-03-02 12:29:51,050 - INFO - ðŸªœ Batch step - 914 -- sub batch step 3658 -- lr 1.37e-04
2025-03-02 12:29:53,207 - INFO - ðŸªœ Batch step - 914 -- sub batch step 3659 -- lr 1.37e-04
2025-03-02 12:29:54,753 - INFO - Step 914 -- ðŸ”„ Training Metrics
2025-03-02 12:29:54,753 - INFO - â”œâ”€â”€ Loss: 8.2634
2025-03-02 12:29:54,753 - INFO - â”œâ”€â”€ Learning Rate: 1.37e-04
2025-03-02 12:29:54,753 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:29:55,432 - INFO - ðŸªœ Batch step - 915 -- sub batch step 3660 -- lr 1.37e-04
2025-03-02 12:29:57,585 - INFO - ðŸªœ Batch step - 915 -- sub batch step 3661 -- lr 1.37e-04
2025-03-02 12:30:00,050 - INFO - ðŸªœ Batch step - 915 -- sub batch step 3662 -- lr 1.37e-04
2025-03-02 12:30:02,195 - INFO - ðŸªœ Batch step - 915 -- sub batch step 3663 -- lr 1.37e-04
2025-03-02 12:30:04,165 - INFO - Step 915 -- ðŸ”„ Training Metrics
2025-03-02 12:30:04,165 - INFO - â”œâ”€â”€ Loss: 8.2462
2025-03-02 12:30:04,165 - INFO - â”œâ”€â”€ Learning Rate: 1.37e-04
2025-03-02 12:30:04,165 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:30:04,842 - INFO - ðŸªœ Batch step - 916 -- sub batch step 3664 -- lr 1.37e-04
2025-03-02 12:30:06,996 - INFO - ðŸªœ Batch step - 916 -- sub batch step 3665 -- lr 1.37e-04
2025-03-02 12:30:09,156 - INFO - ðŸªœ Batch step - 916 -- sub batch step 3666 -- lr 1.37e-04
2025-03-02 12:30:11,313 - INFO - ðŸªœ Batch step - 916 -- sub batch step 3667 -- lr 1.37e-04
2025-03-02 12:30:12,871 - INFO - Step 916 -- ðŸ”„ Training Metrics
2025-03-02 12:30:12,871 - INFO - â”œâ”€â”€ Loss: 8.2628
2025-03-02 12:30:12,871 - INFO - â”œâ”€â”€ Learning Rate: 1.37e-04
2025-03-02 12:30:12,871 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:30:13,543 - INFO - ðŸªœ Batch step - 917 -- sub batch step 3668 -- lr 1.38e-04
2025-03-02 12:30:15,698 - INFO - ðŸªœ Batch step - 917 -- sub batch step 3669 -- lr 1.38e-04
2025-03-02 12:30:18,332 - INFO - ðŸªœ Batch step - 917 -- sub batch step 3670 -- lr 1.38e-04
2025-03-02 12:30:20,480 - INFO - ðŸªœ Batch step - 917 -- sub batch step 3671 -- lr 1.38e-04
2025-03-02 12:30:22,115 - INFO - Step 917 -- ðŸ”„ Training Metrics
2025-03-02 12:30:22,116 - INFO - â”œâ”€â”€ Loss: 8.2550
2025-03-02 12:30:22,116 - INFO - â”œâ”€â”€ Learning Rate: 1.38e-04
2025-03-02 12:30:22,116 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:30:22,787 - INFO - ðŸªœ Batch step - 918 -- sub batch step 3672 -- lr 1.38e-04
2025-03-02 12:30:24,935 - INFO - ðŸªœ Batch step - 918 -- sub batch step 3673 -- lr 1.38e-04
2025-03-02 12:30:27,100 - INFO - ðŸªœ Batch step - 918 -- sub batch step 3674 -- lr 1.38e-04
2025-03-02 12:30:29,253 - INFO - ðŸªœ Batch step - 918 -- sub batch step 3675 -- lr 1.38e-04
2025-03-02 12:30:30,822 - INFO - Step 918 -- ðŸ”„ Training Metrics
2025-03-02 12:30:30,822 - INFO - â”œâ”€â”€ Loss: 8.2465
2025-03-02 12:30:30,822 - INFO - â”œâ”€â”€ Learning Rate: 1.38e-04
2025-03-02 12:30:30,823 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:30:31,495 - INFO - ðŸªœ Batch step - 919 -- sub batch step 3676 -- lr 1.38e-04
2025-03-02 12:30:33,648 - INFO - ðŸªœ Batch step - 919 -- sub batch step 3677 -- lr 1.38e-04
2025-03-02 12:30:35,953 - INFO - ðŸªœ Batch step - 919 -- sub batch step 3678 -- lr 1.38e-04
2025-03-02 12:30:38,108 - INFO - ðŸªœ Batch step - 919 -- sub batch step 3679 -- lr 1.38e-04
2025-03-02 12:30:39,743 - INFO - Step 919 -- ðŸ”„ Training Metrics
2025-03-02 12:30:39,743 - INFO - â”œâ”€â”€ Loss: 8.2209
2025-03-02 12:30:39,743 - INFO - â”œâ”€â”€ Learning Rate: 1.38e-04
2025-03-02 12:30:39,744 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:30:40,914 - INFO - ðŸªœ Batch step - 920 -- sub batch step 3680 -- lr 1.38e-04
2025-03-02 12:30:43,061 - INFO - ðŸªœ Batch step - 920 -- sub batch step 3681 -- lr 1.38e-04
2025-03-02 12:30:45,217 - INFO - ðŸªœ Batch step - 920 -- sub batch step 3682 -- lr 1.38e-04
2025-03-02 12:30:47,381 - INFO - ðŸªœ Batch step - 920 -- sub batch step 3683 -- lr 1.38e-04
2025-03-02 12:30:49,121 - INFO - Step 920 -- ðŸ”„ Training Metrics
2025-03-02 12:30:49,121 - INFO - â”œâ”€â”€ Loss: 8.2423
2025-03-02 12:30:49,121 - INFO - â”œâ”€â”€ Learning Rate: 1.38e-04
2025-03-02 12:30:49,121 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:30:49,795 - INFO - ðŸªœ Batch step - 921 -- sub batch step 3684 -- lr 1.38e-04
2025-03-02 12:30:51,948 - INFO - ðŸªœ Batch step - 921 -- sub batch step 3685 -- lr 1.38e-04
2025-03-02 12:30:54,092 - INFO - ðŸªœ Batch step - 921 -- sub batch step 3686 -- lr 1.38e-04
2025-03-02 12:30:56,533 - INFO - ðŸªœ Batch step - 921 -- sub batch step 3687 -- lr 1.38e-04
2025-03-02 12:30:58,376 - INFO - Step 921 -- ðŸ”„ Training Metrics
2025-03-02 12:30:58,376 - INFO - â”œâ”€â”€ Loss: 8.2374
2025-03-02 12:30:58,377 - INFO - â”œâ”€â”€ Learning Rate: 1.38e-04
2025-03-02 12:30:58,377 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:30:59,044 - INFO - ðŸªœ Batch step - 922 -- sub batch step 3688 -- lr 1.38e-04
2025-03-02 12:31:01,199 - INFO - ðŸªœ Batch step - 922 -- sub batch step 3689 -- lr 1.38e-04
2025-03-02 12:31:03,347 - INFO - ðŸªœ Batch step - 922 -- sub batch step 3690 -- lr 1.38e-04
2025-03-02 12:31:05,507 - INFO - ðŸªœ Batch step - 922 -- sub batch step 3691 -- lr 1.38e-04
2025-03-02 12:31:07,074 - INFO - Step 922 -- ðŸ”„ Training Metrics
2025-03-02 12:31:07,074 - INFO - â”œâ”€â”€ Loss: 8.2392
2025-03-02 12:31:07,074 - INFO - â”œâ”€â”€ Learning Rate: 1.38e-04
2025-03-02 12:31:07,074 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:31:07,751 - INFO - ðŸªœ Batch step - 923 -- sub batch step 3692 -- lr 1.38e-04
2025-03-02 12:31:09,901 - INFO - ðŸªœ Batch step - 923 -- sub batch step 3693 -- lr 1.38e-04
2025-03-02 12:31:12,053 - INFO - ðŸªœ Batch step - 923 -- sub batch step 3694 -- lr 1.38e-04
2025-03-02 12:31:14,477 - INFO - ðŸªœ Batch step - 923 -- sub batch step 3695 -- lr 1.38e-04
2025-03-02 12:31:16,400 - INFO - Step 923 -- ðŸ”„ Training Metrics
2025-03-02 12:31:16,401 - INFO - â”œâ”€â”€ Loss: 8.1976
2025-03-02 12:31:16,401 - INFO - â”œâ”€â”€ Learning Rate: 1.38e-04
2025-03-02 12:31:16,401 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:31:17,073 - INFO - ðŸªœ Batch step - 924 -- sub batch step 3696 -- lr 1.39e-04
2025-03-02 12:31:19,230 - INFO - ðŸªœ Batch step - 924 -- sub batch step 3697 -- lr 1.39e-04
2025-03-02 12:31:21,381 - INFO - ðŸªœ Batch step - 924 -- sub batch step 3698 -- lr 1.39e-04
2025-03-02 12:31:23,543 - INFO - ðŸªœ Batch step - 924 -- sub batch step 3699 -- lr 1.39e-04
2025-03-02 12:31:25,081 - INFO - Step 924 -- ðŸ”„ Training Metrics
2025-03-02 12:31:25,081 - INFO - â”œâ”€â”€ Loss: 8.2137
2025-03-02 12:31:25,081 - INFO - â”œâ”€â”€ Learning Rate: 1.39e-04
2025-03-02 12:31:25,081 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:31:25,755 - INFO - ðŸªœ Batch step - 925 -- sub batch step 3700 -- lr 1.39e-04
2025-03-02 12:31:27,903 - INFO - ðŸªœ Batch step - 925 -- sub batch step 3701 -- lr 1.39e-04
2025-03-02 12:31:30,050 - INFO - ðŸªœ Batch step - 925 -- sub batch step 3702 -- lr 1.39e-04
2025-03-02 12:31:32,416 - INFO - ðŸªœ Batch step - 925 -- sub batch step 3703 -- lr 1.39e-04
2025-03-02 12:31:34,401 - INFO - Step 925 -- ðŸ”„ Training Metrics
2025-03-02 12:31:34,401 - INFO - â”œâ”€â”€ Loss: 8.2021
2025-03-02 12:31:34,401 - INFO - â”œâ”€â”€ Learning Rate: 1.39e-04
2025-03-02 12:31:34,401 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:31:35,078 - INFO - ðŸªœ Batch step - 926 -- sub batch step 3704 -- lr 1.39e-04
2025-03-02 12:31:37,231 - INFO - ðŸªœ Batch step - 926 -- sub batch step 3705 -- lr 1.39e-04
2025-03-02 12:31:39,382 - INFO - ðŸªœ Batch step - 926 -- sub batch step 3706 -- lr 1.39e-04
2025-03-02 12:31:41,547 - INFO - ðŸªœ Batch step - 926 -- sub batch step 3707 -- lr 1.39e-04
2025-03-02 12:31:43,087 - INFO - Step 926 -- ðŸ”„ Training Metrics
2025-03-02 12:31:43,088 - INFO - â”œâ”€â”€ Loss: 8.1895
2025-03-02 12:31:43,088 - INFO - â”œâ”€â”€ Learning Rate: 1.39e-04
2025-03-02 12:31:43,088 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:31:43,756 - INFO - ðŸªœ Batch step - 927 -- sub batch step 3708 -- lr 1.39e-04
2025-03-02 12:31:45,911 - INFO - ðŸªœ Batch step - 927 -- sub batch step 3709 -- lr 1.39e-04
2025-03-02 12:31:48,069 - INFO - ðŸªœ Batch step - 927 -- sub batch step 3710 -- lr 1.39e-04
2025-03-02 12:31:50,680 - INFO - ðŸªœ Batch step - 927 -- sub batch step 3711 -- lr 1.39e-04
2025-03-02 12:31:52,252 - INFO - Step 927 -- ðŸ”„ Training Metrics
2025-03-02 12:31:52,253 - INFO - â”œâ”€â”€ Loss: 8.2101
2025-03-02 12:31:52,253 - INFO - â”œâ”€â”€ Learning Rate: 1.39e-04
2025-03-02 12:31:52,253 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:31:52,929 - INFO - ðŸªœ Batch step - 928 -- sub batch step 3712 -- lr 1.39e-04
2025-03-02 12:31:55,076 - INFO - ðŸªœ Batch step - 928 -- sub batch step 3713 -- lr 1.39e-04
2025-03-02 12:31:57,229 - INFO - ðŸªœ Batch step - 928 -- sub batch step 3714 -- lr 1.39e-04
2025-03-02 12:31:59,398 - INFO - ðŸªœ Batch step - 928 -- sub batch step 3715 -- lr 1.39e-04
2025-03-02 12:32:00,936 - INFO - Step 928 -- ðŸ”„ Training Metrics
2025-03-02 12:32:00,937 - INFO - â”œâ”€â”€ Loss: 8.1637
2025-03-02 12:32:00,937 - INFO - â”œâ”€â”€ Learning Rate: 1.39e-04
2025-03-02 12:32:00,937 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:32:01,608 - INFO - ðŸªœ Batch step - 929 -- sub batch step 3716 -- lr 1.39e-04
2025-03-02 12:32:03,762 - INFO - ðŸªœ Batch step - 929 -- sub batch step 3717 -- lr 1.39e-04
2025-03-02 12:32:05,910 - INFO - ðŸªœ Batch step - 929 -- sub batch step 3718 -- lr 1.39e-04
2025-03-02 12:32:08,578 - INFO - ðŸªœ Batch step - 929 -- sub batch step 3719 -- lr 1.39e-04
2025-03-02 12:32:10,065 - INFO - Step 929 -- ðŸ”„ Training Metrics
2025-03-02 12:32:10,065 - INFO - â”œâ”€â”€ Loss: 8.1810
2025-03-02 12:32:10,066 - INFO - â”œâ”€â”€ Learning Rate: 1.39e-04
2025-03-02 12:32:10,066 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:32:10,740 - INFO - ðŸªœ Batch step - 930 -- sub batch step 3720 -- lr 1.40e-04
2025-03-02 12:32:12,885 - INFO - ðŸªœ Batch step - 930 -- sub batch step 3721 -- lr 1.40e-04
2025-03-02 12:32:15,037 - INFO - ðŸªœ Batch step - 930 -- sub batch step 3722 -- lr 1.40e-04
2025-03-02 12:32:17,200 - INFO - ðŸªœ Batch step - 930 -- sub batch step 3723 -- lr 1.40e-04
2025-03-02 12:32:18,748 - INFO - Step 930 -- ðŸ”„ Training Metrics
2025-03-02 12:32:18,748 - INFO - â”œâ”€â”€ Loss: 8.1891
2025-03-02 12:32:18,748 - INFO - â”œâ”€â”€ Learning Rate: 1.40e-04
2025-03-02 12:32:18,749 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:32:19,422 - INFO - ðŸªœ Batch step - 931 -- sub batch step 3724 -- lr 1.40e-04
2025-03-02 12:32:21,574 - INFO - ðŸªœ Batch step - 931 -- sub batch step 3725 -- lr 1.40e-04
2025-03-02 12:32:24,237 - INFO - ðŸªœ Batch step - 931 -- sub batch step 3726 -- lr 1.40e-04
2025-03-02 12:32:26,386 - INFO - ðŸªœ Batch step - 931 -- sub batch step 3727 -- lr 1.40e-04
2025-03-02 12:32:28,009 - INFO - Step 931 -- ðŸ”„ Training Metrics
2025-03-02 12:32:28,009 - INFO - â”œâ”€â”€ Loss: 8.1540
2025-03-02 12:32:28,009 - INFO - â”œâ”€â”€ Learning Rate: 1.40e-04
2025-03-02 12:32:28,010 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:32:28,681 - INFO - ðŸªœ Batch step - 932 -- sub batch step 3728 -- lr 1.40e-04
2025-03-02 12:32:30,835 - INFO - ðŸªœ Batch step - 932 -- sub batch step 3729 -- lr 1.40e-04
2025-03-02 12:32:33,003 - INFO - ðŸªœ Batch step - 932 -- sub batch step 3730 -- lr 1.40e-04
2025-03-02 12:32:35,149 - INFO - ðŸªœ Batch step - 932 -- sub batch step 3731 -- lr 1.40e-04
2025-03-02 12:32:36,693 - INFO - Step 932 -- ðŸ”„ Training Metrics
2025-03-02 12:32:36,694 - INFO - â”œâ”€â”€ Loss: 8.1359
2025-03-02 12:32:36,694 - INFO - â”œâ”€â”€ Learning Rate: 1.40e-04
2025-03-02 12:32:36,694 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:32:37,371 - INFO - ðŸªœ Batch step - 933 -- sub batch step 3732 -- lr 1.40e-04
2025-03-02 12:32:39,518 - INFO - ðŸªœ Batch step - 933 -- sub batch step 3733 -- lr 1.40e-04
2025-03-02 12:32:41,926 - INFO - ðŸªœ Batch step - 933 -- sub batch step 3734 -- lr 1.40e-04
2025-03-02 12:32:44,076 - INFO - ðŸªœ Batch step - 933 -- sub batch step 3735 -- lr 1.40e-04
2025-03-02 12:32:46,020 - INFO - Step 933 -- ðŸ”„ Training Metrics
2025-03-02 12:32:46,020 - INFO - â”œâ”€â”€ Loss: 8.1641
2025-03-02 12:32:46,020 - INFO - â”œâ”€â”€ Learning Rate: 1.40e-04
2025-03-02 12:32:46,020 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:32:46,688 - INFO - ðŸªœ Batch step - 934 -- sub batch step 3736 -- lr 1.40e-04
2025-03-02 12:32:48,840 - INFO - ðŸªœ Batch step - 934 -- sub batch step 3737 -- lr 1.40e-04
2025-03-02 12:32:51,016 - INFO - ðŸªœ Batch step - 934 -- sub batch step 3738 -- lr 1.40e-04
2025-03-02 12:32:53,168 - INFO - ðŸªœ Batch step - 934 -- sub batch step 3739 -- lr 1.40e-04
2025-03-02 12:32:54,703 - INFO - Step 934 -- ðŸ”„ Training Metrics
2025-03-02 12:32:54,703 - INFO - â”œâ”€â”€ Loss: 8.1743
2025-03-02 12:32:54,703 - INFO - â”œâ”€â”€ Learning Rate: 1.40e-04
2025-03-02 12:32:54,703 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:32:55,378 - INFO - ðŸªœ Batch step - 935 -- sub batch step 3740 -- lr 1.40e-04
2025-03-02 12:32:57,523 - INFO - ðŸªœ Batch step - 935 -- sub batch step 3741 -- lr 1.40e-04
2025-03-02 12:33:00,190 - INFO - ðŸªœ Batch step - 935 -- sub batch step 3742 -- lr 1.40e-04
2025-03-02 12:33:02,335 - INFO - ðŸªœ Batch step - 935 -- sub batch step 3743 -- lr 1.40e-04
2025-03-02 12:33:03,897 - INFO - Step 935 -- ðŸ”„ Training Metrics
2025-03-02 12:33:03,897 - INFO - â”œâ”€â”€ Loss: 8.1666
2025-03-02 12:33:03,897 - INFO - â”œâ”€â”€ Learning Rate: 1.40e-04
2025-03-02 12:33:03,897 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:33:04,570 - INFO - ðŸªœ Batch step - 936 -- sub batch step 3744 -- lr 1.40e-04
2025-03-02 12:33:06,721 - INFO - ðŸªœ Batch step - 936 -- sub batch step 3745 -- lr 1.40e-04
2025-03-02 12:33:08,882 - INFO - ðŸªœ Batch step - 936 -- sub batch step 3746 -- lr 1.40e-04
2025-03-02 12:33:11,032 - INFO - ðŸªœ Batch step - 936 -- sub batch step 3747 -- lr 1.40e-04
2025-03-02 12:33:12,586 - INFO - Step 936 -- ðŸ”„ Training Metrics
2025-03-02 12:33:12,587 - INFO - â”œâ”€â”€ Loss: 8.1408
2025-03-02 12:33:12,587 - INFO - â”œâ”€â”€ Learning Rate: 1.40e-04
2025-03-02 12:33:12,587 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:33:13,255 - INFO - ðŸªœ Batch step - 937 -- sub batch step 3748 -- lr 1.41e-04
2025-03-02 12:33:15,408 - INFO - ðŸªœ Batch step - 937 -- sub batch step 3749 -- lr 1.41e-04
2025-03-02 12:33:18,003 - INFO - ðŸªœ Batch step - 937 -- sub batch step 3750 -- lr 1.41e-04
2025-03-02 12:33:20,148 - INFO - ðŸªœ Batch step - 937 -- sub batch step 3751 -- lr 1.41e-04
2025-03-02 12:33:21,746 - INFO - Step 937 -- ðŸ”„ Training Metrics
2025-03-02 12:33:21,746 - INFO - â”œâ”€â”€ Loss: 8.1252
2025-03-02 12:33:21,747 - INFO - â”œâ”€â”€ Learning Rate: 1.41e-04
2025-03-02 12:33:21,747 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:33:22,420 - INFO - ðŸªœ Batch step - 938 -- sub batch step 3752 -- lr 1.41e-04
2025-03-02 12:33:24,565 - INFO - ðŸªœ Batch step - 938 -- sub batch step 3753 -- lr 1.41e-04
2025-03-02 12:33:26,736 - INFO - ðŸªœ Batch step - 938 -- sub batch step 3754 -- lr 1.41e-04
2025-03-02 12:33:28,890 - INFO - ðŸªœ Batch step - 938 -- sub batch step 3755 -- lr 1.41e-04
2025-03-02 12:33:30,442 - INFO - Step 938 -- ðŸ”„ Training Metrics
2025-03-02 12:33:30,442 - INFO - â”œâ”€â”€ Loss: 8.1411
2025-03-02 12:33:30,442 - INFO - â”œâ”€â”€ Learning Rate: 1.41e-04
2025-03-02 12:33:30,442 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:33:31,111 - INFO - ðŸªœ Batch step - 939 -- sub batch step 3756 -- lr 1.41e-04
2025-03-02 12:33:33,264 - INFO - ðŸªœ Batch step - 939 -- sub batch step 3757 -- lr 1.41e-04
2025-03-02 12:33:35,538 - INFO - ðŸªœ Batch step - 939 -- sub batch step 3758 -- lr 1.41e-04
2025-03-02 12:33:37,690 - INFO - ðŸªœ Batch step - 939 -- sub batch step 3759 -- lr 1.41e-04
2025-03-02 12:33:39,240 - INFO - Step 939 -- ðŸ”„ Training Metrics
2025-03-02 12:33:39,240 - INFO - â”œâ”€â”€ Loss: 8.1436
2025-03-02 12:33:39,240 - INFO - â”œâ”€â”€ Learning Rate: 1.41e-04
2025-03-02 12:33:39,240 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:33:40,448 - INFO - ðŸªœ Batch step - 940 -- sub batch step 3760 -- lr 1.41e-04
2025-03-02 12:33:42,600 - INFO - ðŸªœ Batch step - 940 -- sub batch step 3761 -- lr 1.41e-04
2025-03-02 12:33:44,757 - INFO - ðŸªœ Batch step - 940 -- sub batch step 3762 -- lr 1.41e-04
2025-03-02 12:33:46,926 - INFO - ðŸªœ Batch step - 940 -- sub batch step 3763 -- lr 1.41e-04
2025-03-02 12:33:48,635 - INFO - Step 940 -- ðŸ”„ Training Metrics
2025-03-02 12:33:48,635 - INFO - â”œâ”€â”€ Loss: 8.1214
2025-03-02 12:33:48,635 - INFO - â”œâ”€â”€ Learning Rate: 1.41e-04
2025-03-02 12:33:48,635 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:33:49,307 - INFO - ðŸªœ Batch step - 941 -- sub batch step 3764 -- lr 1.41e-04
2025-03-02 12:33:51,461 - INFO - ðŸªœ Batch step - 941 -- sub batch step 3765 -- lr 1.41e-04
2025-03-02 12:33:53,605 - INFO - ðŸªœ Batch step - 941 -- sub batch step 3766 -- lr 1.41e-04
2025-03-02 12:33:55,994 - INFO - ðŸªœ Batch step - 941 -- sub batch step 3767 -- lr 1.41e-04
2025-03-02 12:33:59,517 - INFO - Step 941 -- ðŸ”„ Training Metrics
2025-03-02 12:33:59,517 - INFO - â”œâ”€â”€ Loss: 8.1227
2025-03-02 12:33:59,517 - INFO - â”œâ”€â”€ Learning Rate: 1.41e-04
2025-03-02 12:33:59,517 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:34:00,181 - INFO - ðŸªœ Batch step - 942 -- sub batch step 3768 -- lr 1.41e-04
2025-03-02 12:34:02,334 - INFO - ðŸªœ Batch step - 942 -- sub batch step 3769 -- lr 1.41e-04
2025-03-02 12:34:04,485 - INFO - ðŸªœ Batch step - 942 -- sub batch step 3770 -- lr 1.41e-04
2025-03-02 12:34:06,648 - INFO - ðŸªœ Batch step - 942 -- sub batch step 3771 -- lr 1.41e-04
2025-03-02 12:34:08,203 - INFO - Step 942 -- ðŸ”„ Training Metrics
2025-03-02 12:34:08,203 - INFO - â”œâ”€â”€ Loss: 8.1148
2025-03-02 12:34:08,203 - INFO - â”œâ”€â”€ Learning Rate: 1.41e-04
2025-03-02 12:34:08,204 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:34:08,876 - INFO - ðŸªœ Batch step - 943 -- sub batch step 3772 -- lr 1.41e-04
2025-03-02 12:34:11,024 - INFO - ðŸªœ Batch step - 943 -- sub batch step 3773 -- lr 1.41e-04
2025-03-02 12:34:13,176 - INFO - ðŸªœ Batch step - 943 -- sub batch step 3774 -- lr 1.41e-04
2025-03-02 12:34:15,542 - INFO - ðŸªœ Batch step - 943 -- sub batch step 3775 -- lr 1.41e-04
2025-03-02 12:34:17,527 - INFO - Step 943 -- ðŸ”„ Training Metrics
2025-03-02 12:34:17,527 - INFO - â”œâ”€â”€ Loss: 8.1278
2025-03-02 12:34:17,527 - INFO - â”œâ”€â”€ Learning Rate: 1.41e-04
2025-03-02 12:34:17,527 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:34:18,195 - INFO - ðŸªœ Batch step - 944 -- sub batch step 3776 -- lr 1.42e-04
2025-03-02 12:34:20,348 - INFO - ðŸªœ Batch step - 944 -- sub batch step 3777 -- lr 1.42e-04
2025-03-02 12:34:22,497 - INFO - ðŸªœ Batch step - 944 -- sub batch step 3778 -- lr 1.42e-04
2025-03-02 12:34:24,667 - INFO - ðŸªœ Batch step - 944 -- sub batch step 3779 -- lr 1.42e-04
2025-03-02 12:34:26,204 - INFO - Step 944 -- ðŸ”„ Training Metrics
2025-03-02 12:34:26,204 - INFO - â”œâ”€â”€ Loss: 8.1089
2025-03-02 12:34:26,204 - INFO - â”œâ”€â”€ Learning Rate: 1.42e-04
2025-03-02 12:34:26,204 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:34:26,879 - INFO - ðŸªœ Batch step - 945 -- sub batch step 3780 -- lr 1.42e-04
2025-03-02 12:34:29,026 - INFO - ðŸªœ Batch step - 945 -- sub batch step 3781 -- lr 1.42e-04
2025-03-02 12:34:31,178 - INFO - ðŸªœ Batch step - 945 -- sub batch step 3782 -- lr 1.42e-04
2025-03-02 12:34:33,613 - INFO - ðŸªœ Batch step - 945 -- sub batch step 3783 -- lr 1.42e-04
2025-03-02 12:34:35,524 - INFO - Step 945 -- ðŸ”„ Training Metrics
2025-03-02 12:34:35,524 - INFO - â”œâ”€â”€ Loss: 8.1002
2025-03-02 12:34:35,524 - INFO - â”œâ”€â”€ Learning Rate: 1.42e-04
2025-03-02 12:34:35,524 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:34:36,199 - INFO - ðŸªœ Batch step - 946 -- sub batch step 3784 -- lr 1.42e-04
2025-03-02 12:34:38,350 - INFO - ðŸªœ Batch step - 946 -- sub batch step 3785 -- lr 1.42e-04
2025-03-02 12:34:40,496 - INFO - ðŸªœ Batch step - 946 -- sub batch step 3786 -- lr 1.42e-04
2025-03-02 12:34:42,667 - INFO - ðŸªœ Batch step - 946 -- sub batch step 3787 -- lr 1.42e-04
2025-03-02 12:34:44,203 - INFO - Step 946 -- ðŸ”„ Training Metrics
2025-03-02 12:34:44,203 - INFO - â”œâ”€â”€ Loss: 8.0871
2025-03-02 12:34:44,203 - INFO - â”œâ”€â”€ Learning Rate: 1.42e-04
2025-03-02 12:34:44,203 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:34:44,874 - INFO - ðŸªœ Batch step - 947 -- sub batch step 3788 -- lr 1.42e-04
2025-03-02 12:34:47,024 - INFO - ðŸªœ Batch step - 947 -- sub batch step 3789 -- lr 1.42e-04
2025-03-02 12:34:49,178 - INFO - ðŸªœ Batch step - 947 -- sub batch step 3790 -- lr 1.42e-04
2025-03-02 12:34:51,844 - INFO - ðŸªœ Batch step - 947 -- sub batch step 3791 -- lr 1.42e-04
2025-03-02 12:34:53,853 - INFO - Step 947 -- ðŸ”„ Training Metrics
2025-03-02 12:34:53,853 - INFO - â”œâ”€â”€ Loss: 8.0679
2025-03-02 12:34:53,853 - INFO - â”œâ”€â”€ Learning Rate: 1.42e-04
2025-03-02 12:34:53,853 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:34:54,527 - INFO - ðŸªœ Batch step - 948 -- sub batch step 3792 -- lr 1.42e-04
2025-03-02 12:34:56,672 - INFO - ðŸªœ Batch step - 948 -- sub batch step 3793 -- lr 1.42e-04
2025-03-02 12:34:58,824 - INFO - ðŸªœ Batch step - 948 -- sub batch step 3794 -- lr 1.42e-04
2025-03-02 12:35:00,992 - INFO - ðŸªœ Batch step - 948 -- sub batch step 3795 -- lr 1.42e-04
2025-03-02 12:35:02,532 - INFO - Step 948 -- ðŸ”„ Training Metrics
2025-03-02 12:35:02,532 - INFO - â”œâ”€â”€ Loss: 8.0971
2025-03-02 12:35:02,532 - INFO - â”œâ”€â”€ Learning Rate: 1.42e-04
2025-03-02 12:35:02,532 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:35:03,196 - INFO - ðŸªœ Batch step - 949 -- sub batch step 3796 -- lr 1.42e-04
2025-03-02 12:35:05,345 - INFO - ðŸªœ Batch step - 949 -- sub batch step 3797 -- lr 1.42e-04
2025-03-02 12:35:07,488 - INFO - ðŸªœ Batch step - 949 -- sub batch step 3798 -- lr 1.42e-04
2025-03-02 12:35:10,204 - INFO - ðŸªœ Batch step - 949 -- sub batch step 3799 -- lr 1.42e-04
2025-03-02 12:35:11,725 - INFO - Step 949 -- ðŸ”„ Training Metrics
2025-03-02 12:35:11,725 - INFO - â”œâ”€â”€ Loss: 8.0855
2025-03-02 12:35:11,725 - INFO - â”œâ”€â”€ Learning Rate: 1.42e-04
2025-03-02 12:35:11,725 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:35:12,398 - INFO - ðŸªœ Batch step - 950 -- sub batch step 3800 -- lr 1.42e-04
2025-03-02 12:35:14,547 - INFO - ðŸªœ Batch step - 950 -- sub batch step 3801 -- lr 1.42e-04
2025-03-02 12:35:16,697 - INFO - ðŸªœ Batch step - 950 -- sub batch step 3802 -- lr 1.42e-04
2025-03-02 12:35:18,861 - INFO - ðŸªœ Batch step - 950 -- sub batch step 3803 -- lr 1.42e-04
2025-03-02 12:35:20,403 - INFO - Step 950 -- ðŸ”„ Training Metrics
2025-03-02 12:35:20,404 - INFO - â”œâ”€â”€ Loss: 8.1082
2025-03-02 12:35:20,404 - INFO - â”œâ”€â”€ Learning Rate: 1.42e-04
2025-03-02 12:35:20,404 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:35:21,086 - INFO - ðŸªœ Batch step - 951 -- sub batch step 3804 -- lr 1.43e-04
2025-03-02 12:35:23,251 - INFO - ðŸªœ Batch step - 951 -- sub batch step 3805 -- lr 1.43e-04
2025-03-02 12:35:25,927 - INFO - ðŸªœ Batch step - 951 -- sub batch step 3806 -- lr 1.43e-04
2025-03-02 12:35:28,082 - INFO - ðŸªœ Batch step - 951 -- sub batch step 3807 -- lr 1.43e-04
2025-03-02 12:35:29,598 - INFO - Step 951 -- ðŸ”„ Training Metrics
2025-03-02 12:35:29,599 - INFO - â”œâ”€â”€ Loss: 8.0725
2025-03-02 12:35:29,599 - INFO - â”œâ”€â”€ Learning Rate: 1.43e-04
2025-03-02 12:35:29,599 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:35:30,266 - INFO - ðŸªœ Batch step - 952 -- sub batch step 3808 -- lr 1.43e-04
2025-03-02 12:35:32,418 - INFO - ðŸªœ Batch step - 952 -- sub batch step 3809 -- lr 1.43e-04
2025-03-02 12:35:34,586 - INFO - ðŸªœ Batch step - 952 -- sub batch step 3810 -- lr 1.43e-04
2025-03-02 12:35:36,732 - INFO - ðŸªœ Batch step - 952 -- sub batch step 3811 -- lr 1.43e-04
2025-03-02 12:35:38,272 - INFO - Step 952 -- ðŸ”„ Training Metrics
2025-03-02 12:35:38,272 - INFO - â”œâ”€â”€ Loss: 8.0609
2025-03-02 12:35:38,272 - INFO - â”œâ”€â”€ Learning Rate: 1.43e-04
2025-03-02 12:35:38,273 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:35:38,946 - INFO - ðŸªœ Batch step - 953 -- sub batch step 3812 -- lr 1.43e-04
2025-03-02 12:35:41,092 - INFO - ðŸªœ Batch step - 953 -- sub batch step 3813 -- lr 1.43e-04
2025-03-02 12:35:43,475 - INFO - ðŸªœ Batch step - 953 -- sub batch step 3814 -- lr 1.43e-04
2025-03-02 12:35:45,630 - INFO - ðŸªœ Batch step - 953 -- sub batch step 3815 -- lr 1.43e-04
2025-03-02 12:35:47,449 - INFO - Step 953 -- ðŸ”„ Training Metrics
2025-03-02 12:35:47,449 - INFO - â”œâ”€â”€ Loss: 8.0554
2025-03-02 12:35:47,450 - INFO - â”œâ”€â”€ Learning Rate: 1.43e-04
2025-03-02 12:35:47,450 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:35:48,115 - INFO - ðŸªœ Batch step - 954 -- sub batch step 3816 -- lr 1.43e-04
2025-03-02 12:35:50,267 - INFO - ðŸªœ Batch step - 954 -- sub batch step 3817 -- lr 1.43e-04
2025-03-02 12:35:52,432 - INFO - ðŸªœ Batch step - 954 -- sub batch step 3818 -- lr 1.43e-04
2025-03-02 12:35:54,582 - INFO - ðŸªœ Batch step - 954 -- sub batch step 3819 -- lr 1.43e-04
2025-03-02 12:35:56,145 - INFO - Step 954 -- ðŸ”„ Training Metrics
2025-03-02 12:35:56,146 - INFO - â”œâ”€â”€ Loss: 8.0628
2025-03-02 12:35:56,146 - INFO - â”œâ”€â”€ Learning Rate: 1.43e-04
2025-03-02 12:35:56,146 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:35:56,819 - INFO - ðŸªœ Batch step - 955 -- sub batch step 3820 -- lr 1.43e-04
2025-03-02 12:35:58,961 - INFO - ðŸªœ Batch step - 955 -- sub batch step 3821 -- lr 1.43e-04
2025-03-02 12:36:01,555 - INFO - ðŸªœ Batch step - 955 -- sub batch step 3822 -- lr 1.43e-04
2025-03-02 12:36:03,701 - INFO - ðŸªœ Batch step - 955 -- sub batch step 3823 -- lr 1.43e-04
2025-03-02 12:36:05,338 - INFO - Step 955 -- ðŸ”„ Training Metrics
2025-03-02 12:36:05,338 - INFO - â”œâ”€â”€ Loss: 8.0579
2025-03-02 12:36:05,338 - INFO - â”œâ”€â”€ Learning Rate: 1.43e-04
2025-03-02 12:36:05,338 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:36:06,013 - INFO - ðŸªœ Batch step - 956 -- sub batch step 3824 -- lr 1.43e-04
2025-03-02 12:36:08,165 - INFO - ðŸªœ Batch step - 956 -- sub batch step 3825 -- lr 1.43e-04
2025-03-02 12:36:10,330 - INFO - ðŸªœ Batch step - 956 -- sub batch step 3826 -- lr 1.43e-04
2025-03-02 12:36:12,482 - INFO - ðŸªœ Batch step - 956 -- sub batch step 3827 -- lr 1.43e-04
2025-03-02 12:36:14,029 - INFO - Step 956 -- ðŸ”„ Training Metrics
2025-03-02 12:36:14,029 - INFO - â”œâ”€â”€ Loss: 8.0498
2025-03-02 12:36:14,029 - INFO - â”œâ”€â”€ Learning Rate: 1.43e-04
2025-03-02 12:36:14,029 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:36:14,697 - INFO - ðŸªœ Batch step - 957 -- sub batch step 3828 -- lr 1.44e-04
2025-03-02 12:36:16,852 - INFO - ðŸªœ Batch step - 957 -- sub batch step 3829 -- lr 1.44e-04
2025-03-02 12:36:19,228 - INFO - ðŸªœ Batch step - 957 -- sub batch step 3830 -- lr 1.44e-04
2025-03-02 12:36:21,382 - INFO - ðŸªœ Batch step - 957 -- sub batch step 3831 -- lr 1.44e-04
2025-03-02 12:36:23,163 - INFO - Step 957 -- ðŸ”„ Training Metrics
2025-03-02 12:36:23,164 - INFO - â”œâ”€â”€ Loss: 8.0417
2025-03-02 12:36:23,164 - INFO - â”œâ”€â”€ Learning Rate: 1.44e-04
2025-03-02 12:36:23,164 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:36:23,838 - INFO - ðŸªœ Batch step - 958 -- sub batch step 3832 -- lr 1.44e-04
2025-03-02 12:36:25,982 - INFO - ðŸªœ Batch step - 958 -- sub batch step 3833 -- lr 1.44e-04
2025-03-02 12:36:28,151 - INFO - ðŸªœ Batch step - 958 -- sub batch step 3834 -- lr 1.44e-04
2025-03-02 12:36:30,303 - INFO - ðŸªœ Batch step - 958 -- sub batch step 3835 -- lr 1.44e-04
2025-03-02 12:36:31,848 - INFO - Step 958 -- ðŸ”„ Training Metrics
2025-03-02 12:36:31,848 - INFO - â”œâ”€â”€ Loss: 8.0325
2025-03-02 12:36:31,849 - INFO - â”œâ”€â”€ Learning Rate: 1.44e-04
2025-03-02 12:36:31,849 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:36:32,519 - INFO - ðŸªœ Batch step - 959 -- sub batch step 3836 -- lr 1.44e-04
2025-03-02 12:36:34,671 - INFO - ðŸªœ Batch step - 959 -- sub batch step 3837 -- lr 1.44e-04
2025-03-02 12:36:36,950 - INFO - ðŸªœ Batch step - 959 -- sub batch step 3838 -- lr 1.44e-04
2025-03-02 12:36:39,101 - INFO - ðŸªœ Batch step - 959 -- sub batch step 3839 -- lr 1.44e-04
2025-03-02 12:36:40,671 - INFO - Step 959 -- ðŸ”„ Training Metrics
2025-03-02 12:36:40,671 - INFO - â”œâ”€â”€ Loss: 8.0378
2025-03-02 12:36:40,671 - INFO - â”œâ”€â”€ Learning Rate: 1.44e-04
2025-03-02 12:36:40,672 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:36:41,916 - INFO - ðŸªœ Batch step - 960 -- sub batch step 3840 -- lr 1.44e-04
2025-03-02 12:36:44,063 - INFO - ðŸªœ Batch step - 960 -- sub batch step 3841 -- lr 1.44e-04
2025-03-02 12:36:46,215 - INFO - ðŸªœ Batch step - 960 -- sub batch step 3842 -- lr 1.44e-04
2025-03-02 12:36:48,383 - INFO - ðŸªœ Batch step - 960 -- sub batch step 3843 -- lr 1.44e-04
2025-03-02 12:36:50,059 - INFO - Step 960 -- ðŸ”„ Training Metrics
2025-03-02 12:36:50,060 - INFO - â”œâ”€â”€ Loss: 8.0341
2025-03-02 12:36:50,060 - INFO - â”œâ”€â”€ Learning Rate: 1.44e-04
2025-03-02 12:36:50,060 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:36:50,731 - INFO - ðŸªœ Batch step - 961 -- sub batch step 3844 -- lr 1.44e-04
2025-03-02 12:36:52,881 - INFO - ðŸªœ Batch step - 961 -- sub batch step 3845 -- lr 1.44e-04
2025-03-02 12:36:55,029 - INFO - ðŸªœ Batch step - 961 -- sub batch step 3846 -- lr 1.44e-04
2025-03-02 12:36:57,505 - INFO - ðŸªœ Batch step - 961 -- sub batch step 3847 -- lr 1.44e-04
2025-03-02 12:36:59,125 - INFO - Step 961 -- ðŸ”„ Training Metrics
2025-03-02 12:36:59,125 - INFO - â”œâ”€â”€ Loss: 8.0166
2025-03-02 12:36:59,125 - INFO - â”œâ”€â”€ Learning Rate: 1.44e-04
2025-03-02 12:36:59,125 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:36:59,794 - INFO - ðŸªœ Batch step - 962 -- sub batch step 3848 -- lr 1.44e-04
2025-03-02 12:37:01,949 - INFO - ðŸªœ Batch step - 962 -- sub batch step 3849 -- lr 1.44e-04
2025-03-02 12:37:04,101 - INFO - ðŸªœ Batch step - 962 -- sub batch step 3850 -- lr 1.44e-04
2025-03-02 12:37:06,265 - INFO - ðŸªœ Batch step - 962 -- sub batch step 3851 -- lr 1.44e-04
2025-03-02 12:37:07,829 - INFO - Step 962 -- ðŸ”„ Training Metrics
2025-03-02 12:37:07,830 - INFO - â”œâ”€â”€ Loss: 8.0289
2025-03-02 12:37:07,830 - INFO - â”œâ”€â”€ Learning Rate: 1.44e-04
2025-03-02 12:37:07,830 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:37:08,503 - INFO - ðŸªœ Batch step - 963 -- sub batch step 3852 -- lr 1.44e-04
2025-03-02 12:37:10,651 - INFO - ðŸªœ Batch step - 963 -- sub batch step 3853 -- lr 1.44e-04
2025-03-02 12:37:12,802 - INFO - ðŸªœ Batch step - 963 -- sub batch step 3854 -- lr 1.44e-04
2025-03-02 12:37:15,512 - INFO - ðŸªœ Batch step - 963 -- sub batch step 3855 -- lr 1.44e-04
2025-03-02 12:37:17,146 - INFO - Step 963 -- ðŸ”„ Training Metrics
2025-03-02 12:37:17,146 - INFO - â”œâ”€â”€ Loss: 8.0183
2025-03-02 12:37:17,147 - INFO - â”œâ”€â”€ Learning Rate: 1.44e-04
2025-03-02 12:37:17,147 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:37:17,813 - INFO - ðŸªœ Batch step - 964 -- sub batch step 3856 -- lr 1.45e-04
2025-03-02 12:37:19,964 - INFO - ðŸªœ Batch step - 964 -- sub batch step 3857 -- lr 1.45e-04
2025-03-02 12:37:22,107 - INFO - ðŸªœ Batch step - 964 -- sub batch step 3858 -- lr 1.45e-04
2025-03-02 12:37:24,274 - INFO - ðŸªœ Batch step - 964 -- sub batch step 3859 -- lr 1.45e-04
2025-03-02 12:37:25,837 - INFO - Step 964 -- ðŸ”„ Training Metrics
2025-03-02 12:37:25,837 - INFO - â”œâ”€â”€ Loss: 8.0241
2025-03-02 12:37:25,837 - INFO - â”œâ”€â”€ Learning Rate: 1.45e-04
2025-03-02 12:37:25,837 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:37:26,514 - INFO - ðŸªœ Batch step - 965 -- sub batch step 3860 -- lr 1.45e-04
2025-03-02 12:37:28,658 - INFO - ðŸªœ Batch step - 965 -- sub batch step 3861 -- lr 1.45e-04
2025-03-02 12:37:30,810 - INFO - ðŸªœ Batch step - 965 -- sub batch step 3862 -- lr 1.45e-04
2025-03-02 12:37:33,224 - INFO - ðŸªœ Batch step - 965 -- sub batch step 3863 -- lr 1.45e-04
2025-03-02 12:37:35,008 - INFO - Step 965 -- ðŸ”„ Training Metrics
2025-03-02 12:37:35,008 - INFO - â”œâ”€â”€ Loss: 8.0120
2025-03-02 12:37:35,008 - INFO - â”œâ”€â”€ Learning Rate: 1.45e-04
2025-03-02 12:37:35,008 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:37:35,685 - INFO - ðŸªœ Batch step - 966 -- sub batch step 3864 -- lr 1.45e-04
2025-03-02 12:37:37,839 - INFO - ðŸªœ Batch step - 966 -- sub batch step 3865 -- lr 1.45e-04
2025-03-02 12:37:39,989 - INFO - ðŸªœ Batch step - 966 -- sub batch step 3866 -- lr 1.45e-04
2025-03-02 12:37:42,157 - INFO - ðŸªœ Batch step - 966 -- sub batch step 3867 -- lr 1.45e-04
2025-03-02 12:37:43,714 - INFO - Step 966 -- ðŸ”„ Training Metrics
2025-03-02 12:37:43,714 - INFO - â”œâ”€â”€ Loss: 7.9833
2025-03-02 12:37:43,714 - INFO - â”œâ”€â”€ Learning Rate: 1.45e-04
2025-03-02 12:37:43,714 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:37:44,386 - INFO - ðŸªœ Batch step - 967 -- sub batch step 3868 -- lr 1.45e-04
2025-03-02 12:37:46,543 - INFO - ðŸªœ Batch step - 967 -- sub batch step 3869 -- lr 1.45e-04
2025-03-02 12:37:48,699 - INFO - ðŸªœ Batch step - 967 -- sub batch step 3870 -- lr 1.45e-04
2025-03-02 12:37:51,132 - INFO - ðŸªœ Batch step - 967 -- sub batch step 3871 -- lr 1.45e-04
2025-03-02 12:37:52,948 - INFO - Step 967 -- ðŸ”„ Training Metrics
2025-03-02 12:37:52,948 - INFO - â”œâ”€â”€ Loss: 7.9869
2025-03-02 12:37:52,948 - INFO - â”œâ”€â”€ Learning Rate: 1.45e-04
2025-03-02 12:37:52,948 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:37:53,627 - INFO - ðŸªœ Batch step - 968 -- sub batch step 3872 -- lr 1.45e-04
2025-03-02 12:37:55,779 - INFO - ðŸªœ Batch step - 968 -- sub batch step 3873 -- lr 1.45e-04
2025-03-02 12:37:57,935 - INFO - ðŸªœ Batch step - 968 -- sub batch step 3874 -- lr 1.45e-04
2025-03-02 12:38:00,107 - INFO - ðŸªœ Batch step - 968 -- sub batch step 3875 -- lr 1.45e-04
2025-03-02 12:38:01,635 - INFO - Step 968 -- ðŸ”„ Training Metrics
2025-03-02 12:38:01,635 - INFO - â”œâ”€â”€ Loss: 7.9792
2025-03-02 12:38:01,635 - INFO - â”œâ”€â”€ Learning Rate: 1.45e-04
2025-03-02 12:38:01,635 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:38:02,304 - INFO - ðŸªœ Batch step - 969 -- sub batch step 3876 -- lr 1.45e-04
2025-03-02 12:38:04,459 - INFO - ðŸªœ Batch step - 969 -- sub batch step 3877 -- lr 1.45e-04
2025-03-02 12:38:06,606 - INFO - ðŸªœ Batch step - 969 -- sub batch step 3878 -- lr 1.45e-04
2025-03-02 12:38:09,295 - INFO - ðŸªœ Batch step - 969 -- sub batch step 3879 -- lr 1.45e-04
2025-03-02 12:38:10,955 - INFO - Step 969 -- ðŸ”„ Training Metrics
2025-03-02 12:38:10,955 - INFO - â”œâ”€â”€ Loss: 7.9900
2025-03-02 12:38:10,955 - INFO - â”œâ”€â”€ Learning Rate: 1.45e-04
2025-03-02 12:38:10,956 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:38:11,635 - INFO - ðŸªœ Batch step - 970 -- sub batch step 3880 -- lr 1.45e-04
2025-03-02 12:38:13,784 - INFO - ðŸªœ Batch step - 970 -- sub batch step 3881 -- lr 1.45e-04
2025-03-02 12:38:15,934 - INFO - ðŸªœ Batch step - 970 -- sub batch step 3882 -- lr 1.45e-04
2025-03-02 12:38:18,092 - INFO - ðŸªœ Batch step - 970 -- sub batch step 3883 -- lr 1.45e-04
2025-03-02 12:38:19,643 - INFO - Step 970 -- ðŸ”„ Training Metrics
2025-03-02 12:38:19,643 - INFO - â”œâ”€â”€ Loss: 7.9809
2025-03-02 12:38:19,643 - INFO - â”œâ”€â”€ Learning Rate: 1.45e-04
2025-03-02 12:38:19,643 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:38:20,317 - INFO - ðŸªœ Batch step - 971 -- sub batch step 3884 -- lr 1.46e-04
2025-03-02 12:38:22,470 - INFO - ðŸªœ Batch step - 971 -- sub batch step 3885 -- lr 1.46e-04
2025-03-02 12:38:25,081 - INFO - ðŸªœ Batch step - 971 -- sub batch step 3886 -- lr 1.46e-04
2025-03-02 12:38:27,234 - INFO - ðŸªœ Batch step - 971 -- sub batch step 3887 -- lr 1.46e-04
2025-03-02 12:38:28,931 - INFO - Step 971 -- ðŸ”„ Training Metrics
2025-03-02 12:38:28,931 - INFO - â”œâ”€â”€ Loss: 7.9707
2025-03-02 12:38:28,931 - INFO - â”œâ”€â”€ Learning Rate: 1.46e-04
2025-03-02 12:38:28,931 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:38:29,600 - INFO - ðŸªœ Batch step - 972 -- sub batch step 3888 -- lr 1.46e-04
2025-03-02 12:38:31,755 - INFO - ðŸªœ Batch step - 972 -- sub batch step 3889 -- lr 1.46e-04
2025-03-02 12:38:33,921 - INFO - ðŸªœ Batch step - 972 -- sub batch step 3890 -- lr 1.46e-04
2025-03-02 12:38:36,068 - INFO - ðŸªœ Batch step - 972 -- sub batch step 3891 -- lr 1.46e-04
2025-03-02 12:38:37,622 - INFO - Step 972 -- ðŸ”„ Training Metrics
2025-03-02 12:38:37,622 - INFO - â”œâ”€â”€ Loss: 7.9427
2025-03-02 12:38:37,622 - INFO - â”œâ”€â”€ Learning Rate: 1.46e-04
2025-03-02 12:38:37,622 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:38:38,294 - INFO - ðŸªœ Batch step - 973 -- sub batch step 3892 -- lr 1.46e-04
2025-03-02 12:38:40,440 - INFO - ðŸªœ Batch step - 973 -- sub batch step 3893 -- lr 1.46e-04
2025-03-02 12:38:43,160 - INFO - ðŸªœ Batch step - 973 -- sub batch step 3894 -- lr 1.46e-04
2025-03-02 12:38:45,313 - INFO - ðŸªœ Batch step - 973 -- sub batch step 3895 -- lr 1.46e-04
2025-03-02 12:38:46,831 - INFO - Step 973 -- ðŸ”„ Training Metrics
2025-03-02 12:38:46,831 - INFO - â”œâ”€â”€ Loss: 7.9698
2025-03-02 12:38:46,832 - INFO - â”œâ”€â”€ Learning Rate: 1.46e-04
2025-03-02 12:38:46,832 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:38:47,500 - INFO - ðŸªœ Batch step - 974 -- sub batch step 3896 -- lr 1.46e-04
2025-03-02 12:38:49,652 - INFO - ðŸªœ Batch step - 974 -- sub batch step 3897 -- lr 1.46e-04
2025-03-02 12:38:51,811 - INFO - ðŸªœ Batch step - 974 -- sub batch step 3898 -- lr 1.46e-04
2025-03-02 12:38:53,964 - INFO - ðŸªœ Batch step - 974 -- sub batch step 3899 -- lr 1.46e-04
2025-03-02 12:38:55,542 - INFO - Step 974 -- ðŸ”„ Training Metrics
2025-03-02 12:38:55,542 - INFO - â”œâ”€â”€ Loss: 7.9774
2025-03-02 12:38:55,542 - INFO - â”œâ”€â”€ Learning Rate: 1.46e-04
2025-03-02 12:38:55,542 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:38:56,212 - INFO - ðŸªœ Batch step - 975 -- sub batch step 3900 -- lr 1.46e-04
2025-03-02 12:38:58,357 - INFO - ðŸªœ Batch step - 975 -- sub batch step 3901 -- lr 1.46e-04
2025-03-02 12:39:01,010 - INFO - ðŸªœ Batch step - 975 -- sub batch step 3902 -- lr 1.46e-04
2025-03-02 12:39:03,153 - INFO - ðŸªœ Batch step - 975 -- sub batch step 3903 -- lr 1.46e-04
2025-03-02 12:39:04,706 - INFO - Step 975 -- ðŸ”„ Training Metrics
2025-03-02 12:39:04,706 - INFO - â”œâ”€â”€ Loss: 7.9783
2025-03-02 12:39:04,706 - INFO - â”œâ”€â”€ Learning Rate: 1.46e-04
2025-03-02 12:39:04,707 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:39:05,380 - INFO - ðŸªœ Batch step - 976 -- sub batch step 3904 -- lr 1.46e-04
2025-03-02 12:39:07,534 - INFO - ðŸªœ Batch step - 976 -- sub batch step 3905 -- lr 1.46e-04
2025-03-02 12:39:09,697 - INFO - ðŸªœ Batch step - 976 -- sub batch step 3906 -- lr 1.46e-04
2025-03-02 12:39:11,848 - INFO - ðŸªœ Batch step - 976 -- sub batch step 3907 -- lr 1.46e-04
2025-03-02 12:39:13,425 - INFO - Step 976 -- ðŸ”„ Training Metrics
2025-03-02 12:39:13,425 - INFO - â”œâ”€â”€ Loss: 7.9529
2025-03-02 12:39:13,425 - INFO - â”œâ”€â”€ Learning Rate: 1.46e-04
2025-03-02 12:39:13,425 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:39:14,092 - INFO - ðŸªœ Batch step - 977 -- sub batch step 3908 -- lr 1.47e-04
2025-03-02 12:39:16,245 - INFO - ðŸªœ Batch step - 977 -- sub batch step 3909 -- lr 1.47e-04
2025-03-02 12:39:18,701 - INFO - ðŸªœ Batch step - 977 -- sub batch step 3910 -- lr 1.47e-04
2025-03-02 12:39:20,852 - INFO - ðŸªœ Batch step - 977 -- sub batch step 3911 -- lr 1.47e-04
2025-03-02 12:39:22,550 - INFO - Step 977 -- ðŸ”„ Training Metrics
2025-03-02 12:39:22,551 - INFO - â”œâ”€â”€ Loss: 7.9758
2025-03-02 12:39:22,551 - INFO - â”œâ”€â”€ Learning Rate: 1.47e-04
2025-03-02 12:39:22,551 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:39:23,222 - INFO - ðŸªœ Batch step - 978 -- sub batch step 3912 -- lr 1.47e-04
2025-03-02 12:39:25,367 - INFO - ðŸªœ Batch step - 978 -- sub batch step 3913 -- lr 1.47e-04
2025-03-02 12:39:27,533 - INFO - ðŸªœ Batch step - 978 -- sub batch step 3914 -- lr 1.47e-04
2025-03-02 12:39:29,684 - INFO - ðŸªœ Batch step - 978 -- sub batch step 3915 -- lr 1.47e-04
2025-03-02 12:39:31,240 - INFO - Step 978 -- ðŸ”„ Training Metrics
2025-03-02 12:39:31,240 - INFO - â”œâ”€â”€ Loss: 7.9528
2025-03-02 12:39:31,240 - INFO - â”œâ”€â”€ Learning Rate: 1.47e-04
2025-03-02 12:39:31,240 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:39:31,907 - INFO - ðŸªœ Batch step - 979 -- sub batch step 3916 -- lr 1.47e-04
2025-03-02 12:39:34,059 - INFO - ðŸªœ Batch step - 979 -- sub batch step 3917 -- lr 1.47e-04
2025-03-02 12:39:36,333 - INFO - ðŸªœ Batch step - 979 -- sub batch step 3918 -- lr 1.47e-04
2025-03-02 12:39:38,483 - INFO - ðŸªœ Batch step - 979 -- sub batch step 3919 -- lr 1.47e-04
2025-03-02 12:39:40,033 - INFO - Step 979 -- ðŸ”„ Training Metrics
2025-03-02 12:39:40,033 - INFO - â”œâ”€â”€ Loss: 7.9734
2025-03-02 12:39:40,033 - INFO - â”œâ”€â”€ Learning Rate: 1.47e-04
2025-03-02 12:39:40,033 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:39:41,283 - INFO - ðŸªœ Batch step - 980 -- sub batch step 3920 -- lr 1.47e-04
2025-03-02 12:39:43,436 - INFO - ðŸªœ Batch step - 980 -- sub batch step 3921 -- lr 1.47e-04
2025-03-02 12:39:45,594 - INFO - ðŸªœ Batch step - 980 -- sub batch step 3922 -- lr 1.47e-04
2025-03-02 12:39:47,770 - INFO - ðŸªœ Batch step - 980 -- sub batch step 3923 -- lr 1.47e-04
2025-03-02 12:39:49,313 - INFO - Step 980 -- ðŸ”„ Training Metrics
2025-03-02 12:39:49,313 - INFO - â”œâ”€â”€ Loss: 7.9023
2025-03-02 12:39:49,314 - INFO - â”œâ”€â”€ Learning Rate: 1.47e-04
2025-03-02 12:39:49,314 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:39:49,987 - INFO - ðŸªœ Batch step - 981 -- sub batch step 3924 -- lr 1.47e-04
2025-03-02 12:39:52,140 - INFO - ðŸªœ Batch step - 981 -- sub batch step 3925 -- lr 1.47e-04
2025-03-02 12:39:54,289 - INFO - ðŸªœ Batch step - 981 -- sub batch step 3926 -- lr 1.47e-04
2025-03-02 12:39:56,812 - INFO - ðŸªœ Batch step - 981 -- sub batch step 3927 -- lr 1.47e-04
2025-03-02 12:39:58,403 - INFO - Step 981 -- ðŸ”„ Training Metrics
2025-03-02 12:39:58,404 - INFO - â”œâ”€â”€ Loss: 7.9363
2025-03-02 12:39:58,404 - INFO - â”œâ”€â”€ Learning Rate: 1.47e-04
2025-03-02 12:39:58,404 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:39:59,078 - INFO - ðŸªœ Batch step - 982 -- sub batch step 3928 -- lr 1.47e-04
2025-03-02 12:40:01,236 - INFO - ðŸªœ Batch step - 982 -- sub batch step 3929 -- lr 1.47e-04
2025-03-02 12:40:03,392 - INFO - ðŸªœ Batch step - 982 -- sub batch step 3930 -- lr 1.47e-04
2025-03-02 12:40:05,558 - INFO - ðŸªœ Batch step - 982 -- sub batch step 3931 -- lr 1.47e-04
2025-03-02 12:40:07,106 - INFO - Step 982 -- ðŸ”„ Training Metrics
2025-03-02 12:40:07,106 - INFO - â”œâ”€â”€ Loss: 7.9256
2025-03-02 12:40:07,106 - INFO - â”œâ”€â”€ Learning Rate: 1.47e-04
2025-03-02 12:40:07,106 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:40:07,782 - INFO - ðŸªœ Batch step - 983 -- sub batch step 3932 -- lr 1.47e-04
2025-03-02 12:40:09,929 - INFO - ðŸªœ Batch step - 983 -- sub batch step 3933 -- lr 1.47e-04
2025-03-02 12:40:12,079 - INFO - ðŸªœ Batch step - 983 -- sub batch step 3934 -- lr 1.47e-04
2025-03-02 12:40:14,903 - INFO - ðŸªœ Batch step - 983 -- sub batch step 3935 -- lr 1.47e-04
2025-03-02 12:40:16,393 - INFO - Step 983 -- ðŸ”„ Training Metrics
2025-03-02 12:40:16,393 - INFO - â”œâ”€â”€ Loss: 7.9379
2025-03-02 12:40:16,393 - INFO - â”œâ”€â”€ Learning Rate: 1.47e-04
2025-03-02 12:40:16,393 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:40:17,062 - INFO - ðŸªœ Batch step - 984 -- sub batch step 3936 -- lr 1.48e-04
2025-03-02 12:40:19,221 - INFO - ðŸªœ Batch step - 984 -- sub batch step 3937 -- lr 1.48e-04
2025-03-02 12:40:21,376 - INFO - ðŸªœ Batch step - 984 -- sub batch step 3938 -- lr 1.48e-04
2025-03-02 12:40:23,561 - INFO - ðŸªœ Batch step - 984 -- sub batch step 3939 -- lr 1.48e-04
2025-03-02 12:40:25,092 - INFO - Step 984 -- ðŸ”„ Training Metrics
2025-03-02 12:40:25,092 - INFO - â”œâ”€â”€ Loss: 7.9261
2025-03-02 12:40:25,092 - INFO - â”œâ”€â”€ Learning Rate: 1.48e-04
2025-03-02 12:40:25,092 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:40:25,771 - INFO - ðŸªœ Batch step - 985 -- sub batch step 3940 -- lr 1.48e-04
2025-03-02 12:40:27,921 - INFO - ðŸªœ Batch step - 985 -- sub batch step 3941 -- lr 1.48e-04
2025-03-02 12:40:30,075 - INFO - ðŸªœ Batch step - 985 -- sub batch step 3942 -- lr 1.48e-04
2025-03-02 12:40:32,748 - INFO - ðŸªœ Batch step - 985 -- sub batch step 3943 -- lr 1.48e-04
2025-03-02 12:40:34,466 - INFO - Step 985 -- ðŸ”„ Training Metrics
2025-03-02 12:40:34,466 - INFO - â”œâ”€â”€ Loss: 7.9312
2025-03-02 12:40:34,466 - INFO - â”œâ”€â”€ Learning Rate: 1.48e-04
2025-03-02 12:40:34,466 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:40:35,142 - INFO - ðŸªœ Batch step - 986 -- sub batch step 3944 -- lr 1.48e-04
2025-03-02 12:40:37,297 - INFO - ðŸªœ Batch step - 986 -- sub batch step 3945 -- lr 1.48e-04
2025-03-02 12:40:39,445 - INFO - ðŸªœ Batch step - 986 -- sub batch step 3946 -- lr 1.48e-04
2025-03-02 12:40:41,626 - INFO - ðŸªœ Batch step - 986 -- sub batch step 3947 -- lr 1.48e-04
2025-03-02 12:40:43,184 - INFO - Step 986 -- ðŸ”„ Training Metrics
2025-03-02 12:40:43,184 - INFO - â”œâ”€â”€ Loss: 7.9328
2025-03-02 12:40:43,184 - INFO - â”œâ”€â”€ Learning Rate: 1.48e-04
2025-03-02 12:40:43,184 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:40:43,851 - INFO - ðŸªœ Batch step - 987 -- sub batch step 3948 -- lr 1.48e-04
2025-03-02 12:40:46,012 - INFO - ðŸªœ Batch step - 987 -- sub batch step 3949 -- lr 1.48e-04
2025-03-02 12:40:48,169 - INFO - ðŸªœ Batch step - 987 -- sub batch step 3950 -- lr 1.48e-04
2025-03-02 12:40:50,760 - INFO - ðŸªœ Batch step - 987 -- sub batch step 3951 -- lr 1.48e-04
2025-03-02 12:40:52,280 - INFO - Step 987 -- ðŸ”„ Training Metrics
2025-03-02 12:40:52,280 - INFO - â”œâ”€â”€ Loss: 7.9376
2025-03-02 12:40:52,280 - INFO - â”œâ”€â”€ Learning Rate: 1.48e-04
2025-03-02 12:40:52,280 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:40:52,958 - INFO - ðŸªœ Batch step - 988 -- sub batch step 3952 -- lr 1.48e-04
2025-03-02 12:40:55,108 - INFO - ðŸªœ Batch step - 988 -- sub batch step 3953 -- lr 1.48e-04
2025-03-02 12:40:57,262 - INFO - ðŸªœ Batch step - 988 -- sub batch step 3954 -- lr 1.48e-04
2025-03-02 12:40:59,436 - INFO - ðŸªœ Batch step - 988 -- sub batch step 3955 -- lr 1.48e-04
2025-03-02 12:41:01,001 - INFO - Step 988 -- ðŸ”„ Training Metrics
2025-03-02 12:41:01,002 - INFO - â”œâ”€â”€ Loss: 7.9166
2025-03-02 12:41:01,002 - INFO - â”œâ”€â”€ Learning Rate: 1.48e-04
2025-03-02 12:41:01,002 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:41:01,676 - INFO - ðŸªœ Batch step - 989 -- sub batch step 3956 -- lr 1.48e-04
2025-03-02 12:41:03,834 - INFO - ðŸªœ Batch step - 989 -- sub batch step 3957 -- lr 1.48e-04
2025-03-02 12:41:05,984 - INFO - ðŸªœ Batch step - 989 -- sub batch step 3958 -- lr 1.48e-04
2025-03-02 12:41:08,832 - INFO - ðŸªœ Batch step - 989 -- sub batch step 3959 -- lr 1.48e-04
2025-03-02 12:41:10,319 - INFO - Step 989 -- ðŸ”„ Training Metrics
2025-03-02 12:41:10,319 - INFO - â”œâ”€â”€ Loss: 7.8919
2025-03-02 12:41:10,319 - INFO - â”œâ”€â”€ Learning Rate: 1.48e-04
2025-03-02 12:41:10,319 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:41:10,996 - INFO - ðŸªœ Batch step - 990 -- sub batch step 3960 -- lr 1.48e-04
2025-03-02 12:41:13,145 - INFO - ðŸªœ Batch step - 990 -- sub batch step 3961 -- lr 1.48e-04
2025-03-02 12:41:15,299 - INFO - ðŸªœ Batch step - 990 -- sub batch step 3962 -- lr 1.48e-04
2025-03-02 12:41:17,460 - INFO - ðŸªœ Batch step - 990 -- sub batch step 3963 -- lr 1.48e-04
2025-03-02 12:41:19,013 - INFO - Step 990 -- ðŸ”„ Training Metrics
2025-03-02 12:41:19,013 - INFO - â”œâ”€â”€ Loss: 7.9138
2025-03-02 12:41:19,013 - INFO - â”œâ”€â”€ Learning Rate: 1.48e-04
2025-03-02 12:41:19,014 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:41:19,689 - INFO - ðŸªœ Batch step - 991 -- sub batch step 3964 -- lr 1.49e-04
2025-03-02 12:41:21,848 - INFO - ðŸªœ Batch step - 991 -- sub batch step 3965 -- lr 1.49e-04
2025-03-02 12:41:24,336 - INFO - ðŸªœ Batch step - 991 -- sub batch step 3966 -- lr 1.49e-04
2025-03-02 12:41:26,495 - INFO - ðŸªœ Batch step - 991 -- sub batch step 3967 -- lr 1.49e-04
2025-03-02 12:41:28,139 - INFO - Step 991 -- ðŸ”„ Training Metrics
2025-03-02 12:41:28,139 - INFO - â”œâ”€â”€ Loss: 7.8775
2025-03-02 12:41:28,140 - INFO - â”œâ”€â”€ Learning Rate: 1.49e-04
2025-03-02 12:41:28,140 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:41:28,810 - INFO - ðŸªœ Batch step - 992 -- sub batch step 3968 -- lr 1.49e-04
2025-03-02 12:41:30,972 - INFO - ðŸªœ Batch step - 992 -- sub batch step 3969 -- lr 1.49e-04
2025-03-02 12:41:33,149 - INFO - ðŸªœ Batch step - 992 -- sub batch step 3970 -- lr 1.49e-04
2025-03-02 12:41:35,298 - INFO - ðŸªœ Batch step - 992 -- sub batch step 3971 -- lr 1.49e-04
2025-03-02 12:41:36,831 - INFO - Step 992 -- ðŸ”„ Training Metrics
2025-03-02 12:41:36,831 - INFO - â”œâ”€â”€ Loss: 7.8875
2025-03-02 12:41:36,831 - INFO - â”œâ”€â”€ Learning Rate: 1.49e-04
2025-03-02 12:41:36,831 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:41:37,508 - INFO - ðŸªœ Batch step - 993 -- sub batch step 3972 -- lr 1.49e-04
2025-03-02 12:41:39,657 - INFO - ðŸªœ Batch step - 993 -- sub batch step 3973 -- lr 1.49e-04
2025-03-02 12:41:42,282 - INFO - ðŸªœ Batch step - 993 -- sub batch step 3974 -- lr 1.49e-04
2025-03-02 12:41:44,444 - INFO - ðŸªœ Batch step - 993 -- sub batch step 3975 -- lr 1.49e-04
2025-03-02 12:41:46,155 - INFO - Step 993 -- ðŸ”„ Training Metrics
2025-03-02 12:41:46,155 - INFO - â”œâ”€â”€ Loss: 7.8849
2025-03-02 12:41:46,155 - INFO - â”œâ”€â”€ Learning Rate: 1.49e-04
2025-03-02 12:41:46,155 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:41:46,829 - INFO - ðŸªœ Batch step - 994 -- sub batch step 3976 -- lr 1.49e-04
2025-03-02 12:41:48,984 - INFO - ðŸªœ Batch step - 994 -- sub batch step 3977 -- lr 1.49e-04
2025-03-02 12:41:51,151 - INFO - ðŸªœ Batch step - 994 -- sub batch step 3978 -- lr 1.49e-04
2025-03-02 12:41:53,309 - INFO - ðŸªœ Batch step - 994 -- sub batch step 3979 -- lr 1.49e-04
2025-03-02 12:41:54,871 - INFO - Step 994 -- ðŸ”„ Training Metrics
2025-03-02 12:41:54,871 - INFO - â”œâ”€â”€ Loss: 7.8958
2025-03-02 12:41:54,871 - INFO - â”œâ”€â”€ Learning Rate: 1.49e-04
2025-03-02 12:41:54,872 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:41:55,551 - INFO - ðŸªœ Batch step - 995 -- sub batch step 3980 -- lr 1.49e-04
2025-03-02 12:41:57,701 - INFO - ðŸªœ Batch step - 995 -- sub batch step 3981 -- lr 1.49e-04
2025-03-02 12:42:00,509 - INFO - ðŸªœ Batch step - 995 -- sub batch step 3982 -- lr 1.49e-04
2025-03-02 12:42:02,667 - INFO - ðŸªœ Batch step - 995 -- sub batch step 3983 -- lr 1.49e-04
2025-03-02 12:42:04,159 - INFO - Step 995 -- ðŸ”„ Training Metrics
2025-03-02 12:42:04,159 - INFO - â”œâ”€â”€ Loss: 7.8700
2025-03-02 12:42:04,159 - INFO - â”œâ”€â”€ Learning Rate: 1.49e-04
2025-03-02 12:42:04,159 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:42:04,841 - INFO - ðŸªœ Batch step - 996 -- sub batch step 3984 -- lr 1.49e-04
2025-03-02 12:42:07,001 - INFO - ðŸªœ Batch step - 996 -- sub batch step 3985 -- lr 1.49e-04
2025-03-02 12:42:09,170 - INFO - ðŸªœ Batch step - 996 -- sub batch step 3986 -- lr 1.49e-04
2025-03-02 12:42:11,326 - INFO - ðŸªœ Batch step - 996 -- sub batch step 3987 -- lr 1.49e-04
2025-03-02 12:42:12,875 - INFO - Step 996 -- ðŸ”„ Training Metrics
2025-03-02 12:42:12,876 - INFO - â”œâ”€â”€ Loss: 7.8864
2025-03-02 12:42:12,876 - INFO - â”œâ”€â”€ Learning Rate: 1.49e-04
2025-03-02 12:42:12,876 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:42:13,543 - INFO - ðŸªœ Batch step - 997 -- sub batch step 3988 -- lr 1.50e-04
2025-03-02 12:42:15,700 - INFO - ðŸªœ Batch step - 997 -- sub batch step 3989 -- lr 1.50e-04
2025-03-02 12:42:18,060 - INFO - ðŸªœ Batch step - 997 -- sub batch step 3990 -- lr 1.50e-04
2025-03-02 12:42:20,214 - INFO - ðŸªœ Batch step - 997 -- sub batch step 3991 -- lr 1.50e-04
2025-03-02 12:42:22,053 - INFO - Step 997 -- ðŸ”„ Training Metrics
2025-03-02 12:42:22,053 - INFO - â”œâ”€â”€ Loss: 7.8880
2025-03-02 12:42:22,053 - INFO - â”œâ”€â”€ Learning Rate: 1.50e-04
2025-03-02 12:42:22,053 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:42:22,731 - INFO - ðŸªœ Batch step - 998 -- sub batch step 3992 -- lr 1.50e-04
2025-03-02 12:42:24,882 - INFO - ðŸªœ Batch step - 998 -- sub batch step 3993 -- lr 1.50e-04
2025-03-02 12:42:27,057 - INFO - ðŸªœ Batch step - 998 -- sub batch step 3994 -- lr 1.50e-04
2025-03-02 12:42:29,213 - INFO - ðŸªœ Batch step - 998 -- sub batch step 3995 -- lr 1.50e-04
2025-03-02 12:42:30,768 - INFO - Step 998 -- ðŸ”„ Training Metrics
2025-03-02 12:42:30,768 - INFO - â”œâ”€â”€ Loss: 7.8697
2025-03-02 12:42:30,768 - INFO - â”œâ”€â”€ Learning Rate: 1.50e-04
2025-03-02 12:42:30,769 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:42:31,442 - INFO - ðŸªœ Batch step - 999 -- sub batch step 3996 -- lr 1.50e-04
2025-03-02 12:42:33,598 - INFO - ðŸªœ Batch step - 999 -- sub batch step 3997 -- lr 1.50e-04
2025-03-02 12:42:35,883 - INFO - ðŸªœ Batch step - 999 -- sub batch step 3998 -- lr 1.50e-04
2025-03-02 12:42:38,041 - INFO - ðŸªœ Batch step - 999 -- sub batch step 3999 -- lr 1.50e-04
2025-03-02 12:42:39,648 - INFO - Step 999 -- ðŸ”„ Training Metrics
2025-03-02 12:42:39,648 - INFO - â”œâ”€â”€ Loss: 7.9041
2025-03-02 12:42:39,648 - INFO - â”œâ”€â”€ Learning Rate: 1.50e-04
2025-03-02 12:42:39,649 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:42:39,654 - INFO - Step 1000 -- ðŸ’¾ Saving Checkpoint
model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]model.safetensors:   3%|â–Ž         | 1.61M/46.8M [00:00<00:03, 13.9MB/s]model.safetensors:   6%|â–‹         | 3.00M/46.8M [00:00<00:04, 10.4MB/s]model.safetensors:  20%|â–ˆâ–ˆ        | 9.57M/46.8M [00:00<00:01, 27.0MB/s]model.safetensors:  26%|â–ˆâ–ˆâ–‹       | 12.3M/46.8M [00:00<00:01, 18.4MB/s]model.safetensors:  32%|â–ˆâ–ˆâ–ˆâ–      | 15.0M/46.8M [00:00<00:01, 19.9MB/s]model.safetensors:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17.2M/46.8M [00:01<00:02, 12.4MB/s]model.safetensors:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23.6M/46.8M [00:01<00:01, 20.2MB/s]model.safetensors:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26.6M/46.8M [00:01<00:01, 12.9MB/s]model.safetensors:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30.0M/46.8M [00:01<00:01, 14.6MB/s]model.safetensors:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32.1M/46.8M [00:02<00:01, 11.2MB/s]model.safetensors:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38.5M/46.8M [00:02<00:00, 17.9MB/s]model.safetensors:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41.5M/46.8M [00:02<00:00, 19.4MB/s]model.safetensors:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44.2M/46.8M [00:02<00:00, 13.6MB/s]model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46.8M/46.8M [00:03<00:00, 14.0MB/s]
No files have been modified since last commit. Skipping to prevent empty commit.
bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s]
bf16_zero_pp_rank_10_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][A

bf16_zero_pp_rank_11_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][A[A


Upload 17 LFS files:   0%|          | 0/17 [00:00<?, ?it/s][A[A[A



bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][A[A[A[A




bf16_zero_pp_rank_13_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][A[A[A[A[Abf16_zero_pp_rank_0_mp_rank_00_optim_states.pt:  28%|â–ˆâ–ˆâ–Š       | 2.10M/7.55M [00:00<00:00, 18.1MB/s]

bf16_zero_pp_rank_11_mp_rank_00_optim_states.pt:  19%|â–ˆâ–‰        | 1.43M/7.55M [00:00<00:00, 11.8MB/s][A[A
bf16_zero_pp_rank_10_mp_rank_00_optim_states.pt:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 3.00M/7.55M [00:00<00:00, 22.2MB/s][A




bf16_zero_pp_rank_13_mp_rank_00_optim_states.pt:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 3.03M/7.55M [00:00<00:00, 23.9MB/s][A[A[A[A[A



bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 3.10M/7.55M [00:00<00:00, 23.9MB/s][A[A[A[A

bf16_zero_pp_rank_11_mp_rank_00_optim_states.pt:  35%|â–ˆâ–ˆâ–ˆâ–      | 2.62M/7.55M [00:00<00:00, 9.71MB/s][A[A
bf16_zero_pp_rank_10_mp_rank_00_optim_states.pt:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 5.31M/7.55M [00:00<00:00, 17.0MB/s][Abf16_zero_pp_rank_0_mp_rank_00_optim_states.pt:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3.92M/7.55M [00:00<00:00, 12.1MB/s]



bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5.60M/7.55M [00:00<00:00, 13.2MB/s][A[A[A[Abf16_zero_pp_rank_0_mp_rank_00_optim_states.pt:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 5.37M/7.55M [00:00<00:00, 12.9MB/s]




bf16_zero_pp_rank_13_mp_rank_00_optim_states.pt:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5.42M/7.55M [00:00<00:00, 12.4MB/s][A[A[A[A[A
bf16_zero_pp_rank_10_mp_rank_00_optim_states.pt:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 7.36M/7.55M [00:00<00:00, 16.7MB/s][Abf16_zero_pp_rank_10_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:00<00:00, 9.92MB/s]
bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:00<00:00, 9.32MB/s]
bf16_zero_pp_rank_13_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:00<00:00, 9.20MB/s]
bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:00<00:00, 8.21MB/s]
bf16_zero_pp_rank_14_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s]


Upload 17 LFS files:   6%|â–Œ         | 1/17 [00:00<00:15,  1.00it/s][A[A[A
bf16_zero_pp_rank_15_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][Abf16_zero_pp_rank_11_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:01<00:00, 7.16MB/s]


bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][A[Abf16_zero_pp_rank_14_mp_rank_00_optim_states.pt:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4.26M/7.55M [00:00<00:00, 31.1MB/s]
bf16_zero_pp_rank_15_mp_rank_00_optim_states.pt:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 3.51M/7.55M [00:00<00:00, 25.4MB/s][A



bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][A[A[A[A

bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5.44M/7.55M [00:00<00:00, 33.5MB/s][A[Abf16_zero_pp_rank_14_mp_rank_00_optim_states.pt:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 7.37M/7.55M [00:00<00:00, 24.4MB/s]



bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 7.27M/7.55M [00:00<00:00, 72.6MB/s][A[A[A[A
bf16_zero_pp_rank_15_mp_rank_00_optim_states.pt:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 6.06M/7.55M [00:00<00:00, 18.7MB/s][A


Upload 17 LFS files:  18%|â–ˆâ–Š        | 3/17 [00:01<00:05,  2.34it/s][A[A[A




bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][A[A[A[A[Abf16_zero_pp_rank_2_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:00<00:00, 22.1MB/s]
bf16_zero_pp_rank_14_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:00<00:00, 10.4MB/s]
bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s]bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:00<00:00, 28.6MB/s]
bf16_zero_pp_rank_15_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:00<00:00, 9.92MB/s]
bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:00<00:00, 9.69MB/s]



Upload 17 LFS files:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [00:01<00:02,  3.98it/s][A[A[A
bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][Abf16_zero_pp_rank_4_mp_rank_00_optim_states.pt:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5.65M/7.55M [00:00<00:00, 30.6MB/s]

bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][A[A



bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.56M [00:00<?, ?B/s][A[A[A[A

bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4.10M/7.55M [00:00<00:00, 34.8MB/s][A[A



bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4.15M/7.56M [00:00<00:00, 30.7MB/s][A[A[A[A
bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 5.37M/7.55M [00:00<00:00, 27.8MB/s][A


Upload 17 LFS files:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8/17 [00:02<00:01,  4.84it/s][A[A[A




bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.56M [00:00<?, ?B/s][A[A[A[A[A




bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4.06M/7.56M [00:00<00:00, 35.1MB/s][A[A[A[A[A



bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 7.23M/7.56M [00:00<00:00, 21.3MB/s][A[A[A[Abf16_zero_pp_rank_4_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:00<00:00, 9.65MB/s]
bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:00<00:00, 10.8MB/s]



Upload 17 LFS files:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:02<00:01,  5.17it/s][A[A[Abf16_zero_pp_rank_9_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s]bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.56M/7.56M [00:00<00:00, 10.1MB/s]



Upload 17 LFS files:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:02<00:00,  5.54it/s][A[A[A
mp_rank_00_model_states.pt:   0%|          | 0.00/26.7M [00:00<?, ?B/s][Abf16_zero_pp_rank_9_mp_rank_00_optim_states.pt:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4.13M/7.55M [00:00<00:00, 31.2MB/s]bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.56M/7.56M [00:00<00:00, 10.2MB/s]
bf16_zero_pp_rank_9_mp_rank_00_optim_states.pt:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 7.26M/7.55M [00:00<00:00, 28.7MB/s]bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:01<00:00, 7.28MB/s]

mp_rank_00_model_states.pt:  21%|â–ˆâ–ˆ        | 5.59M/26.7M [00:00<00:00, 30.4MB/s][A
mp_rank_00_model_states.pt:  32%|â–ˆâ–ˆâ–ˆâ–      | 8.63M/26.7M [00:00<00:00, 30.3MB/s][A


Upload 17 LFS files:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 13/17 [00:03<00:00,  4.76it/s][A[A[A
mp_rank_00_model_states.pt:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12.0M/26.7M [00:00<00:00, 29.4MB/s][Abf16_zero_pp_rank_9_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:00<00:00, 9.68MB/s]

mp_rank_00_model_states.pt:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16.0M/26.7M [00:00<00:00, 15.3MB/s][A


Upload 17 LFS files:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [00:03<00:00,  5.11it/s][A[A[A
mp_rank_00_model_states.pt:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22.4M/26.7M [00:00<00:00, 22.7MB/s][A
mp_rank_00_model_states.pt:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 25.5M/26.7M [00:01<00:00, 23.8MB/s][Amp_rank_00_model_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26.7M/26.7M [00:01<00:00, 16.5MB/s]



Upload 17 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  2.99it/s][A[A[AUpload 17 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.68it/s]
2025-03-02 12:44:06,021 - INFO - Step 1000 -- ðŸ“Š Evaluation Results
2025-03-02 12:44:06,022 - INFO - â””â”€â”€ paloma: 3707.631759930654
2025-03-02 12:44:07,978 - INFO - ðŸªœ Batch step - 1000 -- sub batch step 4000 -- lr 1.50e-04
2025-03-02 12:44:10,147 - INFO - ðŸªœ Batch step - 1000 -- sub batch step 4001 -- lr 1.50e-04
2025-03-02 12:44:12,338 - INFO - ðŸªœ Batch step - 1000 -- sub batch step 4002 -- lr 1.50e-04
2025-03-02 12:44:14,544 - INFO - ðŸªœ Batch step - 1000 -- sub batch step 4003 -- lr 1.50e-04
2025-03-02 12:44:16,071 - INFO - Step 1000 -- ðŸ”„ Training Metrics
2025-03-02 12:44:16,071 - INFO - â”œâ”€â”€ Loss: 7.8586
2025-03-02 12:44:16,072 - INFO - â”œâ”€â”€ Learning Rate: 1.50e-04
2025-03-02 12:44:16,072 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:44:16,072 - INFO - Step 1000 -- ðŸ“ˆ Saving Learning Dynamics
[2025-03-02 12:44:17,118] [WARNING] [engine.py:1244:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****
Saving the dataset (0/1 shards):   0%|          | 0/1024 [00:00<?, ? examples/s]Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:00<00:00, 23799.45 examples/s]Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:00<00:00, 23606.63 examples/s]
Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]
data-00000-of-00001.arrow:   0%|          | 0.00/17.4M [00:00<?, ?B/s][A

train_activations.pt:   0%|          | 0.00/12.2M [00:00<?, ?B/s][A[A
data-00000-of-00001.arrow:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5.69M/17.4M [00:00<00:00, 54.3MB/s][A

train_activations.pt:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 7.23M/12.2M [00:00<00:00, 63.5MB/s][A[A
data-00000-of-00001.arrow:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 12.6M/17.4M [00:00<00:00, 61.8MB/s][Atrain_activations.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12.2M/12.2M [00:00<00:00, 31.2MB/s]
Upload 2 LFS files:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.70it/s]data-00000-of-00001.arrow: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17.4M/17.4M [00:00<00:00, 20.3MB/s]
Upload 2 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.90it/s]Upload 2 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.87it/s]
[2025-03-02 12:44:34,605] [WARNING] [engine.py:1244:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****
val_activations.pt:   0%|          | 0.00/17.2M [00:00<?, ?B/s]val_activations.pt:  24%|â–ˆâ–ˆâ–       | 4.15M/17.2M [00:00<00:00, 18.4MB/s]val_activations.pt:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 9.09M/17.2M [00:00<00:00, 27.0MB/s]val_activations.pt:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12.0M/17.2M [00:00<00:00, 19.6MB/s]val_activations.pt:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 14.2M/17.2M [00:00<00:00, 17.8MB/s]val_activations.pt:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16.1M/17.2M [00:01<00:00, 11.2MB/s]val_activations.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17.2M/17.2M [00:01<00:00, 13.7MB/s]
2025-03-02 12:44:43,522 - INFO - ðŸªœ Batch step - 1001 -- sub batch step 4004 -- lr 1.50e-04
2025-03-02 12:44:45,686 - INFO - ðŸªœ Batch step - 1001 -- sub batch step 4005 -- lr 1.50e-04
2025-03-02 12:44:47,842 - INFO - ðŸªœ Batch step - 1001 -- sub batch step 4006 -- lr 1.50e-04
2025-03-02 12:44:50,646 - INFO - ðŸªœ Batch step - 1001 -- sub batch step 4007 -- lr 1.50e-04
2025-03-02 12:44:52,135 - INFO - Step 1001 -- ðŸ”„ Training Metrics
2025-03-02 12:44:52,136 - INFO - â”œâ”€â”€ Loss: 7.8767
2025-03-02 12:44:52,136 - INFO - â”œâ”€â”€ Learning Rate: 1.50e-04
2025-03-02 12:44:52,136 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:44:52,806 - INFO - ðŸªœ Batch step - 1002 -- sub batch step 4008 -- lr 1.50e-04
2025-03-02 12:44:54,966 - INFO - ðŸªœ Batch step - 1002 -- sub batch step 4009 -- lr 1.50e-04
2025-03-02 12:44:57,130 - INFO - ðŸªœ Batch step - 1002 -- sub batch step 4010 -- lr 1.50e-04
2025-03-02 12:44:59,299 - INFO - ðŸªœ Batch step - 1002 -- sub batch step 4011 -- lr 1.50e-04
2025-03-02 12:45:00,833 - INFO - Step 1002 -- ðŸ”„ Training Metrics
2025-03-02 12:45:00,833 - INFO - â”œâ”€â”€ Loss: 7.8634
2025-03-02 12:45:00,833 - INFO - â”œâ”€â”€ Learning Rate: 1.50e-04
2025-03-02 12:45:00,833 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:45:01,506 - INFO - ðŸªœ Batch step - 1003 -- sub batch step 4012 -- lr 1.50e-04
2025-03-02 12:45:03,652 - INFO - ðŸªœ Batch step - 1003 -- sub batch step 4013 -- lr 1.50e-04
2025-03-02 12:45:05,810 - INFO - ðŸªœ Batch step - 1003 -- sub batch step 4014 -- lr 1.50e-04
2025-03-02 12:45:08,459 - INFO - ðŸªœ Batch step - 1003 -- sub batch step 4015 -- lr 1.50e-04
2025-03-02 12:45:10,094 - INFO - Step 1003 -- ðŸ”„ Training Metrics
2025-03-02 12:45:10,095 - INFO - â”œâ”€â”€ Loss: 7.8459
2025-03-02 12:45:10,095 - INFO - â”œâ”€â”€ Learning Rate: 1.50e-04
2025-03-02 12:45:10,095 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:45:10,759 - INFO - ðŸªœ Batch step - 1004 -- sub batch step 4016 -- lr 1.51e-04
2025-03-02 12:45:12,911 - INFO - ðŸªœ Batch step - 1004 -- sub batch step 4017 -- lr 1.51e-04
2025-03-02 12:45:15,060 - INFO - ðŸªœ Batch step - 1004 -- sub batch step 4018 -- lr 1.51e-04
2025-03-02 12:45:17,234 - INFO - ðŸªœ Batch step - 1004 -- sub batch step 4019 -- lr 1.51e-04
2025-03-02 12:45:18,778 - INFO - Step 1004 -- ðŸ”„ Training Metrics
2025-03-02 12:45:18,778 - INFO - â”œâ”€â”€ Loss: 7.8843
2025-03-02 12:45:18,778 - INFO - â”œâ”€â”€ Learning Rate: 1.51e-04
2025-03-02 12:45:18,778 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:45:19,450 - INFO - ðŸªœ Batch step - 1005 -- sub batch step 4020 -- lr 1.51e-04
2025-03-02 12:45:21,602 - INFO - ðŸªœ Batch step - 1005 -- sub batch step 4021 -- lr 1.51e-04
2025-03-02 12:45:23,756 - INFO - ðŸªœ Batch step - 1005 -- sub batch step 4022 -- lr 1.51e-04
2025-03-02 12:45:26,331 - INFO - ðŸªœ Batch step - 1005 -- sub batch step 4023 -- lr 1.51e-04
2025-03-02 12:45:28,077 - INFO - Step 1005 -- ðŸ”„ Training Metrics
2025-03-02 12:45:28,077 - INFO - â”œâ”€â”€ Loss: 7.8233
2025-03-02 12:45:28,077 - INFO - â”œâ”€â”€ Learning Rate: 1.51e-04
2025-03-02 12:45:28,077 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:45:28,750 - INFO - ðŸªœ Batch step - 1006 -- sub batch step 4024 -- lr 1.51e-04
2025-03-02 12:45:30,903 - INFO - ðŸªœ Batch step - 1006 -- sub batch step 4025 -- lr 1.51e-04
2025-03-02 12:45:33,049 - INFO - ðŸªœ Batch step - 1006 -- sub batch step 4026 -- lr 1.51e-04
2025-03-02 12:45:35,218 - INFO - ðŸªœ Batch step - 1006 -- sub batch step 4027 -- lr 1.51e-04
2025-03-02 12:45:36,773 - INFO - Step 1006 -- ðŸ”„ Training Metrics
2025-03-02 12:45:36,773 - INFO - â”œâ”€â”€ Loss: 7.8505
2025-03-02 12:45:36,773 - INFO - â”œâ”€â”€ Learning Rate: 1.51e-04
2025-03-02 12:45:36,773 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:45:37,437 - INFO - ðŸªœ Batch step - 1007 -- sub batch step 4028 -- lr 1.51e-04
2025-03-02 12:45:39,595 - INFO - ðŸªœ Batch step - 1007 -- sub batch step 4029 -- lr 1.51e-04
2025-03-02 12:45:41,751 - INFO - ðŸªœ Batch step - 1007 -- sub batch step 4030 -- lr 1.51e-04
2025-03-02 12:45:44,155 - INFO - ðŸªœ Batch step - 1007 -- sub batch step 4031 -- lr 1.51e-04
2025-03-02 12:45:46,044 - INFO - Step 1007 -- ðŸ”„ Training Metrics
2025-03-02 12:45:46,045 - INFO - â”œâ”€â”€ Loss: 7.8294
2025-03-02 12:45:46,045 - INFO - â”œâ”€â”€ Learning Rate: 1.51e-04
2025-03-02 12:45:46,045 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:45:46,720 - INFO - ðŸªœ Batch step - 1008 -- sub batch step 4032 -- lr 1.51e-04
2025-03-02 12:45:48,869 - INFO - ðŸªœ Batch step - 1008 -- sub batch step 4033 -- lr 1.51e-04
2025-03-02 12:45:51,025 - INFO - ðŸªœ Batch step - 1008 -- sub batch step 4034 -- lr 1.51e-04
2025-03-02 12:45:53,196 - INFO - ðŸªœ Batch step - 1008 -- sub batch step 4035 -- lr 1.51e-04
2025-03-02 12:45:54,750 - INFO - Step 1008 -- ðŸ”„ Training Metrics
2025-03-02 12:45:54,751 - INFO - â”œâ”€â”€ Loss: 7.8449
2025-03-02 12:45:54,751 - INFO - â”œâ”€â”€ Learning Rate: 1.51e-04
2025-03-02 12:45:54,751 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:45:55,417 - INFO - ðŸªœ Batch step - 1009 -- sub batch step 4036 -- lr 1.51e-04
2025-03-02 12:45:57,572 - INFO - ðŸªœ Batch step - 1009 -- sub batch step 4037 -- lr 1.51e-04
2025-03-02 12:45:59,721 - INFO - ðŸªœ Batch step - 1009 -- sub batch step 4038 -- lr 1.51e-04
2025-03-02 12:46:02,347 - INFO - ðŸªœ Batch step - 1009 -- sub batch step 4039 -- lr 1.51e-04
2025-03-02 12:46:03,984 - INFO - Step 1009 -- ðŸ”„ Training Metrics
2025-03-02 12:46:03,984 - INFO - â”œâ”€â”€ Loss: 7.8790
2025-03-02 12:46:03,984 - INFO - â”œâ”€â”€ Learning Rate: 1.51e-04
2025-03-02 12:46:03,984 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:46:04,656 - INFO - ðŸªœ Batch step - 1010 -- sub batch step 4040 -- lr 1.51e-04
2025-03-02 12:46:06,804 - INFO - ðŸªœ Batch step - 1010 -- sub batch step 4041 -- lr 1.51e-04
2025-03-02 12:46:08,956 - INFO - ðŸªœ Batch step - 1010 -- sub batch step 4042 -- lr 1.51e-04
2025-03-02 12:46:11,119 - INFO - ðŸªœ Batch step - 1010 -- sub batch step 4043 -- lr 1.51e-04
2025-03-02 12:46:12,667 - INFO - Step 1010 -- ðŸ”„ Training Metrics
2025-03-02 12:46:12,667 - INFO - â”œâ”€â”€ Loss: 7.8407
2025-03-02 12:46:12,668 - INFO - â”œâ”€â”€ Learning Rate: 1.51e-04
2025-03-02 12:46:12,668 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:46:13,336 - INFO - ðŸªœ Batch step - 1011 -- sub batch step 4044 -- lr 1.52e-04
2025-03-02 12:46:15,491 - INFO - ðŸªœ Batch step - 1011 -- sub batch step 4045 -- lr 1.52e-04
2025-03-02 12:46:18,166 - INFO - ðŸªœ Batch step - 1011 -- sub batch step 4046 -- lr 1.52e-04
2025-03-02 12:46:20,325 - INFO - ðŸªœ Batch step - 1011 -- sub batch step 4047 -- lr 1.52e-04
2025-03-02 12:46:21,925 - INFO - Step 1011 -- ðŸ”„ Training Metrics
2025-03-02 12:46:21,925 - INFO - â”œâ”€â”€ Loss: 7.8330
2025-03-02 12:46:21,925 - INFO - â”œâ”€â”€ Learning Rate: 1.52e-04
2025-03-02 12:46:21,925 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:46:22,588 - INFO - ðŸªœ Batch step - 1012 -- sub batch step 4048 -- lr 1.52e-04
2025-03-02 12:46:24,746 - INFO - ðŸªœ Batch step - 1012 -- sub batch step 4049 -- lr 1.52e-04
2025-03-02 12:46:26,922 - INFO - ðŸªœ Batch step - 1012 -- sub batch step 4050 -- lr 1.52e-04
2025-03-02 12:46:29,067 - INFO - ðŸªœ Batch step - 1012 -- sub batch step 4051 -- lr 1.52e-04
2025-03-02 12:46:30,627 - INFO - Step 1012 -- ðŸ”„ Training Metrics
2025-03-02 12:46:30,627 - INFO - â”œâ”€â”€ Loss: 7.8491
2025-03-02 12:46:30,627 - INFO - â”œâ”€â”€ Learning Rate: 1.52e-04
2025-03-02 12:46:30,628 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:46:31,300 - INFO - ðŸªœ Batch step - 1013 -- sub batch step 4052 -- lr 1.52e-04
2025-03-02 12:46:33,449 - INFO - ðŸªœ Batch step - 1013 -- sub batch step 4053 -- lr 1.52e-04
2025-03-02 12:46:36,262 - INFO - ðŸªœ Batch step - 1013 -- sub batch step 4054 -- lr 1.52e-04
2025-03-02 12:46:38,419 - INFO - ðŸªœ Batch step - 1013 -- sub batch step 4055 -- lr 1.52e-04
2025-03-02 12:46:39,909 - INFO - Step 1013 -- ðŸ”„ Training Metrics
2025-03-02 12:46:39,909 - INFO - â”œâ”€â”€ Loss: 7.8257
2025-03-02 12:46:39,910 - INFO - â”œâ”€â”€ Learning Rate: 1.52e-04
2025-03-02 12:46:39,910 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:46:40,573 - INFO - ðŸªœ Batch step - 1014 -- sub batch step 4056 -- lr 1.52e-04
2025-03-02 12:46:42,729 - INFO - ðŸªœ Batch step - 1014 -- sub batch step 4057 -- lr 1.52e-04
2025-03-02 12:46:44,894 - INFO - ðŸªœ Batch step - 1014 -- sub batch step 4058 -- lr 1.52e-04
2025-03-02 12:46:47,051 - INFO - ðŸªœ Batch step - 1014 -- sub batch step 4059 -- lr 1.52e-04
2025-03-02 12:46:48,618 - INFO - Step 1014 -- ðŸ”„ Training Metrics
2025-03-02 12:46:48,619 - INFO - â”œâ”€â”€ Loss: 7.8334
2025-03-02 12:46:48,619 - INFO - â”œâ”€â”€ Learning Rate: 1.52e-04
2025-03-02 12:46:48,619 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:46:49,292 - INFO - ðŸªœ Batch step - 1015 -- sub batch step 4060 -- lr 1.52e-04
2025-03-02 12:46:51,442 - INFO - ðŸªœ Batch step - 1015 -- sub batch step 4061 -- lr 1.52e-04
2025-03-02 12:46:54,031 - INFO - ðŸªœ Batch step - 1015 -- sub batch step 4062 -- lr 1.52e-04
2025-03-02 12:46:56,182 - INFO - ðŸªœ Batch step - 1015 -- sub batch step 4063 -- lr 1.52e-04
2025-03-02 12:46:57,816 - INFO - Step 1015 -- ðŸ”„ Training Metrics
2025-03-02 12:46:57,816 - INFO - â”œâ”€â”€ Loss: 7.8197
2025-03-02 12:46:57,816 - INFO - â”œâ”€â”€ Learning Rate: 1.52e-04
2025-03-02 12:46:57,816 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:46:58,492 - INFO - ðŸªœ Batch step - 1016 -- sub batch step 4064 -- lr 1.52e-04
2025-03-02 12:47:00,644 - INFO - ðŸªœ Batch step - 1016 -- sub batch step 4065 -- lr 1.52e-04
2025-03-02 12:47:02,808 - INFO - ðŸªœ Batch step - 1016 -- sub batch step 4066 -- lr 1.52e-04
2025-03-02 12:47:04,960 - INFO - ðŸªœ Batch step - 1016 -- sub batch step 4067 -- lr 1.52e-04
2025-03-02 12:47:06,518 - INFO - Step 1016 -- ðŸ”„ Training Metrics
2025-03-02 12:47:06,518 - INFO - â”œâ”€â”€ Loss: 7.7998
2025-03-02 12:47:06,519 - INFO - â”œâ”€â”€ Learning Rate: 1.52e-04
2025-03-02 12:47:06,519 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:47:07,184 - INFO - ðŸªœ Batch step - 1017 -- sub batch step 4068 -- lr 1.53e-04
2025-03-02 12:47:09,343 - INFO - ðŸªœ Batch step - 1017 -- sub batch step 4069 -- lr 1.53e-04
2025-03-02 12:47:12,034 - INFO - ðŸªœ Batch step - 1017 -- sub batch step 4070 -- lr 1.53e-04
2025-03-02 12:47:14,179 - INFO - ðŸªœ Batch step - 1017 -- sub batch step 4071 -- lr 1.53e-04
2025-03-02 12:47:15,819 - INFO - Step 1017 -- ðŸ”„ Training Metrics
2025-03-02 12:47:15,819 - INFO - â”œâ”€â”€ Loss: 7.8150
2025-03-02 12:47:15,820 - INFO - â”œâ”€â”€ Learning Rate: 1.53e-04
2025-03-02 12:47:15,820 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:47:16,490 - INFO - ðŸªœ Batch step - 1018 -- sub batch step 4072 -- lr 1.53e-04
2025-03-02 12:47:18,637 - INFO - ðŸªœ Batch step - 1018 -- sub batch step 4073 -- lr 1.53e-04
2025-03-02 12:47:20,811 - INFO - ðŸªœ Batch step - 1018 -- sub batch step 4074 -- lr 1.53e-04
2025-03-02 12:47:22,966 - INFO - ðŸªœ Batch step - 1018 -- sub batch step 4075 -- lr 1.53e-04
2025-03-02 12:47:24,519 - INFO - Step 1018 -- ðŸ”„ Training Metrics
2025-03-02 12:47:24,519 - INFO - â”œâ”€â”€ Loss: 7.8276
2025-03-02 12:47:24,519 - INFO - â”œâ”€â”€ Learning Rate: 1.53e-04
2025-03-02 12:47:24,519 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:47:25,182 - INFO - ðŸªœ Batch step - 1019 -- sub batch step 4076 -- lr 1.53e-04
2025-03-02 12:47:27,335 - INFO - ðŸªœ Batch step - 1019 -- sub batch step 4077 -- lr 1.53e-04
2025-03-02 12:47:29,723 - INFO - ðŸªœ Batch step - 1019 -- sub batch step 4078 -- lr 1.53e-04
2025-03-02 12:47:31,885 - INFO - ðŸªœ Batch step - 1019 -- sub batch step 4079 -- lr 1.53e-04
2025-03-02 12:47:33,394 - INFO - Step 1019 -- ðŸ”„ Training Metrics
2025-03-02 12:47:33,395 - INFO - â”œâ”€â”€ Loss: 7.8096
2025-03-02 12:47:33,395 - INFO - â”œâ”€â”€ Learning Rate: 1.53e-04
2025-03-02 12:47:33,395 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:47:34,577 - INFO - ðŸªœ Batch step - 1020 -- sub batch step 4080 -- lr 1.53e-04
2025-03-02 12:47:36,723 - INFO - ðŸªœ Batch step - 1020 -- sub batch step 4081 -- lr 1.53e-04
2025-03-02 12:47:38,875 - INFO - ðŸªœ Batch step - 1020 -- sub batch step 4082 -- lr 1.53e-04
2025-03-02 12:47:41,039 - INFO - ðŸªœ Batch step - 1020 -- sub batch step 4083 -- lr 1.53e-04
2025-03-02 12:47:42,645 - INFO - Step 1020 -- ðŸ”„ Training Metrics
2025-03-02 12:47:42,645 - INFO - â”œâ”€â”€ Loss: 7.7940
2025-03-02 12:47:42,645 - INFO - â”œâ”€â”€ Learning Rate: 1.53e-04
2025-03-02 12:47:42,646 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:47:43,326 - INFO - ðŸªœ Batch step - 1021 -- sub batch step 4084 -- lr 1.53e-04
2025-03-02 12:47:45,486 - INFO - ðŸªœ Batch step - 1021 -- sub batch step 4085 -- lr 1.53e-04
2025-03-02 12:47:47,641 - INFO - ðŸªœ Batch step - 1021 -- sub batch step 4086 -- lr 1.53e-04
2025-03-02 12:47:50,247 - INFO - ðŸªœ Batch step - 1021 -- sub batch step 4087 -- lr 1.53e-04
2025-03-02 12:47:51,922 - INFO - Step 1021 -- ðŸ”„ Training Metrics
2025-03-02 12:47:51,923 - INFO - â”œâ”€â”€ Loss: 7.7892
2025-03-02 12:47:51,923 - INFO - â”œâ”€â”€ Learning Rate: 1.53e-04
2025-03-02 12:47:51,923 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:47:52,596 - INFO - ðŸªœ Batch step - 1022 -- sub batch step 4088 -- lr 1.53e-04
2025-03-02 12:47:54,760 - INFO - ðŸªœ Batch step - 1022 -- sub batch step 4089 -- lr 1.53e-04
2025-03-02 12:47:56,920 - INFO - ðŸªœ Batch step - 1022 -- sub batch step 4090 -- lr 1.53e-04
2025-03-02 12:47:59,090 - INFO - ðŸªœ Batch step - 1022 -- sub batch step 4091 -- lr 1.53e-04
2025-03-02 12:48:00,618 - INFO - Step 1022 -- ðŸ”„ Training Metrics
2025-03-02 12:48:00,618 - INFO - â”œâ”€â”€ Loss: 7.8284
2025-03-02 12:48:00,618 - INFO - â”œâ”€â”€ Learning Rate: 1.53e-04
2025-03-02 12:48:00,619 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:48:01,291 - INFO - ðŸªœ Batch step - 1023 -- sub batch step 4092 -- lr 1.53e-04
2025-03-02 12:48:03,443 - INFO - ðŸªœ Batch step - 1023 -- sub batch step 4093 -- lr 1.53e-04
2025-03-02 12:48:05,601 - INFO - ðŸªœ Batch step - 1023 -- sub batch step 4094 -- lr 1.53e-04
2025-03-02 12:48:08,538 - INFO - ðŸªœ Batch step - 1023 -- sub batch step 4095 -- lr 1.53e-04
2025-03-02 12:48:10,030 - INFO - Step 1023 -- ðŸ”„ Training Metrics
2025-03-02 12:48:10,030 - INFO - â”œâ”€â”€ Loss: 7.7878
2025-03-02 12:48:10,030 - INFO - â”œâ”€â”€ Learning Rate: 1.53e-04
2025-03-02 12:48:10,030 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:48:10,694 - INFO - ðŸªœ Batch step - 1024 -- sub batch step 4096 -- lr 1.54e-04
2025-03-02 12:48:12,846 - INFO - ðŸªœ Batch step - 1024 -- sub batch step 4097 -- lr 1.54e-04
2025-03-02 12:48:14,996 - INFO - ðŸªœ Batch step - 1024 -- sub batch step 4098 -- lr 1.54e-04
2025-03-02 12:48:17,173 - INFO - ðŸªœ Batch step - 1024 -- sub batch step 4099 -- lr 1.54e-04
2025-03-02 12:48:18,716 - INFO - Step 1024 -- ðŸ”„ Training Metrics
2025-03-02 12:48:18,716 - INFO - â”œâ”€â”€ Loss: 7.8041
2025-03-02 12:48:18,716 - INFO - â”œâ”€â”€ Learning Rate: 1.54e-04
2025-03-02 12:48:18,716 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:48:19,388 - INFO - ðŸªœ Batch step - 1025 -- sub batch step 4100 -- lr 1.54e-04
2025-03-02 12:48:21,535 - INFO - ðŸªœ Batch step - 1025 -- sub batch step 4101 -- lr 1.54e-04
2025-03-02 12:48:23,690 - INFO - ðŸªœ Batch step - 1025 -- sub batch step 4102 -- lr 1.54e-04
2025-03-02 12:48:26,103 - INFO - ðŸªœ Batch step - 1025 -- sub batch step 4103 -- lr 1.54e-04
2025-03-02 12:48:28,025 - INFO - Step 1025 -- ðŸ”„ Training Metrics
2025-03-02 12:48:28,025 - INFO - â”œâ”€â”€ Loss: 7.7647
2025-03-02 12:48:28,026 - INFO - â”œâ”€â”€ Learning Rate: 1.54e-04
2025-03-02 12:48:28,026 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:48:28,699 - INFO - ðŸªœ Batch step - 1026 -- sub batch step 4104 -- lr 1.54e-04
2025-03-02 12:48:30,852 - INFO - ðŸªœ Batch step - 1026 -- sub batch step 4105 -- lr 1.54e-04
2025-03-02 12:48:32,997 - INFO - ðŸªœ Batch step - 1026 -- sub batch step 4106 -- lr 1.54e-04
2025-03-02 12:48:35,172 - INFO - ðŸªœ Batch step - 1026 -- sub batch step 4107 -- lr 1.54e-04
2025-03-02 12:48:36,704 - INFO - Step 1026 -- ðŸ”„ Training Metrics
2025-03-02 12:48:36,705 - INFO - â”œâ”€â”€ Loss: 7.7714
2025-03-02 12:48:36,705 - INFO - â”œâ”€â”€ Learning Rate: 1.54e-04
2025-03-02 12:48:36,705 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:48:37,371 - INFO - ðŸªœ Batch step - 1027 -- sub batch step 4108 -- lr 1.54e-04
2025-03-02 12:48:39,530 - INFO - ðŸªœ Batch step - 1027 -- sub batch step 4109 -- lr 1.54e-04
2025-03-02 12:48:41,686 - INFO - ðŸªœ Batch step - 1027 -- sub batch step 4110 -- lr 1.54e-04
2025-03-02 12:48:44,345 - INFO - ðŸªœ Batch step - 1027 -- sub batch step 4111 -- lr 1.54e-04
2025-03-02 12:48:45,957 - INFO - Step 1027 -- ðŸ”„ Training Metrics
2025-03-02 12:48:45,957 - INFO - â”œâ”€â”€ Loss: 7.7796
2025-03-02 12:48:45,957 - INFO - â”œâ”€â”€ Learning Rate: 1.54e-04
2025-03-02 12:48:45,957 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:48:46,631 - INFO - ðŸªœ Batch step - 1028 -- sub batch step 4112 -- lr 1.54e-04
2025-03-02 12:48:48,778 - INFO - ðŸªœ Batch step - 1028 -- sub batch step 4113 -- lr 1.54e-04
2025-03-02 12:48:50,936 - INFO - ðŸªœ Batch step - 1028 -- sub batch step 4114 -- lr 1.54e-04
2025-03-02 12:48:53,106 - INFO - ðŸªœ Batch step - 1028 -- sub batch step 4115 -- lr 1.54e-04
2025-03-02 12:48:54,666 - INFO - Step 1028 -- ðŸ”„ Training Metrics
2025-03-02 12:48:54,666 - INFO - â”œâ”€â”€ Loss: 7.7597
2025-03-02 12:48:54,666 - INFO - â”œâ”€â”€ Learning Rate: 1.54e-04
2025-03-02 12:48:54,666 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:48:55,332 - INFO - ðŸªœ Batch step - 1029 -- sub batch step 4116 -- lr 1.54e-04
2025-03-02 12:48:57,487 - INFO - ðŸªœ Batch step - 1029 -- sub batch step 4117 -- lr 1.54e-04
2025-03-02 12:48:59,635 - INFO - ðŸªœ Batch step - 1029 -- sub batch step 4118 -- lr 1.54e-04
2025-03-02 12:49:02,326 - INFO - ðŸªœ Batch step - 1029 -- sub batch step 4119 -- lr 1.54e-04
2025-03-02 12:49:03,895 - INFO - Step 1029 -- ðŸ”„ Training Metrics
2025-03-02 12:49:03,895 - INFO - â”œâ”€â”€ Loss: 7.7530
2025-03-02 12:49:03,895 - INFO - â”œâ”€â”€ Learning Rate: 1.54e-04
2025-03-02 12:49:03,896 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:49:04,567 - INFO - ðŸªœ Batch step - 1030 -- sub batch step 4120 -- lr 1.54e-04
2025-03-02 12:49:06,713 - INFO - ðŸªœ Batch step - 1030 -- sub batch step 4121 -- lr 1.54e-04
2025-03-02 12:49:08,866 - INFO - ðŸªœ Batch step - 1030 -- sub batch step 4122 -- lr 1.54e-04
2025-03-02 12:49:11,033 - INFO - ðŸªœ Batch step - 1030 -- sub batch step 4123 -- lr 1.54e-04
2025-03-02 12:49:12,592 - INFO - Step 1030 -- ðŸ”„ Training Metrics
2025-03-02 12:49:12,593 - INFO - â”œâ”€â”€ Loss: 7.7780
2025-03-02 12:49:12,593 - INFO - â”œâ”€â”€ Learning Rate: 1.54e-04
2025-03-02 12:49:12,593 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:49:13,267 - INFO - ðŸªœ Batch step - 1031 -- sub batch step 4124 -- lr 1.55e-04
2025-03-02 12:49:15,425 - INFO - ðŸªœ Batch step - 1031 -- sub batch step 4125 -- lr 1.55e-04
2025-03-02 12:49:18,105 - INFO - ðŸªœ Batch step - 1031 -- sub batch step 4126 -- lr 1.55e-04
2025-03-02 12:49:20,259 - INFO - ðŸªœ Batch step - 1031 -- sub batch step 4127 -- lr 1.55e-04
2025-03-02 12:49:21,744 - INFO - Step 1031 -- ðŸ”„ Training Metrics
2025-03-02 12:49:21,744 - INFO - â”œâ”€â”€ Loss: 7.7672
2025-03-02 12:49:21,744 - INFO - â”œâ”€â”€ Learning Rate: 1.55e-04
2025-03-02 12:49:21,744 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:49:22,406 - INFO - ðŸªœ Batch step - 1032 -- sub batch step 4128 -- lr 1.55e-04
2025-03-02 12:49:24,562 - INFO - ðŸªœ Batch step - 1032 -- sub batch step 4129 -- lr 1.55e-04
2025-03-02 12:49:26,735 - INFO - ðŸªœ Batch step - 1032 -- sub batch step 4130 -- lr 1.55e-04
2025-03-02 12:49:28,882 - INFO - ðŸªœ Batch step - 1032 -- sub batch step 4131 -- lr 1.55e-04
2025-03-02 12:49:30,443 - INFO - Step 1032 -- ðŸ”„ Training Metrics
2025-03-02 12:49:30,443 - INFO - â”œâ”€â”€ Loss: 7.7726
2025-03-02 12:49:30,443 - INFO - â”œâ”€â”€ Learning Rate: 1.55e-04
2025-03-02 12:49:30,443 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:49:31,111 - INFO - ðŸªœ Batch step - 1033 -- sub batch step 4132 -- lr 1.55e-04
2025-03-02 12:49:33,256 - INFO - ðŸªœ Batch step - 1033 -- sub batch step 4133 -- lr 1.55e-04
2025-03-02 12:49:36,070 - INFO - ðŸªœ Batch step - 1033 -- sub batch step 4134 -- lr 1.55e-04
2025-03-02 12:49:38,227 - INFO - ðŸªœ Batch step - 1033 -- sub batch step 4135 -- lr 1.55e-04
2025-03-02 12:49:39,781 - INFO - Step 1033 -- ðŸ”„ Training Metrics
2025-03-02 12:49:39,781 - INFO - â”œâ”€â”€ Loss: 7.7843
2025-03-02 12:49:39,781 - INFO - â”œâ”€â”€ Learning Rate: 1.55e-04
2025-03-02 12:49:39,782 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:49:40,446 - INFO - ðŸªœ Batch step - 1034 -- sub batch step 4136 -- lr 1.55e-04
2025-03-02 12:49:42,597 - INFO - ðŸªœ Batch step - 1034 -- sub batch step 4137 -- lr 1.55e-04
2025-03-02 12:49:44,761 - INFO - ðŸªœ Batch step - 1034 -- sub batch step 4138 -- lr 1.55e-04
2025-03-02 12:49:46,918 - INFO - ðŸªœ Batch step - 1034 -- sub batch step 4139 -- lr 1.55e-04
2025-03-02 12:49:48,528 - INFO - Step 1034 -- ðŸ”„ Training Metrics
2025-03-02 12:49:48,529 - INFO - â”œâ”€â”€ Loss: 7.7712
2025-03-02 12:49:48,529 - INFO - â”œâ”€â”€ Learning Rate: 1.55e-04
2025-03-02 12:49:48,529 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:49:49,201 - INFO - ðŸªœ Batch step - 1035 -- sub batch step 4140 -- lr 1.55e-04
2025-03-02 12:49:51,354 - INFO - ðŸªœ Batch step - 1035 -- sub batch step 4141 -- lr 1.55e-04
2025-03-02 12:49:54,048 - INFO - ðŸªœ Batch step - 1035 -- sub batch step 4142 -- lr 1.55e-04
2025-03-02 12:49:56,191 - INFO - ðŸªœ Batch step - 1035 -- sub batch step 4143 -- lr 1.55e-04
2025-03-02 12:49:57,818 - INFO - Step 1035 -- ðŸ”„ Training Metrics
2025-03-02 12:49:57,819 - INFO - â”œâ”€â”€ Loss: 7.7726
2025-03-02 12:49:57,819 - INFO - â”œâ”€â”€ Learning Rate: 1.55e-04
2025-03-02 12:49:57,819 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:49:58,494 - INFO - ðŸªœ Batch step - 1036 -- sub batch step 4144 -- lr 1.55e-04
2025-03-02 12:50:00,647 - INFO - ðŸªœ Batch step - 1036 -- sub batch step 4145 -- lr 1.55e-04
2025-03-02 12:50:02,815 - INFO - ðŸªœ Batch step - 1036 -- sub batch step 4146 -- lr 1.55e-04
2025-03-02 12:50:04,967 - INFO - ðŸªœ Batch step - 1036 -- sub batch step 4147 -- lr 1.55e-04
2025-03-02 12:50:06,507 - INFO - Step 1036 -- ðŸ”„ Training Metrics
2025-03-02 12:50:06,507 - INFO - â”œâ”€â”€ Loss: 7.7638
2025-03-02 12:50:06,508 - INFO - â”œâ”€â”€ Learning Rate: 1.55e-04
2025-03-02 12:50:06,508 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:50:07,171 - INFO - ðŸªœ Batch step - 1037 -- sub batch step 4148 -- lr 1.56e-04
2025-03-02 12:50:09,326 - INFO - ðŸªœ Batch step - 1037 -- sub batch step 4149 -- lr 1.56e-04
2025-03-02 12:50:11,702 - INFO - ðŸªœ Batch step - 1037 -- sub batch step 4150 -- lr 1.56e-04
2025-03-02 12:50:13,850 - INFO - ðŸªœ Batch step - 1037 -- sub batch step 4151 -- lr 1.56e-04
2025-03-02 12:50:15,816 - INFO - Step 1037 -- ðŸ”„ Training Metrics
2025-03-02 12:50:15,817 - INFO - â”œâ”€â”€ Loss: 7.7490
2025-03-02 12:50:15,817 - INFO - â”œâ”€â”€ Learning Rate: 1.56e-04
2025-03-02 12:50:15,817 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:50:16,487 - INFO - ðŸªœ Batch step - 1038 -- sub batch step 4152 -- lr 1.56e-04
2025-03-02 12:50:18,637 - INFO - ðŸªœ Batch step - 1038 -- sub batch step 4153 -- lr 1.56e-04
2025-03-02 12:50:20,813 - INFO - ðŸªœ Batch step - 1038 -- sub batch step 4154 -- lr 1.56e-04
2025-03-02 12:50:22,968 - INFO - ðŸªœ Batch step - 1038 -- sub batch step 4155 -- lr 1.56e-04
2025-03-02 12:50:24,503 - INFO - Step 1038 -- ðŸ”„ Training Metrics
2025-03-02 12:50:24,504 - INFO - â”œâ”€â”€ Loss: 7.7378
2025-03-02 12:50:24,504 - INFO - â”œâ”€â”€ Learning Rate: 1.56e-04
2025-03-02 12:50:24,504 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:50:25,168 - INFO - ðŸªœ Batch step - 1039 -- sub batch step 4156 -- lr 1.56e-04
2025-03-02 12:50:27,322 - INFO - ðŸªœ Batch step - 1039 -- sub batch step 4157 -- lr 1.56e-04
2025-03-02 12:50:29,595 - INFO - ðŸªœ Batch step - 1039 -- sub batch step 4158 -- lr 1.56e-04
2025-03-02 12:50:31,753 - INFO - ðŸªœ Batch step - 1039 -- sub batch step 4159 -- lr 1.56e-04
2025-03-02 12:50:33,323 - INFO - Step 1039 -- ðŸ”„ Training Metrics
2025-03-02 12:50:33,324 - INFO - â”œâ”€â”€ Loss: 7.7474
2025-03-02 12:50:33,324 - INFO - â”œâ”€â”€ Learning Rate: 1.56e-04
2025-03-02 12:50:33,324 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:50:34,479 - INFO - ðŸªœ Batch step - 1040 -- sub batch step 4160 -- lr 1.56e-04
2025-03-02 12:50:36,639 - INFO - ðŸªœ Batch step - 1040 -- sub batch step 4161 -- lr 1.56e-04
2025-03-02 12:50:38,792 - INFO - ðŸªœ Batch step - 1040 -- sub batch step 4162 -- lr 1.56e-04
2025-03-02 12:50:40,957 - INFO - ðŸªœ Batch step - 1040 -- sub batch step 4163 -- lr 1.56e-04
2025-03-02 12:50:45,074 - INFO - Step 1040 -- ðŸ”„ Training Metrics
2025-03-02 12:50:45,075 - INFO - â”œâ”€â”€ Loss: 7.7421
2025-03-02 12:50:45,075 - INFO - â”œâ”€â”€ Learning Rate: 1.56e-04
2025-03-02 12:50:45,075 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:50:45,747 - INFO - ðŸªœ Batch step - 1041 -- sub batch step 4164 -- lr 1.56e-04
2025-03-02 12:50:47,899 - INFO - ðŸªœ Batch step - 1041 -- sub batch step 4165 -- lr 1.56e-04
2025-03-02 12:50:50,049 - INFO - ðŸªœ Batch step - 1041 -- sub batch step 4166 -- lr 1.56e-04
2025-03-02 12:50:52,538 - INFO - ðŸªœ Batch step - 1041 -- sub batch step 4167 -- lr 1.56e-04
2025-03-02 12:50:54,227 - INFO - Step 1041 -- ðŸ”„ Training Metrics
2025-03-02 12:50:54,227 - INFO - â”œâ”€â”€ Loss: 7.7769
2025-03-02 12:50:54,227 - INFO - â”œâ”€â”€ Learning Rate: 1.56e-04
2025-03-02 12:50:54,227 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:50:54,892 - INFO - ðŸªœ Batch step - 1042 -- sub batch step 4168 -- lr 1.56e-04
2025-03-02 12:50:57,049 - INFO - ðŸªœ Batch step - 1042 -- sub batch step 4169 -- lr 1.56e-04
2025-03-02 12:50:59,200 - INFO - ðŸªœ Batch step - 1042 -- sub batch step 4170 -- lr 1.56e-04
2025-03-02 12:51:01,360 - INFO - ðŸªœ Batch step - 1042 -- sub batch step 4171 -- lr 1.56e-04
2025-03-02 12:51:02,915 - INFO - Step 1042 -- ðŸ”„ Training Metrics
2025-03-02 12:51:02,915 - INFO - â”œâ”€â”€ Loss: 7.7577
2025-03-02 12:51:02,915 - INFO - â”œâ”€â”€ Learning Rate: 1.56e-04
2025-03-02 12:51:02,915 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:51:03,586 - INFO - ðŸªœ Batch step - 1043 -- sub batch step 4172 -- lr 1.56e-04
2025-03-02 12:51:05,733 - INFO - ðŸªœ Batch step - 1043 -- sub batch step 4173 -- lr 1.56e-04
2025-03-02 12:51:07,892 - INFO - ðŸªœ Batch step - 1043 -- sub batch step 4174 -- lr 1.56e-04
2025-03-02 12:51:10,481 - INFO - ðŸªœ Batch step - 1043 -- sub batch step 4175 -- lr 1.56e-04
2025-03-02 12:51:12,166 - INFO - Step 1043 -- ðŸ”„ Training Metrics
2025-03-02 12:51:12,167 - INFO - â”œâ”€â”€ Loss: 7.7387
2025-03-02 12:51:12,167 - INFO - â”œâ”€â”€ Learning Rate: 1.56e-04
2025-03-02 12:51:12,167 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:51:12,830 - INFO - ðŸªœ Batch step - 1044 -- sub batch step 4176 -- lr 1.57e-04
2025-03-02 12:51:14,982 - INFO - ðŸªœ Batch step - 1044 -- sub batch step 4177 -- lr 1.57e-04
2025-03-02 12:51:17,130 - INFO - ðŸªœ Batch step - 1044 -- sub batch step 4178 -- lr 1.57e-04
2025-03-02 12:51:19,302 - INFO - ðŸªœ Batch step - 1044 -- sub batch step 4179 -- lr 1.57e-04
2025-03-02 12:51:20,869 - INFO - Step 1044 -- ðŸ”„ Training Metrics
2025-03-02 12:51:20,869 - INFO - â”œâ”€â”€ Loss: 7.7623
2025-03-02 12:51:20,869 - INFO - â”œâ”€â”€ Learning Rate: 1.57e-04
2025-03-02 12:51:20,869 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:51:21,538 - INFO - ðŸªœ Batch step - 1045 -- sub batch step 4180 -- lr 1.57e-04
2025-03-02 12:51:23,688 - INFO - ðŸªœ Batch step - 1045 -- sub batch step 4181 -- lr 1.57e-04
2025-03-02 12:51:25,845 - INFO - ðŸªœ Batch step - 1045 -- sub batch step 4182 -- lr 1.57e-04
2025-03-02 12:51:28,436 - INFO - ðŸªœ Batch step - 1045 -- sub batch step 4183 -- lr 1.57e-04
2025-03-02 12:51:30,030 - INFO - Step 1045 -- ðŸ”„ Training Metrics
2025-03-02 12:51:30,031 - INFO - â”œâ”€â”€ Loss: 7.7691
2025-03-02 12:51:30,031 - INFO - â”œâ”€â”€ Learning Rate: 1.57e-04
2025-03-02 12:51:30,031 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:51:30,702 - INFO - ðŸªœ Batch step - 1046 -- sub batch step 4184 -- lr 1.57e-04
2025-03-02 12:51:32,855 - INFO - ðŸªœ Batch step - 1046 -- sub batch step 4185 -- lr 1.57e-04
2025-03-02 12:51:35,002 - INFO - ðŸªœ Batch step - 1046 -- sub batch step 4186 -- lr 1.57e-04
2025-03-02 12:51:37,172 - INFO - ðŸªœ Batch step - 1046 -- sub batch step 4187 -- lr 1.57e-04
2025-03-02 12:51:38,715 - INFO - Step 1046 -- ðŸ”„ Training Metrics
2025-03-02 12:51:38,715 - INFO - â”œâ”€â”€ Loss: 7.7253
2025-03-02 12:51:38,715 - INFO - â”œâ”€â”€ Learning Rate: 1.57e-04
2025-03-02 12:51:38,715 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:51:39,381 - INFO - ðŸªœ Batch step - 1047 -- sub batch step 4188 -- lr 1.57e-04
2025-03-02 12:51:41,536 - INFO - ðŸªœ Batch step - 1047 -- sub batch step 4189 -- lr 1.57e-04
2025-03-02 12:51:43,689 - INFO - ðŸªœ Batch step - 1047 -- sub batch step 4190 -- lr 1.57e-04
2025-03-02 12:51:46,069 - INFO - ðŸªœ Batch step - 1047 -- sub batch step 4191 -- lr 1.57e-04
2025-03-02 12:51:47,899 - INFO - Step 1047 -- ðŸ”„ Training Metrics
2025-03-02 12:51:47,900 - INFO - â”œâ”€â”€ Loss: 7.7167
2025-03-02 12:51:47,900 - INFO - â”œâ”€â”€ Learning Rate: 1.57e-04
2025-03-02 12:51:47,900 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:51:48,570 - INFO - ðŸªœ Batch step - 1048 -- sub batch step 4192 -- lr 1.57e-04
2025-03-02 12:51:50,715 - INFO - ðŸªœ Batch step - 1048 -- sub batch step 4193 -- lr 1.57e-04
2025-03-02 12:51:52,870 - INFO - ðŸªœ Batch step - 1048 -- sub batch step 4194 -- lr 1.57e-04
2025-03-02 12:51:55,042 - INFO - ðŸªœ Batch step - 1048 -- sub batch step 4195 -- lr 1.57e-04
2025-03-02 12:51:56,584 - INFO - Step 1048 -- ðŸ”„ Training Metrics
2025-03-02 12:51:56,584 - INFO - â”œâ”€â”€ Loss: 7.7408
2025-03-02 12:51:56,584 - INFO - â”œâ”€â”€ Learning Rate: 1.57e-04
2025-03-02 12:51:56,584 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:51:57,249 - INFO - ðŸªœ Batch step - 1049 -- sub batch step 4196 -- lr 1.57e-04
2025-03-02 12:51:59,401 - INFO - ðŸªœ Batch step - 1049 -- sub batch step 4197 -- lr 1.57e-04
2025-03-02 12:52:01,550 - INFO - ðŸªœ Batch step - 1049 -- sub batch step 4198 -- lr 1.57e-04
2025-03-02 12:52:04,231 - INFO - ðŸªœ Batch step - 1049 -- sub batch step 4199 -- lr 1.57e-04
2025-03-02 12:52:05,759 - INFO - Step 1049 -- ðŸ”„ Training Metrics
2025-03-02 12:52:05,759 - INFO - â”œâ”€â”€ Loss: 7.7139
2025-03-02 12:52:05,759 - INFO - â”œâ”€â”€ Learning Rate: 1.57e-04
2025-03-02 12:52:05,759 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:52:06,432 - INFO - ðŸªœ Batch step - 1050 -- sub batch step 4200 -- lr 1.57e-04
2025-03-02 12:52:08,579 - INFO - ðŸªœ Batch step - 1050 -- sub batch step 4201 -- lr 1.57e-04
2025-03-02 12:52:10,732 - INFO - ðŸªœ Batch step - 1050 -- sub batch step 4202 -- lr 1.57e-04
2025-03-02 12:52:12,896 - INFO - ðŸªœ Batch step - 1050 -- sub batch step 4203 -- lr 1.57e-04
2025-03-02 12:52:14,438 - INFO - Step 1050 -- ðŸ”„ Training Metrics
2025-03-02 12:52:14,438 - INFO - â”œâ”€â”€ Loss: 7.7302
2025-03-02 12:52:14,438 - INFO - â”œâ”€â”€ Learning Rate: 1.57e-04
2025-03-02 12:52:14,438 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:52:15,107 - INFO - ðŸªœ Batch step - 1051 -- sub batch step 4204 -- lr 1.58e-04
2025-03-02 12:52:17,261 - INFO - ðŸªœ Batch step - 1051 -- sub batch step 4205 -- lr 1.58e-04
2025-03-02 12:52:19,989 - INFO - ðŸªœ Batch step - 1051 -- sub batch step 4206 -- lr 1.58e-04
2025-03-02 12:52:22,140 - INFO - ðŸªœ Batch step - 1051 -- sub batch step 4207 -- lr 1.58e-04
2025-03-02 12:52:23,677 - INFO - Step 1051 -- ðŸ”„ Training Metrics
2025-03-02 12:52:23,678 - INFO - â”œâ”€â”€ Loss: 7.7401
2025-03-02 12:52:23,678 - INFO - â”œâ”€â”€ Learning Rate: 1.58e-04
2025-03-02 12:52:23,678 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:52:24,343 - INFO - ðŸªœ Batch step - 1052 -- sub batch step 4208 -- lr 1.58e-04
2025-03-02 12:52:26,497 - INFO - ðŸªœ Batch step - 1052 -- sub batch step 4209 -- lr 1.58e-04
2025-03-02 12:52:28,666 - INFO - ðŸªœ Batch step - 1052 -- sub batch step 4210 -- lr 1.58e-04
2025-03-02 12:52:30,814 - INFO - ðŸªœ Batch step - 1052 -- sub batch step 4211 -- lr 1.58e-04
2025-03-02 12:52:32,359 - INFO - Step 1052 -- ðŸ”„ Training Metrics
2025-03-02 12:52:32,359 - INFO - â”œâ”€â”€ Loss: 7.7257
2025-03-02 12:52:32,359 - INFO - â”œâ”€â”€ Learning Rate: 1.58e-04
2025-03-02 12:52:32,359 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:52:33,029 - INFO - ðŸªœ Batch step - 1053 -- sub batch step 4212 -- lr 1.58e-04
2025-03-02 12:52:35,174 - INFO - ðŸªœ Batch step - 1053 -- sub batch step 4213 -- lr 1.58e-04
2025-03-02 12:52:37,865 - INFO - ðŸªœ Batch step - 1053 -- sub batch step 4214 -- lr 1.58e-04
2025-03-02 12:52:40,020 - INFO - ðŸªœ Batch step - 1053 -- sub batch step 4215 -- lr 1.58e-04
2025-03-02 12:52:41,670 - INFO - Step 1053 -- ðŸ”„ Training Metrics
2025-03-02 12:52:41,670 - INFO - â”œâ”€â”€ Loss: 7.7484
2025-03-02 12:52:41,670 - INFO - â”œâ”€â”€ Learning Rate: 1.58e-04
2025-03-02 12:52:41,670 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:52:42,337 - INFO - ðŸªœ Batch step - 1054 -- sub batch step 4216 -- lr 1.58e-04
2025-03-02 12:52:44,489 - INFO - ðŸªœ Batch step - 1054 -- sub batch step 4217 -- lr 1.58e-04
2025-03-02 12:52:46,651 - INFO - ðŸªœ Batch step - 1054 -- sub batch step 4218 -- lr 1.58e-04
2025-03-02 12:52:48,806 - INFO - ðŸªœ Batch step - 1054 -- sub batch step 4219 -- lr 1.58e-04
2025-03-02 12:52:50,354 - INFO - Step 1054 -- ðŸ”„ Training Metrics
2025-03-02 12:52:50,354 - INFO - â”œâ”€â”€ Loss: 7.7260
2025-03-02 12:52:50,354 - INFO - â”œâ”€â”€ Learning Rate: 1.58e-04
2025-03-02 12:52:50,354 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:52:51,029 - INFO - ðŸªœ Batch step - 1055 -- sub batch step 4220 -- lr 1.58e-04
2025-03-02 12:52:53,180 - INFO - ðŸªœ Batch step - 1055 -- sub batch step 4221 -- lr 1.58e-04
2025-03-02 12:52:55,893 - INFO - ðŸªœ Batch step - 1055 -- sub batch step 4222 -- lr 1.58e-04
2025-03-02 12:52:58,039 - INFO - ðŸªœ Batch step - 1055 -- sub batch step 4223 -- lr 1.58e-04
2025-03-02 12:52:59,608 - INFO - Step 1055 -- ðŸ”„ Training Metrics
2025-03-02 12:52:59,608 - INFO - â”œâ”€â”€ Loss: 7.7313
2025-03-02 12:52:59,608 - INFO - â”œâ”€â”€ Learning Rate: 1.58e-04
2025-03-02 12:52:59,608 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:53:00,283 - INFO - ðŸªœ Batch step - 1056 -- sub batch step 4224 -- lr 1.58e-04
2025-03-02 12:53:02,434 - INFO - ðŸªœ Batch step - 1056 -- sub batch step 4225 -- lr 1.58e-04
2025-03-02 12:53:04,598 - INFO - ðŸªœ Batch step - 1056 -- sub batch step 4226 -- lr 1.58e-04
2025-03-02 12:53:06,749 - INFO - ðŸªœ Batch step - 1056 -- sub batch step 4227 -- lr 1.58e-04
2025-03-02 12:53:08,292 - INFO - Step 1056 -- ðŸ”„ Training Metrics
2025-03-02 12:53:08,293 - INFO - â”œâ”€â”€ Loss: 7.7098
2025-03-02 12:53:08,293 - INFO - â”œâ”€â”€ Learning Rate: 1.58e-04
2025-03-02 12:53:08,293 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:53:08,957 - INFO - ðŸªœ Batch step - 1057 -- sub batch step 4228 -- lr 1.59e-04
2025-03-02 12:53:11,115 - INFO - ðŸªœ Batch step - 1057 -- sub batch step 4229 -- lr 1.59e-04
2025-03-02 12:53:13,822 - INFO - ðŸªœ Batch step - 1057 -- sub batch step 4230 -- lr 1.59e-04
2025-03-02 12:53:15,968 - INFO - ðŸªœ Batch step - 1057 -- sub batch step 4231 -- lr 1.59e-04
2025-03-02 12:53:17,532 - INFO - Step 1057 -- ðŸ”„ Training Metrics
2025-03-02 12:53:17,532 - INFO - â”œâ”€â”€ Loss: 7.7247
2025-03-02 12:53:17,532 - INFO - â”œâ”€â”€ Learning Rate: 1.59e-04
2025-03-02 12:53:17,532 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:53:18,204 - INFO - ðŸªœ Batch step - 1058 -- sub batch step 4232 -- lr 1.59e-04
2025-03-02 12:53:20,350 - INFO - ðŸªœ Batch step - 1058 -- sub batch step 4233 -- lr 1.59e-04
2025-03-02 12:53:22,520 - INFO - ðŸªœ Batch step - 1058 -- sub batch step 4234 -- lr 1.59e-04
2025-03-02 12:53:24,674 - INFO - ðŸªœ Batch step - 1058 -- sub batch step 4235 -- lr 1.59e-04
2025-03-02 12:53:26,216 - INFO - Step 1058 -- ðŸ”„ Training Metrics
2025-03-02 12:53:26,217 - INFO - â”œâ”€â”€ Loss: 7.6962
2025-03-02 12:53:26,217 - INFO - â”œâ”€â”€ Learning Rate: 1.59e-04
2025-03-02 12:53:26,217 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:53:26,883 - INFO - ðŸªœ Batch step - 1059 -- sub batch step 4236 -- lr 1.59e-04
2025-03-02 12:53:29,040 - INFO - ðŸªœ Batch step - 1059 -- sub batch step 4237 -- lr 1.59e-04
2025-03-02 12:53:31,353 - INFO - ðŸªœ Batch step - 1059 -- sub batch step 4238 -- lr 1.59e-04
2025-03-02 12:53:33,505 - INFO - ðŸªœ Batch step - 1059 -- sub batch step 4239 -- lr 1.59e-04
2025-03-02 12:53:35,119 - INFO - Step 1059 -- ðŸ”„ Training Metrics
2025-03-02 12:53:35,119 - INFO - â”œâ”€â”€ Loss: 7.6937
2025-03-02 12:53:35,119 - INFO - â”œâ”€â”€ Learning Rate: 1.59e-04
2025-03-02 12:53:35,119 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:53:36,301 - INFO - ðŸªœ Batch step - 1060 -- sub batch step 4240 -- lr 1.59e-04
2025-03-02 12:53:38,446 - INFO - ðŸªœ Batch step - 1060 -- sub batch step 4241 -- lr 1.59e-04
2025-03-02 12:53:40,597 - INFO - ðŸªœ Batch step - 1060 -- sub batch step 4242 -- lr 1.59e-04
2025-03-02 12:53:42,760 - INFO - ðŸªœ Batch step - 1060 -- sub batch step 4243 -- lr 1.59e-04
2025-03-02 12:53:44,719 - INFO - Step 1060 -- ðŸ”„ Training Metrics
2025-03-02 12:53:44,720 - INFO - â”œâ”€â”€ Loss: 7.7009
2025-03-02 12:53:44,720 - INFO - â”œâ”€â”€ Learning Rate: 1.59e-04
2025-03-02 12:53:44,720 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:53:45,393 - INFO - ðŸªœ Batch step - 1061 -- sub batch step 4244 -- lr 1.59e-04
2025-03-02 12:53:47,544 - INFO - ðŸªœ Batch step - 1061 -- sub batch step 4245 -- lr 1.59e-04
2025-03-02 12:53:49,689 - INFO - ðŸªœ Batch step - 1061 -- sub batch step 4246 -- lr 1.59e-04
2025-03-02 12:53:52,129 - INFO - ðŸªœ Batch step - 1061 -- sub batch step 4247 -- lr 1.59e-04
2025-03-02 12:53:54,036 - INFO - Step 1061 -- ðŸ”„ Training Metrics
2025-03-02 12:53:54,036 - INFO - â”œâ”€â”€ Loss: 7.7017
2025-03-02 12:53:54,036 - INFO - â”œâ”€â”€ Learning Rate: 1.59e-04
2025-03-02 12:53:54,037 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:53:54,705 - INFO - ðŸªœ Batch step - 1062 -- sub batch step 4248 -- lr 1.59e-04
2025-03-02 12:53:56,863 - INFO - ðŸªœ Batch step - 1062 -- sub batch step 4249 -- lr 1.59e-04
2025-03-02 12:53:59,015 - INFO - ðŸªœ Batch step - 1062 -- sub batch step 4250 -- lr 1.59e-04
2025-03-02 12:54:01,178 - INFO - ðŸªœ Batch step - 1062 -- sub batch step 4251 -- lr 1.59e-04
2025-03-02 12:54:02,734 - INFO - Step 1062 -- ðŸ”„ Training Metrics
2025-03-02 12:54:02,734 - INFO - â”œâ”€â”€ Loss: 7.7024
2025-03-02 12:54:02,734 - INFO - â”œâ”€â”€ Learning Rate: 1.59e-04
2025-03-02 12:54:02,734 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:54:03,409 - INFO - ðŸªœ Batch step - 1063 -- sub batch step 4252 -- lr 1.59e-04
2025-03-02 12:54:05,557 - INFO - ðŸªœ Batch step - 1063 -- sub batch step 4253 -- lr 1.59e-04
2025-03-02 12:54:07,712 - INFO - ðŸªœ Batch step - 1063 -- sub batch step 4254 -- lr 1.59e-04
2025-03-02 12:54:10,537 - INFO - ðŸªœ Batch step - 1063 -- sub batch step 4255 -- lr 1.59e-04
2025-03-02 12:54:12,046 - INFO - Step 1063 -- ðŸ”„ Training Metrics
2025-03-02 12:54:12,046 - INFO - â”œâ”€â”€ Loss: 7.7221
2025-03-02 12:54:12,046 - INFO - â”œâ”€â”€ Learning Rate: 1.59e-04
2025-03-02 12:54:12,047 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:54:12,713 - INFO - ðŸªœ Batch step - 1064 -- sub batch step 4256 -- lr 1.60e-04
2025-03-02 12:54:14,872 - INFO - ðŸªœ Batch step - 1064 -- sub batch step 4257 -- lr 1.60e-04
2025-03-02 12:54:17,019 - INFO - ðŸªœ Batch step - 1064 -- sub batch step 4258 -- lr 1.60e-04
2025-03-02 12:54:19,186 - INFO - ðŸªœ Batch step - 1064 -- sub batch step 4259 -- lr 1.60e-04
2025-03-02 12:54:20,745 - INFO - Step 1064 -- ðŸ”„ Training Metrics
2025-03-02 12:54:20,745 - INFO - â”œâ”€â”€ Loss: 7.7077
2025-03-02 12:54:20,745 - INFO - â”œâ”€â”€ Learning Rate: 1.60e-04
2025-03-02 12:54:20,745 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:54:21,416 - INFO - ðŸªœ Batch step - 1065 -- sub batch step 4260 -- lr 1.60e-04
2025-03-02 12:54:23,569 - INFO - ðŸªœ Batch step - 1065 -- sub batch step 4261 -- lr 1.60e-04
2025-03-02 12:54:25,727 - INFO - ðŸªœ Batch step - 1065 -- sub batch step 4262 -- lr 1.60e-04
2025-03-02 12:54:28,524 - INFO - ðŸªœ Batch step - 1065 -- sub batch step 4263 -- lr 1.60e-04
2025-03-02 12:54:30,037 - INFO - Step 1065 -- ðŸ”„ Training Metrics
2025-03-02 12:54:30,037 - INFO - â”œâ”€â”€ Loss: 7.6756
2025-03-02 12:54:30,037 - INFO - â”œâ”€â”€ Learning Rate: 1.60e-04
2025-03-02 12:54:30,037 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:54:30,711 - INFO - ðŸªœ Batch step - 1066 -- sub batch step 4264 -- lr 1.60e-04
2025-03-02 12:54:32,865 - INFO - ðŸªœ Batch step - 1066 -- sub batch step 4265 -- lr 1.60e-04
2025-03-02 12:54:35,013 - INFO - ðŸªœ Batch step - 1066 -- sub batch step 4266 -- lr 1.60e-04
2025-03-02 12:54:37,179 - INFO - ðŸªœ Batch step - 1066 -- sub batch step 4267 -- lr 1.60e-04
2025-03-02 12:54:38,738 - INFO - Step 1066 -- ðŸ”„ Training Metrics
2025-03-02 12:54:38,738 - INFO - â”œâ”€â”€ Loss: 7.6923
2025-03-02 12:54:38,738 - INFO - â”œâ”€â”€ Learning Rate: 1.60e-04
2025-03-02 12:54:38,738 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:54:39,403 - INFO - ðŸªœ Batch step - 1067 -- sub batch step 4268 -- lr 1.60e-04
2025-03-02 12:54:41,564 - INFO - ðŸªœ Batch step - 1067 -- sub batch step 4269 -- lr 1.60e-04
2025-03-02 12:54:43,716 - INFO - ðŸªœ Batch step - 1067 -- sub batch step 4270 -- lr 1.60e-04
2025-03-02 12:54:46,397 - INFO - ðŸªœ Batch step - 1067 -- sub batch step 4271 -- lr 1.60e-04
2025-03-02 12:54:48,103 - INFO - Step 1067 -- ðŸ”„ Training Metrics
2025-03-02 12:54:48,103 - INFO - â”œâ”€â”€ Loss: 7.7135
2025-03-02 12:54:48,103 - INFO - â”œâ”€â”€ Learning Rate: 1.60e-04
2025-03-02 12:54:48,104 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:54:48,775 - INFO - ðŸªœ Batch step - 1068 -- sub batch step 4272 -- lr 1.60e-04
2025-03-02 12:54:50,923 - INFO - ðŸªœ Batch step - 1068 -- sub batch step 4273 -- lr 1.60e-04
2025-03-02 12:54:53,077 - INFO - ðŸªœ Batch step - 1068 -- sub batch step 4274 -- lr 1.60e-04
2025-03-02 12:54:55,251 - INFO - ðŸªœ Batch step - 1068 -- sub batch step 4275 -- lr 1.60e-04
2025-03-02 12:54:56,800 - INFO - Step 1068 -- ðŸ”„ Training Metrics
2025-03-02 12:54:56,800 - INFO - â”œâ”€â”€ Loss: 7.6986
2025-03-02 12:54:56,800 - INFO - â”œâ”€â”€ Learning Rate: 1.60e-04
2025-03-02 12:54:56,801 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:54:57,465 - INFO - ðŸªœ Batch step - 1069 -- sub batch step 4276 -- lr 1.60e-04
2025-03-02 12:54:59,617 - INFO - ðŸªœ Batch step - 1069 -- sub batch step 4277 -- lr 1.60e-04
2025-03-02 12:55:01,769 - INFO - ðŸªœ Batch step - 1069 -- sub batch step 4278 -- lr 1.60e-04
2025-03-02 12:55:04,447 - INFO - ðŸªœ Batch step - 1069 -- sub batch step 4279 -- lr 1.60e-04
2025-03-02 12:55:06,028 - INFO - Step 1069 -- ðŸ”„ Training Metrics
2025-03-02 12:55:06,028 - INFO - â”œâ”€â”€ Loss: 7.7124
2025-03-02 12:55:06,028 - INFO - â”œâ”€â”€ Learning Rate: 1.60e-04
2025-03-02 12:55:06,028 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:55:06,700 - INFO - ðŸªœ Batch step - 1070 -- sub batch step 4280 -- lr 1.60e-04
2025-03-02 12:55:08,849 - INFO - ðŸªœ Batch step - 1070 -- sub batch step 4281 -- lr 1.60e-04
2025-03-02 12:55:11,004 - INFO - ðŸªœ Batch step - 1070 -- sub batch step 4282 -- lr 1.60e-04
2025-03-02 12:55:13,171 - INFO - ðŸªœ Batch step - 1070 -- sub batch step 4283 -- lr 1.60e-04
2025-03-02 12:55:14,725 - INFO - Step 1070 -- ðŸ”„ Training Metrics
2025-03-02 12:55:14,726 - INFO - â”œâ”€â”€ Loss: 7.6924
2025-03-02 12:55:14,726 - INFO - â”œâ”€â”€ Learning Rate: 1.60e-04
2025-03-02 12:55:14,726 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:55:15,405 - INFO - ðŸªœ Batch step - 1071 -- sub batch step 4284 -- lr 1.61e-04
2025-03-02 12:55:17,559 - INFO - ðŸªœ Batch step - 1071 -- sub batch step 4285 -- lr 1.61e-04
2025-03-02 12:55:20,180 - INFO - ðŸªœ Batch step - 1071 -- sub batch step 4286 -- lr 1.61e-04
2025-03-02 12:55:22,339 - INFO - ðŸªœ Batch step - 1071 -- sub batch step 4287 -- lr 1.61e-04
2025-03-02 12:55:23,980 - INFO - Step 1071 -- ðŸ”„ Training Metrics
2025-03-02 12:55:23,980 - INFO - â”œâ”€â”€ Loss: 7.6966
2025-03-02 12:55:23,980 - INFO - â”œâ”€â”€ Learning Rate: 1.61e-04
2025-03-02 12:55:23,980 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:55:24,646 - INFO - ðŸªœ Batch step - 1072 -- sub batch step 4288 -- lr 1.61e-04
2025-03-02 12:55:26,799 - INFO - ðŸªœ Batch step - 1072 -- sub batch step 4289 -- lr 1.61e-04
2025-03-02 12:55:28,966 - INFO - ðŸªœ Batch step - 1072 -- sub batch step 4290 -- lr 1.61e-04
2025-03-02 12:55:31,116 - INFO - ðŸªœ Batch step - 1072 -- sub batch step 4291 -- lr 1.61e-04
2025-03-02 12:55:32,675 - INFO - Step 1072 -- ðŸ”„ Training Metrics
2025-03-02 12:55:32,675 - INFO - â”œâ”€â”€ Loss: 7.6619
2025-03-02 12:55:32,675 - INFO - â”œâ”€â”€ Learning Rate: 1.61e-04
2025-03-02 12:55:32,675 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:55:33,348 - INFO - ðŸªœ Batch step - 1073 -- sub batch step 4292 -- lr 1.61e-04
2025-03-02 12:55:35,496 - INFO - ðŸªœ Batch step - 1073 -- sub batch step 4293 -- lr 1.61e-04
2025-03-02 12:55:38,133 - INFO - ðŸªœ Batch step - 1073 -- sub batch step 4294 -- lr 1.61e-04
2025-03-02 12:55:40,286 - INFO - ðŸªœ Batch step - 1073 -- sub batch step 4295 -- lr 1.61e-04
2025-03-02 12:55:41,884 - INFO - Step 1073 -- ðŸ”„ Training Metrics
2025-03-02 12:55:41,884 - INFO - â”œâ”€â”€ Loss: 7.6808
2025-03-02 12:55:41,884 - INFO - â”œâ”€â”€ Learning Rate: 1.61e-04
2025-03-02 12:55:41,884 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:55:42,550 - INFO - ðŸªœ Batch step - 1074 -- sub batch step 4296 -- lr 1.61e-04
2025-03-02 12:55:44,701 - INFO - ðŸªœ Batch step - 1074 -- sub batch step 4297 -- lr 1.61e-04
2025-03-02 12:55:46,867 - INFO - ðŸªœ Batch step - 1074 -- sub batch step 4298 -- lr 1.61e-04
2025-03-02 12:55:49,025 - INFO - ðŸªœ Batch step - 1074 -- sub batch step 4299 -- lr 1.61e-04
2025-03-02 12:55:50,588 - INFO - Step 1074 -- ðŸ”„ Training Metrics
2025-03-02 12:55:50,588 - INFO - â”œâ”€â”€ Loss: 7.6983
2025-03-02 12:55:50,588 - INFO - â”œâ”€â”€ Learning Rate: 1.61e-04
2025-03-02 12:55:50,588 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:55:51,259 - INFO - ðŸªœ Batch step - 1075 -- sub batch step 4300 -- lr 1.61e-04
2025-03-02 12:55:53,408 - INFO - ðŸªœ Batch step - 1075 -- sub batch step 4301 -- lr 1.61e-04
2025-03-02 12:55:55,963 - INFO - ðŸªœ Batch step - 1075 -- sub batch step 4302 -- lr 1.61e-04
2025-03-02 12:55:58,113 - INFO - ðŸªœ Batch step - 1075 -- sub batch step 4303 -- lr 1.61e-04
2025-03-02 12:55:59,858 - INFO - Step 1075 -- ðŸ”„ Training Metrics
2025-03-02 12:55:59,858 - INFO - â”œâ”€â”€ Loss: 7.6632
2025-03-02 12:55:59,858 - INFO - â”œâ”€â”€ Learning Rate: 1.61e-04
2025-03-02 12:55:59,858 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:56:00,531 - INFO - ðŸªœ Batch step - 1076 -- sub batch step 4304 -- lr 1.61e-04
2025-03-02 12:56:02,686 - INFO - ðŸªœ Batch step - 1076 -- sub batch step 4305 -- lr 1.61e-04
2025-03-02 12:56:04,848 - INFO - ðŸªœ Batch step - 1076 -- sub batch step 4306 -- lr 1.61e-04
2025-03-02 12:56:07,006 - INFO - ðŸªœ Batch step - 1076 -- sub batch step 4307 -- lr 1.61e-04
2025-03-02 12:56:08,565 - INFO - Step 1076 -- ðŸ”„ Training Metrics
2025-03-02 12:56:08,565 - INFO - â”œâ”€â”€ Loss: 7.6792
2025-03-02 12:56:08,565 - INFO - â”œâ”€â”€ Learning Rate: 1.61e-04
2025-03-02 12:56:08,565 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:56:09,230 - INFO - ðŸªœ Batch step - 1077 -- sub batch step 4308 -- lr 1.62e-04
2025-03-02 12:56:11,383 - INFO - ðŸªœ Batch step - 1077 -- sub batch step 4309 -- lr 1.62e-04
2025-03-02 12:56:13,976 - INFO - ðŸªœ Batch step - 1077 -- sub batch step 4310 -- lr 1.62e-04
2025-03-02 12:56:16,121 - INFO - ðŸªœ Batch step - 1077 -- sub batch step 4311 -- lr 1.62e-04
2025-03-02 12:56:17,734 - INFO - Step 1077 -- ðŸ”„ Training Metrics
2025-03-02 12:56:17,735 - INFO - â”œâ”€â”€ Loss: 7.6890
2025-03-02 12:56:17,735 - INFO - â”œâ”€â”€ Learning Rate: 1.62e-04
2025-03-02 12:56:17,735 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:56:18,408 - INFO - ðŸªœ Batch step - 1078 -- sub batch step 4312 -- lr 1.62e-04
2025-03-02 12:56:20,557 - INFO - ðŸªœ Batch step - 1078 -- sub batch step 4313 -- lr 1.62e-04
2025-03-02 12:56:22,729 - INFO - ðŸªœ Batch step - 1078 -- sub batch step 4314 -- lr 1.62e-04
2025-03-02 12:56:24,888 - INFO - ðŸªœ Batch step - 1078 -- sub batch step 4315 -- lr 1.62e-04
2025-03-02 12:56:26,458 - INFO - Step 1078 -- ðŸ”„ Training Metrics
2025-03-02 12:56:26,459 - INFO - â”œâ”€â”€ Loss: 7.6785
2025-03-02 12:56:26,459 - INFO - â”œâ”€â”€ Learning Rate: 1.62e-04
2025-03-02 12:56:26,459 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:56:27,126 - INFO - ðŸªœ Batch step - 1079 -- sub batch step 4316 -- lr 1.62e-04
2025-03-02 12:56:29,283 - INFO - ðŸªœ Batch step - 1079 -- sub batch step 4317 -- lr 1.62e-04
2025-03-02 12:56:31,556 - INFO - ðŸªœ Batch step - 1079 -- sub batch step 4318 -- lr 1.62e-04
2025-03-02 12:56:33,712 - INFO - ðŸªœ Batch step - 1079 -- sub batch step 4319 -- lr 1.62e-04
2025-03-02 12:56:35,398 - INFO - Step 1079 -- ðŸ”„ Training Metrics
2025-03-02 12:56:35,399 - INFO - â”œâ”€â”€ Loss: 7.6824
2025-03-02 12:56:35,399 - INFO - â”œâ”€â”€ Learning Rate: 1.62e-04
2025-03-02 12:56:35,399 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:56:36,593 - INFO - ðŸªœ Batch step - 1080 -- sub batch step 4320 -- lr 1.62e-04
2025-03-02 12:56:38,747 - INFO - ðŸªœ Batch step - 1080 -- sub batch step 4321 -- lr 1.62e-04
2025-03-02 12:56:40,906 - INFO - ðŸªœ Batch step - 1080 -- sub batch step 4322 -- lr 1.62e-04
2025-03-02 12:56:43,073 - INFO - ðŸªœ Batch step - 1080 -- sub batch step 4323 -- lr 1.62e-04
2025-03-02 12:56:44,625 - INFO - Step 1080 -- ðŸ”„ Training Metrics
2025-03-02 12:56:44,626 - INFO - â”œâ”€â”€ Loss: 7.6870
2025-03-02 12:56:44,626 - INFO - â”œâ”€â”€ Learning Rate: 1.62e-04
2025-03-02 12:56:44,626 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:56:45,296 - INFO - ðŸªœ Batch step - 1081 -- sub batch step 4324 -- lr 1.62e-04
2025-03-02 12:56:47,451 - INFO - ðŸªœ Batch step - 1081 -- sub batch step 4325 -- lr 1.62e-04
2025-03-02 12:56:49,600 - INFO - ðŸªœ Batch step - 1081 -- sub batch step 4326 -- lr 1.62e-04
2025-03-02 12:56:52,036 - INFO - ðŸªœ Batch step - 1081 -- sub batch step 4327 -- lr 1.62e-04
2025-03-02 12:56:53,873 - INFO - Step 1081 -- ðŸ”„ Training Metrics
2025-03-02 12:56:53,873 - INFO - â”œâ”€â”€ Loss: 7.6645
2025-03-02 12:56:53,873 - INFO - â”œâ”€â”€ Learning Rate: 1.62e-04
2025-03-02 12:56:53,873 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:56:54,536 - INFO - ðŸªœ Batch step - 1082 -- sub batch step 4328 -- lr 1.62e-04
2025-03-02 12:56:56,695 - INFO - ðŸªœ Batch step - 1082 -- sub batch step 4329 -- lr 1.62e-04
2025-03-02 12:56:58,847 - INFO - ðŸªœ Batch step - 1082 -- sub batch step 4330 -- lr 1.62e-04
2025-03-02 12:57:01,013 - INFO - ðŸªœ Batch step - 1082 -- sub batch step 4331 -- lr 1.62e-04
2025-03-02 12:57:02,580 - INFO - Step 1082 -- ðŸ”„ Training Metrics
2025-03-02 12:57:02,581 - INFO - â”œâ”€â”€ Loss: 7.6368
2025-03-02 12:57:02,581 - INFO - â”œâ”€â”€ Learning Rate: 1.62e-04
2025-03-02 12:57:02,581 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:57:03,254 - INFO - ðŸªœ Batch step - 1083 -- sub batch step 4332 -- lr 1.62e-04
2025-03-02 12:57:05,404 - INFO - ðŸªœ Batch step - 1083 -- sub batch step 4333 -- lr 1.62e-04
2025-03-02 12:57:07,560 - INFO - ðŸªœ Batch step - 1083 -- sub batch step 4334 -- lr 1.62e-04
2025-03-02 12:57:10,199 - INFO - ðŸªœ Batch step - 1083 -- sub batch step 4335 -- lr 1.62e-04
2025-03-02 12:57:11,962 - INFO - Step 1083 -- ðŸ”„ Training Metrics
2025-03-02 12:57:11,962 - INFO - â”œâ”€â”€ Loss: 7.6672
2025-03-02 12:57:11,962 - INFO - â”œâ”€â”€ Learning Rate: 1.62e-04
2025-03-02 12:57:11,962 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:57:12,628 - INFO - ðŸªœ Batch step - 1084 -- sub batch step 4336 -- lr 1.63e-04
2025-03-02 12:57:14,782 - INFO - ðŸªœ Batch step - 1084 -- sub batch step 4337 -- lr 1.63e-04
2025-03-02 12:57:16,933 - INFO - ðŸªœ Batch step - 1084 -- sub batch step 4338 -- lr 1.63e-04
2025-03-02 12:57:19,110 - INFO - ðŸªœ Batch step - 1084 -- sub batch step 4339 -- lr 1.63e-04
2025-03-02 12:57:20,673 - INFO - Step 1084 -- ðŸ”„ Training Metrics
2025-03-02 12:57:20,674 - INFO - â”œâ”€â”€ Loss: 7.6492
2025-03-02 12:57:20,674 - INFO - â”œâ”€â”€ Learning Rate: 1.63e-04
2025-03-02 12:57:20,674 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:57:21,346 - INFO - ðŸªœ Batch step - 1085 -- sub batch step 4340 -- lr 1.63e-04
2025-03-02 12:57:23,498 - INFO - ðŸªœ Batch step - 1085 -- sub batch step 4341 -- lr 1.63e-04
2025-03-02 12:57:25,651 - INFO - ðŸªœ Batch step - 1085 -- sub batch step 4342 -- lr 1.63e-04
2025-03-02 12:57:28,044 - INFO - ðŸªœ Batch step - 1085 -- sub batch step 4343 -- lr 1.63e-04
2025-03-02 12:57:29,895 - INFO - Step 1085 -- ðŸ”„ Training Metrics
2025-03-02 12:57:29,895 - INFO - â”œâ”€â”€ Loss: 7.6579
2025-03-02 12:57:29,895 - INFO - â”œâ”€â”€ Learning Rate: 1.63e-04
2025-03-02 12:57:29,896 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:57:30,569 - INFO - ðŸªœ Batch step - 1086 -- sub batch step 4344 -- lr 1.63e-04
2025-03-02 12:57:32,721 - INFO - ðŸªœ Batch step - 1086 -- sub batch step 4345 -- lr 1.63e-04
2025-03-02 12:57:34,867 - INFO - ðŸªœ Batch step - 1086 -- sub batch step 4346 -- lr 1.63e-04
2025-03-02 12:57:37,037 - INFO - ðŸªœ Batch step - 1086 -- sub batch step 4347 -- lr 1.63e-04
2025-03-02 12:57:38,591 - INFO - Step 1086 -- ðŸ”„ Training Metrics
2025-03-02 12:57:38,591 - INFO - â”œâ”€â”€ Loss: 7.6549
2025-03-02 12:57:38,591 - INFO - â”œâ”€â”€ Learning Rate: 1.63e-04
2025-03-02 12:57:38,591 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:57:39,257 - INFO - ðŸªœ Batch step - 1087 -- sub batch step 4348 -- lr 1.63e-04
2025-03-02 12:57:41,413 - INFO - ðŸªœ Batch step - 1087 -- sub batch step 4349 -- lr 1.63e-04
2025-03-02 12:57:43,565 - INFO - ðŸªœ Batch step - 1087 -- sub batch step 4350 -- lr 1.63e-04
2025-03-02 12:57:45,912 - INFO - ðŸªœ Batch step - 1087 -- sub batch step 4351 -- lr 1.63e-04
2025-03-02 12:57:47,865 - INFO - Step 1087 -- ðŸ”„ Training Metrics
2025-03-02 12:57:47,865 - INFO - â”œâ”€â”€ Loss: 7.6468
2025-03-02 12:57:47,865 - INFO - â”œâ”€â”€ Learning Rate: 1.63e-04
2025-03-02 12:57:47,865 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:57:48,537 - INFO - ðŸªœ Batch step - 1088 -- sub batch step 4352 -- lr 1.63e-04
2025-03-02 12:57:50,685 - INFO - ðŸªœ Batch step - 1088 -- sub batch step 4353 -- lr 1.63e-04
2025-03-02 12:57:52,841 - INFO - ðŸªœ Batch step - 1088 -- sub batch step 4354 -- lr 1.63e-04
2025-03-02 12:57:55,007 - INFO - ðŸªœ Batch step - 1088 -- sub batch step 4355 -- lr 1.63e-04
2025-03-02 12:57:56,565 - INFO - Step 1088 -- ðŸ”„ Training Metrics
2025-03-02 12:57:56,565 - INFO - â”œâ”€â”€ Loss: 7.6583
2025-03-02 12:57:56,565 - INFO - â”œâ”€â”€ Learning Rate: 1.63e-04
2025-03-02 12:57:56,565 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:57:57,231 - INFO - ðŸªœ Batch step - 1089 -- sub batch step 4356 -- lr 1.63e-04
2025-03-02 12:57:59,390 - INFO - ðŸªœ Batch step - 1089 -- sub batch step 4357 -- lr 1.63e-04
2025-03-02 12:58:01,540 - INFO - ðŸªœ Batch step - 1089 -- sub batch step 4358 -- lr 1.63e-04
2025-03-02 12:58:04,228 - INFO - ðŸªœ Batch step - 1089 -- sub batch step 4359 -- lr 1.63e-04
2025-03-02 12:58:05,796 - INFO - Step 1089 -- ðŸ”„ Training Metrics
2025-03-02 12:58:05,796 - INFO - â”œâ”€â”€ Loss: 7.6793
2025-03-02 12:58:05,796 - INFO - â”œâ”€â”€ Learning Rate: 1.63e-04
2025-03-02 12:58:05,796 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:58:06,468 - INFO - ðŸªœ Batch step - 1090 -- sub batch step 4360 -- lr 1.63e-04
2025-03-02 12:58:08,621 - INFO - ðŸªœ Batch step - 1090 -- sub batch step 4361 -- lr 1.63e-04
2025-03-02 12:58:10,775 - INFO - ðŸªœ Batch step - 1090 -- sub batch step 4362 -- lr 1.63e-04
2025-03-02 12:58:12,941 - INFO - ðŸªœ Batch step - 1090 -- sub batch step 4363 -- lr 1.63e-04
2025-03-02 12:58:14,487 - INFO - Step 1090 -- ðŸ”„ Training Metrics
2025-03-02 12:58:14,487 - INFO - â”œâ”€â”€ Loss: 7.6869
2025-03-02 12:58:14,487 - INFO - â”œâ”€â”€ Learning Rate: 1.63e-04
2025-03-02 12:58:14,487 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:58:15,158 - INFO - ðŸªœ Batch step - 1091 -- sub batch step 4364 -- lr 1.64e-04
2025-03-02 12:58:17,315 - INFO - ðŸªœ Batch step - 1091 -- sub batch step 4365 -- lr 1.64e-04
2025-03-02 12:58:19,685 - INFO - ðŸªœ Batch step - 1091 -- sub batch step 4366 -- lr 1.64e-04
2025-03-02 12:58:21,843 - INFO - ðŸªœ Batch step - 1091 -- sub batch step 4367 -- lr 1.64e-04
2025-03-02 12:58:24,107 - INFO - Step 1091 -- ðŸ”„ Training Metrics
2025-03-02 12:58:24,108 - INFO - â”œâ”€â”€ Loss: 7.6704
2025-03-02 12:58:24,108 - INFO - â”œâ”€â”€ Learning Rate: 1.64e-04
2025-03-02 12:58:24,108 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:58:24,775 - INFO - ðŸªœ Batch step - 1092 -- sub batch step 4368 -- lr 1.64e-04
2025-03-02 12:58:26,931 - INFO - ðŸªœ Batch step - 1092 -- sub batch step 4369 -- lr 1.64e-04
2025-03-02 12:58:29,098 - INFO - ðŸªœ Batch step - 1092 -- sub batch step 4370 -- lr 1.64e-04
2025-03-02 12:58:31,249 - INFO - ðŸªœ Batch step - 1092 -- sub batch step 4371 -- lr 1.64e-04
2025-03-02 12:58:32,808 - INFO - Step 1092 -- ðŸ”„ Training Metrics
2025-03-02 12:58:32,808 - INFO - â”œâ”€â”€ Loss: 7.6394
2025-03-02 12:58:32,808 - INFO - â”œâ”€â”€ Learning Rate: 1.64e-04
2025-03-02 12:58:32,808 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:58:33,480 - INFO - ðŸªœ Batch step - 1093 -- sub batch step 4372 -- lr 1.64e-04
2025-03-02 12:58:35,629 - INFO - ðŸªœ Batch step - 1093 -- sub batch step 4373 -- lr 1.64e-04
2025-03-02 12:58:38,441 - INFO - ðŸªœ Batch step - 1093 -- sub batch step 4374 -- lr 1.64e-04
2025-03-02 12:58:40,599 - INFO - ðŸªœ Batch step - 1093 -- sub batch step 4375 -- lr 1.64e-04
2025-03-02 12:58:42,300 - INFO - Step 1093 -- ðŸ”„ Training Metrics
2025-03-02 12:58:42,301 - INFO - â”œâ”€â”€ Loss: 7.6702
2025-03-02 12:58:42,301 - INFO - â”œâ”€â”€ Learning Rate: 1.64e-04
2025-03-02 12:58:42,301 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:58:42,964 - INFO - ðŸªœ Batch step - 1094 -- sub batch step 4376 -- lr 1.64e-04
2025-03-02 12:58:45,124 - INFO - ðŸªœ Batch step - 1094 -- sub batch step 4377 -- lr 1.64e-04
2025-03-02 12:58:47,284 - INFO - ðŸªœ Batch step - 1094 -- sub batch step 4378 -- lr 1.64e-04
2025-03-02 12:58:49,442 - INFO - ðŸªœ Batch step - 1094 -- sub batch step 4379 -- lr 1.64e-04
2025-03-02 12:58:50,988 - INFO - Step 1094 -- ðŸ”„ Training Metrics
2025-03-02 12:58:50,988 - INFO - â”œâ”€â”€ Loss: 7.6669
2025-03-02 12:58:50,988 - INFO - â”œâ”€â”€ Learning Rate: 1.64e-04
2025-03-02 12:58:50,988 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:58:51,660 - INFO - ðŸªœ Batch step - 1095 -- sub batch step 4380 -- lr 1.64e-04
2025-03-02 12:58:53,812 - INFO - ðŸªœ Batch step - 1095 -- sub batch step 4381 -- lr 1.64e-04
2025-03-02 12:58:56,491 - INFO - ðŸªœ Batch step - 1095 -- sub batch step 4382 -- lr 1.64e-04
2025-03-02 12:58:58,641 - INFO - ðŸªœ Batch step - 1095 -- sub batch step 4383 -- lr 1.64e-04
2025-03-02 12:59:00,312 - INFO - Step 1095 -- ðŸ”„ Training Metrics
2025-03-02 12:59:00,312 - INFO - â”œâ”€â”€ Loss: 7.6581
2025-03-02 12:59:00,312 - INFO - â”œâ”€â”€ Learning Rate: 1.64e-04
2025-03-02 12:59:00,312 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:59:00,986 - INFO - ðŸªœ Batch step - 1096 -- sub batch step 4384 -- lr 1.64e-04
2025-03-02 12:59:03,141 - INFO - ðŸªœ Batch step - 1096 -- sub batch step 4385 -- lr 1.64e-04
2025-03-02 12:59:05,308 - INFO - ðŸªœ Batch step - 1096 -- sub batch step 4386 -- lr 1.64e-04
2025-03-02 12:59:07,461 - INFO - ðŸªœ Batch step - 1096 -- sub batch step 4387 -- lr 1.64e-04
2025-03-02 12:59:09,011 - INFO - Step 1096 -- ðŸ”„ Training Metrics
2025-03-02 12:59:09,012 - INFO - â”œâ”€â”€ Loss: 7.6533
2025-03-02 12:59:09,012 - INFO - â”œâ”€â”€ Learning Rate: 1.64e-04
2025-03-02 12:59:09,012 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:59:09,675 - INFO - ðŸªœ Batch step - 1097 -- sub batch step 4388 -- lr 1.65e-04
2025-03-02 12:59:11,839 - INFO - ðŸªœ Batch step - 1097 -- sub batch step 4389 -- lr 1.65e-04
2025-03-02 12:59:14,733 - INFO - ðŸªœ Batch step - 1097 -- sub batch step 4390 -- lr 1.65e-04
2025-03-02 12:59:16,883 - INFO - ðŸªœ Batch step - 1097 -- sub batch step 4391 -- lr 1.65e-04
2025-03-02 12:59:18,464 - INFO - Step 1097 -- ðŸ”„ Training Metrics
2025-03-02 12:59:18,464 - INFO - â”œâ”€â”€ Loss: 7.6417
2025-03-02 12:59:18,464 - INFO - â”œâ”€â”€ Learning Rate: 1.65e-04
2025-03-02 12:59:18,464 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:59:19,136 - INFO - ðŸªœ Batch step - 1098 -- sub batch step 4392 -- lr 1.65e-04
2025-03-02 12:59:21,285 - INFO - ðŸªœ Batch step - 1098 -- sub batch step 4393 -- lr 1.65e-04
2025-03-02 12:59:23,453 - INFO - ðŸªœ Batch step - 1098 -- sub batch step 4394 -- lr 1.65e-04
2025-03-02 12:59:25,606 - INFO - ðŸªœ Batch step - 1098 -- sub batch step 4395 -- lr 1.65e-04
2025-03-02 12:59:27,158 - INFO - Step 1098 -- ðŸ”„ Training Metrics
2025-03-02 12:59:27,158 - INFO - â”œâ”€â”€ Loss: 7.6636
2025-03-02 12:59:27,158 - INFO - â”œâ”€â”€ Learning Rate: 1.65e-04
2025-03-02 12:59:27,159 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:59:27,824 - INFO - ðŸªœ Batch step - 1099 -- sub batch step 4396 -- lr 1.65e-04
2025-03-02 12:59:29,978 - INFO - ðŸªœ Batch step - 1099 -- sub batch step 4397 -- lr 1.65e-04
2025-03-02 12:59:32,261 - INFO - ðŸªœ Batch step - 1099 -- sub batch step 4398 -- lr 1.65e-04
2025-03-02 12:59:34,411 - INFO - ðŸªœ Batch step - 1099 -- sub batch step 4399 -- lr 1.65e-04
2025-03-02 12:59:35,960 - INFO - Step 1099 -- ðŸ”„ Training Metrics
2025-03-02 12:59:35,961 - INFO - â”œâ”€â”€ Loss: 7.6576
2025-03-02 12:59:35,961 - INFO - â”œâ”€â”€ Learning Rate: 1.65e-04
2025-03-02 12:59:35,961 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:59:37,091 - INFO - ðŸªœ Batch step - 1100 -- sub batch step 4400 -- lr 1.65e-04
2025-03-02 12:59:39,244 - INFO - ðŸªœ Batch step - 1100 -- sub batch step 4401 -- lr 1.65e-04
2025-03-02 12:59:41,403 - INFO - ðŸªœ Batch step - 1100 -- sub batch step 4402 -- lr 1.65e-04
2025-03-02 12:59:43,573 - INFO - ðŸªœ Batch step - 1100 -- sub batch step 4403 -- lr 1.65e-04
2025-03-02 12:59:45,218 - INFO - Step 1100 -- ðŸ”„ Training Metrics
2025-03-02 12:59:45,218 - INFO - â”œâ”€â”€ Loss: 7.6462
2025-03-02 12:59:45,219 - INFO - â”œâ”€â”€ Learning Rate: 1.65e-04
2025-03-02 12:59:45,219 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:59:45,896 - INFO - ðŸªœ Batch step - 1101 -- sub batch step 4404 -- lr 1.65e-04
2025-03-02 12:59:48,048 - INFO - ðŸªœ Batch step - 1101 -- sub batch step 4405 -- lr 1.65e-04
2025-03-02 12:59:50,196 - INFO - ðŸªœ Batch step - 1101 -- sub batch step 4406 -- lr 1.65e-04
2025-03-02 12:59:52,703 - INFO - ðŸªœ Batch step - 1101 -- sub batch step 4407 -- lr 1.65e-04
2025-03-02 12:59:54,344 - INFO - Step 1101 -- ðŸ”„ Training Metrics
2025-03-02 12:59:54,344 - INFO - â”œâ”€â”€ Loss: 7.6222
2025-03-02 12:59:54,344 - INFO - â”œâ”€â”€ Learning Rate: 1.65e-04
2025-03-02 12:59:54,345 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 12:59:55,011 - INFO - ðŸªœ Batch step - 1102 -- sub batch step 4408 -- lr 1.65e-04
2025-03-02 12:59:57,174 - INFO - ðŸªœ Batch step - 1102 -- sub batch step 4409 -- lr 1.65e-04
2025-03-02 12:59:59,330 - INFO - ðŸªœ Batch step - 1102 -- sub batch step 4410 -- lr 1.65e-04
2025-03-02 13:00:01,498 - INFO - ðŸªœ Batch step - 1102 -- sub batch step 4411 -- lr 1.65e-04
2025-03-02 13:00:03,057 - INFO - Step 1102 -- ðŸ”„ Training Metrics
2025-03-02 13:00:03,058 - INFO - â”œâ”€â”€ Loss: 7.6402
2025-03-02 13:00:03,058 - INFO - â”œâ”€â”€ Learning Rate: 1.65e-04
2025-03-02 13:00:03,058 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:00:03,733 - INFO - ðŸªœ Batch step - 1103 -- sub batch step 4412 -- lr 1.65e-04
2025-03-02 13:00:05,883 - INFO - ðŸªœ Batch step - 1103 -- sub batch step 4413 -- lr 1.65e-04
2025-03-02 13:00:08,042 - INFO - ðŸªœ Batch step - 1103 -- sub batch step 4414 -- lr 1.65e-04
2025-03-02 13:00:10,820 - INFO - ðŸªœ Batch step - 1103 -- sub batch step 4415 -- lr 1.65e-04
2025-03-02 13:00:12,344 - INFO - Step 1103 -- ðŸ”„ Training Metrics
2025-03-02 13:00:12,344 - INFO - â”œâ”€â”€ Loss: 7.6226
2025-03-02 13:00:12,344 - INFO - â”œâ”€â”€ Learning Rate: 1.65e-04
2025-03-02 13:00:12,344 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:00:13,013 - INFO - ðŸªœ Batch step - 1104 -- sub batch step 4416 -- lr 1.66e-04
2025-03-02 13:00:15,174 - INFO - ðŸªœ Batch step - 1104 -- sub batch step 4417 -- lr 1.66e-04
2025-03-02 13:00:17,320 - INFO - ðŸªœ Batch step - 1104 -- sub batch step 4418 -- lr 1.66e-04
2025-03-02 13:00:19,494 - INFO - ðŸªœ Batch step - 1104 -- sub batch step 4419 -- lr 1.66e-04
2025-03-02 13:00:21,040 - INFO - Step 1104 -- ðŸ”„ Training Metrics
2025-03-02 13:00:21,040 - INFO - â”œâ”€â”€ Loss: 7.6524
2025-03-02 13:00:21,040 - INFO - â”œâ”€â”€ Learning Rate: 1.66e-04
2025-03-02 13:00:21,040 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:00:21,715 - INFO - ðŸªœ Batch step - 1105 -- sub batch step 4420 -- lr 1.66e-04
2025-03-02 13:00:23,870 - INFO - ðŸªœ Batch step - 1105 -- sub batch step 4421 -- lr 1.66e-04
2025-03-02 13:00:26,025 - INFO - ðŸªœ Batch step - 1105 -- sub batch step 4422 -- lr 1.66e-04
2025-03-02 13:00:28,554 - INFO - ðŸªœ Batch step - 1105 -- sub batch step 4423 -- lr 1.66e-04
2025-03-02 13:00:30,343 - INFO - Step 1105 -- ðŸ”„ Training Metrics
2025-03-02 13:00:30,343 - INFO - â”œâ”€â”€ Loss: 7.6127
2025-03-02 13:00:30,343 - INFO - â”œâ”€â”€ Learning Rate: 1.66e-04
2025-03-02 13:00:30,343 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:00:31,015 - INFO - ðŸªœ Batch step - 1106 -- sub batch step 4424 -- lr 1.66e-04
2025-03-02 13:00:33,170 - INFO - ðŸªœ Batch step - 1106 -- sub batch step 4425 -- lr 1.66e-04
2025-03-02 13:00:35,321 - INFO - ðŸªœ Batch step - 1106 -- sub batch step 4426 -- lr 1.66e-04
2025-03-02 13:00:37,491 - INFO - ðŸªœ Batch step - 1106 -- sub batch step 4427 -- lr 1.66e-04
2025-03-02 13:00:39,048 - INFO - Step 1106 -- ðŸ”„ Training Metrics
2025-03-02 13:00:39,048 - INFO - â”œâ”€â”€ Loss: 7.6419
2025-03-02 13:00:39,048 - INFO - â”œâ”€â”€ Learning Rate: 1.66e-04
2025-03-02 13:00:39,048 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:00:39,715 - INFO - ðŸªœ Batch step - 1107 -- sub batch step 4428 -- lr 1.66e-04
2025-03-02 13:00:41,875 - INFO - ðŸªœ Batch step - 1107 -- sub batch step 4429 -- lr 1.66e-04
2025-03-02 13:00:44,031 - INFO - ðŸªœ Batch step - 1107 -- sub batch step 4430 -- lr 1.66e-04
2025-03-02 13:00:46,742 - INFO - ðŸªœ Batch step - 1107 -- sub batch step 4431 -- lr 1.66e-04
2025-03-02 13:00:48,320 - INFO - Step 1107 -- ðŸ”„ Training Metrics
2025-03-02 13:00:48,320 - INFO - â”œâ”€â”€ Loss: 7.6494
2025-03-02 13:00:48,320 - INFO - â”œâ”€â”€ Learning Rate: 1.66e-04
2025-03-02 13:00:48,320 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:00:48,995 - INFO - ðŸªœ Batch step - 1108 -- sub batch step 4432 -- lr 1.66e-04
2025-03-02 13:00:51,148 - INFO - ðŸªœ Batch step - 1108 -- sub batch step 4433 -- lr 1.66e-04
2025-03-02 13:00:53,307 - INFO - ðŸªœ Batch step - 1108 -- sub batch step 4434 -- lr 1.66e-04
2025-03-02 13:00:55,480 - INFO - ðŸªœ Batch step - 1108 -- sub batch step 4435 -- lr 1.66e-04
2025-03-02 13:00:57,022 - INFO - Step 1108 -- ðŸ”„ Training Metrics
2025-03-02 13:00:57,023 - INFO - â”œâ”€â”€ Loss: 7.6274
2025-03-02 13:00:57,023 - INFO - â”œâ”€â”€ Learning Rate: 1.66e-04
2025-03-02 13:00:57,023 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:00:57,690 - INFO - ðŸªœ Batch step - 1109 -- sub batch step 4436 -- lr 1.66e-04
2025-03-02 13:00:59,849 - INFO - ðŸªœ Batch step - 1109 -- sub batch step 4437 -- lr 1.66e-04
2025-03-02 13:01:02,002 - INFO - ðŸªœ Batch step - 1109 -- sub batch step 4438 -- lr 1.66e-04
2025-03-02 13:01:04,691 - INFO - ðŸªœ Batch step - 1109 -- sub batch step 4439 -- lr 1.66e-04
2025-03-02 13:01:06,250 - INFO - Step 1109 -- ðŸ”„ Training Metrics
2025-03-02 13:01:06,250 - INFO - â”œâ”€â”€ Loss: 7.6456
2025-03-02 13:01:06,250 - INFO - â”œâ”€â”€ Learning Rate: 1.66e-04
2025-03-02 13:01:06,251 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:01:06,923 - INFO - ðŸªœ Batch step - 1110 -- sub batch step 4440 -- lr 1.67e-04
2025-03-02 13:01:09,076 - INFO - ðŸªœ Batch step - 1110 -- sub batch step 4441 -- lr 1.67e-04
2025-03-02 13:01:11,231 - INFO - ðŸªœ Batch step - 1110 -- sub batch step 4442 -- lr 1.67e-04
2025-03-02 13:01:13,400 - INFO - ðŸªœ Batch step - 1110 -- sub batch step 4443 -- lr 1.67e-04
2025-03-02 13:01:14,940 - INFO - Step 1110 -- ðŸ”„ Training Metrics
2025-03-02 13:01:14,940 - INFO - â”œâ”€â”€ Loss: 7.6400
2025-03-02 13:01:14,940 - INFO - â”œâ”€â”€ Learning Rate: 1.67e-04
2025-03-02 13:01:14,940 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:01:15,618 - INFO - ðŸªœ Batch step - 1111 -- sub batch step 4444 -- lr 1.67e-04
2025-03-02 13:01:17,775 - INFO - ðŸªœ Batch step - 1111 -- sub batch step 4445 -- lr 1.67e-04
2025-03-02 13:01:20,681 - INFO - ðŸªœ Batch step - 1111 -- sub batch step 4446 -- lr 1.67e-04
2025-03-02 13:01:22,838 - INFO - ðŸªœ Batch step - 1111 -- sub batch step 4447 -- lr 1.67e-04
2025-03-02 13:01:24,348 - INFO - Step 1111 -- ðŸ”„ Training Metrics
2025-03-02 13:01:24,348 - INFO - â”œâ”€â”€ Loss: 7.6263
2025-03-02 13:01:24,348 - INFO - â”œâ”€â”€ Learning Rate: 1.67e-04
2025-03-02 13:01:24,348 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:01:25,016 - INFO - ðŸªœ Batch step - 1112 -- sub batch step 4448 -- lr 1.67e-04
2025-03-02 13:01:27,171 - INFO - ðŸªœ Batch step - 1112 -- sub batch step 4449 -- lr 1.67e-04
2025-03-02 13:01:29,341 - INFO - ðŸªœ Batch step - 1112 -- sub batch step 4450 -- lr 1.67e-04
2025-03-02 13:01:31,496 - INFO - ðŸªœ Batch step - 1112 -- sub batch step 4451 -- lr 1.67e-04
2025-03-02 13:01:33,057 - INFO - Step 1112 -- ðŸ”„ Training Metrics
2025-03-02 13:01:33,057 - INFO - â”œâ”€â”€ Loss: 7.6334
2025-03-02 13:01:33,057 - INFO - â”œâ”€â”€ Learning Rate: 1.67e-04
2025-03-02 13:01:33,057 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:01:33,737 - INFO - ðŸªœ Batch step - 1113 -- sub batch step 4452 -- lr 1.67e-04
2025-03-02 13:01:35,889 - INFO - ðŸªœ Batch step - 1113 -- sub batch step 4453 -- lr 1.67e-04
2025-03-02 13:01:38,399 - INFO - ðŸªœ Batch step - 1113 -- sub batch step 4454 -- lr 1.67e-04
2025-03-02 13:01:40,556 - INFO - ðŸªœ Batch step - 1113 -- sub batch step 4455 -- lr 1.67e-04
2025-03-02 13:01:42,247 - INFO - Step 1113 -- ðŸ”„ Training Metrics
2025-03-02 13:01:42,248 - INFO - â”œâ”€â”€ Loss: 7.6546
2025-03-02 13:01:42,248 - INFO - â”œâ”€â”€ Learning Rate: 1.67e-04
2025-03-02 13:01:42,248 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:01:42,919 - INFO - ðŸªœ Batch step - 1114 -- sub batch step 4456 -- lr 1.67e-04
2025-03-02 13:01:45,075 - INFO - ðŸªœ Batch step - 1114 -- sub batch step 4457 -- lr 1.67e-04
2025-03-02 13:01:47,236 - INFO - ðŸªœ Batch step - 1114 -- sub batch step 4458 -- lr 1.67e-04
2025-03-02 13:01:49,390 - INFO - ðŸªœ Batch step - 1114 -- sub batch step 4459 -- lr 1.67e-04
2025-03-02 13:01:50,940 - INFO - Step 1114 -- ðŸ”„ Training Metrics
2025-03-02 13:01:50,940 - INFO - â”œâ”€â”€ Loss: 7.6243
2025-03-02 13:01:50,940 - INFO - â”œâ”€â”€ Learning Rate: 1.67e-04
2025-03-02 13:01:50,940 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:01:51,614 - INFO - ðŸªœ Batch step - 1115 -- sub batch step 4460 -- lr 1.67e-04
2025-03-02 13:01:53,763 - INFO - ðŸªœ Batch step - 1115 -- sub batch step 4461 -- lr 1.67e-04
2025-03-02 13:01:56,295 - INFO - ðŸªœ Batch step - 1115 -- sub batch step 4462 -- lr 1.67e-04
2025-03-02 13:01:58,439 - INFO - ðŸªœ Batch step - 1115 -- sub batch step 4463 -- lr 1.67e-04
2025-03-02 13:02:00,107 - INFO - Step 1115 -- ðŸ”„ Training Metrics
2025-03-02 13:02:00,107 - INFO - â”œâ”€â”€ Loss: 7.6271
2025-03-02 13:02:00,107 - INFO - â”œâ”€â”€ Learning Rate: 1.67e-04
2025-03-02 13:02:00,107 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:02:00,778 - INFO - ðŸªœ Batch step - 1116 -- sub batch step 4464 -- lr 1.67e-04
2025-03-02 13:02:02,932 - INFO - ðŸªœ Batch step - 1116 -- sub batch step 4465 -- lr 1.67e-04
2025-03-02 13:02:05,106 - INFO - ðŸªœ Batch step - 1116 -- sub batch step 4466 -- lr 1.67e-04
2025-03-02 13:02:07,264 - INFO - ðŸªœ Batch step - 1116 -- sub batch step 4467 -- lr 1.67e-04
2025-03-02 13:02:08,844 - INFO - Step 1116 -- ðŸ”„ Training Metrics
2025-03-02 13:02:08,844 - INFO - â”œâ”€â”€ Loss: 7.6061
2025-03-02 13:02:08,844 - INFO - â”œâ”€â”€ Learning Rate: 1.67e-04
2025-03-02 13:02:08,844 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:02:09,509 - INFO - ðŸªœ Batch step - 1117 -- sub batch step 4468 -- lr 1.68e-04
2025-03-02 13:02:11,667 - INFO - ðŸªœ Batch step - 1117 -- sub batch step 4469 -- lr 1.68e-04
2025-03-02 13:02:14,231 - INFO - ðŸªœ Batch step - 1117 -- sub batch step 4470 -- lr 1.68e-04
2025-03-02 13:02:16,381 - INFO - ðŸªœ Batch step - 1117 -- sub batch step 4471 -- lr 1.68e-04
2025-03-02 13:02:18,007 - INFO - Step 1117 -- ðŸ”„ Training Metrics
2025-03-02 13:02:18,007 - INFO - â”œâ”€â”€ Loss: 7.5986
2025-03-02 13:02:18,007 - INFO - â”œâ”€â”€ Learning Rate: 1.68e-04
2025-03-02 13:02:18,007 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:02:18,684 - INFO - ðŸªœ Batch step - 1118 -- sub batch step 4472 -- lr 1.68e-04
2025-03-02 13:02:20,833 - INFO - ðŸªœ Batch step - 1118 -- sub batch step 4473 -- lr 1.68e-04
2025-03-02 13:02:23,005 - INFO - ðŸªœ Batch step - 1118 -- sub batch step 4474 -- lr 1.68e-04
2025-03-02 13:02:25,155 - INFO - ðŸªœ Batch step - 1118 -- sub batch step 4475 -- lr 1.68e-04
2025-03-02 13:02:26,708 - INFO - Step 1118 -- ðŸ”„ Training Metrics
2025-03-02 13:02:26,708 - INFO - â”œâ”€â”€ Loss: 7.6187
2025-03-02 13:02:26,708 - INFO - â”œâ”€â”€ Learning Rate: 1.68e-04
2025-03-02 13:02:26,708 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:02:27,375 - INFO - ðŸªœ Batch step - 1119 -- sub batch step 4476 -- lr 1.68e-04
2025-03-02 13:02:29,531 - INFO - ðŸªœ Batch step - 1119 -- sub batch step 4477 -- lr 1.68e-04
2025-03-02 13:02:31,992 - INFO - ðŸªœ Batch step - 1119 -- sub batch step 4478 -- lr 1.68e-04
2025-03-02 13:02:34,151 - INFO - ðŸªœ Batch step - 1119 -- sub batch step 4479 -- lr 1.68e-04
2025-03-02 13:02:35,641 - INFO - Step 1119 -- ðŸ”„ Training Metrics
2025-03-02 13:02:35,642 - INFO - â”œâ”€â”€ Loss: 7.6390
2025-03-02 13:02:35,642 - INFO - â”œâ”€â”€ Learning Rate: 1.68e-04
2025-03-02 13:02:35,642 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:02:36,963 - INFO - ðŸªœ Batch step - 1120 -- sub batch step 4480 -- lr 1.68e-04
2025-03-02 13:02:39,119 - INFO - ðŸªœ Batch step - 1120 -- sub batch step 4481 -- lr 1.68e-04
2025-03-02 13:02:41,273 - INFO - ðŸªœ Batch step - 1120 -- sub batch step 4482 -- lr 1.68e-04
2025-03-02 13:02:43,441 - INFO - ðŸªœ Batch step - 1120 -- sub batch step 4483 -- lr 1.68e-04
2025-03-02 13:02:44,997 - INFO - Step 1120 -- ðŸ”„ Training Metrics
2025-03-02 13:02:44,997 - INFO - â”œâ”€â”€ Loss: 7.6229
2025-03-02 13:02:44,998 - INFO - â”œâ”€â”€ Learning Rate: 1.68e-04
2025-03-02 13:02:44,998 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:02:45,672 - INFO - ðŸªœ Batch step - 1121 -- sub batch step 4484 -- lr 1.68e-04
2025-03-02 13:02:47,824 - INFO - ðŸªœ Batch step - 1121 -- sub batch step 4485 -- lr 1.68e-04
2025-03-02 13:02:49,970 - INFO - ðŸªœ Batch step - 1121 -- sub batch step 4486 -- lr 1.68e-04
2025-03-02 13:02:52,527 - INFO - ðŸªœ Batch step - 1121 -- sub batch step 4487 -- lr 1.68e-04
2025-03-02 13:02:54,069 - INFO - Step 1121 -- ðŸ”„ Training Metrics
2025-03-02 13:02:54,070 - INFO - â”œâ”€â”€ Loss: 7.6355
2025-03-02 13:02:54,070 - INFO - â”œâ”€â”€ Learning Rate: 1.68e-04
2025-03-02 13:02:54,070 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:02:54,734 - INFO - ðŸªœ Batch step - 1122 -- sub batch step 4488 -- lr 1.68e-04
2025-03-02 13:02:56,892 - INFO - ðŸªœ Batch step - 1122 -- sub batch step 4489 -- lr 1.68e-04
2025-03-02 13:02:59,048 - INFO - ðŸªœ Batch step - 1122 -- sub batch step 4490 -- lr 1.68e-04
2025-03-02 13:03:01,210 - INFO - ðŸªœ Batch step - 1122 -- sub batch step 4491 -- lr 1.68e-04
2025-03-02 13:03:02,762 - INFO - Step 1122 -- ðŸ”„ Training Metrics
2025-03-02 13:03:02,762 - INFO - â”œâ”€â”€ Loss: 7.6299
2025-03-02 13:03:02,762 - INFO - â”œâ”€â”€ Learning Rate: 1.68e-04
2025-03-02 13:03:02,762 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:03:03,435 - INFO - ðŸªœ Batch step - 1123 -- sub batch step 4492 -- lr 1.68e-04
2025-03-02 13:03:05,584 - INFO - ðŸªœ Batch step - 1123 -- sub batch step 4493 -- lr 1.68e-04
2025-03-02 13:03:07,741 - INFO - ðŸªœ Batch step - 1123 -- sub batch step 4494 -- lr 1.68e-04
2025-03-02 13:03:10,425 - INFO - ðŸªœ Batch step - 1123 -- sub batch step 4495 -- lr 1.68e-04
2025-03-02 13:03:12,124 - INFO - Step 1123 -- ðŸ”„ Training Metrics
2025-03-02 13:03:12,124 - INFO - â”œâ”€â”€ Loss: 7.6023
2025-03-02 13:03:12,124 - INFO - â”œâ”€â”€ Learning Rate: 1.68e-04
2025-03-02 13:03:12,124 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:03:12,789 - INFO - ðŸªœ Batch step - 1124 -- sub batch step 4496 -- lr 1.69e-04
2025-03-02 13:03:14,942 - INFO - ðŸªœ Batch step - 1124 -- sub batch step 4497 -- lr 1.69e-04
2025-03-02 13:03:17,102 - INFO - ðŸªœ Batch step - 1124 -- sub batch step 4498 -- lr 1.69e-04
2025-03-02 13:03:19,267 - INFO - ðŸªœ Batch step - 1124 -- sub batch step 4499 -- lr 1.69e-04
2025-03-02 13:03:20,821 - INFO - Step 1124 -- ðŸ”„ Training Metrics
2025-03-02 13:03:20,821 - INFO - â”œâ”€â”€ Loss: 7.5903
2025-03-02 13:03:20,821 - INFO - â”œâ”€â”€ Learning Rate: 1.69e-04
2025-03-02 13:03:20,821 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:03:21,492 - INFO - ðŸªœ Batch step - 1125 -- sub batch step 4500 -- lr 1.69e-04
2025-03-02 13:03:23,641 - INFO - ðŸªœ Batch step - 1125 -- sub batch step 4501 -- lr 1.69e-04
2025-03-02 13:03:25,795 - INFO - ðŸªœ Batch step - 1125 -- sub batch step 4502 -- lr 1.69e-04
2025-03-02 13:03:28,540 - INFO - ðŸªœ Batch step - 1125 -- sub batch step 4503 -- lr 1.69e-04
2025-03-02 13:03:30,031 - INFO - Step 1125 -- ðŸ”„ Training Metrics
2025-03-02 13:03:30,031 - INFO - â”œâ”€â”€ Loss: 7.6145
2025-03-02 13:03:30,031 - INFO - â”œâ”€â”€ Learning Rate: 1.69e-04
2025-03-02 13:03:30,031 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:03:30,705 - INFO - ðŸªœ Batch step - 1126 -- sub batch step 4504 -- lr 1.69e-04
2025-03-02 13:03:32,860 - INFO - ðŸªœ Batch step - 1126 -- sub batch step 4505 -- lr 1.69e-04
2025-03-02 13:03:35,008 - INFO - ðŸªœ Batch step - 1126 -- sub batch step 4506 -- lr 1.69e-04
2025-03-02 13:03:37,183 - INFO - ðŸªœ Batch step - 1126 -- sub batch step 4507 -- lr 1.69e-04
2025-03-02 13:03:38,738 - INFO - Step 1126 -- ðŸ”„ Training Metrics
2025-03-02 13:03:38,739 - INFO - â”œâ”€â”€ Loss: 7.6155
2025-03-02 13:03:38,739 - INFO - â”œâ”€â”€ Learning Rate: 1.69e-04
2025-03-02 13:03:38,739 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:03:39,404 - INFO - ðŸªœ Batch step - 1127 -- sub batch step 4508 -- lr 1.69e-04
2025-03-02 13:03:41,565 - INFO - ðŸªœ Batch step - 1127 -- sub batch step 4509 -- lr 1.69e-04
2025-03-02 13:03:43,719 - INFO - ðŸªœ Batch step - 1127 -- sub batch step 4510 -- lr 1.69e-04
2025-03-02 13:03:46,373 - INFO - ðŸªœ Batch step - 1127 -- sub batch step 4511 -- lr 1.69e-04
2025-03-02 13:03:47,967 - INFO - Step 1127 -- ðŸ”„ Training Metrics
2025-03-02 13:03:47,967 - INFO - â”œâ”€â”€ Loss: 7.6175
2025-03-02 13:03:47,967 - INFO - â”œâ”€â”€ Learning Rate: 1.69e-04
2025-03-02 13:03:47,968 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:03:48,639 - INFO - ðŸªœ Batch step - 1128 -- sub batch step 4512 -- lr 1.69e-04
2025-03-02 13:03:50,786 - INFO - ðŸªœ Batch step - 1128 -- sub batch step 4513 -- lr 1.69e-04
2025-03-02 13:03:52,938 - INFO - ðŸªœ Batch step - 1128 -- sub batch step 4514 -- lr 1.69e-04
2025-03-02 13:03:55,105 - INFO - ðŸªœ Batch step - 1128 -- sub batch step 4515 -- lr 1.69e-04
2025-03-02 13:03:56,676 - INFO - Step 1128 -- ðŸ”„ Training Metrics
2025-03-02 13:03:56,677 - INFO - â”œâ”€â”€ Loss: 7.6300
2025-03-02 13:03:56,677 - INFO - â”œâ”€â”€ Learning Rate: 1.69e-04
2025-03-02 13:03:56,677 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:03:57,346 - INFO - ðŸªœ Batch step - 1129 -- sub batch step 4516 -- lr 1.69e-04
2025-03-02 13:03:59,503 - INFO - ðŸªœ Batch step - 1129 -- sub batch step 4517 -- lr 1.69e-04
2025-03-02 13:04:01,649 - INFO - ðŸªœ Batch step - 1129 -- sub batch step 4518 -- lr 1.69e-04
2025-03-02 13:04:04,124 - INFO - ðŸªœ Batch step - 1129 -- sub batch step 4519 -- lr 1.69e-04
2025-03-02 13:04:06,004 - INFO - Step 1129 -- ðŸ”„ Training Metrics
2025-03-02 13:04:06,005 - INFO - â”œâ”€â”€ Loss: 7.6163
2025-03-02 13:04:06,005 - INFO - â”œâ”€â”€ Learning Rate: 1.69e-04
2025-03-02 13:04:06,005 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:04:06,677 - INFO - ðŸªœ Batch step - 1130 -- sub batch step 4520 -- lr 1.69e-04
2025-03-02 13:04:08,829 - INFO - ðŸªœ Batch step - 1130 -- sub batch step 4521 -- lr 1.69e-04
2025-03-02 13:04:10,981 - INFO - ðŸªœ Batch step - 1130 -- sub batch step 4522 -- lr 1.69e-04
2025-03-02 13:04:13,146 - INFO - ðŸªœ Batch step - 1130 -- sub batch step 4523 -- lr 1.69e-04
2025-03-02 13:04:14,696 - INFO - Step 1130 -- ðŸ”„ Training Metrics
2025-03-02 13:04:14,697 - INFO - â”œâ”€â”€ Loss: 7.6273
2025-03-02 13:04:14,697 - INFO - â”œâ”€â”€ Learning Rate: 1.69e-04
2025-03-02 13:04:14,697 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:04:15,371 - INFO - ðŸªœ Batch step - 1131 -- sub batch step 4524 -- lr 1.70e-04
2025-03-02 13:04:17,524 - INFO - ðŸªœ Batch step - 1131 -- sub batch step 4525 -- lr 1.70e-04
2025-03-02 13:04:19,952 - INFO - ðŸªœ Batch step - 1131 -- sub batch step 4526 -- lr 1.70e-04
2025-03-02 13:04:22,105 - INFO - ðŸªœ Batch step - 1131 -- sub batch step 4527 -- lr 1.70e-04
2025-03-02 13:04:24,041 - INFO - Step 1131 -- ðŸ”„ Training Metrics
2025-03-02 13:04:24,041 - INFO - â”œâ”€â”€ Loss: 7.6222
2025-03-02 13:04:24,042 - INFO - â”œâ”€â”€ Learning Rate: 1.70e-04
2025-03-02 13:04:24,042 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:04:24,707 - INFO - ðŸªœ Batch step - 1132 -- sub batch step 4528 -- lr 1.70e-04
2025-03-02 13:04:26,870 - INFO - ðŸªœ Batch step - 1132 -- sub batch step 4529 -- lr 1.70e-04
2025-03-02 13:04:29,037 - INFO - ðŸªœ Batch step - 1132 -- sub batch step 4530 -- lr 1.70e-04
2025-03-02 13:04:31,187 - INFO - ðŸªœ Batch step - 1132 -- sub batch step 4531 -- lr 1.70e-04
2025-03-02 13:04:32,747 - INFO - Step 1132 -- ðŸ”„ Training Metrics
2025-03-02 13:04:32,747 - INFO - â”œâ”€â”€ Loss: 7.6206
2025-03-02 13:04:32,747 - INFO - â”œâ”€â”€ Learning Rate: 1.70e-04
2025-03-02 13:04:32,747 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:04:33,419 - INFO - ðŸªœ Batch step - 1133 -- sub batch step 4532 -- lr 1.70e-04
2025-03-02 13:04:35,567 - INFO - ðŸªœ Batch step - 1133 -- sub batch step 4533 -- lr 1.70e-04
2025-03-02 13:04:38,275 - INFO - ðŸªœ Batch step - 1133 -- sub batch step 4534 -- lr 1.70e-04
2025-03-02 13:04:40,428 - INFO - ðŸªœ Batch step - 1133 -- sub batch step 4535 -- lr 1.70e-04
2025-03-02 13:04:41,995 - INFO - Step 1133 -- ðŸ”„ Training Metrics
2025-03-02 13:04:41,995 - INFO - â”œâ”€â”€ Loss: 7.6341
2025-03-02 13:04:41,996 - INFO - â”œâ”€â”€ Learning Rate: 1.70e-04
2025-03-02 13:04:41,996 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:04:42,662 - INFO - ðŸªœ Batch step - 1134 -- sub batch step 4536 -- lr 1.70e-04
2025-03-02 13:04:44,822 - INFO - ðŸªœ Batch step - 1134 -- sub batch step 4537 -- lr 1.70e-04
2025-03-02 13:04:46,982 - INFO - ðŸªœ Batch step - 1134 -- sub batch step 4538 -- lr 1.70e-04
2025-03-02 13:04:49,139 - INFO - ðŸªœ Batch step - 1134 -- sub batch step 4539 -- lr 1.70e-04
2025-03-02 13:04:50,692 - INFO - Step 1134 -- ðŸ”„ Training Metrics
2025-03-02 13:04:50,692 - INFO - â”œâ”€â”€ Loss: 7.6079
2025-03-02 13:04:50,692 - INFO - â”œâ”€â”€ Learning Rate: 1.70e-04
2025-03-02 13:04:50,692 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:04:51,366 - INFO - ðŸªœ Batch step - 1135 -- sub batch step 4540 -- lr 1.70e-04
2025-03-02 13:04:53,519 - INFO - ðŸªœ Batch step - 1135 -- sub batch step 4541 -- lr 1.70e-04
2025-03-02 13:04:56,236 - INFO - ðŸªœ Batch step - 1135 -- sub batch step 4542 -- lr 1.70e-04
2025-03-02 13:04:58,382 - INFO - ðŸªœ Batch step - 1135 -- sub batch step 4543 -- lr 1.70e-04
2025-03-02 13:04:59,922 - INFO - Step 1135 -- ðŸ”„ Training Metrics
2025-03-02 13:04:59,922 - INFO - â”œâ”€â”€ Loss: 7.5948
2025-03-02 13:04:59,922 - INFO - â”œâ”€â”€ Learning Rate: 1.70e-04
2025-03-02 13:04:59,922 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:05:00,597 - INFO - ðŸªœ Batch step - 1136 -- sub batch step 4544 -- lr 1.70e-04
2025-03-02 13:05:02,750 - INFO - ðŸªœ Batch step - 1136 -- sub batch step 4545 -- lr 1.70e-04
2025-03-02 13:05:04,912 - INFO - ðŸªœ Batch step - 1136 -- sub batch step 4546 -- lr 1.70e-04
2025-03-02 13:05:07,066 - INFO - ðŸªœ Batch step - 1136 -- sub batch step 4547 -- lr 1.70e-04
2025-03-02 13:05:08,623 - INFO - Step 1136 -- ðŸ”„ Training Metrics
2025-03-02 13:05:08,623 - INFO - â”œâ”€â”€ Loss: 7.5760
2025-03-02 13:05:08,623 - INFO - â”œâ”€â”€ Learning Rate: 1.70e-04
2025-03-02 13:05:08,624 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:05:09,292 - INFO - ðŸªœ Batch step - 1137 -- sub batch step 4548 -- lr 1.71e-04
2025-03-02 13:05:11,445 - INFO - ðŸªœ Batch step - 1137 -- sub batch step 4549 -- lr 1.71e-04
2025-03-02 13:05:14,173 - INFO - ðŸªœ Batch step - 1137 -- sub batch step 4550 -- lr 1.71e-04
2025-03-02 13:05:16,329 - INFO - ðŸªœ Batch step - 1137 -- sub batch step 4551 -- lr 1.71e-04
2025-03-02 13:05:17,867 - INFO - Step 1137 -- ðŸ”„ Training Metrics
2025-03-02 13:05:17,867 - INFO - â”œâ”€â”€ Loss: 7.5787
2025-03-02 13:05:17,868 - INFO - â”œâ”€â”€ Learning Rate: 1.71e-04
2025-03-02 13:05:17,868 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:05:18,538 - INFO - ðŸªœ Batch step - 1138 -- sub batch step 4552 -- lr 1.71e-04
2025-03-02 13:05:20,686 - INFO - ðŸªœ Batch step - 1138 -- sub batch step 4553 -- lr 1.71e-04
2025-03-02 13:05:22,855 - INFO - ðŸªœ Batch step - 1138 -- sub batch step 4554 -- lr 1.71e-04
2025-03-02 13:05:25,010 - INFO - ðŸªœ Batch step - 1138 -- sub batch step 4555 -- lr 1.71e-04
2025-03-02 13:05:26,564 - INFO - Step 1138 -- ðŸ”„ Training Metrics
2025-03-02 13:05:26,564 - INFO - â”œâ”€â”€ Loss: 7.6041
2025-03-02 13:05:26,565 - INFO - â”œâ”€â”€ Learning Rate: 1.71e-04
2025-03-02 13:05:26,565 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:05:27,233 - INFO - ðŸªœ Batch step - 1139 -- sub batch step 4556 -- lr 1.71e-04
2025-03-02 13:05:29,389 - INFO - ðŸªœ Batch step - 1139 -- sub batch step 4557 -- lr 1.71e-04
2025-03-02 13:05:31,848 - INFO - ðŸªœ Batch step - 1139 -- sub batch step 4558 -- lr 1.71e-04
2025-03-02 13:05:34,009 - INFO - ðŸªœ Batch step - 1139 -- sub batch step 4559 -- lr 1.71e-04
2025-03-02 13:05:35,501 - INFO - Step 1139 -- ðŸ”„ Training Metrics
2025-03-02 13:05:35,501 - INFO - â”œâ”€â”€ Loss: 7.6034
2025-03-02 13:05:35,501 - INFO - â”œâ”€â”€ Learning Rate: 1.71e-04
2025-03-02 13:05:35,501 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:05:37,068 - INFO - ðŸªœ Batch step - 1140 -- sub batch step 4560 -- lr 1.71e-04
2025-03-02 13:05:39,225 - INFO - ðŸªœ Batch step - 1140 -- sub batch step 4561 -- lr 1.71e-04
2025-03-02 13:05:41,386 - INFO - ðŸªœ Batch step - 1140 -- sub batch step 4562 -- lr 1.71e-04
2025-03-02 13:05:43,559 - INFO - ðŸªœ Batch step - 1140 -- sub batch step 4563 -- lr 1.71e-04
2025-03-02 13:05:45,049 - INFO - Step 1140 -- ðŸ”„ Training Metrics
2025-03-02 13:05:45,050 - INFO - â”œâ”€â”€ Loss: 7.5997
2025-03-02 13:05:45,050 - INFO - â”œâ”€â”€ Learning Rate: 1.71e-04
2025-03-02 13:05:45,050 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:05:45,726 - INFO - ðŸªœ Batch step - 1141 -- sub batch step 4564 -- lr 1.71e-04
2025-03-02 13:05:47,879 - INFO - ðŸªœ Batch step - 1141 -- sub batch step 4565 -- lr 1.71e-04
2025-03-02 13:05:50,027 - INFO - ðŸªœ Batch step - 1141 -- sub batch step 4566 -- lr 1.71e-04
2025-03-02 13:05:52,472 - INFO - ðŸªœ Batch step - 1141 -- sub batch step 4567 -- lr 1.71e-04
2025-03-02 13:05:54,405 - INFO - Step 1141 -- ðŸ”„ Training Metrics
2025-03-02 13:05:54,406 - INFO - â”œâ”€â”€ Loss: 7.6102
2025-03-02 13:05:54,406 - INFO - â”œâ”€â”€ Learning Rate: 1.71e-04
2025-03-02 13:05:54,406 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:05:55,075 - INFO - ðŸªœ Batch step - 1142 -- sub batch step 4568 -- lr 1.71e-04
2025-03-02 13:05:57,233 - INFO - ðŸªœ Batch step - 1142 -- sub batch step 4569 -- lr 1.71e-04
2025-03-02 13:05:59,386 - INFO - ðŸªœ Batch step - 1142 -- sub batch step 4570 -- lr 1.71e-04
2025-03-02 13:06:01,549 - INFO - ðŸªœ Batch step - 1142 -- sub batch step 4571 -- lr 1.71e-04
2025-03-02 13:06:03,105 - INFO - Step 1142 -- ðŸ”„ Training Metrics
2025-03-02 13:06:03,105 - INFO - â”œâ”€â”€ Loss: 7.6103
2025-03-02 13:06:03,105 - INFO - â”œâ”€â”€ Learning Rate: 1.71e-04
2025-03-02 13:06:03,105 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:06:03,776 - INFO - ðŸªœ Batch step - 1143 -- sub batch step 4572 -- lr 1.71e-04
2025-03-02 13:06:05,925 - INFO - ðŸªœ Batch step - 1143 -- sub batch step 4573 -- lr 1.71e-04
2025-03-02 13:06:08,083 - INFO - ðŸªœ Batch step - 1143 -- sub batch step 4574 -- lr 1.71e-04
2025-03-02 13:06:10,485 - INFO - ðŸªœ Batch step - 1143 -- sub batch step 4575 -- lr 1.71e-04
2025-03-02 13:06:12,421 - INFO - Step 1143 -- ðŸ”„ Training Metrics
2025-03-02 13:06:12,421 - INFO - â”œâ”€â”€ Loss: 7.6105
2025-03-02 13:06:12,422 - INFO - â”œâ”€â”€ Learning Rate: 1.71e-04
2025-03-02 13:06:12,422 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:06:13,091 - INFO - ðŸªœ Batch step - 1144 -- sub batch step 4576 -- lr 1.72e-04
2025-03-02 13:06:15,244 - INFO - ðŸªœ Batch step - 1144 -- sub batch step 4577 -- lr 1.72e-04
2025-03-02 13:06:17,394 - INFO - ðŸªœ Batch step - 1144 -- sub batch step 4578 -- lr 1.72e-04
2025-03-02 13:06:19,570 - INFO - ðŸªœ Batch step - 1144 -- sub batch step 4579 -- lr 1.72e-04
2025-03-02 13:06:21,125 - INFO - Step 1144 -- ðŸ”„ Training Metrics
2025-03-02 13:06:21,125 - INFO - â”œâ”€â”€ Loss: 7.6180
2025-03-02 13:06:21,125 - INFO - â”œâ”€â”€ Learning Rate: 1.72e-04
2025-03-02 13:06:21,125 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:06:21,798 - INFO - ðŸªœ Batch step - 1145 -- sub batch step 4580 -- lr 1.72e-04
2025-03-02 13:06:23,950 - INFO - ðŸªœ Batch step - 1145 -- sub batch step 4581 -- lr 1.72e-04
2025-03-02 13:06:26,108 - INFO - ðŸªœ Batch step - 1145 -- sub batch step 4582 -- lr 1.72e-04
2025-03-02 13:06:28,497 - INFO - ðŸªœ Batch step - 1145 -- sub batch step 4583 -- lr 1.72e-04
2025-03-02 13:06:30,463 - INFO - Step 1145 -- ðŸ”„ Training Metrics
2025-03-02 13:06:30,463 - INFO - â”œâ”€â”€ Loss: 7.5826
2025-03-02 13:06:30,463 - INFO - â”œâ”€â”€ Learning Rate: 1.72e-04
2025-03-02 13:06:30,463 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:06:31,134 - INFO - ðŸªœ Batch step - 1146 -- sub batch step 4584 -- lr 1.72e-04
2025-03-02 13:06:33,293 - INFO - ðŸªœ Batch step - 1146 -- sub batch step 4585 -- lr 1.72e-04
2025-03-02 13:06:35,439 - INFO - ðŸªœ Batch step - 1146 -- sub batch step 4586 -- lr 1.72e-04
2025-03-02 13:06:37,607 - INFO - ðŸªœ Batch step - 1146 -- sub batch step 4587 -- lr 1.72e-04
2025-03-02 13:06:39,171 - INFO - Step 1146 -- ðŸ”„ Training Metrics
2025-03-02 13:06:39,171 - INFO - â”œâ”€â”€ Loss: 7.5909
2025-03-02 13:06:39,171 - INFO - â”œâ”€â”€ Learning Rate: 1.72e-04
2025-03-02 13:06:39,172 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:06:39,836 - INFO - ðŸªœ Batch step - 1147 -- sub batch step 4588 -- lr 1.72e-04
2025-03-02 13:06:41,997 - INFO - ðŸªœ Batch step - 1147 -- sub batch step 4589 -- lr 1.72e-04
2025-03-02 13:06:44,153 - INFO - ðŸªœ Batch step - 1147 -- sub batch step 4590 -- lr 1.72e-04
2025-03-02 13:06:46,841 - INFO - ðŸªœ Batch step - 1147 -- sub batch step 4591 -- lr 1.72e-04
2025-03-02 13:06:48,424 - INFO - Step 1147 -- ðŸ”„ Training Metrics
2025-03-02 13:06:48,424 - INFO - â”œâ”€â”€ Loss: 7.6026
2025-03-02 13:06:48,424 - INFO - â”œâ”€â”€ Learning Rate: 1.72e-04
2025-03-02 13:06:48,424 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:06:49,097 - INFO - ðŸªœ Batch step - 1148 -- sub batch step 4592 -- lr 1.72e-04
2025-03-02 13:06:51,248 - INFO - ðŸªœ Batch step - 1148 -- sub batch step 4593 -- lr 1.72e-04
2025-03-02 13:06:53,405 - INFO - ðŸªœ Batch step - 1148 -- sub batch step 4594 -- lr 1.72e-04
2025-03-02 13:06:55,575 - INFO - ðŸªœ Batch step - 1148 -- sub batch step 4595 -- lr 1.72e-04
2025-03-02 13:06:57,130 - INFO - Step 1148 -- ðŸ”„ Training Metrics
2025-03-02 13:06:57,130 - INFO - â”œâ”€â”€ Loss: 7.5825
2025-03-02 13:06:57,130 - INFO - â”œâ”€â”€ Learning Rate: 1.72e-04
2025-03-02 13:06:57,130 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:06:57,798 - INFO - ðŸªœ Batch step - 1149 -- sub batch step 4596 -- lr 1.72e-04
2025-03-02 13:06:59,954 - INFO - ðŸªœ Batch step - 1149 -- sub batch step 4597 -- lr 1.72e-04
2025-03-02 13:07:02,104 - INFO - ðŸªœ Batch step - 1149 -- sub batch step 4598 -- lr 1.72e-04
2025-03-02 13:07:04,960 - INFO - ðŸªœ Batch step - 1149 -- sub batch step 4599 -- lr 1.72e-04
2025-03-02 13:07:06,505 - INFO - Step 1149 -- ðŸ”„ Training Metrics
2025-03-02 13:07:06,505 - INFO - â”œâ”€â”€ Loss: 7.5795
2025-03-02 13:07:06,505 - INFO - â”œâ”€â”€ Learning Rate: 1.72e-04
2025-03-02 13:07:06,506 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:07:07,180 - INFO - ðŸªœ Batch step - 1150 -- sub batch step 4600 -- lr 1.72e-04
2025-03-02 13:07:09,336 - INFO - ðŸªœ Batch step - 1150 -- sub batch step 4601 -- lr 1.72e-04
2025-03-02 13:07:11,491 - INFO - ðŸªœ Batch step - 1150 -- sub batch step 4602 -- lr 1.72e-04
2025-03-02 13:07:13,655 - INFO - ðŸªœ Batch step - 1150 -- sub batch step 4603 -- lr 1.72e-04
2025-03-02 13:07:15,199 - INFO - Step 1150 -- ðŸ”„ Training Metrics
2025-03-02 13:07:15,200 - INFO - â”œâ”€â”€ Loss: 7.6065
2025-03-02 13:07:15,200 - INFO - â”œâ”€â”€ Learning Rate: 1.72e-04
2025-03-02 13:07:15,200 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:07:15,875 - INFO - ðŸªœ Batch step - 1151 -- sub batch step 4604 -- lr 1.73e-04
2025-03-02 13:07:18,033 - INFO - ðŸªœ Batch step - 1151 -- sub batch step 4605 -- lr 1.73e-04
2025-03-02 13:07:20,870 - INFO - ðŸªœ Batch step - 1151 -- sub batch step 4606 -- lr 1.73e-04
2025-03-02 13:07:23,029 - INFO - ðŸªœ Batch step - 1151 -- sub batch step 4607 -- lr 1.73e-04
2025-03-02 13:07:24,520 - INFO - Step 1151 -- ðŸ”„ Training Metrics
2025-03-02 13:07:24,521 - INFO - â”œâ”€â”€ Loss: 7.5945
2025-03-02 13:07:24,521 - INFO - â”œâ”€â”€ Learning Rate: 1.73e-04
2025-03-02 13:07:24,521 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:07:25,187 - INFO - ðŸªœ Batch step - 1152 -- sub batch step 4608 -- lr 1.73e-04
2025-03-02 13:07:27,350 - INFO - ðŸªœ Batch step - 1152 -- sub batch step 4609 -- lr 1.73e-04
2025-03-02 13:07:29,519 - INFO - ðŸªœ Batch step - 1152 -- sub batch step 4610 -- lr 1.73e-04
2025-03-02 13:07:31,671 - INFO - ðŸªœ Batch step - 1152 -- sub batch step 4611 -- lr 1.73e-04
2025-03-02 13:07:33,215 - INFO - Step 1152 -- ðŸ”„ Training Metrics
2025-03-02 13:07:33,215 - INFO - â”œâ”€â”€ Loss: 7.5830
2025-03-02 13:07:33,233 - INFO - â”œâ”€â”€ Learning Rate: 1.73e-04
2025-03-02 13:07:33,233 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:07:33,906 - INFO - ðŸªœ Batch step - 1153 -- sub batch step 4612 -- lr 1.73e-04
2025-03-02 13:07:36,062 - INFO - ðŸªœ Batch step - 1153 -- sub batch step 4613 -- lr 1.73e-04
2025-03-02 13:07:38,734 - INFO - ðŸªœ Batch step - 1153 -- sub batch step 4614 -- lr 1.73e-04
2025-03-02 13:07:40,890 - INFO - ðŸªœ Batch step - 1153 -- sub batch step 4615 -- lr 1.73e-04
2025-03-02 13:07:42,520 - INFO - Step 1153 -- ðŸ”„ Training Metrics
2025-03-02 13:07:42,520 - INFO - â”œâ”€â”€ Loss: 7.6127
2025-03-02 13:07:42,520 - INFO - â”œâ”€â”€ Learning Rate: 1.73e-04
2025-03-02 13:07:42,520 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:07:43,187 - INFO - ðŸªœ Batch step - 1154 -- sub batch step 4616 -- lr 1.73e-04
2025-03-02 13:07:45,346 - INFO - ðŸªœ Batch step - 1154 -- sub batch step 4617 -- lr 1.73e-04
2025-03-02 13:07:47,518 - INFO - ðŸªœ Batch step - 1154 -- sub batch step 4618 -- lr 1.73e-04
2025-03-02 13:07:49,673 - INFO - ðŸªœ Batch step - 1154 -- sub batch step 4619 -- lr 1.73e-04
2025-03-02 13:07:51,229 - INFO - Step 1154 -- ðŸ”„ Training Metrics
2025-03-02 13:07:51,230 - INFO - â”œâ”€â”€ Loss: 7.5975
2025-03-02 13:07:51,230 - INFO - â”œâ”€â”€ Learning Rate: 1.73e-04
2025-03-02 13:07:51,230 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:07:51,905 - INFO - ðŸªœ Batch step - 1155 -- sub batch step 4620 -- lr 1.73e-04
2025-03-02 13:07:54,055 - INFO - ðŸªœ Batch step - 1155 -- sub batch step 4621 -- lr 1.73e-04
2025-03-02 13:07:56,904 - INFO - ðŸªœ Batch step - 1155 -- sub batch step 4622 -- lr 1.73e-04
2025-03-02 13:07:59,054 - INFO - ðŸªœ Batch step - 1155 -- sub batch step 4623 -- lr 1.73e-04
2025-03-02 13:08:00,544 - INFO - Step 1155 -- ðŸ”„ Training Metrics
2025-03-02 13:08:00,545 - INFO - â”œâ”€â”€ Loss: 7.5822
2025-03-02 13:08:00,545 - INFO - â”œâ”€â”€ Learning Rate: 1.73e-04
2025-03-02 13:08:00,545 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:08:01,217 - INFO - ðŸªœ Batch step - 1156 -- sub batch step 4624 -- lr 1.73e-04
2025-03-02 13:08:03,375 - INFO - ðŸªœ Batch step - 1156 -- sub batch step 4625 -- lr 1.73e-04
2025-03-02 13:08:05,534 - INFO - ðŸªœ Batch step - 1156 -- sub batch step 4626 -- lr 1.73e-04
2025-03-02 13:08:07,688 - INFO - ðŸªœ Batch step - 1156 -- sub batch step 4627 -- lr 1.73e-04
2025-03-02 13:08:09,244 - INFO - Step 1156 -- ðŸ”„ Training Metrics
2025-03-02 13:08:09,244 - INFO - â”œâ”€â”€ Loss: 7.5935
2025-03-02 13:08:09,244 - INFO - â”œâ”€â”€ Learning Rate: 1.73e-04
2025-03-02 13:08:09,244 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:08:09,910 - INFO - ðŸªœ Batch step - 1157 -- sub batch step 4628 -- lr 1.74e-04
2025-03-02 13:08:12,068 - INFO - ðŸªœ Batch step - 1157 -- sub batch step 4629 -- lr 1.74e-04
2025-03-02 13:08:14,827 - INFO - ðŸªœ Batch step - 1157 -- sub batch step 4630 -- lr 1.74e-04
2025-03-02 13:08:16,976 - INFO - ðŸªœ Batch step - 1157 -- sub batch step 4631 -- lr 1.74e-04
2025-03-02 13:08:18,462 - INFO - Step 1157 -- ðŸ”„ Training Metrics
2025-03-02 13:08:18,462 - INFO - â”œâ”€â”€ Loss: 7.5933
2025-03-02 13:08:18,462 - INFO - â”œâ”€â”€ Learning Rate: 1.74e-04
2025-03-02 13:08:18,462 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:08:19,138 - INFO - ðŸªœ Batch step - 1158 -- sub batch step 4632 -- lr 1.74e-04
2025-03-02 13:08:21,286 - INFO - ðŸªœ Batch step - 1158 -- sub batch step 4633 -- lr 1.74e-04
2025-03-02 13:08:23,461 - INFO - ðŸªœ Batch step - 1158 -- sub batch step 4634 -- lr 1.74e-04
2025-03-02 13:08:25,614 - INFO - ðŸªœ Batch step - 1158 -- sub batch step 4635 -- lr 1.74e-04
2025-03-02 13:08:27,153 - INFO - Step 1158 -- ðŸ”„ Training Metrics
2025-03-02 13:08:27,154 - INFO - â”œâ”€â”€ Loss: 7.5718
2025-03-02 13:08:27,154 - INFO - â”œâ”€â”€ Learning Rate: 1.74e-04
2025-03-02 13:08:27,154 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:08:27,820 - INFO - ðŸªœ Batch step - 1159 -- sub batch step 4636 -- lr 1.74e-04
2025-03-02 13:08:29,976 - INFO - ðŸªœ Batch step - 1159 -- sub batch step 4637 -- lr 1.74e-04
2025-03-02 13:08:32,266 - INFO - ðŸªœ Batch step - 1159 -- sub batch step 4638 -- lr 1.74e-04
2025-03-02 13:08:34,418 - INFO - ðŸªœ Batch step - 1159 -- sub batch step 4639 -- lr 1.74e-04
2025-03-02 13:08:36,072 - INFO - Step 1159 -- ðŸ”„ Training Metrics
2025-03-02 13:08:36,072 - INFO - â”œâ”€â”€ Loss: 7.5901
2025-03-02 13:08:36,073 - INFO - â”œâ”€â”€ Learning Rate: 1.74e-04
2025-03-02 13:08:36,073 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:08:37,477 - INFO - ðŸªœ Batch step - 1160 -- sub batch step 4640 -- lr 1.74e-04
2025-03-02 13:08:39,630 - INFO - ðŸªœ Batch step - 1160 -- sub batch step 4641 -- lr 1.74e-04
2025-03-02 13:08:41,789 - INFO - ðŸªœ Batch step - 1160 -- sub batch step 4642 -- lr 1.74e-04
2025-03-02 13:08:43,963 - INFO - ðŸªœ Batch step - 1160 -- sub batch step 4643 -- lr 1.74e-04
2025-03-02 13:08:45,585 - INFO - Step 1160 -- ðŸ”„ Training Metrics
2025-03-02 13:08:45,585 - INFO - â”œâ”€â”€ Loss: 7.6001
2025-03-02 13:08:45,585 - INFO - â”œâ”€â”€ Learning Rate: 1.74e-04
2025-03-02 13:08:45,585 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:08:46,260 - INFO - ðŸªœ Batch step - 1161 -- sub batch step 4644 -- lr 1.74e-04
2025-03-02 13:08:48,413 - INFO - ðŸªœ Batch step - 1161 -- sub batch step 4645 -- lr 1.74e-04
2025-03-02 13:08:50,562 - INFO - ðŸªœ Batch step - 1161 -- sub batch step 4646 -- lr 1.74e-04
2025-03-02 13:08:53,102 - INFO - ðŸªœ Batch step - 1161 -- sub batch step 4647 -- lr 1.74e-04
2025-03-02 13:08:54,933 - INFO - Step 1161 -- ðŸ”„ Training Metrics
2025-03-02 13:08:54,934 - INFO - â”œâ”€â”€ Loss: 7.5750
2025-03-02 13:08:54,934 - INFO - â”œâ”€â”€ Learning Rate: 1.74e-04
2025-03-02 13:08:54,934 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:08:55,603 - INFO - ðŸªœ Batch step - 1162 -- sub batch step 4648 -- lr 1.74e-04
2025-03-02 13:08:57,761 - INFO - ðŸªœ Batch step - 1162 -- sub batch step 4649 -- lr 1.74e-04
2025-03-02 13:08:59,920 - INFO - ðŸªœ Batch step - 1162 -- sub batch step 4650 -- lr 1.74e-04
2025-03-02 13:09:02,091 - INFO - ðŸªœ Batch step - 1162 -- sub batch step 4651 -- lr 1.74e-04
2025-03-02 13:09:03,635 - INFO - Step 1162 -- ðŸ”„ Training Metrics
2025-03-02 13:09:03,635 - INFO - â”œâ”€â”€ Loss: 7.5709
2025-03-02 13:09:03,635 - INFO - â”œâ”€â”€ Learning Rate: 1.74e-04
2025-03-02 13:09:03,635 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:09:04,307 - INFO - ðŸªœ Batch step - 1163 -- sub batch step 4652 -- lr 1.74e-04
2025-03-02 13:09:06,457 - INFO - ðŸªœ Batch step - 1163 -- sub batch step 4653 -- lr 1.74e-04
2025-03-02 13:09:08,617 - INFO - ðŸªœ Batch step - 1163 -- sub batch step 4654 -- lr 1.74e-04
2025-03-02 13:09:11,046 - INFO - ðŸªœ Batch step - 1163 -- sub batch step 4655 -- lr 1.74e-04
2025-03-02 13:09:12,987 - INFO - Step 1163 -- ðŸ”„ Training Metrics
2025-03-02 13:09:12,988 - INFO - â”œâ”€â”€ Loss: 7.6065
2025-03-02 13:09:12,988 - INFO - â”œâ”€â”€ Learning Rate: 1.74e-04
2025-03-02 13:09:12,988 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:09:13,657 - INFO - ðŸªœ Batch step - 1164 -- sub batch step 4656 -- lr 1.75e-04
2025-03-02 13:09:15,812 - INFO - ðŸªœ Batch step - 1164 -- sub batch step 4657 -- lr 1.75e-04
2025-03-02 13:09:17,961 - INFO - ðŸªœ Batch step - 1164 -- sub batch step 4658 -- lr 1.75e-04
2025-03-02 13:09:20,138 - INFO - ðŸªœ Batch step - 1164 -- sub batch step 4659 -- lr 1.75e-04
2025-03-02 13:09:21,692 - INFO - Step 1164 -- ðŸ”„ Training Metrics
2025-03-02 13:09:21,693 - INFO - â”œâ”€â”€ Loss: 7.5894
2025-03-02 13:09:21,693 - INFO - â”œâ”€â”€ Learning Rate: 1.75e-04
2025-03-02 13:09:21,693 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:09:22,363 - INFO - ðŸªœ Batch step - 1165 -- sub batch step 4660 -- lr 1.75e-04
2025-03-02 13:09:24,517 - INFO - ðŸªœ Batch step - 1165 -- sub batch step 4661 -- lr 1.75e-04
2025-03-02 13:09:26,671 - INFO - ðŸªœ Batch step - 1165 -- sub batch step 4662 -- lr 1.75e-04
2025-03-02 13:09:29,293 - INFO - ðŸªœ Batch step - 1165 -- sub batch step 4663 -- lr 1.75e-04
2025-03-02 13:09:31,042 - INFO - Step 1165 -- ðŸ”„ Training Metrics
2025-03-02 13:09:31,042 - INFO - â”œâ”€â”€ Loss: 7.6041
2025-03-02 13:09:31,042 - INFO - â”œâ”€â”€ Learning Rate: 1.75e-04
2025-03-02 13:09:31,043 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:09:31,720 - INFO - ðŸªœ Batch step - 1166 -- sub batch step 4664 -- lr 1.75e-04
2025-03-02 13:09:33,875 - INFO - ðŸªœ Batch step - 1166 -- sub batch step 4665 -- lr 1.75e-04
2025-03-02 13:09:36,024 - INFO - ðŸªœ Batch step - 1166 -- sub batch step 4666 -- lr 1.75e-04
2025-03-02 13:09:38,196 - INFO - ðŸªœ Batch step - 1166 -- sub batch step 4667 -- lr 1.75e-04
2025-03-02 13:09:39,737 - INFO - Step 1166 -- ðŸ”„ Training Metrics
2025-03-02 13:09:39,737 - INFO - â”œâ”€â”€ Loss: 7.5877
2025-03-02 13:09:39,738 - INFO - â”œâ”€â”€ Learning Rate: 1.75e-04
2025-03-02 13:09:39,738 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:09:40,400 - INFO - ðŸªœ Batch step - 1167 -- sub batch step 4668 -- lr 1.75e-04
2025-03-02 13:09:42,556 - INFO - ðŸªœ Batch step - 1167 -- sub batch step 4669 -- lr 1.75e-04
2025-03-02 13:09:44,710 - INFO - ðŸªœ Batch step - 1167 -- sub batch step 4670 -- lr 1.75e-04
2025-03-02 13:09:47,284 - INFO - ðŸªœ Batch step - 1167 -- sub batch step 4671 -- lr 1.75e-04
2025-03-02 13:09:49,058 - INFO - Step 1167 -- ðŸ”„ Training Metrics
2025-03-02 13:09:49,058 - INFO - â”œâ”€â”€ Loss: 7.5837
2025-03-02 13:09:49,059 - INFO - â”œâ”€â”€ Learning Rate: 1.75e-04
2025-03-02 13:09:49,059 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:09:49,729 - INFO - ðŸªœ Batch step - 1168 -- sub batch step 4672 -- lr 1.75e-04
2025-03-02 13:09:51,877 - INFO - ðŸªœ Batch step - 1168 -- sub batch step 4673 -- lr 1.75e-04
2025-03-02 13:09:54,034 - INFO - ðŸªœ Batch step - 1168 -- sub batch step 4674 -- lr 1.75e-04
2025-03-02 13:09:56,209 - INFO - ðŸªœ Batch step - 1168 -- sub batch step 4675 -- lr 1.75e-04
2025-03-02 13:09:57,760 - INFO - Step 1168 -- ðŸ”„ Training Metrics
2025-03-02 13:09:57,760 - INFO - â”œâ”€â”€ Loss: 7.6007
2025-03-02 13:09:57,760 - INFO - â”œâ”€â”€ Learning Rate: 1.75e-04
2025-03-02 13:09:57,760 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:09:58,426 - INFO - ðŸªœ Batch step - 1169 -- sub batch step 4676 -- lr 1.75e-04
2025-03-02 13:10:00,577 - INFO - ðŸªœ Batch step - 1169 -- sub batch step 4677 -- lr 1.75e-04
2025-03-02 13:10:02,722 - INFO - ðŸªœ Batch step - 1169 -- sub batch step 4678 -- lr 1.75e-04
2025-03-02 13:10:05,665 - INFO - ðŸªœ Batch step - 1169 -- sub batch step 4679 -- lr 1.75e-04
2025-03-02 13:10:07,157 - INFO - Step 1169 -- ðŸ”„ Training Metrics
2025-03-02 13:10:07,157 - INFO - â”œâ”€â”€ Loss: 7.5807
2025-03-02 13:10:07,157 - INFO - â”œâ”€â”€ Learning Rate: 1.75e-04
2025-03-02 13:10:07,158 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:10:07,829 - INFO - ðŸªœ Batch step - 1170 -- sub batch step 4680 -- lr 1.75e-04
2025-03-02 13:10:09,976 - INFO - ðŸªœ Batch step - 1170 -- sub batch step 4681 -- lr 1.75e-04
2025-03-02 13:10:12,133 - INFO - ðŸªœ Batch step - 1170 -- sub batch step 4682 -- lr 1.75e-04
2025-03-02 13:10:14,304 - INFO - ðŸªœ Batch step - 1170 -- sub batch step 4683 -- lr 1.75e-04
2025-03-02 13:10:15,850 - INFO - Step 1170 -- ðŸ”„ Training Metrics
2025-03-02 13:10:15,850 - INFO - â”œâ”€â”€ Loss: 7.5743
2025-03-02 13:10:15,850 - INFO - â”œâ”€â”€ Learning Rate: 1.75e-04
2025-03-02 13:10:15,850 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:10:16,524 - INFO - ðŸªœ Batch step - 1171 -- sub batch step 4684 -- lr 1.76e-04
2025-03-02 13:10:18,675 - INFO - ðŸªœ Batch step - 1171 -- sub batch step 4685 -- lr 1.76e-04
2025-03-02 13:10:21,464 - INFO - ðŸªœ Batch step - 1171 -- sub batch step 4686 -- lr 1.76e-04
2025-03-02 13:10:23,618 - INFO - ðŸªœ Batch step - 1171 -- sub batch step 4687 -- lr 1.76e-04
2025-03-02 13:10:25,187 - INFO - Step 1171 -- ðŸ”„ Training Metrics
2025-03-02 13:10:25,188 - INFO - â”œâ”€â”€ Loss: 7.5865
2025-03-02 13:10:25,188 - INFO - â”œâ”€â”€ Learning Rate: 1.76e-04
2025-03-02 13:10:25,188 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:10:25,855 - INFO - ðŸªœ Batch step - 1172 -- sub batch step 4688 -- lr 1.76e-04
2025-03-02 13:10:28,008 - INFO - ðŸªœ Batch step - 1172 -- sub batch step 4689 -- lr 1.76e-04
2025-03-02 13:10:30,181 - INFO - ðŸªœ Batch step - 1172 -- sub batch step 4690 -- lr 1.76e-04
2025-03-02 13:10:32,327 - INFO - ðŸªœ Batch step - 1172 -- sub batch step 4691 -- lr 1.76e-04
2025-03-02 13:10:33,862 - INFO - Step 1172 -- ðŸ”„ Training Metrics
2025-03-02 13:10:33,862 - INFO - â”œâ”€â”€ Loss: 7.5910
2025-03-02 13:10:33,862 - INFO - â”œâ”€â”€ Learning Rate: 1.76e-04
2025-03-02 13:10:33,862 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:10:34,536 - INFO - ðŸªœ Batch step - 1173 -- sub batch step 4692 -- lr 1.76e-04
2025-03-02 13:10:36,681 - INFO - ðŸªœ Batch step - 1173 -- sub batch step 4693 -- lr 1.76e-04
2025-03-02 13:10:39,366 - INFO - ðŸªœ Batch step - 1173 -- sub batch step 4694 -- lr 1.76e-04
2025-03-02 13:10:41,519 - INFO - ðŸªœ Batch step - 1173 -- sub batch step 4695 -- lr 1.76e-04
2025-03-02 13:10:43,205 - INFO - Step 1173 -- ðŸ”„ Training Metrics
2025-03-02 13:10:43,205 - INFO - â”œâ”€â”€ Loss: 7.5623
2025-03-02 13:10:43,205 - INFO - â”œâ”€â”€ Learning Rate: 1.76e-04
2025-03-02 13:10:43,205 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:10:43,873 - INFO - ðŸªœ Batch step - 1174 -- sub batch step 4696 -- lr 1.76e-04
2025-03-02 13:10:46,027 - INFO - ðŸªœ Batch step - 1174 -- sub batch step 4697 -- lr 1.76e-04
2025-03-02 13:10:48,194 - INFO - ðŸªœ Batch step - 1174 -- sub batch step 4698 -- lr 1.76e-04
2025-03-02 13:10:50,350 - INFO - ðŸªœ Batch step - 1174 -- sub batch step 4699 -- lr 1.76e-04
2025-03-02 13:10:51,887 - INFO - Step 1174 -- ðŸ”„ Training Metrics
2025-03-02 13:10:51,888 - INFO - â”œâ”€â”€ Loss: 7.5715
2025-03-02 13:10:51,888 - INFO - â”œâ”€â”€ Learning Rate: 1.76e-04
2025-03-02 13:10:51,888 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:10:52,560 - INFO - ðŸªœ Batch step - 1175 -- sub batch step 4700 -- lr 1.76e-04
2025-03-02 13:10:54,708 - INFO - ðŸªœ Batch step - 1175 -- sub batch step 4701 -- lr 1.76e-04
2025-03-02 13:10:57,445 - INFO - ðŸªœ Batch step - 1175 -- sub batch step 4702 -- lr 1.76e-04
2025-03-02 13:10:59,590 - INFO - ðŸªœ Batch step - 1175 -- sub batch step 4703 -- lr 1.76e-04
2025-03-02 13:11:01,088 - INFO - Step 1175 -- ðŸ”„ Training Metrics
2025-03-02 13:11:01,089 - INFO - â”œâ”€â”€ Loss: 7.5877
2025-03-02 13:11:01,089 - INFO - â”œâ”€â”€ Learning Rate: 1.76e-04
2025-03-02 13:11:01,089 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:11:01,761 - INFO - ðŸªœ Batch step - 1176 -- sub batch step 4704 -- lr 1.76e-04
2025-03-02 13:11:03,912 - INFO - ðŸªœ Batch step - 1176 -- sub batch step 4705 -- lr 1.76e-04
2025-03-02 13:11:06,079 - INFO - ðŸªœ Batch step - 1176 -- sub batch step 4706 -- lr 1.76e-04
2025-03-02 13:11:08,228 - INFO - ðŸªœ Batch step - 1176 -- sub batch step 4707 -- lr 1.76e-04
2025-03-02 13:11:09,778 - INFO - Step 1176 -- ðŸ”„ Training Metrics
2025-03-02 13:11:09,778 - INFO - â”œâ”€â”€ Loss: 7.5669
2025-03-02 13:11:09,778 - INFO - â”œâ”€â”€ Learning Rate: 1.76e-04
2025-03-02 13:11:09,778 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:11:10,446 - INFO - ðŸªœ Batch step - 1177 -- sub batch step 4708 -- lr 1.77e-04
2025-03-02 13:11:12,598 - INFO - ðŸªœ Batch step - 1177 -- sub batch step 4709 -- lr 1.77e-04
2025-03-02 13:11:15,283 - INFO - ðŸªœ Batch step - 1177 -- sub batch step 4710 -- lr 1.77e-04
2025-03-02 13:11:17,428 - INFO - ðŸªœ Batch step - 1177 -- sub batch step 4711 -- lr 1.77e-04
2025-03-02 13:11:18,960 - INFO - Step 1177 -- ðŸ”„ Training Metrics
2025-03-02 13:11:18,960 - INFO - â”œâ”€â”€ Loss: 7.6067
2025-03-02 13:11:18,960 - INFO - â”œâ”€â”€ Learning Rate: 1.77e-04
2025-03-02 13:11:18,960 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:11:19,635 - INFO - ðŸªœ Batch step - 1178 -- sub batch step 4712 -- lr 1.77e-04
2025-03-02 13:11:21,781 - INFO - ðŸªœ Batch step - 1178 -- sub batch step 4713 -- lr 1.77e-04
2025-03-02 13:11:23,954 - INFO - ðŸªœ Batch step - 1178 -- sub batch step 4714 -- lr 1.77e-04
2025-03-02 13:11:26,109 - INFO - ðŸªœ Batch step - 1178 -- sub batch step 4715 -- lr 1.77e-04
2025-03-02 13:11:27,655 - INFO - Step 1178 -- ðŸ”„ Training Metrics
2025-03-02 13:11:27,655 - INFO - â”œâ”€â”€ Loss: 7.5720
2025-03-02 13:11:27,655 - INFO - â”œâ”€â”€ Learning Rate: 1.77e-04
2025-03-02 13:11:27,655 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:11:28,319 - INFO - ðŸªœ Batch step - 1179 -- sub batch step 4716 -- lr 1.77e-04
2025-03-02 13:11:30,469 - INFO - ðŸªœ Batch step - 1179 -- sub batch step 4717 -- lr 1.77e-04
2025-03-02 13:11:32,755 - INFO - ðŸªœ Batch step - 1179 -- sub batch step 4718 -- lr 1.77e-04
2025-03-02 13:11:34,913 - INFO - ðŸªœ Batch step - 1179 -- sub batch step 4719 -- lr 1.77e-04
2025-03-02 13:11:36,592 - INFO - Step 1179 -- ðŸ”„ Training Metrics
2025-03-02 13:11:36,593 - INFO - â”œâ”€â”€ Loss: 7.5804
2025-03-02 13:11:36,593 - INFO - â”œâ”€â”€ Learning Rate: 1.77e-04
2025-03-02 13:11:36,593 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:11:37,849 - INFO - ðŸªœ Batch step - 1180 -- sub batch step 4720 -- lr 1.77e-04
2025-03-02 13:11:39,998 - INFO - ðŸªœ Batch step - 1180 -- sub batch step 4721 -- lr 1.77e-04
2025-03-02 13:11:42,152 - INFO - ðŸªœ Batch step - 1180 -- sub batch step 4722 -- lr 1.77e-04
2025-03-02 13:11:44,324 - INFO - ðŸªœ Batch step - 1180 -- sub batch step 4723 -- lr 1.77e-04
2025-03-02 13:11:45,862 - INFO - Step 1180 -- ðŸ”„ Training Metrics
2025-03-02 13:11:45,863 - INFO - â”œâ”€â”€ Loss: 7.5748
2025-03-02 13:11:45,863 - INFO - â”œâ”€â”€ Learning Rate: 1.77e-04
2025-03-02 13:11:45,863 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:11:46,537 - INFO - ðŸªœ Batch step - 1181 -- sub batch step 4724 -- lr 1.77e-04
2025-03-02 13:11:48,687 - INFO - ðŸªœ Batch step - 1181 -- sub batch step 4725 -- lr 1.77e-04
2025-03-02 13:11:50,835 - INFO - ðŸªœ Batch step - 1181 -- sub batch step 4726 -- lr 1.77e-04
2025-03-02 13:11:53,296 - INFO - ðŸªœ Batch step - 1181 -- sub batch step 4727 -- lr 1.77e-04
2025-03-02 13:11:54,931 - INFO - Step 1181 -- ðŸ”„ Training Metrics
2025-03-02 13:11:54,931 - INFO - â”œâ”€â”€ Loss: 7.5494
2025-03-02 13:11:54,931 - INFO - â”œâ”€â”€ Learning Rate: 1.77e-04
2025-03-02 13:11:54,931 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:11:55,596 - INFO - ðŸªœ Batch step - 1182 -- sub batch step 4728 -- lr 1.77e-04
2025-03-02 13:11:57,749 - INFO - ðŸªœ Batch step - 1182 -- sub batch step 4729 -- lr 1.77e-04
2025-03-02 13:11:59,903 - INFO - ðŸªœ Batch step - 1182 -- sub batch step 4730 -- lr 1.77e-04
2025-03-02 13:12:02,070 - INFO - ðŸªœ Batch step - 1182 -- sub batch step 4731 -- lr 1.77e-04
2025-03-02 13:12:03,608 - INFO - Step 1182 -- ðŸ”„ Training Metrics
2025-03-02 13:12:03,609 - INFO - â”œâ”€â”€ Loss: 7.5485
2025-03-02 13:12:03,609 - INFO - â”œâ”€â”€ Learning Rate: 1.77e-04
2025-03-02 13:12:03,609 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:12:04,280 - INFO - ðŸªœ Batch step - 1183 -- sub batch step 4732 -- lr 1.77e-04
2025-03-02 13:12:06,428 - INFO - ðŸªœ Batch step - 1183 -- sub batch step 4733 -- lr 1.77e-04
2025-03-02 13:12:08,582 - INFO - ðŸªœ Batch step - 1183 -- sub batch step 4734 -- lr 1.77e-04
2025-03-02 13:12:11,003 - INFO - ðŸªœ Batch step - 1183 -- sub batch step 4735 -- lr 1.77e-04
2025-03-02 13:12:12,988 - INFO - Step 1183 -- ðŸ”„ Training Metrics
2025-03-02 13:12:12,988 - INFO - â”œâ”€â”€ Loss: 7.5874
2025-03-02 13:12:12,988 - INFO - â”œâ”€â”€ Learning Rate: 1.77e-04
2025-03-02 13:12:12,988 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:12:13,656 - INFO - ðŸªœ Batch step - 1184 -- sub batch step 4736 -- lr 1.78e-04
2025-03-02 13:12:15,808 - INFO - ðŸªœ Batch step - 1184 -- sub batch step 4737 -- lr 1.78e-04
2025-03-02 13:12:17,957 - INFO - ðŸªœ Batch step - 1184 -- sub batch step 4738 -- lr 1.78e-04
2025-03-02 13:12:20,132 - INFO - ðŸªœ Batch step - 1184 -- sub batch step 4739 -- lr 1.78e-04
2025-03-02 13:12:21,672 - INFO - Step 1184 -- ðŸ”„ Training Metrics
2025-03-02 13:12:21,672 - INFO - â”œâ”€â”€ Loss: 7.5799
2025-03-02 13:12:21,672 - INFO - â”œâ”€â”€ Learning Rate: 1.78e-04
2025-03-02 13:12:21,672 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:12:22,349 - INFO - ðŸªœ Batch step - 1185 -- sub batch step 4740 -- lr 1.78e-04
2025-03-02 13:12:24,500 - INFO - ðŸªœ Batch step - 1185 -- sub batch step 4741 -- lr 1.78e-04
2025-03-02 13:12:26,654 - INFO - ðŸªœ Batch step - 1185 -- sub batch step 4742 -- lr 1.78e-04
2025-03-02 13:12:29,511 - INFO - ðŸªœ Batch step - 1185 -- sub batch step 4743 -- lr 1.78e-04
2025-03-02 13:12:31,002 - INFO - Step 1185 -- ðŸ”„ Training Metrics
2025-03-02 13:12:31,002 - INFO - â”œâ”€â”€ Loss: 7.5658
2025-03-02 13:12:31,002 - INFO - â”œâ”€â”€ Learning Rate: 1.78e-04
2025-03-02 13:12:31,002 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:12:31,676 - INFO - ðŸªœ Batch step - 1186 -- sub batch step 4744 -- lr 1.78e-04
2025-03-02 13:12:33,826 - INFO - ðŸªœ Batch step - 1186 -- sub batch step 4745 -- lr 1.78e-04
2025-03-02 13:12:35,972 - INFO - ðŸªœ Batch step - 1186 -- sub batch step 4746 -- lr 1.78e-04
2025-03-02 13:12:38,146 - INFO - ðŸªœ Batch step - 1186 -- sub batch step 4747 -- lr 1.78e-04
2025-03-02 13:12:39,686 - INFO - Step 1186 -- ðŸ”„ Training Metrics
2025-03-02 13:12:39,687 - INFO - â”œâ”€â”€ Loss: 7.5724
2025-03-02 13:12:39,687 - INFO - â”œâ”€â”€ Learning Rate: 1.78e-04
2025-03-02 13:12:39,687 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:12:40,352 - INFO - ðŸªœ Batch step - 1187 -- sub batch step 4748 -- lr 1.78e-04
2025-03-02 13:12:42,505 - INFO - ðŸªœ Batch step - 1187 -- sub batch step 4749 -- lr 1.78e-04
2025-03-02 13:12:44,656 - INFO - ðŸªœ Batch step - 1187 -- sub batch step 4750 -- lr 1.78e-04
2025-03-02 13:12:47,286 - INFO - ðŸªœ Batch step - 1187 -- sub batch step 4751 -- lr 1.78e-04
2025-03-02 13:12:48,776 - INFO - Step 1187 -- ðŸ”„ Training Metrics
2025-03-02 13:12:48,777 - INFO - â”œâ”€â”€ Loss: 7.5629
2025-03-02 13:12:48,777 - INFO - â”œâ”€â”€ Learning Rate: 1.78e-04
2025-03-02 13:12:48,777 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:12:49,447 - INFO - ðŸªœ Batch step - 1188 -- sub batch step 4752 -- lr 1.78e-04
2025-03-02 13:12:51,592 - INFO - ðŸªœ Batch step - 1188 -- sub batch step 4753 -- lr 1.78e-04
2025-03-02 13:12:53,748 - INFO - ðŸªœ Batch step - 1188 -- sub batch step 4754 -- lr 1.78e-04
2025-03-02 13:12:55,927 - INFO - ðŸªœ Batch step - 1188 -- sub batch step 4755 -- lr 1.78e-04
2025-03-02 13:12:57,467 - INFO - Step 1188 -- ðŸ”„ Training Metrics
2025-03-02 13:12:57,467 - INFO - â”œâ”€â”€ Loss: 7.5778
2025-03-02 13:12:57,467 - INFO - â”œâ”€â”€ Learning Rate: 1.78e-04
2025-03-02 13:12:57,467 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:12:58,136 - INFO - ðŸªœ Batch step - 1189 -- sub batch step 4756 -- lr 1.78e-04
2025-03-02 13:13:00,297 - INFO - ðŸªœ Batch step - 1189 -- sub batch step 4757 -- lr 1.78e-04
2025-03-02 13:13:02,446 - INFO - ðŸªœ Batch step - 1189 -- sub batch step 4758 -- lr 1.78e-04
2025-03-02 13:13:05,057 - INFO - ðŸªœ Batch step - 1189 -- sub batch step 4759 -- lr 1.78e-04
2025-03-02 13:13:06,548 - INFO - Step 1189 -- ðŸ”„ Training Metrics
2025-03-02 13:13:06,548 - INFO - â”œâ”€â”€ Loss: 7.5835
2025-03-02 13:13:06,548 - INFO - â”œâ”€â”€ Learning Rate: 1.78e-04
2025-03-02 13:13:06,549 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:13:07,220 - INFO - ðŸªœ Batch step - 1190 -- sub batch step 4760 -- lr 1.78e-04
2025-03-02 13:13:09,368 - INFO - ðŸªœ Batch step - 1190 -- sub batch step 4761 -- lr 1.78e-04
2025-03-02 13:13:11,525 - INFO - ðŸªœ Batch step - 1190 -- sub batch step 4762 -- lr 1.78e-04
2025-03-02 13:13:13,694 - INFO - ðŸªœ Batch step - 1190 -- sub batch step 4763 -- lr 1.78e-04
2025-03-02 13:13:15,230 - INFO - Step 1190 -- ðŸ”„ Training Metrics
2025-03-02 13:13:15,231 - INFO - â”œâ”€â”€ Loss: 7.5850
2025-03-02 13:13:15,231 - INFO - â”œâ”€â”€ Learning Rate: 1.78e-04
2025-03-02 13:13:15,231 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:13:15,903 - INFO - ðŸªœ Batch step - 1191 -- sub batch step 4764 -- lr 1.79e-04
2025-03-02 13:13:18,052 - INFO - ðŸªœ Batch step - 1191 -- sub batch step 4765 -- lr 1.79e-04
2025-03-02 13:13:20,610 - INFO - ðŸªœ Batch step - 1191 -- sub batch step 4766 -- lr 1.79e-04
2025-03-02 13:13:22,760 - INFO - ðŸªœ Batch step - 1191 -- sub batch step 4767 -- lr 1.79e-04
2025-03-02 13:13:24,246 - INFO - Step 1191 -- ðŸ”„ Training Metrics
2025-03-02 13:13:24,247 - INFO - â”œâ”€â”€ Loss: 7.5747
2025-03-02 13:13:24,247 - INFO - â”œâ”€â”€ Learning Rate: 1.79e-04
2025-03-02 13:13:24,247 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:13:24,912 - INFO - ðŸªœ Batch step - 1192 -- sub batch step 4768 -- lr 1.79e-04
2025-03-02 13:13:27,068 - INFO - ðŸªœ Batch step - 1192 -- sub batch step 4769 -- lr 1.79e-04
2025-03-02 13:13:29,243 - INFO - ðŸªœ Batch step - 1192 -- sub batch step 4770 -- lr 1.79e-04
2025-03-02 13:13:31,394 - INFO - ðŸªœ Batch step - 1192 -- sub batch step 4771 -- lr 1.79e-04
2025-03-02 13:13:32,939 - INFO - Step 1192 -- ðŸ”„ Training Metrics
2025-03-02 13:13:32,939 - INFO - â”œâ”€â”€ Loss: 7.5770
2025-03-02 13:13:32,939 - INFO - â”œâ”€â”€ Learning Rate: 1.79e-04
2025-03-02 13:13:32,939 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:13:33,610 - INFO - ðŸªœ Batch step - 1193 -- sub batch step 4772 -- lr 1.79e-04
2025-03-02 13:13:35,761 - INFO - ðŸªœ Batch step - 1193 -- sub batch step 4773 -- lr 1.79e-04
2025-03-02 13:13:38,190 - INFO - ðŸªœ Batch step - 1193 -- sub batch step 4774 -- lr 1.79e-04
2025-03-02 13:13:40,344 - INFO - ðŸªœ Batch step - 1193 -- sub batch step 4775 -- lr 1.79e-04
2025-03-02 13:13:42,014 - INFO - Step 1193 -- ðŸ”„ Training Metrics
2025-03-02 13:13:42,014 - INFO - â”œâ”€â”€ Loss: 7.5723
2025-03-02 13:13:42,014 - INFO - â”œâ”€â”€ Learning Rate: 1.79e-04
2025-03-02 13:13:42,014 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:13:42,683 - INFO - ðŸªœ Batch step - 1194 -- sub batch step 4776 -- lr 1.79e-04
2025-03-02 13:13:44,837 - INFO - ðŸªœ Batch step - 1194 -- sub batch step 4777 -- lr 1.79e-04
2025-03-02 13:13:47,006 - INFO - ðŸªœ Batch step - 1194 -- sub batch step 4778 -- lr 1.79e-04
2025-03-02 13:13:49,162 - INFO - ðŸªœ Batch step - 1194 -- sub batch step 4779 -- lr 1.79e-04
2025-03-02 13:13:50,718 - INFO - Step 1194 -- ðŸ”„ Training Metrics
2025-03-02 13:13:50,718 - INFO - â”œâ”€â”€ Loss: 7.5671
2025-03-02 13:13:50,718 - INFO - â”œâ”€â”€ Learning Rate: 1.79e-04
2025-03-02 13:13:50,719 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:13:51,390 - INFO - ðŸªœ Batch step - 1195 -- sub batch step 4780 -- lr 1.79e-04
2025-03-02 13:13:53,537 - INFO - ðŸªœ Batch step - 1195 -- sub batch step 4781 -- lr 1.79e-04
2025-03-02 13:13:56,009 - INFO - ðŸªœ Batch step - 1195 -- sub batch step 4782 -- lr 1.79e-04
2025-03-02 13:13:58,153 - INFO - ðŸªœ Batch step - 1195 -- sub batch step 4783 -- lr 1.79e-04
2025-03-02 13:13:59,858 - INFO - Step 1195 -- ðŸ”„ Training Metrics
2025-03-02 13:13:59,859 - INFO - â”œâ”€â”€ Loss: 7.5537
2025-03-02 13:13:59,859 - INFO - â”œâ”€â”€ Learning Rate: 1.79e-04
2025-03-02 13:13:59,859 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:14:00,532 - INFO - ðŸªœ Batch step - 1196 -- sub batch step 4784 -- lr 1.79e-04
2025-03-02 13:14:02,679 - INFO - ðŸªœ Batch step - 1196 -- sub batch step 4785 -- lr 1.79e-04
2025-03-02 13:14:04,844 - INFO - ðŸªœ Batch step - 1196 -- sub batch step 4786 -- lr 1.79e-04
2025-03-02 13:14:06,997 - INFO - ðŸªœ Batch step - 1196 -- sub batch step 4787 -- lr 1.79e-04
2025-03-02 13:14:08,543 - INFO - Step 1196 -- ðŸ”„ Training Metrics
2025-03-02 13:14:08,543 - INFO - â”œâ”€â”€ Loss: 7.5476
2025-03-02 13:14:08,543 - INFO - â”œâ”€â”€ Learning Rate: 1.79e-04
2025-03-02 13:14:08,543 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:14:09,209 - INFO - ðŸªœ Batch step - 1197 -- sub batch step 4788 -- lr 1.80e-04
2025-03-02 13:14:11,358 - INFO - ðŸªœ Batch step - 1197 -- sub batch step 4789 -- lr 1.80e-04
2025-03-02 13:14:14,034 - INFO - ðŸªœ Batch step - 1197 -- sub batch step 4790 -- lr 1.80e-04
2025-03-02 13:14:16,184 - INFO - ðŸªœ Batch step - 1197 -- sub batch step 4791 -- lr 1.80e-04
2025-03-02 13:14:17,840 - INFO - Step 1197 -- ðŸ”„ Training Metrics
2025-03-02 13:14:17,841 - INFO - â”œâ”€â”€ Loss: 7.5514
2025-03-02 13:14:17,841 - INFO - â”œâ”€â”€ Learning Rate: 1.80e-04
2025-03-02 13:14:17,841 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:14:18,513 - INFO - ðŸªœ Batch step - 1198 -- sub batch step 4792 -- lr 1.80e-04
2025-03-02 13:14:20,659 - INFO - ðŸªœ Batch step - 1198 -- sub batch step 4793 -- lr 1.80e-04
2025-03-02 13:14:22,835 - INFO - ðŸªœ Batch step - 1198 -- sub batch step 4794 -- lr 1.80e-04
2025-03-02 13:14:24,987 - INFO - ðŸªœ Batch step - 1198 -- sub batch step 4795 -- lr 1.80e-04
2025-03-02 13:14:26,530 - INFO - Step 1198 -- ðŸ”„ Training Metrics
2025-03-02 13:14:26,530 - INFO - â”œâ”€â”€ Loss: 7.5619
2025-03-02 13:14:26,530 - INFO - â”œâ”€â”€ Learning Rate: 1.80e-04
2025-03-02 13:14:26,530 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:14:27,196 - INFO - ðŸªœ Batch step - 1199 -- sub batch step 4796 -- lr 1.80e-04
2025-03-02 13:14:29,348 - INFO - ðŸªœ Batch step - 1199 -- sub batch step 4797 -- lr 1.80e-04
2025-03-02 13:14:31,620 - INFO - ðŸªœ Batch step - 1199 -- sub batch step 4798 -- lr 1.80e-04
2025-03-02 13:14:33,782 - INFO - ðŸªœ Batch step - 1199 -- sub batch step 4799 -- lr 1.80e-04
2025-03-02 13:14:36,289 - INFO - Step 1199 -- ðŸ”„ Training Metrics
2025-03-02 13:14:36,289 - INFO - â”œâ”€â”€ Loss: 7.5551
2025-03-02 13:14:36,289 - INFO - â”œâ”€â”€ Learning Rate: 1.80e-04
2025-03-02 13:14:36,290 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:14:45,051 - INFO - ðŸªœ Batch step - 1200 -- sub batch step 4800 -- lr 1.80e-04
2025-03-02 13:14:47,208 - INFO - ðŸªœ Batch step - 1200 -- sub batch step 4801 -- lr 1.80e-04
2025-03-02 13:14:49,362 - INFO - ðŸªœ Batch step - 1200 -- sub batch step 4802 -- lr 1.80e-04
2025-03-02 13:14:51,529 - INFO - ðŸªœ Batch step - 1200 -- sub batch step 4803 -- lr 1.80e-04
2025-03-02 13:14:53,104 - INFO - Step 1200 -- ðŸ”„ Training Metrics
2025-03-02 13:14:53,104 - INFO - â”œâ”€â”€ Loss: 7.5571
2025-03-02 13:14:53,104 - INFO - â”œâ”€â”€ Learning Rate: 1.80e-04
2025-03-02 13:14:53,104 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:14:53,779 - INFO - ðŸªœ Batch step - 1201 -- sub batch step 4804 -- lr 1.80e-04
2025-03-02 13:14:55,931 - INFO - ðŸªœ Batch step - 1201 -- sub batch step 4805 -- lr 1.80e-04
2025-03-02 13:14:58,078 - INFO - ðŸªœ Batch step - 1201 -- sub batch step 4806 -- lr 1.80e-04
2025-03-02 13:15:00,670 - INFO - ðŸªœ Batch step - 1201 -- sub batch step 4807 -- lr 1.80e-04
2025-03-02 13:15:02,345 - INFO - Step 1201 -- ðŸ”„ Training Metrics
2025-03-02 13:15:02,345 - INFO - â”œâ”€â”€ Loss: 7.5696
2025-03-02 13:15:02,345 - INFO - â”œâ”€â”€ Learning Rate: 1.80e-04
2025-03-02 13:15:02,345 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:15:03,012 - INFO - ðŸªœ Batch step - 1202 -- sub batch step 4808 -- lr 1.80e-04
2025-03-02 13:15:05,170 - INFO - ðŸªœ Batch step - 1202 -- sub batch step 4809 -- lr 1.80e-04
2025-03-02 13:15:07,326 - INFO - ðŸªœ Batch step - 1202 -- sub batch step 4810 -- lr 1.80e-04
2025-03-02 13:15:09,489 - INFO - ðŸªœ Batch step - 1202 -- sub batch step 4811 -- lr 1.80e-04
2025-03-02 13:15:11,049 - INFO - Step 1202 -- ðŸ”„ Training Metrics
2025-03-02 13:15:11,050 - INFO - â”œâ”€â”€ Loss: 7.5537
2025-03-02 13:15:11,050 - INFO - â”œâ”€â”€ Learning Rate: 1.80e-04
2025-03-02 13:15:11,050 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:15:11,724 - INFO - ðŸªœ Batch step - 1203 -- sub batch step 4812 -- lr 1.80e-04
2025-03-02 13:15:13,874 - INFO - ðŸªœ Batch step - 1203 -- sub batch step 4813 -- lr 1.80e-04
2025-03-02 13:15:16,031 - INFO - ðŸªœ Batch step - 1203 -- sub batch step 4814 -- lr 1.80e-04
2025-03-02 13:15:18,486 - INFO - ðŸªœ Batch step - 1203 -- sub batch step 4815 -- lr 1.80e-04
2025-03-02 13:15:20,304 - INFO - Step 1203 -- ðŸ”„ Training Metrics
2025-03-02 13:15:20,304 - INFO - â”œâ”€â”€ Loss: 7.5713
2025-03-02 13:15:20,304 - INFO - â”œâ”€â”€ Learning Rate: 1.80e-04
2025-03-02 13:15:20,304 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:15:20,970 - INFO - ðŸªœ Batch step - 1204 -- sub batch step 4816 -- lr 1.81e-04
2025-03-02 13:15:23,120 - INFO - ðŸªœ Batch step - 1204 -- sub batch step 4817 -- lr 1.81e-04
2025-03-02 13:15:25,266 - INFO - ðŸªœ Batch step - 1204 -- sub batch step 4818 -- lr 1.81e-04
2025-03-02 13:15:27,441 - INFO - ðŸªœ Batch step - 1204 -- sub batch step 4819 -- lr 1.81e-04
2025-03-02 13:15:28,987 - INFO - Step 1204 -- ðŸ”„ Training Metrics
2025-03-02 13:15:28,987 - INFO - â”œâ”€â”€ Loss: 7.5594
2025-03-02 13:15:28,987 - INFO - â”œâ”€â”€ Learning Rate: 1.81e-04
2025-03-02 13:15:28,987 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:15:29,659 - INFO - ðŸªœ Batch step - 1205 -- sub batch step 4820 -- lr 1.81e-04
2025-03-02 13:15:31,807 - INFO - ðŸªœ Batch step - 1205 -- sub batch step 4821 -- lr 1.81e-04
2025-03-02 13:15:33,960 - INFO - ðŸªœ Batch step - 1205 -- sub batch step 4822 -- lr 1.81e-04
2025-03-02 13:15:36,372 - INFO - ðŸªœ Batch step - 1205 -- sub batch step 4823 -- lr 1.81e-04
2025-03-02 13:15:38,475 - INFO - Step 1205 -- ðŸ”„ Training Metrics
2025-03-02 13:15:38,476 - INFO - â”œâ”€â”€ Loss: 7.5562
2025-03-02 13:15:38,476 - INFO - â”œâ”€â”€ Learning Rate: 1.81e-04
2025-03-02 13:15:38,476 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:15:39,149 - INFO - ðŸªœ Batch step - 1206 -- sub batch step 4824 -- lr 1.81e-04
2025-03-02 13:15:41,299 - INFO - ðŸªœ Batch step - 1206 -- sub batch step 4825 -- lr 1.81e-04
2025-03-02 13:15:43,444 - INFO - ðŸªœ Batch step - 1206 -- sub batch step 4826 -- lr 1.81e-04
2025-03-02 13:15:45,608 - INFO - ðŸªœ Batch step - 1206 -- sub batch step 4827 -- lr 1.81e-04
2025-03-02 13:15:47,162 - INFO - Step 1206 -- ðŸ”„ Training Metrics
2025-03-02 13:15:47,163 - INFO - â”œâ”€â”€ Loss: 7.5324
2025-03-02 13:15:47,163 - INFO - â”œâ”€â”€ Learning Rate: 1.81e-04
2025-03-02 13:15:47,163 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:15:47,828 - INFO - ðŸªœ Batch step - 1207 -- sub batch step 4828 -- lr 1.81e-04
2025-03-02 13:15:49,981 - INFO - ðŸªœ Batch step - 1207 -- sub batch step 4829 -- lr 1.81e-04
2025-03-02 13:15:52,131 - INFO - ðŸªœ Batch step - 1207 -- sub batch step 4830 -- lr 1.81e-04
2025-03-02 13:15:54,498 - INFO - ðŸªœ Batch step - 1207 -- sub batch step 4831 -- lr 1.81e-04
2025-03-02 13:15:56,356 - INFO - Step 1207 -- ðŸ”„ Training Metrics
2025-03-02 13:15:56,357 - INFO - â”œâ”€â”€ Loss: 7.5413
2025-03-02 13:15:56,357 - INFO - â”œâ”€â”€ Learning Rate: 1.81e-04
2025-03-02 13:15:56,357 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:15:57,032 - INFO - ðŸªœ Batch step - 1208 -- sub batch step 4832 -- lr 1.81e-04
2025-03-02 13:15:59,178 - INFO - ðŸªœ Batch step - 1208 -- sub batch step 4833 -- lr 1.81e-04
2025-03-02 13:16:01,328 - INFO - ðŸªœ Batch step - 1208 -- sub batch step 4834 -- lr 1.81e-04
2025-03-02 13:16:03,495 - INFO - ðŸªœ Batch step - 1208 -- sub batch step 4835 -- lr 1.81e-04
2025-03-02 13:16:05,041 - INFO - Step 1208 -- ðŸ”„ Training Metrics
2025-03-02 13:16:05,041 - INFO - â”œâ”€â”€ Loss: 7.5465
2025-03-02 13:16:05,041 - INFO - â”œâ”€â”€ Learning Rate: 1.81e-04
2025-03-02 13:16:05,041 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:16:05,707 - INFO - ðŸªœ Batch step - 1209 -- sub batch step 4836 -- lr 1.81e-04
2025-03-02 13:16:07,858 - INFO - ðŸªœ Batch step - 1209 -- sub batch step 4837 -- lr 1.81e-04
2025-03-02 13:16:10,002 - INFO - ðŸªœ Batch step - 1209 -- sub batch step 4838 -- lr 1.81e-04
2025-03-02 13:16:12,361 - INFO - ðŸªœ Batch step - 1209 -- sub batch step 4839 -- lr 1.81e-04
2025-03-02 13:16:14,213 - INFO - Step 1209 -- ðŸ”„ Training Metrics
2025-03-02 13:16:14,213 - INFO - â”œâ”€â”€ Loss: 7.5358
2025-03-02 13:16:14,213 - INFO - â”œâ”€â”€ Learning Rate: 1.81e-04
2025-03-02 13:16:14,213 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:16:14,884 - INFO - ðŸªœ Batch step - 1210 -- sub batch step 4840 -- lr 1.81e-04
2025-03-02 13:16:17,031 - INFO - ðŸªœ Batch step - 1210 -- sub batch step 4841 -- lr 1.81e-04
2025-03-02 13:16:19,181 - INFO - ðŸªœ Batch step - 1210 -- sub batch step 4842 -- lr 1.81e-04
2025-03-02 13:16:21,344 - INFO - ðŸªœ Batch step - 1210 -- sub batch step 4843 -- lr 1.81e-04
2025-03-02 13:16:22,900 - INFO - Step 1210 -- ðŸ”„ Training Metrics
2025-03-02 13:16:22,900 - INFO - â”œâ”€â”€ Loss: 7.5476
2025-03-02 13:16:22,900 - INFO - â”œâ”€â”€ Learning Rate: 1.81e-04
2025-03-02 13:16:22,900 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:16:23,572 - INFO - ðŸªœ Batch step - 1211 -- sub batch step 4844 -- lr 1.82e-04
2025-03-02 13:16:25,721 - INFO - ðŸªœ Batch step - 1211 -- sub batch step 4845 -- lr 1.82e-04
2025-03-02 13:16:28,069 - INFO - ðŸªœ Batch step - 1211 -- sub batch step 4846 -- lr 1.82e-04
2025-03-02 13:16:30,226 - INFO - ðŸªœ Batch step - 1211 -- sub batch step 4847 -- lr 1.82e-04
2025-03-02 13:16:32,085 - INFO - Step 1211 -- ðŸ”„ Training Metrics
2025-03-02 13:16:32,085 - INFO - â”œâ”€â”€ Loss: 7.5526
2025-03-02 13:16:32,086 - INFO - â”œâ”€â”€ Learning Rate: 1.82e-04
2025-03-02 13:16:32,103 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:16:32,767 - INFO - ðŸªœ Batch step - 1212 -- sub batch step 4848 -- lr 1.82e-04
2025-03-02 13:16:34,925 - INFO - ðŸªœ Batch step - 1212 -- sub batch step 4849 -- lr 1.82e-04
2025-03-02 13:16:37,091 - INFO - ðŸªœ Batch step - 1212 -- sub batch step 4850 -- lr 1.82e-04
2025-03-02 13:16:39,237 - INFO - ðŸªœ Batch step - 1212 -- sub batch step 4851 -- lr 1.82e-04
2025-03-02 13:16:40,791 - INFO - Step 1212 -- ðŸ”„ Training Metrics
2025-03-02 13:16:40,791 - INFO - â”œâ”€â”€ Loss: 7.5608
2025-03-02 13:16:40,791 - INFO - â”œâ”€â”€ Learning Rate: 1.82e-04
2025-03-02 13:16:40,791 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:16:41,462 - INFO - ðŸªœ Batch step - 1213 -- sub batch step 4852 -- lr 1.82e-04
2025-03-02 13:16:43,610 - INFO - ðŸªœ Batch step - 1213 -- sub batch step 4853 -- lr 1.82e-04
2025-03-02 13:16:46,273 - INFO - ðŸªœ Batch step - 1213 -- sub batch step 4854 -- lr 1.82e-04
2025-03-02 13:16:48,425 - INFO - ðŸªœ Batch step - 1213 -- sub batch step 4855 -- lr 1.82e-04
2025-03-02 13:16:50,091 - INFO - Step 1213 -- ðŸ”„ Training Metrics
2025-03-02 13:16:50,091 - INFO - â”œâ”€â”€ Loss: 7.5324
2025-03-02 13:16:50,092 - INFO - â”œâ”€â”€ Learning Rate: 1.82e-04
2025-03-02 13:16:50,092 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:16:50,760 - INFO - ðŸªœ Batch step - 1214 -- sub batch step 4856 -- lr 1.82e-04
2025-03-02 13:16:52,913 - INFO - ðŸªœ Batch step - 1214 -- sub batch step 4857 -- lr 1.82e-04
2025-03-02 13:16:55,074 - INFO - ðŸªœ Batch step - 1214 -- sub batch step 4858 -- lr 1.82e-04
2025-03-02 13:16:57,227 - INFO - ðŸªœ Batch step - 1214 -- sub batch step 4859 -- lr 1.82e-04
2025-03-02 13:16:58,772 - INFO - Step 1214 -- ðŸ”„ Training Metrics
2025-03-02 13:16:58,773 - INFO - â”œâ”€â”€ Loss: 7.5191
2025-03-02 13:16:58,773 - INFO - â”œâ”€â”€ Learning Rate: 1.82e-04
2025-03-02 13:16:58,773 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:16:59,445 - INFO - ðŸªœ Batch step - 1215 -- sub batch step 4860 -- lr 1.82e-04
2025-03-02 13:17:01,591 - INFO - ðŸªœ Batch step - 1215 -- sub batch step 4861 -- lr 1.82e-04
2025-03-02 13:17:03,960 - INFO - ðŸªœ Batch step - 1215 -- sub batch step 4862 -- lr 1.82e-04
2025-03-02 13:17:06,111 - INFO - ðŸªœ Batch step - 1215 -- sub batch step 4863 -- lr 1.82e-04
2025-03-02 13:17:07,988 - INFO - Step 1215 -- ðŸ”„ Training Metrics
2025-03-02 13:17:07,989 - INFO - â”œâ”€â”€ Loss: 7.5468
2025-03-02 13:17:07,989 - INFO - â”œâ”€â”€ Learning Rate: 1.82e-04
2025-03-02 13:17:07,989 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:17:08,663 - INFO - ðŸªœ Batch step - 1216 -- sub batch step 4864 -- lr 1.82e-04
2025-03-02 13:17:10,814 - INFO - ðŸªœ Batch step - 1216 -- sub batch step 4865 -- lr 1.82e-04
2025-03-02 13:17:12,977 - INFO - ðŸªœ Batch step - 1216 -- sub batch step 4866 -- lr 1.82e-04
2025-03-02 13:17:15,130 - INFO - ðŸªœ Batch step - 1216 -- sub batch step 4867 -- lr 1.82e-04
2025-03-02 13:17:16,673 - INFO - Step 1216 -- ðŸ”„ Training Metrics
2025-03-02 13:17:16,673 - INFO - â”œâ”€â”€ Loss: 7.5499
2025-03-02 13:17:16,673 - INFO - â”œâ”€â”€ Learning Rate: 1.82e-04
2025-03-02 13:17:16,674 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:17:17,342 - INFO - ðŸªœ Batch step - 1217 -- sub batch step 4868 -- lr 1.83e-04
2025-03-02 13:17:19,496 - INFO - ðŸªœ Batch step - 1217 -- sub batch step 4869 -- lr 1.83e-04
2025-03-02 13:17:22,175 - INFO - ðŸªœ Batch step - 1217 -- sub batch step 4870 -- lr 1.83e-04
2025-03-02 13:17:24,324 - INFO - ðŸªœ Batch step - 1217 -- sub batch step 4871 -- lr 1.83e-04
2025-03-02 13:17:25,954 - INFO - Step 1217 -- ðŸ”„ Training Metrics
2025-03-02 13:17:25,954 - INFO - â”œâ”€â”€ Loss: 7.5369
2025-03-02 13:17:25,954 - INFO - â”œâ”€â”€ Learning Rate: 1.83e-04
2025-03-02 13:17:25,955 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:17:26,628 - INFO - ðŸªœ Batch step - 1218 -- sub batch step 4872 -- lr 1.83e-04
2025-03-02 13:17:28,776 - INFO - ðŸªœ Batch step - 1218 -- sub batch step 4873 -- lr 1.83e-04
2025-03-02 13:17:30,942 - INFO - ðŸªœ Batch step - 1218 -- sub batch step 4874 -- lr 1.83e-04
2025-03-02 13:17:33,093 - INFO - ðŸªœ Batch step - 1218 -- sub batch step 4875 -- lr 1.83e-04
2025-03-02 13:17:34,650 - INFO - Step 1218 -- ðŸ”„ Training Metrics
2025-03-02 13:17:34,651 - INFO - â”œâ”€â”€ Loss: 7.5416
2025-03-02 13:17:34,651 - INFO - â”œâ”€â”€ Learning Rate: 1.83e-04
2025-03-02 13:17:34,651 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:17:35,318 - INFO - ðŸªœ Batch step - 1219 -- sub batch step 4876 -- lr 1.83e-04
2025-03-02 13:17:37,471 - INFO - ðŸªœ Batch step - 1219 -- sub batch step 4877 -- lr 1.83e-04
2025-03-02 13:17:39,768 - INFO - ðŸªœ Batch step - 1219 -- sub batch step 4878 -- lr 1.83e-04
2025-03-02 13:17:41,923 - INFO - ðŸªœ Batch step - 1219 -- sub batch step 4879 -- lr 1.83e-04
2025-03-02 13:17:43,455 - INFO - Step 1219 -- ðŸ”„ Training Metrics
2025-03-02 13:17:43,456 - INFO - â”œâ”€â”€ Loss: 7.5301
2025-03-02 13:17:43,456 - INFO - â”œâ”€â”€ Learning Rate: 1.83e-04
2025-03-02 13:17:43,456 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:17:44,730 - INFO - ðŸªœ Batch step - 1220 -- sub batch step 4880 -- lr 1.83e-04
2025-03-02 13:17:46,885 - INFO - ðŸªœ Batch step - 1220 -- sub batch step 4881 -- lr 1.83e-04
2025-03-02 13:17:49,045 - INFO - ðŸªœ Batch step - 1220 -- sub batch step 4882 -- lr 1.83e-04
2025-03-02 13:17:51,211 - INFO - ðŸªœ Batch step - 1220 -- sub batch step 4883 -- lr 1.83e-04
2025-03-02 13:17:52,821 - INFO - Step 1220 -- ðŸ”„ Training Metrics
2025-03-02 13:17:52,822 - INFO - â”œâ”€â”€ Loss: 7.5515
2025-03-02 13:17:52,822 - INFO - â”œâ”€â”€ Learning Rate: 1.83e-04
2025-03-02 13:17:52,822 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:17:53,494 - INFO - ðŸªœ Batch step - 1221 -- sub batch step 4884 -- lr 1.83e-04
2025-03-02 13:17:55,652 - INFO - ðŸªœ Batch step - 1221 -- sub batch step 4885 -- lr 1.83e-04
2025-03-02 13:17:57,803 - INFO - ðŸªœ Batch step - 1221 -- sub batch step 4886 -- lr 1.83e-04
2025-03-02 13:18:00,499 - INFO - ðŸªœ Batch step - 1221 -- sub batch step 4887 -- lr 1.83e-04
2025-03-02 13:18:02,166 - INFO - Step 1221 -- ðŸ”„ Training Metrics
2025-03-02 13:18:02,166 - INFO - â”œâ”€â”€ Loss: 7.5264
2025-03-02 13:18:02,166 - INFO - â”œâ”€â”€ Learning Rate: 1.83e-04
2025-03-02 13:18:02,166 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:18:02,832 - INFO - ðŸªœ Batch step - 1222 -- sub batch step 4888 -- lr 1.83e-04
2025-03-02 13:18:04,993 - INFO - ðŸªœ Batch step - 1222 -- sub batch step 4889 -- lr 1.83e-04
2025-03-02 13:18:07,152 - INFO - ðŸªœ Batch step - 1222 -- sub batch step 4890 -- lr 1.83e-04
2025-03-02 13:18:09,324 - INFO - ðŸªœ Batch step - 1222 -- sub batch step 4891 -- lr 1.83e-04
2025-03-02 13:18:10,850 - INFO - Step 1222 -- ðŸ”„ Training Metrics
2025-03-02 13:18:10,850 - INFO - â”œâ”€â”€ Loss: 7.5348
2025-03-02 13:18:10,850 - INFO - â”œâ”€â”€ Learning Rate: 1.83e-04
2025-03-02 13:18:10,850 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:18:11,523 - INFO - ðŸªœ Batch step - 1223 -- sub batch step 4892 -- lr 1.83e-04
2025-03-02 13:18:13,672 - INFO - ðŸªœ Batch step - 1223 -- sub batch step 4893 -- lr 1.83e-04
2025-03-02 13:18:15,831 - INFO - ðŸªœ Batch step - 1223 -- sub batch step 4894 -- lr 1.83e-04
2025-03-02 13:18:18,327 - INFO - ðŸªœ Batch step - 1223 -- sub batch step 4895 -- lr 1.83e-04
2025-03-02 13:18:19,997 - INFO - Step 1223 -- ðŸ”„ Training Metrics
2025-03-02 13:18:19,997 - INFO - â”œâ”€â”€ Loss: 7.5322
2025-03-02 13:18:19,998 - INFO - â”œâ”€â”€ Learning Rate: 1.83e-04
2025-03-02 13:18:19,998 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:18:20,664 - INFO - ðŸªœ Batch step - 1224 -- sub batch step 4896 -- lr 1.84e-04
2025-03-02 13:18:22,824 - INFO - ðŸªœ Batch step - 1224 -- sub batch step 4897 -- lr 1.84e-04
2025-03-02 13:18:24,972 - INFO - ðŸªœ Batch step - 1224 -- sub batch step 4898 -- lr 1.84e-04
2025-03-02 13:18:27,145 - INFO - ðŸªœ Batch step - 1224 -- sub batch step 4899 -- lr 1.84e-04
2025-03-02 13:18:28,675 - INFO - Step 1224 -- ðŸ”„ Training Metrics
2025-03-02 13:18:28,675 - INFO - â”œâ”€â”€ Loss: 7.5379
2025-03-02 13:18:28,676 - INFO - â”œâ”€â”€ Learning Rate: 1.84e-04
2025-03-02 13:18:28,676 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:18:29,347 - INFO - ðŸªœ Batch step - 1225 -- sub batch step 4900 -- lr 1.84e-04
2025-03-02 13:18:31,497 - INFO - ðŸªœ Batch step - 1225 -- sub batch step 4901 -- lr 1.84e-04
2025-03-02 13:18:33,652 - INFO - ðŸªœ Batch step - 1225 -- sub batch step 4902 -- lr 1.84e-04
2025-03-02 13:18:36,360 - INFO - ðŸªœ Batch step - 1225 -- sub batch step 4903 -- lr 1.84e-04
2025-03-02 13:18:37,902 - INFO - Step 1225 -- ðŸ”„ Training Metrics
2025-03-02 13:18:37,902 - INFO - â”œâ”€â”€ Loss: 7.5266
2025-03-02 13:18:37,902 - INFO - â”œâ”€â”€ Learning Rate: 1.84e-04
2025-03-02 13:18:37,902 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:18:38,578 - INFO - ðŸªœ Batch step - 1226 -- sub batch step 4904 -- lr 1.84e-04
2025-03-02 13:18:40,735 - INFO - ðŸªœ Batch step - 1226 -- sub batch step 4905 -- lr 1.84e-04
2025-03-02 13:18:42,883 - INFO - ðŸªœ Batch step - 1226 -- sub batch step 4906 -- lr 1.84e-04
2025-03-02 13:18:45,057 - INFO - ðŸªœ Batch step - 1226 -- sub batch step 4907 -- lr 1.84e-04
2025-03-02 13:18:46,589 - INFO - Step 1226 -- ðŸ”„ Training Metrics
2025-03-02 13:18:46,589 - INFO - â”œâ”€â”€ Loss: 7.5453
2025-03-02 13:18:46,589 - INFO - â”œâ”€â”€ Learning Rate: 1.84e-04
2025-03-02 13:18:46,590 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:18:47,259 - INFO - ðŸªœ Batch step - 1227 -- sub batch step 4908 -- lr 1.84e-04
2025-03-02 13:18:49,418 - INFO - ðŸªœ Batch step - 1227 -- sub batch step 4909 -- lr 1.84e-04
2025-03-02 13:18:51,575 - INFO - ðŸªœ Batch step - 1227 -- sub batch step 4910 -- lr 1.84e-04
2025-03-02 13:18:54,250 - INFO - ðŸªœ Batch step - 1227 -- sub batch step 4911 -- lr 1.84e-04
2025-03-02 13:18:55,741 - INFO - Step 1227 -- ðŸ”„ Training Metrics
2025-03-02 13:18:55,741 - INFO - â”œâ”€â”€ Loss: 7.5297
2025-03-02 13:18:55,741 - INFO - â”œâ”€â”€ Learning Rate: 1.84e-04
2025-03-02 13:18:55,741 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:18:56,413 - INFO - ðŸªœ Batch step - 1228 -- sub batch step 4912 -- lr 1.84e-04
2025-03-02 13:18:58,564 - INFO - ðŸªœ Batch step - 1228 -- sub batch step 4913 -- lr 1.84e-04
2025-03-02 13:19:00,719 - INFO - ðŸªœ Batch step - 1228 -- sub batch step 4914 -- lr 1.84e-04
2025-03-02 13:19:02,891 - INFO - ðŸªœ Batch step - 1228 -- sub batch step 4915 -- lr 1.84e-04
2025-03-02 13:19:04,438 - INFO - Step 1228 -- ðŸ”„ Training Metrics
2025-03-02 13:19:04,438 - INFO - â”œâ”€â”€ Loss: 7.5073
2025-03-02 13:19:04,438 - INFO - â”œâ”€â”€ Learning Rate: 1.84e-04
2025-03-02 13:19:04,438 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:19:05,107 - INFO - ðŸªœ Batch step - 1229 -- sub batch step 4916 -- lr 1.84e-04
2025-03-02 13:19:07,265 - INFO - ðŸªœ Batch step - 1229 -- sub batch step 4917 -- lr 1.84e-04
2025-03-02 13:19:09,412 - INFO - ðŸªœ Batch step - 1229 -- sub batch step 4918 -- lr 1.84e-04
2025-03-02 13:19:11,815 - INFO - ðŸªœ Batch step - 1229 -- sub batch step 4919 -- lr 1.84e-04
2025-03-02 13:19:13,555 - INFO - Step 1229 -- ðŸ”„ Training Metrics
2025-03-02 13:19:13,556 - INFO - â”œâ”€â”€ Loss: 7.5322
2025-03-02 13:19:13,556 - INFO - â”œâ”€â”€ Learning Rate: 1.84e-04
2025-03-02 13:19:13,556 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:19:14,229 - INFO - ðŸªœ Batch step - 1230 -- sub batch step 4920 -- lr 1.84e-04
2025-03-02 13:19:16,383 - INFO - ðŸªœ Batch step - 1230 -- sub batch step 4921 -- lr 1.84e-04
2025-03-02 13:19:18,536 - INFO - ðŸªœ Batch step - 1230 -- sub batch step 4922 -- lr 1.84e-04
2025-03-02 13:19:20,705 - INFO - ðŸªœ Batch step - 1230 -- sub batch step 4923 -- lr 1.84e-04
2025-03-02 13:19:22,232 - INFO - Step 1230 -- ðŸ”„ Training Metrics
2025-03-02 13:19:22,233 - INFO - â”œâ”€â”€ Loss: 7.5106
2025-03-02 13:19:22,233 - INFO - â”œâ”€â”€ Learning Rate: 1.84e-04
2025-03-02 13:19:22,233 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:19:22,902 - INFO - ðŸªœ Batch step - 1231 -- sub batch step 4924 -- lr 1.85e-04
2025-03-02 13:19:25,060 - INFO - ðŸªœ Batch step - 1231 -- sub batch step 4925 -- lr 1.85e-04
2025-03-02 13:19:27,703 - INFO - ðŸªœ Batch step - 1231 -- sub batch step 4926 -- lr 1.85e-04
2025-03-02 13:19:29,863 - INFO - ðŸªœ Batch step - 1231 -- sub batch step 4927 -- lr 1.85e-04
2025-03-02 13:19:31,539 - INFO - Step 1231 -- ðŸ”„ Training Metrics
2025-03-02 13:19:31,539 - INFO - â”œâ”€â”€ Loss: 7.5151
2025-03-02 13:19:31,539 - INFO - â”œâ”€â”€ Learning Rate: 1.85e-04
2025-03-02 13:19:31,539 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:19:32,210 - INFO - ðŸªœ Batch step - 1232 -- sub batch step 4928 -- lr 1.85e-04
2025-03-02 13:19:34,369 - INFO - ðŸªœ Batch step - 1232 -- sub batch step 4929 -- lr 1.85e-04
2025-03-02 13:19:36,534 - INFO - ðŸªœ Batch step - 1232 -- sub batch step 4930 -- lr 1.85e-04
2025-03-02 13:19:38,686 - INFO - ðŸªœ Batch step - 1232 -- sub batch step 4931 -- lr 1.85e-04
2025-03-02 13:19:40,230 - INFO - Step 1232 -- ðŸ”„ Training Metrics
2025-03-02 13:19:40,230 - INFO - â”œâ”€â”€ Loss: 7.5223
2025-03-02 13:19:40,230 - INFO - â”œâ”€â”€ Learning Rate: 1.85e-04
2025-03-02 13:19:40,230 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:19:40,903 - INFO - ðŸªœ Batch step - 1233 -- sub batch step 4932 -- lr 1.85e-04
2025-03-02 13:19:43,053 - INFO - ðŸªœ Batch step - 1233 -- sub batch step 4933 -- lr 1.85e-04
2025-03-02 13:19:45,688 - INFO - ðŸªœ Batch step - 1233 -- sub batch step 4934 -- lr 1.85e-04
2025-03-02 13:19:47,840 - INFO - ðŸªœ Batch step - 1233 -- sub batch step 4935 -- lr 1.85e-04
2025-03-02 13:19:49,497 - INFO - Step 1233 -- ðŸ”„ Training Metrics
2025-03-02 13:19:49,497 - INFO - â”œâ”€â”€ Loss: 7.5164
2025-03-02 13:19:49,497 - INFO - â”œâ”€â”€ Learning Rate: 1.85e-04
2025-03-02 13:19:49,497 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:19:50,165 - INFO - ðŸªœ Batch step - 1234 -- sub batch step 4936 -- lr 1.85e-04
2025-03-02 13:19:52,325 - INFO - ðŸªœ Batch step - 1234 -- sub batch step 4937 -- lr 1.85e-04
2025-03-02 13:19:54,484 - INFO - ðŸªœ Batch step - 1234 -- sub batch step 4938 -- lr 1.85e-04
2025-03-02 13:19:56,642 - INFO - ðŸªœ Batch step - 1234 -- sub batch step 4939 -- lr 1.85e-04
2025-03-02 13:19:58,202 - INFO - Step 1234 -- ðŸ”„ Training Metrics
2025-03-02 13:19:58,202 - INFO - â”œâ”€â”€ Loss: 7.5053
2025-03-02 13:19:58,202 - INFO - â”œâ”€â”€ Learning Rate: 1.85e-04
2025-03-02 13:19:58,202 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:19:58,876 - INFO - ðŸªœ Batch step - 1235 -- sub batch step 4940 -- lr 1.85e-04
2025-03-02 13:20:01,031 - INFO - ðŸªœ Batch step - 1235 -- sub batch step 4941 -- lr 1.85e-04
2025-03-02 13:20:03,732 - INFO - ðŸªœ Batch step - 1235 -- sub batch step 4942 -- lr 1.85e-04
2025-03-02 13:20:05,881 - INFO - ðŸªœ Batch step - 1235 -- sub batch step 4943 -- lr 1.85e-04
2025-03-02 13:20:08,829 - INFO - Step 1235 -- ðŸ”„ Training Metrics
2025-03-02 13:20:08,829 - INFO - â”œâ”€â”€ Loss: 7.5160
2025-03-02 13:20:08,829 - INFO - â”œâ”€â”€ Learning Rate: 1.85e-04
2025-03-02 13:20:08,829 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:20:09,509 - INFO - ðŸªœ Batch step - 1236 -- sub batch step 4944 -- lr 1.85e-04
2025-03-02 13:20:11,664 - INFO - ðŸªœ Batch step - 1236 -- sub batch step 4945 -- lr 1.85e-04
2025-03-02 13:20:13,828 - INFO - ðŸªœ Batch step - 1236 -- sub batch step 4946 -- lr 1.85e-04
2025-03-02 13:20:15,984 - INFO - ðŸªœ Batch step - 1236 -- sub batch step 4947 -- lr 1.85e-04
2025-03-02 13:20:17,514 - INFO - Step 1236 -- ðŸ”„ Training Metrics
2025-03-02 13:20:17,514 - INFO - â”œâ”€â”€ Loss: 7.5227
2025-03-02 13:20:17,515 - INFO - â”œâ”€â”€ Learning Rate: 1.85e-04
2025-03-02 13:20:17,515 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:20:18,181 - INFO - ðŸªœ Batch step - 1237 -- sub batch step 4948 -- lr 1.86e-04
2025-03-02 13:20:20,345 - INFO - ðŸªœ Batch step - 1237 -- sub batch step 4949 -- lr 1.86e-04
2025-03-02 13:20:22,733 - INFO - ðŸªœ Batch step - 1237 -- sub batch step 4950 -- lr 1.86e-04
2025-03-02 13:20:24,886 - INFO - ðŸªœ Batch step - 1237 -- sub batch step 4951 -- lr 1.86e-04
2025-03-02 13:20:26,724 - INFO - Step 1237 -- ðŸ”„ Training Metrics
2025-03-02 13:20:26,725 - INFO - â”œâ”€â”€ Loss: 7.5248
2025-03-02 13:20:26,725 - INFO - â”œâ”€â”€ Learning Rate: 1.86e-04
2025-03-02 13:20:26,725 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:20:27,397 - INFO - ðŸªœ Batch step - 1238 -- sub batch step 4952 -- lr 1.86e-04
2025-03-02 13:20:29,547 - INFO - ðŸªœ Batch step - 1238 -- sub batch step 4953 -- lr 1.86e-04
2025-03-02 13:20:31,725 - INFO - ðŸªœ Batch step - 1238 -- sub batch step 4954 -- lr 1.86e-04
2025-03-02 13:20:33,878 - INFO - ðŸªœ Batch step - 1238 -- sub batch step 4955 -- lr 1.86e-04
2025-03-02 13:20:35,429 - INFO - Step 1238 -- ðŸ”„ Training Metrics
2025-03-02 13:20:35,430 - INFO - â”œâ”€â”€ Loss: 7.5439
2025-03-02 13:20:35,430 - INFO - â”œâ”€â”€ Learning Rate: 1.86e-04
2025-03-02 13:20:35,430 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:20:36,098 - INFO - ðŸªœ Batch step - 1239 -- sub batch step 4956 -- lr 1.86e-04
2025-03-02 13:20:38,257 - INFO - ðŸªœ Batch step - 1239 -- sub batch step 4957 -- lr 1.86e-04
2025-03-02 13:20:40,530 - INFO - ðŸªœ Batch step - 1239 -- sub batch step 4958 -- lr 1.86e-04
2025-03-02 13:20:42,691 - INFO - ðŸªœ Batch step - 1239 -- sub batch step 4959 -- lr 1.86e-04
2025-03-02 13:20:44,343 - INFO - Step 1239 -- ðŸ”„ Training Metrics
2025-03-02 13:20:44,343 - INFO - â”œâ”€â”€ Loss: 7.5168
2025-03-02 13:20:44,343 - INFO - â”œâ”€â”€ Learning Rate: 1.86e-04
2025-03-02 13:20:44,343 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:20:45,668 - INFO - ðŸªœ Batch step - 1240 -- sub batch step 4960 -- lr 1.86e-04
2025-03-02 13:20:47,820 - INFO - ðŸªœ Batch step - 1240 -- sub batch step 4961 -- lr 1.86e-04
2025-03-02 13:20:49,980 - INFO - ðŸªœ Batch step - 1240 -- sub batch step 4962 -- lr 1.86e-04
2025-03-02 13:20:52,143 - INFO - ðŸªœ Batch step - 1240 -- sub batch step 4963 -- lr 1.86e-04
2025-03-02 13:20:53,703 - INFO - Step 1240 -- ðŸ”„ Training Metrics
2025-03-02 13:20:53,703 - INFO - â”œâ”€â”€ Loss: 7.5293
2025-03-02 13:20:53,703 - INFO - â”œâ”€â”€ Learning Rate: 1.86e-04
2025-03-02 13:20:53,703 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:20:54,382 - INFO - ðŸªœ Batch step - 1241 -- sub batch step 4964 -- lr 1.86e-04
2025-03-02 13:20:56,535 - INFO - ðŸªœ Batch step - 1241 -- sub batch step 4965 -- lr 1.86e-04
2025-03-02 13:20:58,683 - INFO - ðŸªœ Batch step - 1241 -- sub batch step 4966 -- lr 1.86e-04
2025-03-02 13:21:01,302 - INFO - ðŸªœ Batch step - 1241 -- sub batch step 4967 -- lr 1.86e-04
2025-03-02 13:21:02,917 - INFO - Step 1241 -- ðŸ”„ Training Metrics
2025-03-02 13:21:02,917 - INFO - â”œâ”€â”€ Loss: 7.5149
2025-03-02 13:21:02,917 - INFO - â”œâ”€â”€ Learning Rate: 1.86e-04
2025-03-02 13:21:02,917 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:21:03,591 - INFO - ðŸªœ Batch step - 1242 -- sub batch step 4968 -- lr 1.86e-04
2025-03-02 13:21:05,752 - INFO - ðŸªœ Batch step - 1242 -- sub batch step 4969 -- lr 1.86e-04
2025-03-02 13:21:07,911 - INFO - ðŸªœ Batch step - 1242 -- sub batch step 4970 -- lr 1.86e-04
2025-03-02 13:21:10,074 - INFO - ðŸªœ Batch step - 1242 -- sub batch step 4971 -- lr 1.86e-04
2025-03-02 13:21:11,623 - INFO - Step 1242 -- ðŸ”„ Training Metrics
2025-03-02 13:21:11,623 - INFO - â”œâ”€â”€ Loss: 7.5107
2025-03-02 13:21:11,623 - INFO - â”œâ”€â”€ Learning Rate: 1.86e-04
2025-03-02 13:21:11,623 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:21:12,303 - INFO - ðŸªœ Batch step - 1243 -- sub batch step 4972 -- lr 1.86e-04
2025-03-02 13:21:14,458 - INFO - ðŸªœ Batch step - 1243 -- sub batch step 4973 -- lr 1.86e-04
2025-03-02 13:21:16,612 - INFO - ðŸªœ Batch step - 1243 -- sub batch step 4974 -- lr 1.86e-04
2025-03-02 13:21:19,421 - INFO - ðŸªœ Batch step - 1243 -- sub batch step 4975 -- lr 1.86e-04
2025-03-02 13:21:20,912 - INFO - Step 1243 -- ðŸ”„ Training Metrics
2025-03-02 13:21:20,912 - INFO - â”œâ”€â”€ Loss: 7.5254
2025-03-02 13:21:20,912 - INFO - â”œâ”€â”€ Learning Rate: 1.86e-04
2025-03-02 13:21:20,912 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:21:21,581 - INFO - ðŸªœ Batch step - 1244 -- sub batch step 4976 -- lr 1.87e-04
2025-03-02 13:21:23,743 - INFO - ðŸªœ Batch step - 1244 -- sub batch step 4977 -- lr 1.87e-04
2025-03-02 13:21:26,137 - INFO - ðŸªœ Batch step - 1244 -- sub batch step 4978 -- lr 1.87e-04
2025-03-02 13:21:28,632 - INFO - ðŸªœ Batch step - 1244 -- sub batch step 4979 -- lr 1.87e-04
2025-03-02 13:21:30,291 - INFO - Step 1244 -- ðŸ”„ Training Metrics
2025-03-02 13:21:30,291 - INFO - â”œâ”€â”€ Loss: 7.5063
2025-03-02 13:21:30,291 - INFO - â”œâ”€â”€ Learning Rate: 1.87e-04
2025-03-02 13:21:30,291 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:21:31,087 - INFO - ðŸªœ Batch step - 1245 -- sub batch step 4980 -- lr 1.87e-04
2025-03-02 13:21:33,238 - INFO - ðŸªœ Batch step - 1245 -- sub batch step 4981 -- lr 1.87e-04
2025-03-02 13:21:35,392 - INFO - ðŸªœ Batch step - 1245 -- sub batch step 4982 -- lr 1.87e-04
2025-03-02 13:21:38,100 - INFO - ðŸªœ Batch step - 1245 -- sub batch step 4983 -- lr 1.87e-04
2025-03-02 13:21:39,640 - INFO - Step 1245 -- ðŸ”„ Training Metrics
2025-03-02 13:21:39,640 - INFO - â”œâ”€â”€ Loss: 7.5023
2025-03-02 13:21:39,640 - INFO - â”œâ”€â”€ Learning Rate: 1.87e-04
2025-03-02 13:21:39,640 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:21:40,316 - INFO - ðŸªœ Batch step - 1246 -- sub batch step 4984 -- lr 1.87e-04
2025-03-02 13:21:42,474 - INFO - ðŸªœ Batch step - 1246 -- sub batch step 4985 -- lr 1.87e-04
2025-03-02 13:21:44,624 - INFO - ðŸªœ Batch step - 1246 -- sub batch step 4986 -- lr 1.87e-04
2025-03-02 13:21:46,799 - INFO - ðŸªœ Batch step - 1246 -- sub batch step 4987 -- lr 1.87e-04
2025-03-02 13:21:48,382 - INFO - Step 1246 -- ðŸ”„ Training Metrics
2025-03-02 13:21:48,382 - INFO - â”œâ”€â”€ Loss: 7.4941
2025-03-02 13:21:48,382 - INFO - â”œâ”€â”€ Learning Rate: 1.87e-04
2025-03-02 13:21:48,383 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:21:49,051 - INFO - ðŸªœ Batch step - 1247 -- sub batch step 4988 -- lr 1.87e-04
2025-03-02 13:21:51,210 - INFO - ðŸªœ Batch step - 1247 -- sub batch step 4989 -- lr 1.87e-04
2025-03-02 13:21:53,364 - INFO - ðŸªœ Batch step - 1247 -- sub batch step 4990 -- lr 1.87e-04
2025-03-02 13:21:55,948 - INFO - ðŸªœ Batch step - 1247 -- sub batch step 4991 -- lr 1.87e-04
2025-03-02 13:21:57,845 - INFO - Step 1247 -- ðŸ”„ Training Metrics
2025-03-02 13:21:57,845 - INFO - â”œâ”€â”€ Loss: 7.5275
2025-03-02 13:21:57,845 - INFO - â”œâ”€â”€ Learning Rate: 1.87e-04
2025-03-02 13:21:57,846 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:21:58,531 - INFO - ðŸªœ Batch step - 1248 -- sub batch step 4992 -- lr 1.87e-04
2025-03-02 13:22:00,684 - INFO - ðŸªœ Batch step - 1248 -- sub batch step 4993 -- lr 1.87e-04
2025-03-02 13:22:02,843 - INFO - ðŸªœ Batch step - 1248 -- sub batch step 4994 -- lr 1.87e-04
2025-03-02 13:22:05,012 - INFO - ðŸªœ Batch step - 1248 -- sub batch step 4995 -- lr 1.87e-04
2025-03-02 13:22:06,557 - INFO - Step 1248 -- ðŸ”„ Training Metrics
2025-03-02 13:22:06,557 - INFO - â”œâ”€â”€ Loss: 7.5366
2025-03-02 13:22:06,557 - INFO - â”œâ”€â”€ Learning Rate: 1.87e-04
2025-03-02 13:22:06,557 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:22:07,227 - INFO - ðŸªœ Batch step - 1249 -- sub batch step 4996 -- lr 1.87e-04
2025-03-02 13:22:09,386 - INFO - ðŸªœ Batch step - 1249 -- sub batch step 4997 -- lr 1.87e-04
2025-03-02 13:22:11,534 - INFO - ðŸªœ Batch step - 1249 -- sub batch step 4998 -- lr 1.87e-04
2025-03-02 13:22:14,182 - INFO - ðŸªœ Batch step - 1249 -- sub batch step 4999 -- lr 1.87e-04
2025-03-02 13:22:15,725 - INFO - Step 1249 -- ðŸ”„ Training Metrics
2025-03-02 13:22:15,725 - INFO - â”œâ”€â”€ Loss: 7.5244
2025-03-02 13:22:15,725 - INFO - â”œâ”€â”€ Learning Rate: 1.87e-04
2025-03-02 13:22:15,725 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:22:16,402 - INFO - ðŸªœ Batch step - 1250 -- sub batch step 5000 -- lr 1.87e-04
2025-03-02 13:22:18,553 - INFO - ðŸªœ Batch step - 1250 -- sub batch step 5001 -- lr 1.87e-04
2025-03-02 13:22:20,707 - INFO - ðŸªœ Batch step - 1250 -- sub batch step 5002 -- lr 1.87e-04
2025-03-02 13:22:22,869 - INFO - ðŸªœ Batch step - 1250 -- sub batch step 5003 -- lr 1.87e-04
2025-03-02 13:22:24,408 - INFO - Step 1250 -- ðŸ”„ Training Metrics
2025-03-02 13:22:24,409 - INFO - â”œâ”€â”€ Loss: 7.5285
2025-03-02 13:22:24,409 - INFO - â”œâ”€â”€ Learning Rate: 1.87e-04
2025-03-02 13:22:24,409 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:22:25,084 - INFO - ðŸªœ Batch step - 1251 -- sub batch step 5004 -- lr 1.88e-04
2025-03-02 13:22:27,237 - INFO - ðŸªœ Batch step - 1251 -- sub batch step 5005 -- lr 1.88e-04
2025-03-02 13:22:29,596 - INFO - ðŸªœ Batch step - 1251 -- sub batch step 5006 -- lr 1.88e-04
2025-03-02 13:22:31,758 - INFO - ðŸªœ Batch step - 1251 -- sub batch step 5007 -- lr 1.88e-04
2025-03-02 13:22:33,701 - INFO - Step 1251 -- ðŸ”„ Training Metrics
2025-03-02 13:22:33,701 - INFO - â”œâ”€â”€ Loss: 7.5246
2025-03-02 13:22:33,701 - INFO - â”œâ”€â”€ Learning Rate: 1.88e-04
2025-03-02 13:22:33,701 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:22:34,370 - INFO - ðŸªœ Batch step - 1252 -- sub batch step 5008 -- lr 1.88e-04
2025-03-02 13:22:36,526 - INFO - ðŸªœ Batch step - 1252 -- sub batch step 5009 -- lr 1.88e-04
2025-03-02 13:22:38,701 - INFO - ðŸªœ Batch step - 1252 -- sub batch step 5010 -- lr 1.88e-04
2025-03-02 13:22:40,850 - INFO - ðŸªœ Batch step - 1252 -- sub batch step 5011 -- lr 1.88e-04
2025-03-02 13:22:42,395 - INFO - Step 1252 -- ðŸ”„ Training Metrics
2025-03-02 13:22:42,396 - INFO - â”œâ”€â”€ Loss: 7.5099
2025-03-02 13:22:42,396 - INFO - â”œâ”€â”€ Learning Rate: 1.88e-04
2025-03-02 13:22:42,396 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:22:43,068 - INFO - ðŸªœ Batch step - 1253 -- sub batch step 5012 -- lr 1.88e-04
2025-03-02 13:22:45,225 - INFO - ðŸªœ Batch step - 1253 -- sub batch step 5013 -- lr 1.88e-04
2025-03-02 13:22:48,028 - INFO - ðŸªœ Batch step - 1253 -- sub batch step 5014 -- lr 1.88e-04
2025-03-02 13:22:50,192 - INFO - ðŸªœ Batch step - 1253 -- sub batch step 5015 -- lr 1.88e-04
2025-03-02 13:22:51,683 - INFO - Step 1253 -- ðŸ”„ Training Metrics
2025-03-02 13:22:51,683 - INFO - â”œâ”€â”€ Loss: 7.5127
2025-03-02 13:22:51,683 - INFO - â”œâ”€â”€ Learning Rate: 1.88e-04
2025-03-02 13:22:51,684 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:22:52,353 - INFO - ðŸªœ Batch step - 1254 -- sub batch step 5016 -- lr 1.88e-04
2025-03-02 13:22:54,513 - INFO - ðŸªœ Batch step - 1254 -- sub batch step 5017 -- lr 1.88e-04
2025-03-02 13:22:56,675 - INFO - ðŸªœ Batch step - 1254 -- sub batch step 5018 -- lr 1.88e-04
2025-03-02 13:22:58,835 - INFO - ðŸªœ Batch step - 1254 -- sub batch step 5019 -- lr 1.88e-04
2025-03-02 13:23:00,388 - INFO - Step 1254 -- ðŸ”„ Training Metrics
2025-03-02 13:23:00,388 - INFO - â”œâ”€â”€ Loss: 7.5166
2025-03-02 13:23:00,388 - INFO - â”œâ”€â”€ Learning Rate: 1.88e-04
2025-03-02 13:23:00,388 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:23:01,064 - INFO - ðŸªœ Batch step - 1255 -- sub batch step 5020 -- lr 1.88e-04
2025-03-02 13:23:03,219 - INFO - ðŸªœ Batch step - 1255 -- sub batch step 5021 -- lr 1.88e-04
2025-03-02 13:23:05,909 - INFO - ðŸªœ Batch step - 1255 -- sub batch step 5022 -- lr 1.88e-04
2025-03-02 13:23:08,064 - INFO - ðŸªœ Batch step - 1255 -- sub batch step 5023 -- lr 1.88e-04
2025-03-02 13:23:09,554 - INFO - Step 1255 -- ðŸ”„ Training Metrics
2025-03-02 13:23:09,555 - INFO - â”œâ”€â”€ Loss: 7.5204
2025-03-02 13:23:09,555 - INFO - â”œâ”€â”€ Learning Rate: 1.88e-04
2025-03-02 13:23:09,555 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:23:10,230 - INFO - ðŸªœ Batch step - 1256 -- sub batch step 5024 -- lr 1.88e-04
2025-03-02 13:23:12,387 - INFO - ðŸªœ Batch step - 1256 -- sub batch step 5025 -- lr 1.88e-04
2025-03-02 13:23:14,551 - INFO - ðŸªœ Batch step - 1256 -- sub batch step 5026 -- lr 1.88e-04
2025-03-02 13:23:16,708 - INFO - ðŸªœ Batch step - 1256 -- sub batch step 5027 -- lr 1.88e-04
2025-03-02 13:23:18,263 - INFO - Step 1256 -- ðŸ”„ Training Metrics
2025-03-02 13:23:18,263 - INFO - â”œâ”€â”€ Loss: 7.5126
2025-03-02 13:23:18,263 - INFO - â”œâ”€â”€ Learning Rate: 1.88e-04
2025-03-02 13:23:18,263 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:23:18,933 - INFO - ðŸªœ Batch step - 1257 -- sub batch step 5028 -- lr 1.89e-04
2025-03-02 13:23:21,096 - INFO - ðŸªœ Batch step - 1257 -- sub batch step 5029 -- lr 1.89e-04
2025-03-02 13:23:23,707 - INFO - ðŸªœ Batch step - 1257 -- sub batch step 5030 -- lr 1.89e-04
2025-03-02 13:23:25,860 - INFO - ðŸªœ Batch step - 1257 -- sub batch step 5031 -- lr 1.89e-04
2025-03-02 13:23:27,488 - INFO - Step 1257 -- ðŸ”„ Training Metrics
2025-03-02 13:23:27,488 - INFO - â”œâ”€â”€ Loss: 7.5161
2025-03-02 13:23:27,489 - INFO - â”œâ”€â”€ Learning Rate: 1.89e-04
2025-03-02 13:23:27,489 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:23:28,165 - INFO - ðŸªœ Batch step - 1258 -- sub batch step 5032 -- lr 1.89e-04
2025-03-02 13:23:30,320 - INFO - ðŸªœ Batch step - 1258 -- sub batch step 5033 -- lr 1.89e-04
2025-03-02 13:23:32,493 - INFO - ðŸªœ Batch step - 1258 -- sub batch step 5034 -- lr 1.89e-04
2025-03-02 13:23:34,655 - INFO - ðŸªœ Batch step - 1258 -- sub batch step 5035 -- lr 1.89e-04
2025-03-02 13:23:36,203 - INFO - Step 1258 -- ðŸ”„ Training Metrics
2025-03-02 13:23:36,203 - INFO - â”œâ”€â”€ Loss: 7.5186
2025-03-02 13:23:36,203 - INFO - â”œâ”€â”€ Learning Rate: 1.89e-04
2025-03-02 13:23:36,203 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:23:36,875 - INFO - ðŸªœ Batch step - 1259 -- sub batch step 5036 -- lr 1.89e-04
2025-03-02 13:23:39,034 - INFO - ðŸªœ Batch step - 1259 -- sub batch step 5037 -- lr 1.89e-04
2025-03-02 13:23:41,310 - INFO - ðŸªœ Batch step - 1259 -- sub batch step 5038 -- lr 1.89e-04
2025-03-02 13:23:43,473 - INFO - ðŸªœ Batch step - 1259 -- sub batch step 5039 -- lr 1.89e-04
2025-03-02 13:23:45,045 - INFO - Step 1259 -- ðŸ”„ Training Metrics
2025-03-02 13:23:45,045 - INFO - â”œâ”€â”€ Loss: 7.5111
2025-03-02 13:23:45,046 - INFO - â”œâ”€â”€ Learning Rate: 1.89e-04
2025-03-02 13:23:45,046 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:23:46,433 - INFO - ðŸªœ Batch step - 1260 -- sub batch step 5040 -- lr 1.89e-04
2025-03-02 13:23:48,587 - INFO - ðŸªœ Batch step - 1260 -- sub batch step 5041 -- lr 1.89e-04
2025-03-02 13:23:50,743 - INFO - ðŸªœ Batch step - 1260 -- sub batch step 5042 -- lr 1.89e-04
2025-03-02 13:23:52,913 - INFO - ðŸªœ Batch step - 1260 -- sub batch step 5043 -- lr 1.89e-04
2025-03-02 13:23:54,522 - INFO - Step 1260 -- ðŸ”„ Training Metrics
2025-03-02 13:23:54,522 - INFO - â”œâ”€â”€ Loss: 7.4949
2025-03-02 13:23:54,522 - INFO - â”œâ”€â”€ Learning Rate: 1.89e-04
2025-03-02 13:23:54,522 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:23:55,208 - INFO - ðŸªœ Batch step - 1261 -- sub batch step 5044 -- lr 1.89e-04
2025-03-02 13:23:57,369 - INFO - ðŸªœ Batch step - 1261 -- sub batch step 5045 -- lr 1.89e-04
2025-03-02 13:23:59,519 - INFO - ðŸªœ Batch step - 1261 -- sub batch step 5046 -- lr 1.89e-04
2025-03-02 13:24:02,145 - INFO - ðŸªœ Batch step - 1261 -- sub batch step 5047 -- lr 1.89e-04
2025-03-02 13:24:03,667 - INFO - Step 1261 -- ðŸ”„ Training Metrics
2025-03-02 13:24:03,668 - INFO - â”œâ”€â”€ Loss: 7.5115
2025-03-02 13:24:03,668 - INFO - â”œâ”€â”€ Learning Rate: 1.89e-04
2025-03-02 13:24:03,668 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:24:04,337 - INFO - ðŸªœ Batch step - 1262 -- sub batch step 5048 -- lr 1.89e-04
2025-03-02 13:24:06,500 - INFO - ðŸªœ Batch step - 1262 -- sub batch step 5049 -- lr 1.89e-04
2025-03-02 13:24:08,656 - INFO - ðŸªœ Batch step - 1262 -- sub batch step 5050 -- lr 1.89e-04
2025-03-02 13:24:10,820 - INFO - ðŸªœ Batch step - 1262 -- sub batch step 5051 -- lr 1.89e-04
2025-03-02 13:24:12,366 - INFO - Step 1262 -- ðŸ”„ Training Metrics
2025-03-02 13:24:12,366 - INFO - â”œâ”€â”€ Loss: 7.5157
2025-03-02 13:24:12,366 - INFO - â”œâ”€â”€ Learning Rate: 1.89e-04
2025-03-02 13:24:12,367 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:24:13,040 - INFO - ðŸªœ Batch step - 1263 -- sub batch step 5052 -- lr 1.89e-04
2025-03-02 13:24:15,190 - INFO - ðŸªœ Batch step - 1263 -- sub batch step 5053 -- lr 1.89e-04
2025-03-02 13:24:17,347 - INFO - ðŸªœ Batch step - 1263 -- sub batch step 5054 -- lr 1.89e-04
2025-03-02 13:24:19,992 - INFO - ðŸªœ Batch step - 1263 -- sub batch step 5055 -- lr 1.89e-04
2025-03-02 13:24:21,610 - INFO - Step 1263 -- ðŸ”„ Training Metrics
2025-03-02 13:24:21,610 - INFO - â”œâ”€â”€ Loss: 7.4905
2025-03-02 13:24:21,610 - INFO - â”œâ”€â”€ Learning Rate: 1.89e-04
2025-03-02 13:24:21,611 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:24:22,280 - INFO - ðŸªœ Batch step - 1264 -- sub batch step 5056 -- lr 1.90e-04
2025-03-02 13:24:24,438 - INFO - ðŸªœ Batch step - 1264 -- sub batch step 5057 -- lr 1.90e-04
2025-03-02 13:24:26,587 - INFO - ðŸªœ Batch step - 1264 -- sub batch step 5058 -- lr 1.90e-04
2025-03-02 13:24:28,754 - INFO - ðŸªœ Batch step - 1264 -- sub batch step 5059 -- lr 1.90e-04
2025-03-02 13:24:30,320 - INFO - Step 1264 -- ðŸ”„ Training Metrics
2025-03-02 13:24:30,320 - INFO - â”œâ”€â”€ Loss: 7.5228
2025-03-02 13:24:30,320 - INFO - â”œâ”€â”€ Learning Rate: 1.90e-04
2025-03-02 13:24:30,320 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:24:30,991 - INFO - ðŸªœ Batch step - 1265 -- sub batch step 5060 -- lr 1.90e-04
2025-03-02 13:24:33,140 - INFO - ðŸªœ Batch step - 1265 -- sub batch step 5061 -- lr 1.90e-04
2025-03-02 13:24:35,299 - INFO - ðŸªœ Batch step - 1265 -- sub batch step 5062 -- lr 1.90e-04
2025-03-02 13:24:38,042 - INFO - ðŸªœ Batch step - 1265 -- sub batch step 5063 -- lr 1.90e-04
2025-03-02 13:24:39,560 - INFO - Step 1265 -- ðŸ”„ Training Metrics
2025-03-02 13:24:39,560 - INFO - â”œâ”€â”€ Loss: 7.4988
2025-03-02 13:24:39,560 - INFO - â”œâ”€â”€ Learning Rate: 1.90e-04
2025-03-02 13:24:39,560 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:24:40,235 - INFO - ðŸªœ Batch step - 1266 -- sub batch step 5064 -- lr 1.90e-04
2025-03-02 13:24:42,391 - INFO - ðŸªœ Batch step - 1266 -- sub batch step 5065 -- lr 1.90e-04
2025-03-02 13:24:44,537 - INFO - ðŸªœ Batch step - 1266 -- sub batch step 5066 -- lr 1.90e-04
2025-03-02 13:24:46,711 - INFO - ðŸªœ Batch step - 1266 -- sub batch step 5067 -- lr 1.90e-04
2025-03-02 13:24:48,266 - INFO - Step 1266 -- ðŸ”„ Training Metrics
2025-03-02 13:24:48,266 - INFO - â”œâ”€â”€ Loss: 7.4968
2025-03-02 13:24:48,266 - INFO - â”œâ”€â”€ Learning Rate: 1.90e-04
2025-03-02 13:24:48,267 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:24:48,935 - INFO - ðŸªœ Batch step - 1267 -- sub batch step 5068 -- lr 1.90e-04
2025-03-02 13:24:51,092 - INFO - ðŸªœ Batch step - 1267 -- sub batch step 5069 -- lr 1.90e-04
2025-03-02 13:24:53,246 - INFO - ðŸªœ Batch step - 1267 -- sub batch step 5070 -- lr 1.90e-04
2025-03-02 13:24:55,845 - INFO - ðŸªœ Batch step - 1267 -- sub batch step 5071 -- lr 1.90e-04
2025-03-02 13:24:57,452 - INFO - Step 1267 -- ðŸ”„ Training Metrics
2025-03-02 13:24:57,452 - INFO - â”œâ”€â”€ Loss: 7.5085
2025-03-02 13:24:57,452 - INFO - â”œâ”€â”€ Learning Rate: 1.90e-04
2025-03-02 13:24:57,452 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:24:58,126 - INFO - ðŸªœ Batch step - 1268 -- sub batch step 5072 -- lr 1.90e-04
2025-03-02 13:25:00,277 - INFO - ðŸªœ Batch step - 1268 -- sub batch step 5073 -- lr 1.90e-04
2025-03-02 13:25:02,435 - INFO - ðŸªœ Batch step - 1268 -- sub batch step 5074 -- lr 1.90e-04
2025-03-02 13:25:04,602 - INFO - ðŸªœ Batch step - 1268 -- sub batch step 5075 -- lr 1.90e-04
2025-03-02 13:25:06,176 - INFO - Step 1268 -- ðŸ”„ Training Metrics
2025-03-02 13:25:06,176 - INFO - â”œâ”€â”€ Loss: 7.5023
2025-03-02 13:25:06,176 - INFO - â”œâ”€â”€ Learning Rate: 1.90e-04
2025-03-02 13:25:06,176 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:25:06,841 - INFO - ðŸªœ Batch step - 1269 -- sub batch step 5076 -- lr 1.90e-04
2025-03-02 13:25:08,997 - INFO - ðŸªœ Batch step - 1269 -- sub batch step 5077 -- lr 1.90e-04
2025-03-02 13:25:11,147 - INFO - ðŸªœ Batch step - 1269 -- sub batch step 5078 -- lr 1.90e-04
2025-03-02 13:25:13,821 - INFO - ðŸªœ Batch step - 1269 -- sub batch step 5079 -- lr 1.90e-04
2025-03-02 13:25:15,311 - INFO - Step 1269 -- ðŸ”„ Training Metrics
2025-03-02 13:25:15,311 - INFO - â”œâ”€â”€ Loss: 7.5062
2025-03-02 13:25:15,311 - INFO - â”œâ”€â”€ Learning Rate: 1.90e-04
2025-03-02 13:25:15,311 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:25:15,983 - INFO - ðŸªœ Batch step - 1270 -- sub batch step 5080 -- lr 1.90e-04
2025-03-02 13:25:18,130 - INFO - ðŸªœ Batch step - 1270 -- sub batch step 5081 -- lr 1.90e-04
2025-03-02 13:25:20,285 - INFO - ðŸªœ Batch step - 1270 -- sub batch step 5082 -- lr 1.90e-04
2025-03-02 13:25:22,454 - INFO - ðŸªœ Batch step - 1270 -- sub batch step 5083 -- lr 1.90e-04
2025-03-02 13:25:24,014 - INFO - Step 1270 -- ðŸ”„ Training Metrics
2025-03-02 13:25:24,015 - INFO - â”œâ”€â”€ Loss: 7.5174
2025-03-02 13:25:24,015 - INFO - â”œâ”€â”€ Learning Rate: 1.90e-04
2025-03-02 13:25:24,015 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:25:24,745 - INFO - ðŸªœ Batch step - 1271 -- sub batch step 5084 -- lr 1.91e-04
2025-03-02 13:25:26,927 - INFO - ðŸªœ Batch step - 1271 -- sub batch step 5085 -- lr 1.91e-04
2025-03-02 13:25:29,609 - INFO - ðŸªœ Batch step - 1271 -- sub batch step 5086 -- lr 1.91e-04
2025-03-02 13:25:31,768 - INFO - ðŸªœ Batch step - 1271 -- sub batch step 5087 -- lr 1.91e-04
2025-03-02 13:25:33,271 - INFO - Step 1271 -- ðŸ”„ Training Metrics
2025-03-02 13:25:33,272 - INFO - â”œâ”€â”€ Loss: 7.5254
2025-03-02 13:25:33,272 - INFO - â”œâ”€â”€ Learning Rate: 1.91e-04
2025-03-02 13:25:33,272 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:25:33,935 - INFO - ðŸªœ Batch step - 1272 -- sub batch step 5088 -- lr 1.91e-04
2025-03-02 13:25:36,095 - INFO - ðŸªœ Batch step - 1272 -- sub batch step 5089 -- lr 1.91e-04
2025-03-02 13:25:38,267 - INFO - ðŸªœ Batch step - 1272 -- sub batch step 5090 -- lr 1.91e-04
2025-03-02 13:25:40,416 - INFO - ðŸªœ Batch step - 1272 -- sub batch step 5091 -- lr 1.91e-04
2025-03-02 13:25:41,985 - INFO - Step 1272 -- ðŸ”„ Training Metrics
2025-03-02 13:25:41,985 - INFO - â”œâ”€â”€ Loss: 7.4768
2025-03-02 13:25:41,985 - INFO - â”œâ”€â”€ Learning Rate: 1.91e-04
2025-03-02 13:25:41,985 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:25:42,656 - INFO - ðŸªœ Batch step - 1273 -- sub batch step 5092 -- lr 1.91e-04
2025-03-02 13:25:44,804 - INFO - ðŸªœ Batch step - 1273 -- sub batch step 5093 -- lr 1.91e-04
2025-03-02 13:25:47,506 - INFO - ðŸªœ Batch step - 1273 -- sub batch step 5094 -- lr 1.91e-04
2025-03-02 13:25:49,658 - INFO - ðŸªœ Batch step - 1273 -- sub batch step 5095 -- lr 1.91e-04
2025-03-02 13:25:51,273 - INFO - Step 1273 -- ðŸ”„ Training Metrics
2025-03-02 13:25:51,273 - INFO - â”œâ”€â”€ Loss: 7.4887
2025-03-02 13:25:51,274 - INFO - â”œâ”€â”€ Learning Rate: 1.91e-04
2025-03-02 13:25:51,274 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:25:51,942 - INFO - ðŸªœ Batch step - 1274 -- sub batch step 5096 -- lr 1.91e-04
2025-03-02 13:25:54,100 - INFO - ðŸªœ Batch step - 1274 -- sub batch step 5097 -- lr 1.91e-04
2025-03-02 13:25:56,266 - INFO - ðŸªœ Batch step - 1274 -- sub batch step 5098 -- lr 1.91e-04
2025-03-02 13:25:58,430 - INFO - ðŸªœ Batch step - 1274 -- sub batch step 5099 -- lr 1.91e-04
2025-03-02 13:25:59,975 - INFO - Step 1274 -- ðŸ”„ Training Metrics
2025-03-02 13:25:59,975 - INFO - â”œâ”€â”€ Loss: 7.4914
2025-03-02 13:25:59,975 - INFO - â”œâ”€â”€ Learning Rate: 1.91e-04
2025-03-02 13:25:59,975 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:26:00,652 - INFO - ðŸªœ Batch step - 1275 -- sub batch step 5100 -- lr 1.91e-04
2025-03-02 13:26:02,811 - INFO - ðŸªœ Batch step - 1275 -- sub batch step 5101 -- lr 1.91e-04
2025-03-02 13:26:05,476 - INFO - ðŸªœ Batch step - 1275 -- sub batch step 5102 -- lr 1.91e-04
2025-03-02 13:26:07,633 - INFO - ðŸªœ Batch step - 1275 -- sub batch step 5103 -- lr 1.91e-04
2025-03-02 13:26:09,168 - INFO - Step 1275 -- ðŸ”„ Training Metrics
2025-03-02 13:26:09,168 - INFO - â”œâ”€â”€ Loss: 7.5230
2025-03-02 13:26:09,169 - INFO - â”œâ”€â”€ Learning Rate: 1.91e-04
2025-03-02 13:26:09,169 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:26:09,850 - INFO - ðŸªœ Batch step - 1276 -- sub batch step 5104 -- lr 1.91e-04
2025-03-02 13:26:12,014 - INFO - ðŸªœ Batch step - 1276 -- sub batch step 5105 -- lr 1.91e-04
2025-03-02 13:26:14,183 - INFO - ðŸªœ Batch step - 1276 -- sub batch step 5106 -- lr 1.91e-04
2025-03-02 13:26:16,339 - INFO - ðŸªœ Batch step - 1276 -- sub batch step 5107 -- lr 1.91e-04
2025-03-02 13:26:17,879 - INFO - Step 1276 -- ðŸ”„ Training Metrics
2025-03-02 13:26:17,879 - INFO - â”œâ”€â”€ Loss: 7.4926
2025-03-02 13:26:17,879 - INFO - â”œâ”€â”€ Learning Rate: 1.91e-04
2025-03-02 13:26:17,879 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:26:18,548 - INFO - ðŸªœ Batch step - 1277 -- sub batch step 5108 -- lr 1.92e-04
2025-03-02 13:26:20,707 - INFO - ðŸªœ Batch step - 1277 -- sub batch step 5109 -- lr 1.92e-04
2025-03-02 13:26:23,380 - INFO - ðŸªœ Batch step - 1277 -- sub batch step 5110 -- lr 1.92e-04
2025-03-02 13:26:25,529 - INFO - ðŸªœ Batch step - 1277 -- sub batch step 5111 -- lr 1.92e-04
2025-03-02 13:26:27,471 - INFO - Step 1277 -- ðŸ”„ Training Metrics
2025-03-02 13:26:27,471 - INFO - â”œâ”€â”€ Loss: 7.4990
2025-03-02 13:26:27,471 - INFO - â”œâ”€â”€ Learning Rate: 1.92e-04
2025-03-02 13:26:27,471 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:26:28,146 - INFO - ðŸªœ Batch step - 1278 -- sub batch step 5112 -- lr 1.92e-04
2025-03-02 13:26:30,297 - INFO - ðŸªœ Batch step - 1278 -- sub batch step 5113 -- lr 1.92e-04
2025-03-02 13:26:32,476 - INFO - ðŸªœ Batch step - 1278 -- sub batch step 5114 -- lr 1.92e-04
2025-03-02 13:26:34,630 - INFO - ðŸªœ Batch step - 1278 -- sub batch step 5115 -- lr 1.92e-04
2025-03-02 13:26:36,162 - INFO - Step 1278 -- ðŸ”„ Training Metrics
2025-03-02 13:26:36,162 - INFO - â”œâ”€â”€ Loss: 7.5013
2025-03-02 13:26:36,162 - INFO - â”œâ”€â”€ Learning Rate: 1.92e-04
2025-03-02 13:26:36,162 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:26:36,829 - INFO - ðŸªœ Batch step - 1279 -- sub batch step 5116 -- lr 1.92e-04
2025-03-02 13:26:38,991 - INFO - ðŸªœ Batch step - 1279 -- sub batch step 5117 -- lr 1.92e-04
2025-03-02 13:26:41,266 - INFO - ðŸªœ Batch step - 1279 -- sub batch step 5118 -- lr 1.92e-04
2025-03-02 13:26:43,422 - INFO - ðŸªœ Batch step - 1279 -- sub batch step 5119 -- lr 1.92e-04
2025-03-02 13:26:44,998 - INFO - Step 1279 -- ðŸ”„ Training Metrics
2025-03-02 13:26:44,998 - INFO - â”œâ”€â”€ Loss: 7.4858
2025-03-02 13:26:44,998 - INFO - â”œâ”€â”€ Learning Rate: 1.92e-04
2025-03-02 13:26:44,998 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:26:46,209 - INFO - ðŸªœ Batch step - 1280 -- sub batch step 5120 -- lr 1.92e-04
2025-03-02 13:26:48,360 - INFO - ðŸªœ Batch step - 1280 -- sub batch step 5121 -- lr 1.92e-04
2025-03-02 13:26:50,509 - INFO - ðŸªœ Batch step - 1280 -- sub batch step 5122 -- lr 1.92e-04
2025-03-02 13:26:52,673 - INFO - ðŸªœ Batch step - 1280 -- sub batch step 5123 -- lr 1.92e-04
2025-03-02 13:26:54,338 - INFO - Step 1280 -- ðŸ”„ Training Metrics
2025-03-02 13:26:54,339 - INFO - â”œâ”€â”€ Loss: 7.4882
2025-03-02 13:26:54,339 - INFO - â”œâ”€â”€ Learning Rate: 1.92e-04
2025-03-02 13:26:54,339 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:26:55,014 - INFO - ðŸªœ Batch step - 1281 -- sub batch step 5124 -- lr 1.92e-04
2025-03-02 13:26:57,169 - INFO - ðŸªœ Batch step - 1281 -- sub batch step 5125 -- lr 1.92e-04
2025-03-02 13:26:59,317 - INFO - ðŸªœ Batch step - 1281 -- sub batch step 5126 -- lr 1.92e-04
2025-03-02 13:27:02,107 - INFO - ðŸªœ Batch step - 1281 -- sub batch step 5127 -- lr 1.92e-04
2025-03-02 13:27:03,644 - INFO - Step 1281 -- ðŸ”„ Training Metrics
2025-03-02 13:27:03,645 - INFO - â”œâ”€â”€ Loss: 7.4764
2025-03-02 13:27:03,645 - INFO - â”œâ”€â”€ Learning Rate: 1.92e-04
2025-03-02 13:27:03,645 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:27:04,311 - INFO - ðŸªœ Batch step - 1282 -- sub batch step 5128 -- lr 1.92e-04
2025-03-02 13:27:06,467 - INFO - ðŸªœ Batch step - 1282 -- sub batch step 5129 -- lr 1.92e-04
2025-03-02 13:27:08,620 - INFO - ðŸªœ Batch step - 1282 -- sub batch step 5130 -- lr 1.92e-04
2025-03-02 13:27:10,787 - INFO - ðŸªœ Batch step - 1282 -- sub batch step 5131 -- lr 1.92e-04
2025-03-02 13:27:12,331 - INFO - Step 1282 -- ðŸ”„ Training Metrics
2025-03-02 13:27:12,331 - INFO - â”œâ”€â”€ Loss: 7.4920
2025-03-02 13:27:12,332 - INFO - â”œâ”€â”€ Learning Rate: 1.92e-04
2025-03-02 13:27:12,332 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:27:13,004 - INFO - ðŸªœ Batch step - 1283 -- sub batch step 5132 -- lr 1.92e-04
2025-03-02 13:27:15,153 - INFO - ðŸªœ Batch step - 1283 -- sub batch step 5133 -- lr 1.92e-04
2025-03-02 13:27:17,311 - INFO - ðŸªœ Batch step - 1283 -- sub batch step 5134 -- lr 1.92e-04
2025-03-02 13:27:19,947 - INFO - ðŸªœ Batch step - 1283 -- sub batch step 5135 -- lr 1.92e-04
2025-03-02 13:27:21,486 - INFO - Step 1283 -- ðŸ”„ Training Metrics
2025-03-02 13:27:21,486 - INFO - â”œâ”€â”€ Loss: 7.4921
2025-03-02 13:27:21,486 - INFO - â”œâ”€â”€ Learning Rate: 1.92e-04
2025-03-02 13:27:21,487 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:27:22,158 - INFO - ðŸªœ Batch step - 1284 -- sub batch step 5136 -- lr 1.93e-04
2025-03-02 13:27:24,312 - INFO - ðŸªœ Batch step - 1284 -- sub batch step 5137 -- lr 1.93e-04
2025-03-02 13:27:26,459 - INFO - ðŸªœ Batch step - 1284 -- sub batch step 5138 -- lr 1.93e-04
2025-03-02 13:27:28,637 - INFO - ðŸªœ Batch step - 1284 -- sub batch step 5139 -- lr 1.93e-04
2025-03-02 13:27:30,167 - INFO - Step 1284 -- ðŸ”„ Training Metrics
2025-03-02 13:27:30,167 - INFO - â”œâ”€â”€ Loss: 7.5025
2025-03-02 13:27:30,167 - INFO - â”œâ”€â”€ Learning Rate: 1.93e-04
2025-03-02 13:27:30,167 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:27:30,842 - INFO - ðŸªœ Batch step - 1285 -- sub batch step 5140 -- lr 1.93e-04
2025-03-02 13:27:32,994 - INFO - ðŸªœ Batch step - 1285 -- sub batch step 5141 -- lr 1.93e-04
2025-03-02 13:27:35,153 - INFO - ðŸªœ Batch step - 1285 -- sub batch step 5142 -- lr 1.93e-04
2025-03-02 13:27:37,882 - INFO - ðŸªœ Batch step - 1285 -- sub batch step 5143 -- lr 1.93e-04
2025-03-02 13:27:39,399 - INFO - Step 1285 -- ðŸ”„ Training Metrics
2025-03-02 13:27:39,399 - INFO - â”œâ”€â”€ Loss: 7.5168
2025-03-02 13:27:39,400 - INFO - â”œâ”€â”€ Learning Rate: 1.93e-04
2025-03-02 13:27:39,400 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:27:40,074 - INFO - ðŸªœ Batch step - 1286 -- sub batch step 5144 -- lr 1.93e-04
2025-03-02 13:27:42,231 - INFO - ðŸªœ Batch step - 1286 -- sub batch step 5145 -- lr 1.93e-04
2025-03-02 13:27:44,377 - INFO - ðŸªœ Batch step - 1286 -- sub batch step 5146 -- lr 1.93e-04
2025-03-02 13:27:46,547 - INFO - ðŸªœ Batch step - 1286 -- sub batch step 5147 -- lr 1.93e-04
2025-03-02 13:27:48,106 - INFO - Step 1286 -- ðŸ”„ Training Metrics
2025-03-02 13:27:48,106 - INFO - â”œâ”€â”€ Loss: 7.5005
2025-03-02 13:27:48,107 - INFO - â”œâ”€â”€ Learning Rate: 1.93e-04
2025-03-02 13:27:48,107 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:27:48,774 - INFO - ðŸªœ Batch step - 1287 -- sub batch step 5148 -- lr 1.93e-04
2025-03-02 13:27:50,931 - INFO - ðŸªœ Batch step - 1287 -- sub batch step 5149 -- lr 1.93e-04
2025-03-02 13:27:53,086 - INFO - ðŸªœ Batch step - 1287 -- sub batch step 5150 -- lr 1.93e-04
2025-03-02 13:27:55,817 - INFO - ðŸªœ Batch step - 1287 -- sub batch step 5151 -- lr 1.93e-04
2025-03-02 13:27:57,312 - INFO - Step 1287 -- ðŸ”„ Training Metrics
2025-03-02 13:27:57,313 - INFO - â”œâ”€â”€ Loss: 7.4880
2025-03-02 13:27:57,313 - INFO - â”œâ”€â”€ Learning Rate: 1.93e-04
2025-03-02 13:27:57,313 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:27:57,987 - INFO - ðŸªœ Batch step - 1288 -- sub batch step 5152 -- lr 1.93e-04
2025-03-02 13:28:00,138 - INFO - ðŸªœ Batch step - 1288 -- sub batch step 5153 -- lr 1.93e-04
2025-03-02 13:28:02,300 - INFO - ðŸªœ Batch step - 1288 -- sub batch step 5154 -- lr 1.93e-04
2025-03-02 13:28:04,468 - INFO - ðŸªœ Batch step - 1288 -- sub batch step 5155 -- lr 1.93e-04
2025-03-02 13:28:05,994 - INFO - Step 1288 -- ðŸ”„ Training Metrics
2025-03-02 13:28:05,995 - INFO - â”œâ”€â”€ Loss: 7.4893
2025-03-02 13:28:05,995 - INFO - â”œâ”€â”€ Learning Rate: 1.93e-04
2025-03-02 13:28:05,995 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:28:06,664 - INFO - ðŸªœ Batch step - 1289 -- sub batch step 5156 -- lr 1.93e-04
2025-03-02 13:28:08,825 - INFO - ðŸªœ Batch step - 1289 -- sub batch step 5157 -- lr 1.93e-04
2025-03-02 13:28:10,978 - INFO - ðŸªœ Batch step - 1289 -- sub batch step 5158 -- lr 1.93e-04
2025-03-02 13:28:13,347 - INFO - ðŸªœ Batch step - 1289 -- sub batch step 5159 -- lr 1.93e-04
2025-03-02 13:28:15,163 - INFO - Step 1289 -- ðŸ”„ Training Metrics
2025-03-02 13:28:15,163 - INFO - â”œâ”€â”€ Loss: 7.4961
2025-03-02 13:28:15,163 - INFO - â”œâ”€â”€ Learning Rate: 1.93e-04
2025-03-02 13:28:15,163 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:28:15,840 - INFO - ðŸªœ Batch step - 1290 -- sub batch step 5160 -- lr 1.93e-04
2025-03-02 13:28:17,993 - INFO - ðŸªœ Batch step - 1290 -- sub batch step 5161 -- lr 1.93e-04
2025-03-02 13:28:20,149 - INFO - ðŸªœ Batch step - 1290 -- sub batch step 5162 -- lr 1.93e-04
2025-03-02 13:28:22,325 - INFO - ðŸªœ Batch step - 1290 -- sub batch step 5163 -- lr 1.93e-04
2025-03-02 13:28:23,842 - INFO - Step 1290 -- ðŸ”„ Training Metrics
2025-03-02 13:28:23,843 - INFO - â”œâ”€â”€ Loss: 7.4953
2025-03-02 13:28:23,843 - INFO - â”œâ”€â”€ Learning Rate: 1.93e-04
2025-03-02 13:28:23,843 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:28:24,519 - INFO - ðŸªœ Batch step - 1291 -- sub batch step 5164 -- lr 1.94e-04
2025-03-02 13:28:26,674 - INFO - ðŸªœ Batch step - 1291 -- sub batch step 5165 -- lr 1.94e-04
2025-03-02 13:28:29,299 - INFO - ðŸªœ Batch step - 1291 -- sub batch step 5166 -- lr 1.94e-04
2025-03-02 13:28:31,460 - INFO - ðŸªœ Batch step - 1291 -- sub batch step 5167 -- lr 1.94e-04
2025-03-02 13:28:33,021 - INFO - Step 1291 -- ðŸ”„ Training Metrics
2025-03-02 13:28:33,022 - INFO - â”œâ”€â”€ Loss: 7.4962
2025-03-02 13:28:33,022 - INFO - â”œâ”€â”€ Learning Rate: 1.94e-04
2025-03-02 13:28:33,022 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:28:33,690 - INFO - ðŸªœ Batch step - 1292 -- sub batch step 5168 -- lr 1.94e-04
2025-03-02 13:28:35,849 - INFO - ðŸªœ Batch step - 1292 -- sub batch step 5169 -- lr 1.94e-04
2025-03-02 13:28:38,018 - INFO - ðŸªœ Batch step - 1292 -- sub batch step 5170 -- lr 1.94e-04
2025-03-02 13:28:40,169 - INFO - ðŸªœ Batch step - 1292 -- sub batch step 5171 -- lr 1.94e-04
2025-03-02 13:28:41,706 - INFO - Step 1292 -- ðŸ”„ Training Metrics
2025-03-02 13:28:41,706 - INFO - â”œâ”€â”€ Loss: 7.4980
2025-03-02 13:28:41,707 - INFO - â”œâ”€â”€ Learning Rate: 1.94e-04
2025-03-02 13:28:41,707 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:28:42,389 - INFO - ðŸªœ Batch step - 1293 -- sub batch step 5172 -- lr 1.94e-04
2025-03-02 13:28:44,541 - INFO - ðŸªœ Batch step - 1293 -- sub batch step 5173 -- lr 1.94e-04
2025-03-02 13:28:47,220 - INFO - ðŸªœ Batch step - 1293 -- sub batch step 5174 -- lr 1.94e-04
2025-03-02 13:28:49,376 - INFO - ðŸªœ Batch step - 1293 -- sub batch step 5175 -- lr 1.94e-04
2025-03-02 13:28:51,222 - INFO - Step 1293 -- ðŸ”„ Training Metrics
2025-03-02 13:28:51,223 - INFO - â”œâ”€â”€ Loss: 7.4572
2025-03-02 13:28:51,223 - INFO - â”œâ”€â”€ Learning Rate: 1.94e-04
2025-03-02 13:28:51,223 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:28:51,893 - INFO - ðŸªœ Batch step - 1294 -- sub batch step 5176 -- lr 1.94e-04
2025-03-02 13:28:54,050 - INFO - ðŸªœ Batch step - 1294 -- sub batch step 5177 -- lr 1.94e-04
2025-03-02 13:28:56,224 - INFO - ðŸªœ Batch step - 1294 -- sub batch step 5178 -- lr 1.94e-04
2025-03-02 13:28:58,381 - INFO - ðŸªœ Batch step - 1294 -- sub batch step 5179 -- lr 1.94e-04
2025-03-02 13:28:59,919 - INFO - Step 1294 -- ðŸ”„ Training Metrics
2025-03-02 13:28:59,919 - INFO - â”œâ”€â”€ Loss: 7.4730
2025-03-02 13:28:59,919 - INFO - â”œâ”€â”€ Learning Rate: 1.94e-04
2025-03-02 13:28:59,919 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:29:00,593 - INFO - ðŸªœ Batch step - 1295 -- sub batch step 5180 -- lr 1.94e-04
2025-03-02 13:29:02,751 - INFO - ðŸªœ Batch step - 1295 -- sub batch step 5181 -- lr 1.94e-04
2025-03-02 13:29:05,435 - INFO - ðŸªœ Batch step - 1295 -- sub batch step 5182 -- lr 1.94e-04
2025-03-02 13:29:07,585 - INFO - ðŸªœ Batch step - 1295 -- sub batch step 5183 -- lr 1.94e-04
2025-03-02 13:29:09,178 - INFO - Step 1295 -- ðŸ”„ Training Metrics
2025-03-02 13:29:09,178 - INFO - â”œâ”€â”€ Loss: 7.4806
2025-03-02 13:29:09,179 - INFO - â”œâ”€â”€ Learning Rate: 1.94e-04
2025-03-02 13:29:09,179 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:29:09,853 - INFO - ðŸªœ Batch step - 1296 -- sub batch step 5184 -- lr 1.94e-04
2025-03-02 13:29:12,007 - INFO - ðŸªœ Batch step - 1296 -- sub batch step 5185 -- lr 1.94e-04
2025-03-02 13:29:14,169 - INFO - ðŸªœ Batch step - 1296 -- sub batch step 5186 -- lr 1.94e-04
2025-03-02 13:29:16,322 - INFO - ðŸªœ Batch step - 1296 -- sub batch step 5187 -- lr 1.94e-04
2025-03-02 13:29:17,861 - INFO - Step 1296 -- ðŸ”„ Training Metrics
2025-03-02 13:29:17,861 - INFO - â”œâ”€â”€ Loss: 7.4510
2025-03-02 13:29:17,861 - INFO - â”œâ”€â”€ Learning Rate: 1.94e-04
2025-03-02 13:29:17,861 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:29:18,528 - INFO - ðŸªœ Batch step - 1297 -- sub batch step 5188 -- lr 1.95e-04
2025-03-02 13:29:20,685 - INFO - ðŸªœ Batch step - 1297 -- sub batch step 5189 -- lr 1.95e-04
2025-03-02 13:29:23,059 - INFO - ðŸªœ Batch step - 1297 -- sub batch step 5190 -- lr 1.95e-04
2025-03-02 13:29:25,212 - INFO - ðŸªœ Batch step - 1297 -- sub batch step 5191 -- lr 1.95e-04
2025-03-02 13:29:27,389 - INFO - Step 1297 -- ðŸ”„ Training Metrics
2025-03-02 13:29:27,389 - INFO - â”œâ”€â”€ Loss: 7.5028
2025-03-02 13:29:27,389 - INFO - â”œâ”€â”€ Learning Rate: 1.95e-04
2025-03-02 13:29:27,389 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:29:28,064 - INFO - ðŸªœ Batch step - 1298 -- sub batch step 5192 -- lr 1.95e-04
2025-03-02 13:29:30,216 - INFO - ðŸªœ Batch step - 1298 -- sub batch step 5193 -- lr 1.95e-04
2025-03-02 13:29:32,391 - INFO - ðŸªœ Batch step - 1298 -- sub batch step 5194 -- lr 1.95e-04
2025-03-02 13:29:34,543 - INFO - ðŸªœ Batch step - 1298 -- sub batch step 5195 -- lr 1.95e-04
2025-03-02 13:29:36,090 - INFO - Step 1298 -- ðŸ”„ Training Metrics
2025-03-02 13:29:36,091 - INFO - â”œâ”€â”€ Loss: 7.5140
2025-03-02 13:29:36,091 - INFO - â”œâ”€â”€ Learning Rate: 1.95e-04
2025-03-02 13:29:36,091 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:29:36,761 - INFO - ðŸªœ Batch step - 1299 -- sub batch step 5196 -- lr 1.95e-04
2025-03-02 13:29:38,919 - INFO - ðŸªœ Batch step - 1299 -- sub batch step 5197 -- lr 1.95e-04
2025-03-02 13:29:41,197 - INFO - ðŸªœ Batch step - 1299 -- sub batch step 5198 -- lr 1.95e-04
2025-03-02 13:29:43,350 - INFO - ðŸªœ Batch step - 1299 -- sub batch step 5199 -- lr 1.95e-04
2025-03-02 13:29:45,042 - INFO - Step 1299 -- ðŸ”„ Training Metrics
2025-03-02 13:29:45,042 - INFO - â”œâ”€â”€ Loss: 7.4949
2025-03-02 13:29:45,042 - INFO - â”œâ”€â”€ Learning Rate: 1.95e-04
2025-03-02 13:29:45,042 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:29:46,254 - INFO - ðŸªœ Batch step - 1300 -- sub batch step 5200 -- lr 1.95e-04
2025-03-02 13:29:48,402 - INFO - ðŸªœ Batch step - 1300 -- sub batch step 5201 -- lr 1.95e-04
2025-03-02 13:29:50,553 - INFO - ðŸªœ Batch step - 1300 -- sub batch step 5202 -- lr 1.95e-04
2025-03-02 13:29:52,715 - INFO - ðŸªœ Batch step - 1300 -- sub batch step 5203 -- lr 1.95e-04
2025-03-02 13:29:54,316 - INFO - Step 1300 -- ðŸ”„ Training Metrics
2025-03-02 13:29:54,317 - INFO - â”œâ”€â”€ Loss: 7.4757
2025-03-02 13:29:54,317 - INFO - â”œâ”€â”€ Learning Rate: 1.95e-04
2025-03-02 13:29:54,317 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:29:54,986 - INFO - ðŸªœ Batch step - 1301 -- sub batch step 5204 -- lr 1.95e-04
2025-03-02 13:29:57,137 - INFO - ðŸªœ Batch step - 1301 -- sub batch step 5205 -- lr 1.95e-04
2025-03-02 13:29:59,282 - INFO - ðŸªœ Batch step - 1301 -- sub batch step 5206 -- lr 1.95e-04
2025-03-02 13:30:01,652 - INFO - ðŸªœ Batch step - 1301 -- sub batch step 5207 -- lr 1.95e-04
2025-03-02 13:30:03,519 - INFO - Step 1301 -- ðŸ”„ Training Metrics
2025-03-02 13:30:03,520 - INFO - â”œâ”€â”€ Loss: 7.4984
2025-03-02 13:30:03,520 - INFO - â”œâ”€â”€ Learning Rate: 1.95e-04
2025-03-02 13:30:03,520 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:30:04,188 - INFO - ðŸªœ Batch step - 1302 -- sub batch step 5208 -- lr 1.95e-04
2025-03-02 13:30:06,339 - INFO - ðŸªœ Batch step - 1302 -- sub batch step 5209 -- lr 1.95e-04
2025-03-02 13:30:08,494 - INFO - ðŸªœ Batch step - 1302 -- sub batch step 5210 -- lr 1.95e-04
2025-03-02 13:30:10,660 - INFO - ðŸªœ Batch step - 1302 -- sub batch step 5211 -- lr 1.95e-04
2025-03-02 13:30:12,206 - INFO - Step 1302 -- ðŸ”„ Training Metrics
2025-03-02 13:30:12,207 - INFO - â”œâ”€â”€ Loss: 7.4572
2025-03-02 13:30:12,207 - INFO - â”œâ”€â”€ Learning Rate: 1.95e-04
2025-03-02 13:30:12,207 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:30:12,880 - INFO - ðŸªœ Batch step - 1303 -- sub batch step 5212 -- lr 1.95e-04
2025-03-02 13:30:15,027 - INFO - ðŸªœ Batch step - 1303 -- sub batch step 5213 -- lr 1.95e-04
2025-03-02 13:30:17,178 - INFO - ðŸªœ Batch step - 1303 -- sub batch step 5214 -- lr 1.95e-04
2025-03-02 13:30:19,836 - INFO - ðŸªœ Batch step - 1303 -- sub batch step 5215 -- lr 1.95e-04
2025-03-02 13:30:21,466 - INFO - Step 1303 -- ðŸ”„ Training Metrics
2025-03-02 13:30:21,467 - INFO - â”œâ”€â”€ Loss: 7.5067
2025-03-02 13:30:21,467 - INFO - â”œâ”€â”€ Learning Rate: 1.95e-04
2025-03-02 13:30:21,467 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:30:22,137 - INFO - ðŸªœ Batch step - 1304 -- sub batch step 5216 -- lr 1.96e-04
2025-03-02 13:30:24,292 - INFO - ðŸªœ Batch step - 1304 -- sub batch step 5217 -- lr 1.96e-04
2025-03-02 13:30:26,440 - INFO - ðŸªœ Batch step - 1304 -- sub batch step 5218 -- lr 1.96e-04
2025-03-02 13:30:28,607 - INFO - ðŸªœ Batch step - 1304 -- sub batch step 5219 -- lr 1.96e-04
2025-03-02 13:30:30,144 - INFO - Step 1304 -- ðŸ”„ Training Metrics
2025-03-02 13:30:30,144 - INFO - â”œâ”€â”€ Loss: 7.4796
2025-03-02 13:30:30,144 - INFO - â”œâ”€â”€ Learning Rate: 1.96e-04
2025-03-02 13:30:30,144 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:30:30,816 - INFO - ðŸªœ Batch step - 1305 -- sub batch step 5220 -- lr 1.96e-04
2025-03-02 13:30:32,964 - INFO - ðŸªœ Batch step - 1305 -- sub batch step 5221 -- lr 1.96e-04
2025-03-02 13:30:35,114 - INFO - ðŸªœ Batch step - 1305 -- sub batch step 5222 -- lr 1.96e-04
2025-03-02 13:30:37,800 - INFO - ðŸªœ Batch step - 1305 -- sub batch step 5223 -- lr 1.96e-04
2025-03-02 13:30:39,344 - INFO - Step 1305 -- ðŸ”„ Training Metrics
2025-03-02 13:30:39,344 - INFO - â”œâ”€â”€ Loss: 7.4820
2025-03-02 13:30:39,344 - INFO - â”œâ”€â”€ Learning Rate: 1.96e-04
2025-03-02 13:30:39,344 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:30:40,017 - INFO - ðŸªœ Batch step - 1306 -- sub batch step 5224 -- lr 1.96e-04
2025-03-02 13:30:42,173 - INFO - ðŸªœ Batch step - 1306 -- sub batch step 5225 -- lr 1.96e-04
2025-03-02 13:30:44,320 - INFO - ðŸªœ Batch step - 1306 -- sub batch step 5226 -- lr 1.96e-04
2025-03-02 13:30:46,488 - INFO - ðŸªœ Batch step - 1306 -- sub batch step 5227 -- lr 1.96e-04
2025-03-02 13:30:48,044 - INFO - Step 1306 -- ðŸ”„ Training Metrics
2025-03-02 13:30:48,044 - INFO - â”œâ”€â”€ Loss: 7.4965
2025-03-02 13:30:48,044 - INFO - â”œâ”€â”€ Learning Rate: 1.96e-04
2025-03-02 13:30:48,044 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:30:48,710 - INFO - ðŸªœ Batch step - 1307 -- sub batch step 5228 -- lr 1.96e-04
2025-03-02 13:30:50,867 - INFO - ðŸªœ Batch step - 1307 -- sub batch step 5229 -- lr 1.96e-04
2025-03-02 13:30:53,022 - INFO - ðŸªœ Batch step - 1307 -- sub batch step 5230 -- lr 1.96e-04
2025-03-02 13:30:55,713 - INFO - ðŸªœ Batch step - 1307 -- sub batch step 5231 -- lr 1.96e-04
2025-03-02 13:30:57,266 - INFO - Step 1307 -- ðŸ”„ Training Metrics
2025-03-02 13:30:57,267 - INFO - â”œâ”€â”€ Loss: 7.4962
2025-03-02 13:30:57,267 - INFO - â”œâ”€â”€ Learning Rate: 1.96e-04
2025-03-02 13:30:57,267 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:30:57,939 - INFO - ðŸªœ Batch step - 1308 -- sub batch step 5232 -- lr 1.96e-04
2025-03-02 13:31:00,090 - INFO - ðŸªœ Batch step - 1308 -- sub batch step 5233 -- lr 1.96e-04
2025-03-02 13:31:02,248 - INFO - ðŸªœ Batch step - 1308 -- sub batch step 5234 -- lr 1.96e-04
2025-03-02 13:31:04,418 - INFO - ðŸªœ Batch step - 1308 -- sub batch step 5235 -- lr 1.96e-04
2025-03-02 13:31:05,951 - INFO - Step 1308 -- ðŸ”„ Training Metrics
2025-03-02 13:31:05,951 - INFO - â”œâ”€â”€ Loss: 7.4672
2025-03-02 13:31:05,951 - INFO - â”œâ”€â”€ Learning Rate: 1.96e-04
2025-03-02 13:31:05,951 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:31:06,617 - INFO - ðŸªœ Batch step - 1309 -- sub batch step 5236 -- lr 1.96e-04
2025-03-02 13:31:08,768 - INFO - ðŸªœ Batch step - 1309 -- sub batch step 5237 -- lr 1.96e-04
2025-03-02 13:31:10,915 - INFO - ðŸªœ Batch step - 1309 -- sub batch step 5238 -- lr 1.96e-04
2025-03-02 13:31:13,653 - INFO - ðŸªœ Batch step - 1309 -- sub batch step 5239 -- lr 1.96e-04
2025-03-02 13:31:15,168 - INFO - Step 1309 -- ðŸ”„ Training Metrics
2025-03-02 13:31:15,169 - INFO - â”œâ”€â”€ Loss: 7.4892
2025-03-02 13:31:15,169 - INFO - â”œâ”€â”€ Learning Rate: 1.96e-04
2025-03-02 13:31:15,169 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:31:15,840 - INFO - ðŸªœ Batch step - 1310 -- sub batch step 5240 -- lr 1.96e-04
2025-03-02 13:31:17,990 - INFO - ðŸªœ Batch step - 1310 -- sub batch step 5241 -- lr 1.96e-04
2025-03-02 13:31:20,144 - INFO - ðŸªœ Batch step - 1310 -- sub batch step 5242 -- lr 1.96e-04
2025-03-02 13:31:22,313 - INFO - ðŸªœ Batch step - 1310 -- sub batch step 5243 -- lr 1.96e-04
2025-03-02 13:31:23,855 - INFO - Step 1310 -- ðŸ”„ Training Metrics
2025-03-02 13:31:23,855 - INFO - â”œâ”€â”€ Loss: 7.4720
2025-03-02 13:31:23,855 - INFO - â”œâ”€â”€ Learning Rate: 1.96e-04
2025-03-02 13:31:23,855 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:31:24,527 - INFO - ðŸªœ Batch step - 1311 -- sub batch step 5244 -- lr 1.97e-04
2025-03-02 13:31:26,678 - INFO - ðŸªœ Batch step - 1311 -- sub batch step 5245 -- lr 1.97e-04
2025-03-02 13:31:29,331 - INFO - ðŸªœ Batch step - 1311 -- sub batch step 5246 -- lr 1.97e-04
2025-03-02 13:31:31,499 - INFO - ðŸªœ Batch step - 1311 -- sub batch step 5247 -- lr 1.97e-04
2025-03-02 13:31:33,398 - INFO - Step 1311 -- ðŸ”„ Training Metrics
2025-03-02 13:31:33,399 - INFO - â”œâ”€â”€ Loss: 7.4841
2025-03-02 13:31:33,399 - INFO - â”œâ”€â”€ Learning Rate: 1.97e-04
2025-03-02 13:31:33,399 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:31:34,077 - INFO - ðŸªœ Batch step - 1312 -- sub batch step 5248 -- lr 1.97e-04
2025-03-02 13:31:36,241 - INFO - ðŸªœ Batch step - 1312 -- sub batch step 5249 -- lr 1.97e-04
2025-03-02 13:31:38,421 - INFO - ðŸªœ Batch step - 1312 -- sub batch step 5250 -- lr 1.97e-04
2025-03-02 13:31:40,575 - INFO - ðŸªœ Batch step - 1312 -- sub batch step 5251 -- lr 1.97e-04
2025-03-02 13:31:42,080 - INFO - Step 1312 -- ðŸ”„ Training Metrics
2025-03-02 13:31:42,080 - INFO - â”œâ”€â”€ Loss: 7.4803
2025-03-02 13:31:42,080 - INFO - â”œâ”€â”€ Learning Rate: 1.97e-04
2025-03-02 13:31:42,081 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:31:42,761 - INFO - ðŸªœ Batch step - 1313 -- sub batch step 5252 -- lr 1.97e-04
2025-03-02 13:31:44,916 - INFO - ðŸªœ Batch step - 1313 -- sub batch step 5253 -- lr 1.97e-04
2025-03-02 13:31:47,396 - INFO - ðŸªœ Batch step - 1313 -- sub batch step 5254 -- lr 1.97e-04
2025-03-02 13:31:49,557 - INFO - ðŸªœ Batch step - 1313 -- sub batch step 5255 -- lr 1.97e-04
2025-03-02 13:31:51,280 - INFO - Step 1313 -- ðŸ”„ Training Metrics
2025-03-02 13:31:51,281 - INFO - â”œâ”€â”€ Loss: 7.4845
2025-03-02 13:31:51,281 - INFO - â”œâ”€â”€ Learning Rate: 1.97e-04
2025-03-02 13:31:51,281 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:31:51,952 - INFO - ðŸªœ Batch step - 1314 -- sub batch step 5256 -- lr 1.97e-04
2025-03-02 13:31:54,107 - INFO - ðŸªœ Batch step - 1314 -- sub batch step 5257 -- lr 1.97e-04
2025-03-02 13:31:56,270 - INFO - ðŸªœ Batch step - 1314 -- sub batch step 5258 -- lr 1.97e-04
2025-03-02 13:31:58,422 - INFO - ðŸªœ Batch step - 1314 -- sub batch step 5259 -- lr 1.97e-04
2025-03-02 13:31:59,955 - INFO - Step 1314 -- ðŸ”„ Training Metrics
2025-03-02 13:31:59,956 - INFO - â”œâ”€â”€ Loss: 7.5015
2025-03-02 13:31:59,956 - INFO - â”œâ”€â”€ Learning Rate: 1.97e-04
2025-03-02 13:31:59,956 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:32:00,631 - INFO - ðŸªœ Batch step - 1315 -- sub batch step 5260 -- lr 1.97e-04
2025-03-02 13:32:02,779 - INFO - ðŸªœ Batch step - 1315 -- sub batch step 5261 -- lr 1.97e-04
2025-03-02 13:32:05,472 - INFO - ðŸªœ Batch step - 1315 -- sub batch step 5262 -- lr 1.97e-04
2025-03-02 13:32:07,619 - INFO - ðŸªœ Batch step - 1315 -- sub batch step 5263 -- lr 1.97e-04
2025-03-02 13:32:09,185 - INFO - Step 1315 -- ðŸ”„ Training Metrics
2025-03-02 13:32:09,186 - INFO - â”œâ”€â”€ Loss: 7.4608
2025-03-02 13:32:09,186 - INFO - â”œâ”€â”€ Learning Rate: 1.97e-04
2025-03-02 13:32:09,186 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:32:09,858 - INFO - ðŸªœ Batch step - 1316 -- sub batch step 5264 -- lr 1.97e-04
2025-03-02 13:32:12,012 - INFO - ðŸªœ Batch step - 1316 -- sub batch step 5265 -- lr 1.97e-04
2025-03-02 13:32:14,176 - INFO - ðŸªœ Batch step - 1316 -- sub batch step 5266 -- lr 1.97e-04
2025-03-02 13:32:16,329 - INFO - ðŸªœ Batch step - 1316 -- sub batch step 5267 -- lr 1.97e-04
2025-03-02 13:32:17,875 - INFO - Step 1316 -- ðŸ”„ Training Metrics
2025-03-02 13:32:17,876 - INFO - â”œâ”€â”€ Loss: 7.4833
2025-03-02 13:32:17,876 - INFO - â”œâ”€â”€ Learning Rate: 1.97e-04
2025-03-02 13:32:17,876 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:32:18,543 - INFO - ðŸªœ Batch step - 1317 -- sub batch step 5268 -- lr 1.98e-04
2025-03-02 13:32:20,699 - INFO - ðŸªœ Batch step - 1317 -- sub batch step 5269 -- lr 1.98e-04
2025-03-02 13:32:23,367 - INFO - ðŸªœ Batch step - 1317 -- sub batch step 5270 -- lr 1.98e-04
2025-03-02 13:32:25,519 - INFO - ðŸªœ Batch step - 1317 -- sub batch step 5271 -- lr 1.98e-04
2025-03-02 13:32:27,072 - INFO - Step 1317 -- ðŸ”„ Training Metrics
2025-03-02 13:32:27,072 - INFO - â”œâ”€â”€ Loss: 7.4583
2025-03-02 13:32:27,072 - INFO - â”œâ”€â”€ Learning Rate: 1.98e-04
2025-03-02 13:32:27,072 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:32:27,751 - INFO - ðŸªœ Batch step - 1318 -- sub batch step 5272 -- lr 1.98e-04
2025-03-02 13:32:29,900 - INFO - ðŸªœ Batch step - 1318 -- sub batch step 5273 -- lr 1.98e-04
2025-03-02 13:32:32,072 - INFO - ðŸªœ Batch step - 1318 -- sub batch step 5274 -- lr 1.98e-04
2025-03-02 13:32:34,223 - INFO - ðŸªœ Batch step - 1318 -- sub batch step 5275 -- lr 1.98e-04
2025-03-02 13:32:35,771 - INFO - Step 1318 -- ðŸ”„ Training Metrics
2025-03-02 13:32:35,772 - INFO - â”œâ”€â”€ Loss: 7.4599
2025-03-02 13:32:35,772 - INFO - â”œâ”€â”€ Learning Rate: 1.98e-04
2025-03-02 13:32:35,772 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:32:36,439 - INFO - ðŸªœ Batch step - 1319 -- sub batch step 5276 -- lr 1.98e-04
2025-03-02 13:32:38,591 - INFO - ðŸªœ Batch step - 1319 -- sub batch step 5277 -- lr 1.98e-04
2025-03-02 13:32:40,873 - INFO - ðŸªœ Batch step - 1319 -- sub batch step 5278 -- lr 1.98e-04
2025-03-02 13:32:43,033 - INFO - ðŸªœ Batch step - 1319 -- sub batch step 5279 -- lr 1.98e-04
2025-03-02 13:32:44,577 - INFO - Step 1319 -- ðŸ”„ Training Metrics
2025-03-02 13:32:44,577 - INFO - â”œâ”€â”€ Loss: 7.4696
2025-03-02 13:32:44,577 - INFO - â”œâ”€â”€ Learning Rate: 1.98e-04
2025-03-02 13:32:44,578 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:32:45,700 - INFO - ðŸªœ Batch step - 1320 -- sub batch step 5280 -- lr 1.98e-04
2025-03-02 13:32:47,852 - INFO - ðŸªœ Batch step - 1320 -- sub batch step 5281 -- lr 1.98e-04
2025-03-02 13:32:50,009 - INFO - ðŸªœ Batch step - 1320 -- sub batch step 5282 -- lr 1.98e-04
2025-03-02 13:32:52,183 - INFO - ðŸªœ Batch step - 1320 -- sub batch step 5283 -- lr 1.98e-04
2025-03-02 13:32:53,866 - INFO - Step 1320 -- ðŸ”„ Training Metrics
2025-03-02 13:32:53,866 - INFO - â”œâ”€â”€ Loss: 7.4947
2025-03-02 13:32:53,866 - INFO - â”œâ”€â”€ Learning Rate: 1.98e-04
2025-03-02 13:32:53,866 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:32:54,543 - INFO - ðŸªœ Batch step - 1321 -- sub batch step 5284 -- lr 1.98e-04
2025-03-02 13:32:56,700 - INFO - ðŸªœ Batch step - 1321 -- sub batch step 5285 -- lr 1.98e-04
2025-03-02 13:32:58,848 - INFO - ðŸªœ Batch step - 1321 -- sub batch step 5286 -- lr 1.98e-04
2025-03-02 13:33:01,445 - INFO - ðŸªœ Batch step - 1321 -- sub batch step 5287 -- lr 1.98e-04
2025-03-02 13:33:03,025 - INFO - Step 1321 -- ðŸ”„ Training Metrics
2025-03-02 13:33:03,026 - INFO - â”œâ”€â”€ Loss: 7.4675
2025-03-02 13:33:03,026 - INFO - â”œâ”€â”€ Learning Rate: 1.98e-04
2025-03-02 13:33:03,026 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:33:03,694 - INFO - ðŸªœ Batch step - 1322 -- sub batch step 5288 -- lr 1.98e-04
2025-03-02 13:33:05,854 - INFO - ðŸªœ Batch step - 1322 -- sub batch step 5289 -- lr 1.98e-04
2025-03-02 13:33:08,011 - INFO - ðŸªœ Batch step - 1322 -- sub batch step 5290 -- lr 1.98e-04
2025-03-02 13:33:10,172 - INFO - ðŸªœ Batch step - 1322 -- sub batch step 5291 -- lr 1.98e-04
2025-03-02 13:33:11,732 - INFO - Step 1322 -- ðŸ”„ Training Metrics
2025-03-02 13:33:11,732 - INFO - â”œâ”€â”€ Loss: 7.4497
2025-03-02 13:33:11,732 - INFO - â”œâ”€â”€ Learning Rate: 1.98e-04
2025-03-02 13:33:11,732 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:33:12,406 - INFO - ðŸªœ Batch step - 1323 -- sub batch step 5292 -- lr 1.98e-04
2025-03-02 13:33:14,558 - INFO - ðŸªœ Batch step - 1323 -- sub batch step 5293 -- lr 1.98e-04
2025-03-02 13:33:16,715 - INFO - ðŸªœ Batch step - 1323 -- sub batch step 5294 -- lr 1.98e-04
2025-03-02 13:33:19,067 - INFO - ðŸªœ Batch step - 1323 -- sub batch step 5295 -- lr 1.98e-04
2025-03-02 13:33:20,900 - INFO - Step 1323 -- ðŸ”„ Training Metrics
2025-03-02 13:33:20,900 - INFO - â”œâ”€â”€ Loss: 7.4695
2025-03-02 13:33:20,900 - INFO - â”œâ”€â”€ Learning Rate: 1.98e-04
2025-03-02 13:33:20,900 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:33:21,570 - INFO - ðŸªœ Batch step - 1324 -- sub batch step 5296 -- lr 1.99e-04
2025-03-02 13:33:23,729 - INFO - ðŸªœ Batch step - 1324 -- sub batch step 5297 -- lr 1.99e-04
2025-03-02 13:33:25,877 - INFO - ðŸªœ Batch step - 1324 -- sub batch step 5298 -- lr 1.99e-04
2025-03-02 13:33:28,049 - INFO - ðŸªœ Batch step - 1324 -- sub batch step 5299 -- lr 1.99e-04
2025-03-02 13:33:29,599 - INFO - Step 1324 -- ðŸ”„ Training Metrics
2025-03-02 13:33:29,599 - INFO - â”œâ”€â”€ Loss: 7.4584
2025-03-02 13:33:29,600 - INFO - â”œâ”€â”€ Learning Rate: 1.99e-04
2025-03-02 13:33:29,600 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:33:30,274 - INFO - ðŸªœ Batch step - 1325 -- sub batch step 5300 -- lr 1.99e-04
2025-03-02 13:33:32,428 - INFO - ðŸªœ Batch step - 1325 -- sub batch step 5301 -- lr 1.99e-04
2025-03-02 13:33:34,585 - INFO - ðŸªœ Batch step - 1325 -- sub batch step 5302 -- lr 1.99e-04
2025-03-02 13:33:37,286 - INFO - ðŸªœ Batch step - 1325 -- sub batch step 5303 -- lr 1.99e-04
2025-03-02 13:33:38,891 - INFO - Step 1325 -- ðŸ”„ Training Metrics
2025-03-02 13:33:38,892 - INFO - â”œâ”€â”€ Loss: 7.4728
2025-03-02 13:33:38,892 - INFO - â”œâ”€â”€ Learning Rate: 1.99e-04
2025-03-02 13:33:38,892 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:33:39,569 - INFO - ðŸªœ Batch step - 1326 -- sub batch step 5304 -- lr 1.99e-04
2025-03-02 13:33:41,722 - INFO - ðŸªœ Batch step - 1326 -- sub batch step 5305 -- lr 1.99e-04
2025-03-02 13:33:43,870 - INFO - ðŸªœ Batch step - 1326 -- sub batch step 5306 -- lr 1.99e-04
2025-03-02 13:33:46,039 - INFO - ðŸªœ Batch step - 1326 -- sub batch step 5307 -- lr 1.99e-04
2025-03-02 13:33:47,600 - INFO - Step 1326 -- ðŸ”„ Training Metrics
2025-03-02 13:33:47,600 - INFO - â”œâ”€â”€ Loss: 7.4617
2025-03-02 13:33:47,600 - INFO - â”œâ”€â”€ Learning Rate: 1.99e-04
2025-03-02 13:33:47,600 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:33:48,265 - INFO - ðŸªœ Batch step - 1327 -- sub batch step 5308 -- lr 1.99e-04
2025-03-02 13:33:50,427 - INFO - ðŸªœ Batch step - 1327 -- sub batch step 5309 -- lr 1.99e-04
2025-03-02 13:33:52,584 - INFO - ðŸªœ Batch step - 1327 -- sub batch step 5310 -- lr 1.99e-04
2025-03-02 13:33:55,223 - INFO - ðŸªœ Batch step - 1327 -- sub batch step 5311 -- lr 1.99e-04
2025-03-02 13:33:56,799 - INFO - Step 1327 -- ðŸ”„ Training Metrics
2025-03-02 13:33:56,799 - INFO - â”œâ”€â”€ Loss: 7.4663
2025-03-02 13:33:56,799 - INFO - â”œâ”€â”€ Learning Rate: 1.99e-04
2025-03-02 13:33:56,799 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:33:57,482 - INFO - ðŸªœ Batch step - 1328 -- sub batch step 5312 -- lr 1.99e-04
2025-03-02 13:33:59,630 - INFO - ðŸªœ Batch step - 1328 -- sub batch step 5313 -- lr 1.99e-04
2025-03-02 13:34:01,785 - INFO - ðŸªœ Batch step - 1328 -- sub batch step 5314 -- lr 1.99e-04
2025-03-02 13:34:03,951 - INFO - ðŸªœ Batch step - 1328 -- sub batch step 5315 -- lr 1.99e-04
2025-03-02 13:34:05,515 - INFO - Step 1328 -- ðŸ”„ Training Metrics
2025-03-02 13:34:05,516 - INFO - â”œâ”€â”€ Loss: 7.4689
2025-03-02 13:34:05,516 - INFO - â”œâ”€â”€ Learning Rate: 1.99e-04
2025-03-02 13:34:05,516 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:34:06,184 - INFO - ðŸªœ Batch step - 1329 -- sub batch step 5316 -- lr 1.99e-04
2025-03-02 13:34:08,344 - INFO - ðŸªœ Batch step - 1329 -- sub batch step 5317 -- lr 1.99e-04
2025-03-02 13:34:10,493 - INFO - ðŸªœ Batch step - 1329 -- sub batch step 5318 -- lr 1.99e-04
2025-03-02 13:34:12,881 - INFO - ðŸªœ Batch step - 1329 -- sub batch step 5319 -- lr 1.99e-04
2025-03-02 13:34:14,735 - INFO - Step 1329 -- ðŸ”„ Training Metrics
2025-03-02 13:34:14,735 - INFO - â”œâ”€â”€ Loss: 7.4650
2025-03-02 13:34:14,735 - INFO - â”œâ”€â”€ Learning Rate: 1.99e-04
2025-03-02 13:34:14,735 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:34:15,409 - INFO - ðŸªœ Batch step - 1330 -- sub batch step 5320 -- lr 1.99e-04
2025-03-02 13:34:17,566 - INFO - ðŸªœ Batch step - 1330 -- sub batch step 5321 -- lr 1.99e-04
2025-03-02 13:34:19,740 - INFO - ðŸªœ Batch step - 1330 -- sub batch step 5322 -- lr 1.99e-04
2025-03-02 13:34:21,907 - INFO - ðŸªœ Batch step - 1330 -- sub batch step 5323 -- lr 1.99e-04
2025-03-02 13:34:23,430 - INFO - Step 1330 -- ðŸ”„ Training Metrics
2025-03-02 13:34:23,430 - INFO - â”œâ”€â”€ Loss: 7.4698
2025-03-02 13:34:23,430 - INFO - â”œâ”€â”€ Learning Rate: 1.99e-04
2025-03-02 13:34:23,430 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:34:24,108 - INFO - ðŸªœ Batch step - 1331 -- sub batch step 5324 -- lr 2.00e-04
2025-03-02 13:34:26,264 - INFO - ðŸªœ Batch step - 1331 -- sub batch step 5325 -- lr 2.00e-04
2025-03-02 13:34:28,620 - INFO - ðŸªœ Batch step - 1331 -- sub batch step 5326 -- lr 2.00e-04
2025-03-02 13:34:30,779 - INFO - ðŸªœ Batch step - 1331 -- sub batch step 5327 -- lr 2.00e-04
2025-03-02 13:34:32,655 - INFO - Step 1331 -- ðŸ”„ Training Metrics
2025-03-02 13:34:32,655 - INFO - â”œâ”€â”€ Loss: 7.4498
2025-03-02 13:34:32,655 - INFO - â”œâ”€â”€ Learning Rate: 2.00e-04
2025-03-02 13:34:32,655 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:34:33,324 - INFO - ðŸªœ Batch step - 1332 -- sub batch step 5328 -- lr 2.00e-04
2025-03-02 13:34:35,483 - INFO - ðŸªœ Batch step - 1332 -- sub batch step 5329 -- lr 2.00e-04
2025-03-02 13:34:37,654 - INFO - ðŸªœ Batch step - 1332 -- sub batch step 5330 -- lr 2.00e-04
2025-03-02 13:34:39,802 - INFO - ðŸªœ Batch step - 1332 -- sub batch step 5331 -- lr 2.00e-04
2025-03-02 13:34:41,361 - INFO - Step 1332 -- ðŸ”„ Training Metrics
2025-03-02 13:34:41,362 - INFO - â”œâ”€â”€ Loss: 7.4420
2025-03-02 13:34:41,362 - INFO - â”œâ”€â”€ Learning Rate: 2.00e-04
2025-03-02 13:34:41,362 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:34:42,042 - INFO - ðŸªœ Batch step - 1333 -- sub batch step 5332 -- lr 2.00e-04
2025-03-02 13:34:44,193 - INFO - ðŸªœ Batch step - 1333 -- sub batch step 5333 -- lr 2.00e-04
2025-03-02 13:34:46,912 - INFO - ðŸªœ Batch step - 1333 -- sub batch step 5334 -- lr 2.00e-04
2025-03-02 13:34:49,068 - INFO - ðŸªœ Batch step - 1333 -- sub batch step 5335 -- lr 2.00e-04
2025-03-02 13:34:50,610 - INFO - Step 1333 -- ðŸ”„ Training Metrics
2025-03-02 13:34:50,610 - INFO - â”œâ”€â”€ Loss: 7.4640
2025-03-02 13:34:50,610 - INFO - â”œâ”€â”€ Learning Rate: 2.00e-04
2025-03-02 13:34:50,610 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:34:51,285 - INFO - ðŸªœ Batch step - 1334 -- sub batch step 5336 -- lr 2.00e-04
2025-03-02 13:34:53,444 - INFO - ðŸªœ Batch step - 1334 -- sub batch step 5337 -- lr 2.00e-04
2025-03-02 13:34:55,609 - INFO - ðŸªœ Batch step - 1334 -- sub batch step 5338 -- lr 2.00e-04
2025-03-02 13:34:57,764 - INFO - ðŸªœ Batch step - 1334 -- sub batch step 5339 -- lr 2.00e-04
2025-03-02 13:34:59,325 - INFO - Step 1334 -- ðŸ”„ Training Metrics
2025-03-02 13:34:59,325 - INFO - â”œâ”€â”€ Loss: 7.4709
2025-03-02 13:34:59,325 - INFO - â”œâ”€â”€ Learning Rate: 2.00e-04
2025-03-02 13:34:59,325 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:34:59,997 - INFO - ðŸªœ Batch step - 1335 -- sub batch step 5340 -- lr 2.00e-04
2025-03-02 13:35:02,153 - INFO - ðŸªœ Batch step - 1335 -- sub batch step 5341 -- lr 2.00e-04
2025-03-02 13:35:04,548 - INFO - ðŸªœ Batch step - 1335 -- sub batch step 5342 -- lr 2.00e-04
2025-03-02 13:35:06,706 - INFO - ðŸªœ Batch step - 1335 -- sub batch step 5343 -- lr 2.00e-04
2025-03-02 13:35:08,503 - INFO - Step 1335 -- ðŸ”„ Training Metrics
2025-03-02 13:35:08,503 - INFO - â”œâ”€â”€ Loss: 7.4746
2025-03-02 13:35:08,503 - INFO - â”œâ”€â”€ Learning Rate: 2.00e-04
2025-03-02 13:35:08,503 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:35:09,182 - INFO - ðŸªœ Batch step - 1336 -- sub batch step 5344 -- lr 2.00e-04
2025-03-02 13:35:11,344 - INFO - ðŸªœ Batch step - 1336 -- sub batch step 5345 -- lr 2.00e-04
2025-03-02 13:35:13,511 - INFO - ðŸªœ Batch step - 1336 -- sub batch step 5346 -- lr 2.00e-04
2025-03-02 13:35:15,665 - INFO - ðŸªœ Batch step - 1336 -- sub batch step 5347 -- lr 2.00e-04
2025-03-02 13:35:17,220 - INFO - Step 1336 -- ðŸ”„ Training Metrics
2025-03-02 13:35:17,220 - INFO - â”œâ”€â”€ Loss: 7.4688
2025-03-02 13:35:17,220 - INFO - â”œâ”€â”€ Learning Rate: 2.00e-04
2025-03-02 13:35:17,220 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:35:17,891 - INFO - ðŸªœ Batch step - 1337 -- sub batch step 5348 -- lr 2.01e-04
2025-03-02 13:35:20,054 - INFO - ðŸªœ Batch step - 1337 -- sub batch step 5349 -- lr 2.01e-04
2025-03-02 13:35:22,553 - INFO - ðŸªœ Batch step - 1337 -- sub batch step 5350 -- lr 2.01e-04
2025-03-02 13:35:24,710 - INFO - ðŸªœ Batch step - 1337 -- sub batch step 5351 -- lr 2.01e-04
2025-03-02 13:35:26,413 - INFO - Step 1337 -- ðŸ”„ Training Metrics
2025-03-02 13:35:26,414 - INFO - â”œâ”€â”€ Loss: 7.4480
2025-03-02 13:35:26,414 - INFO - â”œâ”€â”€ Learning Rate: 2.01e-04
2025-03-02 13:35:26,414 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:35:27,092 - INFO - ðŸªœ Batch step - 1338 -- sub batch step 5352 -- lr 2.01e-04
2025-03-02 13:35:29,247 - INFO - ðŸªœ Batch step - 1338 -- sub batch step 5353 -- lr 2.01e-04
2025-03-02 13:35:31,414 - INFO - ðŸªœ Batch step - 1338 -- sub batch step 5354 -- lr 2.01e-04
2025-03-02 13:35:33,566 - INFO - ðŸªœ Batch step - 1338 -- sub batch step 5355 -- lr 2.01e-04
2025-03-02 13:35:35,124 - INFO - Step 1338 -- ðŸ”„ Training Metrics
2025-03-02 13:35:35,124 - INFO - â”œâ”€â”€ Loss: 7.4531
2025-03-02 13:35:35,124 - INFO - â”œâ”€â”€ Learning Rate: 2.01e-04
2025-03-02 13:35:35,125 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:35:35,790 - INFO - ðŸªœ Batch step - 1339 -- sub batch step 5356 -- lr 2.01e-04
2025-03-02 13:35:37,944 - INFO - ðŸªœ Batch step - 1339 -- sub batch step 5357 -- lr 2.01e-04
2025-03-02 13:35:40,240 - INFO - ðŸªœ Batch step - 1339 -- sub batch step 5358 -- lr 2.01e-04
2025-03-02 13:35:42,397 - INFO - ðŸªœ Batch step - 1339 -- sub batch step 5359 -- lr 2.01e-04
2025-03-02 13:35:44,209 - INFO - Step 1339 -- ðŸ”„ Training Metrics
2025-03-02 13:35:44,210 - INFO - â”œâ”€â”€ Loss: 7.4752
2025-03-02 13:35:44,210 - INFO - â”œâ”€â”€ Learning Rate: 2.01e-04
2025-03-02 13:35:44,210 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:35:45,499 - INFO - ðŸªœ Batch step - 1340 -- sub batch step 5360 -- lr 2.01e-04
2025-03-02 13:35:47,648 - INFO - ðŸªœ Batch step - 1340 -- sub batch step 5361 -- lr 2.01e-04
2025-03-02 13:35:49,800 - INFO - ðŸªœ Batch step - 1340 -- sub batch step 5362 -- lr 2.01e-04
2025-03-02 13:35:51,963 - INFO - ðŸªœ Batch step - 1340 -- sub batch step 5363 -- lr 2.01e-04
2025-03-02 13:35:53,848 - INFO - Step 1340 -- ðŸ”„ Training Metrics
2025-03-02 13:35:53,848 - INFO - â”œâ”€â”€ Loss: 7.4481
2025-03-02 13:35:53,848 - INFO - â”œâ”€â”€ Learning Rate: 2.01e-04
2025-03-02 13:35:53,848 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:35:54,524 - INFO - ðŸªœ Batch step - 1341 -- sub batch step 5364 -- lr 2.01e-04
2025-03-02 13:35:56,679 - INFO - ðŸªœ Batch step - 1341 -- sub batch step 5365 -- lr 2.01e-04
2025-03-02 13:35:58,830 - INFO - ðŸªœ Batch step - 1341 -- sub batch step 5366 -- lr 2.01e-04
2025-03-02 13:36:01,242 - INFO - ðŸªœ Batch step - 1341 -- sub batch step 5367 -- lr 2.01e-04
2025-03-02 13:36:03,205 - INFO - Step 1341 -- ðŸ”„ Training Metrics
2025-03-02 13:36:03,205 - INFO - â”œâ”€â”€ Loss: 7.4565
2025-03-02 13:36:03,205 - INFO - â”œâ”€â”€ Learning Rate: 2.01e-04
2025-03-02 13:36:03,206 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:36:03,871 - INFO - ðŸªœ Batch step - 1342 -- sub batch step 5368 -- lr 2.01e-04
2025-03-02 13:36:06,030 - INFO - ðŸªœ Batch step - 1342 -- sub batch step 5369 -- lr 2.01e-04
2025-03-02 13:36:08,187 - INFO - ðŸªœ Batch step - 1342 -- sub batch step 5370 -- lr 2.01e-04
2025-03-02 13:36:10,355 - INFO - ðŸªœ Batch step - 1342 -- sub batch step 5371 -- lr 2.01e-04
2025-03-02 13:36:11,901 - INFO - Step 1342 -- ðŸ”„ Training Metrics
2025-03-02 13:36:11,902 - INFO - â”œâ”€â”€ Loss: 7.4614
2025-03-02 13:36:11,902 - INFO - â”œâ”€â”€ Learning Rate: 2.01e-04
2025-03-02 13:36:11,902 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:36:12,577 - INFO - ðŸªœ Batch step - 1343 -- sub batch step 5372 -- lr 2.01e-04
2025-03-02 13:36:14,730 - INFO - ðŸªœ Batch step - 1343 -- sub batch step 5373 -- lr 2.01e-04
2025-03-02 13:36:16,884 - INFO - ðŸªœ Batch step - 1343 -- sub batch step 5374 -- lr 2.01e-04
2025-03-02 13:36:19,299 - INFO - ðŸªœ Batch step - 1343 -- sub batch step 5375 -- lr 2.01e-04
2025-03-02 13:36:21,135 - INFO - Step 1343 -- ðŸ”„ Training Metrics
2025-03-02 13:36:21,136 - INFO - â”œâ”€â”€ Loss: 7.4555
2025-03-02 13:36:21,136 - INFO - â”œâ”€â”€ Learning Rate: 2.01e-04
2025-03-02 13:36:21,136 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:36:21,807 - INFO - ðŸªœ Batch step - 1344 -- sub batch step 5376 -- lr 2.02e-04
2025-03-02 13:36:23,967 - INFO - ðŸªœ Batch step - 1344 -- sub batch step 5377 -- lr 2.02e-04
2025-03-02 13:36:26,117 - INFO - ðŸªœ Batch step - 1344 -- sub batch step 5378 -- lr 2.02e-04
2025-03-02 13:36:28,285 - INFO - ðŸªœ Batch step - 1344 -- sub batch step 5379 -- lr 2.02e-04
2025-03-02 13:36:29,851 - INFO - Step 1344 -- ðŸ”„ Training Metrics
2025-03-02 13:36:29,851 - INFO - â”œâ”€â”€ Loss: 7.4518
2025-03-02 13:36:29,851 - INFO - â”œâ”€â”€ Learning Rate: 2.02e-04
2025-03-02 13:36:29,851 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:36:30,525 - INFO - ðŸªœ Batch step - 1345 -- sub batch step 5380 -- lr 2.02e-04
2025-03-02 13:36:32,680 - INFO - ðŸªœ Batch step - 1345 -- sub batch step 5381 -- lr 2.02e-04
2025-03-02 13:36:34,836 - INFO - ðŸªœ Batch step - 1345 -- sub batch step 5382 -- lr 2.02e-04
2025-03-02 13:36:37,524 - INFO - ðŸªœ Batch step - 1345 -- sub batch step 5383 -- lr 2.02e-04
2025-03-02 13:36:39,014 - INFO - Step 1345 -- ðŸ”„ Training Metrics
2025-03-02 13:36:39,014 - INFO - â”œâ”€â”€ Loss: 7.4616
2025-03-02 13:36:39,014 - INFO - â”œâ”€â”€ Learning Rate: 2.02e-04
2025-03-02 13:36:39,014 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:36:39,691 - INFO - ðŸªœ Batch step - 1346 -- sub batch step 5384 -- lr 2.02e-04
2025-03-02 13:36:41,846 - INFO - ðŸªœ Batch step - 1346 -- sub batch step 5385 -- lr 2.02e-04
2025-03-02 13:36:43,992 - INFO - ðŸªœ Batch step - 1346 -- sub batch step 5386 -- lr 2.02e-04
2025-03-02 13:36:46,161 - INFO - ðŸªœ Batch step - 1346 -- sub batch step 5387 -- lr 2.02e-04
2025-03-02 13:36:47,712 - INFO - Step 1346 -- ðŸ”„ Training Metrics
2025-03-02 13:36:47,712 - INFO - â”œâ”€â”€ Loss: 7.4508
2025-03-02 13:36:47,712 - INFO - â”œâ”€â”€ Learning Rate: 2.02e-04
2025-03-02 13:36:47,712 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:36:48,381 - INFO - ðŸªœ Batch step - 1347 -- sub batch step 5388 -- lr 2.02e-04
2025-03-02 13:36:50,541 - INFO - ðŸªœ Batch step - 1347 -- sub batch step 5389 -- lr 2.02e-04
2025-03-02 13:36:52,701 - INFO - ðŸªœ Batch step - 1347 -- sub batch step 5390 -- lr 2.02e-04
2025-03-02 13:36:55,384 - INFO - ðŸªœ Batch step - 1347 -- sub batch step 5391 -- lr 2.02e-04
2025-03-02 13:36:57,021 - INFO - Step 1347 -- ðŸ”„ Training Metrics
2025-03-02 13:36:57,021 - INFO - â”œâ”€â”€ Loss: 7.4525
2025-03-02 13:36:57,022 - INFO - â”œâ”€â”€ Learning Rate: 2.02e-04
2025-03-02 13:36:57,022 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:36:57,696 - INFO - ðŸªœ Batch step - 1348 -- sub batch step 5392 -- lr 2.02e-04
2025-03-02 13:36:59,848 - INFO - ðŸªœ Batch step - 1348 -- sub batch step 5393 -- lr 2.02e-04
2025-03-02 13:37:02,007 - INFO - ðŸªœ Batch step - 1348 -- sub batch step 5394 -- lr 2.02e-04
2025-03-02 13:37:04,178 - INFO - ðŸªœ Batch step - 1348 -- sub batch step 5395 -- lr 2.02e-04
2025-03-02 13:37:05,718 - INFO - Step 1348 -- ðŸ”„ Training Metrics
2025-03-02 13:37:05,718 - INFO - â”œâ”€â”€ Loss: 7.4403
2025-03-02 13:37:05,719 - INFO - â”œâ”€â”€ Learning Rate: 2.02e-04
2025-03-02 13:37:05,719 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:37:06,389 - INFO - ðŸªœ Batch step - 1349 -- sub batch step 5396 -- lr 2.02e-04
2025-03-02 13:37:08,549 - INFO - ðŸªœ Batch step - 1349 -- sub batch step 5397 -- lr 2.02e-04
2025-03-02 13:37:10,702 - INFO - ðŸªœ Batch step - 1349 -- sub batch step 5398 -- lr 2.02e-04
2025-03-02 13:37:13,379 - INFO - ðŸªœ Batch step - 1349 -- sub batch step 5399 -- lr 2.02e-04
2025-03-02 13:37:14,918 - INFO - Step 1349 -- ðŸ”„ Training Metrics
2025-03-02 13:37:14,919 - INFO - â”œâ”€â”€ Loss: 7.4816
2025-03-02 13:37:14,919 - INFO - â”œâ”€â”€ Learning Rate: 2.02e-04
2025-03-02 13:37:14,919 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:37:15,592 - INFO - ðŸªœ Batch step - 1350 -- sub batch step 5400 -- lr 2.02e-04
2025-03-02 13:37:17,747 - INFO - ðŸªœ Batch step - 1350 -- sub batch step 5401 -- lr 2.02e-04
2025-03-02 13:37:19,904 - INFO - ðŸªœ Batch step - 1350 -- sub batch step 5402 -- lr 2.02e-04
2025-03-02 13:37:22,067 - INFO - ðŸªœ Batch step - 1350 -- sub batch step 5403 -- lr 2.02e-04
2025-03-02 13:37:23,605 - INFO - Step 1350 -- ðŸ”„ Training Metrics
2025-03-02 13:37:23,606 - INFO - â”œâ”€â”€ Loss: 7.4429
2025-03-02 13:37:23,606 - INFO - â”œâ”€â”€ Learning Rate: 2.02e-04
2025-03-02 13:37:23,606 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:37:24,286 - INFO - ðŸªœ Batch step - 1351 -- sub batch step 5404 -- lr 2.03e-04
2025-03-02 13:37:26,446 - INFO - ðŸªœ Batch step - 1351 -- sub batch step 5405 -- lr 2.03e-04
2025-03-02 13:37:29,079 - INFO - ðŸªœ Batch step - 1351 -- sub batch step 5406 -- lr 2.03e-04
2025-03-02 13:37:31,241 - INFO - ðŸªœ Batch step - 1351 -- sub batch step 5407 -- lr 2.03e-04
2025-03-02 13:37:32,898 - INFO - Step 1351 -- ðŸ”„ Training Metrics
2025-03-02 13:37:32,898 - INFO - â”œâ”€â”€ Loss: 7.4720
2025-03-02 13:37:32,898 - INFO - â”œâ”€â”€ Learning Rate: 2.03e-04
2025-03-02 13:37:32,898 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:37:33,567 - INFO - ðŸªœ Batch step - 1352 -- sub batch step 5408 -- lr 2.03e-04
2025-03-02 13:37:35,730 - INFO - ðŸªœ Batch step - 1352 -- sub batch step 5409 -- lr 2.03e-04
2025-03-02 13:37:37,899 - INFO - ðŸªœ Batch step - 1352 -- sub batch step 5410 -- lr 2.03e-04
2025-03-02 13:37:40,048 - INFO - ðŸªœ Batch step - 1352 -- sub batch step 5411 -- lr 2.03e-04
2025-03-02 13:37:41,598 - INFO - Step 1352 -- ðŸ”„ Training Metrics
2025-03-02 13:37:41,599 - INFO - â”œâ”€â”€ Loss: 7.4609
2025-03-02 13:37:41,599 - INFO - â”œâ”€â”€ Learning Rate: 2.03e-04
2025-03-02 13:37:41,599 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:37:42,273 - INFO - ðŸªœ Batch step - 1353 -- sub batch step 5412 -- lr 2.03e-04
2025-03-02 13:37:44,428 - INFO - ðŸªœ Batch step - 1353 -- sub batch step 5413 -- lr 2.03e-04
2025-03-02 13:37:47,102 - INFO - ðŸªœ Batch step - 1353 -- sub batch step 5414 -- lr 2.03e-04
2025-03-02 13:37:49,256 - INFO - ðŸªœ Batch step - 1353 -- sub batch step 5415 -- lr 2.03e-04
2025-03-02 13:37:50,757 - INFO - Step 1353 -- ðŸ”„ Training Metrics
2025-03-02 13:37:50,758 - INFO - â”œâ”€â”€ Loss: 7.4708
2025-03-02 13:37:50,758 - INFO - â”œâ”€â”€ Learning Rate: 2.03e-04
2025-03-02 13:37:50,758 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:37:51,427 - INFO - ðŸªœ Batch step - 1354 -- sub batch step 5416 -- lr 2.03e-04
2025-03-02 13:37:53,585 - INFO - ðŸªœ Batch step - 1354 -- sub batch step 5417 -- lr 2.03e-04
2025-03-02 13:37:55,748 - INFO - ðŸªœ Batch step - 1354 -- sub batch step 5418 -- lr 2.03e-04
2025-03-02 13:37:57,906 - INFO - ðŸªœ Batch step - 1354 -- sub batch step 5419 -- lr 2.03e-04
2025-03-02 13:37:59,461 - INFO - Step 1354 -- ðŸ”„ Training Metrics
2025-03-02 13:37:59,461 - INFO - â”œâ”€â”€ Loss: 7.4355
2025-03-02 13:37:59,461 - INFO - â”œâ”€â”€ Learning Rate: 2.03e-04
2025-03-02 13:37:59,461 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:38:00,136 - INFO - ðŸªœ Batch step - 1355 -- sub batch step 5420 -- lr 2.03e-04
2025-03-02 13:38:02,292 - INFO - ðŸªœ Batch step - 1355 -- sub batch step 5421 -- lr 2.03e-04
2025-03-02 13:38:04,896 - INFO - ðŸªœ Batch step - 1355 -- sub batch step 5422 -- lr 2.03e-04
2025-03-02 13:38:07,051 - INFO - ðŸªœ Batch step - 1355 -- sub batch step 5423 -- lr 2.03e-04
2025-03-02 13:38:08,940 - INFO - Step 1355 -- ðŸ”„ Training Metrics
2025-03-02 13:38:08,940 - INFO - â”œâ”€â”€ Loss: 7.4419
2025-03-02 13:38:08,940 - INFO - â”œâ”€â”€ Learning Rate: 2.03e-04
2025-03-02 13:38:08,940 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:38:09,617 - INFO - ðŸªœ Batch step - 1356 -- sub batch step 5424 -- lr 2.03e-04
2025-03-02 13:38:11,775 - INFO - ðŸªœ Batch step - 1356 -- sub batch step 5425 -- lr 2.03e-04
2025-03-02 13:38:13,939 - INFO - ðŸªœ Batch step - 1356 -- sub batch step 5426 -- lr 2.03e-04
2025-03-02 13:38:16,098 - INFO - ðŸªœ Batch step - 1356 -- sub batch step 5427 -- lr 2.03e-04
2025-03-02 13:38:17,634 - INFO - Step 1356 -- ðŸ”„ Training Metrics
2025-03-02 13:38:17,634 - INFO - â”œâ”€â”€ Loss: 7.4404
2025-03-02 13:38:17,634 - INFO - â”œâ”€â”€ Learning Rate: 2.03e-04
2025-03-02 13:38:17,634 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:38:18,305 - INFO - ðŸªœ Batch step - 1357 -- sub batch step 5428 -- lr 2.04e-04
2025-03-02 13:38:20,466 - INFO - ðŸªœ Batch step - 1357 -- sub batch step 5429 -- lr 2.04e-04
2025-03-02 13:38:23,151 - INFO - ðŸªœ Batch step - 1357 -- sub batch step 5430 -- lr 2.04e-04
2025-03-02 13:38:25,308 - INFO - ðŸªœ Batch step - 1357 -- sub batch step 5431 -- lr 2.04e-04
2025-03-02 13:38:27,199 - INFO - Step 1357 -- ðŸ”„ Training Metrics
2025-03-02 13:38:27,199 - INFO - â”œâ”€â”€ Loss: 7.4214
2025-03-02 13:38:27,200 - INFO - â”œâ”€â”€ Learning Rate: 2.04e-04
2025-03-02 13:38:27,200 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:38:27,872 - INFO - ðŸªœ Batch step - 1358 -- sub batch step 5432 -- lr 2.04e-04
2025-03-02 13:38:30,023 - INFO - ðŸªœ Batch step - 1358 -- sub batch step 5433 -- lr 2.04e-04
2025-03-02 13:38:32,205 - INFO - ðŸªœ Batch step - 1358 -- sub batch step 5434 -- lr 2.04e-04
2025-03-02 13:38:34,362 - INFO - ðŸªœ Batch step - 1358 -- sub batch step 5435 -- lr 2.04e-04
2025-03-02 13:38:35,899 - INFO - Step 1358 -- ðŸ”„ Training Metrics
2025-03-02 13:38:35,899 - INFO - â”œâ”€â”€ Loss: 7.4750
2025-03-02 13:38:35,899 - INFO - â”œâ”€â”€ Learning Rate: 2.04e-04
2025-03-02 13:38:35,900 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:38:36,570 - INFO - ðŸªœ Batch step - 1359 -- sub batch step 5436 -- lr 2.04e-04
2025-03-02 13:38:38,731 - INFO - ðŸªœ Batch step - 1359 -- sub batch step 5437 -- lr 2.04e-04
2025-03-02 13:38:41,159 - INFO - ðŸªœ Batch step - 1359 -- sub batch step 5438 -- lr 2.04e-04
2025-03-02 13:38:43,319 - INFO - ðŸªœ Batch step - 1359 -- sub batch step 5439 -- lr 2.04e-04
2025-03-02 13:38:44,945 - INFO - Step 1359 -- ðŸ”„ Training Metrics
2025-03-02 13:38:44,945 - INFO - â”œâ”€â”€ Loss: 7.4486
2025-03-02 13:38:44,945 - INFO - â”œâ”€â”€ Learning Rate: 2.04e-04
2025-03-02 13:38:44,946 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:38:46,230 - INFO - ðŸªœ Batch step - 1360 -- sub batch step 5440 -- lr 2.04e-04
2025-03-02 13:38:48,385 - INFO - ðŸªœ Batch step - 1360 -- sub batch step 5441 -- lr 2.04e-04
2025-03-02 13:38:50,540 - INFO - ðŸªœ Batch step - 1360 -- sub batch step 5442 -- lr 2.04e-04
2025-03-02 13:38:52,708 - INFO - ðŸªœ Batch step - 1360 -- sub batch step 5443 -- lr 2.04e-04
2025-03-02 13:38:54,278 - INFO - Step 1360 -- ðŸ”„ Training Metrics
2025-03-02 13:38:54,278 - INFO - â”œâ”€â”€ Loss: 7.4468
2025-03-02 13:38:54,278 - INFO - â”œâ”€â”€ Learning Rate: 2.04e-04
2025-03-02 13:38:54,278 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:38:54,954 - INFO - ðŸªœ Batch step - 1361 -- sub batch step 5444 -- lr 2.04e-04
2025-03-02 13:38:57,109 - INFO - ðŸªœ Batch step - 1361 -- sub batch step 5445 -- lr 2.04e-04
2025-03-02 13:38:59,254 - INFO - ðŸªœ Batch step - 1361 -- sub batch step 5446 -- lr 2.04e-04
2025-03-02 13:39:01,879 - INFO - ðŸªœ Batch step - 1361 -- sub batch step 5447 -- lr 2.04e-04
2025-03-02 13:39:03,444 - INFO - Step 1361 -- ðŸ”„ Training Metrics
2025-03-02 13:39:03,444 - INFO - â”œâ”€â”€ Loss: 7.4668
2025-03-02 13:39:03,444 - INFO - â”œâ”€â”€ Learning Rate: 2.04e-04
2025-03-02 13:39:03,444 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:39:04,113 - INFO - ðŸªœ Batch step - 1362 -- sub batch step 5448 -- lr 2.04e-04
2025-03-02 13:39:06,274 - INFO - ðŸªœ Batch step - 1362 -- sub batch step 5449 -- lr 2.04e-04
2025-03-02 13:39:08,430 - INFO - ðŸªœ Batch step - 1362 -- sub batch step 5450 -- lr 2.04e-04
2025-03-02 13:39:10,594 - INFO - ðŸªœ Batch step - 1362 -- sub batch step 5451 -- lr 2.04e-04
2025-03-02 13:39:12,146 - INFO - Step 1362 -- ðŸ”„ Training Metrics
2025-03-02 13:39:12,146 - INFO - â”œâ”€â”€ Loss: 7.4588
2025-03-02 13:39:12,146 - INFO - â”œâ”€â”€ Learning Rate: 2.04e-04
2025-03-02 13:39:12,147 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:39:12,822 - INFO - ðŸªœ Batch step - 1363 -- sub batch step 5452 -- lr 2.04e-04
2025-03-02 13:39:14,974 - INFO - ðŸªœ Batch step - 1363 -- sub batch step 5453 -- lr 2.04e-04
2025-03-02 13:39:17,128 - INFO - ðŸªœ Batch step - 1363 -- sub batch step 5454 -- lr 2.04e-04
2025-03-02 13:39:19,504 - INFO - ðŸªœ Batch step - 1363 -- sub batch step 5455 -- lr 2.04e-04
2025-03-02 13:39:21,272 - INFO - Step 1363 -- ðŸ”„ Training Metrics
2025-03-02 13:39:21,273 - INFO - â”œâ”€â”€ Loss: 7.4508
2025-03-02 13:39:21,273 - INFO - â”œâ”€â”€ Learning Rate: 2.04e-04
2025-03-02 13:39:21,273 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:39:21,940 - INFO - ðŸªœ Batch step - 1364 -- sub batch step 5456 -- lr 2.05e-04
2025-03-02 13:39:24,100 - INFO - ðŸªœ Batch step - 1364 -- sub batch step 5457 -- lr 2.05e-04
2025-03-02 13:39:26,243 - INFO - ðŸªœ Batch step - 1364 -- sub batch step 5458 -- lr 2.05e-04
2025-03-02 13:39:28,412 - INFO - ðŸªœ Batch step - 1364 -- sub batch step 5459 -- lr 2.05e-04
2025-03-02 13:39:29,961 - INFO - Step 1364 -- ðŸ”„ Training Metrics
2025-03-02 13:39:29,961 - INFO - â”œâ”€â”€ Loss: 7.4289
2025-03-02 13:39:29,961 - INFO - â”œâ”€â”€ Learning Rate: 2.05e-04
2025-03-02 13:39:29,961 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:39:30,633 - INFO - ðŸªœ Batch step - 1365 -- sub batch step 5460 -- lr 2.05e-04
2025-03-02 13:39:32,782 - INFO - ðŸªœ Batch step - 1365 -- sub batch step 5461 -- lr 2.05e-04
2025-03-02 13:39:34,940 - INFO - ðŸªœ Batch step - 1365 -- sub batch step 5462 -- lr 2.05e-04
2025-03-02 13:39:37,555 - INFO - ðŸªœ Batch step - 1365 -- sub batch step 5463 -- lr 2.05e-04
2025-03-02 13:39:39,394 - INFO - Step 1365 -- ðŸ”„ Training Metrics
2025-03-02 13:39:39,395 - INFO - â”œâ”€â”€ Loss: 7.4677
2025-03-02 13:39:39,395 - INFO - â”œâ”€â”€ Learning Rate: 2.05e-04
2025-03-02 13:39:39,395 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:39:40,073 - INFO - ðŸªœ Batch step - 1366 -- sub batch step 5464 -- lr 2.05e-04
2025-03-02 13:39:42,229 - INFO - ðŸªœ Batch step - 1366 -- sub batch step 5465 -- lr 2.05e-04
2025-03-02 13:39:44,375 - INFO - ðŸªœ Batch step - 1366 -- sub batch step 5466 -- lr 2.05e-04
2025-03-02 13:39:46,545 - INFO - ðŸªœ Batch step - 1366 -- sub batch step 5467 -- lr 2.05e-04
2025-03-02 13:39:48,094 - INFO - Step 1366 -- ðŸ”„ Training Metrics
2025-03-02 13:39:48,094 - INFO - â”œâ”€â”€ Loss: 7.4451
2025-03-02 13:39:48,094 - INFO - â”œâ”€â”€ Learning Rate: 2.05e-04
2025-03-02 13:39:48,094 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:39:48,762 - INFO - ðŸªœ Batch step - 1367 -- sub batch step 5468 -- lr 2.05e-04
2025-03-02 13:39:50,918 - INFO - ðŸªœ Batch step - 1367 -- sub batch step 5469 -- lr 2.05e-04
2025-03-02 13:39:53,071 - INFO - ðŸªœ Batch step - 1367 -- sub batch step 5470 -- lr 2.05e-04
2025-03-02 13:39:55,786 - INFO - ðŸªœ Batch step - 1367 -- sub batch step 5471 -- lr 2.05e-04
2025-03-02 13:39:57,311 - INFO - Step 1367 -- ðŸ”„ Training Metrics
2025-03-02 13:39:57,311 - INFO - â”œâ”€â”€ Loss: 7.4338
2025-03-02 13:39:57,311 - INFO - â”œâ”€â”€ Learning Rate: 2.05e-04
2025-03-02 13:39:57,311 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:39:57,984 - INFO - ðŸªœ Batch step - 1368 -- sub batch step 5472 -- lr 2.05e-04
2025-03-02 13:40:00,137 - INFO - ðŸªœ Batch step - 1368 -- sub batch step 5473 -- lr 2.05e-04
2025-03-02 13:40:02,297 - INFO - ðŸªœ Batch step - 1368 -- sub batch step 5474 -- lr 2.05e-04
2025-03-02 13:40:04,465 - INFO - ðŸªœ Batch step - 1368 -- sub batch step 5475 -- lr 2.05e-04
2025-03-02 13:40:06,020 - INFO - Step 1368 -- ðŸ”„ Training Metrics
2025-03-02 13:40:06,020 - INFO - â”œâ”€â”€ Loss: 7.4431
2025-03-02 13:40:06,020 - INFO - â”œâ”€â”€ Learning Rate: 2.05e-04
2025-03-02 13:40:06,020 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:40:06,688 - INFO - ðŸªœ Batch step - 1369 -- sub batch step 5476 -- lr 2.05e-04
2025-03-02 13:40:08,847 - INFO - ðŸªœ Batch step - 1369 -- sub batch step 5477 -- lr 2.05e-04
2025-03-02 13:40:10,996 - INFO - ðŸªœ Batch step - 1369 -- sub batch step 5478 -- lr 2.05e-04
2025-03-02 13:40:13,617 - INFO - ðŸªœ Batch step - 1369 -- sub batch step 5479 -- lr 2.05e-04
2025-03-02 13:40:15,199 - INFO - Step 1369 -- ðŸ”„ Training Metrics
2025-03-02 13:40:15,199 - INFO - â”œâ”€â”€ Loss: 7.4284
2025-03-02 13:40:15,199 - INFO - â”œâ”€â”€ Learning Rate: 2.05e-04
2025-03-02 13:40:15,199 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:40:15,874 - INFO - ðŸªœ Batch step - 1370 -- sub batch step 5480 -- lr 2.06e-04
2025-03-02 13:40:18,025 - INFO - ðŸªœ Batch step - 1370 -- sub batch step 5481 -- lr 2.06e-04
2025-03-02 13:40:20,179 - INFO - ðŸªœ Batch step - 1370 -- sub batch step 5482 -- lr 2.06e-04
2025-03-02 13:40:22,342 - INFO - ðŸªœ Batch step - 1370 -- sub batch step 5483 -- lr 2.06e-04
2025-03-02 13:40:23,896 - INFO - Step 1370 -- ðŸ”„ Training Metrics
2025-03-02 13:40:23,896 - INFO - â”œâ”€â”€ Loss: 7.4309
2025-03-02 13:40:23,896 - INFO - â”œâ”€â”€ Learning Rate: 2.06e-04
2025-03-02 13:40:23,897 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:40:24,573 - INFO - ðŸªœ Batch step - 1371 -- sub batch step 5484 -- lr 2.06e-04
2025-03-02 13:40:26,728 - INFO - ðŸªœ Batch step - 1371 -- sub batch step 5485 -- lr 2.06e-04
2025-03-02 13:40:29,379 - INFO - ðŸªœ Batch step - 1371 -- sub batch step 5486 -- lr 2.06e-04
2025-03-02 13:40:31,541 - INFO - ðŸªœ Batch step - 1371 -- sub batch step 5487 -- lr 2.06e-04
2025-03-02 13:40:33,070 - INFO - Step 1371 -- ðŸ”„ Training Metrics
2025-03-02 13:40:33,070 - INFO - â”œâ”€â”€ Loss: 7.4508
2025-03-02 13:40:33,070 - INFO - â”œâ”€â”€ Learning Rate: 2.06e-04
2025-03-02 13:40:33,070 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:40:33,737 - INFO - ðŸªœ Batch step - 1372 -- sub batch step 5488 -- lr 2.06e-04
2025-03-02 13:40:35,893 - INFO - ðŸªœ Batch step - 1372 -- sub batch step 5489 -- lr 2.06e-04
2025-03-02 13:40:38,069 - INFO - ðŸªœ Batch step - 1372 -- sub batch step 5490 -- lr 2.06e-04
2025-03-02 13:40:40,216 - INFO - ðŸªœ Batch step - 1372 -- sub batch step 5491 -- lr 2.06e-04
2025-03-02 13:40:41,773 - INFO - Step 1372 -- ðŸ”„ Training Metrics
2025-03-02 13:40:41,773 - INFO - â”œâ”€â”€ Loss: 7.4518
2025-03-02 13:40:41,773 - INFO - â”œâ”€â”€ Learning Rate: 2.06e-04
2025-03-02 13:40:41,773 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:40:42,447 - INFO - ðŸªœ Batch step - 1373 -- sub batch step 5492 -- lr 2.06e-04
2025-03-02 13:40:44,596 - INFO - ðŸªœ Batch step - 1373 -- sub batch step 5493 -- lr 2.06e-04
2025-03-02 13:40:47,314 - INFO - ðŸªœ Batch step - 1373 -- sub batch step 5494 -- lr 2.06e-04
2025-03-02 13:40:49,468 - INFO - ðŸªœ Batch step - 1373 -- sub batch step 5495 -- lr 2.06e-04
2025-03-02 13:40:51,009 - INFO - Step 1373 -- ðŸ”„ Training Metrics
2025-03-02 13:40:51,009 - INFO - â”œâ”€â”€ Loss: 7.4413
2025-03-02 13:40:51,009 - INFO - â”œâ”€â”€ Learning Rate: 2.06e-04
2025-03-02 13:40:51,009 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:40:51,679 - INFO - ðŸªœ Batch step - 1374 -- sub batch step 5496 -- lr 2.06e-04
2025-03-02 13:40:53,838 - INFO - ðŸªœ Batch step - 1374 -- sub batch step 5497 -- lr 2.06e-04
2025-03-02 13:40:55,999 - INFO - ðŸªœ Batch step - 1374 -- sub batch step 5498 -- lr 2.06e-04
2025-03-02 13:40:58,156 - INFO - ðŸªœ Batch step - 1374 -- sub batch step 5499 -- lr 2.06e-04
2025-03-02 13:40:59,705 - INFO - Step 1374 -- ðŸ”„ Training Metrics
2025-03-02 13:40:59,705 - INFO - â”œâ”€â”€ Loss: 7.4524
2025-03-02 13:40:59,706 - INFO - â”œâ”€â”€ Learning Rate: 2.06e-04
2025-03-02 13:40:59,706 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:41:00,376 - INFO - ðŸªœ Batch step - 1375 -- sub batch step 5500 -- lr 2.06e-04
2025-03-02 13:41:02,524 - INFO - ðŸªœ Batch step - 1375 -- sub batch step 5501 -- lr 2.06e-04
2025-03-02 13:41:04,902 - INFO - ðŸªœ Batch step - 1375 -- sub batch step 5502 -- lr 2.06e-04
2025-03-02 13:41:07,052 - INFO - ðŸªœ Batch step - 1375 -- sub batch step 5503 -- lr 2.06e-04
2025-03-02 13:41:09,046 - INFO - Step 1375 -- ðŸ”„ Training Metrics
2025-03-02 13:41:09,046 - INFO - â”œâ”€â”€ Loss: 7.4425
2025-03-02 13:41:09,046 - INFO - â”œâ”€â”€ Learning Rate: 2.06e-04
2025-03-02 13:41:09,046 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:41:09,722 - INFO - ðŸªœ Batch step - 1376 -- sub batch step 5504 -- lr 2.06e-04
2025-03-02 13:41:11,877 - INFO - ðŸªœ Batch step - 1376 -- sub batch step 5505 -- lr 2.06e-04
2025-03-02 13:41:14,043 - INFO - ðŸªœ Batch step - 1376 -- sub batch step 5506 -- lr 2.06e-04
2025-03-02 13:41:16,197 - INFO - ðŸªœ Batch step - 1376 -- sub batch step 5507 -- lr 2.06e-04
2025-03-02 13:41:17,739 - INFO - Step 1376 -- ðŸ”„ Training Metrics
2025-03-02 13:41:17,739 - INFO - â”œâ”€â”€ Loss: 7.4578
2025-03-02 13:41:17,739 - INFO - â”œâ”€â”€ Learning Rate: 2.06e-04
2025-03-02 13:41:17,739 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:41:18,407 - INFO - ðŸªœ Batch step - 1377 -- sub batch step 5508 -- lr 2.07e-04
2025-03-02 13:41:20,567 - INFO - ðŸªœ Batch step - 1377 -- sub batch step 5509 -- lr 2.07e-04
2025-03-02 13:41:23,159 - INFO - ðŸªœ Batch step - 1377 -- sub batch step 5510 -- lr 2.07e-04
2025-03-02 13:41:25,313 - INFO - ðŸªœ Batch step - 1377 -- sub batch step 5511 -- lr 2.07e-04
2025-03-02 13:41:26,941 - INFO - Step 1377 -- ðŸ”„ Training Metrics
2025-03-02 13:41:26,942 - INFO - â”œâ”€â”€ Loss: 7.4367
2025-03-02 13:41:26,942 - INFO - â”œâ”€â”€ Learning Rate: 2.07e-04
2025-03-02 13:41:26,942 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:41:27,617 - INFO - ðŸªœ Batch step - 1378 -- sub batch step 5512 -- lr 2.07e-04
2025-03-02 13:41:29,767 - INFO - ðŸªœ Batch step - 1378 -- sub batch step 5513 -- lr 2.07e-04
2025-03-02 13:41:31,941 - INFO - ðŸªœ Batch step - 1378 -- sub batch step 5514 -- lr 2.07e-04
2025-03-02 13:41:34,097 - INFO - ðŸªœ Batch step - 1378 -- sub batch step 5515 -- lr 2.07e-04
2025-03-02 13:41:35,635 - INFO - Step 1378 -- ðŸ”„ Training Metrics
2025-03-02 13:41:35,635 - INFO - â”œâ”€â”€ Loss: 7.4349
2025-03-02 13:41:35,635 - INFO - â”œâ”€â”€ Learning Rate: 2.07e-04
2025-03-02 13:41:35,635 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:41:36,304 - INFO - ðŸªœ Batch step - 1379 -- sub batch step 5516 -- lr 2.07e-04
2025-03-02 13:41:38,466 - INFO - ðŸªœ Batch step - 1379 -- sub batch step 5517 -- lr 2.07e-04
2025-03-02 13:41:40,744 - INFO - ðŸªœ Batch step - 1379 -- sub batch step 5518 -- lr 2.07e-04
2025-03-02 13:41:42,900 - INFO - ðŸªœ Batch step - 1379 -- sub batch step 5519 -- lr 2.07e-04
2025-03-02 13:41:44,566 - INFO - Step 1379 -- ðŸ”„ Training Metrics
2025-03-02 13:41:44,566 - INFO - â”œâ”€â”€ Loss: 7.4421
2025-03-02 13:41:44,566 - INFO - â”œâ”€â”€ Learning Rate: 2.07e-04
2025-03-02 13:41:44,567 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:41:45,844 - INFO - ðŸªœ Batch step - 1380 -- sub batch step 5520 -- lr 2.07e-04
2025-03-02 13:41:47,994 - INFO - ðŸªœ Batch step - 1380 -- sub batch step 5521 -- lr 2.07e-04
2025-03-02 13:41:50,147 - INFO - ðŸªœ Batch step - 1380 -- sub batch step 5522 -- lr 2.07e-04
2025-03-02 13:41:52,319 - INFO - ðŸªœ Batch step - 1380 -- sub batch step 5523 -- lr 2.07e-04
2025-03-02 13:41:53,905 - INFO - Step 1380 -- ðŸ”„ Training Metrics
2025-03-02 13:41:53,905 - INFO - â”œâ”€â”€ Loss: 7.4428
2025-03-02 13:41:53,905 - INFO - â”œâ”€â”€ Learning Rate: 2.07e-04
2025-03-02 13:41:53,905 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:41:54,581 - INFO - ðŸªœ Batch step - 1381 -- sub batch step 5524 -- lr 2.07e-04
2025-03-02 13:41:56,735 - INFO - ðŸªœ Batch step - 1381 -- sub batch step 5525 -- lr 2.07e-04
2025-03-02 13:41:58,881 - INFO - ðŸªœ Batch step - 1381 -- sub batch step 5526 -- lr 2.07e-04
2025-03-02 13:42:01,475 - INFO - ðŸªœ Batch step - 1381 -- sub batch step 5527 -- lr 2.07e-04
2025-03-02 13:42:03,044 - INFO - Step 1381 -- ðŸ”„ Training Metrics
2025-03-02 13:42:03,045 - INFO - â”œâ”€â”€ Loss: 7.4363
2025-03-02 13:42:03,045 - INFO - â”œâ”€â”€ Learning Rate: 2.07e-04
2025-03-02 13:42:03,045 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:42:03,712 - INFO - ðŸªœ Batch step - 1382 -- sub batch step 5528 -- lr 2.07e-04
2025-03-02 13:42:05,874 - INFO - ðŸªœ Batch step - 1382 -- sub batch step 5529 -- lr 2.07e-04
2025-03-02 13:42:08,028 - INFO - ðŸªœ Batch step - 1382 -- sub batch step 5530 -- lr 2.07e-04
2025-03-02 13:42:10,191 - INFO - ðŸªœ Batch step - 1382 -- sub batch step 5531 -- lr 2.07e-04
2025-03-02 13:42:11,731 - INFO - Step 1382 -- ðŸ”„ Training Metrics
2025-03-02 13:42:11,731 - INFO - â”œâ”€â”€ Loss: 7.4099
2025-03-02 13:42:11,731 - INFO - â”œâ”€â”€ Learning Rate: 2.07e-04
2025-03-02 13:42:11,731 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:42:12,406 - INFO - ðŸªœ Batch step - 1383 -- sub batch step 5532 -- lr 2.07e-04
2025-03-02 13:42:14,558 - INFO - ðŸªœ Batch step - 1383 -- sub batch step 5533 -- lr 2.07e-04
2025-03-02 13:42:16,715 - INFO - ðŸªœ Batch step - 1383 -- sub batch step 5534 -- lr 2.07e-04
2025-03-02 13:42:19,352 - INFO - ðŸªœ Batch step - 1383 -- sub batch step 5535 -- lr 2.07e-04
2025-03-02 13:42:20,920 - INFO - Step 1383 -- ðŸ”„ Training Metrics
2025-03-02 13:42:20,921 - INFO - â”œâ”€â”€ Loss: 7.4451
2025-03-02 13:42:20,921 - INFO - â”œâ”€â”€ Learning Rate: 2.07e-04
2025-03-02 13:42:20,921 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:42:21,591 - INFO - ðŸªœ Batch step - 1384 -- sub batch step 5536 -- lr 2.08e-04
2025-03-02 13:42:23,747 - INFO - ðŸªœ Batch step - 1384 -- sub batch step 5537 -- lr 2.08e-04
2025-03-02 13:42:25,896 - INFO - ðŸªœ Batch step - 1384 -- sub batch step 5538 -- lr 2.08e-04
2025-03-02 13:42:28,072 - INFO - ðŸªœ Batch step - 1384 -- sub batch step 5539 -- lr 2.08e-04
2025-03-02 13:42:29,617 - INFO - Step 1384 -- ðŸ”„ Training Metrics
2025-03-02 13:42:29,617 - INFO - â”œâ”€â”€ Loss: 7.4473
2025-03-02 13:42:29,617 - INFO - â”œâ”€â”€ Learning Rate: 2.08e-04
2025-03-02 13:42:29,617 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:42:30,291 - INFO - ðŸªœ Batch step - 1385 -- sub batch step 5540 -- lr 2.08e-04
2025-03-02 13:42:32,449 - INFO - ðŸªœ Batch step - 1385 -- sub batch step 5541 -- lr 2.08e-04
2025-03-02 13:42:34,602 - INFO - ðŸªœ Batch step - 1385 -- sub batch step 5542 -- lr 2.08e-04
2025-03-02 13:42:37,424 - INFO - ðŸªœ Batch step - 1385 -- sub batch step 5543 -- lr 2.08e-04
2025-03-02 13:42:38,916 - INFO - Step 1385 -- ðŸ”„ Training Metrics
2025-03-02 13:42:38,917 - INFO - â”œâ”€â”€ Loss: 7.4614
2025-03-02 13:42:38,917 - INFO - â”œâ”€â”€ Learning Rate: 2.08e-04
2025-03-02 13:42:38,917 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:42:39,593 - INFO - ðŸªœ Batch step - 1386 -- sub batch step 5544 -- lr 2.08e-04
2025-03-02 13:42:41,747 - INFO - ðŸªœ Batch step - 1386 -- sub batch step 5545 -- lr 2.08e-04
2025-03-02 13:42:43,892 - INFO - ðŸªœ Batch step - 1386 -- sub batch step 5546 -- lr 2.08e-04
2025-03-02 13:42:46,060 - INFO - ðŸªœ Batch step - 1386 -- sub batch step 5547 -- lr 2.08e-04
2025-03-02 13:42:47,611 - INFO - Step 1386 -- ðŸ”„ Training Metrics
2025-03-02 13:42:47,611 - INFO - â”œâ”€â”€ Loss: 7.4083
2025-03-02 13:42:47,611 - INFO - â”œâ”€â”€ Learning Rate: 2.08e-04
2025-03-02 13:42:47,611 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:42:48,276 - INFO - ðŸªœ Batch step - 1387 -- sub batch step 5548 -- lr 2.08e-04
2025-03-02 13:42:50,437 - INFO - ðŸªœ Batch step - 1387 -- sub batch step 5549 -- lr 2.08e-04
2025-03-02 13:42:52,596 - INFO - ðŸªœ Batch step - 1387 -- sub batch step 5550 -- lr 2.08e-04
2025-03-02 13:42:55,410 - INFO - ðŸªœ Batch step - 1387 -- sub batch step 5551 -- lr 2.08e-04
2025-03-02 13:42:56,902 - INFO - Step 1387 -- ðŸ”„ Training Metrics
2025-03-02 13:42:56,902 - INFO - â”œâ”€â”€ Loss: 7.4202
2025-03-02 13:42:56,903 - INFO - â”œâ”€â”€ Learning Rate: 2.08e-04
2025-03-02 13:42:56,903 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:42:57,575 - INFO - ðŸªœ Batch step - 1388 -- sub batch step 5552 -- lr 2.08e-04
2025-03-02 13:42:59,727 - INFO - ðŸªœ Batch step - 1388 -- sub batch step 5553 -- lr 2.08e-04
2025-03-02 13:43:01,885 - INFO - ðŸªœ Batch step - 1388 -- sub batch step 5554 -- lr 2.08e-04
2025-03-02 13:43:04,056 - INFO - ðŸªœ Batch step - 1388 -- sub batch step 5555 -- lr 2.08e-04
2025-03-02 13:43:05,605 - INFO - Step 1388 -- ðŸ”„ Training Metrics
2025-03-02 13:43:05,605 - INFO - â”œâ”€â”€ Loss: 7.4425
2025-03-02 13:43:05,606 - INFO - â”œâ”€â”€ Learning Rate: 2.08e-04
2025-03-02 13:43:05,606 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:43:06,274 - INFO - ðŸªœ Batch step - 1389 -- sub batch step 5556 -- lr 2.08e-04
2025-03-02 13:43:08,432 - INFO - ðŸªœ Batch step - 1389 -- sub batch step 5557 -- lr 2.08e-04
2025-03-02 13:43:10,623 - INFO - ðŸªœ Batch step - 1389 -- sub batch step 5558 -- lr 2.08e-04
2025-03-02 13:43:13,034 - INFO - ðŸªœ Batch step - 1389 -- sub batch step 5559 -- lr 2.08e-04
2025-03-02 13:43:14,798 - INFO - Step 1389 -- ðŸ”„ Training Metrics
2025-03-02 13:43:14,798 - INFO - â”œâ”€â”€ Loss: 7.4372
2025-03-02 13:43:14,798 - INFO - â”œâ”€â”€ Learning Rate: 2.08e-04
2025-03-02 13:43:14,798 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:43:15,478 - INFO - ðŸªœ Batch step - 1390 -- sub batch step 5560 -- lr 2.08e-04
2025-03-02 13:43:17,633 - INFO - ðŸªœ Batch step - 1390 -- sub batch step 5561 -- lr 2.08e-04
2025-03-02 13:43:19,791 - INFO - ðŸªœ Batch step - 1390 -- sub batch step 5562 -- lr 2.08e-04
2025-03-02 13:43:21,960 - INFO - ðŸªœ Batch step - 1390 -- sub batch step 5563 -- lr 2.08e-04
2025-03-02 13:43:23,490 - INFO - Step 1390 -- ðŸ”„ Training Metrics
2025-03-02 13:43:23,491 - INFO - â”œâ”€â”€ Loss: 7.4385
2025-03-02 13:43:23,491 - INFO - â”œâ”€â”€ Learning Rate: 2.08e-04
2025-03-02 13:43:23,491 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:43:24,162 - INFO - ðŸªœ Batch step - 1391 -- sub batch step 5564 -- lr 2.09e-04
2025-03-02 13:43:26,318 - INFO - ðŸªœ Batch step - 1391 -- sub batch step 5565 -- lr 2.09e-04
2025-03-02 13:43:28,823 - INFO - ðŸªœ Batch step - 1391 -- sub batch step 5566 -- lr 2.09e-04
2025-03-02 13:43:30,975 - INFO - ðŸªœ Batch step - 1391 -- sub batch step 5567 -- lr 2.09e-04
2025-03-02 13:43:32,583 - INFO - Step 1391 -- ðŸ”„ Training Metrics
2025-03-02 13:43:32,583 - INFO - â”œâ”€â”€ Loss: 7.4419
2025-03-02 13:43:32,583 - INFO - â”œâ”€â”€ Learning Rate: 2.09e-04
2025-03-02 13:43:32,583 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:43:33,248 - INFO - ðŸªœ Batch step - 1392 -- sub batch step 5568 -- lr 2.09e-04
2025-03-02 13:43:35,407 - INFO - ðŸªœ Batch step - 1392 -- sub batch step 5569 -- lr 2.09e-04
2025-03-02 13:43:37,577 - INFO - ðŸªœ Batch step - 1392 -- sub batch step 5570 -- lr 2.09e-04
2025-03-02 13:43:39,725 - INFO - ðŸªœ Batch step - 1392 -- sub batch step 5571 -- lr 2.09e-04
2025-03-02 13:43:41,272 - INFO - Step 1392 -- ðŸ”„ Training Metrics
2025-03-02 13:43:41,273 - INFO - â”œâ”€â”€ Loss: 7.4199
2025-03-02 13:43:41,273 - INFO - â”œâ”€â”€ Learning Rate: 2.09e-04
2025-03-02 13:43:41,273 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:43:41,944 - INFO - ðŸªœ Batch step - 1393 -- sub batch step 5572 -- lr 2.09e-04
2025-03-02 13:43:44,095 - INFO - ðŸªœ Batch step - 1393 -- sub batch step 5573 -- lr 2.09e-04
2025-03-02 13:43:46,518 - INFO - ðŸªœ Batch step - 1393 -- sub batch step 5574 -- lr 2.09e-04
2025-03-02 13:43:48,677 - INFO - ðŸªœ Batch step - 1393 -- sub batch step 5575 -- lr 2.09e-04
2025-03-02 13:43:50,438 - INFO - Step 1393 -- ðŸ”„ Training Metrics
2025-03-02 13:43:50,438 - INFO - â”œâ”€â”€ Loss: 7.4423
2025-03-02 13:43:50,438 - INFO - â”œâ”€â”€ Learning Rate: 2.09e-04
2025-03-02 13:43:50,438 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:43:51,103 - INFO - ðŸªœ Batch step - 1394 -- sub batch step 5576 -- lr 2.09e-04
2025-03-02 13:43:53,258 - INFO - ðŸªœ Batch step - 1394 -- sub batch step 5577 -- lr 2.09e-04
2025-03-02 13:43:55,421 - INFO - ðŸªœ Batch step - 1394 -- sub batch step 5578 -- lr 2.09e-04
2025-03-02 13:43:57,583 - INFO - ðŸªœ Batch step - 1394 -- sub batch step 5579 -- lr 2.09e-04
2025-03-02 13:43:59,133 - INFO - Step 1394 -- ðŸ”„ Training Metrics
2025-03-02 13:43:59,133 - INFO - â”œâ”€â”€ Loss: 7.4568
2025-03-02 13:43:59,133 - INFO - â”œâ”€â”€ Learning Rate: 2.09e-04
2025-03-02 13:43:59,133 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:43:59,805 - INFO - ðŸªœ Batch step - 1395 -- sub batch step 5580 -- lr 2.09e-04
2025-03-02 13:44:01,955 - INFO - ðŸªœ Batch step - 1395 -- sub batch step 5581 -- lr 2.09e-04
2025-03-02 13:44:04,758 - INFO - ðŸªœ Batch step - 1395 -- sub batch step 5582 -- lr 2.09e-04
2025-03-02 13:44:06,913 - INFO - ðŸªœ Batch step - 1395 -- sub batch step 5583 -- lr 2.09e-04
2025-03-02 13:44:08,405 - INFO - Step 1395 -- ðŸ”„ Training Metrics
2025-03-02 13:44:08,405 - INFO - â”œâ”€â”€ Loss: 7.4134
2025-03-02 13:44:08,405 - INFO - â”œâ”€â”€ Learning Rate: 2.09e-04
2025-03-02 13:44:08,406 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:44:09,077 - INFO - ðŸªœ Batch step - 1396 -- sub batch step 5584 -- lr 2.09e-04
2025-03-02 13:44:11,239 - INFO - ðŸªœ Batch step - 1396 -- sub batch step 5585 -- lr 2.09e-04
2025-03-02 13:44:13,400 - INFO - ðŸªœ Batch step - 1396 -- sub batch step 5586 -- lr 2.09e-04
2025-03-02 13:44:15,560 - INFO - ðŸªœ Batch step - 1396 -- sub batch step 5587 -- lr 2.09e-04
2025-03-02 13:44:17,099 - INFO - Step 1396 -- ðŸ”„ Training Metrics
2025-03-02 13:44:17,099 - INFO - â”œâ”€â”€ Loss: 7.4206
2025-03-02 13:44:17,099 - INFO - â”œâ”€â”€ Learning Rate: 2.09e-04
2025-03-02 13:44:17,099 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:44:17,767 - INFO - ðŸªœ Batch step - 1397 -- sub batch step 5588 -- lr 2.10e-04
2025-03-02 13:44:19,927 - INFO - ðŸªœ Batch step - 1397 -- sub batch step 5589 -- lr 2.10e-04
2025-03-02 13:44:22,655 - INFO - ðŸªœ Batch step - 1397 -- sub batch step 5590 -- lr 2.10e-04
2025-03-02 13:44:24,799 - INFO - ðŸªœ Batch step - 1397 -- sub batch step 5591 -- lr 2.10e-04
2025-03-02 13:44:26,322 - INFO - Step 1397 -- ðŸ”„ Training Metrics
2025-03-02 13:44:26,323 - INFO - â”œâ”€â”€ Loss: 7.4166
2025-03-02 13:44:26,323 - INFO - â”œâ”€â”€ Learning Rate: 2.10e-04
2025-03-02 13:44:26,323 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:44:26,994 - INFO - ðŸªœ Batch step - 1398 -- sub batch step 5592 -- lr 2.10e-04
2025-03-02 13:44:29,141 - INFO - ðŸªœ Batch step - 1398 -- sub batch step 5593 -- lr 2.10e-04
2025-03-02 13:44:31,313 - INFO - ðŸªœ Batch step - 1398 -- sub batch step 5594 -- lr 2.10e-04
2025-03-02 13:44:33,467 - INFO - ðŸªœ Batch step - 1398 -- sub batch step 5595 -- lr 2.10e-04
2025-03-02 13:44:35,007 - INFO - Step 1398 -- ðŸ”„ Training Metrics
2025-03-02 13:44:35,008 - INFO - â”œâ”€â”€ Loss: 7.4169
2025-03-02 13:44:35,008 - INFO - â”œâ”€â”€ Learning Rate: 2.10e-04
2025-03-02 13:44:35,008 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:44:35,674 - INFO - ðŸªœ Batch step - 1399 -- sub batch step 5596 -- lr 2.10e-04
2025-03-02 13:44:37,829 - INFO - ðŸªœ Batch step - 1399 -- sub batch step 5597 -- lr 2.10e-04
2025-03-02 13:44:40,110 - INFO - ðŸªœ Batch step - 1399 -- sub batch step 5598 -- lr 2.10e-04
2025-03-02 13:44:42,270 - INFO - ðŸªœ Batch step - 1399 -- sub batch step 5599 -- lr 2.10e-04
2025-03-02 13:44:43,870 - INFO - Step 1399 -- ðŸ”„ Training Metrics
2025-03-02 13:44:43,870 - INFO - â”œâ”€â”€ Loss: 7.4439
2025-03-02 13:44:43,870 - INFO - â”œâ”€â”€ Learning Rate: 2.10e-04
2025-03-02 13:44:43,870 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:44:45,051 - INFO - ðŸªœ Batch step - 1400 -- sub batch step 5600 -- lr 2.10e-04
2025-03-02 13:44:47,208 - INFO - ðŸªœ Batch step - 1400 -- sub batch step 5601 -- lr 2.10e-04
2025-03-02 13:44:49,358 - INFO - ðŸªœ Batch step - 1400 -- sub batch step 5602 -- lr 2.10e-04
2025-03-02 13:44:51,525 - INFO - ðŸªœ Batch step - 1400 -- sub batch step 5603 -- lr 2.10e-04
2025-03-02 13:44:53,152 - INFO - Step 1400 -- ðŸ”„ Training Metrics
2025-03-02 13:44:53,153 - INFO - â”œâ”€â”€ Loss: 7.4054
2025-03-02 13:44:53,153 - INFO - â”œâ”€â”€ Learning Rate: 2.10e-04
2025-03-02 13:44:53,153 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:44:53,831 - INFO - ðŸªœ Batch step - 1401 -- sub batch step 5604 -- lr 2.10e-04
2025-03-02 13:44:55,986 - INFO - ðŸªœ Batch step - 1401 -- sub batch step 5605 -- lr 2.10e-04
2025-03-02 13:44:58,134 - INFO - ðŸªœ Batch step - 1401 -- sub batch step 5606 -- lr 2.10e-04
2025-03-02 13:45:00,737 - INFO - ðŸªœ Batch step - 1401 -- sub batch step 5607 -- lr 2.10e-04
2025-03-02 13:45:02,335 - INFO - Step 1401 -- ðŸ”„ Training Metrics
2025-03-02 13:45:02,335 - INFO - â”œâ”€â”€ Loss: 7.4036
2025-03-02 13:45:02,335 - INFO - â”œâ”€â”€ Learning Rate: 2.10e-04
2025-03-02 13:45:02,336 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:45:03,005 - INFO - ðŸªœ Batch step - 1402 -- sub batch step 5608 -- lr 2.10e-04
2025-03-02 13:45:05,165 - INFO - ðŸªœ Batch step - 1402 -- sub batch step 5609 -- lr 2.10e-04
2025-03-02 13:45:07,321 - INFO - ðŸªœ Batch step - 1402 -- sub batch step 5610 -- lr 2.10e-04
2025-03-02 13:45:09,488 - INFO - ðŸªœ Batch step - 1402 -- sub batch step 5611 -- lr 2.10e-04
2025-03-02 13:45:11,032 - INFO - Step 1402 -- ðŸ”„ Training Metrics
2025-03-02 13:45:11,032 - INFO - â”œâ”€â”€ Loss: 7.4522
2025-03-02 13:45:11,032 - INFO - â”œâ”€â”€ Learning Rate: 2.10e-04
2025-03-02 13:45:11,032 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:45:11,712 - INFO - ðŸªœ Batch step - 1403 -- sub batch step 5612 -- lr 2.10e-04
2025-03-02 13:45:13,867 - INFO - ðŸªœ Batch step - 1403 -- sub batch step 5613 -- lr 2.10e-04
2025-03-02 13:45:16,025 - INFO - ðŸªœ Batch step - 1403 -- sub batch step 5614 -- lr 2.10e-04
2025-03-02 13:45:18,681 - INFO - ðŸªœ Batch step - 1403 -- sub batch step 5615 -- lr 2.10e-04
2025-03-02 13:45:20,214 - INFO - Step 1403 -- ðŸ”„ Training Metrics
2025-03-02 13:45:20,214 - INFO - â”œâ”€â”€ Loss: 7.4359
2025-03-02 13:45:20,214 - INFO - â”œâ”€â”€ Learning Rate: 2.10e-04
2025-03-02 13:45:20,214 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:45:20,882 - INFO - ðŸªœ Batch step - 1404 -- sub batch step 5616 -- lr 2.11e-04
2025-03-02 13:45:23,042 - INFO - ðŸªœ Batch step - 1404 -- sub batch step 5617 -- lr 2.11e-04
2025-03-02 13:45:25,184 - INFO - ðŸªœ Batch step - 1404 -- sub batch step 5618 -- lr 2.11e-04
2025-03-02 13:45:27,357 - INFO - ðŸªœ Batch step - 1404 -- sub batch step 5619 -- lr 2.11e-04
2025-03-02 13:45:28,903 - INFO - Step 1404 -- ðŸ”„ Training Metrics
2025-03-02 13:45:28,903 - INFO - â”œâ”€â”€ Loss: 7.4212
2025-03-02 13:45:28,903 - INFO - â”œâ”€â”€ Learning Rate: 2.11e-04
2025-03-02 13:45:28,903 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:45:29,577 - INFO - ðŸªœ Batch step - 1405 -- sub batch step 5620 -- lr 2.11e-04
2025-03-02 13:45:31,731 - INFO - ðŸªœ Batch step - 1405 -- sub batch step 5621 -- lr 2.11e-04
2025-03-02 13:45:33,886 - INFO - ðŸªœ Batch step - 1405 -- sub batch step 5622 -- lr 2.11e-04
2025-03-02 13:45:36,493 - INFO - ðŸªœ Batch step - 1405 -- sub batch step 5623 -- lr 2.11e-04
2025-03-02 13:45:38,188 - INFO - Step 1405 -- ðŸ”„ Training Metrics
2025-03-02 13:45:38,188 - INFO - â”œâ”€â”€ Loss: 7.4258
2025-03-02 13:45:38,188 - INFO - â”œâ”€â”€ Learning Rate: 2.11e-04
2025-03-02 13:45:38,188 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:45:38,864 - INFO - ðŸªœ Batch step - 1406 -- sub batch step 5624 -- lr 2.11e-04
2025-03-02 13:45:41,021 - INFO - ðŸªœ Batch step - 1406 -- sub batch step 5625 -- lr 2.11e-04
2025-03-02 13:45:43,167 - INFO - ðŸªœ Batch step - 1406 -- sub batch step 5626 -- lr 2.11e-04
2025-03-02 13:45:45,340 - INFO - ðŸªœ Batch step - 1406 -- sub batch step 5627 -- lr 2.11e-04
2025-03-02 13:45:46,909 - INFO - Step 1406 -- ðŸ”„ Training Metrics
2025-03-02 13:45:46,909 - INFO - â”œâ”€â”€ Loss: 7.4259
2025-03-02 13:45:46,909 - INFO - â”œâ”€â”€ Learning Rate: 2.11e-04
2025-03-02 13:45:46,909 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:45:47,584 - INFO - ðŸªœ Batch step - 1407 -- sub batch step 5628 -- lr 2.11e-04
2025-03-02 13:45:49,746 - INFO - ðŸªœ Batch step - 1407 -- sub batch step 5629 -- lr 2.11e-04
2025-03-02 13:45:51,904 - INFO - ðŸªœ Batch step - 1407 -- sub batch step 5630 -- lr 2.11e-04
2025-03-02 13:45:54,311 - INFO - ðŸªœ Batch step - 1407 -- sub batch step 5631 -- lr 2.11e-04
2025-03-02 13:45:56,080 - INFO - Step 1407 -- ðŸ”„ Training Metrics
2025-03-02 13:45:56,080 - INFO - â”œâ”€â”€ Loss: 7.4151
2025-03-02 13:45:56,080 - INFO - â”œâ”€â”€ Learning Rate: 2.11e-04
2025-03-02 13:45:56,080 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:45:56,759 - INFO - ðŸªœ Batch step - 1408 -- sub batch step 5632 -- lr 2.11e-04
2025-03-02 13:45:58,912 - INFO - ðŸªœ Batch step - 1408 -- sub batch step 5633 -- lr 2.11e-04
2025-03-02 13:46:01,072 - INFO - ðŸªœ Batch step - 1408 -- sub batch step 5634 -- lr 2.11e-04
2025-03-02 13:46:03,244 - INFO - ðŸªœ Batch step - 1408 -- sub batch step 5635 -- lr 2.11e-04
2025-03-02 13:46:04,783 - INFO - Step 1408 -- ðŸ”„ Training Metrics
2025-03-02 13:46:04,784 - INFO - â”œâ”€â”€ Loss: 7.4124
2025-03-02 13:46:04,784 - INFO - â”œâ”€â”€ Learning Rate: 2.11e-04
2025-03-02 13:46:04,784 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:46:05,451 - INFO - ðŸªœ Batch step - 1409 -- sub batch step 5636 -- lr 2.11e-04
2025-03-02 13:46:07,608 - INFO - ðŸªœ Batch step - 1409 -- sub batch step 5637 -- lr 2.11e-04
2025-03-02 13:46:09,758 - INFO - ðŸªœ Batch step - 1409 -- sub batch step 5638 -- lr 2.11e-04
2025-03-02 13:46:12,450 - INFO - ðŸªœ Batch step - 1409 -- sub batch step 5639 -- lr 2.11e-04
2025-03-02 13:46:13,939 - INFO - Step 1409 -- ðŸ”„ Training Metrics
2025-03-02 13:46:13,940 - INFO - â”œâ”€â”€ Loss: 7.4300
2025-03-02 13:46:13,940 - INFO - â”œâ”€â”€ Learning Rate: 2.11e-04
2025-03-02 13:46:13,940 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:46:14,616 - INFO - ðŸªœ Batch step - 1410 -- sub batch step 5640 -- lr 2.11e-04
2025-03-02 13:46:16,765 - INFO - ðŸªœ Batch step - 1410 -- sub batch step 5641 -- lr 2.11e-04
2025-03-02 13:46:18,918 - INFO - ðŸªœ Batch step - 1410 -- sub batch step 5642 -- lr 2.11e-04
2025-03-02 13:46:21,087 - INFO - ðŸªœ Batch step - 1410 -- sub batch step 5643 -- lr 2.11e-04
2025-03-02 13:46:22,637 - INFO - Step 1410 -- ðŸ”„ Training Metrics
2025-03-02 13:46:22,637 - INFO - â”œâ”€â”€ Loss: 7.4200
2025-03-02 13:46:22,637 - INFO - â”œâ”€â”€ Learning Rate: 2.11e-04
2025-03-02 13:46:22,637 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:46:23,315 - INFO - ðŸªœ Batch step - 1411 -- sub batch step 5644 -- lr 2.12e-04
2025-03-02 13:46:25,473 - INFO - ðŸªœ Batch step - 1411 -- sub batch step 5645 -- lr 2.12e-04
2025-03-02 13:46:28,140 - INFO - ðŸªœ Batch step - 1411 -- sub batch step 5646 -- lr 2.12e-04
2025-03-02 13:46:30,297 - INFO - ðŸªœ Batch step - 1411 -- sub batch step 5647 -- lr 2.12e-04
2025-03-02 13:46:31,804 - INFO - Step 1411 -- ðŸ”„ Training Metrics
2025-03-02 13:46:31,804 - INFO - â”œâ”€â”€ Loss: 7.4191
2025-03-02 13:46:31,805 - INFO - â”œâ”€â”€ Learning Rate: 2.12e-04
2025-03-02 13:46:31,805 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:46:32,481 - INFO - ðŸªœ Batch step - 1412 -- sub batch step 5648 -- lr 2.12e-04
2025-03-02 13:46:34,640 - INFO - ðŸªœ Batch step - 1412 -- sub batch step 5649 -- lr 2.12e-04
2025-03-02 13:46:36,810 - INFO - ðŸªœ Batch step - 1412 -- sub batch step 5650 -- lr 2.12e-04
2025-03-02 13:46:38,960 - INFO - ðŸªœ Batch step - 1412 -- sub batch step 5651 -- lr 2.12e-04
2025-03-02 13:46:40,501 - INFO - Step 1412 -- ðŸ”„ Training Metrics
2025-03-02 13:46:40,501 - INFO - â”œâ”€â”€ Loss: 7.4014
2025-03-02 13:46:40,501 - INFO - â”œâ”€â”€ Learning Rate: 2.12e-04
2025-03-02 13:46:40,502 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:46:41,179 - INFO - ðŸªœ Batch step - 1413 -- sub batch step 5652 -- lr 2.12e-04
2025-03-02 13:46:43,333 - INFO - ðŸªœ Batch step - 1413 -- sub batch step 5653 -- lr 2.12e-04
2025-03-02 13:46:46,024 - INFO - ðŸªœ Batch step - 1413 -- sub batch step 5654 -- lr 2.12e-04
2025-03-02 13:46:48,180 - INFO - ðŸªœ Batch step - 1413 -- sub batch step 5655 -- lr 2.12e-04
2025-03-02 13:46:49,678 - INFO - Step 1413 -- ðŸ”„ Training Metrics
2025-03-02 13:46:49,678 - INFO - â”œâ”€â”€ Loss: 7.4362
2025-03-02 13:46:49,678 - INFO - â”œâ”€â”€ Learning Rate: 2.12e-04
2025-03-02 13:46:49,678 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:46:50,353 - INFO - ðŸªœ Batch step - 1414 -- sub batch step 5656 -- lr 2.12e-04
2025-03-02 13:46:52,510 - INFO - ðŸªœ Batch step - 1414 -- sub batch step 5657 -- lr 2.12e-04
2025-03-02 13:46:54,671 - INFO - ðŸªœ Batch step - 1414 -- sub batch step 5658 -- lr 2.12e-04
2025-03-02 13:46:56,827 - INFO - ðŸªœ Batch step - 1414 -- sub batch step 5659 -- lr 2.12e-04
2025-03-02 13:46:58,376 - INFO - Step 1414 -- ðŸ”„ Training Metrics
2025-03-02 13:46:58,376 - INFO - â”œâ”€â”€ Loss: 7.4023
2025-03-02 13:46:58,376 - INFO - â”œâ”€â”€ Learning Rate: 2.12e-04
2025-03-02 13:46:58,376 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:46:59,049 - INFO - ðŸªœ Batch step - 1415 -- sub batch step 5660 -- lr 2.12e-04
2025-03-02 13:47:01,198 - INFO - ðŸªœ Batch step - 1415 -- sub batch step 5661 -- lr 2.12e-04
2025-03-02 13:47:03,860 - INFO - ðŸªœ Batch step - 1415 -- sub batch step 5662 -- lr 2.12e-04
2025-03-02 13:47:06,014 - INFO - ðŸªœ Batch step - 1415 -- sub batch step 5663 -- lr 2.12e-04
2025-03-02 13:47:07,583 - INFO - Step 1415 -- ðŸ”„ Training Metrics
2025-03-02 13:47:07,583 - INFO - â”œâ”€â”€ Loss: 7.4110
2025-03-02 13:47:07,583 - INFO - â”œâ”€â”€ Learning Rate: 2.12e-04
2025-03-02 13:47:07,583 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:47:08,261 - INFO - ðŸªœ Batch step - 1416 -- sub batch step 5664 -- lr 2.12e-04
2025-03-02 13:47:10,415 - INFO - ðŸªœ Batch step - 1416 -- sub batch step 5665 -- lr 2.12e-04
2025-03-02 13:47:12,585 - INFO - ðŸªœ Batch step - 1416 -- sub batch step 5666 -- lr 2.12e-04
2025-03-02 13:47:14,738 - INFO - ðŸªœ Batch step - 1416 -- sub batch step 5667 -- lr 2.12e-04
2025-03-02 13:47:16,297 - INFO - Step 1416 -- ðŸ”„ Training Metrics
2025-03-02 13:47:16,297 - INFO - â”œâ”€â”€ Loss: 7.4165
2025-03-02 13:47:16,297 - INFO - â”œâ”€â”€ Learning Rate: 2.12e-04
2025-03-02 13:47:16,297 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:47:16,963 - INFO - ðŸªœ Batch step - 1417 -- sub batch step 5668 -- lr 2.13e-04
2025-03-02 13:47:19,122 - INFO - ðŸªœ Batch step - 1417 -- sub batch step 5669 -- lr 2.13e-04
2025-03-02 13:47:21,793 - INFO - ðŸªœ Batch step - 1417 -- sub batch step 5670 -- lr 2.13e-04
2025-03-02 13:47:23,950 - INFO - ðŸªœ Batch step - 1417 -- sub batch step 5671 -- lr 2.13e-04
2025-03-02 13:47:25,474 - INFO - Step 1417 -- ðŸ”„ Training Metrics
2025-03-02 13:47:25,475 - INFO - â”œâ”€â”€ Loss: 7.4205
2025-03-02 13:47:25,475 - INFO - â”œâ”€â”€ Learning Rate: 2.13e-04
2025-03-02 13:47:25,475 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:47:26,147 - INFO - ðŸªœ Batch step - 1418 -- sub batch step 5672 -- lr 2.13e-04
2025-03-02 13:47:28,295 - INFO - ðŸªœ Batch step - 1418 -- sub batch step 5673 -- lr 2.13e-04
2025-03-02 13:47:30,471 - INFO - ðŸªœ Batch step - 1418 -- sub batch step 5674 -- lr 2.13e-04
2025-03-02 13:47:32,627 - INFO - ðŸªœ Batch step - 1418 -- sub batch step 5675 -- lr 2.13e-04
2025-03-02 13:47:34,179 - INFO - Step 1418 -- ðŸ”„ Training Metrics
2025-03-02 13:47:34,180 - INFO - â”œâ”€â”€ Loss: 7.4248
2025-03-02 13:47:34,180 - INFO - â”œâ”€â”€ Learning Rate: 2.13e-04
2025-03-02 13:47:34,180 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:47:34,849 - INFO - ðŸªœ Batch step - 1419 -- sub batch step 5676 -- lr 2.13e-04
2025-03-02 13:47:37,007 - INFO - ðŸªœ Batch step - 1419 -- sub batch step 5677 -- lr 2.13e-04
2025-03-02 13:47:39,325 - INFO - ðŸªœ Batch step - 1419 -- sub batch step 5678 -- lr 2.13e-04
2025-03-02 13:47:41,480 - INFO - ðŸªœ Batch step - 1419 -- sub batch step 5679 -- lr 2.13e-04
2025-03-02 13:47:43,095 - INFO - Step 1419 -- ðŸ”„ Training Metrics
2025-03-02 13:47:43,095 - INFO - â”œâ”€â”€ Loss: 7.4391
2025-03-02 13:47:43,095 - INFO - â”œâ”€â”€ Learning Rate: 2.13e-04
2025-03-02 13:47:43,095 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:47:44,214 - INFO - ðŸªœ Batch step - 1420 -- sub batch step 5680 -- lr 2.13e-04
2025-03-02 13:47:46,360 - INFO - ðŸªœ Batch step - 1420 -- sub batch step 5681 -- lr 2.13e-04
2025-03-02 13:47:48,517 - INFO - ðŸªœ Batch step - 1420 -- sub batch step 5682 -- lr 2.13e-04
2025-03-02 13:47:50,687 - INFO - ðŸªœ Batch step - 1420 -- sub batch step 5683 -- lr 2.13e-04
2025-03-02 13:47:52,368 - INFO - Step 1420 -- ðŸ”„ Training Metrics
2025-03-02 13:47:52,368 - INFO - â”œâ”€â”€ Loss: 7.4145
2025-03-02 13:47:52,368 - INFO - â”œâ”€â”€ Learning Rate: 2.13e-04
2025-03-02 13:47:52,368 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:47:53,043 - INFO - ðŸªœ Batch step - 1421 -- sub batch step 5684 -- lr 2.13e-04
2025-03-02 13:47:55,197 - INFO - ðŸªœ Batch step - 1421 -- sub batch step 5685 -- lr 2.13e-04
2025-03-02 13:47:57,439 - INFO - ðŸªœ Batch step - 1421 -- sub batch step 5686 -- lr 2.13e-04
2025-03-02 13:48:00,329 - INFO - ðŸªœ Batch step - 1421 -- sub batch step 5687 -- lr 2.13e-04
2025-03-02 13:48:01,821 - INFO - Step 1421 -- ðŸ”„ Training Metrics
2025-03-02 13:48:01,821 - INFO - â”œâ”€â”€ Loss: 7.4172
2025-03-02 13:48:01,822 - INFO - â”œâ”€â”€ Learning Rate: 2.13e-04
2025-03-02 13:48:01,822 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:48:02,492 - INFO - ðŸªœ Batch step - 1422 -- sub batch step 5688 -- lr 2.13e-04
2025-03-02 13:48:04,649 - INFO - ðŸªœ Batch step - 1422 -- sub batch step 5689 -- lr 2.13e-04
2025-03-02 13:48:06,877 - INFO - ðŸªœ Batch step - 1422 -- sub batch step 5690 -- lr 2.13e-04
2025-03-02 13:48:09,188 - INFO - ðŸªœ Batch step - 1422 -- sub batch step 5691 -- lr 2.13e-04
2025-03-02 13:48:10,688 - INFO - Step 1422 -- ðŸ”„ Training Metrics
2025-03-02 13:48:10,689 - INFO - â”œâ”€â”€ Loss: 7.4352
2025-03-02 13:48:10,689 - INFO - â”œâ”€â”€ Learning Rate: 2.13e-04
2025-03-02 13:48:10,689 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:48:11,363 - INFO - ðŸªœ Batch step - 1423 -- sub batch step 5692 -- lr 2.13e-04
2025-03-02 13:48:13,514 - INFO - ðŸªœ Batch step - 1423 -- sub batch step 5693 -- lr 2.13e-04
2025-03-02 13:48:15,667 - INFO - ðŸªœ Batch step - 1423 -- sub batch step 5694 -- lr 2.13e-04
2025-03-02 13:48:18,294 - INFO - ðŸªœ Batch step - 1423 -- sub batch step 5695 -- lr 2.13e-04
2025-03-02 13:48:19,871 - INFO - Step 1423 -- ðŸ”„ Training Metrics
2025-03-02 13:48:19,871 - INFO - â”œâ”€â”€ Loss: 7.4073
2025-03-02 13:48:19,871 - INFO - â”œâ”€â”€ Learning Rate: 2.13e-04
2025-03-02 13:48:19,872 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:48:20,537 - INFO - ðŸªœ Batch step - 1424 -- sub batch step 5696 -- lr 2.14e-04
2025-03-02 13:48:22,698 - INFO - ðŸªœ Batch step - 1424 -- sub batch step 5697 -- lr 2.14e-04
2025-03-02 13:48:24,848 - INFO - ðŸªœ Batch step - 1424 -- sub batch step 5698 -- lr 2.14e-04
2025-03-02 13:48:27,023 - INFO - ðŸªœ Batch step - 1424 -- sub batch step 5699 -- lr 2.14e-04
2025-03-02 13:48:28,570 - INFO - Step 1424 -- ðŸ”„ Training Metrics
2025-03-02 13:48:28,570 - INFO - â”œâ”€â”€ Loss: 7.4081
2025-03-02 13:48:28,570 - INFO - â”œâ”€â”€ Learning Rate: 2.14e-04
2025-03-02 13:48:28,570 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:48:29,242 - INFO - ðŸªœ Batch step - 1425 -- sub batch step 5700 -- lr 2.14e-04
2025-03-02 13:48:31,393 - INFO - ðŸªœ Batch step - 1425 -- sub batch step 5701 -- lr 2.14e-04
2025-03-02 13:48:33,551 - INFO - ðŸªœ Batch step - 1425 -- sub batch step 5702 -- lr 2.14e-04
2025-03-02 13:48:35,970 - INFO - ðŸªœ Batch step - 1425 -- sub batch step 5703 -- lr 2.14e-04
2025-03-02 13:48:37,906 - INFO - Step 1425 -- ðŸ”„ Training Metrics
2025-03-02 13:48:37,906 - INFO - â”œâ”€â”€ Loss: 7.4049
2025-03-02 13:48:37,907 - INFO - â”œâ”€â”€ Learning Rate: 2.14e-04
2025-03-02 13:48:37,907 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:48:38,582 - INFO - ðŸªœ Batch step - 1426 -- sub batch step 5704 -- lr 2.14e-04
2025-03-02 13:48:40,739 - INFO - ðŸªœ Batch step - 1426 -- sub batch step 5705 -- lr 2.14e-04
2025-03-02 13:48:42,891 - INFO - ðŸªœ Batch step - 1426 -- sub batch step 5706 -- lr 2.14e-04
2025-03-02 13:48:45,060 - INFO - ðŸªœ Batch step - 1426 -- sub batch step 5707 -- lr 2.14e-04
2025-03-02 13:48:46,608 - INFO - Step 1426 -- ðŸ”„ Training Metrics
2025-03-02 13:48:46,608 - INFO - â”œâ”€â”€ Loss: 7.4158
2025-03-02 13:48:46,608 - INFO - â”œâ”€â”€ Learning Rate: 2.14e-04
2025-03-02 13:48:46,608 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:48:47,282 - INFO - ðŸªœ Batch step - 1427 -- sub batch step 5708 -- lr 2.14e-04
2025-03-02 13:48:49,446 - INFO - ðŸªœ Batch step - 1427 -- sub batch step 5709 -- lr 2.14e-04
2025-03-02 13:48:51,605 - INFO - ðŸªœ Batch step - 1427 -- sub batch step 5710 -- lr 2.14e-04
2025-03-02 13:48:53,963 - INFO - ðŸªœ Batch step - 1427 -- sub batch step 5711 -- lr 2.14e-04
2025-03-02 13:48:56,054 - INFO - Step 1427 -- ðŸ”„ Training Metrics
2025-03-02 13:48:56,055 - INFO - â”œâ”€â”€ Loss: 7.4140
2025-03-02 13:48:56,055 - INFO - â”œâ”€â”€ Learning Rate: 2.14e-04
2025-03-02 13:48:56,055 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:48:56,730 - INFO - ðŸªœ Batch step - 1428 -- sub batch step 5712 -- lr 2.14e-04
2025-03-02 13:48:58,882 - INFO - ðŸªœ Batch step - 1428 -- sub batch step 5713 -- lr 2.14e-04
2025-03-02 13:49:01,040 - INFO - ðŸªœ Batch step - 1428 -- sub batch step 5714 -- lr 2.14e-04
2025-03-02 13:49:03,216 - INFO - ðŸªœ Batch step - 1428 -- sub batch step 5715 -- lr 2.14e-04
2025-03-02 13:49:04,765 - INFO - Step 1428 -- ðŸ”„ Training Metrics
2025-03-02 13:49:04,766 - INFO - â”œâ”€â”€ Loss: 7.4415
2025-03-02 13:49:04,766 - INFO - â”œâ”€â”€ Learning Rate: 2.14e-04
2025-03-02 13:49:04,766 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:49:05,440 - INFO - ðŸªœ Batch step - 1429 -- sub batch step 5716 -- lr 2.14e-04
2025-03-02 13:49:07,598 - INFO - ðŸªœ Batch step - 1429 -- sub batch step 5717 -- lr 2.14e-04
2025-03-02 13:49:09,746 - INFO - ðŸªœ Batch step - 1429 -- sub batch step 5718 -- lr 2.14e-04
2025-03-02 13:49:12,382 - INFO - ðŸªœ Batch step - 1429 -- sub batch step 5719 -- lr 2.14e-04
2025-03-02 13:49:13,987 - INFO - Step 1429 -- ðŸ”„ Training Metrics
2025-03-02 13:49:13,987 - INFO - â”œâ”€â”€ Loss: 7.4034
2025-03-02 13:49:13,987 - INFO - â”œâ”€â”€ Learning Rate: 2.14e-04
2025-03-02 13:49:13,987 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:49:14,661 - INFO - ðŸªœ Batch step - 1430 -- sub batch step 5720 -- lr 2.14e-04
2025-03-02 13:49:16,815 - INFO - ðŸªœ Batch step - 1430 -- sub batch step 5721 -- lr 2.14e-04
2025-03-02 13:49:18,972 - INFO - ðŸªœ Batch step - 1430 -- sub batch step 5722 -- lr 2.14e-04
2025-03-02 13:49:21,138 - INFO - ðŸªœ Batch step - 1430 -- sub batch step 5723 -- lr 2.14e-04
2025-03-02 13:49:22,779 - INFO - Step 1430 -- ðŸ”„ Training Metrics
2025-03-02 13:49:22,779 - INFO - â”œâ”€â”€ Loss: 7.3903
2025-03-02 13:49:22,779 - INFO - â”œâ”€â”€ Learning Rate: 2.14e-04
2025-03-02 13:49:22,779 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:49:23,451 - INFO - ðŸªœ Batch step - 1431 -- sub batch step 5724 -- lr 2.15e-04
2025-03-02 13:49:25,606 - INFO - ðŸªœ Batch step - 1431 -- sub batch step 5725 -- lr 2.15e-04
2025-03-02 13:49:28,018 - INFO - ðŸªœ Batch step - 1431 -- sub batch step 5726 -- lr 2.15e-04
2025-03-02 13:49:30,173 - INFO - ðŸªœ Batch step - 1431 -- sub batch step 5727 -- lr 2.15e-04
2025-03-02 13:49:32,131 - INFO - Step 1431 -- ðŸ”„ Training Metrics
2025-03-02 13:49:32,131 - INFO - â”œâ”€â”€ Loss: 7.4252
2025-03-02 13:49:32,132 - INFO - â”œâ”€â”€ Learning Rate: 2.15e-04
2025-03-02 13:49:32,132 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:49:32,798 - INFO - ðŸªœ Batch step - 1432 -- sub batch step 5728 -- lr 2.15e-04
2025-03-02 13:49:34,954 - INFO - ðŸªœ Batch step - 1432 -- sub batch step 5729 -- lr 2.15e-04
2025-03-02 13:49:37,127 - INFO - ðŸªœ Batch step - 1432 -- sub batch step 5730 -- lr 2.15e-04
2025-03-02 13:49:39,283 - INFO - ðŸªœ Batch step - 1432 -- sub batch step 5731 -- lr 2.15e-04
2025-03-02 13:49:40,834 - INFO - Step 1432 -- ðŸ”„ Training Metrics
2025-03-02 13:49:40,834 - INFO - â”œâ”€â”€ Loss: 7.3831
2025-03-02 13:49:40,835 - INFO - â”œâ”€â”€ Learning Rate: 2.15e-04
2025-03-02 13:49:40,835 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:49:41,507 - INFO - ðŸªœ Batch step - 1433 -- sub batch step 5732 -- lr 2.15e-04
2025-03-02 13:49:43,659 - INFO - ðŸªœ Batch step - 1433 -- sub batch step 5733 -- lr 2.15e-04
2025-03-02 13:49:46,025 - INFO - ðŸªœ Batch step - 1433 -- sub batch step 5734 -- lr 2.15e-04
2025-03-02 13:49:48,180 - INFO - ðŸªœ Batch step - 1433 -- sub batch step 5735 -- lr 2.15e-04
2025-03-02 13:49:50,201 - INFO - Step 1433 -- ðŸ”„ Training Metrics
2025-03-02 13:49:50,202 - INFO - â”œâ”€â”€ Loss: 7.4132
2025-03-02 13:49:50,202 - INFO - â”œâ”€â”€ Learning Rate: 2.15e-04
2025-03-02 13:49:50,202 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:49:50,870 - INFO - ðŸªœ Batch step - 1434 -- sub batch step 5736 -- lr 2.15e-04
2025-03-02 13:49:53,024 - INFO - ðŸªœ Batch step - 1434 -- sub batch step 5737 -- lr 2.15e-04
2025-03-02 13:49:55,187 - INFO - ðŸªœ Batch step - 1434 -- sub batch step 5738 -- lr 2.15e-04
2025-03-02 13:49:57,346 - INFO - ðŸªœ Batch step - 1434 -- sub batch step 5739 -- lr 2.15e-04
2025-03-02 13:49:58,895 - INFO - Step 1434 -- ðŸ”„ Training Metrics
2025-03-02 13:49:58,895 - INFO - â”œâ”€â”€ Loss: 7.4044
2025-03-02 13:49:58,895 - INFO - â”œâ”€â”€ Learning Rate: 2.15e-04
2025-03-02 13:49:58,895 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:49:59,566 - INFO - ðŸªœ Batch step - 1435 -- sub batch step 5740 -- lr 2.15e-04
2025-03-02 13:50:01,715 - INFO - ðŸªœ Batch step - 1435 -- sub batch step 5741 -- lr 2.15e-04
2025-03-02 13:50:04,353 - INFO - ðŸªœ Batch step - 1435 -- sub batch step 5742 -- lr 2.15e-04
2025-03-02 13:50:06,503 - INFO - ðŸªœ Batch step - 1435 -- sub batch step 5743 -- lr 2.15e-04
2025-03-02 13:50:08,088 - INFO - Step 1435 -- ðŸ”„ Training Metrics
2025-03-02 13:50:08,088 - INFO - â”œâ”€â”€ Loss: 7.3887
2025-03-02 13:50:08,088 - INFO - â”œâ”€â”€ Learning Rate: 2.15e-04
2025-03-02 13:50:08,088 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:50:08,763 - INFO - ðŸªœ Batch step - 1436 -- sub batch step 5744 -- lr 2.15e-04
2025-03-02 13:50:10,917 - INFO - ðŸªœ Batch step - 1436 -- sub batch step 5745 -- lr 2.15e-04
2025-03-02 13:50:13,080 - INFO - ðŸªœ Batch step - 1436 -- sub batch step 5746 -- lr 2.15e-04
2025-03-02 13:50:15,234 - INFO - ðŸªœ Batch step - 1436 -- sub batch step 5747 -- lr 2.15e-04
2025-03-02 13:50:16,793 - INFO - Step 1436 -- ðŸ”„ Training Metrics
2025-03-02 13:50:16,793 - INFO - â”œâ”€â”€ Loss: 7.4122
2025-03-02 13:50:16,794 - INFO - â”œâ”€â”€ Learning Rate: 2.15e-04
2025-03-02 13:50:16,794 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:50:17,464 - INFO - ðŸªœ Batch step - 1437 -- sub batch step 5748 -- lr 2.16e-04
2025-03-02 13:50:19,620 - INFO - ðŸªœ Batch step - 1437 -- sub batch step 5749 -- lr 2.16e-04
2025-03-02 13:50:22,037 - INFO - ðŸªœ Batch step - 1437 -- sub batch step 5750 -- lr 2.16e-04
2025-03-02 13:50:24,189 - INFO - ðŸªœ Batch step - 1437 -- sub batch step 5751 -- lr 2.16e-04
2025-03-02 13:50:26,041 - INFO - Step 1437 -- ðŸ”„ Training Metrics
2025-03-02 13:50:26,041 - INFO - â”œâ”€â”€ Loss: 7.3830
2025-03-02 13:50:26,041 - INFO - â”œâ”€â”€ Learning Rate: 2.16e-04
2025-03-02 13:50:26,042 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:50:26,715 - INFO - ðŸªœ Batch step - 1438 -- sub batch step 5752 -- lr 2.16e-04
2025-03-02 13:50:28,864 - INFO - ðŸªœ Batch step - 1438 -- sub batch step 5753 -- lr 2.16e-04
2025-03-02 13:50:31,037 - INFO - ðŸªœ Batch step - 1438 -- sub batch step 5754 -- lr 2.16e-04
2025-03-02 13:50:33,191 - INFO - ðŸªœ Batch step - 1438 -- sub batch step 5755 -- lr 2.16e-04
2025-03-02 13:50:34,750 - INFO - Step 1438 -- ðŸ”„ Training Metrics
2025-03-02 13:50:34,750 - INFO - â”œâ”€â”€ Loss: 7.3977
2025-03-02 13:50:34,751 - INFO - â”œâ”€â”€ Learning Rate: 2.16e-04
2025-03-02 13:50:34,751 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:50:35,417 - INFO - ðŸªœ Batch step - 1439 -- sub batch step 5756 -- lr 2.16e-04
2025-03-02 13:50:37,575 - INFO - ðŸªœ Batch step - 1439 -- sub batch step 5757 -- lr 2.16e-04
2025-03-02 13:50:39,850 - INFO - ðŸªœ Batch step - 1439 -- sub batch step 5758 -- lr 2.16e-04
2025-03-02 13:50:42,004 - INFO - ðŸªœ Batch step - 1439 -- sub batch step 5759 -- lr 2.16e-04
2025-03-02 13:50:43,700 - INFO - Step 1439 -- ðŸ”„ Training Metrics
2025-03-02 13:50:43,701 - INFO - â”œâ”€â”€ Loss: 7.4018
2025-03-02 13:50:43,701 - INFO - â”œâ”€â”€ Learning Rate: 2.16e-04
2025-03-02 13:50:43,701 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:50:45,134 - INFO - ðŸªœ Batch step - 1440 -- sub batch step 5760 -- lr 2.16e-04
2025-03-02 13:50:47,283 - INFO - ðŸªœ Batch step - 1440 -- sub batch step 5761 -- lr 2.16e-04
2025-03-02 13:50:49,436 - INFO - ðŸªœ Batch step - 1440 -- sub batch step 5762 -- lr 2.16e-04
2025-03-02 13:50:51,597 - INFO - ðŸªœ Batch step - 1440 -- sub batch step 5763 -- lr 2.16e-04
2025-03-02 13:50:53,137 - INFO - Step 1440 -- ðŸ”„ Training Metrics
2025-03-02 13:50:53,137 - INFO - â”œâ”€â”€ Loss: 7.4112
2025-03-02 13:50:53,137 - INFO - â”œâ”€â”€ Learning Rate: 2.16e-04
2025-03-02 13:50:53,137 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:50:53,807 - INFO - ðŸªœ Batch step - 1441 -- sub batch step 5764 -- lr 2.16e-04
2025-03-02 13:50:55,961 - INFO - ðŸªœ Batch step - 1441 -- sub batch step 5765 -- lr 2.16e-04
2025-03-02 13:50:58,114 - INFO - ðŸªœ Batch step - 1441 -- sub batch step 5766 -- lr 2.16e-04
2025-03-02 13:51:00,776 - INFO - ðŸªœ Batch step - 1441 -- sub batch step 5767 -- lr 2.16e-04
2025-03-02 13:51:02,320 - INFO - Step 1441 -- ðŸ”„ Training Metrics
2025-03-02 13:51:02,320 - INFO - â”œâ”€â”€ Loss: 7.4131
2025-03-02 13:51:02,320 - INFO - â”œâ”€â”€ Learning Rate: 2.16e-04
2025-03-02 13:51:02,320 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:51:02,989 - INFO - ðŸªœ Batch step - 1442 -- sub batch step 5768 -- lr 2.16e-04
2025-03-02 13:51:05,151 - INFO - ðŸªœ Batch step - 1442 -- sub batch step 5769 -- lr 2.16e-04
2025-03-02 13:51:07,309 - INFO - ðŸªœ Batch step - 1442 -- sub batch step 5770 -- lr 2.16e-04
2025-03-02 13:51:09,473 - INFO - ðŸªœ Batch step - 1442 -- sub batch step 5771 -- lr 2.16e-04
2025-03-02 13:51:11,018 - INFO - Step 1442 -- ðŸ”„ Training Metrics
2025-03-02 13:51:11,019 - INFO - â”œâ”€â”€ Loss: 7.4044
2025-03-02 13:51:11,019 - INFO - â”œâ”€â”€ Learning Rate: 2.16e-04
2025-03-02 13:51:11,019 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:51:11,691 - INFO - ðŸªœ Batch step - 1443 -- sub batch step 5772 -- lr 2.16e-04
2025-03-02 13:51:13,839 - INFO - ðŸªœ Batch step - 1443 -- sub batch step 5773 -- lr 2.16e-04
2025-03-02 13:51:15,999 - INFO - ðŸªœ Batch step - 1443 -- sub batch step 5774 -- lr 2.16e-04
2025-03-02 13:51:18,370 - INFO - ðŸªœ Batch step - 1443 -- sub batch step 5775 -- lr 2.16e-04
2025-03-02 13:51:20,300 - INFO - Step 1443 -- ðŸ”„ Training Metrics
2025-03-02 13:51:20,301 - INFO - â”œâ”€â”€ Loss: 7.3987
2025-03-02 13:51:20,301 - INFO - â”œâ”€â”€ Learning Rate: 2.16e-04
2025-03-02 13:51:20,301 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:51:20,968 - INFO - ðŸªœ Batch step - 1444 -- sub batch step 5776 -- lr 2.17e-04
2025-03-02 13:51:23,121 - INFO - ðŸªœ Batch step - 1444 -- sub batch step 5777 -- lr 2.17e-04
2025-03-02 13:51:25,273 - INFO - ðŸªœ Batch step - 1444 -- sub batch step 5778 -- lr 2.17e-04
2025-03-02 13:51:27,450 - INFO - ðŸªœ Batch step - 1444 -- sub batch step 5779 -- lr 2.17e-04
2025-03-02 13:51:28,997 - INFO - Step 1444 -- ðŸ”„ Training Metrics
2025-03-02 13:51:28,997 - INFO - â”œâ”€â”€ Loss: 7.3880
2025-03-02 13:51:28,997 - INFO - â”œâ”€â”€ Learning Rate: 2.17e-04
2025-03-02 13:51:28,997 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:51:29,669 - INFO - ðŸªœ Batch step - 1445 -- sub batch step 5780 -- lr 2.17e-04
2025-03-02 13:51:31,819 - INFO - ðŸªœ Batch step - 1445 -- sub batch step 5781 -- lr 2.17e-04
2025-03-02 13:51:33,973 - INFO - ðŸªœ Batch step - 1445 -- sub batch step 5782 -- lr 2.17e-04
2025-03-02 13:51:36,438 - INFO - ðŸªœ Batch step - 1445 -- sub batch step 5783 -- lr 2.17e-04
2025-03-02 13:51:38,192 - INFO - Step 1445 -- ðŸ”„ Training Metrics
2025-03-02 13:51:38,192 - INFO - â”œâ”€â”€ Loss: 7.3870
2025-03-02 13:51:38,192 - INFO - â”œâ”€â”€ Learning Rate: 2.17e-04
2025-03-02 13:51:38,193 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:51:38,864 - INFO - ðŸªœ Batch step - 1446 -- sub batch step 5784 -- lr 2.17e-04
2025-03-02 13:51:41,024 - INFO - ðŸªœ Batch step - 1446 -- sub batch step 5785 -- lr 2.17e-04
2025-03-02 13:51:43,172 - INFO - ðŸªœ Batch step - 1446 -- sub batch step 5786 -- lr 2.17e-04
2025-03-02 13:51:45,339 - INFO - ðŸªœ Batch step - 1446 -- sub batch step 5787 -- lr 2.17e-04
2025-03-02 13:51:46,895 - INFO - Step 1446 -- ðŸ”„ Training Metrics
2025-03-02 13:51:46,895 - INFO - â”œâ”€â”€ Loss: 7.3992
2025-03-02 13:51:46,895 - INFO - â”œâ”€â”€ Learning Rate: 2.17e-04
2025-03-02 13:51:46,895 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:51:47,563 - INFO - ðŸªœ Batch step - 1447 -- sub batch step 5788 -- lr 2.17e-04
2025-03-02 13:51:49,719 - INFO - ðŸªœ Batch step - 1447 -- sub batch step 5789 -- lr 2.17e-04
2025-03-02 13:51:51,876 - INFO - ðŸªœ Batch step - 1447 -- sub batch step 5790 -- lr 2.17e-04
2025-03-02 13:51:54,247 - INFO - ðŸªœ Batch step - 1447 -- sub batch step 5791 -- lr 2.17e-04
2025-03-02 13:51:56,155 - INFO - Step 1447 -- ðŸ”„ Training Metrics
2025-03-02 13:51:56,155 - INFO - â”œâ”€â”€ Loss: 7.3882
2025-03-02 13:51:56,155 - INFO - â”œâ”€â”€ Learning Rate: 2.17e-04
2025-03-02 13:51:56,155 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:51:56,826 - INFO - ðŸªœ Batch step - 1448 -- sub batch step 5792 -- lr 2.17e-04
2025-03-02 13:51:58,975 - INFO - ðŸªœ Batch step - 1448 -- sub batch step 5793 -- lr 2.17e-04
2025-03-02 13:52:01,154 - INFO - ðŸªœ Batch step - 1448 -- sub batch step 5794 -- lr 2.17e-04
2025-03-02 13:52:03,330 - INFO - ðŸªœ Batch step - 1448 -- sub batch step 5795 -- lr 2.17e-04
2025-03-02 13:52:04,858 - INFO - Step 1448 -- ðŸ”„ Training Metrics
2025-03-02 13:52:04,858 - INFO - â”œâ”€â”€ Loss: 7.4182
2025-03-02 13:52:04,859 - INFO - â”œâ”€â”€ Learning Rate: 2.17e-04
2025-03-02 13:52:04,859 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:52:05,528 - INFO - ðŸªœ Batch step - 1449 -- sub batch step 5796 -- lr 2.17e-04
2025-03-02 13:52:07,686 - INFO - ðŸªœ Batch step - 1449 -- sub batch step 5797 -- lr 2.17e-04
2025-03-02 13:52:09,833 - INFO - ðŸªœ Batch step - 1449 -- sub batch step 5798 -- lr 2.17e-04
2025-03-02 13:52:12,419 - INFO - ðŸªœ Batch step - 1449 -- sub batch step 5799 -- lr 2.17e-04
2025-03-02 13:52:14,165 - INFO - Step 1449 -- ðŸ”„ Training Metrics
2025-03-02 13:52:14,166 - INFO - â”œâ”€â”€ Loss: 7.3879
2025-03-02 13:52:14,166 - INFO - â”œâ”€â”€ Learning Rate: 2.17e-04
2025-03-02 13:52:14,166 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:52:14,838 - INFO - ðŸªœ Batch step - 1450 -- sub batch step 5800 -- lr 2.17e-04
2025-03-02 13:52:16,992 - INFO - ðŸªœ Batch step - 1450 -- sub batch step 5801 -- lr 2.17e-04
2025-03-02 13:52:19,148 - INFO - ðŸªœ Batch step - 1450 -- sub batch step 5802 -- lr 2.17e-04
2025-03-02 13:52:21,309 - INFO - ðŸªœ Batch step - 1450 -- sub batch step 5803 -- lr 2.17e-04
2025-03-02 13:52:22,844 - INFO - Step 1450 -- ðŸ”„ Training Metrics
2025-03-02 13:52:22,844 - INFO - â”œâ”€â”€ Loss: 7.4086
2025-03-02 13:52:22,844 - INFO - â”œâ”€â”€ Learning Rate: 2.17e-04
2025-03-02 13:52:22,844 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:52:23,519 - INFO - ðŸªœ Batch step - 1451 -- sub batch step 5804 -- lr 2.18e-04
2025-03-02 13:52:25,671 - INFO - ðŸªœ Batch step - 1451 -- sub batch step 5805 -- lr 2.18e-04
2025-03-02 13:52:28,335 - INFO - ðŸªœ Batch step - 1451 -- sub batch step 5806 -- lr 2.18e-04
2025-03-02 13:52:30,489 - INFO - ðŸªœ Batch step - 1451 -- sub batch step 5807 -- lr 2.18e-04
2025-03-02 13:52:32,056 - INFO - Step 1451 -- ðŸ”„ Training Metrics
2025-03-02 13:52:32,057 - INFO - â”œâ”€â”€ Loss: 7.3784
2025-03-02 13:52:32,057 - INFO - â”œâ”€â”€ Learning Rate: 2.18e-04
2025-03-02 13:52:32,057 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:52:32,724 - INFO - ðŸªœ Batch step - 1452 -- sub batch step 5808 -- lr 2.18e-04
2025-03-02 13:52:34,878 - INFO - ðŸªœ Batch step - 1452 -- sub batch step 5809 -- lr 2.18e-04
2025-03-02 13:52:37,048 - INFO - ðŸªœ Batch step - 1452 -- sub batch step 5810 -- lr 2.18e-04
2025-03-02 13:52:39,199 - INFO - ðŸªœ Batch step - 1452 -- sub batch step 5811 -- lr 2.18e-04
2025-03-02 13:52:40,747 - INFO - Step 1452 -- ðŸ”„ Training Metrics
2025-03-02 13:52:40,748 - INFO - â”œâ”€â”€ Loss: 7.4162
2025-03-02 13:52:40,748 - INFO - â”œâ”€â”€ Learning Rate: 2.18e-04
2025-03-02 13:52:40,748 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:52:41,422 - INFO - ðŸªœ Batch step - 1453 -- sub batch step 5812 -- lr 2.18e-04
2025-03-02 13:52:43,572 - INFO - ðŸªœ Batch step - 1453 -- sub batch step 5813 -- lr 2.18e-04
2025-03-02 13:52:46,164 - INFO - ðŸªœ Batch step - 1453 -- sub batch step 5814 -- lr 2.18e-04
2025-03-02 13:52:48,322 - INFO - ðŸªœ Batch step - 1453 -- sub batch step 5815 -- lr 2.18e-04
2025-03-02 13:52:50,069 - INFO - Step 1453 -- ðŸ”„ Training Metrics
2025-03-02 13:52:50,069 - INFO - â”œâ”€â”€ Loss: 7.3823
2025-03-02 13:52:50,069 - INFO - â”œâ”€â”€ Learning Rate: 2.18e-04
2025-03-02 13:52:50,069 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:52:50,736 - INFO - ðŸªœ Batch step - 1454 -- sub batch step 5816 -- lr 2.18e-04
2025-03-02 13:52:52,892 - INFO - ðŸªœ Batch step - 1454 -- sub batch step 5817 -- lr 2.18e-04
2025-03-02 13:52:55,057 - INFO - ðŸªœ Batch step - 1454 -- sub batch step 5818 -- lr 2.18e-04
2025-03-02 13:52:57,215 - INFO - ðŸªœ Batch step - 1454 -- sub batch step 5819 -- lr 2.18e-04
2025-03-02 13:52:58,764 - INFO - Step 1454 -- ðŸ”„ Training Metrics
2025-03-02 13:52:58,764 - INFO - â”œâ”€â”€ Loss: 7.3939
2025-03-02 13:52:58,764 - INFO - â”œâ”€â”€ Learning Rate: 2.18e-04
2025-03-02 13:52:58,765 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:52:59,443 - INFO - ðŸªœ Batch step - 1455 -- sub batch step 5820 -- lr 2.18e-04
2025-03-02 13:53:01,593 - INFO - ðŸªœ Batch step - 1455 -- sub batch step 5821 -- lr 2.18e-04
2025-03-02 13:53:04,266 - INFO - ðŸªœ Batch step - 1455 -- sub batch step 5822 -- lr 2.18e-04
2025-03-02 13:53:06,414 - INFO - ðŸªœ Batch step - 1455 -- sub batch step 5823 -- lr 2.18e-04
2025-03-02 13:53:07,997 - INFO - Step 1455 -- ðŸ”„ Training Metrics
2025-03-02 13:53:07,998 - INFO - â”œâ”€â”€ Loss: 7.3992
2025-03-02 13:53:07,998 - INFO - â”œâ”€â”€ Learning Rate: 2.18e-04
2025-03-02 13:53:07,998 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:53:08,675 - INFO - ðŸªœ Batch step - 1456 -- sub batch step 5824 -- lr 2.18e-04
2025-03-02 13:53:10,827 - INFO - ðŸªœ Batch step - 1456 -- sub batch step 5825 -- lr 2.18e-04
2025-03-02 13:53:12,988 - INFO - ðŸªœ Batch step - 1456 -- sub batch step 5826 -- lr 2.18e-04
2025-03-02 13:53:15,142 - INFO - ðŸªœ Batch step - 1456 -- sub batch step 5827 -- lr 2.18e-04
2025-03-02 13:53:16,694 - INFO - Step 1456 -- ðŸ”„ Training Metrics
2025-03-02 13:53:16,694 - INFO - â”œâ”€â”€ Loss: 7.4050
2025-03-02 13:53:16,694 - INFO - â”œâ”€â”€ Learning Rate: 2.18e-04
2025-03-02 13:53:16,694 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:53:17,361 - INFO - ðŸªœ Batch step - 1457 -- sub batch step 5828 -- lr 2.19e-04
2025-03-02 13:53:19,517 - INFO - ðŸªœ Batch step - 1457 -- sub batch step 5829 -- lr 2.19e-04
2025-03-02 13:53:22,119 - INFO - ðŸªœ Batch step - 1457 -- sub batch step 5830 -- lr 2.19e-04
2025-03-02 13:53:24,271 - INFO - ðŸªœ Batch step - 1457 -- sub batch step 5831 -- lr 2.19e-04
2025-03-02 13:53:26,013 - INFO - Step 1457 -- ðŸ”„ Training Metrics
2025-03-02 13:53:26,013 - INFO - â”œâ”€â”€ Loss: 7.3580
2025-03-02 13:53:26,013 - INFO - â”œâ”€â”€ Learning Rate: 2.19e-04
2025-03-02 13:53:26,013 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:53:26,693 - INFO - ðŸªœ Batch step - 1458 -- sub batch step 5832 -- lr 2.19e-04
2025-03-02 13:53:28,842 - INFO - ðŸªœ Batch step - 1458 -- sub batch step 5833 -- lr 2.19e-04
2025-03-02 13:53:31,010 - INFO - ðŸªœ Batch step - 1458 -- sub batch step 5834 -- lr 2.19e-04
2025-03-02 13:53:33,163 - INFO - ðŸªœ Batch step - 1458 -- sub batch step 5835 -- lr 2.19e-04
2025-03-02 13:53:34,712 - INFO - Step 1458 -- ðŸ”„ Training Metrics
2025-03-02 13:53:34,712 - INFO - â”œâ”€â”€ Loss: 7.3980
2025-03-02 13:53:34,712 - INFO - â”œâ”€â”€ Learning Rate: 2.19e-04
2025-03-02 13:53:34,713 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:53:35,379 - INFO - ðŸªœ Batch step - 1459 -- sub batch step 5836 -- lr 2.19e-04
2025-03-02 13:53:37,533 - INFO - ðŸªœ Batch step - 1459 -- sub batch step 5837 -- lr 2.19e-04
2025-03-02 13:53:39,805 - INFO - ðŸªœ Batch step - 1459 -- sub batch step 5838 -- lr 2.19e-04
2025-03-02 13:53:41,965 - INFO - ðŸªœ Batch step - 1459 -- sub batch step 5839 -- lr 2.19e-04
2025-03-02 13:53:43,673 - INFO - Step 1459 -- ðŸ”„ Training Metrics
2025-03-02 13:53:43,673 - INFO - â”œâ”€â”€ Loss: 7.3853
2025-03-02 13:53:43,673 - INFO - â”œâ”€â”€ Learning Rate: 2.19e-04
2025-03-02 13:53:43,673 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:53:45,028 - INFO - ðŸªœ Batch step - 1460 -- sub batch step 5840 -- lr 2.19e-04
2025-03-02 13:53:47,181 - INFO - ðŸªœ Batch step - 1460 -- sub batch step 5841 -- lr 2.19e-04
2025-03-02 13:53:49,343 - INFO - ðŸªœ Batch step - 1460 -- sub batch step 5842 -- lr 2.19e-04
2025-03-02 13:53:51,515 - INFO - ðŸªœ Batch step - 1460 -- sub batch step 5843 -- lr 2.19e-04
2025-03-02 13:53:53,005 - INFO - Step 1460 -- ðŸ”„ Training Metrics
2025-03-02 13:53:53,006 - INFO - â”œâ”€â”€ Loss: 7.3744
2025-03-02 13:53:53,006 - INFO - â”œâ”€â”€ Learning Rate: 2.19e-04
2025-03-02 13:53:53,006 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:53:53,680 - INFO - ðŸªœ Batch step - 1461 -- sub batch step 5844 -- lr 2.19e-04
2025-03-02 13:53:55,838 - INFO - ðŸªœ Batch step - 1461 -- sub batch step 5845 -- lr 2.19e-04
2025-03-02 13:53:57,988 - INFO - ðŸªœ Batch step - 1461 -- sub batch step 5846 -- lr 2.19e-04
2025-03-02 13:54:00,448 - INFO - ðŸªœ Batch step - 1461 -- sub batch step 5847 -- lr 2.19e-04
2025-03-02 13:54:02,181 - INFO - Step 1461 -- ðŸ”„ Training Metrics
2025-03-02 13:54:02,181 - INFO - â”œâ”€â”€ Loss: 7.3790
2025-03-02 13:54:02,181 - INFO - â”œâ”€â”€ Learning Rate: 2.19e-04
2025-03-02 13:54:02,181 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:54:02,847 - INFO - ðŸªœ Batch step - 1462 -- sub batch step 5848 -- lr 2.19e-04
2025-03-02 13:54:05,005 - INFO - ðŸªœ Batch step - 1462 -- sub batch step 5849 -- lr 2.19e-04
2025-03-02 13:54:07,164 - INFO - ðŸªœ Batch step - 1462 -- sub batch step 5850 -- lr 2.19e-04
2025-03-02 13:54:09,322 - INFO - ðŸªœ Batch step - 1462 -- sub batch step 5851 -- lr 2.19e-04
2025-03-02 13:54:10,876 - INFO - Step 1462 -- ðŸ”„ Training Metrics
2025-03-02 13:54:10,876 - INFO - â”œâ”€â”€ Loss: 7.3775
2025-03-02 13:54:10,876 - INFO - â”œâ”€â”€ Learning Rate: 2.19e-04
2025-03-02 13:54:10,877 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:54:11,552 - INFO - ðŸªœ Batch step - 1463 -- sub batch step 5852 -- lr 2.19e-04
2025-03-02 13:54:13,703 - INFO - ðŸªœ Batch step - 1463 -- sub batch step 5853 -- lr 2.19e-04
2025-03-02 13:54:15,860 - INFO - ðŸªœ Batch step - 1463 -- sub batch step 5854 -- lr 2.19e-04
2025-03-02 13:54:18,324 - INFO - ðŸªœ Batch step - 1463 -- sub batch step 5855 -- lr 2.19e-04
2025-03-02 13:54:20,138 - INFO - Step 1463 -- ðŸ”„ Training Metrics
2025-03-02 13:54:20,139 - INFO - â”œâ”€â”€ Loss: 7.3968
2025-03-02 13:54:20,139 - INFO - â”œâ”€â”€ Learning Rate: 2.19e-04
2025-03-02 13:54:20,139 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:54:20,809 - INFO - ðŸªœ Batch step - 1464 -- sub batch step 5856 -- lr 2.20e-04
2025-03-02 13:54:22,970 - INFO - ðŸªœ Batch step - 1464 -- sub batch step 5857 -- lr 2.20e-04
2025-03-02 13:54:25,117 - INFO - ðŸªœ Batch step - 1464 -- sub batch step 5858 -- lr 2.20e-04
2025-03-02 13:54:27,297 - INFO - ðŸªœ Batch step - 1464 -- sub batch step 5859 -- lr 2.20e-04
2025-03-02 13:54:28,832 - INFO - Step 1464 -- ðŸ”„ Training Metrics
2025-03-02 13:54:28,832 - INFO - â”œâ”€â”€ Loss: 7.4004
2025-03-02 13:54:28,832 - INFO - â”œâ”€â”€ Learning Rate: 2.20e-04
2025-03-02 13:54:28,832 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:54:29,505 - INFO - ðŸªœ Batch step - 1465 -- sub batch step 5860 -- lr 2.20e-04
2025-03-02 13:54:31,659 - INFO - ðŸªœ Batch step - 1465 -- sub batch step 5861 -- lr 2.20e-04
2025-03-02 13:54:33,811 - INFO - ðŸªœ Batch step - 1465 -- sub batch step 5862 -- lr 2.20e-04
2025-03-02 13:54:36,539 - INFO - ðŸªœ Batch step - 1465 -- sub batch step 5863 -- lr 2.20e-04
2025-03-02 13:54:38,145 - INFO - Step 1465 -- ðŸ”„ Training Metrics
2025-03-02 13:54:38,146 - INFO - â”œâ”€â”€ Loss: 7.3840
2025-03-02 13:54:38,146 - INFO - â”œâ”€â”€ Learning Rate: 2.20e-04
2025-03-02 13:54:38,146 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:54:38,828 - INFO - ðŸªœ Batch step - 1466 -- sub batch step 5864 -- lr 2.20e-04
2025-03-02 13:54:40,987 - INFO - ðŸªœ Batch step - 1466 -- sub batch step 5865 -- lr 2.20e-04
2025-03-02 13:54:43,141 - INFO - ðŸªœ Batch step - 1466 -- sub batch step 5866 -- lr 2.20e-04
2025-03-02 13:54:45,319 - INFO - ðŸªœ Batch step - 1466 -- sub batch step 5867 -- lr 2.20e-04
2025-03-02 13:54:46,840 - INFO - Step 1466 -- ðŸ”„ Training Metrics
2025-03-02 13:54:46,840 - INFO - â”œâ”€â”€ Loss: 7.4046
2025-03-02 13:54:46,840 - INFO - â”œâ”€â”€ Learning Rate: 2.20e-04
2025-03-02 13:54:46,840 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:54:47,510 - INFO - ðŸªœ Batch step - 1467 -- sub batch step 5868 -- lr 2.20e-04
2025-03-02 13:54:49,670 - INFO - ðŸªœ Batch step - 1467 -- sub batch step 5869 -- lr 2.20e-04
2025-03-02 13:54:51,826 - INFO - ðŸªœ Batch step - 1467 -- sub batch step 5870 -- lr 2.20e-04
2025-03-02 13:54:55,241 - INFO - ðŸªœ Batch step - 1467 -- sub batch step 5871 -- lr 2.20e-04
2025-03-02 13:54:56,732 - INFO - Step 1467 -- ðŸ”„ Training Metrics
2025-03-02 13:54:56,732 - INFO - â”œâ”€â”€ Loss: 7.4042
2025-03-02 13:54:56,732 - INFO - â”œâ”€â”€ Learning Rate: 2.20e-04
2025-03-02 13:54:56,732 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:54:57,406 - INFO - ðŸªœ Batch step - 1468 -- sub batch step 5872 -- lr 2.20e-04
2025-03-02 13:54:59,558 - INFO - ðŸªœ Batch step - 1468 -- sub batch step 5873 -- lr 2.20e-04
2025-03-02 13:55:01,712 - INFO - ðŸªœ Batch step - 1468 -- sub batch step 5874 -- lr 2.20e-04
2025-03-02 13:55:03,887 - INFO - ðŸªœ Batch step - 1468 -- sub batch step 5875 -- lr 2.20e-04
2025-03-02 13:55:05,429 - INFO - Step 1468 -- ðŸ”„ Training Metrics
2025-03-02 13:55:05,429 - INFO - â”œâ”€â”€ Loss: 7.3931
2025-03-02 13:55:05,430 - INFO - â”œâ”€â”€ Learning Rate: 2.20e-04
2025-03-02 13:55:05,430 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:55:06,096 - INFO - ðŸªœ Batch step - 1469 -- sub batch step 5876 -- lr 2.20e-04
2025-03-02 13:55:08,250 - INFO - ðŸªœ Batch step - 1469 -- sub batch step 5877 -- lr 2.20e-04
2025-03-02 13:55:10,398 - INFO - ðŸªœ Batch step - 1469 -- sub batch step 5878 -- lr 2.20e-04
2025-03-02 13:55:13,026 - INFO - ðŸªœ Batch step - 1469 -- sub batch step 5879 -- lr 2.20e-04
2025-03-02 13:55:14,632 - INFO - Step 1469 -- ðŸ”„ Training Metrics
2025-03-02 13:55:14,632 - INFO - â”œâ”€â”€ Loss: 7.3873
2025-03-02 13:55:14,632 - INFO - â”œâ”€â”€ Learning Rate: 2.20e-04
2025-03-02 13:55:14,633 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:55:15,306 - INFO - ðŸªœ Batch step - 1470 -- sub batch step 5880 -- lr 2.20e-04
2025-03-02 13:55:17,462 - INFO - ðŸªœ Batch step - 1470 -- sub batch step 5881 -- lr 2.20e-04
2025-03-02 13:55:19,616 - INFO - ðŸªœ Batch step - 1470 -- sub batch step 5882 -- lr 2.20e-04
2025-03-02 13:55:21,783 - INFO - ðŸªœ Batch step - 1470 -- sub batch step 5883 -- lr 2.20e-04
2025-03-02 13:55:23,319 - INFO - Step 1470 -- ðŸ”„ Training Metrics
2025-03-02 13:55:23,319 - INFO - â”œâ”€â”€ Loss: 7.4100
2025-03-02 13:55:23,319 - INFO - â”œâ”€â”€ Learning Rate: 2.20e-04
2025-03-02 13:55:23,319 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:55:23,996 - INFO - ðŸªœ Batch step - 1471 -- sub batch step 5884 -- lr 2.21e-04
2025-03-02 13:55:26,150 - INFO - ðŸªœ Batch step - 1471 -- sub batch step 5885 -- lr 2.21e-04
2025-03-02 13:55:28,823 - INFO - ðŸªœ Batch step - 1471 -- sub batch step 5886 -- lr 2.21e-04
2025-03-02 13:55:30,976 - INFO - ðŸªœ Batch step - 1471 -- sub batch step 5887 -- lr 2.21e-04
2025-03-02 13:55:32,508 - INFO - Step 1471 -- ðŸ”„ Training Metrics
2025-03-02 13:55:32,509 - INFO - â”œâ”€â”€ Loss: 7.3842
2025-03-02 13:55:32,509 - INFO - â”œâ”€â”€ Learning Rate: 2.21e-04
2025-03-02 13:55:32,509 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:55:33,177 - INFO - ðŸªœ Batch step - 1472 -- sub batch step 5888 -- lr 2.21e-04
2025-03-02 13:55:35,333 - INFO - ðŸªœ Batch step - 1472 -- sub batch step 5889 -- lr 2.21e-04
2025-03-02 13:55:37,511 - INFO - ðŸªœ Batch step - 1472 -- sub batch step 5890 -- lr 2.21e-04
2025-03-02 13:55:39,662 - INFO - ðŸªœ Batch step - 1472 -- sub batch step 5891 -- lr 2.21e-04
2025-03-02 13:55:41,204 - INFO - Step 1472 -- ðŸ”„ Training Metrics
2025-03-02 13:55:41,204 - INFO - â”œâ”€â”€ Loss: 7.3643
2025-03-02 13:55:41,204 - INFO - â”œâ”€â”€ Learning Rate: 2.21e-04
2025-03-02 13:55:41,205 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:55:41,877 - INFO - ðŸªœ Batch step - 1473 -- sub batch step 5892 -- lr 2.21e-04
2025-03-02 13:55:44,026 - INFO - ðŸªœ Batch step - 1473 -- sub batch step 5893 -- lr 2.21e-04
2025-03-02 13:55:46,719 - INFO - ðŸªœ Batch step - 1473 -- sub batch step 5894 -- lr 2.21e-04
2025-03-02 13:55:48,878 - INFO - ðŸªœ Batch step - 1473 -- sub batch step 5895 -- lr 2.21e-04
2025-03-02 13:55:50,373 - INFO - Step 1473 -- ðŸ”„ Training Metrics
2025-03-02 13:55:50,374 - INFO - â”œâ”€â”€ Loss: 7.3693
2025-03-02 13:55:50,374 - INFO - â”œâ”€â”€ Learning Rate: 2.21e-04
2025-03-02 13:55:50,374 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:55:51,048 - INFO - ðŸªœ Batch step - 1474 -- sub batch step 5896 -- lr 2.21e-04
2025-03-02 13:55:53,205 - INFO - ðŸªœ Batch step - 1474 -- sub batch step 5897 -- lr 2.21e-04
2025-03-02 13:55:55,374 - INFO - ðŸªœ Batch step - 1474 -- sub batch step 5898 -- lr 2.21e-04
2025-03-02 13:55:57,528 - INFO - ðŸªœ Batch step - 1474 -- sub batch step 5899 -- lr 2.21e-04
2025-03-02 13:55:59,075 - INFO - Step 1474 -- ðŸ”„ Training Metrics
2025-03-02 13:55:59,075 - INFO - â”œâ”€â”€ Loss: 7.3544
2025-03-02 13:55:59,075 - INFO - â”œâ”€â”€ Learning Rate: 2.21e-04
2025-03-02 13:55:59,075 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:55:59,749 - INFO - ðŸªœ Batch step - 1475 -- sub batch step 5900 -- lr 2.21e-04
2025-03-02 13:56:01,904 - INFO - ðŸªœ Batch step - 1475 -- sub batch step 5901 -- lr 2.21e-04
2025-03-02 13:56:04,366 - INFO - ðŸªœ Batch step - 1475 -- sub batch step 5902 -- lr 2.21e-04
2025-03-02 13:56:06,517 - INFO - ðŸªœ Batch step - 1475 -- sub batch step 5903 -- lr 2.21e-04
2025-03-02 13:56:08,241 - INFO - Step 1475 -- ðŸ”„ Training Metrics
2025-03-02 13:56:08,241 - INFO - â”œâ”€â”€ Loss: 7.3704
2025-03-02 13:56:08,242 - INFO - â”œâ”€â”€ Learning Rate: 2.21e-04
2025-03-02 13:56:08,242 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:56:08,919 - INFO - ðŸªœ Batch step - 1476 -- sub batch step 5904 -- lr 2.21e-04
2025-03-02 13:56:11,073 - INFO - ðŸªœ Batch step - 1476 -- sub batch step 5905 -- lr 2.21e-04
2025-03-02 13:56:13,239 - INFO - ðŸªœ Batch step - 1476 -- sub batch step 5906 -- lr 2.21e-04
2025-03-02 13:56:15,397 - INFO - ðŸªœ Batch step - 1476 -- sub batch step 5907 -- lr 2.21e-04
2025-03-02 13:56:16,938 - INFO - Step 1476 -- ðŸ”„ Training Metrics
2025-03-02 13:56:16,938 - INFO - â”œâ”€â”€ Loss: 7.3926
2025-03-02 13:56:16,938 - INFO - â”œâ”€â”€ Learning Rate: 2.21e-04
2025-03-02 13:56:16,938 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:56:17,605 - INFO - ðŸªœ Batch step - 1477 -- sub batch step 5908 -- lr 2.22e-04
2025-03-02 13:56:19,764 - INFO - ðŸªœ Batch step - 1477 -- sub batch step 5909 -- lr 2.22e-04
2025-03-02 13:56:22,784 - INFO - ðŸªœ Batch step - 1477 -- sub batch step 5910 -- lr 2.22e-04
2025-03-02 13:56:24,940 - INFO - ðŸªœ Batch step - 1477 -- sub batch step 5911 -- lr 2.22e-04
2025-03-02 13:56:26,431 - INFO - Step 1477 -- ðŸ”„ Training Metrics
2025-03-02 13:56:26,431 - INFO - â”œâ”€â”€ Loss: 7.3789
2025-03-02 13:56:26,431 - INFO - â”œâ”€â”€ Learning Rate: 2.22e-04
2025-03-02 13:56:26,431 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:56:27,103 - INFO - ðŸªœ Batch step - 1478 -- sub batch step 5912 -- lr 2.22e-04
2025-03-02 13:56:29,253 - INFO - ðŸªœ Batch step - 1478 -- sub batch step 5913 -- lr 2.22e-04
2025-03-02 13:56:31,427 - INFO - ðŸªœ Batch step - 1478 -- sub batch step 5914 -- lr 2.22e-04
2025-03-02 13:56:33,584 - INFO - ðŸªœ Batch step - 1478 -- sub batch step 5915 -- lr 2.22e-04
2025-03-02 13:56:35,132 - INFO - Step 1478 -- ðŸ”„ Training Metrics
2025-03-02 13:56:35,132 - INFO - â”œâ”€â”€ Loss: 7.3543
2025-03-02 13:56:35,132 - INFO - â”œâ”€â”€ Learning Rate: 2.22e-04
2025-03-02 13:56:35,132 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:56:35,800 - INFO - ðŸªœ Batch step - 1479 -- sub batch step 5916 -- lr 2.22e-04
2025-03-02 13:56:37,960 - INFO - ðŸªœ Batch step - 1479 -- sub batch step 5917 -- lr 2.22e-04
2025-03-02 13:56:40,236 - INFO - ðŸªœ Batch step - 1479 -- sub batch step 5918 -- lr 2.22e-04
2025-03-02 13:56:42,400 - INFO - ðŸªœ Batch step - 1479 -- sub batch step 5919 -- lr 2.22e-04
2025-03-02 13:56:43,983 - INFO - Step 1479 -- ðŸ”„ Training Metrics
2025-03-02 13:56:43,983 - INFO - â”œâ”€â”€ Loss: 7.3571
2025-03-02 13:56:43,983 - INFO - â”œâ”€â”€ Learning Rate: 2.22e-04
2025-03-02 13:56:43,983 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:56:45,220 - INFO - ðŸªœ Batch step - 1480 -- sub batch step 5920 -- lr 2.22e-04
2025-03-02 13:56:47,373 - INFO - ðŸªœ Batch step - 1480 -- sub batch step 5921 -- lr 2.22e-04
2025-03-02 13:56:49,535 - INFO - ðŸªœ Batch step - 1480 -- sub batch step 5922 -- lr 2.22e-04
2025-03-02 13:56:51,700 - INFO - ðŸªœ Batch step - 1480 -- sub batch step 5923 -- lr 2.22e-04
2025-03-02 13:56:53,316 - INFO - Step 1480 -- ðŸ”„ Training Metrics
2025-03-02 13:56:53,317 - INFO - â”œâ”€â”€ Loss: 7.3752
2025-03-02 13:56:53,317 - INFO - â”œâ”€â”€ Learning Rate: 2.22e-04
2025-03-02 13:56:53,317 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:56:53,992 - INFO - ðŸªœ Batch step - 1481 -- sub batch step 5924 -- lr 2.22e-04
2025-03-02 13:56:56,148 - INFO - ðŸªœ Batch step - 1481 -- sub batch step 5925 -- lr 2.22e-04
2025-03-02 13:56:58,296 - INFO - ðŸªœ Batch step - 1481 -- sub batch step 5926 -- lr 2.22e-04
2025-03-02 13:57:00,649 - INFO - ðŸªœ Batch step - 1481 -- sub batch step 5927 -- lr 2.22e-04
2025-03-02 13:57:02,403 - INFO - Step 1481 -- ðŸ”„ Training Metrics
2025-03-02 13:57:02,403 - INFO - â”œâ”€â”€ Loss: 7.3829
2025-03-02 13:57:02,403 - INFO - â”œâ”€â”€ Learning Rate: 2.22e-04
2025-03-02 13:57:02,403 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:57:03,070 - INFO - ðŸªœ Batch step - 1482 -- sub batch step 5928 -- lr 2.22e-04
2025-03-02 13:57:05,234 - INFO - ðŸªœ Batch step - 1482 -- sub batch step 5929 -- lr 2.22e-04
2025-03-02 13:57:07,390 - INFO - ðŸªœ Batch step - 1482 -- sub batch step 5930 -- lr 2.22e-04
2025-03-02 13:57:09,560 - INFO - ðŸªœ Batch step - 1482 -- sub batch step 5931 -- lr 2.22e-04
2025-03-02 13:57:11,091 - INFO - Step 1482 -- ðŸ”„ Training Metrics
2025-03-02 13:57:11,091 - INFO - â”œâ”€â”€ Loss: 7.3772
2025-03-02 13:57:11,091 - INFO - â”œâ”€â”€ Learning Rate: 2.22e-04
2025-03-02 13:57:11,092 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:57:11,768 - INFO - ðŸªœ Batch step - 1483 -- sub batch step 5932 -- lr 2.22e-04
2025-03-02 13:57:13,923 - INFO - ðŸªœ Batch step - 1483 -- sub batch step 5933 -- lr 2.22e-04
2025-03-02 13:57:16,081 - INFO - ðŸªœ Batch step - 1483 -- sub batch step 5934 -- lr 2.22e-04
2025-03-02 13:57:18,759 - INFO - ðŸªœ Batch step - 1483 -- sub batch step 5935 -- lr 2.22e-04
2025-03-02 13:57:20,327 - INFO - Step 1483 -- ðŸ”„ Training Metrics
2025-03-02 13:57:20,327 - INFO - â”œâ”€â”€ Loss: 7.3738
2025-03-02 13:57:20,327 - INFO - â”œâ”€â”€ Learning Rate: 2.22e-04
2025-03-02 13:57:20,327 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:57:20,996 - INFO - ðŸªœ Batch step - 1484 -- sub batch step 5936 -- lr 2.23e-04
2025-03-02 13:57:23,157 - INFO - ðŸªœ Batch step - 1484 -- sub batch step 5937 -- lr 2.23e-04
2025-03-02 13:57:25,308 - INFO - ðŸªœ Batch step - 1484 -- sub batch step 5938 -- lr 2.23e-04
2025-03-02 13:57:27,477 - INFO - ðŸªœ Batch step - 1484 -- sub batch step 5939 -- lr 2.23e-04
2025-03-02 13:57:29,033 - INFO - Step 1484 -- ðŸ”„ Training Metrics
2025-03-02 13:57:29,033 - INFO - â”œâ”€â”€ Loss: 7.3644
2025-03-02 13:57:29,033 - INFO - â”œâ”€â”€ Learning Rate: 2.23e-04
2025-03-02 13:57:29,034 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:57:29,706 - INFO - ðŸªœ Batch step - 1485 -- sub batch step 5940 -- lr 2.23e-04
2025-03-02 13:57:31,855 - INFO - ðŸªœ Batch step - 1485 -- sub batch step 5941 -- lr 2.23e-04
2025-03-02 13:57:34,014 - INFO - ðŸªœ Batch step - 1485 -- sub batch step 5942 -- lr 2.23e-04
2025-03-02 13:57:36,383 - INFO - ðŸªœ Batch step - 1485 -- sub batch step 5943 -- lr 2.23e-04
2025-03-02 13:57:38,274 - INFO - Step 1485 -- ðŸ”„ Training Metrics
2025-03-02 13:57:38,274 - INFO - â”œâ”€â”€ Loss: 7.3869
2025-03-02 13:57:38,274 - INFO - â”œâ”€â”€ Learning Rate: 2.23e-04
2025-03-02 13:57:38,274 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:57:38,950 - INFO - ðŸªœ Batch step - 1486 -- sub batch step 5944 -- lr 2.23e-04
2025-03-02 13:57:41,106 - INFO - ðŸªœ Batch step - 1486 -- sub batch step 5945 -- lr 2.23e-04
2025-03-02 13:57:43,255 - INFO - ðŸªœ Batch step - 1486 -- sub batch step 5946 -- lr 2.23e-04
2025-03-02 13:57:45,433 - INFO - ðŸªœ Batch step - 1486 -- sub batch step 5947 -- lr 2.23e-04
2025-03-02 13:57:46,972 - INFO - Step 1486 -- ðŸ”„ Training Metrics
2025-03-02 13:57:46,972 - INFO - â”œâ”€â”€ Loss: 7.3903
2025-03-02 13:57:46,972 - INFO - â”œâ”€â”€ Learning Rate: 2.23e-04
2025-03-02 13:57:46,972 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:57:47,646 - INFO - ðŸªœ Batch step - 1487 -- sub batch step 5948 -- lr 2.23e-04
2025-03-02 13:57:49,811 - INFO - ðŸªœ Batch step - 1487 -- sub batch step 5949 -- lr 2.23e-04
2025-03-02 13:57:51,970 - INFO - ðŸªœ Batch step - 1487 -- sub batch step 5950 -- lr 2.23e-04
2025-03-02 13:57:54,378 - INFO - ðŸªœ Batch step - 1487 -- sub batch step 5951 -- lr 2.23e-04
2025-03-02 13:57:56,216 - INFO - Step 1487 -- ðŸ”„ Training Metrics
2025-03-02 13:57:56,217 - INFO - â”œâ”€â”€ Loss: 7.3668
2025-03-02 13:57:56,217 - INFO - â”œâ”€â”€ Learning Rate: 2.23e-04
2025-03-02 13:57:56,217 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:57:56,889 - INFO - ðŸªœ Batch step - 1488 -- sub batch step 5952 -- lr 2.23e-04
2025-03-02 13:57:59,040 - INFO - ðŸªœ Batch step - 1488 -- sub batch step 5953 -- lr 2.23e-04
2025-03-02 13:58:01,197 - INFO - ðŸªœ Batch step - 1488 -- sub batch step 5954 -- lr 2.23e-04
2025-03-02 13:58:03,374 - INFO - ðŸªœ Batch step - 1488 -- sub batch step 5955 -- lr 2.23e-04
2025-03-02 13:58:04,915 - INFO - Step 1488 -- ðŸ”„ Training Metrics
2025-03-02 13:58:04,915 - INFO - â”œâ”€â”€ Loss: 7.3590
2025-03-02 13:58:04,916 - INFO - â”œâ”€â”€ Learning Rate: 2.23e-04
2025-03-02 13:58:04,916 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:58:05,584 - INFO - ðŸªœ Batch step - 1489 -- sub batch step 5956 -- lr 2.23e-04
2025-03-02 13:58:07,742 - INFO - ðŸªœ Batch step - 1489 -- sub batch step 5957 -- lr 2.23e-04
2025-03-02 13:58:09,895 - INFO - ðŸªœ Batch step - 1489 -- sub batch step 5958 -- lr 2.23e-04
2025-03-02 13:58:12,577 - INFO - ðŸªœ Batch step - 1489 -- sub batch step 5959 -- lr 2.23e-04
2025-03-02 13:58:14,135 - INFO - Step 1489 -- ðŸ”„ Training Metrics
2025-03-02 13:58:14,135 - INFO - â”œâ”€â”€ Loss: 7.3885
2025-03-02 13:58:14,135 - INFO - â”œâ”€â”€ Learning Rate: 2.23e-04
2025-03-02 13:58:14,135 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:58:14,810 - INFO - ðŸªœ Batch step - 1490 -- sub batch step 5960 -- lr 2.23e-04
2025-03-02 13:58:16,962 - INFO - ðŸªœ Batch step - 1490 -- sub batch step 5961 -- lr 2.23e-04
2025-03-02 13:58:19,122 - INFO - ðŸªœ Batch step - 1490 -- sub batch step 5962 -- lr 2.23e-04
2025-03-02 13:58:21,292 - INFO - ðŸªœ Batch step - 1490 -- sub batch step 5963 -- lr 2.23e-04
2025-03-02 13:58:22,815 - INFO - Step 1490 -- ðŸ”„ Training Metrics
2025-03-02 13:58:22,815 - INFO - â”œâ”€â”€ Loss: 7.3621
2025-03-02 13:58:22,815 - INFO - â”œâ”€â”€ Learning Rate: 2.23e-04
2025-03-02 13:58:22,815 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:58:23,493 - INFO - ðŸªœ Batch step - 1491 -- sub batch step 5964 -- lr 2.24e-04
2025-03-02 13:58:25,649 - INFO - ðŸªœ Batch step - 1491 -- sub batch step 5965 -- lr 2.24e-04
2025-03-02 13:58:28,063 - INFO - ðŸªœ Batch step - 1491 -- sub batch step 5966 -- lr 2.24e-04
2025-03-02 13:58:30,220 - INFO - ðŸªœ Batch step - 1491 -- sub batch step 5967 -- lr 2.24e-04
2025-03-02 13:58:32,061 - INFO - Step 1491 -- ðŸ”„ Training Metrics
2025-03-02 13:58:32,061 - INFO - â”œâ”€â”€ Loss: 7.3632
2025-03-02 13:58:32,061 - INFO - â”œâ”€â”€ Learning Rate: 2.24e-04
2025-03-02 13:58:32,061 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:58:32,729 - INFO - ðŸªœ Batch step - 1492 -- sub batch step 5968 -- lr 2.24e-04
2025-03-02 13:58:34,891 - INFO - ðŸªœ Batch step - 1492 -- sub batch step 5969 -- lr 2.24e-04
2025-03-02 13:58:37,067 - INFO - ðŸªœ Batch step - 1492 -- sub batch step 5970 -- lr 2.24e-04
2025-03-02 13:58:39,215 - INFO - ðŸªœ Batch step - 1492 -- sub batch step 5971 -- lr 2.24e-04
2025-03-02 13:58:40,758 - INFO - Step 1492 -- ðŸ”„ Training Metrics
2025-03-02 13:58:40,759 - INFO - â”œâ”€â”€ Loss: 7.3758
2025-03-02 13:58:40,759 - INFO - â”œâ”€â”€ Learning Rate: 2.24e-04
2025-03-02 13:58:40,759 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:58:41,433 - INFO - ðŸªœ Batch step - 1493 -- sub batch step 5972 -- lr 2.24e-04
2025-03-02 13:58:43,584 - INFO - ðŸªœ Batch step - 1493 -- sub batch step 5973 -- lr 2.24e-04
2025-03-02 13:58:46,217 - INFO - ðŸªœ Batch step - 1493 -- sub batch step 5974 -- lr 2.24e-04
2025-03-02 13:58:48,378 - INFO - ðŸªœ Batch step - 1493 -- sub batch step 5975 -- lr 2.24e-04
2025-03-02 13:58:50,752 - INFO - Step 1493 -- ðŸ”„ Training Metrics
2025-03-02 13:58:50,752 - INFO - â”œâ”€â”€ Loss: 7.3677
2025-03-02 13:58:50,752 - INFO - â”œâ”€â”€ Learning Rate: 2.24e-04
2025-03-02 13:58:50,752 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:58:51,420 - INFO - ðŸªœ Batch step - 1494 -- sub batch step 5976 -- lr 2.24e-04
2025-03-02 13:58:53,576 - INFO - ðŸªœ Batch step - 1494 -- sub batch step 5977 -- lr 2.24e-04
2025-03-02 13:58:55,736 - INFO - ðŸªœ Batch step - 1494 -- sub batch step 5978 -- lr 2.24e-04
2025-03-02 13:58:57,894 - INFO - ðŸªœ Batch step - 1494 -- sub batch step 5979 -- lr 2.24e-04
2025-03-02 13:58:59,445 - INFO - Step 1494 -- ðŸ”„ Training Metrics
2025-03-02 13:58:59,446 - INFO - â”œâ”€â”€ Loss: 7.3653
2025-03-02 13:58:59,446 - INFO - â”œâ”€â”€ Learning Rate: 2.24e-04
2025-03-02 13:58:59,446 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:59:00,119 - INFO - ðŸªœ Batch step - 1495 -- sub batch step 5980 -- lr 2.24e-04
2025-03-02 13:59:02,274 - INFO - ðŸªœ Batch step - 1495 -- sub batch step 5981 -- lr 2.24e-04
2025-03-02 13:59:04,650 - INFO - ðŸªœ Batch step - 1495 -- sub batch step 5982 -- lr 2.24e-04
2025-03-02 13:59:06,803 - INFO - ðŸªœ Batch step - 1495 -- sub batch step 5983 -- lr 2.24e-04
2025-03-02 13:59:08,635 - INFO - Step 1495 -- ðŸ”„ Training Metrics
2025-03-02 13:59:08,635 - INFO - â”œâ”€â”€ Loss: 7.3941
2025-03-02 13:59:08,636 - INFO - â”œâ”€â”€ Learning Rate: 2.24e-04
2025-03-02 13:59:08,636 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:59:09,312 - INFO - ðŸªœ Batch step - 1496 -- sub batch step 5984 -- lr 2.24e-04
2025-03-02 13:59:11,465 - INFO - ðŸªœ Batch step - 1496 -- sub batch step 5985 -- lr 2.24e-04
2025-03-02 13:59:13,636 - INFO - ðŸªœ Batch step - 1496 -- sub batch step 5986 -- lr 2.24e-04
2025-03-02 13:59:15,794 - INFO - ðŸªœ Batch step - 1496 -- sub batch step 5987 -- lr 2.24e-04
2025-03-02 13:59:17,346 - INFO - Step 1496 -- ðŸ”„ Training Metrics
2025-03-02 13:59:17,346 - INFO - â”œâ”€â”€ Loss: 7.3618
2025-03-02 13:59:17,346 - INFO - â”œâ”€â”€ Learning Rate: 2.24e-04
2025-03-02 13:59:17,346 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:59:18,016 - INFO - ðŸªœ Batch step - 1497 -- sub batch step 5988 -- lr 2.25e-04
2025-03-02 13:59:20,173 - INFO - ðŸªœ Batch step - 1497 -- sub batch step 5989 -- lr 2.25e-04
2025-03-02 13:59:22,574 - INFO - ðŸªœ Batch step - 1497 -- sub batch step 5990 -- lr 2.25e-04
2025-03-02 13:59:24,722 - INFO - ðŸªœ Batch step - 1497 -- sub batch step 5991 -- lr 2.25e-04
2025-03-02 13:59:26,624 - INFO - Step 1497 -- ðŸ”„ Training Metrics
2025-03-02 13:59:26,624 - INFO - â”œâ”€â”€ Loss: 7.3827
2025-03-02 13:59:26,625 - INFO - â”œâ”€â”€ Learning Rate: 2.25e-04
2025-03-02 13:59:26,625 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:59:27,301 - INFO - ðŸªœ Batch step - 1498 -- sub batch step 5992 -- lr 2.25e-04
2025-03-02 13:59:29,449 - INFO - ðŸªœ Batch step - 1498 -- sub batch step 5993 -- lr 2.25e-04
2025-03-02 13:59:31,618 - INFO - ðŸªœ Batch step - 1498 -- sub batch step 5994 -- lr 2.25e-04
2025-03-02 13:59:33,772 - INFO - ðŸªœ Batch step - 1498 -- sub batch step 5995 -- lr 2.25e-04
2025-03-02 13:59:35,341 - INFO - Step 1498 -- ðŸ”„ Training Metrics
2025-03-02 13:59:35,341 - INFO - â”œâ”€â”€ Loss: 7.3602
2025-03-02 13:59:35,341 - INFO - â”œâ”€â”€ Learning Rate: 2.25e-04
2025-03-02 13:59:35,341 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:59:36,012 - INFO - ðŸªœ Batch step - 1499 -- sub batch step 5996 -- lr 2.25e-04
2025-03-02 13:59:38,166 - INFO - ðŸªœ Batch step - 1499 -- sub batch step 5997 -- lr 2.25e-04
2025-03-02 13:59:40,441 - INFO - ðŸªœ Batch step - 1499 -- sub batch step 5998 -- lr 2.25e-04
2025-03-02 13:59:42,597 - INFO - ðŸªœ Batch step - 1499 -- sub batch step 5999 -- lr 2.25e-04
2025-03-02 13:59:44,430 - INFO - Step 1499 -- ðŸ”„ Training Metrics
2025-03-02 13:59:44,430 - INFO - â”œâ”€â”€ Loss: 7.3587
2025-03-02 13:59:44,430 - INFO - â”œâ”€â”€ Learning Rate: 2.25e-04
2025-03-02 13:59:44,431 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:59:45,744 - INFO - ðŸªœ Batch step - 1500 -- sub batch step 6000 -- lr 2.25e-04
2025-03-02 13:59:47,899 - INFO - ðŸªœ Batch step - 1500 -- sub batch step 6001 -- lr 2.25e-04
2025-03-02 13:59:50,054 - INFO - ðŸªœ Batch step - 1500 -- sub batch step 6002 -- lr 2.25e-04
2025-03-02 13:59:52,219 - INFO - ðŸªœ Batch step - 1500 -- sub batch step 6003 -- lr 2.25e-04
2025-03-02 13:59:53,752 - INFO - Step 1500 -- ðŸ”„ Training Metrics
2025-03-02 13:59:53,753 - INFO - â”œâ”€â”€ Loss: 7.3609
2025-03-02 13:59:53,753 - INFO - â”œâ”€â”€ Learning Rate: 2.25e-04
2025-03-02 13:59:53,753 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 13:59:54,428 - INFO - ðŸªœ Batch step - 1501 -- sub batch step 6004 -- lr 2.25e-04
2025-03-02 13:59:56,582 - INFO - ðŸªœ Batch step - 1501 -- sub batch step 6005 -- lr 2.25e-04
2025-03-02 13:59:58,729 - INFO - ðŸªœ Batch step - 1501 -- sub batch step 6006 -- lr 2.25e-04
2025-03-02 14:00:01,168 - INFO - ðŸªœ Batch step - 1501 -- sub batch step 6007 -- lr 2.25e-04
2025-03-02 14:00:02,899 - INFO - Step 1501 -- ðŸ”„ Training Metrics
2025-03-02 14:00:02,899 - INFO - â”œâ”€â”€ Loss: 7.3795
2025-03-02 14:00:02,899 - INFO - â”œâ”€â”€ Learning Rate: 2.25e-04
2025-03-02 14:00:02,899 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:00:03,567 - INFO - ðŸªœ Batch step - 1502 -- sub batch step 6008 -- lr 2.25e-04
2025-03-02 14:00:05,728 - INFO - ðŸªœ Batch step - 1502 -- sub batch step 6009 -- lr 2.25e-04
2025-03-02 14:00:07,884 - INFO - ðŸªœ Batch step - 1502 -- sub batch step 6010 -- lr 2.25e-04
2025-03-02 14:00:10,048 - INFO - ðŸªœ Batch step - 1502 -- sub batch step 6011 -- lr 2.25e-04
2025-03-02 14:00:11,590 - INFO - Step 1502 -- ðŸ”„ Training Metrics
2025-03-02 14:00:11,590 - INFO - â”œâ”€â”€ Loss: 7.3478
2025-03-02 14:00:11,590 - INFO - â”œâ”€â”€ Learning Rate: 2.25e-04
2025-03-02 14:00:11,590 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:00:12,268 - INFO - ðŸªœ Batch step - 1503 -- sub batch step 6012 -- lr 2.25e-04
2025-03-02 14:00:14,417 - INFO - ðŸªœ Batch step - 1503 -- sub batch step 6013 -- lr 2.25e-04
2025-03-02 14:00:16,574 - INFO - ðŸªœ Batch step - 1503 -- sub batch step 6014 -- lr 2.25e-04
2025-03-02 14:00:19,177 - INFO - ðŸªœ Batch step - 1503 -- sub batch step 6015 -- lr 2.25e-04
2025-03-02 14:00:20,788 - INFO - Step 1503 -- ðŸ”„ Training Metrics
2025-03-02 14:00:20,788 - INFO - â”œâ”€â”€ Loss: 7.3708
2025-03-02 14:00:20,788 - INFO - â”œâ”€â”€ Learning Rate: 2.25e-04
2025-03-02 14:00:20,788 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:00:21,462 - INFO - ðŸªœ Batch step - 1504 -- sub batch step 6016 -- lr 2.26e-04
2025-03-02 14:00:23,618 - INFO - ðŸªœ Batch step - 1504 -- sub batch step 6017 -- lr 2.26e-04
2025-03-02 14:00:25,772 - INFO - ðŸªœ Batch step - 1504 -- sub batch step 6018 -- lr 2.26e-04
2025-03-02 14:00:27,950 - INFO - ðŸªœ Batch step - 1504 -- sub batch step 6019 -- lr 2.26e-04
2025-03-02 14:00:29,476 - INFO - Step 1504 -- ðŸ”„ Training Metrics
2025-03-02 14:00:29,476 - INFO - â”œâ”€â”€ Loss: 7.3601
2025-03-02 14:00:29,476 - INFO - â”œâ”€â”€ Learning Rate: 2.26e-04
2025-03-02 14:00:29,476 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:00:30,157 - INFO - ðŸªœ Batch step - 1505 -- sub batch step 6020 -- lr 2.26e-04
2025-03-02 14:00:32,310 - INFO - ðŸªœ Batch step - 1505 -- sub batch step 6021 -- lr 2.26e-04
2025-03-02 14:00:34,466 - INFO - ðŸªœ Batch step - 1505 -- sub batch step 6022 -- lr 2.26e-04
2025-03-02 14:00:37,081 - INFO - ðŸªœ Batch step - 1505 -- sub batch step 6023 -- lr 2.26e-04
2025-03-02 14:00:38,716 - INFO - Step 1505 -- ðŸ”„ Training Metrics
2025-03-02 14:00:38,716 - INFO - â”œâ”€â”€ Loss: 7.3756
2025-03-02 14:00:38,716 - INFO - â”œâ”€â”€ Learning Rate: 2.26e-04
2025-03-02 14:00:38,716 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:00:39,395 - INFO - ðŸªœ Batch step - 1506 -- sub batch step 6024 -- lr 2.26e-04
2025-03-02 14:00:41,551 - INFO - ðŸªœ Batch step - 1506 -- sub batch step 6025 -- lr 2.26e-04
2025-03-02 14:00:43,704 - INFO - ðŸªœ Batch step - 1506 -- sub batch step 6026 -- lr 2.26e-04
2025-03-02 14:00:45,874 - INFO - ðŸªœ Batch step - 1506 -- sub batch step 6027 -- lr 2.26e-04
2025-03-02 14:00:47,419 - INFO - Step 1506 -- ðŸ”„ Training Metrics
2025-03-02 14:00:47,419 - INFO - â”œâ”€â”€ Loss: 7.3723
2025-03-02 14:00:47,419 - INFO - â”œâ”€â”€ Learning Rate: 2.26e-04
2025-03-02 14:00:47,419 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:00:48,086 - INFO - ðŸªœ Batch step - 1507 -- sub batch step 6028 -- lr 2.26e-04
2025-03-02 14:00:50,241 - INFO - ðŸªœ Batch step - 1507 -- sub batch step 6029 -- lr 2.26e-04
2025-03-02 14:00:52,420 - INFO - ðŸªœ Batch step - 1507 -- sub batch step 6030 -- lr 2.26e-04
2025-03-02 14:00:55,074 - INFO - ðŸªœ Batch step - 1507 -- sub batch step 6031 -- lr 2.26e-04
2025-03-02 14:00:56,679 - INFO - Step 1507 -- ðŸ”„ Training Metrics
2025-03-02 14:00:56,679 - INFO - â”œâ”€â”€ Loss: 7.3711
2025-03-02 14:00:56,679 - INFO - â”œâ”€â”€ Learning Rate: 2.26e-04
2025-03-02 14:00:56,679 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:00:57,352 - INFO - ðŸªœ Batch step - 1508 -- sub batch step 6032 -- lr 2.26e-04
2025-03-02 14:00:59,504 - INFO - ðŸªœ Batch step - 1508 -- sub batch step 6033 -- lr 2.26e-04
2025-03-02 14:01:01,663 - INFO - ðŸªœ Batch step - 1508 -- sub batch step 6034 -- lr 2.26e-04
2025-03-02 14:01:03,842 - INFO - ðŸªœ Batch step - 1508 -- sub batch step 6035 -- lr 2.26e-04
2025-03-02 14:01:05,382 - INFO - Step 1508 -- ðŸ”„ Training Metrics
2025-03-02 14:01:05,382 - INFO - â”œâ”€â”€ Loss: 7.3425
2025-03-02 14:01:05,382 - INFO - â”œâ”€â”€ Learning Rate: 2.26e-04
2025-03-02 14:01:05,382 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:01:06,055 - INFO - ðŸªœ Batch step - 1509 -- sub batch step 6036 -- lr 2.26e-04
2025-03-02 14:01:08,212 - INFO - ðŸªœ Batch step - 1509 -- sub batch step 6037 -- lr 2.26e-04
2025-03-02 14:01:10,360 - INFO - ðŸªœ Batch step - 1509 -- sub batch step 6038 -- lr 2.26e-04
2025-03-02 14:01:13,006 - INFO - ðŸªœ Batch step - 1509 -- sub batch step 6039 -- lr 2.26e-04
2025-03-02 14:01:14,635 - INFO - Step 1509 -- ðŸ”„ Training Metrics
2025-03-02 14:01:14,636 - INFO - â”œâ”€â”€ Loss: 7.3200
2025-03-02 14:01:14,636 - INFO - â”œâ”€â”€ Learning Rate: 2.26e-04
2025-03-02 14:01:14,636 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:01:15,308 - INFO - ðŸªœ Batch step - 1510 -- sub batch step 6040 -- lr 2.26e-04
2025-03-02 14:01:17,464 - INFO - ðŸªœ Batch step - 1510 -- sub batch step 6041 -- lr 2.26e-04
2025-03-02 14:01:19,617 - INFO - ðŸªœ Batch step - 1510 -- sub batch step 6042 -- lr 2.26e-04
2025-03-02 14:01:21,787 - INFO - ðŸªœ Batch step - 1510 -- sub batch step 6043 -- lr 2.26e-04
2025-03-02 14:01:23,327 - INFO - Step 1510 -- ðŸ”„ Training Metrics
2025-03-02 14:01:23,328 - INFO - â”œâ”€â”€ Loss: 7.3433
2025-03-02 14:01:23,328 - INFO - â”œâ”€â”€ Learning Rate: 2.26e-04
2025-03-02 14:01:23,328 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:01:24,000 - INFO - ðŸªœ Batch step - 1511 -- sub batch step 6044 -- lr 2.27e-04
2025-03-02 14:01:26,155 - INFO - ðŸªœ Batch step - 1511 -- sub batch step 6045 -- lr 2.27e-04
2025-03-02 14:01:28,770 - INFO - ðŸªœ Batch step - 1511 -- sub batch step 6046 -- lr 2.27e-04
2025-03-02 14:01:30,931 - INFO - ðŸªœ Batch step - 1511 -- sub batch step 6047 -- lr 2.27e-04
2025-03-02 14:01:32,889 - INFO - Step 1511 -- ðŸ”„ Training Metrics
2025-03-02 14:01:32,889 - INFO - â”œâ”€â”€ Loss: 7.3375
2025-03-02 14:01:32,889 - INFO - â”œâ”€â”€ Learning Rate: 2.27e-04
2025-03-02 14:01:32,889 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:01:33,555 - INFO - ðŸªœ Batch step - 1512 -- sub batch step 6048 -- lr 2.27e-04
2025-03-02 14:01:35,713 - INFO - ðŸªœ Batch step - 1512 -- sub batch step 6049 -- lr 2.27e-04
2025-03-02 14:01:37,879 - INFO - ðŸªœ Batch step - 1512 -- sub batch step 6050 -- lr 2.27e-04
2025-03-02 14:01:40,023 - INFO - ðŸªœ Batch step - 1512 -- sub batch step 6051 -- lr 2.27e-04
2025-03-02 14:01:41,568 - INFO - Step 1512 -- ðŸ”„ Training Metrics
2025-03-02 14:01:41,568 - INFO - â”œâ”€â”€ Loss: 7.3608
2025-03-02 14:01:41,568 - INFO - â”œâ”€â”€ Learning Rate: 2.27e-04
2025-03-02 14:01:41,568 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:01:42,243 - INFO - ðŸªœ Batch step - 1513 -- sub batch step 6052 -- lr 2.27e-04
2025-03-02 14:01:44,390 - INFO - ðŸªœ Batch step - 1513 -- sub batch step 6053 -- lr 2.27e-04
2025-03-02 14:01:47,076 - INFO - ðŸªœ Batch step - 1513 -- sub batch step 6054 -- lr 2.27e-04
2025-03-02 14:01:49,230 - INFO - ðŸªœ Batch step - 1513 -- sub batch step 6055 -- lr 2.27e-04
2025-03-02 14:01:50,822 - INFO - Step 1513 -- ðŸ”„ Training Metrics
2025-03-02 14:01:50,822 - INFO - â”œâ”€â”€ Loss: 7.3953
2025-03-02 14:01:50,822 - INFO - â”œâ”€â”€ Learning Rate: 2.27e-04
2025-03-02 14:01:50,822 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:01:51,494 - INFO - ðŸªœ Batch step - 1514 -- sub batch step 6056 -- lr 2.27e-04
2025-03-02 14:01:53,648 - INFO - ðŸªœ Batch step - 1514 -- sub batch step 6057 -- lr 2.27e-04
2025-03-02 14:01:55,813 - INFO - ðŸªœ Batch step - 1514 -- sub batch step 6058 -- lr 2.27e-04
2025-03-02 14:01:57,965 - INFO - ðŸªœ Batch step - 1514 -- sub batch step 6059 -- lr 2.27e-04
2025-03-02 14:01:59,510 - INFO - Step 1514 -- ðŸ”„ Training Metrics
2025-03-02 14:01:59,511 - INFO - â”œâ”€â”€ Loss: 7.3427
2025-03-02 14:01:59,511 - INFO - â”œâ”€â”€ Learning Rate: 2.27e-04
2025-03-02 14:01:59,511 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:02:00,188 - INFO - ðŸªœ Batch step - 1515 -- sub batch step 6060 -- lr 2.27e-04
2025-03-02 14:02:02,343 - INFO - ðŸªœ Batch step - 1515 -- sub batch step 6061 -- lr 2.27e-04
2025-03-02 14:02:05,008 - INFO - ðŸªœ Batch step - 1515 -- sub batch step 6062 -- lr 2.27e-04
2025-03-02 14:02:07,159 - INFO - ðŸªœ Batch step - 1515 -- sub batch step 6063 -- lr 2.27e-04
2025-03-02 14:02:08,645 - INFO - Step 1515 -- ðŸ”„ Training Metrics
2025-03-02 14:02:08,645 - INFO - â”œâ”€â”€ Loss: 7.3730
2025-03-02 14:02:08,645 - INFO - â”œâ”€â”€ Learning Rate: 2.27e-04
2025-03-02 14:02:08,645 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:02:09,324 - INFO - ðŸªœ Batch step - 1516 -- sub batch step 6064 -- lr 2.27e-04
2025-03-02 14:02:11,479 - INFO - ðŸªœ Batch step - 1516 -- sub batch step 6065 -- lr 2.27e-04
2025-03-02 14:02:13,642 - INFO - ðŸªœ Batch step - 1516 -- sub batch step 6066 -- lr 2.27e-04
2025-03-02 14:02:15,798 - INFO - ðŸªœ Batch step - 1516 -- sub batch step 6067 -- lr 2.27e-04
2025-03-02 14:02:17,354 - INFO - Step 1516 -- ðŸ”„ Training Metrics
2025-03-02 14:02:17,355 - INFO - â”œâ”€â”€ Loss: 7.3500
2025-03-02 14:02:17,355 - INFO - â”œâ”€â”€ Learning Rate: 2.27e-04
2025-03-02 14:02:17,355 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:02:18,026 - INFO - ðŸªœ Batch step - 1517 -- sub batch step 6068 -- lr 2.28e-04
2025-03-02 14:02:20,186 - INFO - ðŸªœ Batch step - 1517 -- sub batch step 6069 -- lr 2.28e-04
2025-03-02 14:02:22,616 - INFO - ðŸªœ Batch step - 1517 -- sub batch step 6070 -- lr 2.28e-04
2025-03-02 14:02:24,773 - INFO - ðŸªœ Batch step - 1517 -- sub batch step 6071 -- lr 2.28e-04
2025-03-02 14:02:26,731 - INFO - Step 1517 -- ðŸ”„ Training Metrics
2025-03-02 14:02:26,731 - INFO - â”œâ”€â”€ Loss: 7.3549
2025-03-02 14:02:26,731 - INFO - â”œâ”€â”€ Learning Rate: 2.28e-04
2025-03-02 14:02:26,731 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:02:27,409 - INFO - ðŸªœ Batch step - 1518 -- sub batch step 6072 -- lr 2.28e-04
2025-03-02 14:02:29,558 - INFO - ðŸªœ Batch step - 1518 -- sub batch step 6073 -- lr 2.28e-04
2025-03-02 14:02:31,725 - INFO - ðŸªœ Batch step - 1518 -- sub batch step 6074 -- lr 2.28e-04
2025-03-02 14:02:33,880 - INFO - ðŸªœ Batch step - 1518 -- sub batch step 6075 -- lr 2.28e-04
2025-03-02 14:02:35,435 - INFO - Step 1518 -- ðŸ”„ Training Metrics
2025-03-02 14:02:35,436 - INFO - â”œâ”€â”€ Loss: 7.3534
2025-03-02 14:02:35,436 - INFO - â”œâ”€â”€ Learning Rate: 2.28e-04
2025-03-02 14:02:35,436 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:02:36,108 - INFO - ðŸªœ Batch step - 1519 -- sub batch step 6076 -- lr 2.28e-04
2025-03-02 14:02:38,266 - INFO - ðŸªœ Batch step - 1519 -- sub batch step 6077 -- lr 2.28e-04
2025-03-02 14:02:40,548 - INFO - ðŸªœ Batch step - 1519 -- sub batch step 6078 -- lr 2.28e-04
2025-03-02 14:02:42,705 - INFO - ðŸªœ Batch step - 1519 -- sub batch step 6079 -- lr 2.28e-04
2025-03-02 14:02:44,369 - INFO - Step 1519 -- ðŸ”„ Training Metrics
2025-03-02 14:02:44,370 - INFO - â”œâ”€â”€ Loss: 7.3397
2025-03-02 14:02:44,370 - INFO - â”œâ”€â”€ Learning Rate: 2.28e-04
2025-03-02 14:02:44,370 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:02:45,613 - INFO - ðŸªœ Batch step - 1520 -- sub batch step 6080 -- lr 2.28e-04
2025-03-02 14:02:47,766 - INFO - ðŸªœ Batch step - 1520 -- sub batch step 6081 -- lr 2.28e-04
2025-03-02 14:02:49,931 - INFO - ðŸªœ Batch step - 1520 -- sub batch step 6082 -- lr 2.28e-04
2025-03-02 14:02:52,102 - INFO - ðŸªœ Batch step - 1520 -- sub batch step 6083 -- lr 2.28e-04
2025-03-02 14:02:53,629 - INFO - Step 1520 -- ðŸ”„ Training Metrics
2025-03-02 14:02:53,630 - INFO - â”œâ”€â”€ Loss: 7.3547
2025-03-02 14:02:53,630 - INFO - â”œâ”€â”€ Learning Rate: 2.28e-04
2025-03-02 14:02:53,630 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:02:54,305 - INFO - ðŸªœ Batch step - 1521 -- sub batch step 6084 -- lr 2.28e-04
2025-03-02 14:02:56,461 - INFO - ðŸªœ Batch step - 1521 -- sub batch step 6085 -- lr 2.28e-04
2025-03-02 14:02:58,608 - INFO - ðŸªœ Batch step - 1521 -- sub batch step 6086 -- lr 2.28e-04
2025-03-02 14:03:01,318 - INFO - ðŸªœ Batch step - 1521 -- sub batch step 6087 -- lr 2.28e-04
2025-03-02 14:03:02,814 - INFO - Step 1521 -- ðŸ”„ Training Metrics
2025-03-02 14:03:02,814 - INFO - â”œâ”€â”€ Loss: 7.3685
2025-03-02 14:03:02,814 - INFO - â”œâ”€â”€ Learning Rate: 2.28e-04
2025-03-02 14:03:02,814 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:03:03,483 - INFO - ðŸªœ Batch step - 1522 -- sub batch step 6088 -- lr 2.28e-04
2025-03-02 14:03:05,642 - INFO - ðŸªœ Batch step - 1522 -- sub batch step 6089 -- lr 2.28e-04
2025-03-02 14:03:07,796 - INFO - ðŸªœ Batch step - 1522 -- sub batch step 6090 -- lr 2.28e-04
2025-03-02 14:03:09,960 - INFO - ðŸªœ Batch step - 1522 -- sub batch step 6091 -- lr 2.28e-04
2025-03-02 14:03:11,517 - INFO - Step 1522 -- ðŸ”„ Training Metrics
2025-03-02 14:03:11,518 - INFO - â”œâ”€â”€ Loss: 7.3629
2025-03-02 14:03:11,518 - INFO - â”œâ”€â”€ Learning Rate: 2.28e-04
2025-03-02 14:03:11,518 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:03:12,196 - INFO - ðŸªœ Batch step - 1523 -- sub batch step 6092 -- lr 2.28e-04
2025-03-02 14:03:14,344 - INFO - ðŸªœ Batch step - 1523 -- sub batch step 6093 -- lr 2.28e-04
2025-03-02 14:03:16,501 - INFO - ðŸªœ Batch step - 1523 -- sub batch step 6094 -- lr 2.28e-04
2025-03-02 14:03:19,104 - INFO - ðŸªœ Batch step - 1523 -- sub batch step 6095 -- lr 2.28e-04
2025-03-02 14:03:20,997 - INFO - Step 1523 -- ðŸ”„ Training Metrics
2025-03-02 14:03:20,998 - INFO - â”œâ”€â”€ Loss: 7.3550
2025-03-02 14:03:20,998 - INFO - â”œâ”€â”€ Learning Rate: 2.28e-04
2025-03-02 14:03:20,998 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:03:21,665 - INFO - ðŸªœ Batch step - 1524 -- sub batch step 6096 -- lr 2.29e-04
2025-03-02 14:03:23,826 - INFO - ðŸªœ Batch step - 1524 -- sub batch step 6097 -- lr 2.29e-04
2025-03-02 14:03:25,976 - INFO - ðŸªœ Batch step - 1524 -- sub batch step 6098 -- lr 2.29e-04
2025-03-02 14:03:28,144 - INFO - ðŸªœ Batch step - 1524 -- sub batch step 6099 -- lr 2.29e-04
2025-03-02 14:03:29,677 - INFO - Step 1524 -- ðŸ”„ Training Metrics
2025-03-02 14:03:29,677 - INFO - â”œâ”€â”€ Loss: 7.3459
2025-03-02 14:03:29,677 - INFO - â”œâ”€â”€ Learning Rate: 2.29e-04
2025-03-02 14:03:29,678 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:03:30,356 - INFO - ðŸªœ Batch step - 1525 -- sub batch step 6100 -- lr 2.29e-04
2025-03-02 14:03:32,512 - INFO - ðŸªœ Batch step - 1525 -- sub batch step 6101 -- lr 2.29e-04
2025-03-02 14:03:34,668 - INFO - ðŸªœ Batch step - 1525 -- sub batch step 6102 -- lr 2.29e-04
2025-03-02 14:03:37,037 - INFO - ðŸªœ Batch step - 1525 -- sub batch step 6103 -- lr 2.29e-04
2025-03-02 14:03:38,938 - INFO - Step 1525 -- ðŸ”„ Training Metrics
2025-03-02 14:03:38,938 - INFO - â”œâ”€â”€ Loss: 7.3534
2025-03-02 14:03:38,938 - INFO - â”œâ”€â”€ Learning Rate: 2.29e-04
2025-03-02 14:03:38,938 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:03:39,619 - INFO - ðŸªœ Batch step - 1526 -- sub batch step 6104 -- lr 2.29e-04
2025-03-02 14:03:41,775 - INFO - ðŸªœ Batch step - 1526 -- sub batch step 6105 -- lr 2.29e-04
2025-03-02 14:03:43,925 - INFO - ðŸªœ Batch step - 1526 -- sub batch step 6106 -- lr 2.29e-04
2025-03-02 14:03:46,097 - INFO - ðŸªœ Batch step - 1526 -- sub batch step 6107 -- lr 2.29e-04
2025-03-02 14:03:47,636 - INFO - Step 1526 -- ðŸ”„ Training Metrics
2025-03-02 14:03:47,637 - INFO - â”œâ”€â”€ Loss: 7.3520
2025-03-02 14:03:47,637 - INFO - â”œâ”€â”€ Learning Rate: 2.29e-04
2025-03-02 14:03:47,637 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:03:48,305 - INFO - ðŸªœ Batch step - 1527 -- sub batch step 6108 -- lr 2.29e-04
2025-03-02 14:03:50,465 - INFO - ðŸªœ Batch step - 1527 -- sub batch step 6109 -- lr 2.29e-04
2025-03-02 14:03:52,622 - INFO - ðŸªœ Batch step - 1527 -- sub batch step 6110 -- lr 2.29e-04
2025-03-02 14:03:55,275 - INFO - ðŸªœ Batch step - 1527 -- sub batch step 6111 -- lr 2.29e-04
2025-03-02 14:03:56,816 - INFO - Step 1527 -- ðŸ”„ Training Metrics
2025-03-02 14:03:56,816 - INFO - â”œâ”€â”€ Loss: 7.3579
2025-03-02 14:03:56,816 - INFO - â”œâ”€â”€ Learning Rate: 2.29e-04
2025-03-02 14:03:56,816 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:03:57,490 - INFO - ðŸªœ Batch step - 1528 -- sub batch step 6112 -- lr 2.29e-04
2025-03-02 14:03:59,646 - INFO - ðŸªœ Batch step - 1528 -- sub batch step 6113 -- lr 2.29e-04
2025-03-02 14:04:01,800 - INFO - ðŸªœ Batch step - 1528 -- sub batch step 6114 -- lr 2.29e-04
2025-03-02 14:04:03,971 - INFO - ðŸªœ Batch step - 1528 -- sub batch step 6115 -- lr 2.29e-04
2025-03-02 14:04:05,512 - INFO - Step 1528 -- ðŸ”„ Training Metrics
2025-03-02 14:04:05,512 - INFO - â”œâ”€â”€ Loss: 7.3579
2025-03-02 14:04:05,512 - INFO - â”œâ”€â”€ Learning Rate: 2.29e-04
2025-03-02 14:04:05,512 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:04:06,179 - INFO - ðŸªœ Batch step - 1529 -- sub batch step 6116 -- lr 2.29e-04
2025-03-02 14:04:08,341 - INFO - ðŸªœ Batch step - 1529 -- sub batch step 6117 -- lr 2.29e-04
2025-03-02 14:04:10,490 - INFO - ðŸªœ Batch step - 1529 -- sub batch step 6118 -- lr 2.29e-04
2025-03-02 14:04:13,154 - INFO - ðŸªœ Batch step - 1529 -- sub batch step 6119 -- lr 2.29e-04
2025-03-02 14:04:14,665 - INFO - Step 1529 -- ðŸ”„ Training Metrics
2025-03-02 14:04:14,665 - INFO - â”œâ”€â”€ Loss: 7.3705
2025-03-02 14:04:14,666 - INFO - â”œâ”€â”€ Learning Rate: 2.29e-04
2025-03-02 14:04:14,666 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:04:15,347 - INFO - ðŸªœ Batch step - 1530 -- sub batch step 6120 -- lr 2.29e-04
2025-03-02 14:04:17,497 - INFO - ðŸªœ Batch step - 1530 -- sub batch step 6121 -- lr 2.29e-04
2025-03-02 14:04:19,652 - INFO - ðŸªœ Batch step - 1530 -- sub batch step 6122 -- lr 2.29e-04
2025-03-02 14:04:21,821 - INFO - ðŸªœ Batch step - 1530 -- sub batch step 6123 -- lr 2.29e-04
2025-03-02 14:04:23,354 - INFO - Step 1530 -- ðŸ”„ Training Metrics
2025-03-02 14:04:23,355 - INFO - â”œâ”€â”€ Loss: 7.3339
2025-03-02 14:04:23,355 - INFO - â”œâ”€â”€ Learning Rate: 2.29e-04
2025-03-02 14:04:23,355 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:04:24,034 - INFO - ðŸªœ Batch step - 1531 -- sub batch step 6124 -- lr 2.30e-04
2025-03-02 14:04:26,188 - INFO - ðŸªœ Batch step - 1531 -- sub batch step 6125 -- lr 2.30e-04
2025-03-02 14:04:28,877 - INFO - ðŸªœ Batch step - 1531 -- sub batch step 6126 -- lr 2.30e-04
2025-03-02 14:04:31,032 - INFO - ðŸªœ Batch step - 1531 -- sub batch step 6127 -- lr 2.30e-04
2025-03-02 14:04:32,564 - INFO - Step 1531 -- ðŸ”„ Training Metrics
2025-03-02 14:04:32,564 - INFO - â”œâ”€â”€ Loss: 7.3504
2025-03-02 14:04:32,564 - INFO - â”œâ”€â”€ Learning Rate: 2.30e-04
2025-03-02 14:04:32,564 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:04:33,232 - INFO - ðŸªœ Batch step - 1532 -- sub batch step 6128 -- lr 2.30e-04
2025-03-02 14:04:35,391 - INFO - ðŸªœ Batch step - 1532 -- sub batch step 6129 -- lr 2.30e-04
2025-03-02 14:04:37,560 - INFO - ðŸªœ Batch step - 1532 -- sub batch step 6130 -- lr 2.30e-04
2025-03-02 14:04:39,710 - INFO - ðŸªœ Batch step - 1532 -- sub batch step 6131 -- lr 2.30e-04
2025-03-02 14:04:41,258 - INFO - Step 1532 -- ðŸ”„ Training Metrics
2025-03-02 14:04:41,258 - INFO - â”œâ”€â”€ Loss: 7.3569
2025-03-02 14:04:41,258 - INFO - â”œâ”€â”€ Learning Rate: 2.30e-04
2025-03-02 14:04:41,258 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:04:41,936 - INFO - ðŸªœ Batch step - 1533 -- sub batch step 6132 -- lr 2.30e-04
2025-03-02 14:04:44,085 - INFO - ðŸªœ Batch step - 1533 -- sub batch step 6133 -- lr 2.30e-04
2025-03-02 14:04:46,754 - INFO - ðŸªœ Batch step - 1533 -- sub batch step 6134 -- lr 2.30e-04
2025-03-02 14:04:48,916 - INFO - ðŸªœ Batch step - 1533 -- sub batch step 6135 -- lr 2.30e-04
2025-03-02 14:04:50,403 - INFO - Step 1533 -- ðŸ”„ Training Metrics
2025-03-02 14:04:50,403 - INFO - â”œâ”€â”€ Loss: 7.3514
2025-03-02 14:04:50,403 - INFO - â”œâ”€â”€ Learning Rate: 2.30e-04
2025-03-02 14:04:50,403 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:04:51,075 - INFO - ðŸªœ Batch step - 1534 -- sub batch step 6136 -- lr 2.30e-04
2025-03-02 14:04:53,234 - INFO - ðŸªœ Batch step - 1534 -- sub batch step 6137 -- lr 2.30e-04
2025-03-02 14:04:55,401 - INFO - ðŸªœ Batch step - 1534 -- sub batch step 6138 -- lr 2.30e-04
2025-03-02 14:04:57,556 - INFO - ðŸªœ Batch step - 1534 -- sub batch step 6139 -- lr 2.30e-04
2025-03-02 14:04:59,094 - INFO - Step 1534 -- ðŸ”„ Training Metrics
2025-03-02 14:04:59,095 - INFO - â”œâ”€â”€ Loss: 7.3667
2025-03-02 14:04:59,095 - INFO - â”œâ”€â”€ Learning Rate: 2.30e-04
2025-03-02 14:04:59,095 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:04:59,773 - INFO - ðŸªœ Batch step - 1535 -- sub batch step 6140 -- lr 2.30e-04
2025-03-02 14:05:01,924 - INFO - ðŸªœ Batch step - 1535 -- sub batch step 6141 -- lr 2.30e-04
2025-03-02 14:05:04,606 - INFO - ðŸªœ Batch step - 1535 -- sub batch step 6142 -- lr 2.30e-04
2025-03-02 14:05:06,762 - INFO - ðŸªœ Batch step - 1535 -- sub batch step 6143 -- lr 2.30e-04
2025-03-02 14:05:08,264 - INFO - Step 1535 -- ðŸ”„ Training Metrics
2025-03-02 14:05:08,264 - INFO - â”œâ”€â”€ Loss: 7.3285
2025-03-02 14:05:08,264 - INFO - â”œâ”€â”€ Learning Rate: 2.30e-04
2025-03-02 14:05:08,264 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:05:08,940 - INFO - ðŸªœ Batch step - 1536 -- sub batch step 6144 -- lr 2.30e-04
2025-03-02 14:05:11,094 - INFO - ðŸªœ Batch step - 1536 -- sub batch step 6145 -- lr 2.30e-04
2025-03-02 14:05:13,260 - INFO - ðŸªœ Batch step - 1536 -- sub batch step 6146 -- lr 2.30e-04
2025-03-02 14:05:15,414 - INFO - ðŸªœ Batch step - 1536 -- sub batch step 6147 -- lr 2.30e-04
2025-03-02 14:05:16,963 - INFO - Step 1536 -- ðŸ”„ Training Metrics
2025-03-02 14:05:16,963 - INFO - â”œâ”€â”€ Loss: 7.3551
2025-03-02 14:05:16,963 - INFO - â”œâ”€â”€ Learning Rate: 2.30e-04
2025-03-02 14:05:16,963 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:05:17,633 - INFO - ðŸªœ Batch step - 1537 -- sub batch step 6148 -- lr 2.31e-04
2025-03-02 14:05:19,793 - INFO - ðŸªœ Batch step - 1537 -- sub batch step 6149 -- lr 2.31e-04
2025-03-02 14:05:22,493 - INFO - ðŸªœ Batch step - 1537 -- sub batch step 6150 -- lr 2.31e-04
2025-03-02 14:05:24,649 - INFO - ðŸªœ Batch step - 1537 -- sub batch step 6151 -- lr 2.31e-04
2025-03-02 14:05:26,140 - INFO - Step 1537 -- ðŸ”„ Training Metrics
2025-03-02 14:05:26,140 - INFO - â”œâ”€â”€ Loss: 7.3288
2025-03-02 14:05:26,140 - INFO - â”œâ”€â”€ Learning Rate: 2.31e-04
2025-03-02 14:05:26,140 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:05:26,818 - INFO - ðŸªœ Batch step - 1538 -- sub batch step 6152 -- lr 2.31e-04
2025-03-02 14:05:28,971 - INFO - ðŸªœ Batch step - 1538 -- sub batch step 6153 -- lr 2.31e-04
2025-03-02 14:05:31,143 - INFO - ðŸªœ Batch step - 1538 -- sub batch step 6154 -- lr 2.31e-04
2025-03-02 14:05:33,299 - INFO - ðŸªœ Batch step - 1538 -- sub batch step 6155 -- lr 2.31e-04
2025-03-02 14:05:34,847 - INFO - Step 1538 -- ðŸ”„ Training Metrics
2025-03-02 14:05:34,847 - INFO - â”œâ”€â”€ Loss: 7.3574
2025-03-02 14:05:34,847 - INFO - â”œâ”€â”€ Learning Rate: 2.31e-04
2025-03-02 14:05:34,847 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:05:35,520 - INFO - ðŸªœ Batch step - 1539 -- sub batch step 6156 -- lr 2.31e-04
2025-03-02 14:05:37,675 - INFO - ðŸªœ Batch step - 1539 -- sub batch step 6157 -- lr 2.31e-04
2025-03-02 14:05:39,949 - INFO - ðŸªœ Batch step - 1539 -- sub batch step 6158 -- lr 2.31e-04
2025-03-02 14:05:42,108 - INFO - ðŸªœ Batch step - 1539 -- sub batch step 6159 -- lr 2.31e-04
2025-03-02 14:05:43,659 - INFO - Step 1539 -- ðŸ”„ Training Metrics
2025-03-02 14:05:43,659 - INFO - â”œâ”€â”€ Loss: 7.3554
2025-03-02 14:05:43,659 - INFO - â”œâ”€â”€ Learning Rate: 2.31e-04
2025-03-02 14:05:43,659 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:05:44,806 - INFO - ðŸªœ Batch step - 1540 -- sub batch step 6160 -- lr 2.31e-04
2025-03-02 14:05:46,960 - INFO - ðŸªœ Batch step - 1540 -- sub batch step 6161 -- lr 2.31e-04
2025-03-02 14:05:49,122 - INFO - ðŸªœ Batch step - 1540 -- sub batch step 6162 -- lr 2.31e-04
2025-03-02 14:05:51,300 - INFO - ðŸªœ Batch step - 1540 -- sub batch step 6163 -- lr 2.31e-04
2025-03-02 14:05:53,042 - INFO - Step 1540 -- ðŸ”„ Training Metrics
2025-03-02 14:05:53,042 - INFO - â”œâ”€â”€ Loss: 7.3469
2025-03-02 14:05:53,042 - INFO - â”œâ”€â”€ Learning Rate: 2.31e-04
2025-03-02 14:05:53,042 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:05:53,727 - INFO - ðŸªœ Batch step - 1541 -- sub batch step 6164 -- lr 2.31e-04
2025-03-02 14:05:55,891 - INFO - ðŸªœ Batch step - 1541 -- sub batch step 6165 -- lr 2.31e-04
2025-03-02 14:05:58,045 - INFO - ðŸªœ Batch step - 1541 -- sub batch step 6166 -- lr 2.31e-04
2025-03-02 14:06:00,649 - INFO - ðŸªœ Batch step - 1541 -- sub batch step 6167 -- lr 2.31e-04
2025-03-02 14:06:02,402 - INFO - Step 1541 -- ðŸ”„ Training Metrics
2025-03-02 14:06:02,402 - INFO - â”œâ”€â”€ Loss: 7.3559
2025-03-02 14:06:02,402 - INFO - â”œâ”€â”€ Learning Rate: 2.31e-04
2025-03-02 14:06:02,403 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:06:03,073 - INFO - ðŸªœ Batch step - 1542 -- sub batch step 6168 -- lr 2.31e-04
2025-03-02 14:06:05,236 - INFO - ðŸªœ Batch step - 1542 -- sub batch step 6169 -- lr 2.31e-04
2025-03-02 14:06:07,392 - INFO - ðŸªœ Batch step - 1542 -- sub batch step 6170 -- lr 2.31e-04
2025-03-02 14:06:09,562 - INFO - ðŸªœ Batch step - 1542 -- sub batch step 6171 -- lr 2.31e-04
2025-03-02 14:06:11,099 - INFO - Step 1542 -- ðŸ”„ Training Metrics
2025-03-02 14:06:11,100 - INFO - â”œâ”€â”€ Loss: 7.3356
2025-03-02 14:06:11,100 - INFO - â”œâ”€â”€ Learning Rate: 2.31e-04
2025-03-02 14:06:11,100 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:06:11,777 - INFO - ðŸªœ Batch step - 1543 -- sub batch step 6172 -- lr 2.31e-04
2025-03-02 14:06:13,932 - INFO - ðŸªœ Batch step - 1543 -- sub batch step 6173 -- lr 2.31e-04
2025-03-02 14:06:16,088 - INFO - ðŸªœ Batch step - 1543 -- sub batch step 6174 -- lr 2.31e-04
2025-03-02 14:06:18,790 - INFO - ðŸªœ Batch step - 1543 -- sub batch step 6175 -- lr 2.31e-04
2025-03-02 14:06:20,313 - INFO - Step 1543 -- ðŸ”„ Training Metrics
2025-03-02 14:06:20,313 - INFO - â”œâ”€â”€ Loss: 7.3476
2025-03-02 14:06:20,313 - INFO - â”œâ”€â”€ Learning Rate: 2.31e-04
2025-03-02 14:06:20,313 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:06:20,980 - INFO - ðŸªœ Batch step - 1544 -- sub batch step 6176 -- lr 2.32e-04
2025-03-02 14:06:23,141 - INFO - ðŸªœ Batch step - 1544 -- sub batch step 6177 -- lr 2.32e-04
2025-03-02 14:06:25,292 - INFO - ðŸªœ Batch step - 1544 -- sub batch step 6178 -- lr 2.32e-04
2025-03-02 14:06:27,463 - INFO - ðŸªœ Batch step - 1544 -- sub batch step 6179 -- lr 2.32e-04
2025-03-02 14:06:29,011 - INFO - Step 1544 -- ðŸ”„ Training Metrics
2025-03-02 14:06:29,012 - INFO - â”œâ”€â”€ Loss: 7.3678
2025-03-02 14:06:29,012 - INFO - â”œâ”€â”€ Learning Rate: 2.32e-04
2025-03-02 14:06:29,012 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:06:29,687 - INFO - ðŸªœ Batch step - 1545 -- sub batch step 6180 -- lr 2.32e-04
2025-03-02 14:06:31,842 - INFO - ðŸªœ Batch step - 1545 -- sub batch step 6181 -- lr 2.32e-04
2025-03-02 14:06:33,995 - INFO - ðŸªœ Batch step - 1545 -- sub batch step 6182 -- lr 2.32e-04
2025-03-02 14:06:36,655 - INFO - ðŸªœ Batch step - 1545 -- sub batch step 6183 -- lr 2.32e-04
2025-03-02 14:06:38,217 - INFO - Step 1545 -- ðŸ”„ Training Metrics
2025-03-02 14:06:38,217 - INFO - â”œâ”€â”€ Loss: 7.3224
2025-03-02 14:06:38,217 - INFO - â”œâ”€â”€ Learning Rate: 2.32e-04
2025-03-02 14:06:38,218 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:06:38,891 - INFO - ðŸªœ Batch step - 1546 -- sub batch step 6184 -- lr 2.32e-04
2025-03-02 14:06:41,046 - INFO - ðŸªœ Batch step - 1546 -- sub batch step 6185 -- lr 2.32e-04
2025-03-02 14:06:43,193 - INFO - ðŸªœ Batch step - 1546 -- sub batch step 6186 -- lr 2.32e-04
2025-03-02 14:06:45,370 - INFO - ðŸªœ Batch step - 1546 -- sub batch step 6187 -- lr 2.32e-04
2025-03-02 14:06:46,938 - INFO - Step 1546 -- ðŸ”„ Training Metrics
2025-03-02 14:06:46,938 - INFO - â”œâ”€â”€ Loss: 7.3248
2025-03-02 14:06:46,938 - INFO - â”œâ”€â”€ Learning Rate: 2.32e-04
2025-03-02 14:06:46,938 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:06:47,606 - INFO - ðŸªœ Batch step - 1547 -- sub batch step 6188 -- lr 2.32e-04
2025-03-02 14:06:49,763 - INFO - ðŸªœ Batch step - 1547 -- sub batch step 6189 -- lr 2.32e-04
2025-03-02 14:06:51,917 - INFO - ðŸªœ Batch step - 1547 -- sub batch step 6190 -- lr 2.32e-04
2025-03-02 14:06:54,298 - INFO - ðŸªœ Batch step - 1547 -- sub batch step 6191 -- lr 2.32e-04
2025-03-02 14:06:56,266 - INFO - Step 1547 -- ðŸ”„ Training Metrics
2025-03-02 14:06:56,266 - INFO - â”œâ”€â”€ Loss: 7.3539
2025-03-02 14:06:56,266 - INFO - â”œâ”€â”€ Learning Rate: 2.32e-04
2025-03-02 14:06:56,266 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:06:56,943 - INFO - ðŸªœ Batch step - 1548 -- sub batch step 6192 -- lr 2.32e-04
2025-03-02 14:06:59,095 - INFO - ðŸªœ Batch step - 1548 -- sub batch step 6193 -- lr 2.32e-04
2025-03-02 14:07:01,247 - INFO - ðŸªœ Batch step - 1548 -- sub batch step 6194 -- lr 2.32e-04
2025-03-02 14:07:03,413 - INFO - ðŸªœ Batch step - 1548 -- sub batch step 6195 -- lr 2.32e-04
2025-03-02 14:07:04,958 - INFO - Step 1548 -- ðŸ”„ Training Metrics
2025-03-02 14:07:04,958 - INFO - â”œâ”€â”€ Loss: 7.3407
2025-03-02 14:07:04,958 - INFO - â”œâ”€â”€ Learning Rate: 2.32e-04
2025-03-02 14:07:04,958 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:07:05,629 - INFO - ðŸªœ Batch step - 1549 -- sub batch step 6196 -- lr 2.32e-04
2025-03-02 14:07:07,783 - INFO - ðŸªœ Batch step - 1549 -- sub batch step 6197 -- lr 2.32e-04
2025-03-02 14:07:09,933 - INFO - ðŸªœ Batch step - 1549 -- sub batch step 6198 -- lr 2.32e-04
2025-03-02 14:07:12,636 - INFO - ðŸªœ Batch step - 1549 -- sub batch step 6199 -- lr 2.32e-04
2025-03-02 14:07:14,178 - INFO - Step 1549 -- ðŸ”„ Training Metrics
2025-03-02 14:07:14,178 - INFO - â”œâ”€â”€ Loss: 7.3418
2025-03-02 14:07:14,178 - INFO - â”œâ”€â”€ Learning Rate: 2.32e-04
2025-03-02 14:07:14,178 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:07:14,857 - INFO - ðŸªœ Batch step - 1550 -- sub batch step 6200 -- lr 2.32e-04
2025-03-02 14:07:17,005 - INFO - ðŸªœ Batch step - 1550 -- sub batch step 6201 -- lr 2.32e-04
2025-03-02 14:07:19,160 - INFO - ðŸªœ Batch step - 1550 -- sub batch step 6202 -- lr 2.32e-04
2025-03-02 14:07:21,320 - INFO - ðŸªœ Batch step - 1550 -- sub batch step 6203 -- lr 2.32e-04
2025-03-02 14:07:22,874 - INFO - Step 1550 -- ðŸ”„ Training Metrics
2025-03-02 14:07:22,874 - INFO - â”œâ”€â”€ Loss: 7.3514
2025-03-02 14:07:22,874 - INFO - â”œâ”€â”€ Learning Rate: 2.32e-04
2025-03-02 14:07:22,874 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:07:23,548 - INFO - ðŸªœ Batch step - 1551 -- sub batch step 6204 -- lr 2.33e-04
2025-03-02 14:07:25,702 - INFO - ðŸªœ Batch step - 1551 -- sub batch step 6205 -- lr 2.33e-04
2025-03-02 14:07:28,085 - INFO - ðŸªœ Batch step - 1551 -- sub batch step 6206 -- lr 2.33e-04
2025-03-02 14:07:30,242 - INFO - ðŸªœ Batch step - 1551 -- sub batch step 6207 -- lr 2.33e-04
2025-03-02 14:07:32,521 - INFO - Step 1551 -- ðŸ”„ Training Metrics
2025-03-02 14:07:32,521 - INFO - â”œâ”€â”€ Loss: 7.3441
2025-03-02 14:07:32,521 - INFO - â”œâ”€â”€ Learning Rate: 2.33e-04
2025-03-02 14:07:32,521 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:07:33,188 - INFO - ðŸªœ Batch step - 1552 -- sub batch step 6208 -- lr 2.33e-04
2025-03-02 14:07:35,346 - INFO - ðŸªœ Batch step - 1552 -- sub batch step 6209 -- lr 2.33e-04
2025-03-02 14:07:37,514 - INFO - ðŸªœ Batch step - 1552 -- sub batch step 6210 -- lr 2.33e-04
2025-03-02 14:07:39,663 - INFO - ðŸªœ Batch step - 1552 -- sub batch step 6211 -- lr 2.33e-04
2025-03-02 14:07:41,218 - INFO - Step 1552 -- ðŸ”„ Training Metrics
2025-03-02 14:07:41,218 - INFO - â”œâ”€â”€ Loss: 7.3242
2025-03-02 14:07:41,218 - INFO - â”œâ”€â”€ Learning Rate: 2.33e-04
2025-03-02 14:07:41,218 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:07:41,895 - INFO - ðŸªœ Batch step - 1553 -- sub batch step 6212 -- lr 2.33e-04
2025-03-02 14:07:44,048 - INFO - ðŸªœ Batch step - 1553 -- sub batch step 6213 -- lr 2.33e-04
2025-03-02 14:07:46,757 - INFO - ðŸªœ Batch step - 1553 -- sub batch step 6214 -- lr 2.33e-04
2025-03-02 14:07:48,913 - INFO - ðŸªœ Batch step - 1553 -- sub batch step 6215 -- lr 2.33e-04
2025-03-02 14:07:50,523 - INFO - Step 1553 -- ðŸ”„ Training Metrics
2025-03-02 14:07:50,523 - INFO - â”œâ”€â”€ Loss: 7.3224
2025-03-02 14:07:50,523 - INFO - â”œâ”€â”€ Learning Rate: 2.33e-04
2025-03-02 14:07:50,523 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:07:51,195 - INFO - ðŸªœ Batch step - 1554 -- sub batch step 6216 -- lr 2.33e-04
2025-03-02 14:07:53,352 - INFO - ðŸªœ Batch step - 1554 -- sub batch step 6217 -- lr 2.33e-04
2025-03-02 14:07:55,514 - INFO - ðŸªœ Batch step - 1554 -- sub batch step 6218 -- lr 2.33e-04
2025-03-02 14:07:57,668 - INFO - ðŸªœ Batch step - 1554 -- sub batch step 6219 -- lr 2.33e-04
2025-03-02 14:07:59,220 - INFO - Step 1554 -- ðŸ”„ Training Metrics
2025-03-02 14:07:59,220 - INFO - â”œâ”€â”€ Loss: 7.3084
2025-03-02 14:07:59,220 - INFO - â”œâ”€â”€ Learning Rate: 2.33e-04
2025-03-02 14:07:59,220 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:07:59,896 - INFO - ðŸªœ Batch step - 1555 -- sub batch step 6220 -- lr 2.33e-04
2025-03-02 14:08:02,046 - INFO - ðŸªœ Batch step - 1555 -- sub batch step 6221 -- lr 2.33e-04
2025-03-02 14:08:04,716 - INFO - ðŸªœ Batch step - 1555 -- sub batch step 6222 -- lr 2.33e-04
2025-03-02 14:08:06,868 - INFO - ðŸªœ Batch step - 1555 -- sub batch step 6223 -- lr 2.33e-04
2025-03-02 14:08:08,412 - INFO - Step 1555 -- ðŸ”„ Training Metrics
2025-03-02 14:08:08,412 - INFO - â”œâ”€â”€ Loss: 7.3256
2025-03-02 14:08:08,412 - INFO - â”œâ”€â”€ Learning Rate: 2.33e-04
2025-03-02 14:08:08,412 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:08:09,089 - INFO - ðŸªœ Batch step - 1556 -- sub batch step 6224 -- lr 2.33e-04
2025-03-02 14:08:11,242 - INFO - ðŸªœ Batch step - 1556 -- sub batch step 6225 -- lr 2.33e-04
2025-03-02 14:08:13,408 - INFO - ðŸªœ Batch step - 1556 -- sub batch step 6226 -- lr 2.33e-04
2025-03-02 14:08:15,563 - INFO - ðŸªœ Batch step - 1556 -- sub batch step 6227 -- lr 2.33e-04
2025-03-02 14:08:17,119 - INFO - Step 1556 -- ðŸ”„ Training Metrics
2025-03-02 14:08:17,119 - INFO - â”œâ”€â”€ Loss: 7.3413
2025-03-02 14:08:17,119 - INFO - â”œâ”€â”€ Learning Rate: 2.33e-04
2025-03-02 14:08:17,120 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:08:17,787 - INFO - ðŸªœ Batch step - 1557 -- sub batch step 6228 -- lr 2.34e-04
2025-03-02 14:08:19,946 - INFO - ðŸªœ Batch step - 1557 -- sub batch step 6229 -- lr 2.34e-04
2025-03-02 14:08:22,667 - INFO - ðŸªœ Batch step - 1557 -- sub batch step 6230 -- lr 2.34e-04
2025-03-02 14:08:24,823 - INFO - ðŸªœ Batch step - 1557 -- sub batch step 6231 -- lr 2.34e-04
2025-03-02 14:08:26,371 - INFO - Step 1557 -- ðŸ”„ Training Metrics
2025-03-02 14:08:26,372 - INFO - â”œâ”€â”€ Loss: 7.3175
2025-03-02 14:08:26,372 - INFO - â”œâ”€â”€ Learning Rate: 2.34e-04
2025-03-02 14:08:26,372 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:08:27,047 - INFO - ðŸªœ Batch step - 1558 -- sub batch step 6232 -- lr 2.34e-04
2025-03-02 14:08:29,199 - INFO - ðŸªœ Batch step - 1558 -- sub batch step 6233 -- lr 2.34e-04
2025-03-02 14:08:31,366 - INFO - ðŸªœ Batch step - 1558 -- sub batch step 6234 -- lr 2.34e-04
2025-03-02 14:08:33,520 - INFO - ðŸªœ Batch step - 1558 -- sub batch step 6235 -- lr 2.34e-04
2025-03-02 14:08:35,066 - INFO - Step 1558 -- ðŸ”„ Training Metrics
2025-03-02 14:08:35,066 - INFO - â”œâ”€â”€ Loss: 7.2989
2025-03-02 14:08:35,066 - INFO - â”œâ”€â”€ Learning Rate: 2.34e-04
2025-03-02 14:08:35,066 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:08:35,735 - INFO - ðŸªœ Batch step - 1559 -- sub batch step 6236 -- lr 2.34e-04
2025-03-02 14:08:37,892 - INFO - ðŸªœ Batch step - 1559 -- sub batch step 6237 -- lr 2.34e-04
2025-03-02 14:08:40,172 - INFO - ðŸªœ Batch step - 1559 -- sub batch step 6238 -- lr 2.34e-04
2025-03-02 14:08:42,328 - INFO - ðŸªœ Batch step - 1559 -- sub batch step 6239 -- lr 2.34e-04
2025-03-02 14:08:43,905 - INFO - Step 1559 -- ðŸ”„ Training Metrics
2025-03-02 14:08:43,905 - INFO - â”œâ”€â”€ Loss: 7.3270
2025-03-02 14:08:43,905 - INFO - â”œâ”€â”€ Learning Rate: 2.34e-04
2025-03-02 14:08:43,905 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:08:45,037 - INFO - ðŸªœ Batch step - 1560 -- sub batch step 6240 -- lr 2.34e-04
2025-03-02 14:08:47,192 - INFO - ðŸªœ Batch step - 1560 -- sub batch step 6241 -- lr 2.34e-04
2025-03-02 14:08:49,351 - INFO - ðŸªœ Batch step - 1560 -- sub batch step 6242 -- lr 2.34e-04
2025-03-02 14:08:51,520 - INFO - ðŸªœ Batch step - 1560 -- sub batch step 6243 -- lr 2.34e-04
2025-03-02 14:08:53,237 - INFO - Step 1560 -- ðŸ”„ Training Metrics
2025-03-02 14:08:53,237 - INFO - â”œâ”€â”€ Loss: 7.3549
2025-03-02 14:08:53,237 - INFO - â”œâ”€â”€ Learning Rate: 2.34e-04
2025-03-02 14:08:53,237 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:08:53,909 - INFO - ðŸªœ Batch step - 1561 -- sub batch step 6244 -- lr 2.34e-04
2025-03-02 14:08:56,060 - INFO - ðŸªœ Batch step - 1561 -- sub batch step 6245 -- lr 2.34e-04
2025-03-02 14:08:58,208 - INFO - ðŸªœ Batch step - 1561 -- sub batch step 6246 -- lr 2.34e-04
2025-03-02 14:09:00,624 - INFO - ðŸªœ Batch step - 1561 -- sub batch step 6247 -- lr 2.34e-04
2025-03-02 14:09:02,508 - INFO - Step 1561 -- ðŸ”„ Training Metrics
2025-03-02 14:09:02,508 - INFO - â”œâ”€â”€ Loss: 7.3273
2025-03-02 14:09:02,508 - INFO - â”œâ”€â”€ Learning Rate: 2.34e-04
2025-03-02 14:09:02,508 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:09:03,173 - INFO - ðŸªœ Batch step - 1562 -- sub batch step 6248 -- lr 2.34e-04
2025-03-02 14:09:05,328 - INFO - ðŸªœ Batch step - 1562 -- sub batch step 6249 -- lr 2.34e-04
2025-03-02 14:09:07,483 - INFO - ðŸªœ Batch step - 1562 -- sub batch step 6250 -- lr 2.34e-04
2025-03-02 14:09:09,644 - INFO - ðŸªœ Batch step - 1562 -- sub batch step 6251 -- lr 2.34e-04
2025-03-02 14:09:11,211 - INFO - Step 1562 -- ðŸ”„ Training Metrics
2025-03-02 14:09:11,212 - INFO - â”œâ”€â”€ Loss: 7.3320
2025-03-02 14:09:11,212 - INFO - â”œâ”€â”€ Learning Rate: 2.34e-04
2025-03-02 14:09:11,212 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:09:11,886 - INFO - ðŸªœ Batch step - 1563 -- sub batch step 6252 -- lr 2.34e-04
2025-03-02 14:09:14,036 - INFO - ðŸªœ Batch step - 1563 -- sub batch step 6253 -- lr 2.34e-04
2025-03-02 14:09:16,194 - INFO - ðŸªœ Batch step - 1563 -- sub batch step 6254 -- lr 2.34e-04
2025-03-02 14:09:18,923 - INFO - ðŸªœ Batch step - 1563 -- sub batch step 6255 -- lr 2.34e-04
2025-03-02 14:09:20,429 - INFO - Step 1563 -- ðŸ”„ Training Metrics
2025-03-02 14:09:20,429 - INFO - â”œâ”€â”€ Loss: 7.3328
2025-03-02 14:09:20,429 - INFO - â”œâ”€â”€ Learning Rate: 2.34e-04
2025-03-02 14:09:20,429 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:09:21,095 - INFO - ðŸªœ Batch step - 1564 -- sub batch step 6256 -- lr 2.35e-04
2025-03-02 14:09:23,251 - INFO - ðŸªœ Batch step - 1564 -- sub batch step 6257 -- lr 2.35e-04
2025-03-02 14:09:25,398 - INFO - ðŸªœ Batch step - 1564 -- sub batch step 6258 -- lr 2.35e-04
2025-03-02 14:09:27,565 - INFO - ðŸªœ Batch step - 1564 -- sub batch step 6259 -- lr 2.35e-04
2025-03-02 14:09:29,114 - INFO - Step 1564 -- ðŸ”„ Training Metrics
2025-03-02 14:09:29,114 - INFO - â”œâ”€â”€ Loss: 7.3309
2025-03-02 14:09:29,114 - INFO - â”œâ”€â”€ Learning Rate: 2.35e-04
2025-03-02 14:09:29,114 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:09:29,789 - INFO - ðŸªœ Batch step - 1565 -- sub batch step 6260 -- lr 2.35e-04
2025-03-02 14:09:31,940 - INFO - ðŸªœ Batch step - 1565 -- sub batch step 6261 -- lr 2.35e-04
2025-03-02 14:09:34,092 - INFO - ðŸªœ Batch step - 1565 -- sub batch step 6262 -- lr 2.35e-04
2025-03-02 14:09:36,500 - INFO - ðŸªœ Batch step - 1565 -- sub batch step 6263 -- lr 2.35e-04
2025-03-02 14:09:38,420 - INFO - Step 1565 -- ðŸ”„ Training Metrics
2025-03-02 14:09:38,421 - INFO - â”œâ”€â”€ Loss: 7.3330
2025-03-02 14:09:38,421 - INFO - â”œâ”€â”€ Learning Rate: 2.35e-04
2025-03-02 14:09:38,421 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:09:39,095 - INFO - ðŸªœ Batch step - 1566 -- sub batch step 6264 -- lr 2.35e-04
2025-03-02 14:09:41,249 - INFO - ðŸªœ Batch step - 1566 -- sub batch step 6265 -- lr 2.35e-04
2025-03-02 14:09:43,413 - INFO - ðŸªœ Batch step - 1566 -- sub batch step 6266 -- lr 2.35e-04
2025-03-02 14:09:45,584 - INFO - ðŸªœ Batch step - 1566 -- sub batch step 6267 -- lr 2.35e-04
2025-03-02 14:09:47,114 - INFO - Step 1566 -- ðŸ”„ Training Metrics
2025-03-02 14:09:47,114 - INFO - â”œâ”€â”€ Loss: 7.3276
2025-03-02 14:09:47,114 - INFO - â”œâ”€â”€ Learning Rate: 2.35e-04
2025-03-02 14:09:47,114 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:09:47,779 - INFO - ðŸªœ Batch step - 1567 -- sub batch step 6268 -- lr 2.35e-04
2025-03-02 14:09:49,938 - INFO - ðŸªœ Batch step - 1567 -- sub batch step 6269 -- lr 2.35e-04
2025-03-02 14:09:52,089 - INFO - ðŸªœ Batch step - 1567 -- sub batch step 6270 -- lr 2.35e-04
2025-03-02 14:09:54,434 - INFO - ðŸªœ Batch step - 1567 -- sub batch step 6271 -- lr 2.35e-04
2025-03-02 14:09:56,773 - INFO - Step 1567 -- ðŸ”„ Training Metrics
2025-03-02 14:09:56,773 - INFO - â”œâ”€â”€ Loss: 7.3243
2025-03-02 14:09:56,774 - INFO - â”œâ”€â”€ Learning Rate: 2.35e-04
2025-03-02 14:09:56,774 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:09:57,446 - INFO - ðŸªœ Batch step - 1568 -- sub batch step 6272 -- lr 2.35e-04
2025-03-02 14:09:59,598 - INFO - ðŸªœ Batch step - 1568 -- sub batch step 6273 -- lr 2.35e-04
2025-03-02 14:10:01,755 - INFO - ðŸªœ Batch step - 1568 -- sub batch step 6274 -- lr 2.35e-04
2025-03-02 14:10:03,929 - INFO - ðŸªœ Batch step - 1568 -- sub batch step 6275 -- lr 2.35e-04
2025-03-02 14:10:05,470 - INFO - Step 1568 -- ðŸ”„ Training Metrics
2025-03-02 14:10:05,471 - INFO - â”œâ”€â”€ Loss: 7.3247
2025-03-02 14:10:05,471 - INFO - â”œâ”€â”€ Learning Rate: 2.35e-04
2025-03-02 14:10:05,471 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:10:06,139 - INFO - ðŸªœ Batch step - 1569 -- sub batch step 6276 -- lr 2.35e-04
2025-03-02 14:10:08,297 - INFO - ðŸªœ Batch step - 1569 -- sub batch step 6277 -- lr 2.35e-04
2025-03-02 14:10:10,445 - INFO - ðŸªœ Batch step - 1569 -- sub batch step 6278 -- lr 2.35e-04
2025-03-02 14:10:12,806 - INFO - ðŸªœ Batch step - 1569 -- sub batch step 6279 -- lr 2.35e-04
2025-03-02 14:10:14,727 - INFO - Step 1569 -- ðŸ”„ Training Metrics
2025-03-02 14:10:14,727 - INFO - â”œâ”€â”€ Loss: 7.3254
2025-03-02 14:10:14,727 - INFO - â”œâ”€â”€ Learning Rate: 2.35e-04
2025-03-02 14:10:14,727 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:10:15,402 - INFO - ðŸªœ Batch step - 1570 -- sub batch step 6280 -- lr 2.35e-04
2025-03-02 14:10:17,553 - INFO - ðŸªœ Batch step - 1570 -- sub batch step 6281 -- lr 2.35e-04
2025-03-02 14:10:19,705 - INFO - ðŸªœ Batch step - 1570 -- sub batch step 6282 -- lr 2.35e-04
2025-03-02 14:10:21,872 - INFO - ðŸªœ Batch step - 1570 -- sub batch step 6283 -- lr 2.35e-04
2025-03-02 14:10:23,415 - INFO - Step 1570 -- ðŸ”„ Training Metrics
2025-03-02 14:10:23,415 - INFO - â”œâ”€â”€ Loss: 7.3489
2025-03-02 14:10:23,416 - INFO - â”œâ”€â”€ Learning Rate: 2.35e-04
2025-03-02 14:10:23,416 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:10:24,091 - INFO - ðŸªœ Batch step - 1571 -- sub batch step 6284 -- lr 2.36e-04
2025-03-02 14:10:26,245 - INFO - ðŸªœ Batch step - 1571 -- sub batch step 6285 -- lr 2.36e-04
2025-03-02 14:10:28,709 - INFO - ðŸªœ Batch step - 1571 -- sub batch step 6286 -- lr 2.36e-04
2025-03-02 14:10:30,862 - INFO - ðŸªœ Batch step - 1571 -- sub batch step 6287 -- lr 2.36e-04
2025-03-02 14:10:32,524 - INFO - Step 1571 -- ðŸ”„ Training Metrics
2025-03-02 14:10:32,524 - INFO - â”œâ”€â”€ Loss: 7.3226
2025-03-02 14:10:32,524 - INFO - â”œâ”€â”€ Learning Rate: 2.36e-04
2025-03-02 14:10:32,524 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:10:33,189 - INFO - ðŸªœ Batch step - 1572 -- sub batch step 6288 -- lr 2.36e-04
2025-03-02 14:10:35,346 - INFO - ðŸªœ Batch step - 1572 -- sub batch step 6289 -- lr 2.36e-04
2025-03-02 14:10:37,518 - INFO - ðŸªœ Batch step - 1572 -- sub batch step 6290 -- lr 2.36e-04
2025-03-02 14:10:39,665 - INFO - ðŸªœ Batch step - 1572 -- sub batch step 6291 -- lr 2.36e-04
2025-03-02 14:10:41,203 - INFO - Step 1572 -- ðŸ”„ Training Metrics
2025-03-02 14:10:41,204 - INFO - â”œâ”€â”€ Loss: 7.3287
2025-03-02 14:10:41,204 - INFO - â”œâ”€â”€ Learning Rate: 2.36e-04
2025-03-02 14:10:41,204 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:10:41,877 - INFO - ðŸªœ Batch step - 1573 -- sub batch step 6292 -- lr 2.36e-04
2025-03-02 14:10:44,026 - INFO - ðŸªœ Batch step - 1573 -- sub batch step 6293 -- lr 2.36e-04
2025-03-02 14:10:46,705 - INFO - ðŸªœ Batch step - 1573 -- sub batch step 6294 -- lr 2.36e-04
2025-03-02 14:10:48,862 - INFO - ðŸªœ Batch step - 1573 -- sub batch step 6295 -- lr 2.36e-04
2025-03-02 14:10:50,352 - INFO - Step 1573 -- ðŸ”„ Training Metrics
2025-03-02 14:10:50,353 - INFO - â”œâ”€â”€ Loss: 7.3318
2025-03-02 14:10:50,353 - INFO - â”œâ”€â”€ Learning Rate: 2.36e-04
2025-03-02 14:10:50,353 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:10:51,019 - INFO - ðŸªœ Batch step - 1574 -- sub batch step 6296 -- lr 2.36e-04
2025-03-02 14:10:53,174 - INFO - ðŸªœ Batch step - 1574 -- sub batch step 6297 -- lr 2.36e-04
2025-03-02 14:10:55,337 - INFO - ðŸªœ Batch step - 1574 -- sub batch step 6298 -- lr 2.36e-04
2025-03-02 14:10:57,494 - INFO - ðŸªœ Batch step - 1574 -- sub batch step 6299 -- lr 2.36e-04
2025-03-02 14:10:59,044 - INFO - Step 1574 -- ðŸ”„ Training Metrics
2025-03-02 14:10:59,045 - INFO - â”œâ”€â”€ Loss: 7.2908
2025-03-02 14:10:59,045 - INFO - â”œâ”€â”€ Learning Rate: 2.36e-04
2025-03-02 14:10:59,045 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:10:59,716 - INFO - ðŸªœ Batch step - 1575 -- sub batch step 6300 -- lr 2.36e-04
2025-03-02 14:11:01,866 - INFO - ðŸªœ Batch step - 1575 -- sub batch step 6301 -- lr 2.36e-04
2025-03-02 14:11:04,753 - INFO - ðŸªœ Batch step - 1575 -- sub batch step 6302 -- lr 2.36e-04
2025-03-02 14:11:06,908 - INFO - ðŸªœ Batch step - 1575 -- sub batch step 6303 -- lr 2.36e-04
2025-03-02 14:11:08,399 - INFO - Step 1575 -- ðŸ”„ Training Metrics
2025-03-02 14:11:08,400 - INFO - â”œâ”€â”€ Loss: 7.3072
2025-03-02 14:11:08,400 - INFO - â”œâ”€â”€ Learning Rate: 2.36e-04
2025-03-02 14:11:08,400 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:11:09,072 - INFO - ðŸªœ Batch step - 1576 -- sub batch step 6304 -- lr 2.36e-04
2025-03-02 14:11:11,232 - INFO - ðŸªœ Batch step - 1576 -- sub batch step 6305 -- lr 2.36e-04
2025-03-02 14:11:13,396 - INFO - ðŸªœ Batch step - 1576 -- sub batch step 6306 -- lr 2.36e-04
2025-03-02 14:11:15,552 - INFO - ðŸªœ Batch step - 1576 -- sub batch step 6307 -- lr 2.36e-04
2025-03-02 14:11:17,097 - INFO - Step 1576 -- ðŸ”„ Training Metrics
2025-03-02 14:11:17,097 - INFO - â”œâ”€â”€ Loss: 7.3238
2025-03-02 14:11:17,097 - INFO - â”œâ”€â”€ Learning Rate: 2.36e-04
2025-03-02 14:11:17,097 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:11:17,767 - INFO - ðŸªœ Batch step - 1577 -- sub batch step 6308 -- lr 2.37e-04
2025-03-02 14:11:19,924 - INFO - ðŸªœ Batch step - 1577 -- sub batch step 6309 -- lr 2.37e-04
2025-03-02 14:11:22,656 - INFO - ðŸªœ Batch step - 1577 -- sub batch step 6310 -- lr 2.37e-04
2025-03-02 14:11:24,804 - INFO - ðŸªœ Batch step - 1577 -- sub batch step 6311 -- lr 2.37e-04
2025-03-02 14:11:26,383 - INFO - Step 1577 -- ðŸ”„ Training Metrics
2025-03-02 14:11:26,383 - INFO - â”œâ”€â”€ Loss: 7.3329
2025-03-02 14:11:26,383 - INFO - â”œâ”€â”€ Learning Rate: 2.37e-04
2025-03-02 14:11:26,383 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:11:27,054 - INFO - ðŸªœ Batch step - 1578 -- sub batch step 6312 -- lr 2.37e-04
2025-03-02 14:11:29,203 - INFO - ðŸªœ Batch step - 1578 -- sub batch step 6313 -- lr 2.37e-04
2025-03-02 14:11:31,376 - INFO - ðŸªœ Batch step - 1578 -- sub batch step 6314 -- lr 2.37e-04
2025-03-02 14:11:33,528 - INFO - ðŸªœ Batch step - 1578 -- sub batch step 6315 -- lr 2.37e-04
2025-03-02 14:11:35,077 - INFO - Step 1578 -- ðŸ”„ Training Metrics
2025-03-02 14:11:35,078 - INFO - â”œâ”€â”€ Loss: 7.3043
2025-03-02 14:11:35,078 - INFO - â”œâ”€â”€ Learning Rate: 2.37e-04
2025-03-02 14:11:35,078 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:11:35,743 - INFO - ðŸªœ Batch step - 1579 -- sub batch step 6316 -- lr 2.37e-04
2025-03-02 14:11:37,897 - INFO - ðŸªœ Batch step - 1579 -- sub batch step 6317 -- lr 2.37e-04
2025-03-02 14:11:40,174 - INFO - ðŸªœ Batch step - 1579 -- sub batch step 6318 -- lr 2.37e-04
2025-03-02 14:11:42,333 - INFO - ðŸªœ Batch step - 1579 -- sub batch step 6319 -- lr 2.37e-04
2025-03-02 14:11:43,942 - INFO - Step 1579 -- ðŸ”„ Training Metrics
2025-03-02 14:11:43,942 - INFO - â”œâ”€â”€ Loss: 7.3197
2025-03-02 14:11:43,942 - INFO - â”œâ”€â”€ Learning Rate: 2.37e-04
2025-03-02 14:11:43,942 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:11:45,240 - INFO - ðŸªœ Batch step - 1580 -- sub batch step 6320 -- lr 2.37e-04
2025-03-02 14:11:47,391 - INFO - ðŸªœ Batch step - 1580 -- sub batch step 6321 -- lr 2.37e-04
2025-03-02 14:11:49,544 - INFO - ðŸªœ Batch step - 1580 -- sub batch step 6322 -- lr 2.37e-04
2025-03-02 14:11:51,705 - INFO - ðŸªœ Batch step - 1580 -- sub batch step 6323 -- lr 2.37e-04
2025-03-02 14:11:55,470 - INFO - Step 1580 -- ðŸ”„ Training Metrics
2025-03-02 14:11:55,470 - INFO - â”œâ”€â”€ Loss: 7.3210
2025-03-02 14:11:55,470 - INFO - â”œâ”€â”€ Learning Rate: 2.37e-04
2025-03-02 14:11:55,470 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:11:56,143 - INFO - ðŸªœ Batch step - 1581 -- sub batch step 6324 -- lr 2.37e-04
2025-03-02 14:11:58,294 - INFO - ðŸªœ Batch step - 1581 -- sub batch step 6325 -- lr 2.37e-04
2025-03-02 14:12:00,437 - INFO - ðŸªœ Batch step - 1581 -- sub batch step 6326 -- lr 2.37e-04
2025-03-02 14:12:03,086 - INFO - ðŸªœ Batch step - 1581 -- sub batch step 6327 -- lr 2.37e-04
2025-03-02 14:12:04,929 - INFO - Step 1581 -- ðŸ”„ Training Metrics
2025-03-02 14:12:04,929 - INFO - â”œâ”€â”€ Loss: 7.3108
2025-03-02 14:12:04,929 - INFO - â”œâ”€â”€ Learning Rate: 2.37e-04
2025-03-02 14:12:04,929 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:12:05,596 - INFO - ðŸªœ Batch step - 1582 -- sub batch step 6328 -- lr 2.37e-04
2025-03-02 14:12:07,758 - INFO - ðŸªœ Batch step - 1582 -- sub batch step 6329 -- lr 2.37e-04
2025-03-02 14:12:09,915 - INFO - ðŸªœ Batch step - 1582 -- sub batch step 6330 -- lr 2.37e-04
2025-03-02 14:12:12,075 - INFO - ðŸªœ Batch step - 1582 -- sub batch step 6331 -- lr 2.37e-04
2025-03-02 14:12:13,629 - INFO - Step 1582 -- ðŸ”„ Training Metrics
2025-03-02 14:12:13,630 - INFO - â”œâ”€â”€ Loss: 7.3406
2025-03-02 14:12:13,630 - INFO - â”œâ”€â”€ Learning Rate: 2.37e-04
2025-03-02 14:12:13,630 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:12:14,303 - INFO - ðŸªœ Batch step - 1583 -- sub batch step 6332 -- lr 2.37e-04
2025-03-02 14:12:16,451 - INFO - ðŸªœ Batch step - 1583 -- sub batch step 6333 -- lr 2.37e-04
2025-03-02 14:12:18,605 - INFO - ðŸªœ Batch step - 1583 -- sub batch step 6334 -- lr 2.37e-04
2025-03-02 14:12:21,307 - INFO - ðŸªœ Batch step - 1583 -- sub batch step 6335 -- lr 2.37e-04
2025-03-02 14:12:22,926 - INFO - Step 1583 -- ðŸ”„ Training Metrics
2025-03-02 14:12:22,927 - INFO - â”œâ”€â”€ Loss: 7.3056
2025-03-02 14:12:22,927 - INFO - â”œâ”€â”€ Learning Rate: 2.37e-04
2025-03-02 14:12:22,927 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:12:23,596 - INFO - ðŸªœ Batch step - 1584 -- sub batch step 6336 -- lr 2.38e-04
2025-03-02 14:12:25,748 - INFO - ðŸªœ Batch step - 1584 -- sub batch step 6337 -- lr 2.38e-04
2025-03-02 14:12:27,894 - INFO - ðŸªœ Batch step - 1584 -- sub batch step 6338 -- lr 2.38e-04
2025-03-02 14:12:30,065 - INFO - ðŸªœ Batch step - 1584 -- sub batch step 6339 -- lr 2.38e-04
2025-03-02 14:12:31,626 - INFO - Step 1584 -- ðŸ”„ Training Metrics
2025-03-02 14:12:31,626 - INFO - â”œâ”€â”€ Loss: 7.3174
2025-03-02 14:12:31,626 - INFO - â”œâ”€â”€ Learning Rate: 2.38e-04
2025-03-02 14:12:31,627 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:12:32,301 - INFO - ðŸªœ Batch step - 1585 -- sub batch step 6340 -- lr 2.38e-04
2025-03-02 14:12:34,447 - INFO - ðŸªœ Batch step - 1585 -- sub batch step 6341 -- lr 2.38e-04
2025-03-02 14:12:36,600 - INFO - ðŸªœ Batch step - 1585 -- sub batch step 6342 -- lr 2.38e-04
2025-03-02 14:12:39,293 - INFO - ðŸªœ Batch step - 1585 -- sub batch step 6343 -- lr 2.38e-04
2025-03-02 14:12:40,866 - INFO - Step 1585 -- ðŸ”„ Training Metrics
2025-03-02 14:12:40,867 - INFO - â”œâ”€â”€ Loss: 7.3397
2025-03-02 14:12:40,867 - INFO - â”œâ”€â”€ Learning Rate: 2.38e-04
2025-03-02 14:12:40,867 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:12:41,539 - INFO - ðŸªœ Batch step - 1586 -- sub batch step 6344 -- lr 2.38e-04
2025-03-02 14:12:43,690 - INFO - ðŸªœ Batch step - 1586 -- sub batch step 6345 -- lr 2.38e-04
2025-03-02 14:12:45,834 - INFO - ðŸªœ Batch step - 1586 -- sub batch step 6346 -- lr 2.38e-04
2025-03-02 14:12:48,009 - INFO - ðŸªœ Batch step - 1586 -- sub batch step 6347 -- lr 2.38e-04
2025-03-02 14:12:49,567 - INFO - Step 1586 -- ðŸ”„ Training Metrics
2025-03-02 14:12:49,567 - INFO - â”œâ”€â”€ Loss: 7.3288
2025-03-02 14:12:49,567 - INFO - â”œâ”€â”€ Learning Rate: 2.38e-04
2025-03-02 14:12:49,567 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:12:50,234 - INFO - ðŸªœ Batch step - 1587 -- sub batch step 6348 -- lr 2.38e-04
2025-03-02 14:12:52,387 - INFO - ðŸªœ Batch step - 1587 -- sub batch step 6349 -- lr 2.38e-04
2025-03-02 14:12:54,539 - INFO - ðŸªœ Batch step - 1587 -- sub batch step 6350 -- lr 2.38e-04
2025-03-02 14:12:56,906 - INFO - ðŸªœ Batch step - 1587 -- sub batch step 6351 -- lr 2.38e-04
2025-03-02 14:12:58,743 - INFO - Step 1587 -- ðŸ”„ Training Metrics
2025-03-02 14:12:58,743 - INFO - â”œâ”€â”€ Loss: 7.3327
2025-03-02 14:12:58,743 - INFO - â”œâ”€â”€ Learning Rate: 2.38e-04
2025-03-02 14:12:58,743 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:12:59,419 - INFO - ðŸªœ Batch step - 1588 -- sub batch step 6352 -- lr 2.38e-04
2025-03-02 14:13:01,565 - INFO - ðŸªœ Batch step - 1588 -- sub batch step 6353 -- lr 2.38e-04
2025-03-02 14:13:03,716 - INFO - ðŸªœ Batch step - 1588 -- sub batch step 6354 -- lr 2.38e-04
2025-03-02 14:13:05,886 - INFO - ðŸªœ Batch step - 1588 -- sub batch step 6355 -- lr 2.38e-04
2025-03-02 14:13:07,453 - INFO - Step 1588 -- ðŸ”„ Training Metrics
2025-03-02 14:13:07,454 - INFO - â”œâ”€â”€ Loss: 7.3190
2025-03-02 14:13:07,454 - INFO - â”œâ”€â”€ Learning Rate: 2.38e-04
2025-03-02 14:13:07,454 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:13:08,119 - INFO - ðŸªœ Batch step - 1589 -- sub batch step 6356 -- lr 2.38e-04
2025-03-02 14:13:10,269 - INFO - ðŸªœ Batch step - 1589 -- sub batch step 6357 -- lr 2.38e-04
2025-03-02 14:13:12,415 - INFO - ðŸªœ Batch step - 1589 -- sub batch step 6358 -- lr 2.38e-04
2025-03-02 14:13:15,099 - INFO - ðŸªœ Batch step - 1589 -- sub batch step 6359 -- lr 2.38e-04
2025-03-02 14:13:16,596 - INFO - Step 1589 -- ðŸ”„ Training Metrics
2025-03-02 14:13:16,597 - INFO - â”œâ”€â”€ Loss: 7.3122
2025-03-02 14:13:16,597 - INFO - â”œâ”€â”€ Learning Rate: 2.38e-04
2025-03-02 14:13:16,597 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:13:17,271 - INFO - ðŸªœ Batch step - 1590 -- sub batch step 6360 -- lr 2.38e-04
2025-03-02 14:13:19,417 - INFO - ðŸªœ Batch step - 1590 -- sub batch step 6361 -- lr 2.38e-04
2025-03-02 14:13:21,568 - INFO - ðŸªœ Batch step - 1590 -- sub batch step 6362 -- lr 2.38e-04
2025-03-02 14:13:23,732 - INFO - ðŸªœ Batch step - 1590 -- sub batch step 6363 -- lr 2.38e-04
2025-03-02 14:13:25,278 - INFO - Step 1590 -- ðŸ”„ Training Metrics
2025-03-02 14:13:25,278 - INFO - â”œâ”€â”€ Loss: 7.3224
2025-03-02 14:13:25,279 - INFO - â”œâ”€â”€ Learning Rate: 2.38e-04
2025-03-02 14:13:25,279 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:13:25,952 - INFO - ðŸªœ Batch step - 1591 -- sub batch step 6364 -- lr 2.39e-04
2025-03-02 14:13:28,104 - INFO - ðŸªœ Batch step - 1591 -- sub batch step 6365 -- lr 2.39e-04
2025-03-02 14:13:30,725 - INFO - ðŸªœ Batch step - 1591 -- sub batch step 6366 -- lr 2.39e-04
2025-03-02 14:13:32,877 - INFO - ðŸªœ Batch step - 1591 -- sub batch step 6367 -- lr 2.39e-04
2025-03-02 14:13:34,618 - INFO - Step 1591 -- ðŸ”„ Training Metrics
2025-03-02 14:13:34,618 - INFO - â”œâ”€â”€ Loss: 7.2989
2025-03-02 14:13:34,618 - INFO - â”œâ”€â”€ Learning Rate: 2.39e-04
2025-03-02 14:13:34,618 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:13:35,285 - INFO - ðŸªœ Batch step - 1592 -- sub batch step 6368 -- lr 2.39e-04
2025-03-02 14:13:37,438 - INFO - ðŸªœ Batch step - 1592 -- sub batch step 6369 -- lr 2.39e-04
2025-03-02 14:13:39,608 - INFO - ðŸªœ Batch step - 1592 -- sub batch step 6370 -- lr 2.39e-04
2025-03-02 14:13:41,754 - INFO - ðŸªœ Batch step - 1592 -- sub batch step 6371 -- lr 2.39e-04
2025-03-02 14:13:43,308 - INFO - Step 1592 -- ðŸ”„ Training Metrics
2025-03-02 14:13:43,308 - INFO - â”œâ”€â”€ Loss: 7.3189
2025-03-02 14:13:43,309 - INFO - â”œâ”€â”€ Learning Rate: 2.39e-04
2025-03-02 14:13:43,309 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:13:43,978 - INFO - ðŸªœ Batch step - 1593 -- sub batch step 6372 -- lr 2.39e-04
2025-03-02 14:13:46,122 - INFO - ðŸªœ Batch step - 1593 -- sub batch step 6373 -- lr 2.39e-04
2025-03-02 14:13:48,812 - INFO - ðŸªœ Batch step - 1593 -- sub batch step 6374 -- lr 2.39e-04
2025-03-02 14:13:50,964 - INFO - ðŸªœ Batch step - 1593 -- sub batch step 6375 -- lr 2.39e-04
2025-03-02 14:13:52,449 - INFO - Step 1593 -- ðŸ”„ Training Metrics
2025-03-02 14:13:52,449 - INFO - â”œâ”€â”€ Loss: 7.2846
2025-03-02 14:13:52,449 - INFO - â”œâ”€â”€ Learning Rate: 2.39e-04
2025-03-02 14:13:52,449 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:13:53,116 - INFO - ðŸªœ Batch step - 1594 -- sub batch step 6376 -- lr 2.39e-04
2025-03-02 14:13:55,269 - INFO - ðŸªœ Batch step - 1594 -- sub batch step 6377 -- lr 2.39e-04
2025-03-02 14:13:57,433 - INFO - ðŸªœ Batch step - 1594 -- sub batch step 6378 -- lr 2.39e-04
2025-03-02 14:13:59,586 - INFO - ðŸªœ Batch step - 1594 -- sub batch step 6379 -- lr 2.39e-04
2025-03-02 14:14:01,138 - INFO - Step 1594 -- ðŸ”„ Training Metrics
2025-03-02 14:14:01,138 - INFO - â”œâ”€â”€ Loss: 7.2962
2025-03-02 14:14:01,138 - INFO - â”œâ”€â”€ Learning Rate: 2.39e-04
2025-03-02 14:14:01,138 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:14:01,810 - INFO - ðŸªœ Batch step - 1595 -- sub batch step 6380 -- lr 2.39e-04
2025-03-02 14:14:03,959 - INFO - ðŸªœ Batch step - 1595 -- sub batch step 6381 -- lr 2.39e-04
2025-03-02 14:14:06,395 - INFO - ðŸªœ Batch step - 1595 -- sub batch step 6382 -- lr 2.39e-04
2025-03-02 14:14:08,545 - INFO - ðŸªœ Batch step - 1595 -- sub batch step 6383 -- lr 2.39e-04
2025-03-02 14:14:10,268 - INFO - Step 1595 -- ðŸ”„ Training Metrics
2025-03-02 14:14:10,268 - INFO - â”œâ”€â”€ Loss: 7.3359
2025-03-02 14:14:10,269 - INFO - â”œâ”€â”€ Learning Rate: 2.39e-04
2025-03-02 14:14:10,269 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:14:10,939 - INFO - ðŸªœ Batch step - 1596 -- sub batch step 6384 -- lr 2.39e-04
2025-03-02 14:14:13,091 - INFO - ðŸªœ Batch step - 1596 -- sub batch step 6385 -- lr 2.39e-04
2025-03-02 14:14:15,254 - INFO - ðŸªœ Batch step - 1596 -- sub batch step 6386 -- lr 2.39e-04
2025-03-02 14:14:17,408 - INFO - ðŸªœ Batch step - 1596 -- sub batch step 6387 -- lr 2.39e-04
2025-03-02 14:14:18,964 - INFO - Step 1596 -- ðŸ”„ Training Metrics
2025-03-02 14:14:18,964 - INFO - â”œâ”€â”€ Loss: 7.3211
2025-03-02 14:14:18,965 - INFO - â”œâ”€â”€ Learning Rate: 2.39e-04
2025-03-02 14:14:18,965 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:14:19,630 - INFO - ðŸªœ Batch step - 1597 -- sub batch step 6388 -- lr 2.40e-04
2025-03-02 14:14:21,782 - INFO - ðŸªœ Batch step - 1597 -- sub batch step 6389 -- lr 2.40e-04
2025-03-02 14:14:24,215 - INFO - ðŸªœ Batch step - 1597 -- sub batch step 6390 -- lr 2.40e-04
2025-03-02 14:14:26,365 - INFO - ðŸªœ Batch step - 1597 -- sub batch step 6391 -- lr 2.40e-04
2025-03-02 14:14:28,133 - INFO - Step 1597 -- ðŸ”„ Training Metrics
2025-03-02 14:14:28,133 - INFO - â”œâ”€â”€ Loss: 7.3230
2025-03-02 14:14:28,133 - INFO - â”œâ”€â”€ Learning Rate: 2.40e-04
2025-03-02 14:14:28,134 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:14:28,807 - INFO - ðŸªœ Batch step - 1598 -- sub batch step 6392 -- lr 2.40e-04
2025-03-02 14:14:30,951 - INFO - ðŸªœ Batch step - 1598 -- sub batch step 6393 -- lr 2.40e-04
2025-03-02 14:14:33,122 - INFO - ðŸªœ Batch step - 1598 -- sub batch step 6394 -- lr 2.40e-04
2025-03-02 14:14:35,274 - INFO - ðŸªœ Batch step - 1598 -- sub batch step 6395 -- lr 2.40e-04
2025-03-02 14:14:36,843 - INFO - Step 1598 -- ðŸ”„ Training Metrics
2025-03-02 14:14:36,843 - INFO - â”œâ”€â”€ Loss: 7.3017
2025-03-02 14:14:36,843 - INFO - â”œâ”€â”€ Learning Rate: 2.40e-04
2025-03-02 14:14:36,843 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:14:37,511 - INFO - ðŸªœ Batch step - 1599 -- sub batch step 6396 -- lr 2.40e-04
2025-03-02 14:14:39,661 - INFO - ðŸªœ Batch step - 1599 -- sub batch step 6397 -- lr 2.40e-04
2025-03-02 14:14:41,930 - INFO - ðŸªœ Batch step - 1599 -- sub batch step 6398 -- lr 2.40e-04
2025-03-02 14:14:44,087 - INFO - ðŸªœ Batch step - 1599 -- sub batch step 6399 -- lr 2.40e-04
2025-03-02 14:14:45,649 - INFO - Step 1599 -- ðŸ”„ Training Metrics
2025-03-02 14:14:45,649 - INFO - â”œâ”€â”€ Loss: 7.2774
2025-03-02 14:14:45,649 - INFO - â”œâ”€â”€ Learning Rate: 2.40e-04
2025-03-02 14:14:45,650 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:14:46,849 - INFO - ðŸªœ Batch step - 1600 -- sub batch step 6400 -- lr 2.40e-04
2025-03-02 14:14:49,006 - INFO - ðŸªœ Batch step - 1600 -- sub batch step 6401 -- lr 2.40e-04
2025-03-02 14:14:51,164 - INFO - ðŸªœ Batch step - 1600 -- sub batch step 6402 -- lr 2.40e-04
2025-03-02 14:14:53,328 - INFO - ðŸªœ Batch step - 1600 -- sub batch step 6403 -- lr 2.40e-04
2025-03-02 14:14:54,874 - INFO - Step 1600 -- ðŸ”„ Training Metrics
2025-03-02 14:14:54,874 - INFO - â”œâ”€â”€ Loss: 7.3154
2025-03-02 14:14:54,874 - INFO - â”œâ”€â”€ Learning Rate: 2.40e-04
2025-03-02 14:14:54,875 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:14:55,548 - INFO - ðŸªœ Batch step - 1601 -- sub batch step 6404 -- lr 2.40e-04
2025-03-02 14:14:57,699 - INFO - ðŸªœ Batch step - 1601 -- sub batch step 6405 -- lr 2.40e-04
2025-03-02 14:14:59,846 - INFO - ðŸªœ Batch step - 1601 -- sub batch step 6406 -- lr 2.40e-04
2025-03-02 14:15:02,639 - INFO - ðŸªœ Batch step - 1601 -- sub batch step 6407 -- lr 2.40e-04
2025-03-02 14:15:04,276 - INFO - Step 1601 -- ðŸ”„ Training Metrics
2025-03-02 14:15:04,277 - INFO - â”œâ”€â”€ Loss: 7.3125
2025-03-02 14:15:04,277 - INFO - â”œâ”€â”€ Learning Rate: 2.40e-04
2025-03-02 14:15:04,277 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:15:04,944 - INFO - ðŸªœ Batch step - 1602 -- sub batch step 6408 -- lr 2.40e-04
2025-03-02 14:15:07,102 - INFO - ðŸªœ Batch step - 1602 -- sub batch step 6409 -- lr 2.40e-04
2025-03-02 14:15:09,257 - INFO - ðŸªœ Batch step - 1602 -- sub batch step 6410 -- lr 2.40e-04
2025-03-02 14:15:11,419 - INFO - ðŸªœ Batch step - 1602 -- sub batch step 6411 -- lr 2.40e-04
2025-03-02 14:15:12,968 - INFO - Step 1602 -- ðŸ”„ Training Metrics
2025-03-02 14:15:12,968 - INFO - â”œâ”€â”€ Loss: 7.2911
2025-03-02 14:15:12,968 - INFO - â”œâ”€â”€ Learning Rate: 2.40e-04
2025-03-02 14:15:12,968 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:15:13,642 - INFO - ðŸªœ Batch step - 1603 -- sub batch step 6412 -- lr 2.40e-04
2025-03-02 14:15:15,795 - INFO - ðŸªœ Batch step - 1603 -- sub batch step 6413 -- lr 2.40e-04
2025-03-02 14:15:17,948 - INFO - ðŸªœ Batch step - 1603 -- sub batch step 6414 -- lr 2.40e-04
2025-03-02 14:15:20,745 - INFO - ðŸªœ Batch step - 1603 -- sub batch step 6415 -- lr 2.40e-04
2025-03-02 14:15:22,237 - INFO - Step 1603 -- ðŸ”„ Training Metrics
2025-03-02 14:15:22,237 - INFO - â”œâ”€â”€ Loss: 7.2980
2025-03-02 14:15:22,237 - INFO - â”œâ”€â”€ Learning Rate: 2.40e-04
2025-03-02 14:15:22,237 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:15:22,909 - INFO - ðŸªœ Batch step - 1604 -- sub batch step 6416 -- lr 2.41e-04
2025-03-02 14:15:25,063 - INFO - ðŸªœ Batch step - 1604 -- sub batch step 6417 -- lr 2.41e-04
2025-03-02 14:15:27,213 - INFO - ðŸªœ Batch step - 1604 -- sub batch step 6418 -- lr 2.41e-04
2025-03-02 14:15:29,382 - INFO - ðŸªœ Batch step - 1604 -- sub batch step 6419 -- lr 2.41e-04
2025-03-02 14:15:30,935 - INFO - Step 1604 -- ðŸ”„ Training Metrics
2025-03-02 14:15:30,936 - INFO - â”œâ”€â”€ Loss: 7.3099
2025-03-02 14:15:30,936 - INFO - â”œâ”€â”€ Learning Rate: 2.41e-04
2025-03-02 14:15:30,936 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:15:31,611 - INFO - ðŸªœ Batch step - 1605 -- sub batch step 6420 -- lr 2.41e-04
2025-03-02 14:15:33,760 - INFO - ðŸªœ Batch step - 1605 -- sub batch step 6421 -- lr 2.41e-04
2025-03-02 14:15:35,914 - INFO - ðŸªœ Batch step - 1605 -- sub batch step 6422 -- lr 2.41e-04
2025-03-02 14:15:38,495 - INFO - ðŸªœ Batch step - 1605 -- sub batch step 6423 -- lr 2.41e-04
2025-03-02 14:15:40,258 - INFO - Step 1605 -- ðŸ”„ Training Metrics
2025-03-02 14:15:40,258 - INFO - â”œâ”€â”€ Loss: 7.3181
2025-03-02 14:15:40,258 - INFO - â”œâ”€â”€ Learning Rate: 2.41e-04
2025-03-02 14:15:40,259 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:15:40,935 - INFO - ðŸªœ Batch step - 1606 -- sub batch step 6424 -- lr 2.41e-04
2025-03-02 14:15:43,092 - INFO - ðŸªœ Batch step - 1606 -- sub batch step 6425 -- lr 2.41e-04
2025-03-02 14:15:45,242 - INFO - ðŸªœ Batch step - 1606 -- sub batch step 6426 -- lr 2.41e-04
2025-03-02 14:15:47,413 - INFO - ðŸªœ Batch step - 1606 -- sub batch step 6427 -- lr 2.41e-04
2025-03-02 14:15:49,000 - INFO - Step 1606 -- ðŸ”„ Training Metrics
2025-03-02 14:15:49,000 - INFO - â”œâ”€â”€ Loss: 7.2905
2025-03-02 14:15:49,000 - INFO - â”œâ”€â”€ Learning Rate: 2.41e-04
2025-03-02 14:15:49,001 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:15:49,670 - INFO - ðŸªœ Batch step - 1607 -- sub batch step 6428 -- lr 2.41e-04
2025-03-02 14:15:51,829 - INFO - ðŸªœ Batch step - 1607 -- sub batch step 6429 -- lr 2.41e-04
2025-03-02 14:15:53,983 - INFO - ðŸªœ Batch step - 1607 -- sub batch step 6430 -- lr 2.41e-04
2025-03-02 14:15:56,349 - INFO - ðŸªœ Batch step - 1607 -- sub batch step 6431 -- lr 2.41e-04
2025-03-02 14:15:58,270 - INFO - Step 1607 -- ðŸ”„ Training Metrics
2025-03-02 14:15:58,270 - INFO - â”œâ”€â”€ Loss: 7.3294
2025-03-02 14:15:58,270 - INFO - â”œâ”€â”€ Learning Rate: 2.41e-04
2025-03-02 14:15:58,270 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:15:58,949 - INFO - ðŸªœ Batch step - 1608 -- sub batch step 6432 -- lr 2.41e-04
2025-03-02 14:16:01,098 - INFO - ðŸªœ Batch step - 1608 -- sub batch step 6433 -- lr 2.41e-04
2025-03-02 14:16:03,253 - INFO - ðŸªœ Batch step - 1608 -- sub batch step 6434 -- lr 2.41e-04
2025-03-02 14:16:05,424 - INFO - ðŸªœ Batch step - 1608 -- sub batch step 6435 -- lr 2.41e-04
2025-03-02 14:16:06,993 - INFO - Step 1608 -- ðŸ”„ Training Metrics
2025-03-02 14:16:06,993 - INFO - â”œâ”€â”€ Loss: 7.3264
2025-03-02 14:16:06,993 - INFO - â”œâ”€â”€ Learning Rate: 2.41e-04
2025-03-02 14:16:06,994 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:16:07,660 - INFO - ðŸªœ Batch step - 1609 -- sub batch step 6436 -- lr 2.41e-04
2025-03-02 14:16:09,819 - INFO - ðŸªœ Batch step - 1609 -- sub batch step 6437 -- lr 2.41e-04
2025-03-02 14:16:11,968 - INFO - ðŸªœ Batch step - 1609 -- sub batch step 6438 -- lr 2.41e-04
2025-03-02 14:16:14,776 - INFO - ðŸªœ Batch step - 1609 -- sub batch step 6439 -- lr 2.41e-04
2025-03-02 14:16:16,267 - INFO - Step 1609 -- ðŸ”„ Training Metrics
2025-03-02 14:16:16,267 - INFO - â”œâ”€â”€ Loss: 7.3438
2025-03-02 14:16:16,267 - INFO - â”œâ”€â”€ Learning Rate: 2.41e-04
2025-03-02 14:16:16,267 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:16:16,945 - INFO - ðŸªœ Batch step - 1610 -- sub batch step 6440 -- lr 2.41e-04
2025-03-02 14:16:19,096 - INFO - ðŸªœ Batch step - 1610 -- sub batch step 6441 -- lr 2.41e-04
2025-03-02 14:16:21,247 - INFO - ðŸªœ Batch step - 1610 -- sub batch step 6442 -- lr 2.41e-04
2025-03-02 14:16:23,413 - INFO - ðŸªœ Batch step - 1610 -- sub batch step 6443 -- lr 2.41e-04
2025-03-02 14:16:24,967 - INFO - Step 1610 -- ðŸ”„ Training Metrics
2025-03-02 14:16:24,968 - INFO - â”œâ”€â”€ Loss: 7.3077
2025-03-02 14:16:24,968 - INFO - â”œâ”€â”€ Learning Rate: 2.41e-04
2025-03-02 14:16:24,968 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:16:25,644 - INFO - ðŸªœ Batch step - 1611 -- sub batch step 6444 -- lr 2.42e-04
2025-03-02 14:16:27,798 - INFO - ðŸªœ Batch step - 1611 -- sub batch step 6445 -- lr 2.42e-04
2025-03-02 14:16:30,457 - INFO - ðŸªœ Batch step - 1611 -- sub batch step 6446 -- lr 2.42e-04
2025-03-02 14:16:32,618 - INFO - ðŸªœ Batch step - 1611 -- sub batch step 6447 -- lr 2.42e-04
2025-03-02 14:16:34,286 - INFO - Step 1611 -- ðŸ”„ Training Metrics
2025-03-02 14:16:34,286 - INFO - â”œâ”€â”€ Loss: 7.3028
2025-03-02 14:16:34,286 - INFO - â”œâ”€â”€ Learning Rate: 2.42e-04
2025-03-02 14:16:34,286 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:16:34,954 - INFO - ðŸªœ Batch step - 1612 -- sub batch step 6448 -- lr 2.42e-04
2025-03-02 14:16:37,112 - INFO - ðŸªœ Batch step - 1612 -- sub batch step 6449 -- lr 2.42e-04
2025-03-02 14:16:39,281 - INFO - ðŸªœ Batch step - 1612 -- sub batch step 6450 -- lr 2.42e-04
2025-03-02 14:16:41,429 - INFO - ðŸªœ Batch step - 1612 -- sub batch step 6451 -- lr 2.42e-04
2025-03-02 14:16:42,988 - INFO - Step 1612 -- ðŸ”„ Training Metrics
2025-03-02 14:16:42,988 - INFO - â”œâ”€â”€ Loss: 7.2914
2025-03-02 14:16:42,989 - INFO - â”œâ”€â”€ Learning Rate: 2.42e-04
2025-03-02 14:16:42,989 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:16:43,661 - INFO - ðŸªœ Batch step - 1613 -- sub batch step 6452 -- lr 2.42e-04
2025-03-02 14:16:45,812 - INFO - ðŸªœ Batch step - 1613 -- sub batch step 6453 -- lr 2.42e-04
2025-03-02 14:16:48,237 - INFO - ðŸªœ Batch step - 1613 -- sub batch step 6454 -- lr 2.42e-04
2025-03-02 14:16:50,386 - INFO - ðŸªœ Batch step - 1613 -- sub batch step 6455 -- lr 2.42e-04
2025-03-02 14:16:52,324 - INFO - Step 1613 -- ðŸ”„ Training Metrics
2025-03-02 14:16:52,325 - INFO - â”œâ”€â”€ Loss: 7.3054
2025-03-02 14:16:52,325 - INFO - â”œâ”€â”€ Learning Rate: 2.42e-04
2025-03-02 14:16:52,325 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:16:52,991 - INFO - ðŸªœ Batch step - 1614 -- sub batch step 6456 -- lr 2.42e-04
2025-03-02 14:16:55,149 - INFO - ðŸªœ Batch step - 1614 -- sub batch step 6457 -- lr 2.42e-04
2025-03-02 14:16:57,310 - INFO - ðŸªœ Batch step - 1614 -- sub batch step 6458 -- lr 2.42e-04
2025-03-02 14:16:59,467 - INFO - ðŸªœ Batch step - 1614 -- sub batch step 6459 -- lr 2.42e-04
2025-03-02 14:17:01,021 - INFO - Step 1614 -- ðŸ”„ Training Metrics
2025-03-02 14:17:01,022 - INFO - â”œâ”€â”€ Loss: 7.2955
2025-03-02 14:17:01,022 - INFO - â”œâ”€â”€ Learning Rate: 2.42e-04
2025-03-02 14:17:01,022 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:17:01,700 - INFO - ðŸªœ Batch step - 1615 -- sub batch step 6460 -- lr 2.42e-04
2025-03-02 14:17:03,848 - INFO - ðŸªœ Batch step - 1615 -- sub batch step 6461 -- lr 2.42e-04
2025-03-02 14:17:06,537 - INFO - ðŸªœ Batch step - 1615 -- sub batch step 6462 -- lr 2.42e-04
2025-03-02 14:17:08,684 - INFO - ðŸªœ Batch step - 1615 -- sub batch step 6463 -- lr 2.42e-04
2025-03-02 14:17:10,269 - INFO - Step 1615 -- ðŸ”„ Training Metrics
2025-03-02 14:17:10,270 - INFO - â”œâ”€â”€ Loss: 7.3037
2025-03-02 14:17:10,270 - INFO - â”œâ”€â”€ Learning Rate: 2.42e-04
2025-03-02 14:17:10,270 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:17:10,945 - INFO - ðŸªœ Batch step - 1616 -- sub batch step 6464 -- lr 2.42e-04
2025-03-02 14:17:13,098 - INFO - ðŸªœ Batch step - 1616 -- sub batch step 6465 -- lr 2.42e-04
2025-03-02 14:17:15,258 - INFO - ðŸªœ Batch step - 1616 -- sub batch step 6466 -- lr 2.42e-04
2025-03-02 14:17:17,410 - INFO - ðŸªœ Batch step - 1616 -- sub batch step 6467 -- lr 2.42e-04
2025-03-02 14:17:18,972 - INFO - Step 1616 -- ðŸ”„ Training Metrics
2025-03-02 14:17:18,972 - INFO - â”œâ”€â”€ Loss: 7.2944
2025-03-02 14:17:18,972 - INFO - â”œâ”€â”€ Learning Rate: 2.42e-04
2025-03-02 14:17:18,972 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:17:19,639 - INFO - ðŸªœ Batch step - 1617 -- sub batch step 6468 -- lr 2.43e-04
2025-03-02 14:17:21,793 - INFO - ðŸªœ Batch step - 1617 -- sub batch step 6469 -- lr 2.43e-04
2025-03-02 14:17:24,476 - INFO - ðŸªœ Batch step - 1617 -- sub batch step 6470 -- lr 2.43e-04
2025-03-02 14:17:26,630 - INFO - ðŸªœ Batch step - 1617 -- sub batch step 6471 -- lr 2.43e-04
2025-03-02 14:17:28,235 - INFO - Step 1617 -- ðŸ”„ Training Metrics
2025-03-02 14:17:28,235 - INFO - â”œâ”€â”€ Loss: 7.3049
2025-03-02 14:17:28,235 - INFO - â”œâ”€â”€ Learning Rate: 2.43e-04
2025-03-02 14:17:28,235 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:17:28,913 - INFO - ðŸªœ Batch step - 1618 -- sub batch step 6472 -- lr 2.43e-04
2025-03-02 14:17:31,061 - INFO - ðŸªœ Batch step - 1618 -- sub batch step 6473 -- lr 2.43e-04
2025-03-02 14:17:33,229 - INFO - ðŸªœ Batch step - 1618 -- sub batch step 6474 -- lr 2.43e-04
2025-03-02 14:17:35,381 - INFO - ðŸªœ Batch step - 1618 -- sub batch step 6475 -- lr 2.43e-04
2025-03-02 14:17:36,947 - INFO - Step 1618 -- ðŸ”„ Training Metrics
2025-03-02 14:17:36,947 - INFO - â”œâ”€â”€ Loss: 7.2841
2025-03-02 14:17:36,947 - INFO - â”œâ”€â”€ Learning Rate: 2.43e-04
2025-03-02 14:17:36,947 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:17:37,614 - INFO - ðŸªœ Batch step - 1619 -- sub batch step 6476 -- lr 2.43e-04
2025-03-02 14:17:39,771 - INFO - ðŸªœ Batch step - 1619 -- sub batch step 6477 -- lr 2.43e-04
2025-03-02 14:17:42,045 - INFO - ðŸªœ Batch step - 1619 -- sub batch step 6478 -- lr 2.43e-04
2025-03-02 14:17:44,198 - INFO - ðŸªœ Batch step - 1619 -- sub batch step 6479 -- lr 2.43e-04
2025-03-02 14:17:45,832 - INFO - Step 1619 -- ðŸ”„ Training Metrics
2025-03-02 14:17:45,833 - INFO - â”œâ”€â”€ Loss: 7.3165
2025-03-02 14:17:45,833 - INFO - â”œâ”€â”€ Learning Rate: 2.43e-04
2025-03-02 14:17:45,833 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:17:47,009 - INFO - ðŸªœ Batch step - 1620 -- sub batch step 6480 -- lr 2.43e-04
2025-03-02 14:17:49,167 - INFO - ðŸªœ Batch step - 1620 -- sub batch step 6481 -- lr 2.43e-04
2025-03-02 14:17:51,329 - INFO - ðŸªœ Batch step - 1620 -- sub batch step 6482 -- lr 2.43e-04
2025-03-02 14:17:53,503 - INFO - ðŸªœ Batch step - 1620 -- sub batch step 6483 -- lr 2.43e-04
2025-03-02 14:17:55,062 - INFO - Step 1620 -- ðŸ”„ Training Metrics
2025-03-02 14:17:55,062 - INFO - â”œâ”€â”€ Loss: 7.2873
2025-03-02 14:17:55,062 - INFO - â”œâ”€â”€ Learning Rate: 2.43e-04
2025-03-02 14:17:55,062 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:17:55,743 - INFO - ðŸªœ Batch step - 1621 -- sub batch step 6484 -- lr 2.43e-04
2025-03-02 14:17:57,903 - INFO - ðŸªœ Batch step - 1621 -- sub batch step 6485 -- lr 2.43e-04
2025-03-02 14:18:00,061 - INFO - ðŸªœ Batch step - 1621 -- sub batch step 6486 -- lr 2.43e-04
2025-03-02 14:18:02,661 - INFO - ðŸªœ Batch step - 1621 -- sub batch step 6487 -- lr 2.43e-04
2025-03-02 14:18:04,365 - INFO - Step 1621 -- ðŸ”„ Training Metrics
2025-03-02 14:18:04,365 - INFO - â”œâ”€â”€ Loss: 7.2743
2025-03-02 14:18:04,365 - INFO - â”œâ”€â”€ Learning Rate: 2.43e-04
2025-03-02 14:18:04,365 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:18:05,042 - INFO - ðŸªœ Batch step - 1622 -- sub batch step 6488 -- lr 2.43e-04
2025-03-02 14:18:07,198 - INFO - ðŸªœ Batch step - 1622 -- sub batch step 6489 -- lr 2.43e-04
2025-03-02 14:18:09,356 - INFO - ðŸªœ Batch step - 1622 -- sub batch step 6490 -- lr 2.43e-04
2025-03-02 14:18:11,516 - INFO - ðŸªœ Batch step - 1622 -- sub batch step 6491 -- lr 2.43e-04
2025-03-02 14:18:13,069 - INFO - Step 1622 -- ðŸ”„ Training Metrics
2025-03-02 14:18:13,069 - INFO - â”œâ”€â”€ Loss: 7.2902
2025-03-02 14:18:13,069 - INFO - â”œâ”€â”€ Learning Rate: 2.43e-04
2025-03-02 14:18:13,069 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:18:13,750 - INFO - ðŸªœ Batch step - 1623 -- sub batch step 6492 -- lr 2.43e-04
2025-03-02 14:18:15,901 - INFO - ðŸªœ Batch step - 1623 -- sub batch step 6493 -- lr 2.43e-04
2025-03-02 14:18:18,060 - INFO - ðŸªœ Batch step - 1623 -- sub batch step 6494 -- lr 2.43e-04
2025-03-02 14:18:20,441 - INFO - ðŸªœ Batch step - 1623 -- sub batch step 6495 -- lr 2.43e-04
2025-03-02 14:18:22,418 - INFO - Step 1623 -- ðŸ”„ Training Metrics
2025-03-02 14:18:22,418 - INFO - â”œâ”€â”€ Loss: 7.2979
2025-03-02 14:18:22,418 - INFO - â”œâ”€â”€ Learning Rate: 2.43e-04
2025-03-02 14:18:22,418 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:18:23,088 - INFO - ðŸªœ Batch step - 1624 -- sub batch step 6496 -- lr 2.44e-04
2025-03-02 14:18:25,241 - INFO - ðŸªœ Batch step - 1624 -- sub batch step 6497 -- lr 2.44e-04
2025-03-02 14:18:27,388 - INFO - ðŸªœ Batch step - 1624 -- sub batch step 6498 -- lr 2.44e-04
2025-03-02 14:18:29,559 - INFO - ðŸªœ Batch step - 1624 -- sub batch step 6499 -- lr 2.44e-04
2025-03-02 14:18:31,140 - INFO - Step 1624 -- ðŸ”„ Training Metrics
2025-03-02 14:18:31,140 - INFO - â”œâ”€â”€ Loss: 7.3056
2025-03-02 14:18:31,140 - INFO - â”œâ”€â”€ Learning Rate: 2.44e-04
2025-03-02 14:18:31,140 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:18:31,813 - INFO - ðŸªœ Batch step - 1625 -- sub batch step 6500 -- lr 2.44e-04
2025-03-02 14:18:33,966 - INFO - ðŸªœ Batch step - 1625 -- sub batch step 6501 -- lr 2.44e-04
2025-03-02 14:18:36,120 - INFO - ðŸªœ Batch step - 1625 -- sub batch step 6502 -- lr 2.44e-04
2025-03-02 14:18:38,806 - INFO - ðŸªœ Batch step - 1625 -- sub batch step 6503 -- lr 2.44e-04
2025-03-02 14:18:40,325 - INFO - Step 1625 -- ðŸ”„ Training Metrics
2025-03-02 14:18:40,326 - INFO - â”œâ”€â”€ Loss: 7.3006
2025-03-02 14:18:40,326 - INFO - â”œâ”€â”€ Learning Rate: 2.44e-04
2025-03-02 14:18:40,326 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:18:40,999 - INFO - ðŸªœ Batch step - 1626 -- sub batch step 6504 -- lr 2.44e-04
2025-03-02 14:18:43,149 - INFO - ðŸªœ Batch step - 1626 -- sub batch step 6505 -- lr 2.44e-04
2025-03-02 14:18:45,293 - INFO - ðŸªœ Batch step - 1626 -- sub batch step 6506 -- lr 2.44e-04
2025-03-02 14:18:47,465 - INFO - ðŸªœ Batch step - 1626 -- sub batch step 6507 -- lr 2.44e-04
2025-03-02 14:18:49,043 - INFO - Step 1626 -- ðŸ”„ Training Metrics
2025-03-02 14:18:49,044 - INFO - â”œâ”€â”€ Loss: 7.2776
2025-03-02 14:18:49,044 - INFO - â”œâ”€â”€ Learning Rate: 2.44e-04
2025-03-02 14:18:49,044 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:18:49,708 - INFO - ðŸªœ Batch step - 1627 -- sub batch step 6508 -- lr 2.44e-04
2025-03-02 14:18:51,865 - INFO - ðŸªœ Batch step - 1627 -- sub batch step 6509 -- lr 2.44e-04
2025-03-02 14:18:54,017 - INFO - ðŸªœ Batch step - 1627 -- sub batch step 6510 -- lr 2.44e-04
2025-03-02 14:18:56,757 - INFO - ðŸªœ Batch step - 1627 -- sub batch step 6511 -- lr 2.44e-04
2025-03-02 14:18:58,328 - INFO - Step 1627 -- ðŸ”„ Training Metrics
2025-03-02 14:18:58,329 - INFO - â”œâ”€â”€ Loss: 7.2766
2025-03-02 14:18:58,329 - INFO - â”œâ”€â”€ Learning Rate: 2.44e-04
2025-03-02 14:18:58,329 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:18:58,999 - INFO - ðŸªœ Batch step - 1628 -- sub batch step 6512 -- lr 2.44e-04
2025-03-02 14:19:01,147 - INFO - ðŸªœ Batch step - 1628 -- sub batch step 6513 -- lr 2.44e-04
2025-03-02 14:19:03,303 - INFO - ðŸªœ Batch step - 1628 -- sub batch step 6514 -- lr 2.44e-04
2025-03-02 14:19:05,472 - INFO - ðŸªœ Batch step - 1628 -- sub batch step 6515 -- lr 2.44e-04
2025-03-02 14:19:07,038 - INFO - Step 1628 -- ðŸ”„ Training Metrics
2025-03-02 14:19:07,038 - INFO - â”œâ”€â”€ Loss: 7.3002
2025-03-02 14:19:07,039 - INFO - â”œâ”€â”€ Learning Rate: 2.44e-04
2025-03-02 14:19:07,039 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:19:07,707 - INFO - ðŸªœ Batch step - 1629 -- sub batch step 6516 -- lr 2.44e-04
2025-03-02 14:19:09,864 - INFO - ðŸªœ Batch step - 1629 -- sub batch step 6517 -- lr 2.44e-04
2025-03-02 14:19:12,011 - INFO - ðŸªœ Batch step - 1629 -- sub batch step 6518 -- lr 2.44e-04
2025-03-02 14:19:14,511 - INFO - ðŸªœ Batch step - 1629 -- sub batch step 6519 -- lr 2.44e-04
2025-03-02 14:19:16,436 - INFO - Step 1629 -- ðŸ”„ Training Metrics
2025-03-02 14:19:16,436 - INFO - â”œâ”€â”€ Loss: 7.2951
2025-03-02 14:19:16,437 - INFO - â”œâ”€â”€ Learning Rate: 2.44e-04
2025-03-02 14:19:16,437 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:19:17,108 - INFO - ðŸªœ Batch step - 1630 -- sub batch step 6520 -- lr 2.44e-04
2025-03-02 14:19:19,259 - INFO - ðŸªœ Batch step - 1630 -- sub batch step 6521 -- lr 2.44e-04
2025-03-02 14:19:21,410 - INFO - ðŸªœ Batch step - 1630 -- sub batch step 6522 -- lr 2.44e-04
2025-03-02 14:19:23,569 - INFO - ðŸªœ Batch step - 1630 -- sub batch step 6523 -- lr 2.44e-04
2025-03-02 14:19:25,129 - INFO - Step 1630 -- ðŸ”„ Training Metrics
2025-03-02 14:19:25,129 - INFO - â”œâ”€â”€ Loss: 7.2966
2025-03-02 14:19:25,129 - INFO - â”œâ”€â”€ Learning Rate: 2.44e-04
2025-03-02 14:19:25,130 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:19:25,802 - INFO - ðŸªœ Batch step - 1631 -- sub batch step 6524 -- lr 2.45e-04
2025-03-02 14:19:27,953 - INFO - ðŸªœ Batch step - 1631 -- sub batch step 6525 -- lr 2.45e-04
2025-03-02 14:19:30,667 - INFO - ðŸªœ Batch step - 1631 -- sub batch step 6526 -- lr 2.45e-04
2025-03-02 14:19:32,827 - INFO - ðŸªœ Batch step - 1631 -- sub batch step 6527 -- lr 2.45e-04
2025-03-02 14:19:34,348 - INFO - Step 1631 -- ðŸ”„ Training Metrics
2025-03-02 14:19:34,348 - INFO - â”œâ”€â”€ Loss: 7.2874
2025-03-02 14:19:34,348 - INFO - â”œâ”€â”€ Learning Rate: 2.45e-04
2025-03-02 14:19:34,348 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:19:35,014 - INFO - ðŸªœ Batch step - 1632 -- sub batch step 6528 -- lr 2.45e-04
2025-03-02 14:19:37,171 - INFO - ðŸªœ Batch step - 1632 -- sub batch step 6529 -- lr 2.45e-04
2025-03-02 14:19:39,341 - INFO - ðŸªœ Batch step - 1632 -- sub batch step 6530 -- lr 2.45e-04
2025-03-02 14:19:41,490 - INFO - ðŸªœ Batch step - 1632 -- sub batch step 6531 -- lr 2.45e-04
2025-03-02 14:19:43,042 - INFO - Step 1632 -- ðŸ”„ Training Metrics
2025-03-02 14:19:43,043 - INFO - â”œâ”€â”€ Loss: 7.2869
2025-03-02 14:19:43,043 - INFO - â”œâ”€â”€ Learning Rate: 2.45e-04
2025-03-02 14:19:43,043 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:19:43,713 - INFO - ðŸªœ Batch step - 1633 -- sub batch step 6532 -- lr 2.45e-04
2025-03-02 14:19:45,861 - INFO - ðŸªœ Batch step - 1633 -- sub batch step 6533 -- lr 2.45e-04
2025-03-02 14:19:48,564 - INFO - ðŸªœ Batch step - 1633 -- sub batch step 6534 -- lr 2.45e-04
2025-03-02 14:19:50,715 - INFO - ðŸªœ Batch step - 1633 -- sub batch step 6535 -- lr 2.45e-04
2025-03-02 14:19:52,295 - INFO - Step 1633 -- ðŸ”„ Training Metrics
2025-03-02 14:19:52,295 - INFO - â”œâ”€â”€ Loss: 7.3093
2025-03-02 14:19:52,295 - INFO - â”œâ”€â”€ Learning Rate: 2.45e-04
2025-03-02 14:19:52,295 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:19:52,967 - INFO - ðŸªœ Batch step - 1634 -- sub batch step 6536 -- lr 2.45e-04
2025-03-02 14:19:55,118 - INFO - ðŸªœ Batch step - 1634 -- sub batch step 6537 -- lr 2.45e-04
2025-03-02 14:19:57,275 - INFO - ðŸªœ Batch step - 1634 -- sub batch step 6538 -- lr 2.45e-04
2025-03-02 14:19:59,430 - INFO - ðŸªœ Batch step - 1634 -- sub batch step 6539 -- lr 2.45e-04
2025-03-02 14:20:01,004 - INFO - Step 1634 -- ðŸ”„ Training Metrics
2025-03-02 14:20:01,004 - INFO - â”œâ”€â”€ Loss: 7.3339
2025-03-02 14:20:01,004 - INFO - â”œâ”€â”€ Learning Rate: 2.45e-04
2025-03-02 14:20:01,005 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:20:01,674 - INFO - ðŸªœ Batch step - 1635 -- sub batch step 6540 -- lr 2.45e-04
2025-03-02 14:20:03,820 - INFO - ðŸªœ Batch step - 1635 -- sub batch step 6541 -- lr 2.45e-04
2025-03-02 14:20:06,535 - INFO - ðŸªœ Batch step - 1635 -- sub batch step 6542 -- lr 2.45e-04
2025-03-02 14:20:08,686 - INFO - ðŸªœ Batch step - 1635 -- sub batch step 6543 -- lr 2.45e-04
2025-03-02 14:20:10,217 - INFO - Step 1635 -- ðŸ”„ Training Metrics
2025-03-02 14:20:10,217 - INFO - â”œâ”€â”€ Loss: 7.2992
2025-03-02 14:20:10,217 - INFO - â”œâ”€â”€ Learning Rate: 2.45e-04
2025-03-02 14:20:10,217 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:20:10,891 - INFO - ðŸªœ Batch step - 1636 -- sub batch step 6544 -- lr 2.45e-04
2025-03-02 14:20:13,040 - INFO - ðŸªœ Batch step - 1636 -- sub batch step 6545 -- lr 2.45e-04
2025-03-02 14:20:15,207 - INFO - ðŸªœ Batch step - 1636 -- sub batch step 6546 -- lr 2.45e-04
2025-03-02 14:20:17,361 - INFO - ðŸªœ Batch step - 1636 -- sub batch step 6547 -- lr 2.45e-04
2025-03-02 14:20:18,928 - INFO - Step 1636 -- ðŸ”„ Training Metrics
2025-03-02 14:20:18,928 - INFO - â”œâ”€â”€ Loss: 7.2893
2025-03-02 14:20:18,928 - INFO - â”œâ”€â”€ Learning Rate: 2.45e-04
2025-03-02 14:20:18,928 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:20:19,593 - INFO - ðŸªœ Batch step - 1637 -- sub batch step 6548 -- lr 2.46e-04
2025-03-02 14:20:21,751 - INFO - ðŸªœ Batch step - 1637 -- sub batch step 6549 -- lr 2.46e-04
2025-03-02 14:20:24,332 - INFO - ðŸªœ Batch step - 1637 -- sub batch step 6550 -- lr 2.46e-04
2025-03-02 14:20:26,483 - INFO - ðŸªœ Batch step - 1637 -- sub batch step 6551 -- lr 2.46e-04
2025-03-02 14:20:28,181 - INFO - Step 1637 -- ðŸ”„ Training Metrics
2025-03-02 14:20:28,182 - INFO - â”œâ”€â”€ Loss: 7.2524
2025-03-02 14:20:28,182 - INFO - â”œâ”€â”€ Learning Rate: 2.46e-04
2025-03-02 14:20:28,182 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:20:28,854 - INFO - ðŸªœ Batch step - 1638 -- sub batch step 6552 -- lr 2.46e-04
2025-03-02 14:20:31,002 - INFO - ðŸªœ Batch step - 1638 -- sub batch step 6553 -- lr 2.46e-04
2025-03-02 14:20:33,177 - INFO - ðŸªœ Batch step - 1638 -- sub batch step 6554 -- lr 2.46e-04
2025-03-02 14:20:35,328 - INFO - ðŸªœ Batch step - 1638 -- sub batch step 6555 -- lr 2.46e-04
2025-03-02 14:20:36,882 - INFO - Step 1638 -- ðŸ”„ Training Metrics
2025-03-02 14:20:36,883 - INFO - â”œâ”€â”€ Loss: 7.2880
2025-03-02 14:20:36,883 - INFO - â”œâ”€â”€ Learning Rate: 2.46e-04
2025-03-02 14:20:36,883 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:20:37,548 - INFO - ðŸªœ Batch step - 1639 -- sub batch step 6556 -- lr 2.46e-04
2025-03-02 14:20:39,706 - INFO - ðŸªœ Batch step - 1639 -- sub batch step 6557 -- lr 2.46e-04
2025-03-02 14:20:42,137 - INFO - ðŸªœ Batch step - 1639 -- sub batch step 6558 -- lr 2.46e-04
2025-03-02 14:20:44,293 - INFO - ðŸªœ Batch step - 1639 -- sub batch step 6559 -- lr 2.46e-04
2025-03-02 14:20:45,821 - INFO - Step 1639 -- ðŸ”„ Training Metrics
2025-03-02 14:20:45,821 - INFO - â”œâ”€â”€ Loss: 7.2886
2025-03-02 14:20:45,821 - INFO - â”œâ”€â”€ Learning Rate: 2.46e-04
2025-03-02 14:20:45,821 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:20:47,068 - INFO - ðŸªœ Batch step - 1640 -- sub batch step 6560 -- lr 2.46e-04
2025-03-02 14:20:49,218 - INFO - ðŸªœ Batch step - 1640 -- sub batch step 6561 -- lr 2.46e-04
2025-03-02 14:20:51,373 - INFO - ðŸªœ Batch step - 1640 -- sub batch step 6562 -- lr 2.46e-04
2025-03-02 14:20:53,539 - INFO - ðŸªœ Batch step - 1640 -- sub batch step 6563 -- lr 2.46e-04
2025-03-02 14:20:55,141 - INFO - Step 1640 -- ðŸ”„ Training Metrics
2025-03-02 14:20:55,141 - INFO - â”œâ”€â”€ Loss: 7.2853
2025-03-02 14:20:55,141 - INFO - â”œâ”€â”€ Learning Rate: 2.46e-04
2025-03-02 14:20:55,142 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:20:55,814 - INFO - ðŸªœ Batch step - 1641 -- sub batch step 6564 -- lr 2.46e-04
2025-03-02 14:20:57,967 - INFO - ðŸªœ Batch step - 1641 -- sub batch step 6565 -- lr 2.46e-04
2025-03-02 14:21:00,112 - INFO - ðŸªœ Batch step - 1641 -- sub batch step 6566 -- lr 2.46e-04
2025-03-02 14:21:02,764 - INFO - ðŸªœ Batch step - 1641 -- sub batch step 6567 -- lr 2.46e-04
2025-03-02 14:21:04,273 - INFO - Step 1641 -- ðŸ”„ Training Metrics
2025-03-02 14:21:04,274 - INFO - â”œâ”€â”€ Loss: 7.2570
2025-03-02 14:21:04,274 - INFO - â”œâ”€â”€ Learning Rate: 2.46e-04
2025-03-02 14:21:04,274 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:21:04,938 - INFO - ðŸªœ Batch step - 1642 -- sub batch step 6568 -- lr 2.46e-04
2025-03-02 14:21:07,093 - INFO - ðŸªœ Batch step - 1642 -- sub batch step 6569 -- lr 2.46e-04
2025-03-02 14:21:09,245 - INFO - ðŸªœ Batch step - 1642 -- sub batch step 6570 -- lr 2.46e-04
2025-03-02 14:21:11,412 - INFO - ðŸªœ Batch step - 1642 -- sub batch step 6571 -- lr 2.46e-04
2025-03-02 14:21:12,973 - INFO - Step 1642 -- ðŸ”„ Training Metrics
2025-03-02 14:21:12,973 - INFO - â”œâ”€â”€ Loss: 7.2599
2025-03-02 14:21:12,973 - INFO - â”œâ”€â”€ Learning Rate: 2.46e-04
2025-03-02 14:21:12,973 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:21:13,651 - INFO - ðŸªœ Batch step - 1643 -- sub batch step 6572 -- lr 2.46e-04
2025-03-02 14:21:15,802 - INFO - ðŸªœ Batch step - 1643 -- sub batch step 6573 -- lr 2.46e-04
2025-03-02 14:21:17,961 - INFO - ðŸªœ Batch step - 1643 -- sub batch step 6574 -- lr 2.46e-04
2025-03-02 14:21:20,677 - INFO - ðŸªœ Batch step - 1643 -- sub batch step 6575 -- lr 2.46e-04
2025-03-02 14:21:22,170 - INFO - Step 1643 -- ðŸ”„ Training Metrics
2025-03-02 14:21:22,170 - INFO - â”œâ”€â”€ Loss: 7.3009
2025-03-02 14:21:22,170 - INFO - â”œâ”€â”€ Learning Rate: 2.46e-04
2025-03-02 14:21:22,170 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:21:22,841 - INFO - ðŸªœ Batch step - 1644 -- sub batch step 6576 -- lr 2.47e-04
2025-03-02 14:21:24,995 - INFO - ðŸªœ Batch step - 1644 -- sub batch step 6577 -- lr 2.47e-04
2025-03-02 14:21:27,141 - INFO - ðŸªœ Batch step - 1644 -- sub batch step 6578 -- lr 2.47e-04
2025-03-02 14:21:29,313 - INFO - ðŸªœ Batch step - 1644 -- sub batch step 6579 -- lr 2.47e-04
2025-03-02 14:21:30,862 - INFO - Step 1644 -- ðŸ”„ Training Metrics
2025-03-02 14:21:30,862 - INFO - â”œâ”€â”€ Loss: 7.2754
2025-03-02 14:21:30,862 - INFO - â”œâ”€â”€ Learning Rate: 2.47e-04
2025-03-02 14:21:30,863 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:21:31,538 - INFO - ðŸªœ Batch step - 1645 -- sub batch step 6580 -- lr 2.47e-04
2025-03-02 14:21:33,690 - INFO - ðŸªœ Batch step - 1645 -- sub batch step 6581 -- lr 2.47e-04
2025-03-02 14:21:35,841 - INFO - ðŸªœ Batch step - 1645 -- sub batch step 6582 -- lr 2.47e-04
2025-03-02 14:21:38,568 - INFO - ðŸªœ Batch step - 1645 -- sub batch step 6583 -- lr 2.47e-04
2025-03-02 14:21:40,086 - INFO - Step 1645 -- ðŸ”„ Training Metrics
2025-03-02 14:21:40,086 - INFO - â”œâ”€â”€ Loss: 7.2665
2025-03-02 14:21:40,086 - INFO - â”œâ”€â”€ Learning Rate: 2.47e-04
2025-03-02 14:21:40,087 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:21:40,760 - INFO - ðŸªœ Batch step - 1646 -- sub batch step 6584 -- lr 2.47e-04
2025-03-02 14:21:42,912 - INFO - ðŸªœ Batch step - 1646 -- sub batch step 6585 -- lr 2.47e-04
2025-03-02 14:21:45,056 - INFO - ðŸªœ Batch step - 1646 -- sub batch step 6586 -- lr 2.47e-04
2025-03-02 14:21:47,231 - INFO - ðŸªœ Batch step - 1646 -- sub batch step 6587 -- lr 2.47e-04
2025-03-02 14:21:48,787 - INFO - Step 1646 -- ðŸ”„ Training Metrics
2025-03-02 14:21:48,787 - INFO - â”œâ”€â”€ Loss: 7.2877
2025-03-02 14:21:48,787 - INFO - â”œâ”€â”€ Learning Rate: 2.47e-04
2025-03-02 14:21:48,787 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:21:49,457 - INFO - ðŸªœ Batch step - 1647 -- sub batch step 6588 -- lr 2.47e-04
2025-03-02 14:21:51,613 - INFO - ðŸªœ Batch step - 1647 -- sub batch step 6589 -- lr 2.47e-04
2025-03-02 14:21:53,766 - INFO - ðŸªœ Batch step - 1647 -- sub batch step 6590 -- lr 2.47e-04
2025-03-02 14:21:56,447 - INFO - ðŸªœ Batch step - 1647 -- sub batch step 6591 -- lr 2.47e-04
2025-03-02 14:21:58,074 - INFO - Step 1647 -- ðŸ”„ Training Metrics
2025-03-02 14:21:58,074 - INFO - â”œâ”€â”€ Loss: 7.2601
2025-03-02 14:21:58,074 - INFO - â”œâ”€â”€ Learning Rate: 2.47e-04
2025-03-02 14:21:58,074 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:21:58,750 - INFO - ðŸªœ Batch step - 1648 -- sub batch step 6592 -- lr 2.47e-04
2025-03-02 14:22:00,899 - INFO - ðŸªœ Batch step - 1648 -- sub batch step 6593 -- lr 2.47e-04
2025-03-02 14:22:03,051 - INFO - ðŸªœ Batch step - 1648 -- sub batch step 6594 -- lr 2.47e-04
2025-03-02 14:22:05,227 - INFO - ðŸªœ Batch step - 1648 -- sub batch step 6595 -- lr 2.47e-04
2025-03-02 14:22:06,788 - INFO - Step 1648 -- ðŸ”„ Training Metrics
2025-03-02 14:22:06,788 - INFO - â”œâ”€â”€ Loss: 7.2500
2025-03-02 14:22:06,788 - INFO - â”œâ”€â”€ Learning Rate: 2.47e-04
2025-03-02 14:22:06,788 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:22:07,455 - INFO - ðŸªœ Batch step - 1649 -- sub batch step 6596 -- lr 2.47e-04
2025-03-02 14:22:09,611 - INFO - ðŸªœ Batch step - 1649 -- sub batch step 6597 -- lr 2.47e-04
2025-03-02 14:22:11,756 - INFO - ðŸªœ Batch step - 1649 -- sub batch step 6598 -- lr 2.47e-04
2025-03-02 14:22:14,444 - INFO - ðŸªœ Batch step - 1649 -- sub batch step 6599 -- lr 2.47e-04
2025-03-02 14:22:16,317 - INFO - Step 1649 -- ðŸ”„ Training Metrics
2025-03-02 14:22:16,317 - INFO - â”œâ”€â”€ Loss: 7.3030
2025-03-02 14:22:16,317 - INFO - â”œâ”€â”€ Learning Rate: 2.47e-04
2025-03-02 14:22:16,317 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:22:16,997 - INFO - ðŸªœ Batch step - 1650 -- sub batch step 6600 -- lr 2.47e-04
2025-03-02 14:22:19,144 - INFO - ðŸªœ Batch step - 1650 -- sub batch step 6601 -- lr 2.47e-04
2025-03-02 14:22:21,298 - INFO - ðŸªœ Batch step - 1650 -- sub batch step 6602 -- lr 2.47e-04
2025-03-02 14:22:23,464 - INFO - ðŸªœ Batch step - 1650 -- sub batch step 6603 -- lr 2.47e-04
2025-03-02 14:22:25,016 - INFO - Step 1650 -- ðŸ”„ Training Metrics
2025-03-02 14:22:25,017 - INFO - â”œâ”€â”€ Loss: 7.2845
2025-03-02 14:22:25,017 - INFO - â”œâ”€â”€ Learning Rate: 2.47e-04
2025-03-02 14:22:25,017 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:22:25,688 - INFO - ðŸªœ Batch step - 1651 -- sub batch step 6604 -- lr 2.48e-04
2025-03-02 14:22:27,839 - INFO - ðŸªœ Batch step - 1651 -- sub batch step 6605 -- lr 2.48e-04
2025-03-02 14:22:30,418 - INFO - ðŸªœ Batch step - 1651 -- sub batch step 6606 -- lr 2.48e-04
2025-03-02 14:22:32,575 - INFO - ðŸªœ Batch step - 1651 -- sub batch step 6607 -- lr 2.48e-04
2025-03-02 14:22:34,258 - INFO - Step 1651 -- ðŸ”„ Training Metrics
2025-03-02 14:22:34,259 - INFO - â”œâ”€â”€ Loss: 7.2809
2025-03-02 14:22:34,259 - INFO - â”œâ”€â”€ Learning Rate: 2.48e-04
2025-03-02 14:22:34,259 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:22:34,924 - INFO - ðŸªœ Batch step - 1652 -- sub batch step 6608 -- lr 2.48e-04
2025-03-02 14:22:37,076 - INFO - ðŸªœ Batch step - 1652 -- sub batch step 6609 -- lr 2.48e-04
2025-03-02 14:22:39,252 - INFO - ðŸªœ Batch step - 1652 -- sub batch step 6610 -- lr 2.48e-04
2025-03-02 14:22:41,400 - INFO - ðŸªœ Batch step - 1652 -- sub batch step 6611 -- lr 2.48e-04
2025-03-02 14:22:42,958 - INFO - Step 1652 -- ðŸ”„ Training Metrics
2025-03-02 14:22:42,958 - INFO - â”œâ”€â”€ Loss: 7.2885
2025-03-02 14:22:42,958 - INFO - â”œâ”€â”€ Learning Rate: 2.48e-04
2025-03-02 14:22:42,958 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:22:43,636 - INFO - ðŸªœ Batch step - 1653 -- sub batch step 6612 -- lr 2.48e-04
2025-03-02 14:22:45,786 - INFO - ðŸªœ Batch step - 1653 -- sub batch step 6613 -- lr 2.48e-04
2025-03-02 14:22:48,173 - INFO - ðŸªœ Batch step - 1653 -- sub batch step 6614 -- lr 2.48e-04
2025-03-02 14:22:50,328 - INFO - ðŸªœ Batch step - 1653 -- sub batch step 6615 -- lr 2.48e-04
2025-03-02 14:22:52,236 - INFO - Step 1653 -- ðŸ”„ Training Metrics
2025-03-02 14:22:52,236 - INFO - â”œâ”€â”€ Loss: 7.2804
2025-03-02 14:22:52,236 - INFO - â”œâ”€â”€ Learning Rate: 2.48e-04
2025-03-02 14:22:52,236 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:22:52,908 - INFO - ðŸªœ Batch step - 1654 -- sub batch step 6616 -- lr 2.48e-04
2025-03-02 14:22:55,061 - INFO - ðŸªœ Batch step - 1654 -- sub batch step 6617 -- lr 2.48e-04
2025-03-02 14:22:57,223 - INFO - ðŸªœ Batch step - 1654 -- sub batch step 6618 -- lr 2.48e-04
2025-03-02 14:22:59,374 - INFO - ðŸªœ Batch step - 1654 -- sub batch step 6619 -- lr 2.48e-04
2025-03-02 14:23:00,937 - INFO - Step 1654 -- ðŸ”„ Training Metrics
2025-03-02 14:23:00,937 - INFO - â”œâ”€â”€ Loss: 7.2534
2025-03-02 14:23:00,937 - INFO - â”œâ”€â”€ Learning Rate: 2.48e-04
2025-03-02 14:23:00,937 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:23:01,613 - INFO - ðŸªœ Batch step - 1655 -- sub batch step 6620 -- lr 2.48e-04
2025-03-02 14:23:03,761 - INFO - ðŸªœ Batch step - 1655 -- sub batch step 6621 -- lr 2.48e-04
2025-03-02 14:23:06,421 - INFO - ðŸªœ Batch step - 1655 -- sub batch step 6622 -- lr 2.48e-04
2025-03-02 14:23:08,570 - INFO - ðŸªœ Batch step - 1655 -- sub batch step 6623 -- lr 2.48e-04
2025-03-02 14:23:10,068 - INFO - Step 1655 -- ðŸ”„ Training Metrics
2025-03-02 14:23:10,069 - INFO - â”œâ”€â”€ Loss: 7.2845
2025-03-02 14:23:10,069 - INFO - â”œâ”€â”€ Learning Rate: 2.48e-04
2025-03-02 14:23:10,069 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:23:10,741 - INFO - ðŸªœ Batch step - 1656 -- sub batch step 6624 -- lr 2.48e-04
2025-03-02 14:23:12,893 - INFO - ðŸªœ Batch step - 1656 -- sub batch step 6625 -- lr 2.48e-04
2025-03-02 14:23:15,058 - INFO - ðŸªœ Batch step - 1656 -- sub batch step 6626 -- lr 2.48e-04
2025-03-02 14:23:17,212 - INFO - ðŸªœ Batch step - 1656 -- sub batch step 6627 -- lr 2.48e-04
2025-03-02 14:23:18,764 - INFO - Step 1656 -- ðŸ”„ Training Metrics
2025-03-02 14:23:18,764 - INFO - â”œâ”€â”€ Loss: 7.2733
2025-03-02 14:23:18,764 - INFO - â”œâ”€â”€ Learning Rate: 2.48e-04
2025-03-02 14:23:18,764 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:23:19,431 - INFO - ðŸªœ Batch step - 1657 -- sub batch step 6628 -- lr 2.49e-04
2025-03-02 14:23:21,587 - INFO - ðŸªœ Batch step - 1657 -- sub batch step 6629 -- lr 2.49e-04
2025-03-02 14:23:24,261 - INFO - ðŸªœ Batch step - 1657 -- sub batch step 6630 -- lr 2.49e-04
2025-03-02 14:23:26,410 - INFO - ðŸªœ Batch step - 1657 -- sub batch step 6631 -- lr 2.49e-04
2025-03-02 14:23:27,936 - INFO - Step 1657 -- ðŸ”„ Training Metrics
2025-03-02 14:23:27,936 - INFO - â”œâ”€â”€ Loss: 7.2683
2025-03-02 14:23:27,936 - INFO - â”œâ”€â”€ Learning Rate: 2.49e-04
2025-03-02 14:23:27,936 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:23:28,610 - INFO - ðŸªœ Batch step - 1658 -- sub batch step 6632 -- lr 2.49e-04
2025-03-02 14:23:30,759 - INFO - ðŸªœ Batch step - 1658 -- sub batch step 6633 -- lr 2.49e-04
2025-03-02 14:23:32,933 - INFO - ðŸªœ Batch step - 1658 -- sub batch step 6634 -- lr 2.49e-04
2025-03-02 14:23:35,084 - INFO - ðŸªœ Batch step - 1658 -- sub batch step 6635 -- lr 2.49e-04
2025-03-02 14:23:36,654 - INFO - Step 1658 -- ðŸ”„ Training Metrics
2025-03-02 14:23:36,655 - INFO - â”œâ”€â”€ Loss: 7.2847
2025-03-02 14:23:36,655 - INFO - â”œâ”€â”€ Learning Rate: 2.49e-04
2025-03-02 14:23:36,655 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:23:37,325 - INFO - ðŸªœ Batch step - 1659 -- sub batch step 6636 -- lr 2.49e-04
2025-03-02 14:23:39,480 - INFO - ðŸªœ Batch step - 1659 -- sub batch step 6637 -- lr 2.49e-04
2025-03-02 14:23:41,763 - INFO - ðŸªœ Batch step - 1659 -- sub batch step 6638 -- lr 2.49e-04
2025-03-02 14:23:43,913 - INFO - ðŸªœ Batch step - 1659 -- sub batch step 6639 -- lr 2.49e-04
2025-03-02 14:23:45,532 - INFO - Step 1659 -- ðŸ”„ Training Metrics
2025-03-02 14:23:45,532 - INFO - â”œâ”€â”€ Loss: 7.2594
2025-03-02 14:23:45,532 - INFO - â”œâ”€â”€ Learning Rate: 2.49e-04
2025-03-02 14:23:45,532 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:23:46,695 - INFO - ðŸªœ Batch step - 1660 -- sub batch step 6640 -- lr 2.49e-04
2025-03-02 14:23:48,839 - INFO - ðŸªœ Batch step - 1660 -- sub batch step 6641 -- lr 2.49e-04
2025-03-02 14:23:50,989 - INFO - ðŸªœ Batch step - 1660 -- sub batch step 6642 -- lr 2.49e-04
2025-03-02 14:23:53,154 - INFO - ðŸªœ Batch step - 1660 -- sub batch step 6643 -- lr 2.49e-04
2025-03-02 14:23:54,951 - INFO - Step 1660 -- ðŸ”„ Training Metrics
2025-03-02 14:23:54,952 - INFO - â”œâ”€â”€ Loss: 7.2743
2025-03-02 14:23:54,952 - INFO - â”œâ”€â”€ Learning Rate: 2.49e-04
2025-03-02 14:23:54,952 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:23:55,625 - INFO - ðŸªœ Batch step - 1661 -- sub batch step 6644 -- lr 2.49e-04
2025-03-02 14:23:57,775 - INFO - ðŸªœ Batch step - 1661 -- sub batch step 6645 -- lr 2.49e-04
2025-03-02 14:23:59,919 - INFO - ðŸªœ Batch step - 1661 -- sub batch step 6646 -- lr 2.49e-04
2025-03-02 14:24:02,580 - INFO - ðŸªœ Batch step - 1661 -- sub batch step 6647 -- lr 2.49e-04
2025-03-02 14:24:04,893 - INFO - Step 1661 -- ðŸ”„ Training Metrics
2025-03-02 14:24:04,893 - INFO - â”œâ”€â”€ Loss: 7.2720
2025-03-02 14:24:04,893 - INFO - â”œâ”€â”€ Learning Rate: 2.49e-04
2025-03-02 14:24:04,893 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:24:05,558 - INFO - ðŸªœ Batch step - 1662 -- sub batch step 6648 -- lr 2.49e-04
2025-03-02 14:24:07,712 - INFO - ðŸªœ Batch step - 1662 -- sub batch step 6649 -- lr 2.49e-04
2025-03-02 14:24:09,862 - INFO - ðŸªœ Batch step - 1662 -- sub batch step 6650 -- lr 2.49e-04
2025-03-02 14:24:12,029 - INFO - ðŸªœ Batch step - 1662 -- sub batch step 6651 -- lr 2.49e-04
2025-03-02 14:24:13,600 - INFO - Step 1662 -- ðŸ”„ Training Metrics
2025-03-02 14:24:13,600 - INFO - â”œâ”€â”€ Loss: 7.2776
2025-03-02 14:24:13,600 - INFO - â”œâ”€â”€ Learning Rate: 2.49e-04
2025-03-02 14:24:13,600 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:24:14,270 - INFO - ðŸªœ Batch step - 1663 -- sub batch step 6652 -- lr 2.49e-04
2025-03-02 14:24:16,423 - INFO - ðŸªœ Batch step - 1663 -- sub batch step 6653 -- lr 2.49e-04
2025-03-02 14:24:18,575 - INFO - ðŸªœ Batch step - 1663 -- sub batch step 6654 -- lr 2.49e-04
2025-03-02 14:24:20,987 - INFO - ðŸªœ Batch step - 1663 -- sub batch step 6655 -- lr 2.49e-04
2025-03-02 14:24:22,753 - INFO - Step 1663 -- ðŸ”„ Training Metrics
2025-03-02 14:24:22,754 - INFO - â”œâ”€â”€ Loss: 7.2620
2025-03-02 14:24:22,754 - INFO - â”œâ”€â”€ Learning Rate: 2.49e-04
2025-03-02 14:24:22,754 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:24:23,425 - INFO - ðŸªœ Batch step - 1664 -- sub batch step 6656 -- lr 2.50e-04
2025-03-02 14:24:25,581 - INFO - ðŸªœ Batch step - 1664 -- sub batch step 6657 -- lr 2.50e-04
2025-03-02 14:24:27,727 - INFO - ðŸªœ Batch step - 1664 -- sub batch step 6658 -- lr 2.50e-04
2025-03-02 14:24:29,900 - INFO - ðŸªœ Batch step - 1664 -- sub batch step 6659 -- lr 2.50e-04
2025-03-02 14:24:31,454 - INFO - Step 1664 -- ðŸ”„ Training Metrics
2025-03-02 14:24:31,454 - INFO - â”œâ”€â”€ Loss: 7.2756
2025-03-02 14:24:31,454 - INFO - â”œâ”€â”€ Learning Rate: 2.50e-04
2025-03-02 14:24:31,454 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:24:32,129 - INFO - ðŸªœ Batch step - 1665 -- sub batch step 6660 -- lr 2.50e-04
2025-03-02 14:24:34,280 - INFO - ðŸªœ Batch step - 1665 -- sub batch step 6661 -- lr 2.50e-04
2025-03-02 14:24:36,434 - INFO - ðŸªœ Batch step - 1665 -- sub batch step 6662 -- lr 2.50e-04
2025-03-02 14:24:38,794 - INFO - ðŸªœ Batch step - 1665 -- sub batch step 6663 -- lr 2.50e-04
2025-03-02 14:24:40,747 - INFO - Step 1665 -- ðŸ”„ Training Metrics
2025-03-02 14:24:40,747 - INFO - â”œâ”€â”€ Loss: 7.2865
2025-03-02 14:24:40,748 - INFO - â”œâ”€â”€ Learning Rate: 2.50e-04
2025-03-02 14:24:40,748 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:24:41,421 - INFO - ðŸªœ Batch step - 1666 -- sub batch step 6664 -- lr 2.50e-04
2025-03-02 14:24:43,577 - INFO - ðŸªœ Batch step - 1666 -- sub batch step 6665 -- lr 2.50e-04
2025-03-02 14:24:45,723 - INFO - ðŸªœ Batch step - 1666 -- sub batch step 6666 -- lr 2.50e-04
2025-03-02 14:24:47,890 - INFO - ðŸªœ Batch step - 1666 -- sub batch step 6667 -- lr 2.50e-04
2025-03-02 14:24:49,450 - INFO - Step 1666 -- ðŸ”„ Training Metrics
2025-03-02 14:24:49,450 - INFO - â”œâ”€â”€ Loss: 7.2715
2025-03-02 14:24:49,450 - INFO - â”œâ”€â”€ Learning Rate: 2.50e-04
2025-03-02 14:24:49,450 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:24:50,116 - INFO - ðŸªœ Batch step - 1667 -- sub batch step 6668 -- lr 2.50e-04
2025-03-02 14:24:52,275 - INFO - ðŸªœ Batch step - 1667 -- sub batch step 6669 -- lr 2.50e-04
2025-03-02 14:24:54,432 - INFO - ðŸªœ Batch step - 1667 -- sub batch step 6670 -- lr 2.50e-04
2025-03-02 14:24:57,024 - INFO - ðŸªœ Batch step - 1667 -- sub batch step 6671 -- lr 2.50e-04
2025-03-02 14:24:58,634 - INFO - Step 1667 -- ðŸ”„ Training Metrics
2025-03-02 14:24:58,634 - INFO - â”œâ”€â”€ Loss: 7.2873
2025-03-02 14:24:58,634 - INFO - â”œâ”€â”€ Learning Rate: 2.50e-04
2025-03-02 14:24:58,634 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:24:59,306 - INFO - ðŸªœ Batch step - 1668 -- sub batch step 6672 -- lr 2.50e-04
2025-03-02 14:25:01,461 - INFO - ðŸªœ Batch step - 1668 -- sub batch step 6673 -- lr 2.50e-04
2025-03-02 14:25:03,617 - INFO - ðŸªœ Batch step - 1668 -- sub batch step 6674 -- lr 2.50e-04
2025-03-02 14:25:05,790 - INFO - ðŸªœ Batch step - 1668 -- sub batch step 6675 -- lr 2.50e-04
2025-03-02 14:25:07,340 - INFO - Step 1668 -- ðŸ”„ Training Metrics
2025-03-02 14:25:07,340 - INFO - â”œâ”€â”€ Loss: 7.2530
2025-03-02 14:25:07,340 - INFO - â”œâ”€â”€ Learning Rate: 2.50e-04
2025-03-02 14:25:07,340 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:25:08,007 - INFO - ðŸªœ Batch step - 1669 -- sub batch step 6676 -- lr 2.50e-04
2025-03-02 14:25:10,164 - INFO - ðŸªœ Batch step - 1669 -- sub batch step 6677 -- lr 2.50e-04
2025-03-02 14:25:12,312 - INFO - ðŸªœ Batch step - 1669 -- sub batch step 6678 -- lr 2.50e-04
2025-03-02 14:25:15,109 - INFO - ðŸªœ Batch step - 1669 -- sub batch step 6679 -- lr 2.50e-04
2025-03-02 14:25:16,599 - INFO - Step 1669 -- ðŸ”„ Training Metrics
2025-03-02 14:25:16,600 - INFO - â”œâ”€â”€ Loss: 7.2711
2025-03-02 14:25:16,600 - INFO - â”œâ”€â”€ Learning Rate: 2.50e-04
2025-03-02 14:25:16,600 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:25:17,279 - INFO - ðŸªœ Batch step - 1670 -- sub batch step 6680 -- lr 2.50e-04
2025-03-02 14:25:19,427 - INFO - ðŸªœ Batch step - 1670 -- sub batch step 6681 -- lr 2.50e-04
2025-03-02 14:25:21,582 - INFO - ðŸªœ Batch step - 1670 -- sub batch step 6682 -- lr 2.50e-04
2025-03-02 14:25:23,740 - INFO - ðŸªœ Batch step - 1670 -- sub batch step 6683 -- lr 2.50e-04
2025-03-02 14:25:25,282 - INFO - Step 1670 -- ðŸ”„ Training Metrics
2025-03-02 14:25:25,282 - INFO - â”œâ”€â”€ Loss: 7.2642
2025-03-02 14:25:25,282 - INFO - â”œâ”€â”€ Learning Rate: 2.50e-04
2025-03-02 14:25:25,282 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:25:25,959 - INFO - ðŸªœ Batch step - 1671 -- sub batch step 6684 -- lr 2.51e-04
2025-03-02 14:25:28,112 - INFO - ðŸªœ Batch step - 1671 -- sub batch step 6685 -- lr 2.51e-04
2025-03-02 14:25:30,947 - INFO - ðŸªœ Batch step - 1671 -- sub batch step 6686 -- lr 2.51e-04
2025-03-02 14:25:33,107 - INFO - ðŸªœ Batch step - 1671 -- sub batch step 6687 -- lr 2.51e-04
2025-03-02 14:25:34,599 - INFO - Step 1671 -- ðŸ”„ Training Metrics
2025-03-02 14:25:34,599 - INFO - â”œâ”€â”€ Loss: 7.2618
2025-03-02 14:25:34,599 - INFO - â”œâ”€â”€ Learning Rate: 2.51e-04
2025-03-02 14:25:34,599 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:25:35,267 - INFO - ðŸªœ Batch step - 1672 -- sub batch step 6688 -- lr 2.51e-04
2025-03-02 14:25:37,428 - INFO - ðŸªœ Batch step - 1672 -- sub batch step 6689 -- lr 2.51e-04
2025-03-02 14:25:39,600 - INFO - ðŸªœ Batch step - 1672 -- sub batch step 6690 -- lr 2.51e-04
2025-03-02 14:25:41,748 - INFO - ðŸªœ Batch step - 1672 -- sub batch step 6691 -- lr 2.51e-04
2025-03-02 14:25:43,285 - INFO - Step 1672 -- ðŸ”„ Training Metrics
2025-03-02 14:25:43,286 - INFO - â”œâ”€â”€ Loss: 7.2536
2025-03-02 14:25:43,286 - INFO - â”œâ”€â”€ Learning Rate: 2.51e-04
2025-03-02 14:25:43,286 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:25:43,957 - INFO - ðŸªœ Batch step - 1673 -- sub batch step 6692 -- lr 2.51e-04
2025-03-02 14:25:46,112 - INFO - ðŸªœ Batch step - 1673 -- sub batch step 6693 -- lr 2.51e-04
2025-03-02 14:25:48,787 - INFO - ðŸªœ Batch step - 1673 -- sub batch step 6694 -- lr 2.51e-04
2025-03-02 14:25:50,940 - INFO - ðŸªœ Batch step - 1673 -- sub batch step 6695 -- lr 2.51e-04
2025-03-02 14:25:52,440 - INFO - Step 1673 -- ðŸ”„ Training Metrics
2025-03-02 14:25:52,440 - INFO - â”œâ”€â”€ Loss: 7.2651
2025-03-02 14:25:52,440 - INFO - â”œâ”€â”€ Learning Rate: 2.51e-04
2025-03-02 14:25:52,440 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:25:53,107 - INFO - ðŸªœ Batch step - 1674 -- sub batch step 6696 -- lr 2.51e-04
2025-03-02 14:25:55,264 - INFO - ðŸªœ Batch step - 1674 -- sub batch step 6697 -- lr 2.51e-04
2025-03-02 14:25:57,426 - INFO - ðŸªœ Batch step - 1674 -- sub batch step 6698 -- lr 2.51e-04
2025-03-02 14:25:59,580 - INFO - ðŸªœ Batch step - 1674 -- sub batch step 6699 -- lr 2.51e-04
2025-03-02 14:26:01,370 - INFO - Step 1674 -- ðŸ”„ Training Metrics
2025-03-02 14:26:01,370 - INFO - â”œâ”€â”€ Loss: 7.2627
2025-03-02 14:26:01,370 - INFO - â”œâ”€â”€ Learning Rate: 2.51e-04
2025-03-02 14:26:01,370 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:26:02,041 - INFO - ðŸªœ Batch step - 1675 -- sub batch step 6700 -- lr 2.51e-04
2025-03-02 14:26:04,194 - INFO - ðŸªœ Batch step - 1675 -- sub batch step 6701 -- lr 2.51e-04
2025-03-02 14:26:07,586 - INFO - ðŸªœ Batch step - 1675 -- sub batch step 6702 -- lr 2.51e-04
2025-03-02 14:26:12,678 - INFO - ðŸªœ Batch step - 1675 -- sub batch step 6703 -- lr 2.51e-04
2025-03-02 14:26:14,381 - INFO - Step 1675 -- ðŸ”„ Training Metrics
2025-03-02 14:26:14,381 - INFO - â”œâ”€â”€ Loss: 7.2375
2025-03-02 14:26:14,382 - INFO - â”œâ”€â”€ Learning Rate: 2.51e-04
2025-03-02 14:26:14,382 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:26:15,280 - INFO - ðŸªœ Batch step - 1676 -- sub batch step 6704 -- lr 2.51e-04
2025-03-02 14:26:17,437 - INFO - ðŸªœ Batch step - 1676 -- sub batch step 6705 -- lr 2.51e-04
2025-03-02 14:26:19,603 - INFO - ðŸªœ Batch step - 1676 -- sub batch step 6706 -- lr 2.51e-04
2025-03-02 14:26:21,759 - INFO - ðŸªœ Batch step - 1676 -- sub batch step 6707 -- lr 2.51e-04
2025-03-02 14:26:23,297 - INFO - Step 1676 -- ðŸ”„ Training Metrics
2025-03-02 14:26:23,297 - INFO - â”œâ”€â”€ Loss: 7.2497
2025-03-02 14:26:23,298 - INFO - â”œâ”€â”€ Learning Rate: 2.51e-04
2025-03-02 14:26:23,298 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:26:23,963 - INFO - ðŸªœ Batch step - 1677 -- sub batch step 6708 -- lr 2.52e-04
2025-03-02 14:26:26,124 - INFO - ðŸªœ Batch step - 1677 -- sub batch step 6709 -- lr 2.52e-04
2025-03-02 14:26:28,773 - INFO - ðŸªœ Batch step - 1677 -- sub batch step 6710 -- lr 2.52e-04
2025-03-02 14:26:30,923 - INFO - ðŸªœ Batch step - 1677 -- sub batch step 6711 -- lr 2.52e-04
2025-03-02 14:26:33,297 - INFO - Step 1677 -- ðŸ”„ Training Metrics
2025-03-02 14:26:33,298 - INFO - â”œâ”€â”€ Loss: 7.2693
2025-03-02 14:26:33,298 - INFO - â”œâ”€â”€ Learning Rate: 2.52e-04
2025-03-02 14:26:33,298 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:26:34,065 - INFO - ðŸªœ Batch step - 1678 -- sub batch step 6712 -- lr 2.52e-04
2025-03-02 14:26:36,219 - INFO - ðŸªœ Batch step - 1678 -- sub batch step 6713 -- lr 2.52e-04
2025-03-02 14:26:38,395 - INFO - ðŸªœ Batch step - 1678 -- sub batch step 6714 -- lr 2.52e-04
2025-03-02 14:26:40,548 - INFO - ðŸªœ Batch step - 1678 -- sub batch step 6715 -- lr 2.52e-04
2025-03-02 14:26:42,084 - INFO - Step 1678 -- ðŸ”„ Training Metrics
2025-03-02 14:26:42,084 - INFO - â”œâ”€â”€ Loss: 7.2628
2025-03-02 14:26:42,084 - INFO - â”œâ”€â”€ Learning Rate: 2.52e-04
2025-03-02 14:26:42,085 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:26:42,756 - INFO - ðŸªœ Batch step - 1679 -- sub batch step 6716 -- lr 2.52e-04
2025-03-02 14:26:44,912 - INFO - ðŸªœ Batch step - 1679 -- sub batch step 6717 -- lr 2.52e-04
2025-03-02 14:26:47,189 - INFO - ðŸªœ Batch step - 1679 -- sub batch step 6718 -- lr 2.52e-04
2025-03-02 14:26:49,344 - INFO - ðŸªœ Batch step - 1679 -- sub batch step 6719 -- lr 2.52e-04
2025-03-02 14:26:51,014 - INFO - Step 1679 -- ðŸ”„ Training Metrics
2025-03-02 14:26:51,014 - INFO - â”œâ”€â”€ Loss: 7.2816
2025-03-02 14:26:51,014 - INFO - â”œâ”€â”€ Learning Rate: 2.52e-04
2025-03-02 14:26:51,014 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:26:52,169 - INFO - ðŸªœ Batch step - 1680 -- sub batch step 6720 -- lr 2.52e-04
2025-03-02 14:26:54,320 - INFO - ðŸªœ Batch step - 1680 -- sub batch step 6721 -- lr 2.52e-04
2025-03-02 14:26:56,477 - INFO - ðŸªœ Batch step - 1680 -- sub batch step 6722 -- lr 2.52e-04
2025-03-02 14:26:58,644 - INFO - ðŸªœ Batch step - 1680 -- sub batch step 6723 -- lr 2.52e-04
2025-03-02 14:27:00,778 - INFO - Step 1680 -- ðŸ”„ Training Metrics
2025-03-02 14:27:00,779 - INFO - â”œâ”€â”€ Loss: 7.2490
2025-03-02 14:27:00,779 - INFO - â”œâ”€â”€ Learning Rate: 2.52e-04
2025-03-02 14:27:00,779 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:27:01,451 - INFO - ðŸªœ Batch step - 1681 -- sub batch step 6724 -- lr 2.52e-04
2025-03-02 14:27:03,607 - INFO - ðŸªœ Batch step - 1681 -- sub batch step 6725 -- lr 2.52e-04
2025-03-02 14:27:05,754 - INFO - ðŸªœ Batch step - 1681 -- sub batch step 6726 -- lr 2.52e-04
2025-03-02 14:27:08,350 - INFO - ðŸªœ Batch step - 1681 -- sub batch step 6727 -- lr 2.52e-04
2025-03-02 14:27:10,509 - INFO - Step 1681 -- ðŸ”„ Training Metrics
2025-03-02 14:27:10,509 - INFO - â”œâ”€â”€ Loss: 7.2630
2025-03-02 14:27:10,509 - INFO - â”œâ”€â”€ Learning Rate: 2.52e-04
2025-03-02 14:27:10,509 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:27:11,174 - INFO - ðŸªœ Batch step - 1682 -- sub batch step 6728 -- lr 2.52e-04
2025-03-02 14:27:13,332 - INFO - ðŸªœ Batch step - 1682 -- sub batch step 6729 -- lr 2.52e-04
2025-03-02 14:27:15,482 - INFO - ðŸªœ Batch step - 1682 -- sub batch step 6730 -- lr 2.52e-04
2025-03-02 14:27:17,646 - INFO - ðŸªœ Batch step - 1682 -- sub batch step 6731 -- lr 2.52e-04
2025-03-02 14:27:19,234 - INFO - Step 1682 -- ðŸ”„ Training Metrics
2025-03-02 14:27:19,235 - INFO - â”œâ”€â”€ Loss: 7.2609
2025-03-02 14:27:19,235 - INFO - â”œâ”€â”€ Learning Rate: 2.52e-04
2025-03-02 14:27:19,235 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:27:19,922 - INFO - ðŸªœ Batch step - 1683 -- sub batch step 6732 -- lr 2.52e-04
2025-03-02 14:27:22,073 - INFO - ðŸªœ Batch step - 1683 -- sub batch step 6733 -- lr 2.52e-04
2025-03-02 14:27:24,229 - INFO - ðŸªœ Batch step - 1683 -- sub batch step 6734 -- lr 2.52e-04
2025-03-02 14:27:26,593 - INFO - ðŸªœ Batch step - 1683 -- sub batch step 6735 -- lr 2.52e-04
2025-03-02 14:27:28,524 - INFO - Step 1683 -- ðŸ”„ Training Metrics
2025-03-02 14:27:28,525 - INFO - â”œâ”€â”€ Loss: 7.2590
2025-03-02 14:27:28,525 - INFO - â”œâ”€â”€ Learning Rate: 2.52e-04
2025-03-02 14:27:28,542 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:27:29,218 - INFO - ðŸªœ Batch step - 1684 -- sub batch step 6736 -- lr 2.53e-04
2025-03-02 14:27:31,381 - INFO - ðŸªœ Batch step - 1684 -- sub batch step 6737 -- lr 2.53e-04
2025-03-02 14:27:33,528 - INFO - ðŸªœ Batch step - 1684 -- sub batch step 6738 -- lr 2.53e-04
2025-03-02 14:27:35,700 - INFO - ðŸªœ Batch step - 1684 -- sub batch step 6739 -- lr 2.53e-04
2025-03-02 14:27:37,237 - INFO - Step 1684 -- ðŸ”„ Training Metrics
2025-03-02 14:27:37,237 - INFO - â”œâ”€â”€ Loss: 7.2359
2025-03-02 14:27:37,237 - INFO - â”œâ”€â”€ Learning Rate: 2.53e-04
2025-03-02 14:27:37,238 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:27:37,908 - INFO - ðŸªœ Batch step - 1685 -- sub batch step 6740 -- lr 2.53e-04
2025-03-02 14:27:40,059 - INFO - ðŸªœ Batch step - 1685 -- sub batch step 6741 -- lr 2.53e-04
2025-03-02 14:27:42,218 - INFO - ðŸªœ Batch step - 1685 -- sub batch step 6742 -- lr 2.53e-04
2025-03-02 14:27:44,581 - INFO - ðŸªœ Batch step - 1685 -- sub batch step 6743 -- lr 2.53e-04
2025-03-02 14:27:46,457 - INFO - Step 1685 -- ðŸ”„ Training Metrics
2025-03-02 14:27:46,457 - INFO - â”œâ”€â”€ Loss: 7.2409
2025-03-02 14:27:46,458 - INFO - â”œâ”€â”€ Learning Rate: 2.53e-04
2025-03-02 14:27:46,458 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:27:47,131 - INFO - ðŸªœ Batch step - 1686 -- sub batch step 6744 -- lr 2.53e-04
2025-03-02 14:27:49,284 - INFO - ðŸªœ Batch step - 1686 -- sub batch step 6745 -- lr 2.53e-04
2025-03-02 14:27:51,429 - INFO - ðŸªœ Batch step - 1686 -- sub batch step 6746 -- lr 2.53e-04
2025-03-02 14:27:53,598 - INFO - ðŸªœ Batch step - 1686 -- sub batch step 6747 -- lr 2.53e-04
2025-03-02 14:27:55,157 - INFO - Step 1686 -- ðŸ”„ Training Metrics
2025-03-02 14:27:55,158 - INFO - â”œâ”€â”€ Loss: 7.2644
2025-03-02 14:27:55,158 - INFO - â”œâ”€â”€ Learning Rate: 2.53e-04
2025-03-02 14:27:55,158 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:27:55,825 - INFO - ðŸªœ Batch step - 1687 -- sub batch step 6748 -- lr 2.53e-04
2025-03-02 14:27:57,981 - INFO - ðŸªœ Batch step - 1687 -- sub batch step 6749 -- lr 2.53e-04
2025-03-02 14:28:00,132 - INFO - ðŸªœ Batch step - 1687 -- sub batch step 6750 -- lr 2.53e-04
2025-03-02 14:28:02,790 - INFO - ðŸªœ Batch step - 1687 -- sub batch step 6751 -- lr 2.53e-04
2025-03-02 14:28:04,442 - INFO - Step 1687 -- ðŸ”„ Training Metrics
2025-03-02 14:28:04,442 - INFO - â”œâ”€â”€ Loss: 7.2572
2025-03-02 14:28:04,442 - INFO - â”œâ”€â”€ Learning Rate: 2.53e-04
2025-03-02 14:28:04,442 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:28:05,117 - INFO - ðŸªœ Batch step - 1688 -- sub batch step 6752 -- lr 2.53e-04
2025-03-02 14:28:07,267 - INFO - ðŸªœ Batch step - 1688 -- sub batch step 6753 -- lr 2.53e-04
2025-03-02 14:28:09,422 - INFO - ðŸªœ Batch step - 1688 -- sub batch step 6754 -- lr 2.53e-04
2025-03-02 14:28:11,591 - INFO - ðŸªœ Batch step - 1688 -- sub batch step 6755 -- lr 2.53e-04
2025-03-02 14:28:13,140 - INFO - Step 1688 -- ðŸ”„ Training Metrics
2025-03-02 14:28:13,141 - INFO - â”œâ”€â”€ Loss: 7.2275
2025-03-02 14:28:13,141 - INFO - â”œâ”€â”€ Learning Rate: 2.53e-04
2025-03-02 14:28:13,141 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:28:13,810 - INFO - ðŸªœ Batch step - 1689 -- sub batch step 6756 -- lr 2.53e-04
2025-03-02 14:28:15,969 - INFO - ðŸªœ Batch step - 1689 -- sub batch step 6757 -- lr 2.53e-04
2025-03-02 14:28:18,117 - INFO - ðŸªœ Batch step - 1689 -- sub batch step 6758 -- lr 2.53e-04
2025-03-02 14:28:20,517 - INFO - ðŸªœ Batch step - 1689 -- sub batch step 6759 -- lr 2.53e-04
2025-03-02 14:28:22,305 - INFO - Step 1689 -- ðŸ”„ Training Metrics
2025-03-02 14:28:22,305 - INFO - â”œâ”€â”€ Loss: 7.2508
2025-03-02 14:28:22,305 - INFO - â”œâ”€â”€ Learning Rate: 2.53e-04
2025-03-02 14:28:22,306 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:28:22,983 - INFO - ðŸªœ Batch step - 1690 -- sub batch step 6760 -- lr 2.53e-04
2025-03-02 14:28:25,130 - INFO - ðŸªœ Batch step - 1690 -- sub batch step 6761 -- lr 2.53e-04
2025-03-02 14:28:27,283 - INFO - ðŸªœ Batch step - 1690 -- sub batch step 6762 -- lr 2.53e-04
2025-03-02 14:28:29,443 - INFO - ðŸªœ Batch step - 1690 -- sub batch step 6763 -- lr 2.53e-04
2025-03-02 14:28:30,990 - INFO - Step 1690 -- ðŸ”„ Training Metrics
2025-03-02 14:28:30,990 - INFO - â”œâ”€â”€ Loss: 7.2729
2025-03-02 14:28:30,991 - INFO - â”œâ”€â”€ Learning Rate: 2.53e-04
2025-03-02 14:28:30,991 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:28:31,664 - INFO - ðŸªœ Batch step - 1691 -- sub batch step 6764 -- lr 2.54e-04
2025-03-02 14:28:33,819 - INFO - ðŸªœ Batch step - 1691 -- sub batch step 6765 -- lr 2.54e-04
2025-03-02 14:28:36,370 - INFO - ðŸªœ Batch step - 1691 -- sub batch step 6766 -- lr 2.54e-04
2025-03-02 14:28:38,526 - INFO - ðŸªœ Batch step - 1691 -- sub batch step 6767 -- lr 2.54e-04
2025-03-02 14:28:40,166 - INFO - Step 1691 -- ðŸ”„ Training Metrics
2025-03-02 14:28:40,167 - INFO - â”œâ”€â”€ Loss: 7.2544
2025-03-02 14:28:40,167 - INFO - â”œâ”€â”€ Learning Rate: 2.54e-04
2025-03-02 14:28:40,167 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:28:40,835 - INFO - ðŸªœ Batch step - 1692 -- sub batch step 6768 -- lr 2.54e-04
2025-03-02 14:28:42,992 - INFO - ðŸªœ Batch step - 1692 -- sub batch step 6769 -- lr 2.54e-04
2025-03-02 14:28:45,158 - INFO - ðŸªœ Batch step - 1692 -- sub batch step 6770 -- lr 2.54e-04
2025-03-02 14:28:47,306 - INFO - ðŸªœ Batch step - 1692 -- sub batch step 6771 -- lr 2.54e-04
2025-03-02 14:28:48,876 - INFO - Step 1692 -- ðŸ”„ Training Metrics
2025-03-02 14:28:48,877 - INFO - â”œâ”€â”€ Loss: 7.2978
2025-03-02 14:28:48,877 - INFO - â”œâ”€â”€ Learning Rate: 2.54e-04
2025-03-02 14:28:48,877 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:28:49,549 - INFO - ðŸªœ Batch step - 1693 -- sub batch step 6772 -- lr 2.54e-04
2025-03-02 14:28:51,701 - INFO - ðŸªœ Batch step - 1693 -- sub batch step 6773 -- lr 2.54e-04
2025-03-02 14:28:54,361 - INFO - ðŸªœ Batch step - 1693 -- sub batch step 6774 -- lr 2.54e-04
2025-03-02 14:28:56,550 - INFO - ðŸªœ Batch step - 1693 -- sub batch step 6775 -- lr 2.54e-04
2025-03-02 14:28:58,225 - INFO - Step 1693 -- ðŸ”„ Training Metrics
2025-03-02 14:28:58,225 - INFO - â”œâ”€â”€ Loss: 7.2389
2025-03-02 14:28:58,225 - INFO - â”œâ”€â”€ Learning Rate: 2.54e-04
2025-03-02 14:28:58,225 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:28:58,923 - INFO - ðŸªœ Batch step - 1694 -- sub batch step 6776 -- lr 2.54e-04
2025-03-02 14:29:01,080 - INFO - ðŸªœ Batch step - 1694 -- sub batch step 6777 -- lr 2.54e-04
2025-03-02 14:29:03,482 - INFO - ðŸªœ Batch step - 1694 -- sub batch step 6778 -- lr 2.54e-04
2025-03-02 14:29:05,637 - INFO - ðŸªœ Batch step - 1694 -- sub batch step 6779 -- lr 2.54e-04
2025-03-02 14:29:07,161 - INFO - Step 1694 -- ðŸ”„ Training Metrics
2025-03-02 14:29:07,161 - INFO - â”œâ”€â”€ Loss: 7.2739
2025-03-02 14:29:07,161 - INFO - â”œâ”€â”€ Learning Rate: 2.54e-04
2025-03-02 14:29:07,161 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:29:07,834 - INFO - ðŸªœ Batch step - 1695 -- sub batch step 6780 -- lr 2.54e-04
2025-03-02 14:29:09,983 - INFO - ðŸªœ Batch step - 1695 -- sub batch step 6781 -- lr 2.54e-04
2025-03-02 14:29:12,347 - INFO - ðŸªœ Batch step - 1695 -- sub batch step 6782 -- lr 2.54e-04
2025-03-02 14:29:14,497 - INFO - ðŸªœ Batch step - 1695 -- sub batch step 6783 -- lr 2.54e-04
2025-03-02 14:29:16,718 - INFO - Step 1695 -- ðŸ”„ Training Metrics
2025-03-02 14:29:16,718 - INFO - â”œâ”€â”€ Loss: 7.2333
2025-03-02 14:29:16,718 - INFO - â”œâ”€â”€ Learning Rate: 2.54e-04
2025-03-02 14:29:16,719 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:29:17,397 - INFO - ðŸªœ Batch step - 1696 -- sub batch step 6784 -- lr 2.54e-04
2025-03-02 14:29:19,550 - INFO - ðŸªœ Batch step - 1696 -- sub batch step 6785 -- lr 2.54e-04
2025-03-02 14:29:21,711 - INFO - ðŸªœ Batch step - 1696 -- sub batch step 6786 -- lr 2.54e-04
2025-03-02 14:29:23,866 - INFO - ðŸªœ Batch step - 1696 -- sub batch step 6787 -- lr 2.54e-04
2025-03-02 14:29:25,420 - INFO - Step 1696 -- ðŸ”„ Training Metrics
2025-03-02 14:29:25,420 - INFO - â”œâ”€â”€ Loss: 7.2540
2025-03-02 14:29:25,420 - INFO - â”œâ”€â”€ Learning Rate: 2.54e-04
2025-03-02 14:29:25,421 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:29:26,087 - INFO - ðŸªœ Batch step - 1697 -- sub batch step 6788 -- lr 2.55e-04
2025-03-02 14:29:28,244 - INFO - ðŸªœ Batch step - 1697 -- sub batch step 6789 -- lr 2.55e-04
2025-03-02 14:29:30,878 - INFO - ðŸªœ Batch step - 1697 -- sub batch step 6790 -- lr 2.55e-04
2025-03-02 14:29:33,030 - INFO - ðŸªœ Batch step - 1697 -- sub batch step 6791 -- lr 2.55e-04
2025-03-02 14:29:34,738 - INFO - Step 1697 -- ðŸ”„ Training Metrics
2025-03-02 14:29:34,738 - INFO - â”œâ”€â”€ Loss: 7.2636
2025-03-02 14:29:34,738 - INFO - â”œâ”€â”€ Learning Rate: 2.55e-04
2025-03-02 14:29:34,738 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:29:35,414 - INFO - ðŸªœ Batch step - 1698 -- sub batch step 6792 -- lr 2.55e-04
2025-03-02 14:29:37,564 - INFO - ðŸªœ Batch step - 1698 -- sub batch step 6793 -- lr 2.55e-04
2025-03-02 14:29:39,733 - INFO - ðŸªœ Batch step - 1698 -- sub batch step 6794 -- lr 2.55e-04
2025-03-02 14:29:41,890 - INFO - ðŸªœ Batch step - 1698 -- sub batch step 6795 -- lr 2.55e-04
2025-03-02 14:29:43,435 - INFO - Step 1698 -- ðŸ”„ Training Metrics
2025-03-02 14:29:43,435 - INFO - â”œâ”€â”€ Loss: 7.2515
2025-03-02 14:29:43,435 - INFO - â”œâ”€â”€ Learning Rate: 2.55e-04
2025-03-02 14:29:43,435 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:29:44,106 - INFO - ðŸªœ Batch step - 1699 -- sub batch step 6796 -- lr 2.55e-04
2025-03-02 14:29:46,261 - INFO - ðŸªœ Batch step - 1699 -- sub batch step 6797 -- lr 2.55e-04
2025-03-02 14:29:48,534 - INFO - ðŸªœ Batch step - 1699 -- sub batch step 6798 -- lr 2.55e-04
2025-03-02 14:29:50,687 - INFO - ðŸªœ Batch step - 1699 -- sub batch step 6799 -- lr 2.55e-04
2025-03-02 14:29:52,236 - INFO - Step 1699 -- ðŸ”„ Training Metrics
2025-03-02 14:29:52,236 - INFO - â”œâ”€â”€ Loss: 7.2308
2025-03-02 14:29:52,236 - INFO - â”œâ”€â”€ Learning Rate: 2.55e-04
2025-03-02 14:29:52,236 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:29:53,559 - INFO - ðŸªœ Batch step - 1700 -- sub batch step 6800 -- lr 2.55e-04
2025-03-02 14:29:55,713 - INFO - ðŸªœ Batch step - 1700 -- sub batch step 6801 -- lr 2.55e-04
2025-03-02 14:29:57,870 - INFO - ðŸªœ Batch step - 1700 -- sub batch step 6802 -- lr 2.55e-04
2025-03-02 14:30:00,042 - INFO - ðŸªœ Batch step - 1700 -- sub batch step 6803 -- lr 2.55e-04
2025-03-02 14:30:01,579 - INFO - Step 1700 -- ðŸ”„ Training Metrics
2025-03-02 14:30:01,579 - INFO - â”œâ”€â”€ Loss: 7.2531
2025-03-02 14:30:01,579 - INFO - â”œâ”€â”€ Learning Rate: 2.55e-04
2025-03-02 14:30:01,579 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:30:02,260 - INFO - ðŸªœ Batch step - 1701 -- sub batch step 6804 -- lr 2.55e-04
2025-03-02 14:30:04,415 - INFO - ðŸªœ Batch step - 1701 -- sub batch step 6805 -- lr 2.55e-04
2025-03-02 14:30:06,570 - INFO - ðŸªœ Batch step - 1701 -- sub batch step 6806 -- lr 2.55e-04
2025-03-02 14:30:09,329 - INFO - ðŸªœ Batch step - 1701 -- sub batch step 6807 -- lr 2.55e-04
2025-03-02 14:30:10,819 - INFO - Step 1701 -- ðŸ”„ Training Metrics
2025-03-02 14:30:10,820 - INFO - â”œâ”€â”€ Loss: 7.2500
2025-03-02 14:30:10,820 - INFO - â”œâ”€â”€ Learning Rate: 2.55e-04
2025-03-02 14:30:10,820 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:30:11,494 - INFO - ðŸªœ Batch step - 1702 -- sub batch step 6808 -- lr 2.55e-04
2025-03-02 14:30:13,652 - INFO - ðŸªœ Batch step - 1702 -- sub batch step 6809 -- lr 2.55e-04
2025-03-02 14:30:15,813 - INFO - ðŸªœ Batch step - 1702 -- sub batch step 6810 -- lr 2.55e-04
2025-03-02 14:30:17,982 - INFO - ðŸªœ Batch step - 1702 -- sub batch step 6811 -- lr 2.55e-04
2025-03-02 14:30:19,513 - INFO - Step 1702 -- ðŸ”„ Training Metrics
2025-03-02 14:30:19,513 - INFO - â”œâ”€â”€ Loss: 7.2670
2025-03-02 14:30:19,514 - INFO - â”œâ”€â”€ Learning Rate: 2.55e-04
2025-03-02 14:30:19,514 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:30:20,190 - INFO - ðŸªœ Batch step - 1703 -- sub batch step 6812 -- lr 2.55e-04
2025-03-02 14:30:22,342 - INFO - ðŸªœ Batch step - 1703 -- sub batch step 6813 -- lr 2.55e-04
2025-03-02 14:30:24,495 - INFO - ðŸªœ Batch step - 1703 -- sub batch step 6814 -- lr 2.55e-04
2025-03-02 14:30:27,203 - INFO - ðŸªœ Batch step - 1703 -- sub batch step 6815 -- lr 2.55e-04
2025-03-02 14:30:28,787 - INFO - Step 1703 -- ðŸ”„ Training Metrics
2025-03-02 14:30:28,787 - INFO - â”œâ”€â”€ Loss: 7.2663
2025-03-02 14:30:28,787 - INFO - â”œâ”€â”€ Learning Rate: 2.55e-04
2025-03-02 14:30:28,787 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:30:29,457 - INFO - ðŸªœ Batch step - 1704 -- sub batch step 6816 -- lr 2.56e-04
2025-03-02 14:30:31,613 - INFO - ðŸªœ Batch step - 1704 -- sub batch step 6817 -- lr 2.56e-04
2025-03-02 14:30:33,758 - INFO - ðŸªœ Batch step - 1704 -- sub batch step 6818 -- lr 2.56e-04
2025-03-02 14:30:35,925 - INFO - ðŸªœ Batch step - 1704 -- sub batch step 6819 -- lr 2.56e-04
2025-03-02 14:30:37,467 - INFO - Step 1704 -- ðŸ”„ Training Metrics
2025-03-02 14:30:37,467 - INFO - â”œâ”€â”€ Loss: 7.2396
2025-03-02 14:30:37,467 - INFO - â”œâ”€â”€ Learning Rate: 2.56e-04
2025-03-02 14:30:37,468 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:30:38,144 - INFO - ðŸªœ Batch step - 1705 -- sub batch step 6820 -- lr 2.56e-04
2025-03-02 14:30:40,290 - INFO - ðŸªœ Batch step - 1705 -- sub batch step 6821 -- lr 2.56e-04
2025-03-02 14:30:42,443 - INFO - ðŸªœ Batch step - 1705 -- sub batch step 6822 -- lr 2.56e-04
2025-03-02 14:30:45,054 - INFO - ðŸªœ Batch step - 1705 -- sub batch step 6823 -- lr 2.56e-04
2025-03-02 14:30:46,699 - INFO - Step 1705 -- ðŸ”„ Training Metrics
2025-03-02 14:30:46,700 - INFO - â”œâ”€â”€ Loss: 7.2247
2025-03-02 14:30:46,700 - INFO - â”œâ”€â”€ Learning Rate: 2.56e-04
2025-03-02 14:30:46,700 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:30:47,376 - INFO - ðŸªœ Batch step - 1706 -- sub batch step 6824 -- lr 2.56e-04
2025-03-02 14:30:49,532 - INFO - ðŸªœ Batch step - 1706 -- sub batch step 6825 -- lr 2.56e-04
2025-03-02 14:30:51,678 - INFO - ðŸªœ Batch step - 1706 -- sub batch step 6826 -- lr 2.56e-04
2025-03-02 14:30:53,847 - INFO - ðŸªœ Batch step - 1706 -- sub batch step 6827 -- lr 2.56e-04
2025-03-02 14:30:55,409 - INFO - Step 1706 -- ðŸ”„ Training Metrics
2025-03-02 14:30:55,409 - INFO - â”œâ”€â”€ Loss: 7.2742
2025-03-02 14:30:55,410 - INFO - â”œâ”€â”€ Learning Rate: 2.56e-04
2025-03-02 14:30:55,410 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:30:56,077 - INFO - ðŸªœ Batch step - 1707 -- sub batch step 6828 -- lr 2.56e-04
2025-03-02 14:30:58,232 - INFO - ðŸªœ Batch step - 1707 -- sub batch step 6829 -- lr 2.56e-04
2025-03-02 14:31:00,386 - INFO - ðŸªœ Batch step - 1707 -- sub batch step 6830 -- lr 2.56e-04
2025-03-02 14:31:03,025 - INFO - ðŸªœ Batch step - 1707 -- sub batch step 6831 -- lr 2.56e-04
2025-03-02 14:31:04,571 - INFO - Step 1707 -- ðŸ”„ Training Metrics
2025-03-02 14:31:04,572 - INFO - â”œâ”€â”€ Loss: 7.2547
2025-03-02 14:31:04,572 - INFO - â”œâ”€â”€ Learning Rate: 2.56e-04
2025-03-02 14:31:04,572 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:31:05,244 - INFO - ðŸªœ Batch step - 1708 -- sub batch step 6832 -- lr 2.56e-04
2025-03-02 14:31:07,392 - INFO - ðŸªœ Batch step - 1708 -- sub batch step 6833 -- lr 2.56e-04
2025-03-02 14:31:09,547 - INFO - ðŸªœ Batch step - 1708 -- sub batch step 6834 -- lr 2.56e-04
2025-03-02 14:31:11,723 - INFO - ðŸªœ Batch step - 1708 -- sub batch step 6835 -- lr 2.56e-04
2025-03-02 14:31:13,274 - INFO - Step 1708 -- ðŸ”„ Training Metrics
2025-03-02 14:31:13,274 - INFO - â”œâ”€â”€ Loss: 7.2324
2025-03-02 14:31:13,274 - INFO - â”œâ”€â”€ Learning Rate: 2.56e-04
2025-03-02 14:31:13,275 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:31:13,940 - INFO - ðŸªœ Batch step - 1709 -- sub batch step 6836 -- lr 2.56e-04
2025-03-02 14:31:16,096 - INFO - ðŸªœ Batch step - 1709 -- sub batch step 6837 -- lr 2.56e-04
2025-03-02 14:31:18,243 - INFO - ðŸªœ Batch step - 1709 -- sub batch step 6838 -- lr 2.56e-04
2025-03-02 14:31:20,887 - INFO - ðŸªœ Batch step - 1709 -- sub batch step 6839 -- lr 2.56e-04
2025-03-02 14:31:22,554 - INFO - Step 1709 -- ðŸ”„ Training Metrics
2025-03-02 14:31:22,554 - INFO - â”œâ”€â”€ Loss: 7.2589
2025-03-02 14:31:22,554 - INFO - â”œâ”€â”€ Learning Rate: 2.56e-04
2025-03-02 14:31:22,555 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:31:23,231 - INFO - ðŸªœ Batch step - 1710 -- sub batch step 6840 -- lr 2.56e-04
2025-03-02 14:31:25,382 - INFO - ðŸªœ Batch step - 1710 -- sub batch step 6841 -- lr 2.56e-04
2025-03-02 14:31:27,535 - INFO - ðŸªœ Batch step - 1710 -- sub batch step 6842 -- lr 2.56e-04
2025-03-02 14:31:29,696 - INFO - ðŸªœ Batch step - 1710 -- sub batch step 6843 -- lr 2.56e-04
2025-03-02 14:31:31,237 - INFO - Step 1710 -- ðŸ”„ Training Metrics
2025-03-02 14:31:31,237 - INFO - â”œâ”€â”€ Loss: 7.2448
2025-03-02 14:31:31,237 - INFO - â”œâ”€â”€ Learning Rate: 2.56e-04
2025-03-02 14:31:31,237 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:31:31,913 - INFO - ðŸªœ Batch step - 1711 -- sub batch step 6844 -- lr 2.57e-04
2025-03-02 14:31:34,066 - INFO - ðŸªœ Batch step - 1711 -- sub batch step 6845 -- lr 2.57e-04
2025-03-02 14:31:36,768 - INFO - ðŸªœ Batch step - 1711 -- sub batch step 6846 -- lr 2.57e-04
2025-03-02 14:31:38,921 - INFO - ðŸªœ Batch step - 1711 -- sub batch step 6847 -- lr 2.57e-04
2025-03-02 14:31:40,473 - INFO - Step 1711 -- ðŸ”„ Training Metrics
2025-03-02 14:31:40,473 - INFO - â”œâ”€â”€ Loss: 7.2496
2025-03-02 14:31:40,473 - INFO - â”œâ”€â”€ Learning Rate: 2.57e-04
2025-03-02 14:31:40,473 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:31:41,143 - INFO - ðŸªœ Batch step - 1712 -- sub batch step 6848 -- lr 2.57e-04
2025-03-02 14:31:43,303 - INFO - ðŸªœ Batch step - 1712 -- sub batch step 6849 -- lr 2.57e-04
2025-03-02 14:31:45,470 - INFO - ðŸªœ Batch step - 1712 -- sub batch step 6850 -- lr 2.57e-04
2025-03-02 14:31:47,616 - INFO - ðŸªœ Batch step - 1712 -- sub batch step 6851 -- lr 2.57e-04
2025-03-02 14:31:49,160 - INFO - Step 1712 -- ðŸ”„ Training Metrics
2025-03-02 14:31:49,161 - INFO - â”œâ”€â”€ Loss: 7.2599
2025-03-02 14:31:49,161 - INFO - â”œâ”€â”€ Learning Rate: 2.57e-04
2025-03-02 14:31:49,161 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:31:49,834 - INFO - ðŸªœ Batch step - 1713 -- sub batch step 6852 -- lr 2.57e-04
2025-03-02 14:31:51,985 - INFO - ðŸªœ Batch step - 1713 -- sub batch step 6853 -- lr 2.57e-04
2025-03-02 14:31:54,441 - INFO - ðŸªœ Batch step - 1713 -- sub batch step 6854 -- lr 2.57e-04
2025-03-02 14:31:56,594 - INFO - ðŸªœ Batch step - 1713 -- sub batch step 6855 -- lr 2.57e-04
2025-03-02 14:31:58,388 - INFO - Step 1713 -- ðŸ”„ Training Metrics
2025-03-02 14:31:58,388 - INFO - â”œâ”€â”€ Loss: 7.2552
2025-03-02 14:31:58,388 - INFO - â”œâ”€â”€ Learning Rate: 2.57e-04
2025-03-02 14:31:58,388 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:31:59,058 - INFO - ðŸªœ Batch step - 1714 -- sub batch step 6856 -- lr 2.57e-04
2025-03-02 14:32:01,211 - INFO - ðŸªœ Batch step - 1714 -- sub batch step 6857 -- lr 2.57e-04
2025-03-02 14:32:03,373 - INFO - ðŸªœ Batch step - 1714 -- sub batch step 6858 -- lr 2.57e-04
2025-03-02 14:32:05,523 - INFO - ðŸªœ Batch step - 1714 -- sub batch step 6859 -- lr 2.57e-04
2025-03-02 14:32:07,071 - INFO - Step 1714 -- ðŸ”„ Training Metrics
2025-03-02 14:32:07,072 - INFO - â”œâ”€â”€ Loss: 7.2384
2025-03-02 14:32:07,072 - INFO - â”œâ”€â”€ Learning Rate: 2.57e-04
2025-03-02 14:32:07,072 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:32:07,747 - INFO - ðŸªœ Batch step - 1715 -- sub batch step 6860 -- lr 2.57e-04
2025-03-02 14:32:09,898 - INFO - ðŸªœ Batch step - 1715 -- sub batch step 6861 -- lr 2.57e-04
2025-03-02 14:32:12,541 - INFO - ðŸªœ Batch step - 1715 -- sub batch step 6862 -- lr 2.57e-04
2025-03-02 14:32:14,693 - INFO - ðŸªœ Batch step - 1715 -- sub batch step 6863 -- lr 2.57e-04
2025-03-02 14:32:16,238 - INFO - Step 1715 -- ðŸ”„ Training Metrics
2025-03-02 14:32:16,239 - INFO - â”œâ”€â”€ Loss: 7.2446
2025-03-02 14:32:16,239 - INFO - â”œâ”€â”€ Learning Rate: 2.57e-04
2025-03-02 14:32:16,239 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:32:16,913 - INFO - ðŸªœ Batch step - 1716 -- sub batch step 6864 -- lr 2.57e-04
2025-03-02 14:32:19,066 - INFO - ðŸªœ Batch step - 1716 -- sub batch step 6865 -- lr 2.57e-04
2025-03-02 14:32:21,229 - INFO - ðŸªœ Batch step - 1716 -- sub batch step 6866 -- lr 2.57e-04
2025-03-02 14:32:23,381 - INFO - ðŸªœ Batch step - 1716 -- sub batch step 6867 -- lr 2.57e-04
2025-03-02 14:32:24,932 - INFO - Step 1716 -- ðŸ”„ Training Metrics
2025-03-02 14:32:24,932 - INFO - â”œâ”€â”€ Loss: 7.2371
2025-03-02 14:32:24,932 - INFO - â”œâ”€â”€ Learning Rate: 2.57e-04
2025-03-02 14:32:24,932 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:32:25,601 - INFO - ðŸªœ Batch step - 1717 -- sub batch step 6868 -- lr 2.58e-04
2025-03-02 14:32:27,758 - INFO - ðŸªœ Batch step - 1717 -- sub batch step 6869 -- lr 2.58e-04
2025-03-02 14:32:30,475 - INFO - ðŸªœ Batch step - 1717 -- sub batch step 6870 -- lr 2.58e-04
2025-03-02 14:32:32,627 - INFO - ðŸªœ Batch step - 1717 -- sub batch step 6871 -- lr 2.58e-04
2025-03-02 14:32:34,155 - INFO - Step 1717 -- ðŸ”„ Training Metrics
2025-03-02 14:32:34,155 - INFO - â”œâ”€â”€ Loss: 7.2677
2025-03-02 14:32:34,155 - INFO - â”œâ”€â”€ Learning Rate: 2.58e-04
2025-03-02 14:32:34,156 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:32:34,829 - INFO - ðŸªœ Batch step - 1718 -- sub batch step 6872 -- lr 2.58e-04
2025-03-02 14:32:36,981 - INFO - ðŸªœ Batch step - 1718 -- sub batch step 6873 -- lr 2.58e-04
2025-03-02 14:32:39,153 - INFO - ðŸªœ Batch step - 1718 -- sub batch step 6874 -- lr 2.58e-04
2025-03-02 14:32:41,304 - INFO - ðŸªœ Batch step - 1718 -- sub batch step 6875 -- lr 2.58e-04
2025-03-02 14:32:42,841 - INFO - Step 1718 -- ðŸ”„ Training Metrics
2025-03-02 14:32:42,841 - INFO - â”œâ”€â”€ Loss: 7.2375
2025-03-02 14:32:42,841 - INFO - â”œâ”€â”€ Learning Rate: 2.58e-04
2025-03-02 14:32:42,841 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:32:43,507 - INFO - ðŸªœ Batch step - 1719 -- sub batch step 6876 -- lr 2.58e-04
2025-03-02 14:32:45,663 - INFO - ðŸªœ Batch step - 1719 -- sub batch step 6877 -- lr 2.58e-04
2025-03-02 14:32:47,970 - INFO - ðŸªœ Batch step - 1719 -- sub batch step 6878 -- lr 2.58e-04
2025-03-02 14:32:50,123 - INFO - ðŸªœ Batch step - 1719 -- sub batch step 6879 -- lr 2.58e-04
2025-03-02 14:32:51,888 - INFO - Step 1719 -- ðŸ”„ Training Metrics
2025-03-02 14:32:51,888 - INFO - â”œâ”€â”€ Loss: 7.2125
2025-03-02 14:32:51,888 - INFO - â”œâ”€â”€ Learning Rate: 2.58e-04
2025-03-02 14:32:51,889 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:32:53,156 - INFO - ðŸªœ Batch step - 1720 -- sub batch step 6880 -- lr 2.58e-04
2025-03-02 14:32:55,303 - INFO - ðŸªœ Batch step - 1720 -- sub batch step 6881 -- lr 2.58e-04
2025-03-02 14:32:57,457 - INFO - ðŸªœ Batch step - 1720 -- sub batch step 6882 -- lr 2.58e-04
2025-03-02 14:32:59,626 - INFO - ðŸªœ Batch step - 1720 -- sub batch step 6883 -- lr 2.58e-04
2025-03-02 14:33:01,553 - INFO - Step 1720 -- ðŸ”„ Training Metrics
2025-03-02 14:33:01,554 - INFO - â”œâ”€â”€ Loss: 7.2539
2025-03-02 14:33:01,554 - INFO - â”œâ”€â”€ Learning Rate: 2.58e-04
2025-03-02 14:33:01,554 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:33:02,233 - INFO - ðŸªœ Batch step - 1721 -- sub batch step 6884 -- lr 2.58e-04
2025-03-02 14:33:04,395 - INFO - ðŸªœ Batch step - 1721 -- sub batch step 6885 -- lr 2.58e-04
2025-03-02 14:33:06,554 - INFO - ðŸªœ Batch step - 1721 -- sub batch step 6886 -- lr 2.58e-04
2025-03-02 14:33:09,150 - INFO - ðŸªœ Batch step - 1721 -- sub batch step 6887 -- lr 2.58e-04
2025-03-02 14:33:10,852 - INFO - Step 1721 -- ðŸ”„ Training Metrics
2025-03-02 14:33:10,852 - INFO - â”œâ”€â”€ Loss: 7.2418
2025-03-02 14:33:10,853 - INFO - â”œâ”€â”€ Learning Rate: 2.58e-04
2025-03-02 14:33:10,853 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:33:11,521 - INFO - ðŸªœ Batch step - 1722 -- sub batch step 6888 -- lr 2.58e-04
2025-03-02 14:33:13,683 - INFO - ðŸªœ Batch step - 1722 -- sub batch step 6889 -- lr 2.58e-04
2025-03-02 14:33:15,839 - INFO - ðŸªœ Batch step - 1722 -- sub batch step 6890 -- lr 2.58e-04
2025-03-02 14:33:18,000 - INFO - ðŸªœ Batch step - 1722 -- sub batch step 6891 -- lr 2.58e-04
2025-03-02 14:33:19,544 - INFO - Step 1722 -- ðŸ”„ Training Metrics
2025-03-02 14:33:19,544 - INFO - â”œâ”€â”€ Loss: 7.2523
2025-03-02 14:33:19,544 - INFO - â”œâ”€â”€ Learning Rate: 2.58e-04
2025-03-02 14:33:19,544 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:33:20,221 - INFO - ðŸªœ Batch step - 1723 -- sub batch step 6892 -- lr 2.58e-04
2025-03-02 14:33:22,372 - INFO - ðŸªœ Batch step - 1723 -- sub batch step 6893 -- lr 2.58e-04
2025-03-02 14:33:24,525 - INFO - ðŸªœ Batch step - 1723 -- sub batch step 6894 -- lr 2.58e-04
2025-03-02 14:33:27,142 - INFO - ðŸªœ Batch step - 1723 -- sub batch step 6895 -- lr 2.58e-04
2025-03-02 14:33:28,950 - INFO - Step 1723 -- ðŸ”„ Training Metrics
2025-03-02 14:33:28,950 - INFO - â”œâ”€â”€ Loss: 7.2305
2025-03-02 14:33:28,950 - INFO - â”œâ”€â”€ Learning Rate: 2.58e-04
2025-03-02 14:33:28,950 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:33:29,624 - INFO - ðŸªœ Batch step - 1724 -- sub batch step 6896 -- lr 2.59e-04
2025-03-02 14:33:31,779 - INFO - ðŸªœ Batch step - 1724 -- sub batch step 6897 -- lr 2.59e-04
2025-03-02 14:33:33,925 - INFO - ðŸªœ Batch step - 1724 -- sub batch step 6898 -- lr 2.59e-04
2025-03-02 14:33:36,091 - INFO - ðŸªœ Batch step - 1724 -- sub batch step 6899 -- lr 2.59e-04
2025-03-02 14:33:37,649 - INFO - Step 1724 -- ðŸ”„ Training Metrics
2025-03-02 14:33:37,649 - INFO - â”œâ”€â”€ Loss: 7.2322
2025-03-02 14:33:37,649 - INFO - â”œâ”€â”€ Learning Rate: 2.59e-04
2025-03-02 14:33:37,649 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:33:38,326 - INFO - ðŸªœ Batch step - 1725 -- sub batch step 6900 -- lr 2.59e-04
2025-03-02 14:33:40,477 - INFO - ðŸªœ Batch step - 1725 -- sub batch step 6901 -- lr 2.59e-04
2025-03-02 14:33:42,633 - INFO - ðŸªœ Batch step - 1725 -- sub batch step 6902 -- lr 2.59e-04
2025-03-02 14:33:45,253 - INFO - ðŸªœ Batch step - 1725 -- sub batch step 6903 -- lr 2.59e-04
2025-03-02 14:33:46,869 - INFO - Step 1725 -- ðŸ”„ Training Metrics
2025-03-02 14:33:46,869 - INFO - â”œâ”€â”€ Loss: 7.2259
2025-03-02 14:33:46,869 - INFO - â”œâ”€â”€ Learning Rate: 2.59e-04
2025-03-02 14:33:46,870 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:33:47,549 - INFO - ðŸªœ Batch step - 1726 -- sub batch step 6904 -- lr 2.59e-04
2025-03-02 14:33:49,706 - INFO - ðŸªœ Batch step - 1726 -- sub batch step 6905 -- lr 2.59e-04
2025-03-02 14:33:51,857 - INFO - ðŸªœ Batch step - 1726 -- sub batch step 6906 -- lr 2.59e-04
2025-03-02 14:33:54,032 - INFO - ðŸªœ Batch step - 1726 -- sub batch step 6907 -- lr 2.59e-04
2025-03-02 14:33:55,575 - INFO - Step 1726 -- ðŸ”„ Training Metrics
2025-03-02 14:33:55,575 - INFO - â”œâ”€â”€ Loss: 7.2344
2025-03-02 14:33:55,575 - INFO - â”œâ”€â”€ Learning Rate: 2.59e-04
2025-03-02 14:33:55,575 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:33:56,249 - INFO - ðŸªœ Batch step - 1727 -- sub batch step 6908 -- lr 2.59e-04
2025-03-02 14:33:58,405 - INFO - ðŸªœ Batch step - 1727 -- sub batch step 6909 -- lr 2.59e-04
2025-03-02 14:34:00,562 - INFO - ðŸªœ Batch step - 1727 -- sub batch step 6910 -- lr 2.59e-04
2025-03-02 14:34:03,239 - INFO - ðŸªœ Batch step - 1727 -- sub batch step 6911 -- lr 2.59e-04
2025-03-02 14:34:04,983 - INFO - Step 1727 -- ðŸ”„ Training Metrics
2025-03-02 14:34:04,983 - INFO - â”œâ”€â”€ Loss: 7.2343
2025-03-02 14:34:04,983 - INFO - â”œâ”€â”€ Learning Rate: 2.59e-04
2025-03-02 14:34:04,983 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:34:05,660 - INFO - ðŸªœ Batch step - 1728 -- sub batch step 6912 -- lr 2.59e-04
2025-03-02 14:34:07,811 - INFO - ðŸªœ Batch step - 1728 -- sub batch step 6913 -- lr 2.59e-04
2025-03-02 14:34:09,964 - INFO - ðŸªœ Batch step - 1728 -- sub batch step 6914 -- lr 2.59e-04
2025-03-02 14:34:12,135 - INFO - ðŸªœ Batch step - 1728 -- sub batch step 6915 -- lr 2.59e-04
2025-03-02 14:34:13,675 - INFO - Step 1728 -- ðŸ”„ Training Metrics
2025-03-02 14:34:13,675 - INFO - â”œâ”€â”€ Loss: 7.2245
2025-03-02 14:34:13,675 - INFO - â”œâ”€â”€ Learning Rate: 2.59e-04
2025-03-02 14:34:13,675 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:34:14,349 - INFO - ðŸªœ Batch step - 1729 -- sub batch step 6916 -- lr 2.59e-04
2025-03-02 14:34:16,508 - INFO - ðŸªœ Batch step - 1729 -- sub batch step 6917 -- lr 2.59e-04
2025-03-02 14:34:18,659 - INFO - ðŸªœ Batch step - 1729 -- sub batch step 6918 -- lr 2.59e-04
2025-03-02 14:34:21,314 - INFO - ðŸªœ Batch step - 1729 -- sub batch step 6919 -- lr 2.59e-04
2025-03-02 14:34:23,209 - INFO - Step 1729 -- ðŸ”„ Training Metrics
2025-03-02 14:34:23,209 - INFO - â”œâ”€â”€ Loss: 7.2815
2025-03-02 14:34:23,209 - INFO - â”œâ”€â”€ Learning Rate: 2.59e-04
2025-03-02 14:34:23,209 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:34:23,887 - INFO - ðŸªœ Batch step - 1730 -- sub batch step 6920 -- lr 2.59e-04
2025-03-02 14:34:26,038 - INFO - ðŸªœ Batch step - 1730 -- sub batch step 6921 -- lr 2.59e-04
2025-03-02 14:34:28,190 - INFO - ðŸªœ Batch step - 1730 -- sub batch step 6922 -- lr 2.59e-04
2025-03-02 14:34:30,353 - INFO - ðŸªœ Batch step - 1730 -- sub batch step 6923 -- lr 2.59e-04
2025-03-02 14:34:31,894 - INFO - Step 1730 -- ðŸ”„ Training Metrics
2025-03-02 14:34:31,894 - INFO - â”œâ”€â”€ Loss: 7.2240
2025-03-02 14:34:31,894 - INFO - â”œâ”€â”€ Learning Rate: 2.59e-04
2025-03-02 14:34:31,895 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:34:32,571 - INFO - ðŸªœ Batch step - 1731 -- sub batch step 6924 -- lr 2.60e-04
2025-03-02 14:34:34,723 - INFO - ðŸªœ Batch step - 1731 -- sub batch step 6925 -- lr 2.60e-04
2025-03-02 14:34:37,451 - INFO - ðŸªœ Batch step - 1731 -- sub batch step 6926 -- lr 2.60e-04
2025-03-02 14:34:39,609 - INFO - ðŸªœ Batch step - 1731 -- sub batch step 6927 -- lr 2.60e-04
2025-03-02 14:34:41,099 - INFO - Step 1731 -- ðŸ”„ Training Metrics
2025-03-02 14:34:41,100 - INFO - â”œâ”€â”€ Loss: 7.2392
2025-03-02 14:34:41,100 - INFO - â”œâ”€â”€ Learning Rate: 2.60e-04
2025-03-02 14:34:41,100 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:34:41,769 - INFO - ðŸªœ Batch step - 1732 -- sub batch step 6928 -- lr 2.60e-04
2025-03-02 14:34:43,925 - INFO - ðŸªœ Batch step - 1732 -- sub batch step 6929 -- lr 2.60e-04
2025-03-02 14:34:46,092 - INFO - ðŸªœ Batch step - 1732 -- sub batch step 6930 -- lr 2.60e-04
2025-03-02 14:34:48,242 - INFO - ðŸªœ Batch step - 1732 -- sub batch step 6931 -- lr 2.60e-04
2025-03-02 14:34:49,795 - INFO - Step 1732 -- ðŸ”„ Training Metrics
2025-03-02 14:34:49,796 - INFO - â”œâ”€â”€ Loss: 7.2356
2025-03-02 14:34:49,796 - INFO - â”œâ”€â”€ Learning Rate: 2.60e-04
2025-03-02 14:34:49,796 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:34:50,467 - INFO - ðŸªœ Batch step - 1733 -- sub batch step 6932 -- lr 2.60e-04
2025-03-02 14:34:52,619 - INFO - ðŸªœ Batch step - 1733 -- sub batch step 6933 -- lr 2.60e-04
2025-03-02 14:34:55,251 - INFO - ðŸªœ Batch step - 1733 -- sub batch step 6934 -- lr 2.60e-04
2025-03-02 14:34:57,416 - INFO - ðŸªœ Batch step - 1733 -- sub batch step 6935 -- lr 2.60e-04
2025-03-02 14:34:59,193 - INFO - Step 1733 -- ðŸ”„ Training Metrics
2025-03-02 14:34:59,193 - INFO - â”œâ”€â”€ Loss: 7.2322
2025-03-02 14:34:59,193 - INFO - â”œâ”€â”€ Learning Rate: 2.60e-04
2025-03-02 14:34:59,193 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:34:59,866 - INFO - ðŸªœ Batch step - 1734 -- sub batch step 6936 -- lr 2.60e-04
2025-03-02 14:35:02,022 - INFO - ðŸªœ Batch step - 1734 -- sub batch step 6937 -- lr 2.60e-04
2025-03-02 14:35:04,187 - INFO - ðŸªœ Batch step - 1734 -- sub batch step 6938 -- lr 2.60e-04
2025-03-02 14:35:06,341 - INFO - ðŸªœ Batch step - 1734 -- sub batch step 6939 -- lr 2.60e-04
2025-03-02 14:35:07,888 - INFO - Step 1734 -- ðŸ”„ Training Metrics
2025-03-02 14:35:07,888 - INFO - â”œâ”€â”€ Loss: 7.2541
2025-03-02 14:35:07,888 - INFO - â”œâ”€â”€ Learning Rate: 2.60e-04
2025-03-02 14:35:07,888 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:35:08,567 - INFO - ðŸªœ Batch step - 1735 -- sub batch step 6940 -- lr 2.60e-04
2025-03-02 14:35:10,717 - INFO - ðŸªœ Batch step - 1735 -- sub batch step 6941 -- lr 2.60e-04
2025-03-02 14:35:13,509 - INFO - ðŸªœ Batch step - 1735 -- sub batch step 6942 -- lr 2.60e-04
2025-03-02 14:35:15,666 - INFO - ðŸªœ Batch step - 1735 -- sub batch step 6943 -- lr 2.60e-04
2025-03-02 14:35:17,156 - INFO - Step 1735 -- ðŸ”„ Training Metrics
2025-03-02 14:35:17,156 - INFO - â”œâ”€â”€ Loss: 7.2229
2025-03-02 14:35:17,157 - INFO - â”œâ”€â”€ Learning Rate: 2.60e-04
2025-03-02 14:35:17,157 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:35:17,831 - INFO - ðŸªœ Batch step - 1736 -- sub batch step 6944 -- lr 2.60e-04
2025-03-02 14:35:19,985 - INFO - ðŸªœ Batch step - 1736 -- sub batch step 6945 -- lr 2.60e-04
2025-03-02 14:35:22,147 - INFO - ðŸªœ Batch step - 1736 -- sub batch step 6946 -- lr 2.60e-04
2025-03-02 14:35:24,301 - INFO - ðŸªœ Batch step - 1736 -- sub batch step 6947 -- lr 2.60e-04
2025-03-02 14:35:25,855 - INFO - Step 1736 -- ðŸ”„ Training Metrics
2025-03-02 14:35:25,855 - INFO - â”œâ”€â”€ Loss: 7.2307
2025-03-02 14:35:25,855 - INFO - â”œâ”€â”€ Learning Rate: 2.60e-04
2025-03-02 14:35:25,856 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:35:26,526 - INFO - ðŸªœ Batch step - 1737 -- sub batch step 6948 -- lr 2.61e-04
2025-03-02 14:35:28,685 - INFO - ðŸªœ Batch step - 1737 -- sub batch step 6949 -- lr 2.61e-04
2025-03-02 14:35:31,080 - INFO - ðŸªœ Batch step - 1737 -- sub batch step 6950 -- lr 2.61e-04
2025-03-02 14:35:33,231 - INFO - ðŸªœ Batch step - 1737 -- sub batch step 6951 -- lr 2.61e-04
2025-03-02 14:35:35,089 - INFO - Step 1737 -- ðŸ”„ Training Metrics
2025-03-02 14:35:35,089 - INFO - â”œâ”€â”€ Loss: 7.2427
2025-03-02 14:35:35,089 - INFO - â”œâ”€â”€ Learning Rate: 2.61e-04
2025-03-02 14:35:35,089 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:35:35,768 - INFO - ðŸªœ Batch step - 1738 -- sub batch step 6952 -- lr 2.61e-04
2025-03-02 14:35:37,916 - INFO - ðŸªœ Batch step - 1738 -- sub batch step 6953 -- lr 2.61e-04
2025-03-02 14:35:40,087 - INFO - ðŸªœ Batch step - 1738 -- sub batch step 6954 -- lr 2.61e-04
2025-03-02 14:35:42,241 - INFO - ðŸªœ Batch step - 1738 -- sub batch step 6955 -- lr 2.61e-04
2025-03-02 14:35:43,778 - INFO - Step 1738 -- ðŸ”„ Training Metrics
2025-03-02 14:35:43,779 - INFO - â”œâ”€â”€ Loss: 7.2456
2025-03-02 14:35:43,779 - INFO - â”œâ”€â”€ Learning Rate: 2.61e-04
2025-03-02 14:35:43,779 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:35:44,449 - INFO - ðŸªœ Batch step - 1739 -- sub batch step 6956 -- lr 2.61e-04
2025-03-02 14:35:46,604 - INFO - ðŸªœ Batch step - 1739 -- sub batch step 6957 -- lr 2.61e-04
2025-03-02 14:35:48,876 - INFO - ðŸªœ Batch step - 1739 -- sub batch step 6958 -- lr 2.61e-04
2025-03-02 14:35:51,030 - INFO - ðŸªœ Batch step - 1739 -- sub batch step 6959 -- lr 2.61e-04
2025-03-02 14:35:52,713 - INFO - Step 1739 -- ðŸ”„ Training Metrics
2025-03-02 14:35:52,714 - INFO - â”œâ”€â”€ Loss: 7.2351
2025-03-02 14:35:52,714 - INFO - â”œâ”€â”€ Learning Rate: 2.61e-04
2025-03-02 14:35:52,714 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:35:54,171 - INFO - ðŸªœ Batch step - 1740 -- sub batch step 6960 -- lr 2.61e-04
2025-03-02 14:35:56,323 - INFO - ðŸªœ Batch step - 1740 -- sub batch step 6961 -- lr 2.61e-04
2025-03-02 14:35:58,483 - INFO - ðŸªœ Batch step - 1740 -- sub batch step 6962 -- lr 2.61e-04
2025-03-02 14:36:00,658 - INFO - ðŸªœ Batch step - 1740 -- sub batch step 6963 -- lr 2.61e-04
2025-03-02 14:36:02,161 - INFO - Step 1740 -- ðŸ”„ Training Metrics
2025-03-02 14:36:02,161 - INFO - â”œâ”€â”€ Loss: 7.2255
2025-03-02 14:36:02,161 - INFO - â”œâ”€â”€ Learning Rate: 2.61e-04
2025-03-02 14:36:02,161 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:36:02,837 - INFO - ðŸªœ Batch step - 1741 -- sub batch step 6964 -- lr 2.61e-04
2025-03-02 14:36:04,988 - INFO - ðŸªœ Batch step - 1741 -- sub batch step 6965 -- lr 2.61e-04
2025-03-02 14:36:07,133 - INFO - ðŸªœ Batch step - 1741 -- sub batch step 6966 -- lr 2.61e-04
2025-03-02 14:36:09,777 - INFO - ðŸªœ Batch step - 1741 -- sub batch step 6967 -- lr 2.61e-04
2025-03-02 14:36:11,267 - INFO - Step 1741 -- ðŸ”„ Training Metrics
2025-03-02 14:36:11,267 - INFO - â”œâ”€â”€ Loss: 7.2221
2025-03-02 14:36:11,267 - INFO - â”œâ”€â”€ Learning Rate: 2.61e-04
2025-03-02 14:36:11,267 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:36:11,934 - INFO - ðŸªœ Batch step - 1742 -- sub batch step 6968 -- lr 2.61e-04
2025-03-02 14:36:14,094 - INFO - ðŸªœ Batch step - 1742 -- sub batch step 6969 -- lr 2.61e-04
2025-03-02 14:36:16,249 - INFO - ðŸªœ Batch step - 1742 -- sub batch step 6970 -- lr 2.61e-04
2025-03-02 14:36:18,417 - INFO - ðŸªœ Batch step - 1742 -- sub batch step 6971 -- lr 2.61e-04
2025-03-02 14:36:19,956 - INFO - Step 1742 -- ðŸ”„ Training Metrics
2025-03-02 14:36:19,957 - INFO - â”œâ”€â”€ Loss: 7.2240
2025-03-02 14:36:19,974 - INFO - â”œâ”€â”€ Learning Rate: 2.61e-04
2025-03-02 14:36:19,974 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:36:20,650 - INFO - ðŸªœ Batch step - 1743 -- sub batch step 6972 -- lr 2.61e-04
2025-03-02 14:36:22,805 - INFO - ðŸªœ Batch step - 1743 -- sub batch step 6973 -- lr 2.61e-04
2025-03-02 14:36:24,961 - INFO - ðŸªœ Batch step - 1743 -- sub batch step 6974 -- lr 2.61e-04
2025-03-02 14:36:27,345 - INFO - ðŸªœ Batch step - 1743 -- sub batch step 6975 -- lr 2.61e-04
2025-03-02 14:36:29,158 - INFO - Step 1743 -- ðŸ”„ Training Metrics
2025-03-02 14:36:29,159 - INFO - â”œâ”€â”€ Loss: 7.2416
2025-03-02 14:36:29,159 - INFO - â”œâ”€â”€ Learning Rate: 2.61e-04
2025-03-02 14:36:29,159 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:36:29,828 - INFO - ðŸªœ Batch step - 1744 -- sub batch step 6976 -- lr 2.62e-04
2025-03-02 14:36:31,985 - INFO - ðŸªœ Batch step - 1744 -- sub batch step 6977 -- lr 2.62e-04
2025-03-02 14:36:34,131 - INFO - ðŸªœ Batch step - 1744 -- sub batch step 6978 -- lr 2.62e-04
2025-03-02 14:36:36,299 - INFO - ðŸªœ Batch step - 1744 -- sub batch step 6979 -- lr 2.62e-04
2025-03-02 14:36:37,850 - INFO - Step 1744 -- ðŸ”„ Training Metrics
2025-03-02 14:36:37,851 - INFO - â”œâ”€â”€ Loss: 7.2084
2025-03-02 14:36:37,851 - INFO - â”œâ”€â”€ Learning Rate: 2.62e-04
2025-03-02 14:36:37,851 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:36:38,524 - INFO - ðŸªœ Batch step - 1745 -- sub batch step 6980 -- lr 2.62e-04
2025-03-02 14:36:40,674 - INFO - ðŸªœ Batch step - 1745 -- sub batch step 6981 -- lr 2.62e-04
2025-03-02 14:36:42,830 - INFO - ðŸªœ Batch step - 1745 -- sub batch step 6982 -- lr 2.62e-04
2025-03-02 14:36:45,512 - INFO - ðŸªœ Batch step - 1745 -- sub batch step 6983 -- lr 2.62e-04
2025-03-02 14:36:47,091 - INFO - Step 1745 -- ðŸ”„ Training Metrics
2025-03-02 14:36:47,091 - INFO - â”œâ”€â”€ Loss: 7.2321
2025-03-02 14:36:47,091 - INFO - â”œâ”€â”€ Learning Rate: 2.62e-04
2025-03-02 14:36:47,091 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:36:47,770 - INFO - ðŸªœ Batch step - 1746 -- sub batch step 6984 -- lr 2.62e-04
2025-03-02 14:36:49,925 - INFO - ðŸªœ Batch step - 1746 -- sub batch step 6985 -- lr 2.62e-04
2025-03-02 14:36:52,075 - INFO - ðŸªœ Batch step - 1746 -- sub batch step 6986 -- lr 2.62e-04
2025-03-02 14:36:54,244 - INFO - ðŸªœ Batch step - 1746 -- sub batch step 6987 -- lr 2.62e-04
2025-03-02 14:36:55,785 - INFO - Step 1746 -- ðŸ”„ Training Metrics
2025-03-02 14:36:55,785 - INFO - â”œâ”€â”€ Loss: 7.2268
2025-03-02 14:36:55,786 - INFO - â”œâ”€â”€ Learning Rate: 2.62e-04
2025-03-02 14:36:55,786 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:36:56,454 - INFO - ðŸªœ Batch step - 1747 -- sub batch step 6988 -- lr 2.62e-04
2025-03-02 14:36:58,612 - INFO - ðŸªœ Batch step - 1747 -- sub batch step 6989 -- lr 2.62e-04
2025-03-02 14:37:00,767 - INFO - ðŸªœ Batch step - 1747 -- sub batch step 6990 -- lr 2.62e-04
2025-03-02 14:37:03,190 - INFO - ðŸªœ Batch step - 1747 -- sub batch step 6991 -- lr 2.62e-04
2025-03-02 14:37:05,119 - INFO - Step 1747 -- ðŸ”„ Training Metrics
2025-03-02 14:37:05,119 - INFO - â”œâ”€â”€ Loss: 7.2204
2025-03-02 14:37:05,120 - INFO - â”œâ”€â”€ Learning Rate: 2.62e-04
2025-03-02 14:37:05,120 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:37:05,797 - INFO - ðŸªœ Batch step - 1748 -- sub batch step 6992 -- lr 2.62e-04
2025-03-02 14:37:07,949 - INFO - ðŸªœ Batch step - 1748 -- sub batch step 6993 -- lr 2.62e-04
2025-03-02 14:37:10,103 - INFO - ðŸªœ Batch step - 1748 -- sub batch step 6994 -- lr 2.62e-04
2025-03-02 14:37:12,271 - INFO - ðŸªœ Batch step - 1748 -- sub batch step 6995 -- lr 2.62e-04
2025-03-02 14:37:13,813 - INFO - Step 1748 -- ðŸ”„ Training Metrics
2025-03-02 14:37:13,813 - INFO - â”œâ”€â”€ Loss: 7.2539
2025-03-02 14:37:13,813 - INFO - â”œâ”€â”€ Learning Rate: 2.62e-04
2025-03-02 14:37:13,814 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:37:14,483 - INFO - ðŸªœ Batch step - 1749 -- sub batch step 6996 -- lr 2.62e-04
2025-03-02 14:37:16,640 - INFO - ðŸªœ Batch step - 1749 -- sub batch step 6997 -- lr 2.62e-04
2025-03-02 14:37:18,784 - INFO - ðŸªœ Batch step - 1749 -- sub batch step 6998 -- lr 2.62e-04
2025-03-02 14:37:21,157 - INFO - ðŸªœ Batch step - 1749 -- sub batch step 6999 -- lr 2.62e-04
2025-03-02 14:37:22,959 - INFO - Step 1749 -- ðŸ”„ Training Metrics
2025-03-02 14:37:22,960 - INFO - â”œâ”€â”€ Loss: 7.2030
2025-03-02 14:37:22,960 - INFO - â”œâ”€â”€ Learning Rate: 2.62e-04
2025-03-02 14:37:22,960 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:37:23,633 - INFO - ðŸªœ Batch step - 1750 -- sub batch step 7000 -- lr 2.62e-04
2025-03-02 14:37:25,784 - INFO - ðŸªœ Batch step - 1750 -- sub batch step 7001 -- lr 2.62e-04
2025-03-02 14:37:27,936 - INFO - ðŸªœ Batch step - 1750 -- sub batch step 7002 -- lr 2.62e-04
2025-03-02 14:37:30,097 - INFO - ðŸªœ Batch step - 1750 -- sub batch step 7003 -- lr 2.62e-04
2025-03-02 14:37:31,644 - INFO - Step 1750 -- ðŸ”„ Training Metrics
2025-03-02 14:37:31,645 - INFO - â”œâ”€â”€ Loss: 7.2267
2025-03-02 14:37:31,645 - INFO - â”œâ”€â”€ Learning Rate: 2.62e-04
2025-03-02 14:37:31,645 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:37:32,318 - INFO - ðŸªœ Batch step - 1751 -- sub batch step 7004 -- lr 2.63e-04
2025-03-02 14:37:34,470 - INFO - ðŸªœ Batch step - 1751 -- sub batch step 7005 -- lr 2.63e-04
2025-03-02 14:37:37,083 - INFO - ðŸªœ Batch step - 1751 -- sub batch step 7006 -- lr 2.63e-04
2025-03-02 14:37:39,243 - INFO - ðŸªœ Batch step - 1751 -- sub batch step 7007 -- lr 2.63e-04
2025-03-02 14:37:40,964 - INFO - Step 1751 -- ðŸ”„ Training Metrics
2025-03-02 14:37:40,964 - INFO - â”œâ”€â”€ Loss: 7.2287
2025-03-02 14:37:40,964 - INFO - â”œâ”€â”€ Learning Rate: 2.63e-04
2025-03-02 14:37:40,964 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:37:41,631 - INFO - ðŸªœ Batch step - 1752 -- sub batch step 7008 -- lr 2.63e-04
2025-03-02 14:37:43,790 - INFO - ðŸªœ Batch step - 1752 -- sub batch step 7009 -- lr 2.63e-04
2025-03-02 14:37:45,959 - INFO - ðŸªœ Batch step - 1752 -- sub batch step 7010 -- lr 2.63e-04
2025-03-02 14:37:48,108 - INFO - ðŸªœ Batch step - 1752 -- sub batch step 7011 -- lr 2.63e-04
2025-03-02 14:37:49,644 - INFO - Step 1752 -- ðŸ”„ Training Metrics
2025-03-02 14:37:49,644 - INFO - â”œâ”€â”€ Loss: 7.2164
2025-03-02 14:37:49,645 - INFO - â”œâ”€â”€ Learning Rate: 2.63e-04
2025-03-02 14:37:49,645 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:37:50,321 - INFO - ðŸªœ Batch step - 1753 -- sub batch step 7012 -- lr 2.63e-04
2025-03-02 14:37:52,473 - INFO - ðŸªœ Batch step - 1753 -- sub batch step 7013 -- lr 2.63e-04
2025-03-02 14:37:54,849 - INFO - ðŸªœ Batch step - 1753 -- sub batch step 7014 -- lr 2.63e-04
2025-03-02 14:37:57,008 - INFO - ðŸªœ Batch step - 1753 -- sub batch step 7015 -- lr 2.63e-04
2025-03-02 14:37:58,917 - INFO - Step 1753 -- ðŸ”„ Training Metrics
2025-03-02 14:37:58,917 - INFO - â”œâ”€â”€ Loss: 7.2182
2025-03-02 14:37:58,917 - INFO - â”œâ”€â”€ Learning Rate: 2.63e-04
2025-03-02 14:37:58,917 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:37:59,590 - INFO - ðŸªœ Batch step - 1754 -- sub batch step 7016 -- lr 2.63e-04
2025-03-02 14:38:01,743 - INFO - ðŸªœ Batch step - 1754 -- sub batch step 7017 -- lr 2.63e-04
2025-03-02 14:38:03,903 - INFO - ðŸªœ Batch step - 1754 -- sub batch step 7018 -- lr 2.63e-04
2025-03-02 14:38:06,053 - INFO - ðŸªœ Batch step - 1754 -- sub batch step 7019 -- lr 2.63e-04
2025-03-02 14:38:07,602 - INFO - Step 1754 -- ðŸ”„ Training Metrics
2025-03-02 14:38:07,602 - INFO - â”œâ”€â”€ Loss: 7.2257
2025-03-02 14:38:07,602 - INFO - â”œâ”€â”€ Learning Rate: 2.63e-04
2025-03-02 14:38:07,603 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:38:08,278 - INFO - ðŸªœ Batch step - 1755 -- sub batch step 7020 -- lr 2.63e-04
2025-03-02 14:38:10,430 - INFO - ðŸªœ Batch step - 1755 -- sub batch step 7021 -- lr 2.63e-04
2025-03-02 14:38:12,793 - INFO - ðŸªœ Batch step - 1755 -- sub batch step 7022 -- lr 2.63e-04
2025-03-02 14:38:14,945 - INFO - ðŸªœ Batch step - 1755 -- sub batch step 7023 -- lr 2.63e-04
2025-03-02 14:38:16,816 - INFO - Step 1755 -- ðŸ”„ Training Metrics
2025-03-02 14:38:16,816 - INFO - â”œâ”€â”€ Loss: 7.2141
2025-03-02 14:38:16,816 - INFO - â”œâ”€â”€ Learning Rate: 2.63e-04
2025-03-02 14:38:16,816 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:38:17,494 - INFO - ðŸªœ Batch step - 1756 -- sub batch step 7024 -- lr 2.63e-04
2025-03-02 14:38:19,646 - INFO - ðŸªœ Batch step - 1756 -- sub batch step 7025 -- lr 2.63e-04
2025-03-02 14:38:21,810 - INFO - ðŸªœ Batch step - 1756 -- sub batch step 7026 -- lr 2.63e-04
2025-03-02 14:38:23,965 - INFO - ðŸªœ Batch step - 1756 -- sub batch step 7027 -- lr 2.63e-04
2025-03-02 14:38:25,507 - INFO - Step 1756 -- ðŸ”„ Training Metrics
2025-03-02 14:38:25,507 - INFO - â”œâ”€â”€ Loss: 7.2124
2025-03-02 14:38:25,508 - INFO - â”œâ”€â”€ Learning Rate: 2.63e-04
2025-03-02 14:38:25,508 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:38:26,176 - INFO - ðŸªœ Batch step - 1757 -- sub batch step 7028 -- lr 2.64e-04
2025-03-02 14:38:28,334 - INFO - ðŸªœ Batch step - 1757 -- sub batch step 7029 -- lr 2.64e-04
2025-03-02 14:38:31,021 - INFO - ðŸªœ Batch step - 1757 -- sub batch step 7030 -- lr 2.64e-04
2025-03-02 14:38:33,173 - INFO - ðŸªœ Batch step - 1757 -- sub batch step 7031 -- lr 2.64e-04
2025-03-02 14:38:34,821 - INFO - Step 1757 -- ðŸ”„ Training Metrics
2025-03-02 14:38:34,821 - INFO - â”œâ”€â”€ Loss: 7.1844
2025-03-02 14:38:34,822 - INFO - â”œâ”€â”€ Learning Rate: 2.64e-04
2025-03-02 14:38:34,822 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:38:35,499 - INFO - ðŸªœ Batch step - 1758 -- sub batch step 7032 -- lr 2.64e-04
2025-03-02 14:38:37,647 - INFO - ðŸªœ Batch step - 1758 -- sub batch step 7033 -- lr 2.64e-04
2025-03-02 14:38:39,817 - INFO - ðŸªœ Batch step - 1758 -- sub batch step 7034 -- lr 2.64e-04
2025-03-02 14:38:41,969 - INFO - ðŸªœ Batch step - 1758 -- sub batch step 7035 -- lr 2.64e-04
2025-03-02 14:38:43,547 - INFO - Step 1758 -- ðŸ”„ Training Metrics
2025-03-02 14:38:43,547 - INFO - â”œâ”€â”€ Loss: 7.2202
2025-03-02 14:38:43,547 - INFO - â”œâ”€â”€ Learning Rate: 2.64e-04
2025-03-02 14:38:43,547 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:38:44,214 - INFO - ðŸªœ Batch step - 1759 -- sub batch step 7036 -- lr 2.64e-04
2025-03-02 14:38:46,371 - INFO - ðŸªœ Batch step - 1759 -- sub batch step 7037 -- lr 2.64e-04
2025-03-02 14:38:48,651 - INFO - ðŸªœ Batch step - 1759 -- sub batch step 7038 -- lr 2.64e-04
2025-03-02 14:38:50,807 - INFO - ðŸªœ Batch step - 1759 -- sub batch step 7039 -- lr 2.64e-04
2025-03-02 14:38:52,446 - INFO - Step 1759 -- ðŸ”„ Training Metrics
2025-03-02 14:38:52,447 - INFO - â”œâ”€â”€ Loss: 7.2024
2025-03-02 14:38:52,447 - INFO - â”œâ”€â”€ Learning Rate: 2.64e-04
2025-03-02 14:38:52,447 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:38:54,221 - INFO - ðŸªœ Batch step - 1760 -- sub batch step 7040 -- lr 2.64e-04
2025-03-02 14:38:56,379 - INFO - ðŸªœ Batch step - 1760 -- sub batch step 7041 -- lr 2.64e-04
2025-03-02 14:38:58,539 - INFO - ðŸªœ Batch step - 1760 -- sub batch step 7042 -- lr 2.64e-04
2025-03-02 14:39:00,713 - INFO - ðŸªœ Batch step - 1760 -- sub batch step 7043 -- lr 2.64e-04
2025-03-02 14:39:02,204 - INFO - Step 1760 -- ðŸ”„ Training Metrics
2025-03-02 14:39:02,204 - INFO - â”œâ”€â”€ Loss: 7.2157
2025-03-02 14:39:02,204 - INFO - â”œâ”€â”€ Learning Rate: 2.64e-04
2025-03-02 14:39:02,204 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:39:02,885 - INFO - ðŸªœ Batch step - 1761 -- sub batch step 7044 -- lr 2.64e-04
2025-03-02 14:39:05,040 - INFO - ðŸªœ Batch step - 1761 -- sub batch step 7045 -- lr 2.64e-04
2025-03-02 14:39:07,189 - INFO - ðŸªœ Batch step - 1761 -- sub batch step 7046 -- lr 2.64e-04
2025-03-02 14:39:09,824 - INFO - ðŸªœ Batch step - 1761 -- sub batch step 7047 -- lr 2.64e-04
2025-03-02 14:39:11,494 - INFO - Step 1761 -- ðŸ”„ Training Metrics
2025-03-02 14:39:11,494 - INFO - â”œâ”€â”€ Loss: 7.2005
2025-03-02 14:39:11,494 - INFO - â”œâ”€â”€ Learning Rate: 2.64e-04
2025-03-02 14:39:11,495 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:39:12,164 - INFO - ðŸªœ Batch step - 1762 -- sub batch step 7048 -- lr 2.64e-04
2025-03-02 14:39:14,323 - INFO - ðŸªœ Batch step - 1762 -- sub batch step 7049 -- lr 2.64e-04
2025-03-02 14:39:16,479 - INFO - ðŸªœ Batch step - 1762 -- sub batch step 7050 -- lr 2.64e-04
2025-03-02 14:39:18,650 - INFO - ðŸªœ Batch step - 1762 -- sub batch step 7051 -- lr 2.64e-04
2025-03-02 14:39:20,192 - INFO - Step 1762 -- ðŸ”„ Training Metrics
2025-03-02 14:39:20,192 - INFO - â”œâ”€â”€ Loss: 7.2037
2025-03-02 14:39:20,192 - INFO - â”œâ”€â”€ Learning Rate: 2.64e-04
2025-03-02 14:39:20,192 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:39:20,871 - INFO - ðŸªœ Batch step - 1763 -- sub batch step 7052 -- lr 2.64e-04
2025-03-02 14:39:23,022 - INFO - ðŸªœ Batch step - 1763 -- sub batch step 7053 -- lr 2.64e-04
2025-03-02 14:39:25,177 - INFO - ðŸªœ Batch step - 1763 -- sub batch step 7054 -- lr 2.64e-04
2025-03-02 14:39:27,536 - INFO - ðŸªœ Batch step - 1763 -- sub batch step 7055 -- lr 2.64e-04
2025-03-02 14:39:29,377 - INFO - Step 1763 -- ðŸ”„ Training Metrics
2025-03-02 14:39:29,378 - INFO - â”œâ”€â”€ Loss: 7.2398
2025-03-02 14:39:29,378 - INFO - â”œâ”€â”€ Learning Rate: 2.64e-04
2025-03-02 14:39:29,378 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:39:30,048 - INFO - ðŸªœ Batch step - 1764 -- sub batch step 7056 -- lr 2.65e-04
2025-03-02 14:39:32,208 - INFO - ðŸªœ Batch step - 1764 -- sub batch step 7057 -- lr 2.65e-04
2025-03-02 14:39:34,357 - INFO - ðŸªœ Batch step - 1764 -- sub batch step 7058 -- lr 2.65e-04
2025-03-02 14:39:36,526 - INFO - ðŸªœ Batch step - 1764 -- sub batch step 7059 -- lr 2.65e-04
2025-03-02 14:39:38,072 - INFO - Step 1764 -- ðŸ”„ Training Metrics
2025-03-02 14:39:38,072 - INFO - â”œâ”€â”€ Loss: 7.2007
2025-03-02 14:39:38,072 - INFO - â”œâ”€â”€ Learning Rate: 2.65e-04
2025-03-02 14:39:38,072 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:39:38,749 - INFO - ðŸªœ Batch step - 1765 -- sub batch step 7060 -- lr 2.65e-04
2025-03-02 14:39:40,903 - INFO - ðŸªœ Batch step - 1765 -- sub batch step 7061 -- lr 2.65e-04
2025-03-02 14:39:43,059 - INFO - ðŸªœ Batch step - 1765 -- sub batch step 7062 -- lr 2.65e-04
2025-03-02 14:39:45,661 - INFO - ðŸªœ Batch step - 1765 -- sub batch step 7063 -- lr 2.65e-04
2025-03-02 14:39:47,368 - INFO - Step 1765 -- ðŸ”„ Training Metrics
2025-03-02 14:39:47,369 - INFO - â”œâ”€â”€ Loss: 7.2045
2025-03-02 14:39:47,369 - INFO - â”œâ”€â”€ Learning Rate: 2.65e-04
2025-03-02 14:39:47,369 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:39:48,046 - INFO - ðŸªœ Batch step - 1766 -- sub batch step 7064 -- lr 2.65e-04
2025-03-02 14:39:50,203 - INFO - ðŸªœ Batch step - 1766 -- sub batch step 7065 -- lr 2.65e-04
2025-03-02 14:39:52,350 - INFO - ðŸªœ Batch step - 1766 -- sub batch step 7066 -- lr 2.65e-04
2025-03-02 14:39:54,525 - INFO - ðŸªœ Batch step - 1766 -- sub batch step 7067 -- lr 2.65e-04
2025-03-02 14:39:56,062 - INFO - Step 1766 -- ðŸ”„ Training Metrics
2025-03-02 14:39:56,062 - INFO - â”œâ”€â”€ Loss: 7.2163
2025-03-02 14:39:56,062 - INFO - â”œâ”€â”€ Learning Rate: 2.65e-04
2025-03-02 14:39:56,062 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:39:56,727 - INFO - ðŸªœ Batch step - 1767 -- sub batch step 7068 -- lr 2.65e-04
2025-03-02 14:39:58,881 - INFO - ðŸªœ Batch step - 1767 -- sub batch step 7069 -- lr 2.65e-04
2025-03-02 14:40:01,039 - INFO - ðŸªœ Batch step - 1767 -- sub batch step 7070 -- lr 2.65e-04
2025-03-02 14:40:03,632 - INFO - ðŸªœ Batch step - 1767 -- sub batch step 7071 -- lr 2.65e-04
2025-03-02 14:40:05,233 - INFO - Step 1767 -- ðŸ”„ Training Metrics
2025-03-02 14:40:05,233 - INFO - â”œâ”€â”€ Loss: 7.2249
2025-03-02 14:40:05,233 - INFO - â”œâ”€â”€ Learning Rate: 2.65e-04
2025-03-02 14:40:05,233 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:40:05,912 - INFO - ðŸªœ Batch step - 1768 -- sub batch step 7072 -- lr 2.65e-04
2025-03-02 14:40:08,067 - INFO - ðŸªœ Batch step - 1768 -- sub batch step 7073 -- lr 2.65e-04
2025-03-02 14:40:10,222 - INFO - ðŸªœ Batch step - 1768 -- sub batch step 7074 -- lr 2.65e-04
2025-03-02 14:40:12,391 - INFO - ðŸªœ Batch step - 1768 -- sub batch step 7075 -- lr 2.65e-04
2025-03-02 14:40:13,928 - INFO - Step 1768 -- ðŸ”„ Training Metrics
2025-03-02 14:40:13,928 - INFO - â”œâ”€â”€ Loss: 7.2177
2025-03-02 14:40:13,928 - INFO - â”œâ”€â”€ Learning Rate: 2.65e-04
2025-03-02 14:40:13,928 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:40:14,599 - INFO - ðŸªœ Batch step - 1769 -- sub batch step 7076 -- lr 2.65e-04
2025-03-02 14:40:16,756 - INFO - ðŸªœ Batch step - 1769 -- sub batch step 7077 -- lr 2.65e-04
2025-03-02 14:40:18,906 - INFO - ðŸªœ Batch step - 1769 -- sub batch step 7078 -- lr 2.65e-04
2025-03-02 14:40:21,315 - INFO - ðŸªœ Batch step - 1769 -- sub batch step 7079 -- lr 2.65e-04
2025-03-02 14:40:23,209 - INFO - Step 1769 -- ðŸ”„ Training Metrics
2025-03-02 14:40:23,210 - INFO - â”œâ”€â”€ Loss: 7.2339
2025-03-02 14:40:23,210 - INFO - â”œâ”€â”€ Learning Rate: 2.65e-04
2025-03-02 14:40:23,210 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:40:23,885 - INFO - ðŸªœ Batch step - 1770 -- sub batch step 7080 -- lr 2.66e-04
2025-03-02 14:40:26,040 - INFO - ðŸªœ Batch step - 1770 -- sub batch step 7081 -- lr 2.66e-04
2025-03-02 14:40:28,195 - INFO - ðŸªœ Batch step - 1770 -- sub batch step 7082 -- lr 2.66e-04
2025-03-02 14:40:30,357 - INFO - ðŸªœ Batch step - 1770 -- sub batch step 7083 -- lr 2.66e-04
2025-03-02 14:40:31,898 - INFO - Step 1770 -- ðŸ”„ Training Metrics
2025-03-02 14:40:31,898 - INFO - â”œâ”€â”€ Loss: 7.2201
2025-03-02 14:40:31,898 - INFO - â”œâ”€â”€ Learning Rate: 2.66e-04
2025-03-02 14:40:31,898 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:40:32,575 - INFO - ðŸªœ Batch step - 1771 -- sub batch step 7084 -- lr 2.66e-04
2025-03-02 14:40:34,728 - INFO - ðŸªœ Batch step - 1771 -- sub batch step 7085 -- lr 2.66e-04
2025-03-02 14:40:37,122 - INFO - ðŸªœ Batch step - 1771 -- sub batch step 7086 -- lr 2.66e-04
2025-03-02 14:40:39,280 - INFO - ðŸªœ Batch step - 1771 -- sub batch step 7087 -- lr 2.66e-04
2025-03-02 14:40:41,086 - INFO - Step 1771 -- ðŸ”„ Training Metrics
2025-03-02 14:40:41,086 - INFO - â”œâ”€â”€ Loss: 7.2014
2025-03-02 14:40:41,086 - INFO - â”œâ”€â”€ Learning Rate: 2.66e-04
2025-03-02 14:40:41,087 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:40:41,753 - INFO - ðŸªœ Batch step - 1772 -- sub batch step 7088 -- lr 2.66e-04
2025-03-02 14:40:43,911 - INFO - ðŸªœ Batch step - 1772 -- sub batch step 7089 -- lr 2.66e-04
2025-03-02 14:40:46,079 - INFO - ðŸªœ Batch step - 1772 -- sub batch step 7090 -- lr 2.66e-04
2025-03-02 14:40:48,227 - INFO - ðŸªœ Batch step - 1772 -- sub batch step 7091 -- lr 2.66e-04
2025-03-02 14:40:49,781 - INFO - Step 1772 -- ðŸ”„ Training Metrics
2025-03-02 14:40:49,781 - INFO - â”œâ”€â”€ Loss: 7.2097
2025-03-02 14:40:49,781 - INFO - â”œâ”€â”€ Learning Rate: 2.66e-04
2025-03-02 14:40:49,782 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:40:50,453 - INFO - ðŸªœ Batch step - 1773 -- sub batch step 7092 -- lr 2.66e-04
2025-03-02 14:40:52,610 - INFO - ðŸªœ Batch step - 1773 -- sub batch step 7093 -- lr 2.66e-04
2025-03-02 14:40:55,062 - INFO - ðŸªœ Batch step - 1773 -- sub batch step 7094 -- lr 2.66e-04
2025-03-02 14:40:57,219 - INFO - ðŸªœ Batch step - 1773 -- sub batch step 7095 -- lr 2.66e-04
2025-03-02 14:40:58,961 - INFO - Step 1773 -- ðŸ”„ Training Metrics
2025-03-02 14:40:58,961 - INFO - â”œâ”€â”€ Loss: 7.1941
2025-03-02 14:40:58,961 - INFO - â”œâ”€â”€ Learning Rate: 2.66e-04
2025-03-02 14:40:58,962 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:40:59,634 - INFO - ðŸªœ Batch step - 1774 -- sub batch step 7096 -- lr 2.66e-04
2025-03-02 14:41:01,792 - INFO - ðŸªœ Batch step - 1774 -- sub batch step 7097 -- lr 2.66e-04
2025-03-02 14:41:03,953 - INFO - ðŸªœ Batch step - 1774 -- sub batch step 7098 -- lr 2.66e-04
2025-03-02 14:41:06,107 - INFO - ðŸªœ Batch step - 1774 -- sub batch step 7099 -- lr 2.66e-04
2025-03-02 14:41:07,645 - INFO - Step 1774 -- ðŸ”„ Training Metrics
2025-03-02 14:41:07,646 - INFO - â”œâ”€â”€ Loss: 7.1741
2025-03-02 14:41:07,646 - INFO - â”œâ”€â”€ Learning Rate: 2.66e-04
2025-03-02 14:41:07,646 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:41:08,324 - INFO - ðŸªœ Batch step - 1775 -- sub batch step 7100 -- lr 2.66e-04
2025-03-02 14:41:10,475 - INFO - ðŸªœ Batch step - 1775 -- sub batch step 7101 -- lr 2.66e-04
2025-03-02 14:41:12,841 - INFO - ðŸªœ Batch step - 1775 -- sub batch step 7102 -- lr 2.66e-04
2025-03-02 14:41:14,997 - INFO - ðŸªœ Batch step - 1775 -- sub batch step 7103 -- lr 2.66e-04
2025-03-02 14:41:16,951 - INFO - Step 1775 -- ðŸ”„ Training Metrics
2025-03-02 14:41:16,951 - INFO - â”œâ”€â”€ Loss: 7.2383
2025-03-02 14:41:16,951 - INFO - â”œâ”€â”€ Learning Rate: 2.66e-04
2025-03-02 14:41:16,951 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:41:17,629 - INFO - ðŸªœ Batch step - 1776 -- sub batch step 7104 -- lr 2.66e-04
2025-03-02 14:41:19,788 - INFO - ðŸªœ Batch step - 1776 -- sub batch step 7105 -- lr 2.66e-04
2025-03-02 14:41:21,952 - INFO - ðŸªœ Batch step - 1776 -- sub batch step 7106 -- lr 2.66e-04
2025-03-02 14:41:24,109 - INFO - ðŸªœ Batch step - 1776 -- sub batch step 7107 -- lr 2.66e-04
2025-03-02 14:41:25,640 - INFO - Step 1776 -- ðŸ”„ Training Metrics
2025-03-02 14:41:25,640 - INFO - â”œâ”€â”€ Loss: 7.2096
2025-03-02 14:41:25,641 - INFO - â”œâ”€â”€ Learning Rate: 2.66e-04
2025-03-02 14:41:25,641 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:41:26,308 - INFO - ðŸªœ Batch step - 1777 -- sub batch step 7108 -- lr 2.67e-04
2025-03-02 14:41:28,467 - INFO - ðŸªœ Batch step - 1777 -- sub batch step 7109 -- lr 2.67e-04
2025-03-02 14:41:31,276 - INFO - ðŸªœ Batch step - 1777 -- sub batch step 7110 -- lr 2.67e-04
2025-03-02 14:41:33,430 - INFO - ðŸªœ Batch step - 1777 -- sub batch step 7111 -- lr 2.67e-04
2025-03-02 14:41:34,950 - INFO - Step 1777 -- ðŸ”„ Training Metrics
2025-03-02 14:41:34,950 - INFO - â”œâ”€â”€ Loss: 7.2211
2025-03-02 14:41:34,950 - INFO - â”œâ”€â”€ Learning Rate: 2.67e-04
2025-03-02 14:41:34,951 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:41:35,622 - INFO - ðŸªœ Batch step - 1778 -- sub batch step 7112 -- lr 2.67e-04
2025-03-02 14:41:37,772 - INFO - ðŸªœ Batch step - 1778 -- sub batch step 7113 -- lr 2.67e-04
2025-03-02 14:41:39,944 - INFO - ðŸªœ Batch step - 1778 -- sub batch step 7114 -- lr 2.67e-04
2025-03-02 14:41:42,097 - INFO - ðŸªœ Batch step - 1778 -- sub batch step 7115 -- lr 2.67e-04
2025-03-02 14:41:43,648 - INFO - Step 1778 -- ðŸ”„ Training Metrics
2025-03-02 14:41:43,649 - INFO - â”œâ”€â”€ Loss: 7.2065
2025-03-02 14:41:43,649 - INFO - â”œâ”€â”€ Learning Rate: 2.67e-04
2025-03-02 14:41:43,649 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:41:44,315 - INFO - ðŸªœ Batch step - 1779 -- sub batch step 7116 -- lr 2.67e-04
2025-03-02 14:41:46,474 - INFO - ðŸªœ Batch step - 1779 -- sub batch step 7117 -- lr 2.67e-04
2025-03-02 14:41:48,745 - INFO - ðŸªœ Batch step - 1779 -- sub batch step 7118 -- lr 2.67e-04
2025-03-02 14:41:50,904 - INFO - ðŸªœ Batch step - 1779 -- sub batch step 7119 -- lr 2.67e-04
2025-03-02 14:41:52,569 - INFO - Step 1779 -- ðŸ”„ Training Metrics
2025-03-02 14:41:52,570 - INFO - â”œâ”€â”€ Loss: 7.2161
2025-03-02 14:41:52,570 - INFO - â”œâ”€â”€ Learning Rate: 2.67e-04
2025-03-02 14:41:52,570 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:41:53,847 - INFO - ðŸªœ Batch step - 1780 -- sub batch step 7120 -- lr 2.67e-04
2025-03-02 14:41:55,998 - INFO - ðŸªœ Batch step - 1780 -- sub batch step 7121 -- lr 2.67e-04
2025-03-02 14:41:58,159 - INFO - ðŸªœ Batch step - 1780 -- sub batch step 7122 -- lr 2.67e-04
2025-03-02 14:42:00,324 - INFO - ðŸªœ Batch step - 1780 -- sub batch step 7123 -- lr 2.67e-04
2025-03-02 14:42:01,908 - INFO - Step 1780 -- ðŸ”„ Training Metrics
2025-03-02 14:42:01,909 - INFO - â”œâ”€â”€ Loss: 7.2043
2025-03-02 14:42:01,909 - INFO - â”œâ”€â”€ Learning Rate: 2.67e-04
2025-03-02 14:42:01,909 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:42:02,593 - INFO - ðŸªœ Batch step - 1781 -- sub batch step 7124 -- lr 2.67e-04
2025-03-02 14:42:04,751 - INFO - ðŸªœ Batch step - 1781 -- sub batch step 7125 -- lr 2.67e-04
2025-03-02 14:42:06,901 - INFO - ðŸªœ Batch step - 1781 -- sub batch step 7126 -- lr 2.67e-04
2025-03-02 14:42:09,313 - INFO - ðŸªœ Batch step - 1781 -- sub batch step 7127 -- lr 2.67e-04
2025-03-02 14:42:11,150 - INFO - Step 1781 -- ðŸ”„ Training Metrics
2025-03-02 14:42:11,150 - INFO - â”œâ”€â”€ Loss: 7.2186
2025-03-02 14:42:11,150 - INFO - â”œâ”€â”€ Learning Rate: 2.67e-04
2025-03-02 14:42:11,151 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:42:11,818 - INFO - ðŸªœ Batch step - 1782 -- sub batch step 7128 -- lr 2.67e-04
2025-03-02 14:42:13,978 - INFO - ðŸªœ Batch step - 1782 -- sub batch step 7129 -- lr 2.67e-04
2025-03-02 14:42:16,136 - INFO - ðŸªœ Batch step - 1782 -- sub batch step 7130 -- lr 2.67e-04
2025-03-02 14:42:18,299 - INFO - ðŸªœ Batch step - 1782 -- sub batch step 7131 -- lr 2.67e-04
2025-03-02 14:42:19,848 - INFO - Step 1782 -- ðŸ”„ Training Metrics
2025-03-02 14:42:19,848 - INFO - â”œâ”€â”€ Loss: 7.1987
2025-03-02 14:42:19,849 - INFO - â”œâ”€â”€ Learning Rate: 2.67e-04
2025-03-02 14:42:19,849 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:42:20,521 - INFO - ðŸªœ Batch step - 1783 -- sub batch step 7132 -- lr 2.67e-04
2025-03-02 14:42:22,676 - INFO - ðŸªœ Batch step - 1783 -- sub batch step 7133 -- lr 2.67e-04
2025-03-02 14:42:24,834 - INFO - ðŸªœ Batch step - 1783 -- sub batch step 7134 -- lr 2.67e-04
2025-03-02 14:42:27,212 - INFO - ðŸªœ Batch step - 1783 -- sub batch step 7135 -- lr 2.67e-04
2025-03-02 14:42:29,165 - INFO - Step 1783 -- ðŸ”„ Training Metrics
2025-03-02 14:42:29,166 - INFO - â”œâ”€â”€ Loss: 7.1995
2025-03-02 14:42:29,166 - INFO - â”œâ”€â”€ Learning Rate: 2.67e-04
2025-03-02 14:42:29,166 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:42:29,832 - INFO - ðŸªœ Batch step - 1784 -- sub batch step 7136 -- lr 2.68e-04
2025-03-02 14:42:31,990 - INFO - ðŸªœ Batch step - 1784 -- sub batch step 7137 -- lr 2.68e-04
2025-03-02 14:42:34,137 - INFO - ðŸªœ Batch step - 1784 -- sub batch step 7138 -- lr 2.68e-04
2025-03-02 14:42:36,305 - INFO - ðŸªœ Batch step - 1784 -- sub batch step 7139 -- lr 2.68e-04
2025-03-02 14:42:37,855 - INFO - Step 1784 -- ðŸ”„ Training Metrics
2025-03-02 14:42:37,856 - INFO - â”œâ”€â”€ Loss: 7.1683
2025-03-02 14:42:37,856 - INFO - â”œâ”€â”€ Learning Rate: 2.68e-04
2025-03-02 14:42:37,856 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:42:38,530 - INFO - ðŸªœ Batch step - 1785 -- sub batch step 7140 -- lr 2.68e-04
2025-03-02 14:42:40,684 - INFO - ðŸªœ Batch step - 1785 -- sub batch step 7141 -- lr 2.68e-04
2025-03-02 14:42:42,839 - INFO - ðŸªœ Batch step - 1785 -- sub batch step 7142 -- lr 2.68e-04
2025-03-02 14:42:45,245 - INFO - ðŸªœ Batch step - 1785 -- sub batch step 7143 -- lr 2.68e-04
2025-03-02 14:42:47,271 - INFO - Step 1785 -- ðŸ”„ Training Metrics
2025-03-02 14:42:47,271 - INFO - â”œâ”€â”€ Loss: 7.2097
2025-03-02 14:42:47,271 - INFO - â”œâ”€â”€ Learning Rate: 2.68e-04
2025-03-02 14:42:47,272 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:42:47,946 - INFO - ðŸªœ Batch step - 1786 -- sub batch step 7144 -- lr 2.68e-04
2025-03-02 14:42:50,098 - INFO - ðŸªœ Batch step - 1786 -- sub batch step 7145 -- lr 2.68e-04
2025-03-02 14:42:52,246 - INFO - ðŸªœ Batch step - 1786 -- sub batch step 7146 -- lr 2.68e-04
2025-03-02 14:42:54,413 - INFO - ðŸªœ Batch step - 1786 -- sub batch step 7147 -- lr 2.68e-04
2025-03-02 14:42:55,969 - INFO - Step 1786 -- ðŸ”„ Training Metrics
2025-03-02 14:42:55,969 - INFO - â”œâ”€â”€ Loss: 7.2242
2025-03-02 14:42:55,969 - INFO - â”œâ”€â”€ Learning Rate: 2.68e-04
2025-03-02 14:42:55,969 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:42:56,638 - INFO - ðŸªœ Batch step - 1787 -- sub batch step 7148 -- lr 2.68e-04
2025-03-02 14:42:58,796 - INFO - ðŸªœ Batch step - 1787 -- sub batch step 7149 -- lr 2.68e-04
2025-03-02 14:43:00,952 - INFO - ðŸªœ Batch step - 1787 -- sub batch step 7150 -- lr 2.68e-04
2025-03-02 14:43:03,540 - INFO - ðŸªœ Batch step - 1787 -- sub batch step 7151 -- lr 2.68e-04
2025-03-02 14:43:05,294 - INFO - Step 1787 -- ðŸ”„ Training Metrics
2025-03-02 14:43:05,294 - INFO - â”œâ”€â”€ Loss: 7.1800
2025-03-02 14:43:05,294 - INFO - â”œâ”€â”€ Learning Rate: 2.68e-04
2025-03-02 14:43:05,294 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:43:05,972 - INFO - ðŸªœ Batch step - 1788 -- sub batch step 7152 -- lr 2.68e-04
2025-03-02 14:43:08,121 - INFO - ðŸªœ Batch step - 1788 -- sub batch step 7153 -- lr 2.68e-04
2025-03-02 14:43:10,275 - INFO - ðŸªœ Batch step - 1788 -- sub batch step 7154 -- lr 2.68e-04
2025-03-02 14:43:12,449 - INFO - ðŸªœ Batch step - 1788 -- sub batch step 7155 -- lr 2.68e-04
2025-03-02 14:43:13,999 - INFO - Step 1788 -- ðŸ”„ Training Metrics
2025-03-02 14:43:13,999 - INFO - â”œâ”€â”€ Loss: 7.1977
2025-03-02 14:43:13,999 - INFO - â”œâ”€â”€ Learning Rate: 2.68e-04
2025-03-02 14:43:13,999 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:43:14,667 - INFO - ðŸªœ Batch step - 1789 -- sub batch step 7156 -- lr 2.68e-04
2025-03-02 14:43:16,829 - INFO - ðŸªœ Batch step - 1789 -- sub batch step 7157 -- lr 2.68e-04
2025-03-02 14:43:18,980 - INFO - ðŸªœ Batch step - 1789 -- sub batch step 7158 -- lr 2.68e-04
2025-03-02 14:43:21,626 - INFO - ðŸªœ Batch step - 1789 -- sub batch step 7159 -- lr 2.68e-04
2025-03-02 14:43:23,112 - INFO - Step 1789 -- ðŸ”„ Training Metrics
2025-03-02 14:43:23,113 - INFO - â”œâ”€â”€ Loss: 7.2126
2025-03-02 14:43:23,113 - INFO - â”œâ”€â”€ Learning Rate: 2.68e-04
2025-03-02 14:43:23,113 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:43:23,789 - INFO - ðŸªœ Batch step - 1790 -- sub batch step 7160 -- lr 2.68e-04
2025-03-02 14:43:25,939 - INFO - ðŸªœ Batch step - 1790 -- sub batch step 7161 -- lr 2.68e-04
2025-03-02 14:43:28,094 - INFO - ðŸªœ Batch step - 1790 -- sub batch step 7162 -- lr 2.68e-04
2025-03-02 14:43:30,261 - INFO - ðŸªœ Batch step - 1790 -- sub batch step 7163 -- lr 2.68e-04
2025-03-02 14:43:31,799 - INFO - Step 1790 -- ðŸ”„ Training Metrics
2025-03-02 14:43:31,800 - INFO - â”œâ”€â”€ Loss: 7.1813
2025-03-02 14:43:31,800 - INFO - â”œâ”€â”€ Learning Rate: 2.68e-04
2025-03-02 14:43:31,800 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:43:32,477 - INFO - ðŸªœ Batch step - 1791 -- sub batch step 7164 -- lr 2.69e-04
2025-03-02 14:43:34,630 - INFO - ðŸªœ Batch step - 1791 -- sub batch step 7165 -- lr 2.69e-04
2025-03-02 14:43:37,284 - INFO - ðŸªœ Batch step - 1791 -- sub batch step 7166 -- lr 2.69e-04
2025-03-02 14:43:39,444 - INFO - ðŸªœ Batch step - 1791 -- sub batch step 7167 -- lr 2.69e-04
2025-03-02 14:43:40,991 - INFO - Step 1791 -- ðŸ”„ Training Metrics
2025-03-02 14:43:40,991 - INFO - â”œâ”€â”€ Loss: 7.1957
2025-03-02 14:43:40,991 - INFO - â”œâ”€â”€ Learning Rate: 2.69e-04
2025-03-02 14:43:40,991 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:43:41,659 - INFO - ðŸªœ Batch step - 1792 -- sub batch step 7168 -- lr 2.69e-04
2025-03-02 14:43:43,816 - INFO - ðŸªœ Batch step - 1792 -- sub batch step 7169 -- lr 2.69e-04
2025-03-02 14:43:45,990 - INFO - ðŸªœ Batch step - 1792 -- sub batch step 7170 -- lr 2.69e-04
2025-03-02 14:43:48,138 - INFO - ðŸªœ Batch step - 1792 -- sub batch step 7171 -- lr 2.69e-04
2025-03-02 14:43:49,680 - INFO - Step 1792 -- ðŸ”„ Training Metrics
2025-03-02 14:43:49,680 - INFO - â”œâ”€â”€ Loss: 7.1953
2025-03-02 14:43:49,680 - INFO - â”œâ”€â”€ Learning Rate: 2.69e-04
2025-03-02 14:43:49,680 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:43:50,357 - INFO - ðŸªœ Batch step - 1793 -- sub batch step 7172 -- lr 2.69e-04
2025-03-02 14:43:52,506 - INFO - ðŸªœ Batch step - 1793 -- sub batch step 7173 -- lr 2.69e-04
2025-03-02 14:43:55,165 - INFO - ðŸªœ Batch step - 1793 -- sub batch step 7174 -- lr 2.69e-04
2025-03-02 14:43:57,318 - INFO - ðŸªœ Batch step - 1793 -- sub batch step 7175 -- lr 2.69e-04
2025-03-02 14:43:59,064 - INFO - Step 1793 -- ðŸ”„ Training Metrics
2025-03-02 14:43:59,065 - INFO - â”œâ”€â”€ Loss: 7.1633
2025-03-02 14:43:59,065 - INFO - â”œâ”€â”€ Learning Rate: 2.69e-04
2025-03-02 14:43:59,065 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:43:59,734 - INFO - ðŸªœ Batch step - 1794 -- sub batch step 7176 -- lr 2.69e-04
2025-03-02 14:44:01,893 - INFO - ðŸªœ Batch step - 1794 -- sub batch step 7177 -- lr 2.69e-04
2025-03-02 14:44:04,056 - INFO - ðŸªœ Batch step - 1794 -- sub batch step 7178 -- lr 2.69e-04
2025-03-02 14:44:06,209 - INFO - ðŸªœ Batch step - 1794 -- sub batch step 7179 -- lr 2.69e-04
2025-03-02 14:44:07,759 - INFO - Step 1794 -- ðŸ”„ Training Metrics
2025-03-02 14:44:07,759 - INFO - â”œâ”€â”€ Loss: 7.1875
2025-03-02 14:44:07,760 - INFO - â”œâ”€â”€ Learning Rate: 2.69e-04
2025-03-02 14:44:07,760 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:44:08,438 - INFO - ðŸªœ Batch step - 1795 -- sub batch step 7180 -- lr 2.69e-04
2025-03-02 14:44:10,588 - INFO - ðŸªœ Batch step - 1795 -- sub batch step 7181 -- lr 2.69e-04
2025-03-02 14:44:13,161 - INFO - ðŸªœ Batch step - 1795 -- sub batch step 7182 -- lr 2.69e-04
2025-03-02 14:44:15,312 - INFO - ðŸªœ Batch step - 1795 -- sub batch step 7183 -- lr 2.69e-04
2025-03-02 14:44:17,137 - INFO - Step 1795 -- ðŸ”„ Training Metrics
2025-03-02 14:44:17,138 - INFO - â”œâ”€â”€ Loss: 7.1908
2025-03-02 14:44:17,138 - INFO - â”œâ”€â”€ Learning Rate: 2.69e-04
2025-03-02 14:44:17,138 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:44:17,813 - INFO - ðŸªœ Batch step - 1796 -- sub batch step 7184 -- lr 2.69e-04
2025-03-02 14:44:19,966 - INFO - ðŸªœ Batch step - 1796 -- sub batch step 7185 -- lr 2.69e-04
2025-03-02 14:44:22,130 - INFO - ðŸªœ Batch step - 1796 -- sub batch step 7186 -- lr 2.69e-04
2025-03-02 14:44:24,286 - INFO - ðŸªœ Batch step - 1796 -- sub batch step 7187 -- lr 2.69e-04
2025-03-02 14:44:25,839 - INFO - Step 1796 -- ðŸ”„ Training Metrics
2025-03-02 14:44:25,839 - INFO - â”œâ”€â”€ Loss: 7.2024
2025-03-02 14:44:25,839 - INFO - â”œâ”€â”€ Learning Rate: 2.69e-04
2025-03-02 14:44:25,839 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:44:26,512 - INFO - ðŸªœ Batch step - 1797 -- sub batch step 7188 -- lr 2.70e-04
2025-03-02 14:44:28,671 - INFO - ðŸªœ Batch step - 1797 -- sub batch step 7189 -- lr 2.70e-04
2025-03-02 14:44:31,041 - INFO - ðŸªœ Batch step - 1797 -- sub batch step 7190 -- lr 2.70e-04
2025-03-02 14:44:33,196 - INFO - ðŸªœ Batch step - 1797 -- sub batch step 7191 -- lr 2.70e-04
2025-03-02 14:44:35,058 - INFO - Step 1797 -- ðŸ”„ Training Metrics
2025-03-02 14:44:35,059 - INFO - â”œâ”€â”€ Loss: 7.2072
2025-03-02 14:44:35,059 - INFO - â”œâ”€â”€ Learning Rate: 2.70e-04
2025-03-02 14:44:35,059 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:44:35,736 - INFO - ðŸªœ Batch step - 1798 -- sub batch step 7192 -- lr 2.70e-04
2025-03-02 14:44:37,884 - INFO - ðŸªœ Batch step - 1798 -- sub batch step 7193 -- lr 2.70e-04
2025-03-02 14:44:40,054 - INFO - ðŸªœ Batch step - 1798 -- sub batch step 7194 -- lr 2.70e-04
2025-03-02 14:44:42,208 - INFO - ðŸªœ Batch step - 1798 -- sub batch step 7195 -- lr 2.70e-04
2025-03-02 14:44:43,754 - INFO - Step 1798 -- ðŸ”„ Training Metrics
2025-03-02 14:44:43,754 - INFO - â”œâ”€â”€ Loss: 7.1763
2025-03-02 14:44:43,754 - INFO - â”œâ”€â”€ Learning Rate: 2.70e-04
2025-03-02 14:44:43,754 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:44:44,419 - INFO - ðŸªœ Batch step - 1799 -- sub batch step 7196 -- lr 2.70e-04
2025-03-02 14:44:46,577 - INFO - ðŸªœ Batch step - 1799 -- sub batch step 7197 -- lr 2.70e-04
2025-03-02 14:44:48,850 - INFO - ðŸªœ Batch step - 1799 -- sub batch step 7198 -- lr 2.70e-04
2025-03-02 14:44:51,006 - INFO - ðŸªœ Batch step - 1799 -- sub batch step 7199 -- lr 2.70e-04
2025-03-02 14:44:52,558 - INFO - Step 1799 -- ðŸ”„ Training Metrics
2025-03-02 14:44:52,558 - INFO - â”œâ”€â”€ Loss: 7.1925
2025-03-02 14:44:52,558 - INFO - â”œâ”€â”€ Learning Rate: 2.70e-04
2025-03-02 14:44:52,558 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:44:53,696 - INFO - ðŸªœ Batch step - 1800 -- sub batch step 7200 -- lr 2.70e-04
2025-03-02 14:44:55,844 - INFO - ðŸªœ Batch step - 1800 -- sub batch step 7201 -- lr 2.70e-04
2025-03-02 14:44:57,998 - INFO - ðŸªœ Batch step - 1800 -- sub batch step 7202 -- lr 2.70e-04
2025-03-02 14:45:00,164 - INFO - ðŸªœ Batch step - 1800 -- sub batch step 7203 -- lr 2.70e-04
2025-03-02 14:45:03,655 - INFO - Step 1800 -- ðŸ”„ Training Metrics
2025-03-02 14:45:03,655 - INFO - â”œâ”€â”€ Loss: 7.1734
2025-03-02 14:45:03,655 - INFO - â”œâ”€â”€ Learning Rate: 2.70e-04
2025-03-02 14:45:03,655 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:45:04,332 - INFO - ðŸªœ Batch step - 1801 -- sub batch step 7204 -- lr 2.70e-04
2025-03-02 14:45:06,487 - INFO - ðŸªœ Batch step - 1801 -- sub batch step 7205 -- lr 2.70e-04
2025-03-02 14:45:08,635 - INFO - ðŸªœ Batch step - 1801 -- sub batch step 7206 -- lr 2.70e-04
2025-03-02 14:45:11,265 - INFO - ðŸªœ Batch step - 1801 -- sub batch step 7207 -- lr 2.70e-04
2025-03-02 14:45:12,759 - INFO - Step 1801 -- ðŸ”„ Training Metrics
2025-03-02 14:45:12,776 - INFO - â”œâ”€â”€ Loss: 7.1975
2025-03-02 14:45:12,776 - INFO - â”œâ”€â”€ Learning Rate: 2.70e-04
2025-03-02 14:45:12,776 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:45:13,450 - INFO - ðŸªœ Batch step - 1802 -- sub batch step 7208 -- lr 2.70e-04
2025-03-02 14:45:15,615 - INFO - ðŸªœ Batch step - 1802 -- sub batch step 7209 -- lr 2.70e-04
2025-03-02 14:45:17,776 - INFO - ðŸªœ Batch step - 1802 -- sub batch step 7210 -- lr 2.70e-04
2025-03-02 14:45:19,942 - INFO - ðŸªœ Batch step - 1802 -- sub batch step 7211 -- lr 2.70e-04
2025-03-02 14:45:21,469 - INFO - Step 1802 -- ðŸ”„ Training Metrics
2025-03-02 14:45:21,469 - INFO - â”œâ”€â”€ Loss: 7.1899
2025-03-02 14:45:21,469 - INFO - â”œâ”€â”€ Learning Rate: 2.70e-04
2025-03-02 14:45:21,469 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:45:22,148 - INFO - ðŸªœ Batch step - 1803 -- sub batch step 7212 -- lr 2.70e-04
2025-03-02 14:45:24,298 - INFO - ðŸªœ Batch step - 1803 -- sub batch step 7213 -- lr 2.70e-04
2025-03-02 14:45:26,453 - INFO - ðŸªœ Batch step - 1803 -- sub batch step 7214 -- lr 2.70e-04
2025-03-02 14:45:29,249 - INFO - ðŸªœ Batch step - 1803 -- sub batch step 7215 -- lr 2.70e-04
2025-03-02 14:45:30,740 - INFO - Step 1803 -- ðŸ”„ Training Metrics
2025-03-02 14:45:30,740 - INFO - â”œâ”€â”€ Loss: 7.1844
2025-03-02 14:45:30,740 - INFO - â”œâ”€â”€ Learning Rate: 2.70e-04
2025-03-02 14:45:30,740 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:45:31,415 - INFO - ðŸªœ Batch step - 1804 -- sub batch step 7216 -- lr 2.71e-04
2025-03-02 14:45:33,570 - INFO - ðŸªœ Batch step - 1804 -- sub batch step 7217 -- lr 2.71e-04
2025-03-02 14:45:35,720 - INFO - ðŸªœ Batch step - 1804 -- sub batch step 7218 -- lr 2.71e-04
2025-03-02 14:45:37,888 - INFO - ðŸªœ Batch step - 1804 -- sub batch step 7219 -- lr 2.71e-04
2025-03-02 14:45:39,434 - INFO - Step 1804 -- ðŸ”„ Training Metrics
2025-03-02 14:45:39,434 - INFO - â”œâ”€â”€ Loss: 7.1917
2025-03-02 14:45:39,434 - INFO - â”œâ”€â”€ Learning Rate: 2.71e-04
2025-03-02 14:45:39,434 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:45:40,111 - INFO - ðŸªœ Batch step - 1805 -- sub batch step 7220 -- lr 2.71e-04
2025-03-02 14:45:42,260 - INFO - ðŸªœ Batch step - 1805 -- sub batch step 7221 -- lr 2.71e-04
2025-03-02 14:45:44,416 - INFO - ðŸªœ Batch step - 1805 -- sub batch step 7222 -- lr 2.71e-04
2025-03-02 14:45:46,870 - INFO - ðŸªœ Batch step - 1805 -- sub batch step 7223 -- lr 2.71e-04
2025-03-02 14:45:48,763 - INFO - Step 1805 -- ðŸ”„ Training Metrics
2025-03-02 14:45:48,764 - INFO - â”œâ”€â”€ Loss: 7.1977
2025-03-02 14:45:48,764 - INFO - â”œâ”€â”€ Learning Rate: 2.71e-04
2025-03-02 14:45:48,764 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:45:49,442 - INFO - ðŸªœ Batch step - 1806 -- sub batch step 7224 -- lr 2.71e-04
2025-03-02 14:45:51,599 - INFO - ðŸªœ Batch step - 1806 -- sub batch step 7225 -- lr 2.71e-04
2025-03-02 14:45:53,749 - INFO - ðŸªœ Batch step - 1806 -- sub batch step 7226 -- lr 2.71e-04
2025-03-02 14:45:55,919 - INFO - ðŸªœ Batch step - 1806 -- sub batch step 7227 -- lr 2.71e-04
2025-03-02 14:45:57,460 - INFO - Step 1806 -- ðŸ”„ Training Metrics
2025-03-02 14:45:57,460 - INFO - â”œâ”€â”€ Loss: 7.1784
2025-03-02 14:45:57,461 - INFO - â”œâ”€â”€ Learning Rate: 2.71e-04
2025-03-02 14:45:57,461 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:45:58,128 - INFO - ðŸªœ Batch step - 1807 -- sub batch step 7228 -- lr 2.71e-04
2025-03-02 14:46:00,289 - INFO - ðŸªœ Batch step - 1807 -- sub batch step 7229 -- lr 2.71e-04
2025-03-02 14:46:02,445 - INFO - ðŸªœ Batch step - 1807 -- sub batch step 7230 -- lr 2.71e-04
2025-03-02 14:46:05,261 - INFO - ðŸªœ Batch step - 1807 -- sub batch step 7231 -- lr 2.71e-04
2025-03-02 14:46:06,839 - INFO - Step 1807 -- ðŸ”„ Training Metrics
2025-03-02 14:46:06,839 - INFO - â”œâ”€â”€ Loss: 7.1922
2025-03-02 14:46:06,839 - INFO - â”œâ”€â”€ Learning Rate: 2.71e-04
2025-03-02 14:46:06,840 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:46:07,515 - INFO - ðŸªœ Batch step - 1808 -- sub batch step 7232 -- lr 2.71e-04
2025-03-02 14:46:09,668 - INFO - ðŸªœ Batch step - 1808 -- sub batch step 7233 -- lr 2.71e-04
2025-03-02 14:46:11,826 - INFO - ðŸªœ Batch step - 1808 -- sub batch step 7234 -- lr 2.71e-04
2025-03-02 14:46:14,007 - INFO - ðŸªœ Batch step - 1808 -- sub batch step 7235 -- lr 2.71e-04
2025-03-02 14:46:15,552 - INFO - Step 1808 -- ðŸ”„ Training Metrics
2025-03-02 14:46:15,552 - INFO - â”œâ”€â”€ Loss: 7.1827
2025-03-02 14:46:15,552 - INFO - â”œâ”€â”€ Learning Rate: 2.71e-04
2025-03-02 14:46:15,553 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:46:16,221 - INFO - ðŸªœ Batch step - 1809 -- sub batch step 7236 -- lr 2.71e-04
2025-03-02 14:46:18,374 - INFO - ðŸªœ Batch step - 1809 -- sub batch step 7237 -- lr 2.71e-04
2025-03-02 14:46:20,522 - INFO - ðŸªœ Batch step - 1809 -- sub batch step 7238 -- lr 2.71e-04
2025-03-02 14:46:23,327 - INFO - ðŸªœ Batch step - 1809 -- sub batch step 7239 -- lr 2.71e-04
2025-03-02 14:46:24,940 - INFO - Step 1809 -- ðŸ”„ Training Metrics
2025-03-02 14:46:24,940 - INFO - â”œâ”€â”€ Loss: 7.1987
2025-03-02 14:46:24,940 - INFO - â”œâ”€â”€ Learning Rate: 2.71e-04
2025-03-02 14:46:24,940 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:46:25,612 - INFO - ðŸªœ Batch step - 1810 -- sub batch step 7240 -- lr 2.71e-04
2025-03-02 14:46:27,768 - INFO - ðŸªœ Batch step - 1810 -- sub batch step 7241 -- lr 2.71e-04
2025-03-02 14:46:29,921 - INFO - ðŸªœ Batch step - 1810 -- sub batch step 7242 -- lr 2.71e-04
2025-03-02 14:46:32,084 - INFO - ðŸªœ Batch step - 1810 -- sub batch step 7243 -- lr 2.71e-04
2025-03-02 14:46:33,626 - INFO - Step 1810 -- ðŸ”„ Training Metrics
2025-03-02 14:46:33,627 - INFO - â”œâ”€â”€ Loss: 7.1761
2025-03-02 14:46:33,627 - INFO - â”œâ”€â”€ Learning Rate: 2.71e-04
2025-03-02 14:46:33,627 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:46:34,301 - INFO - ðŸªœ Batch step - 1811 -- sub batch step 7244 -- lr 2.72e-04
2025-03-02 14:46:36,455 - INFO - ðŸªœ Batch step - 1811 -- sub batch step 7245 -- lr 2.72e-04
2025-03-02 14:46:39,162 - INFO - ðŸªœ Batch step - 1811 -- sub batch step 7246 -- lr 2.72e-04
2025-03-02 14:46:41,318 - INFO - ðŸªœ Batch step - 1811 -- sub batch step 7247 -- lr 2.72e-04
2025-03-02 14:46:42,890 - INFO - Step 1811 -- ðŸ”„ Training Metrics
2025-03-02 14:46:42,890 - INFO - â”œâ”€â”€ Loss: 7.1924
2025-03-02 14:46:42,890 - INFO - â”œâ”€â”€ Learning Rate: 2.72e-04
2025-03-02 14:46:42,890 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:46:43,560 - INFO - ðŸªœ Batch step - 1812 -- sub batch step 7248 -- lr 2.72e-04
2025-03-02 14:46:45,719 - INFO - ðŸªœ Batch step - 1812 -- sub batch step 7249 -- lr 2.72e-04
2025-03-02 14:46:47,892 - INFO - ðŸªœ Batch step - 1812 -- sub batch step 7250 -- lr 2.72e-04
2025-03-02 14:46:50,042 - INFO - ðŸªœ Batch step - 1812 -- sub batch step 7251 -- lr 2.72e-04
2025-03-02 14:46:51,593 - INFO - Step 1812 -- ðŸ”„ Training Metrics
2025-03-02 14:46:51,593 - INFO - â”œâ”€â”€ Loss: 7.1599
2025-03-02 14:46:51,593 - INFO - â”œâ”€â”€ Learning Rate: 2.72e-04
2025-03-02 14:46:51,594 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:46:52,273 - INFO - ðŸªœ Batch step - 1813 -- sub batch step 7252 -- lr 2.72e-04
2025-03-02 14:46:54,421 - INFO - ðŸªœ Batch step - 1813 -- sub batch step 7253 -- lr 2.72e-04
2025-03-02 14:46:57,087 - INFO - ðŸªœ Batch step - 1813 -- sub batch step 7254 -- lr 2.72e-04
2025-03-02 14:46:59,241 - INFO - ðŸªœ Batch step - 1813 -- sub batch step 7255 -- lr 2.72e-04
2025-03-02 14:47:00,733 - INFO - Step 1813 -- ðŸ”„ Training Metrics
2025-03-02 14:47:00,733 - INFO - â”œâ”€â”€ Loss: 7.1826
2025-03-02 14:47:00,733 - INFO - â”œâ”€â”€ Learning Rate: 2.72e-04
2025-03-02 14:47:00,734 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:47:01,407 - INFO - ðŸªœ Batch step - 1814 -- sub batch step 7256 -- lr 2.72e-04
2025-03-02 14:47:03,559 - INFO - ðŸªœ Batch step - 1814 -- sub batch step 7257 -- lr 2.72e-04
2025-03-02 14:47:05,720 - INFO - ðŸªœ Batch step - 1814 -- sub batch step 7258 -- lr 2.72e-04
2025-03-02 14:47:07,874 - INFO - ðŸªœ Batch step - 1814 -- sub batch step 7259 -- lr 2.72e-04
2025-03-02 14:47:09,430 - INFO - Step 1814 -- ðŸ”„ Training Metrics
2025-03-02 14:47:09,430 - INFO - â”œâ”€â”€ Loss: 7.1631
2025-03-02 14:47:09,431 - INFO - â”œâ”€â”€ Learning Rate: 2.72e-04
2025-03-02 14:47:09,431 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:47:10,108 - INFO - ðŸªœ Batch step - 1815 -- sub batch step 7260 -- lr 2.72e-04
2025-03-02 14:47:12,259 - INFO - ðŸªœ Batch step - 1815 -- sub batch step 7261 -- lr 2.72e-04
2025-03-02 14:47:14,674 - INFO - ðŸªœ Batch step - 1815 -- sub batch step 7262 -- lr 2.72e-04
2025-03-02 14:47:16,829 - INFO - ðŸªœ Batch step - 1815 -- sub batch step 7263 -- lr 2.72e-04
2025-03-02 14:47:18,615 - INFO - Step 1815 -- ðŸ”„ Training Metrics
2025-03-02 14:47:18,616 - INFO - â”œâ”€â”€ Loss: 7.1754
2025-03-02 14:47:18,616 - INFO - â”œâ”€â”€ Learning Rate: 2.72e-04
2025-03-02 14:47:18,616 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:47:19,293 - INFO - ðŸªœ Batch step - 1816 -- sub batch step 7264 -- lr 2.72e-04
2025-03-02 14:47:21,447 - INFO - ðŸªœ Batch step - 1816 -- sub batch step 7265 -- lr 2.72e-04
2025-03-02 14:47:23,612 - INFO - ðŸªœ Batch step - 1816 -- sub batch step 7266 -- lr 2.72e-04
2025-03-02 14:47:25,768 - INFO - ðŸªœ Batch step - 1816 -- sub batch step 7267 -- lr 2.72e-04
2025-03-02 14:47:27,324 - INFO - Step 1816 -- ðŸ”„ Training Metrics
2025-03-02 14:47:27,324 - INFO - â”œâ”€â”€ Loss: 7.1995
2025-03-02 14:47:27,324 - INFO - â”œâ”€â”€ Learning Rate: 2.72e-04
2025-03-02 14:47:27,324 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:47:27,991 - INFO - ðŸªœ Batch step - 1817 -- sub batch step 7268 -- lr 2.73e-04
2025-03-02 14:47:30,150 - INFO - ðŸªœ Batch step - 1817 -- sub batch step 7269 -- lr 2.73e-04
2025-03-02 14:47:32,800 - INFO - ðŸªœ Batch step - 1817 -- sub batch step 7270 -- lr 2.73e-04
2025-03-02 14:47:34,957 - INFO - ðŸªœ Batch step - 1817 -- sub batch step 7271 -- lr 2.73e-04
2025-03-02 14:47:36,629 - INFO - Step 1817 -- ðŸ”„ Training Metrics
2025-03-02 14:47:36,629 - INFO - â”œâ”€â”€ Loss: 7.1875
2025-03-02 14:47:36,630 - INFO - â”œâ”€â”€ Learning Rate: 2.73e-04
2025-03-02 14:47:36,630 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:47:37,308 - INFO - ðŸªœ Batch step - 1818 -- sub batch step 7272 -- lr 2.73e-04
2025-03-02 14:47:39,462 - INFO - ðŸªœ Batch step - 1818 -- sub batch step 7273 -- lr 2.73e-04
2025-03-02 14:47:41,633 - INFO - ðŸªœ Batch step - 1818 -- sub batch step 7274 -- lr 2.73e-04
2025-03-02 14:47:43,786 - INFO - ðŸªœ Batch step - 1818 -- sub batch step 7275 -- lr 2.73e-04
2025-03-02 14:47:45,339 - INFO - Step 1818 -- ðŸ”„ Training Metrics
2025-03-02 14:47:45,339 - INFO - â”œâ”€â”€ Loss: 7.1762
2025-03-02 14:47:45,339 - INFO - â”œâ”€â”€ Learning Rate: 2.73e-04
2025-03-02 14:47:45,339 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:47:46,012 - INFO - ðŸªœ Batch step - 1819 -- sub batch step 7276 -- lr 2.73e-04
2025-03-02 14:47:48,167 - INFO - ðŸªœ Batch step - 1819 -- sub batch step 7277 -- lr 2.73e-04
2025-03-02 14:47:50,441 - INFO - ðŸªœ Batch step - 1819 -- sub batch step 7278 -- lr 2.73e-04
2025-03-02 14:47:52,601 - INFO - ðŸªœ Batch step - 1819 -- sub batch step 7279 -- lr 2.73e-04
2025-03-02 14:47:54,163 - INFO - Step 1819 -- ðŸ”„ Training Metrics
2025-03-02 14:47:54,163 - INFO - â”œâ”€â”€ Loss: 7.1791
2025-03-02 14:47:54,163 - INFO - â”œâ”€â”€ Learning Rate: 2.73e-04
2025-03-02 14:47:54,163 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:47:55,245 - INFO - ðŸªœ Batch step - 1820 -- sub batch step 7280 -- lr 2.73e-04
2025-03-02 14:47:57,400 - INFO - ðŸªœ Batch step - 1820 -- sub batch step 7281 -- lr 2.73e-04
2025-03-02 14:47:59,557 - INFO - ðŸªœ Batch step - 1820 -- sub batch step 7282 -- lr 2.73e-04
2025-03-02 14:48:01,724 - INFO - ðŸªœ Batch step - 1820 -- sub batch step 7283 -- lr 2.73e-04
2025-03-02 14:48:03,981 - INFO - Step 1820 -- ðŸ”„ Training Metrics
2025-03-02 14:48:03,981 - INFO - â”œâ”€â”€ Loss: 7.1558
2025-03-02 14:48:03,981 - INFO - â”œâ”€â”€ Learning Rate: 2.73e-04
2025-03-02 14:48:03,981 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:48:04,655 - INFO - ðŸªœ Batch step - 1821 -- sub batch step 7284 -- lr 2.73e-04
2025-03-02 14:48:06,809 - INFO - ðŸªœ Batch step - 1821 -- sub batch step 7285 -- lr 2.73e-04
2025-03-02 14:48:08,956 - INFO - ðŸªœ Batch step - 1821 -- sub batch step 7286 -- lr 2.73e-04
2025-03-02 14:48:11,580 - INFO - ðŸªœ Batch step - 1821 -- sub batch step 7287 -- lr 2.73e-04
2025-03-02 14:48:13,071 - INFO - Step 1821 -- ðŸ”„ Training Metrics
2025-03-02 14:48:13,071 - INFO - â”œâ”€â”€ Loss: 7.1821
2025-03-02 14:48:13,071 - INFO - â”œâ”€â”€ Learning Rate: 2.73e-04
2025-03-02 14:48:13,071 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:48:13,739 - INFO - ðŸªœ Batch step - 1822 -- sub batch step 7288 -- lr 2.73e-04
2025-03-02 14:48:15,897 - INFO - ðŸªœ Batch step - 1822 -- sub batch step 7289 -- lr 2.73e-04
2025-03-02 14:48:18,054 - INFO - ðŸªœ Batch step - 1822 -- sub batch step 7290 -- lr 2.73e-04
2025-03-02 14:48:20,223 - INFO - ðŸªœ Batch step - 1822 -- sub batch step 7291 -- lr 2.73e-04
2025-03-02 14:48:21,767 - INFO - Step 1822 -- ðŸ”„ Training Metrics
2025-03-02 14:48:21,767 - INFO - â”œâ”€â”€ Loss: 7.1681
2025-03-02 14:48:21,767 - INFO - â”œâ”€â”€ Learning Rate: 2.73e-04
2025-03-02 14:48:21,767 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:48:22,445 - INFO - ðŸªœ Batch step - 1823 -- sub batch step 7292 -- lr 2.73e-04
2025-03-02 14:48:24,596 - INFO - ðŸªœ Batch step - 1823 -- sub batch step 7293 -- lr 2.73e-04
2025-03-02 14:48:26,752 - INFO - ðŸªœ Batch step - 1823 -- sub batch step 7294 -- lr 2.73e-04
2025-03-02 14:48:29,350 - INFO - ðŸªœ Batch step - 1823 -- sub batch step 7295 -- lr 2.73e-04
2025-03-02 14:48:31,161 - INFO - Step 1823 -- ðŸ”„ Training Metrics
2025-03-02 14:48:31,161 - INFO - â”œâ”€â”€ Loss: 7.1751
2025-03-02 14:48:31,161 - INFO - â”œâ”€â”€ Learning Rate: 2.73e-04
2025-03-02 14:48:31,161 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:48:31,833 - INFO - ðŸªœ Batch step - 1824 -- sub batch step 7296 -- lr 2.74e-04
2025-03-02 14:48:33,990 - INFO - ðŸªœ Batch step - 1824 -- sub batch step 7297 -- lr 2.74e-04
2025-03-02 14:48:36,137 - INFO - ðŸªœ Batch step - 1824 -- sub batch step 7298 -- lr 2.74e-04
2025-03-02 14:48:38,307 - INFO - ðŸªœ Batch step - 1824 -- sub batch step 7299 -- lr 2.74e-04
2025-03-02 14:48:39,854 - INFO - Step 1824 -- ðŸ”„ Training Metrics
2025-03-02 14:48:39,854 - INFO - â”œâ”€â”€ Loss: 7.1748
2025-03-02 14:48:39,855 - INFO - â”œâ”€â”€ Learning Rate: 2.74e-04
2025-03-02 14:48:39,855 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:48:40,526 - INFO - ðŸªœ Batch step - 1825 -- sub batch step 7300 -- lr 2.74e-04
2025-03-02 14:48:42,682 - INFO - ðŸªœ Batch step - 1825 -- sub batch step 7301 -- lr 2.74e-04
2025-03-02 14:48:44,837 - INFO - ðŸªœ Batch step - 1825 -- sub batch step 7302 -- lr 2.74e-04
2025-03-02 14:48:47,629 - INFO - ðŸªœ Batch step - 1825 -- sub batch step 7303 -- lr 2.74e-04
2025-03-02 14:48:49,120 - INFO - Step 1825 -- ðŸ”„ Training Metrics
2025-03-02 14:48:49,120 - INFO - â”œâ”€â”€ Loss: 7.1597
2025-03-02 14:48:49,120 - INFO - â”œâ”€â”€ Learning Rate: 2.74e-04
2025-03-02 14:48:49,120 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:48:49,797 - INFO - ðŸªœ Batch step - 1826 -- sub batch step 7304 -- lr 2.74e-04
2025-03-02 14:48:51,955 - INFO - ðŸªœ Batch step - 1826 -- sub batch step 7305 -- lr 2.74e-04
2025-03-02 14:48:54,106 - INFO - ðŸªœ Batch step - 1826 -- sub batch step 7306 -- lr 2.74e-04
2025-03-02 14:48:56,277 - INFO - ðŸªœ Batch step - 1826 -- sub batch step 7307 -- lr 2.74e-04
2025-03-02 14:48:57,817 - INFO - Step 1826 -- ðŸ”„ Training Metrics
2025-03-02 14:48:57,817 - INFO - â”œâ”€â”€ Loss: 7.2051
2025-03-02 14:48:57,817 - INFO - â”œâ”€â”€ Learning Rate: 2.74e-04
2025-03-02 14:48:57,817 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:48:58,486 - INFO - ðŸªœ Batch step - 1827 -- sub batch step 7308 -- lr 2.74e-04
2025-03-02 14:49:00,643 - INFO - ðŸªœ Batch step - 1827 -- sub batch step 7309 -- lr 2.74e-04
2025-03-02 14:49:02,800 - INFO - ðŸªœ Batch step - 1827 -- sub batch step 7310 -- lr 2.74e-04
2025-03-02 14:49:05,595 - INFO - ðŸªœ Batch step - 1827 -- sub batch step 7311 -- lr 2.74e-04
2025-03-02 14:49:07,085 - INFO - Step 1827 -- ðŸ”„ Training Metrics
2025-03-02 14:49:07,086 - INFO - â”œâ”€â”€ Loss: 7.1811
2025-03-02 14:49:07,086 - INFO - â”œâ”€â”€ Learning Rate: 2.74e-04
2025-03-02 14:49:07,086 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:49:07,763 - INFO - ðŸªœ Batch step - 1828 -- sub batch step 7312 -- lr 2.74e-04
2025-03-02 14:49:09,912 - INFO - ðŸªœ Batch step - 1828 -- sub batch step 7313 -- lr 2.74e-04
2025-03-02 14:49:12,067 - INFO - ðŸªœ Batch step - 1828 -- sub batch step 7314 -- lr 2.74e-04
2025-03-02 14:49:14,237 - INFO - ðŸªœ Batch step - 1828 -- sub batch step 7315 -- lr 2.74e-04
2025-03-02 14:49:15,796 - INFO - Step 1828 -- ðŸ”„ Training Metrics
2025-03-02 14:49:15,796 - INFO - â”œâ”€â”€ Loss: 7.1662
2025-03-02 14:49:15,796 - INFO - â”œâ”€â”€ Learning Rate: 2.74e-04
2025-03-02 14:49:15,796 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:49:16,470 - INFO - ðŸªœ Batch step - 1829 -- sub batch step 7316 -- lr 2.74e-04
2025-03-02 14:49:18,624 - INFO - ðŸªœ Batch step - 1829 -- sub batch step 7317 -- lr 2.74e-04
2025-03-02 14:49:20,774 - INFO - ðŸªœ Batch step - 1829 -- sub batch step 7318 -- lr 2.74e-04
2025-03-02 14:49:23,363 - INFO - ðŸªœ Batch step - 1829 -- sub batch step 7319 -- lr 2.74e-04
2025-03-02 14:49:25,087 - INFO - Step 1829 -- ðŸ”„ Training Metrics
2025-03-02 14:49:25,087 - INFO - â”œâ”€â”€ Loss: 7.1948
2025-03-02 14:49:25,087 - INFO - â”œâ”€â”€ Learning Rate: 2.74e-04
2025-03-02 14:49:25,088 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:49:25,763 - INFO - ðŸªœ Batch step - 1830 -- sub batch step 7320 -- lr 2.75e-04
2025-03-02 14:49:27,911 - INFO - ðŸªœ Batch step - 1830 -- sub batch step 7321 -- lr 2.75e-04
2025-03-02 14:49:30,067 - INFO - ðŸªœ Batch step - 1830 -- sub batch step 7322 -- lr 2.75e-04
2025-03-02 14:49:32,229 - INFO - ðŸªœ Batch step - 1830 -- sub batch step 7323 -- lr 2.75e-04
2025-03-02 14:49:33,780 - INFO - Step 1830 -- ðŸ”„ Training Metrics
2025-03-02 14:49:33,780 - INFO - â”œâ”€â”€ Loss: 7.1774
2025-03-02 14:49:33,780 - INFO - â”œâ”€â”€ Learning Rate: 2.75e-04
2025-03-02 14:49:33,780 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:49:34,455 - INFO - ðŸªœ Batch step - 1831 -- sub batch step 7324 -- lr 2.75e-04
2025-03-02 14:49:36,610 - INFO - ðŸªœ Batch step - 1831 -- sub batch step 7325 -- lr 2.75e-04
2025-03-02 14:49:39,282 - INFO - ðŸªœ Batch step - 1831 -- sub batch step 7326 -- lr 2.75e-04
2025-03-02 14:49:41,440 - INFO - ðŸªœ Batch step - 1831 -- sub batch step 7327 -- lr 2.75e-04
2025-03-02 14:49:43,052 - INFO - Step 1831 -- ðŸ”„ Training Metrics
2025-03-02 14:49:43,052 - INFO - â”œâ”€â”€ Loss: 7.1559
2025-03-02 14:49:43,052 - INFO - â”œâ”€â”€ Learning Rate: 2.75e-04
2025-03-02 14:49:43,052 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:49:43,721 - INFO - ðŸªœ Batch step - 1832 -- sub batch step 7328 -- lr 2.75e-04
2025-03-02 14:49:45,881 - INFO - ðŸªœ Batch step - 1832 -- sub batch step 7329 -- lr 2.75e-04
2025-03-02 14:49:48,057 - INFO - ðŸªœ Batch step - 1832 -- sub batch step 7330 -- lr 2.75e-04
2025-03-02 14:49:50,207 - INFO - ðŸªœ Batch step - 1832 -- sub batch step 7331 -- lr 2.75e-04
2025-03-02 14:49:51,762 - INFO - Step 1832 -- ðŸ”„ Training Metrics
2025-03-02 14:49:51,763 - INFO - â”œâ”€â”€ Loss: 7.2122
2025-03-02 14:49:51,763 - INFO - â”œâ”€â”€ Learning Rate: 2.75e-04
2025-03-02 14:49:51,763 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:49:52,441 - INFO - ðŸªœ Batch step - 1833 -- sub batch step 7332 -- lr 2.75e-04
2025-03-02 14:49:54,592 - INFO - ðŸªœ Batch step - 1833 -- sub batch step 7333 -- lr 2.75e-04
2025-03-02 14:49:57,248 - INFO - ðŸªœ Batch step - 1833 -- sub batch step 7334 -- lr 2.75e-04
2025-03-02 14:49:59,409 - INFO - ðŸªœ Batch step - 1833 -- sub batch step 7335 -- lr 2.75e-04
2025-03-02 14:50:01,011 - INFO - Step 1833 -- ðŸ”„ Training Metrics
2025-03-02 14:50:01,011 - INFO - â”œâ”€â”€ Loss: 7.1519
2025-03-02 14:50:01,011 - INFO - â”œâ”€â”€ Learning Rate: 2.75e-04
2025-03-02 14:50:01,012 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:50:01,686 - INFO - ðŸªœ Batch step - 1834 -- sub batch step 7336 -- lr 2.75e-04
2025-03-02 14:50:03,845 - INFO - ðŸªœ Batch step - 1834 -- sub batch step 7337 -- lr 2.75e-04
2025-03-02 14:50:06,014 - INFO - ðŸªœ Batch step - 1834 -- sub batch step 7338 -- lr 2.75e-04
2025-03-02 14:50:08,170 - INFO - ðŸªœ Batch step - 1834 -- sub batch step 7339 -- lr 2.75e-04
2025-03-02 14:50:09,714 - INFO - Step 1834 -- ðŸ”„ Training Metrics
2025-03-02 14:50:09,715 - INFO - â”œâ”€â”€ Loss: 7.2218
2025-03-02 14:50:09,715 - INFO - â”œâ”€â”€ Learning Rate: 2.75e-04
2025-03-02 14:50:09,715 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:50:10,394 - INFO - ðŸªœ Batch step - 1835 -- sub batch step 7340 -- lr 2.75e-04
2025-03-02 14:50:12,546 - INFO - ðŸªœ Batch step - 1835 -- sub batch step 7341 -- lr 2.75e-04
2025-03-02 14:50:15,233 - INFO - ðŸªœ Batch step - 1835 -- sub batch step 7342 -- lr 2.75e-04
2025-03-02 14:50:17,389 - INFO - ðŸªœ Batch step - 1835 -- sub batch step 7343 -- lr 2.75e-04
2025-03-02 14:50:18,946 - INFO - Step 1835 -- ðŸ”„ Training Metrics
2025-03-02 14:50:18,946 - INFO - â”œâ”€â”€ Loss: 7.1643
2025-03-02 14:50:18,946 - INFO - â”œâ”€â”€ Learning Rate: 2.75e-04
2025-03-02 14:50:18,946 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:50:19,624 - INFO - ðŸªœ Batch step - 1836 -- sub batch step 7344 -- lr 2.75e-04
2025-03-02 14:50:21,780 - INFO - ðŸªœ Batch step - 1836 -- sub batch step 7345 -- lr 2.75e-04
2025-03-02 14:50:23,950 - INFO - ðŸªœ Batch step - 1836 -- sub batch step 7346 -- lr 2.75e-04
2025-03-02 14:50:26,106 - INFO - ðŸªœ Batch step - 1836 -- sub batch step 7347 -- lr 2.75e-04
2025-03-02 14:50:27,654 - INFO - Step 1836 -- ðŸ”„ Training Metrics
2025-03-02 14:50:27,654 - INFO - â”œâ”€â”€ Loss: 7.1773
2025-03-02 14:50:27,654 - INFO - â”œâ”€â”€ Learning Rate: 2.75e-04
2025-03-02 14:50:27,654 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:50:28,323 - INFO - ðŸªœ Batch step - 1837 -- sub batch step 7348 -- lr 2.76e-04
2025-03-02 14:50:30,479 - INFO - ðŸªœ Batch step - 1837 -- sub batch step 7349 -- lr 2.76e-04
2025-03-02 14:50:33,192 - INFO - ðŸªœ Batch step - 1837 -- sub batch step 7350 -- lr 2.76e-04
2025-03-02 14:50:35,339 - INFO - ðŸªœ Batch step - 1837 -- sub batch step 7351 -- lr 2.76e-04
2025-03-02 14:50:36,935 - INFO - Step 1837 -- ðŸ”„ Training Metrics
2025-03-02 14:50:36,935 - INFO - â”œâ”€â”€ Loss: 7.1891
2025-03-02 14:50:36,935 - INFO - â”œâ”€â”€ Learning Rate: 2.76e-04
2025-03-02 14:50:36,935 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:50:37,608 - INFO - ðŸªœ Batch step - 1838 -- sub batch step 7352 -- lr 2.76e-04
2025-03-02 14:50:39,760 - INFO - ðŸªœ Batch step - 1838 -- sub batch step 7353 -- lr 2.76e-04
2025-03-02 14:50:41,930 - INFO - ðŸªœ Batch step - 1838 -- sub batch step 7354 -- lr 2.76e-04
2025-03-02 14:50:44,083 - INFO - ðŸªœ Batch step - 1838 -- sub batch step 7355 -- lr 2.76e-04
2025-03-02 14:50:45,644 - INFO - Step 1838 -- ðŸ”„ Training Metrics
2025-03-02 14:50:45,645 - INFO - â”œâ”€â”€ Loss: 7.1646
2025-03-02 14:50:45,645 - INFO - â”œâ”€â”€ Learning Rate: 2.76e-04
2025-03-02 14:50:45,645 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:50:46,316 - INFO - ðŸªœ Batch step - 1839 -- sub batch step 7356 -- lr 2.76e-04
2025-03-02 14:50:48,471 - INFO - ðŸªœ Batch step - 1839 -- sub batch step 7357 -- lr 2.76e-04
2025-03-02 14:50:50,749 - INFO - ðŸªœ Batch step - 1839 -- sub batch step 7358 -- lr 2.76e-04
2025-03-02 14:50:52,908 - INFO - ðŸªœ Batch step - 1839 -- sub batch step 7359 -- lr 2.76e-04
2025-03-02 14:50:54,517 - INFO - Step 1839 -- ðŸ”„ Training Metrics
2025-03-02 14:50:54,518 - INFO - â”œâ”€â”€ Loss: 7.1579
2025-03-02 14:50:54,518 - INFO - â”œâ”€â”€ Learning Rate: 2.76e-04
2025-03-02 14:50:54,518 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:50:55,653 - INFO - ðŸªœ Batch step - 1840 -- sub batch step 7360 -- lr 2.76e-04
2025-03-02 14:50:57,808 - INFO - ðŸªœ Batch step - 1840 -- sub batch step 7361 -- lr 2.76e-04
2025-03-02 14:50:59,966 - INFO - ðŸªœ Batch step - 1840 -- sub batch step 7362 -- lr 2.76e-04
2025-03-02 14:51:02,142 - INFO - ðŸªœ Batch step - 1840 -- sub batch step 7363 -- lr 2.76e-04
2025-03-02 14:51:03,775 - INFO - Step 1840 -- ðŸ”„ Training Metrics
2025-03-02 14:51:03,775 - INFO - â”œâ”€â”€ Loss: 7.1404
2025-03-02 14:51:03,775 - INFO - â”œâ”€â”€ Learning Rate: 2.76e-04
2025-03-02 14:51:03,775 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:51:04,457 - INFO - ðŸªœ Batch step - 1841 -- sub batch step 7364 -- lr 2.76e-04
2025-03-02 14:51:06,614 - INFO - ðŸªœ Batch step - 1841 -- sub batch step 7365 -- lr 2.76e-04
2025-03-02 14:51:08,768 - INFO - ðŸªœ Batch step - 1841 -- sub batch step 7366 -- lr 2.76e-04
2025-03-02 14:51:11,388 - INFO - ðŸªœ Batch step - 1841 -- sub batch step 7367 -- lr 2.76e-04
2025-03-02 14:51:12,890 - INFO - Step 1841 -- ðŸ”„ Training Metrics
2025-03-02 14:51:12,890 - INFO - â”œâ”€â”€ Loss: 7.1549
2025-03-02 14:51:12,891 - INFO - â”œâ”€â”€ Learning Rate: 2.76e-04
2025-03-02 14:51:12,891 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:51:13,558 - INFO - ðŸªœ Batch step - 1842 -- sub batch step 7368 -- lr 2.76e-04
2025-03-02 14:51:15,716 - INFO - ðŸªœ Batch step - 1842 -- sub batch step 7369 -- lr 2.76e-04
2025-03-02 14:51:17,871 - INFO - ðŸªœ Batch step - 1842 -- sub batch step 7370 -- lr 2.76e-04
2025-03-02 14:51:20,039 - INFO - ðŸªœ Batch step - 1842 -- sub batch step 7371 -- lr 2.76e-04
2025-03-02 14:51:21,593 - INFO - Step 1842 -- ðŸ”„ Training Metrics
2025-03-02 14:51:21,593 - INFO - â”œâ”€â”€ Loss: 7.1339
2025-03-02 14:51:21,593 - INFO - â”œâ”€â”€ Learning Rate: 2.76e-04
2025-03-02 14:51:21,593 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:51:22,272 - INFO - ðŸªœ Batch step - 1843 -- sub batch step 7372 -- lr 2.76e-04
2025-03-02 14:51:24,422 - INFO - ðŸªœ Batch step - 1843 -- sub batch step 7373 -- lr 2.76e-04
2025-03-02 14:51:26,577 - INFO - ðŸªœ Batch step - 1843 -- sub batch step 7374 -- lr 2.76e-04
2025-03-02 14:51:29,273 - INFO - ðŸªœ Batch step - 1843 -- sub batch step 7375 -- lr 2.76e-04
2025-03-02 14:51:30,831 - INFO - Step 1843 -- ðŸ”„ Training Metrics
2025-03-02 14:51:30,832 - INFO - â”œâ”€â”€ Loss: 7.1719
2025-03-02 14:51:30,832 - INFO - â”œâ”€â”€ Learning Rate: 2.76e-04
2025-03-02 14:51:30,832 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:51:31,503 - INFO - ðŸªœ Batch step - 1844 -- sub batch step 7376 -- lr 2.77e-04
2025-03-02 14:51:33,659 - INFO - ðŸªœ Batch step - 1844 -- sub batch step 7377 -- lr 2.77e-04
2025-03-02 14:51:35,804 - INFO - ðŸªœ Batch step - 1844 -- sub batch step 7378 -- lr 2.77e-04
2025-03-02 14:51:37,981 - INFO - ðŸªœ Batch step - 1844 -- sub batch step 7379 -- lr 2.77e-04
2025-03-02 14:51:39,528 - INFO - Step 1844 -- ðŸ”„ Training Metrics
2025-03-02 14:51:39,528 - INFO - â”œâ”€â”€ Loss: 7.1746
2025-03-02 14:51:39,529 - INFO - â”œâ”€â”€ Learning Rate: 2.77e-04
2025-03-02 14:51:39,529 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:51:40,206 - INFO - ðŸªœ Batch step - 1845 -- sub batch step 7380 -- lr 2.77e-04
2025-03-02 14:51:42,359 - INFO - ðŸªœ Batch step - 1845 -- sub batch step 7381 -- lr 2.77e-04
2025-03-02 14:51:44,512 - INFO - ðŸªœ Batch step - 1845 -- sub batch step 7382 -- lr 2.77e-04
2025-03-02 14:51:46,949 - INFO - ðŸªœ Batch step - 1845 -- sub batch step 7383 -- lr 2.77e-04
2025-03-02 14:51:48,671 - INFO - Step 1845 -- ðŸ”„ Training Metrics
2025-03-02 14:51:48,671 - INFO - â”œâ”€â”€ Loss: 7.1584
2025-03-02 14:51:48,672 - INFO - â”œâ”€â”€ Learning Rate: 2.77e-04
2025-03-02 14:51:48,672 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:51:49,346 - INFO - ðŸªœ Batch step - 1846 -- sub batch step 7384 -- lr 2.77e-04
2025-03-02 14:51:51,500 - INFO - ðŸªœ Batch step - 1846 -- sub batch step 7385 -- lr 2.77e-04
2025-03-02 14:51:53,646 - INFO - ðŸªœ Batch step - 1846 -- sub batch step 7386 -- lr 2.77e-04
2025-03-02 14:51:55,814 - INFO - ðŸªœ Batch step - 1846 -- sub batch step 7387 -- lr 2.77e-04
2025-03-02 14:51:57,375 - INFO - Step 1846 -- ðŸ”„ Training Metrics
2025-03-02 14:51:57,375 - INFO - â”œâ”€â”€ Loss: 7.1632
2025-03-02 14:51:57,375 - INFO - â”œâ”€â”€ Learning Rate: 2.77e-04
2025-03-02 14:51:57,375 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:51:58,043 - INFO - ðŸªœ Batch step - 1847 -- sub batch step 7388 -- lr 2.77e-04
2025-03-02 14:52:00,201 - INFO - ðŸªœ Batch step - 1847 -- sub batch step 7389 -- lr 2.77e-04
2025-03-02 14:52:02,356 - INFO - ðŸªœ Batch step - 1847 -- sub batch step 7390 -- lr 2.77e-04
2025-03-02 14:52:04,716 - INFO - ðŸªœ Batch step - 1847 -- sub batch step 7391 -- lr 2.77e-04
2025-03-02 14:52:06,628 - INFO - Step 1847 -- ðŸ”„ Training Metrics
2025-03-02 14:52:06,628 - INFO - â”œâ”€â”€ Loss: 7.1579
2025-03-02 14:52:06,628 - INFO - â”œâ”€â”€ Learning Rate: 2.77e-04
2025-03-02 14:52:06,628 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:52:07,306 - INFO - ðŸªœ Batch step - 1848 -- sub batch step 7392 -- lr 2.77e-04
2025-03-02 14:52:09,459 - INFO - ðŸªœ Batch step - 1848 -- sub batch step 7393 -- lr 2.77e-04
2025-03-02 14:52:11,617 - INFO - ðŸªœ Batch step - 1848 -- sub batch step 7394 -- lr 2.77e-04
2025-03-02 14:52:13,790 - INFO - ðŸªœ Batch step - 1848 -- sub batch step 7395 -- lr 2.77e-04
2025-03-02 14:52:15,336 - INFO - Step 1848 -- ðŸ”„ Training Metrics
2025-03-02 14:52:15,336 - INFO - â”œâ”€â”€ Loss: 7.1261
2025-03-02 14:52:15,336 - INFO - â”œâ”€â”€ Learning Rate: 2.77e-04
2025-03-02 14:52:15,336 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:52:16,007 - INFO - ðŸªœ Batch step - 1849 -- sub batch step 7396 -- lr 2.77e-04
2025-03-02 14:52:18,165 - INFO - ðŸªœ Batch step - 1849 -- sub batch step 7397 -- lr 2.77e-04
2025-03-02 14:52:20,314 - INFO - ðŸªœ Batch step - 1849 -- sub batch step 7398 -- lr 2.77e-04
2025-03-02 14:52:22,672 - INFO - ðŸªœ Batch step - 1849 -- sub batch step 7399 -- lr 2.77e-04
2025-03-02 14:52:24,455 - INFO - Step 1849 -- ðŸ”„ Training Metrics
2025-03-02 14:52:24,455 - INFO - â”œâ”€â”€ Loss: 7.1587
2025-03-02 14:52:24,455 - INFO - â”œâ”€â”€ Learning Rate: 2.77e-04
2025-03-02 14:52:24,455 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:52:25,130 - INFO - ðŸªœ Batch step - 1850 -- sub batch step 7400 -- lr 2.77e-04
2025-03-02 14:52:27,282 - INFO - ðŸªœ Batch step - 1850 -- sub batch step 7401 -- lr 2.77e-04
2025-03-02 14:52:29,437 - INFO - ðŸªœ Batch step - 1850 -- sub batch step 7402 -- lr 2.77e-04
2025-03-02 14:52:31,599 - INFO - ðŸªœ Batch step - 1850 -- sub batch step 7403 -- lr 2.77e-04
2025-03-02 14:52:33,144 - INFO - Step 1850 -- ðŸ”„ Training Metrics
2025-03-02 14:52:33,144 - INFO - â”œâ”€â”€ Loss: 7.1554
2025-03-02 14:52:33,144 - INFO - â”œâ”€â”€ Learning Rate: 2.77e-04
2025-03-02 14:52:33,144 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:52:33,817 - INFO - ðŸªœ Batch step - 1851 -- sub batch step 7404 -- lr 2.78e-04
2025-03-02 14:52:35,970 - INFO - ðŸªœ Batch step - 1851 -- sub batch step 7405 -- lr 2.78e-04
2025-03-02 14:52:38,650 - INFO - ðŸªœ Batch step - 1851 -- sub batch step 7406 -- lr 2.78e-04
2025-03-02 14:52:40,806 - INFO - ðŸªœ Batch step - 1851 -- sub batch step 7407 -- lr 2.78e-04
2025-03-02 14:52:42,387 - INFO - Step 1851 -- ðŸ”„ Training Metrics
2025-03-02 14:52:42,387 - INFO - â”œâ”€â”€ Loss: 7.1853
2025-03-02 14:52:42,388 - INFO - â”œâ”€â”€ Learning Rate: 2.78e-04
2025-03-02 14:52:42,388 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:52:43,055 - INFO - ðŸªœ Batch step - 1852 -- sub batch step 7408 -- lr 2.78e-04
2025-03-02 14:52:45,214 - INFO - ðŸªœ Batch step - 1852 -- sub batch step 7409 -- lr 2.78e-04
2025-03-02 14:52:47,390 - INFO - ðŸªœ Batch step - 1852 -- sub batch step 7410 -- lr 2.78e-04
2025-03-02 14:52:49,538 - INFO - ðŸªœ Batch step - 1852 -- sub batch step 7411 -- lr 2.78e-04
2025-03-02 14:52:51,087 - INFO - Step 1852 -- ðŸ”„ Training Metrics
2025-03-02 14:52:51,088 - INFO - â”œâ”€â”€ Loss: 7.1431
2025-03-02 14:52:51,088 - INFO - â”œâ”€â”€ Learning Rate: 2.78e-04
2025-03-02 14:52:51,088 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:52:51,764 - INFO - ðŸªœ Batch step - 1853 -- sub batch step 7412 -- lr 2.78e-04
2025-03-02 14:52:53,913 - INFO - ðŸªœ Batch step - 1853 -- sub batch step 7413 -- lr 2.78e-04
2025-03-02 14:52:56,287 - INFO - ðŸªœ Batch step - 1853 -- sub batch step 7414 -- lr 2.78e-04
2025-03-02 14:52:58,445 - INFO - ðŸªœ Batch step - 1853 -- sub batch step 7415 -- lr 2.78e-04
2025-03-02 14:53:00,365 - INFO - Step 1853 -- ðŸ”„ Training Metrics
2025-03-02 14:53:00,365 - INFO - â”œâ”€â”€ Loss: 7.1401
2025-03-02 14:53:00,365 - INFO - â”œâ”€â”€ Learning Rate: 2.78e-04
2025-03-02 14:53:00,366 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:53:01,036 - INFO - ðŸªœ Batch step - 1854 -- sub batch step 7416 -- lr 2.78e-04
2025-03-02 14:53:03,189 - INFO - ðŸªœ Batch step - 1854 -- sub batch step 7417 -- lr 2.78e-04
2025-03-02 14:53:05,354 - INFO - ðŸªœ Batch step - 1854 -- sub batch step 7418 -- lr 2.78e-04
2025-03-02 14:53:07,508 - INFO - ðŸªœ Batch step - 1854 -- sub batch step 7419 -- lr 2.78e-04
2025-03-02 14:53:09,063 - INFO - Step 1854 -- ðŸ”„ Training Metrics
2025-03-02 14:53:09,063 - INFO - â”œâ”€â”€ Loss: 7.1611
2025-03-02 14:53:09,064 - INFO - â”œâ”€â”€ Learning Rate: 2.78e-04
2025-03-02 14:53:09,064 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:53:09,737 - INFO - ðŸªœ Batch step - 1855 -- sub batch step 7420 -- lr 2.78e-04
2025-03-02 14:53:11,890 - INFO - ðŸªœ Batch step - 1855 -- sub batch step 7421 -- lr 2.78e-04
2025-03-02 14:53:14,302 - INFO - ðŸªœ Batch step - 1855 -- sub batch step 7422 -- lr 2.78e-04
2025-03-02 14:53:16,456 - INFO - ðŸªœ Batch step - 1855 -- sub batch step 7423 -- lr 2.78e-04
2025-03-02 14:53:18,468 - INFO - Step 1855 -- ðŸ”„ Training Metrics
2025-03-02 14:53:18,468 - INFO - â”œâ”€â”€ Loss: 7.1707
2025-03-02 14:53:18,468 - INFO - â”œâ”€â”€ Learning Rate: 2.78e-04
2025-03-02 14:53:18,468 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:53:19,142 - INFO - ðŸªœ Batch step - 1856 -- sub batch step 7424 -- lr 2.78e-04
2025-03-02 14:53:21,297 - INFO - ðŸªœ Batch step - 1856 -- sub batch step 7425 -- lr 2.78e-04
2025-03-02 14:53:23,460 - INFO - ðŸªœ Batch step - 1856 -- sub batch step 7426 -- lr 2.78e-04
2025-03-02 14:53:25,613 - INFO - ðŸªœ Batch step - 1856 -- sub batch step 7427 -- lr 2.78e-04
2025-03-02 14:53:27,165 - INFO - Step 1856 -- ðŸ”„ Training Metrics
2025-03-02 14:53:27,166 - INFO - â”œâ”€â”€ Loss: 7.1536
2025-03-02 14:53:27,166 - INFO - â”œâ”€â”€ Learning Rate: 2.78e-04
2025-03-02 14:53:27,166 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:53:27,833 - INFO - ðŸªœ Batch step - 1857 -- sub batch step 7428 -- lr 2.79e-04
2025-03-02 14:53:29,989 - INFO - ðŸªœ Batch step - 1857 -- sub batch step 7429 -- lr 2.79e-04
2025-03-02 14:53:32,687 - INFO - ðŸªœ Batch step - 1857 -- sub batch step 7430 -- lr 2.79e-04
2025-03-02 14:53:34,838 - INFO - ðŸªœ Batch step - 1857 -- sub batch step 7431 -- lr 2.79e-04
2025-03-02 14:53:36,386 - INFO - Step 1857 -- ðŸ”„ Training Metrics
2025-03-02 14:53:36,386 - INFO - â”œâ”€â”€ Loss: 7.1466
2025-03-02 14:53:36,386 - INFO - â”œâ”€â”€ Learning Rate: 2.79e-04
2025-03-02 14:53:36,386 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:53:37,062 - INFO - ðŸªœ Batch step - 1858 -- sub batch step 7432 -- lr 2.79e-04
2025-03-02 14:53:39,214 - INFO - ðŸªœ Batch step - 1858 -- sub batch step 7433 -- lr 2.79e-04
2025-03-02 14:53:41,388 - INFO - ðŸªœ Batch step - 1858 -- sub batch step 7434 -- lr 2.79e-04
2025-03-02 14:53:43,541 - INFO - ðŸªœ Batch step - 1858 -- sub batch step 7435 -- lr 2.79e-04
2025-03-02 14:53:45,093 - INFO - Step 1858 -- ðŸ”„ Training Metrics
2025-03-02 14:53:45,094 - INFO - â”œâ”€â”€ Loss: 7.1584
2025-03-02 14:53:45,094 - INFO - â”œâ”€â”€ Learning Rate: 2.79e-04
2025-03-02 14:53:45,094 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:53:45,763 - INFO - ðŸªœ Batch step - 1859 -- sub batch step 7436 -- lr 2.79e-04
2025-03-02 14:53:47,917 - INFO - ðŸªœ Batch step - 1859 -- sub batch step 7437 -- lr 2.79e-04
2025-03-02 14:53:50,191 - INFO - ðŸªœ Batch step - 1859 -- sub batch step 7438 -- lr 2.79e-04
2025-03-02 14:53:52,350 - INFO - ðŸªœ Batch step - 1859 -- sub batch step 7439 -- lr 2.79e-04
2025-03-02 14:53:53,980 - INFO - Step 1859 -- ðŸ”„ Training Metrics
2025-03-02 14:53:53,980 - INFO - â”œâ”€â”€ Loss: 7.1489
2025-03-02 14:53:53,980 - INFO - â”œâ”€â”€ Learning Rate: 2.79e-04
2025-03-02 14:53:53,980 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:53:55,474 - INFO - ðŸªœ Batch step - 1860 -- sub batch step 7440 -- lr 2.79e-04
2025-03-02 14:53:57,627 - INFO - ðŸªœ Batch step - 1860 -- sub batch step 7441 -- lr 2.79e-04
2025-03-02 14:53:59,785 - INFO - ðŸªœ Batch step - 1860 -- sub batch step 7442 -- lr 2.79e-04
2025-03-02 14:54:01,957 - INFO - ðŸªœ Batch step - 1860 -- sub batch step 7443 -- lr 2.79e-04
2025-03-02 14:54:03,473 - INFO - Step 1860 -- ðŸ”„ Training Metrics
2025-03-02 14:54:03,473 - INFO - â”œâ”€â”€ Loss: 7.1674
2025-03-02 14:54:03,474 - INFO - â”œâ”€â”€ Learning Rate: 2.79e-04
2025-03-02 14:54:03,474 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:54:04,149 - INFO - ðŸªœ Batch step - 1861 -- sub batch step 7444 -- lr 2.79e-04
2025-03-02 14:54:06,313 - INFO - ðŸªœ Batch step - 1861 -- sub batch step 7445 -- lr 2.79e-04
2025-03-02 14:54:08,462 - INFO - ðŸªœ Batch step - 1861 -- sub batch step 7446 -- lr 2.79e-04
2025-03-02 14:54:11,271 - INFO - ðŸªœ Batch step - 1861 -- sub batch step 7447 -- lr 2.79e-04
2025-03-02 14:54:12,762 - INFO - Step 1861 -- ðŸ”„ Training Metrics
2025-03-02 14:54:12,762 - INFO - â”œâ”€â”€ Loss: 7.1737
2025-03-02 14:54:12,762 - INFO - â”œâ”€â”€ Learning Rate: 2.79e-04
2025-03-02 14:54:12,762 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:54:13,440 - INFO - ðŸªœ Batch step - 1862 -- sub batch step 7448 -- lr 2.79e-04
2025-03-02 14:54:15,600 - INFO - ðŸªœ Batch step - 1862 -- sub batch step 7449 -- lr 2.79e-04
2025-03-02 14:54:17,759 - INFO - ðŸªœ Batch step - 1862 -- sub batch step 7450 -- lr 2.79e-04
2025-03-02 14:54:19,926 - INFO - ðŸªœ Batch step - 1862 -- sub batch step 7451 -- lr 2.79e-04
2025-03-02 14:54:21,451 - INFO - Step 1862 -- ðŸ”„ Training Metrics
2025-03-02 14:54:21,451 - INFO - â”œâ”€â”€ Loss: 7.1606
2025-03-02 14:54:21,451 - INFO - â”œâ”€â”€ Learning Rate: 2.79e-04
2025-03-02 14:54:21,451 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:54:22,128 - INFO - ðŸªœ Batch step - 1863 -- sub batch step 7452 -- lr 2.79e-04
2025-03-02 14:54:24,277 - INFO - ðŸªœ Batch step - 1863 -- sub batch step 7453 -- lr 2.79e-04
2025-03-02 14:54:26,430 - INFO - ðŸªœ Batch step - 1863 -- sub batch step 7454 -- lr 2.79e-04
2025-03-02 14:54:29,075 - INFO - ðŸªœ Batch step - 1863 -- sub batch step 7455 -- lr 2.79e-04
2025-03-02 14:54:31,136 - INFO - Step 1863 -- ðŸ”„ Training Metrics
2025-03-02 14:54:31,136 - INFO - â”œâ”€â”€ Loss: 7.1614
2025-03-02 14:54:31,136 - INFO - â”œâ”€â”€ Learning Rate: 2.79e-04
2025-03-02 14:54:31,136 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:54:31,806 - INFO - ðŸªœ Batch step - 1864 -- sub batch step 7456 -- lr 2.80e-04
2025-03-02 14:54:33,962 - INFO - ðŸªœ Batch step - 1864 -- sub batch step 7457 -- lr 2.80e-04
2025-03-02 14:54:36,107 - INFO - ðŸªœ Batch step - 1864 -- sub batch step 7458 -- lr 2.80e-04
2025-03-02 14:54:38,281 - INFO - ðŸªœ Batch step - 1864 -- sub batch step 7459 -- lr 2.80e-04
2025-03-02 14:54:39,880 - INFO - Step 1864 -- ðŸ”„ Training Metrics
2025-03-02 14:54:39,880 - INFO - â”œâ”€â”€ Loss: 7.1510
2025-03-02 14:54:39,880 - INFO - â”œâ”€â”€ Learning Rate: 2.80e-04
2025-03-02 14:54:39,880 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:54:40,558 - INFO - ðŸªœ Batch step - 1865 -- sub batch step 7460 -- lr 2.80e-04
2025-03-02 14:54:42,710 - INFO - ðŸªœ Batch step - 1865 -- sub batch step 7461 -- lr 2.80e-04
2025-03-02 14:54:44,861 - INFO - ðŸªœ Batch step - 1865 -- sub batch step 7462 -- lr 2.80e-04
2025-03-02 14:54:47,296 - INFO - ðŸªœ Batch step - 1865 -- sub batch step 7463 -- lr 2.80e-04
2025-03-02 14:54:49,223 - INFO - Step 1865 -- ðŸ”„ Training Metrics
2025-03-02 14:54:49,223 - INFO - â”œâ”€â”€ Loss: 7.1435
2025-03-02 14:54:49,223 - INFO - â”œâ”€â”€ Learning Rate: 2.80e-04
2025-03-02 14:54:49,223 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:54:49,896 - INFO - ðŸªœ Batch step - 1866 -- sub batch step 7464 -- lr 2.80e-04
2025-03-02 14:54:52,047 - INFO - ðŸªœ Batch step - 1866 -- sub batch step 7465 -- lr 2.80e-04
2025-03-02 14:54:54,193 - INFO - ðŸªœ Batch step - 1866 -- sub batch step 7466 -- lr 2.80e-04
2025-03-02 14:54:56,386 - INFO - ðŸªœ Batch step - 1866 -- sub batch step 7467 -- lr 2.80e-04
2025-03-02 14:54:57,932 - INFO - Step 1866 -- ðŸ”„ Training Metrics
2025-03-02 14:54:57,933 - INFO - â”œâ”€â”€ Loss: 7.1159
2025-03-02 14:54:57,933 - INFO - â”œâ”€â”€ Learning Rate: 2.80e-04
2025-03-02 14:54:57,933 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:54:58,600 - INFO - ðŸªœ Batch step - 1867 -- sub batch step 7468 -- lr 2.80e-04
2025-03-02 14:55:00,758 - INFO - ðŸªœ Batch step - 1867 -- sub batch step 7469 -- lr 2.80e-04
2025-03-02 14:55:02,911 - INFO - ðŸªœ Batch step - 1867 -- sub batch step 7470 -- lr 2.80e-04
2025-03-02 14:55:05,571 - INFO - ðŸªœ Batch step - 1867 -- sub batch step 7471 -- lr 2.80e-04
2025-03-02 14:55:07,272 - INFO - Step 1867 -- ðŸ”„ Training Metrics
2025-03-02 14:55:07,272 - INFO - â”œâ”€â”€ Loss: 7.1578
2025-03-02 14:55:07,272 - INFO - â”œâ”€â”€ Learning Rate: 2.80e-04
2025-03-02 14:55:07,272 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:55:07,943 - INFO - ðŸªœ Batch step - 1868 -- sub batch step 7472 -- lr 2.80e-04
2025-03-02 14:55:10,094 - INFO - ðŸªœ Batch step - 1868 -- sub batch step 7473 -- lr 2.80e-04
2025-03-02 14:55:12,248 - INFO - ðŸªœ Batch step - 1868 -- sub batch step 7474 -- lr 2.80e-04
2025-03-02 14:55:14,421 - INFO - ðŸªœ Batch step - 1868 -- sub batch step 7475 -- lr 2.80e-04
2025-03-02 14:55:15,983 - INFO - Step 1868 -- ðŸ”„ Training Metrics
2025-03-02 14:55:15,983 - INFO - â”œâ”€â”€ Loss: 7.1667
2025-03-02 14:55:15,983 - INFO - â”œâ”€â”€ Learning Rate: 2.80e-04
2025-03-02 14:55:15,983 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:55:16,651 - INFO - ðŸªœ Batch step - 1869 -- sub batch step 7476 -- lr 2.80e-04
2025-03-02 14:55:18,805 - INFO - ðŸªœ Batch step - 1869 -- sub batch step 7477 -- lr 2.80e-04
2025-03-02 14:55:20,950 - INFO - ðŸªœ Batch step - 1869 -- sub batch step 7478 -- lr 2.80e-04
2025-03-02 14:55:23,697 - INFO - ðŸªœ Batch step - 1869 -- sub batch step 7479 -- lr 2.80e-04
2025-03-02 14:55:25,183 - INFO - Step 1869 -- ðŸ”„ Training Metrics
2025-03-02 14:55:25,183 - INFO - â”œâ”€â”€ Loss: 7.1446
2025-03-02 14:55:25,184 - INFO - â”œâ”€â”€ Learning Rate: 2.80e-04
2025-03-02 14:55:25,184 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:55:25,855 - INFO - ðŸªœ Batch step - 1870 -- sub batch step 7480 -- lr 2.80e-04
2025-03-02 14:55:28,007 - INFO - ðŸªœ Batch step - 1870 -- sub batch step 7481 -- lr 2.80e-04
2025-03-02 14:55:30,159 - INFO - ðŸªœ Batch step - 1870 -- sub batch step 7482 -- lr 2.80e-04
2025-03-02 14:55:32,322 - INFO - ðŸªœ Batch step - 1870 -- sub batch step 7483 -- lr 2.80e-04
2025-03-02 14:55:33,879 - INFO - Step 1870 -- ðŸ”„ Training Metrics
2025-03-02 14:55:33,879 - INFO - â”œâ”€â”€ Loss: 7.1539
2025-03-02 14:55:33,879 - INFO - â”œâ”€â”€ Learning Rate: 2.80e-04
2025-03-02 14:55:33,879 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:55:34,550 - INFO - ðŸªœ Batch step - 1871 -- sub batch step 7484 -- lr 2.81e-04
2025-03-02 14:55:36,700 - INFO - ðŸªœ Batch step - 1871 -- sub batch step 7485 -- lr 2.81e-04
2025-03-02 14:55:39,329 - INFO - ðŸªœ Batch step - 1871 -- sub batch step 7486 -- lr 2.81e-04
2025-03-02 14:55:41,483 - INFO - ðŸªœ Batch step - 1871 -- sub batch step 7487 -- lr 2.81e-04
2025-03-02 14:55:43,055 - INFO - Step 1871 -- ðŸ”„ Training Metrics
2025-03-02 14:55:43,055 - INFO - â”œâ”€â”€ Loss: 7.1339
2025-03-02 14:55:43,055 - INFO - â”œâ”€â”€ Learning Rate: 2.81e-04
2025-03-02 14:55:43,055 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:55:43,720 - INFO - ðŸªœ Batch step - 1872 -- sub batch step 7488 -- lr 2.81e-04
2025-03-02 14:55:45,873 - INFO - ðŸªœ Batch step - 1872 -- sub batch step 7489 -- lr 2.81e-04
2025-03-02 14:55:48,041 - INFO - ðŸªœ Batch step - 1872 -- sub batch step 7490 -- lr 2.81e-04
2025-03-02 14:55:50,191 - INFO - ðŸªœ Batch step - 1872 -- sub batch step 7491 -- lr 2.81e-04
2025-03-02 14:55:51,762 - INFO - Step 1872 -- ðŸ”„ Training Metrics
2025-03-02 14:55:51,762 - INFO - â”œâ”€â”€ Loss: 7.1735
2025-03-02 14:55:51,762 - INFO - â”œâ”€â”€ Learning Rate: 2.81e-04
2025-03-02 14:55:51,762 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:55:52,435 - INFO - ðŸªœ Batch step - 1873 -- sub batch step 7492 -- lr 2.81e-04
2025-03-02 14:55:54,587 - INFO - ðŸªœ Batch step - 1873 -- sub batch step 7493 -- lr 2.81e-04
2025-03-02 14:55:57,111 - INFO - ðŸªœ Batch step - 1873 -- sub batch step 7494 -- lr 2.81e-04
2025-03-02 14:55:59,268 - INFO - ðŸªœ Batch step - 1873 -- sub batch step 7495 -- lr 2.81e-04
2025-03-02 14:56:01,220 - INFO - Step 1873 -- ðŸ”„ Training Metrics
2025-03-02 14:56:01,220 - INFO - â”œâ”€â”€ Loss: 7.1377
2025-03-02 14:56:01,220 - INFO - â”œâ”€â”€ Learning Rate: 2.81e-04
2025-03-02 14:56:01,221 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:56:01,890 - INFO - ðŸªœ Batch step - 1874 -- sub batch step 7496 -- lr 2.81e-04
2025-03-02 14:56:04,045 - INFO - ðŸªœ Batch step - 1874 -- sub batch step 7497 -- lr 2.81e-04
2025-03-02 14:56:06,213 - INFO - ðŸªœ Batch step - 1874 -- sub batch step 7498 -- lr 2.81e-04
2025-03-02 14:56:08,366 - INFO - ðŸªœ Batch step - 1874 -- sub batch step 7499 -- lr 2.81e-04
2025-03-02 14:56:09,923 - INFO - Step 1874 -- ðŸ”„ Training Metrics
2025-03-02 14:56:09,923 - INFO - â”œâ”€â”€ Loss: 7.1833
2025-03-02 14:56:09,923 - INFO - â”œâ”€â”€ Learning Rate: 2.81e-04
2025-03-02 14:56:09,924 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:56:10,600 - INFO - ðŸªœ Batch step - 1875 -- sub batch step 7500 -- lr 2.81e-04
2025-03-02 14:56:12,746 - INFO - ðŸªœ Batch step - 1875 -- sub batch step 7501 -- lr 2.81e-04
2025-03-02 14:56:15,374 - INFO - ðŸªœ Batch step - 1875 -- sub batch step 7502 -- lr 2.81e-04
2025-03-02 14:56:17,525 - INFO - ðŸªœ Batch step - 1875 -- sub batch step 7503 -- lr 2.81e-04
2025-03-02 14:56:19,196 - INFO - Step 1875 -- ðŸ”„ Training Metrics
2025-03-02 14:56:19,196 - INFO - â”œâ”€â”€ Loss: 7.1503
2025-03-02 14:56:19,196 - INFO - â”œâ”€â”€ Learning Rate: 2.81e-04
2025-03-02 14:56:19,196 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:56:19,870 - INFO - ðŸªœ Batch step - 1876 -- sub batch step 7504 -- lr 2.81e-04
2025-03-02 14:56:22,024 - INFO - ðŸªœ Batch step - 1876 -- sub batch step 7505 -- lr 2.81e-04
2025-03-02 14:56:24,186 - INFO - ðŸªœ Batch step - 1876 -- sub batch step 7506 -- lr 2.81e-04
2025-03-02 14:56:26,340 - INFO - ðŸªœ Batch step - 1876 -- sub batch step 7507 -- lr 2.81e-04
2025-03-02 14:56:27,905 - INFO - Step 1876 -- ðŸ”„ Training Metrics
2025-03-02 14:56:27,906 - INFO - â”œâ”€â”€ Loss: 7.1530
2025-03-02 14:56:27,906 - INFO - â”œâ”€â”€ Learning Rate: 2.81e-04
2025-03-02 14:56:27,906 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:56:28,573 - INFO - ðŸªœ Batch step - 1877 -- sub batch step 7508 -- lr 2.82e-04
2025-03-02 14:56:30,731 - INFO - ðŸªœ Batch step - 1877 -- sub batch step 7509 -- lr 2.82e-04
2025-03-02 14:56:33,354 - INFO - ðŸªœ Batch step - 1877 -- sub batch step 7510 -- lr 2.82e-04
2025-03-02 14:56:35,503 - INFO - ðŸªœ Batch step - 1877 -- sub batch step 7511 -- lr 2.82e-04
2025-03-02 14:56:37,160 - INFO - Step 1877 -- ðŸ”„ Training Metrics
2025-03-02 14:56:37,160 - INFO - â”œâ”€â”€ Loss: 7.1304
2025-03-02 14:56:37,160 - INFO - â”œâ”€â”€ Learning Rate: 2.82e-04
2025-03-02 14:56:37,161 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:56:37,834 - INFO - ðŸªœ Batch step - 1878 -- sub batch step 7512 -- lr 2.82e-04
2025-03-02 14:56:39,986 - INFO - ðŸªœ Batch step - 1878 -- sub batch step 7513 -- lr 2.82e-04
2025-03-02 14:56:42,161 - INFO - ðŸªœ Batch step - 1878 -- sub batch step 7514 -- lr 2.82e-04
2025-03-02 14:56:44,316 - INFO - ðŸªœ Batch step - 1878 -- sub batch step 7515 -- lr 2.82e-04
2025-03-02 14:56:45,869 - INFO - Step 1878 -- ðŸ”„ Training Metrics
2025-03-02 14:56:45,870 - INFO - â”œâ”€â”€ Loss: 7.1517
2025-03-02 14:56:45,870 - INFO - â”œâ”€â”€ Learning Rate: 2.82e-04
2025-03-02 14:56:45,870 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:56:46,535 - INFO - ðŸªœ Batch step - 1879 -- sub batch step 7516 -- lr 2.82e-04
2025-03-02 14:56:48,693 - INFO - ðŸªœ Batch step - 1879 -- sub batch step 7517 -- lr 2.82e-04
2025-03-02 14:56:50,973 - INFO - ðŸªœ Batch step - 1879 -- sub batch step 7518 -- lr 2.82e-04
2025-03-02 14:56:53,128 - INFO - ðŸªœ Batch step - 1879 -- sub batch step 7519 -- lr 2.82e-04
2025-03-02 14:56:54,680 - INFO - Step 1879 -- ðŸ”„ Training Metrics
2025-03-02 14:56:54,681 - INFO - â”œâ”€â”€ Loss: 7.1281
2025-03-02 14:56:54,681 - INFO - â”œâ”€â”€ Learning Rate: 2.82e-04
2025-03-02 14:56:54,681 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:56:55,988 - INFO - ðŸªœ Batch step - 1880 -- sub batch step 7520 -- lr 2.82e-04
2025-03-02 14:56:58,142 - INFO - ðŸªœ Batch step - 1880 -- sub batch step 7521 -- lr 2.82e-04
2025-03-02 14:57:00,305 - INFO - ðŸªœ Batch step - 1880 -- sub batch step 7522 -- lr 2.82e-04
2025-03-02 14:57:02,474 - INFO - ðŸªœ Batch step - 1880 -- sub batch step 7523 -- lr 2.82e-04
2025-03-02 14:57:04,022 - INFO - Step 1880 -- ðŸ”„ Training Metrics
2025-03-02 14:57:04,022 - INFO - â”œâ”€â”€ Loss: 7.1246
2025-03-02 14:57:04,022 - INFO - â”œâ”€â”€ Learning Rate: 2.82e-04
2025-03-02 14:57:04,022 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:57:04,697 - INFO - ðŸªœ Batch step - 1881 -- sub batch step 7524 -- lr 2.82e-04
2025-03-02 14:57:06,855 - INFO - ðŸªœ Batch step - 1881 -- sub batch step 7525 -- lr 2.82e-04
2025-03-02 14:57:09,004 - INFO - ðŸªœ Batch step - 1881 -- sub batch step 7526 -- lr 2.82e-04
2025-03-02 14:57:11,611 - INFO - ðŸªœ Batch step - 1881 -- sub batch step 7527 -- lr 2.82e-04
2025-03-02 14:57:13,103 - INFO - Step 1881 -- ðŸ”„ Training Metrics
2025-03-02 14:57:13,103 - INFO - â”œâ”€â”€ Loss: 7.1613
2025-03-02 14:57:13,103 - INFO - â”œâ”€â”€ Learning Rate: 2.82e-04
2025-03-02 14:57:13,104 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:57:13,772 - INFO - ðŸªœ Batch step - 1882 -- sub batch step 7528 -- lr 2.82e-04
2025-03-02 14:57:15,936 - INFO - ðŸªœ Batch step - 1882 -- sub batch step 7529 -- lr 2.82e-04
2025-03-02 14:57:18,095 - INFO - ðŸªœ Batch step - 1882 -- sub batch step 7530 -- lr 2.82e-04
2025-03-02 14:57:20,260 - INFO - ðŸªœ Batch step - 1882 -- sub batch step 7531 -- lr 2.82e-04
2025-03-02 14:57:21,796 - INFO - Step 1882 -- ðŸ”„ Training Metrics
2025-03-02 14:57:21,797 - INFO - â”œâ”€â”€ Loss: 7.1067
2025-03-02 14:57:21,797 - INFO - â”œâ”€â”€ Learning Rate: 2.82e-04
2025-03-02 14:57:21,797 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:57:22,476 - INFO - ðŸªœ Batch step - 1883 -- sub batch step 7532 -- lr 2.82e-04
2025-03-02 14:57:24,628 - INFO - ðŸªœ Batch step - 1883 -- sub batch step 7533 -- lr 2.82e-04
2025-03-02 14:57:26,782 - INFO - ðŸªœ Batch step - 1883 -- sub batch step 7534 -- lr 2.82e-04
2025-03-02 14:57:29,455 - INFO - ðŸªœ Batch step - 1883 -- sub batch step 7535 -- lr 2.82e-04
2025-03-02 14:57:30,940 - INFO - Step 1883 -- ðŸ”„ Training Metrics
2025-03-02 14:57:30,940 - INFO - â”œâ”€â”€ Loss: 7.1584
2025-03-02 14:57:30,941 - INFO - â”œâ”€â”€ Learning Rate: 2.82e-04
2025-03-02 14:57:30,941 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:57:31,610 - INFO - ðŸªœ Batch step - 1884 -- sub batch step 7536 -- lr 2.83e-04
2025-03-02 14:57:33,772 - INFO - ðŸªœ Batch step - 1884 -- sub batch step 7537 -- lr 2.83e-04
2025-03-02 14:57:35,924 - INFO - ðŸªœ Batch step - 1884 -- sub batch step 7538 -- lr 2.83e-04
2025-03-02 14:57:38,096 - INFO - ðŸªœ Batch step - 1884 -- sub batch step 7539 -- lr 2.83e-04
2025-03-02 14:57:39,638 - INFO - Step 1884 -- ðŸ”„ Training Metrics
2025-03-02 14:57:39,638 - INFO - â”œâ”€â”€ Loss: 7.1469
2025-03-02 14:57:39,638 - INFO - â”œâ”€â”€ Learning Rate: 2.83e-04
2025-03-02 14:57:39,638 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:57:40,318 - INFO - ðŸªœ Batch step - 1885 -- sub batch step 7540 -- lr 2.83e-04
2025-03-02 14:57:42,470 - INFO - ðŸªœ Batch step - 1885 -- sub batch step 7541 -- lr 2.83e-04
2025-03-02 14:57:44,627 - INFO - ðŸªœ Batch step - 1885 -- sub batch step 7542 -- lr 2.83e-04
2025-03-02 14:57:47,333 - INFO - ðŸªœ Batch step - 1885 -- sub batch step 7543 -- lr 2.83e-04
2025-03-02 14:57:48,887 - INFO - Step 1885 -- ðŸ”„ Training Metrics
2025-03-02 14:57:48,887 - INFO - â”œâ”€â”€ Loss: 7.1432
2025-03-02 14:57:48,887 - INFO - â”œâ”€â”€ Learning Rate: 2.83e-04
2025-03-02 14:57:48,887 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:57:49,563 - INFO - ðŸªœ Batch step - 1886 -- sub batch step 7544 -- lr 2.83e-04
2025-03-02 14:57:51,722 - INFO - ðŸªœ Batch step - 1886 -- sub batch step 7545 -- lr 2.83e-04
2025-03-02 14:57:53,873 - INFO - ðŸªœ Batch step - 1886 -- sub batch step 7546 -- lr 2.83e-04
2025-03-02 14:57:56,047 - INFO - ðŸªœ Batch step - 1886 -- sub batch step 7547 -- lr 2.83e-04
2025-03-02 14:57:57,592 - INFO - Step 1886 -- ðŸ”„ Training Metrics
2025-03-02 14:57:57,592 - INFO - â”œâ”€â”€ Loss: 7.1635
2025-03-02 14:57:57,592 - INFO - â”œâ”€â”€ Learning Rate: 2.83e-04
2025-03-02 14:57:57,592 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:57:58,264 - INFO - ðŸªœ Batch step - 1887 -- sub batch step 7548 -- lr 2.83e-04
2025-03-02 14:58:00,427 - INFO - ðŸªœ Batch step - 1887 -- sub batch step 7549 -- lr 2.83e-04
2025-03-02 14:58:02,588 - INFO - ðŸªœ Batch step - 1887 -- sub batch step 7550 -- lr 2.83e-04
2025-03-02 14:58:05,214 - INFO - ðŸªœ Batch step - 1887 -- sub batch step 7551 -- lr 2.83e-04
2025-03-02 14:58:06,887 - INFO - Step 1887 -- ðŸ”„ Training Metrics
2025-03-02 14:58:06,887 - INFO - â”œâ”€â”€ Loss: 7.1457
2025-03-02 14:58:06,887 - INFO - â”œâ”€â”€ Learning Rate: 2.83e-04
2025-03-02 14:58:06,887 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:58:07,566 - INFO - ðŸªœ Batch step - 1888 -- sub batch step 7552 -- lr 2.83e-04
2025-03-02 14:58:09,717 - INFO - ðŸªœ Batch step - 1888 -- sub batch step 7553 -- lr 2.83e-04
2025-03-02 14:58:11,874 - INFO - ðŸªœ Batch step - 1888 -- sub batch step 7554 -- lr 2.83e-04
2025-03-02 14:58:14,043 - INFO - ðŸªœ Batch step - 1888 -- sub batch step 7555 -- lr 2.83e-04
2025-03-02 14:58:15,584 - INFO - Step 1888 -- ðŸ”„ Training Metrics
2025-03-02 14:58:15,584 - INFO - â”œâ”€â”€ Loss: 7.1572
2025-03-02 14:58:15,584 - INFO - â”œâ”€â”€ Learning Rate: 2.83e-04
2025-03-02 14:58:15,584 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:58:16,257 - INFO - ðŸªœ Batch step - 1889 -- sub batch step 7556 -- lr 2.83e-04
2025-03-02 14:58:18,414 - INFO - ðŸªœ Batch step - 1889 -- sub batch step 7557 -- lr 2.83e-04
2025-03-02 14:58:20,563 - INFO - ðŸªœ Batch step - 1889 -- sub batch step 7558 -- lr 2.83e-04
2025-03-02 14:58:23,021 - INFO - ðŸªœ Batch step - 1889 -- sub batch step 7559 -- lr 2.83e-04
2025-03-02 14:58:24,977 - INFO - Step 1889 -- ðŸ”„ Training Metrics
2025-03-02 14:58:24,977 - INFO - â”œâ”€â”€ Loss: 7.1569
2025-03-02 14:58:24,977 - INFO - â”œâ”€â”€ Learning Rate: 2.83e-04
2025-03-02 14:58:24,977 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:58:25,653 - INFO - ðŸªœ Batch step - 1890 -- sub batch step 7560 -- lr 2.83e-04
2025-03-02 14:58:27,809 - INFO - ðŸªœ Batch step - 1890 -- sub batch step 7561 -- lr 2.83e-04
2025-03-02 14:58:29,961 - INFO - ðŸªœ Batch step - 1890 -- sub batch step 7562 -- lr 2.83e-04
2025-03-02 14:58:32,126 - INFO - ðŸªœ Batch step - 1890 -- sub batch step 7563 -- lr 2.83e-04
2025-03-02 14:58:33,668 - INFO - Step 1890 -- ðŸ”„ Training Metrics
2025-03-02 14:58:33,668 - INFO - â”œâ”€â”€ Loss: 7.1644
2025-03-02 14:58:33,668 - INFO - â”œâ”€â”€ Learning Rate: 2.83e-04
2025-03-02 14:58:33,668 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:58:34,345 - INFO - ðŸªœ Batch step - 1891 -- sub batch step 7564 -- lr 2.84e-04
2025-03-02 14:58:36,501 - INFO - ðŸªœ Batch step - 1891 -- sub batch step 7565 -- lr 2.84e-04
2025-03-02 14:58:38,863 - INFO - ðŸªœ Batch step - 1891 -- sub batch step 7566 -- lr 2.84e-04
2025-03-02 14:58:41,021 - INFO - ðŸªœ Batch step - 1891 -- sub batch step 7567 -- lr 2.84e-04
2025-03-02 14:58:42,957 - INFO - Step 1891 -- ðŸ”„ Training Metrics
2025-03-02 14:58:42,957 - INFO - â”œâ”€â”€ Loss: 7.1199
2025-03-02 14:58:42,957 - INFO - â”œâ”€â”€ Learning Rate: 2.84e-04
2025-03-02 14:58:42,957 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:58:43,626 - INFO - ðŸªœ Batch step - 1892 -- sub batch step 7568 -- lr 2.84e-04
2025-03-02 14:58:45,787 - INFO - ðŸªœ Batch step - 1892 -- sub batch step 7569 -- lr 2.84e-04
2025-03-02 14:58:47,960 - INFO - ðŸªœ Batch step - 1892 -- sub batch step 7570 -- lr 2.84e-04
2025-03-02 14:58:50,112 - INFO - ðŸªœ Batch step - 1892 -- sub batch step 7571 -- lr 2.84e-04
2025-03-02 14:58:51,655 - INFO - Step 1892 -- ðŸ”„ Training Metrics
2025-03-02 14:58:51,655 - INFO - â”œâ”€â”€ Loss: 7.1373
2025-03-02 14:58:51,655 - INFO - â”œâ”€â”€ Learning Rate: 2.84e-04
2025-03-02 14:58:51,655 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:58:52,336 - INFO - ðŸªœ Batch step - 1893 -- sub batch step 7572 -- lr 2.84e-04
2025-03-02 14:58:54,486 - INFO - ðŸªœ Batch step - 1893 -- sub batch step 7573 -- lr 2.84e-04
2025-03-02 14:58:57,126 - INFO - ðŸªœ Batch step - 1893 -- sub batch step 7574 -- lr 2.84e-04
2025-03-02 14:58:59,286 - INFO - ðŸªœ Batch step - 1893 -- sub batch step 7575 -- lr 2.84e-04
2025-03-02 14:59:00,869 - INFO - Step 1893 -- ðŸ”„ Training Metrics
2025-03-02 14:59:00,869 - INFO - â”œâ”€â”€ Loss: 7.1265
2025-03-02 14:59:00,869 - INFO - â”œâ”€â”€ Learning Rate: 2.84e-04
2025-03-02 14:59:00,869 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:59:01,537 - INFO - ðŸªœ Batch step - 1894 -- sub batch step 7576 -- lr 2.84e-04
2025-03-02 14:59:03,698 - INFO - ðŸªœ Batch step - 1894 -- sub batch step 7577 -- lr 2.84e-04
2025-03-02 14:59:05,865 - INFO - ðŸªœ Batch step - 1894 -- sub batch step 7578 -- lr 2.84e-04
2025-03-02 14:59:08,020 - INFO - ðŸªœ Batch step - 1894 -- sub batch step 7579 -- lr 2.84e-04
2025-03-02 14:59:09,571 - INFO - Step 1894 -- ðŸ”„ Training Metrics
2025-03-02 14:59:09,572 - INFO - â”œâ”€â”€ Loss: 7.1437
2025-03-02 14:59:09,572 - INFO - â”œâ”€â”€ Learning Rate: 2.84e-04
2025-03-02 14:59:09,572 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:59:10,244 - INFO - ðŸªœ Batch step - 1895 -- sub batch step 7580 -- lr 2.84e-04
2025-03-02 14:59:12,397 - INFO - ðŸªœ Batch step - 1895 -- sub batch step 7581 -- lr 2.84e-04
2025-03-02 14:59:15,149 - INFO - ðŸªœ Batch step - 1895 -- sub batch step 7582 -- lr 2.84e-04
2025-03-02 14:59:17,304 - INFO - ðŸªœ Batch step - 1895 -- sub batch step 7583 -- lr 2.84e-04
2025-03-02 14:59:18,796 - INFO - Step 1895 -- ðŸ”„ Training Metrics
2025-03-02 14:59:18,796 - INFO - â”œâ”€â”€ Loss: 7.1448
2025-03-02 14:59:18,796 - INFO - â”œâ”€â”€ Learning Rate: 2.84e-04
2025-03-02 14:59:18,796 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:59:19,472 - INFO - ðŸªœ Batch step - 1896 -- sub batch step 7584 -- lr 2.84e-04
2025-03-02 14:59:21,627 - INFO - ðŸªœ Batch step - 1896 -- sub batch step 7585 -- lr 2.84e-04
2025-03-02 14:59:23,792 - INFO - ðŸªœ Batch step - 1896 -- sub batch step 7586 -- lr 2.84e-04
2025-03-02 14:59:25,947 - INFO - ðŸªœ Batch step - 1896 -- sub batch step 7587 -- lr 2.84e-04
2025-03-02 14:59:27,490 - INFO - Step 1896 -- ðŸ”„ Training Metrics
2025-03-02 14:59:27,491 - INFO - â”œâ”€â”€ Loss: 7.1586
2025-03-02 14:59:27,491 - INFO - â”œâ”€â”€ Learning Rate: 2.84e-04
2025-03-02 14:59:27,491 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:59:28,157 - INFO - ðŸªœ Batch step - 1897 -- sub batch step 7588 -- lr 2.85e-04
2025-03-02 14:59:30,315 - INFO - ðŸªœ Batch step - 1897 -- sub batch step 7589 -- lr 2.85e-04
2025-03-02 14:59:33,053 - INFO - ðŸªœ Batch step - 1897 -- sub batch step 7590 -- lr 2.85e-04
2025-03-02 14:59:35,201 - INFO - ðŸªœ Batch step - 1897 -- sub batch step 7591 -- lr 2.85e-04
2025-03-02 14:59:36,766 - INFO - Step 1897 -- ðŸ”„ Training Metrics
2025-03-02 14:59:36,766 - INFO - â”œâ”€â”€ Loss: 7.1298
2025-03-02 14:59:36,766 - INFO - â”œâ”€â”€ Learning Rate: 2.85e-04
2025-03-02 14:59:36,766 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:59:37,443 - INFO - ðŸªœ Batch step - 1898 -- sub batch step 7592 -- lr 2.85e-04
2025-03-02 14:59:39,596 - INFO - ðŸªœ Batch step - 1898 -- sub batch step 7593 -- lr 2.85e-04
2025-03-02 14:59:41,767 - INFO - ðŸªœ Batch step - 1898 -- sub batch step 7594 -- lr 2.85e-04
2025-03-02 14:59:43,921 - INFO - ðŸªœ Batch step - 1898 -- sub batch step 7595 -- lr 2.85e-04
2025-03-02 14:59:45,473 - INFO - Step 1898 -- ðŸ”„ Training Metrics
2025-03-02 14:59:45,473 - INFO - â”œâ”€â”€ Loss: 7.1250
2025-03-02 14:59:45,473 - INFO - â”œâ”€â”€ Learning Rate: 2.85e-04
2025-03-02 14:59:45,473 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:59:46,145 - INFO - ðŸªœ Batch step - 1899 -- sub batch step 7596 -- lr 2.85e-04
2025-03-02 14:59:48,299 - INFO - ðŸªœ Batch step - 1899 -- sub batch step 7597 -- lr 2.85e-04
2025-03-02 14:59:50,572 - INFO - ðŸªœ Batch step - 1899 -- sub batch step 7598 -- lr 2.85e-04
2025-03-02 14:59:52,730 - INFO - ðŸªœ Batch step - 1899 -- sub batch step 7599 -- lr 2.85e-04
2025-03-02 14:59:54,316 - INFO - Step 1899 -- ðŸ”„ Training Metrics
2025-03-02 14:59:54,317 - INFO - â”œâ”€â”€ Loss: 7.1267
2025-03-02 14:59:54,317 - INFO - â”œâ”€â”€ Learning Rate: 2.85e-04
2025-03-02 14:59:54,317 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 14:59:55,585 - INFO - ðŸªœ Batch step - 1900 -- sub batch step 7600 -- lr 2.85e-04
2025-03-02 14:59:57,732 - INFO - ðŸªœ Batch step - 1900 -- sub batch step 7601 -- lr 2.85e-04
2025-03-02 14:59:59,886 - INFO - ðŸªœ Batch step - 1900 -- sub batch step 7602 -- lr 2.85e-04
2025-03-02 15:00:02,056 - INFO - ðŸªœ Batch step - 1900 -- sub batch step 7603 -- lr 2.85e-04
2025-03-02 15:00:03,626 - INFO - Step 1900 -- ðŸ”„ Training Metrics
2025-03-02 15:00:03,627 - INFO - â”œâ”€â”€ Loss: 7.1613
2025-03-02 15:00:03,627 - INFO - â”œâ”€â”€ Learning Rate: 2.85e-04
2025-03-02 15:00:03,627 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:00:04,302 - INFO - ðŸªœ Batch step - 1901 -- sub batch step 7604 -- lr 2.85e-04
2025-03-02 15:00:06,455 - INFO - ðŸªœ Batch step - 1901 -- sub batch step 7605 -- lr 2.85e-04
2025-03-02 15:00:08,607 - INFO - ðŸªœ Batch step - 1901 -- sub batch step 7606 -- lr 2.85e-04
2025-03-02 15:00:11,218 - INFO - ðŸªœ Batch step - 1901 -- sub batch step 7607 -- lr 2.85e-04
2025-03-02 15:00:12,708 - INFO - Step 1901 -- ðŸ”„ Training Metrics
2025-03-02 15:00:12,708 - INFO - â”œâ”€â”€ Loss: 7.1186
2025-03-02 15:00:12,708 - INFO - â”œâ”€â”€ Learning Rate: 2.85e-04
2025-03-02 15:00:12,708 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:00:13,376 - INFO - ðŸªœ Batch step - 1902 -- sub batch step 7608 -- lr 2.85e-04
2025-03-02 15:00:15,534 - INFO - ðŸªœ Batch step - 1902 -- sub batch step 7609 -- lr 2.85e-04
2025-03-02 15:00:17,690 - INFO - ðŸªœ Batch step - 1902 -- sub batch step 7610 -- lr 2.85e-04
2025-03-02 15:00:19,860 - INFO - ðŸªœ Batch step - 1902 -- sub batch step 7611 -- lr 2.85e-04
2025-03-02 15:00:21,401 - INFO - Step 1902 -- ðŸ”„ Training Metrics
2025-03-02 15:00:21,401 - INFO - â”œâ”€â”€ Loss: 7.1496
2025-03-02 15:00:21,401 - INFO - â”œâ”€â”€ Learning Rate: 2.85e-04
2025-03-02 15:00:21,401 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:00:22,079 - INFO - ðŸªœ Batch step - 1903 -- sub batch step 7612 -- lr 2.85e-04
2025-03-02 15:00:24,229 - INFO - ðŸªœ Batch step - 1903 -- sub batch step 7613 -- lr 2.85e-04
2025-03-02 15:00:26,384 - INFO - ðŸªœ Batch step - 1903 -- sub batch step 7614 -- lr 2.85e-04
2025-03-02 15:00:29,102 - INFO - ðŸªœ Batch step - 1903 -- sub batch step 7615 -- lr 2.85e-04
2025-03-02 15:00:30,677 - INFO - Step 1903 -- ðŸ”„ Training Metrics
2025-03-02 15:00:30,677 - INFO - â”œâ”€â”€ Loss: 7.1115
2025-03-02 15:00:30,677 - INFO - â”œâ”€â”€ Learning Rate: 2.85e-04
2025-03-02 15:00:30,677 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:00:31,349 - INFO - ðŸªœ Batch step - 1904 -- sub batch step 7616 -- lr 2.86e-04
2025-03-02 15:00:33,504 - INFO - ðŸªœ Batch step - 1904 -- sub batch step 7617 -- lr 2.86e-04
2025-03-02 15:00:35,654 - INFO - ðŸªœ Batch step - 1904 -- sub batch step 7618 -- lr 2.86e-04
2025-03-02 15:00:37,830 - INFO - ðŸªœ Batch step - 1904 -- sub batch step 7619 -- lr 2.86e-04
2025-03-02 15:00:39,395 - INFO - Step 1904 -- ðŸ”„ Training Metrics
2025-03-02 15:00:39,395 - INFO - â”œâ”€â”€ Loss: 7.1323
2025-03-02 15:00:39,395 - INFO - â”œâ”€â”€ Learning Rate: 2.86e-04
2025-03-02 15:00:39,395 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:00:40,073 - INFO - ðŸªœ Batch step - 1905 -- sub batch step 7620 -- lr 2.86e-04
2025-03-02 15:00:42,224 - INFO - ðŸªœ Batch step - 1905 -- sub batch step 7621 -- lr 2.86e-04
2025-03-02 15:00:44,377 - INFO - ðŸªœ Batch step - 1905 -- sub batch step 7622 -- lr 2.86e-04
2025-03-02 15:00:47,074 - INFO - ðŸªœ Batch step - 1905 -- sub batch step 7623 -- lr 2.86e-04
2025-03-02 15:00:48,627 - INFO - Step 1905 -- ðŸ”„ Training Metrics
2025-03-02 15:00:48,627 - INFO - â”œâ”€â”€ Loss: 7.1094
2025-03-02 15:00:48,627 - INFO - â”œâ”€â”€ Learning Rate: 2.86e-04
2025-03-02 15:00:48,627 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:00:49,302 - INFO - ðŸªœ Batch step - 1906 -- sub batch step 7624 -- lr 2.86e-04
2025-03-02 15:00:51,456 - INFO - ðŸªœ Batch step - 1906 -- sub batch step 7625 -- lr 2.86e-04
2025-03-02 15:00:53,602 - INFO - ðŸªœ Batch step - 1906 -- sub batch step 7626 -- lr 2.86e-04
2025-03-02 15:00:55,775 - INFO - ðŸªœ Batch step - 1906 -- sub batch step 7627 -- lr 2.86e-04
2025-03-02 15:00:57,333 - INFO - Step 1906 -- ðŸ”„ Training Metrics
2025-03-02 15:00:57,333 - INFO - â”œâ”€â”€ Loss: 7.1178
2025-03-02 15:00:57,333 - INFO - â”œâ”€â”€ Learning Rate: 2.86e-04
2025-03-02 15:00:57,333 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:00:58,001 - INFO - ðŸªœ Batch step - 1907 -- sub batch step 7628 -- lr 2.86e-04
2025-03-02 15:01:00,161 - INFO - ðŸªœ Batch step - 1907 -- sub batch step 7629 -- lr 2.86e-04
2025-03-02 15:01:02,314 - INFO - ðŸªœ Batch step - 1907 -- sub batch step 7630 -- lr 2.86e-04
2025-03-02 15:01:04,938 - INFO - ðŸªœ Batch step - 1907 -- sub batch step 7631 -- lr 2.86e-04
2025-03-02 15:01:06,615 - INFO - Step 1907 -- ðŸ”„ Training Metrics
2025-03-02 15:01:06,615 - INFO - â”œâ”€â”€ Loss: 7.1153
2025-03-02 15:01:06,615 - INFO - â”œâ”€â”€ Learning Rate: 2.86e-04
2025-03-02 15:01:06,615 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:01:07,291 - INFO - ðŸªœ Batch step - 1908 -- sub batch step 7632 -- lr 2.86e-04
2025-03-02 15:01:09,442 - INFO - ðŸªœ Batch step - 1908 -- sub batch step 7633 -- lr 2.86e-04
2025-03-02 15:01:11,595 - INFO - ðŸªœ Batch step - 1908 -- sub batch step 7634 -- lr 2.86e-04
2025-03-02 15:01:13,769 - INFO - ðŸªœ Batch step - 1908 -- sub batch step 7635 -- lr 2.86e-04
2025-03-02 15:01:15,310 - INFO - Step 1908 -- ðŸ”„ Training Metrics
2025-03-02 15:01:15,311 - INFO - â”œâ”€â”€ Loss: 7.1162
2025-03-02 15:01:15,311 - INFO - â”œâ”€â”€ Learning Rate: 2.86e-04
2025-03-02 15:01:15,311 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:01:15,983 - INFO - ðŸªœ Batch step - 1909 -- sub batch step 7636 -- lr 2.86e-04
2025-03-02 15:01:18,137 - INFO - ðŸªœ Batch step - 1909 -- sub batch step 7637 -- lr 2.86e-04
2025-03-02 15:01:20,284 - INFO - ðŸªœ Batch step - 1909 -- sub batch step 7638 -- lr 2.86e-04
2025-03-02 15:01:22,645 - INFO - ðŸªœ Batch step - 1909 -- sub batch step 7639 -- lr 2.86e-04
2025-03-02 15:01:24,528 - INFO - Step 1909 -- ðŸ”„ Training Metrics
2025-03-02 15:01:24,528 - INFO - â”œâ”€â”€ Loss: 7.1099
2025-03-02 15:01:24,528 - INFO - â”œâ”€â”€ Learning Rate: 2.86e-04
2025-03-02 15:01:24,528 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:01:25,203 - INFO - ðŸªœ Batch step - 1910 -- sub batch step 7640 -- lr 2.86e-04
2025-03-02 15:01:27,353 - INFO - ðŸªœ Batch step - 1910 -- sub batch step 7641 -- lr 2.86e-04
2025-03-02 15:01:29,504 - INFO - ðŸªœ Batch step - 1910 -- sub batch step 7642 -- lr 2.86e-04
2025-03-02 15:01:31,666 - INFO - ðŸªœ Batch step - 1910 -- sub batch step 7643 -- lr 2.86e-04
2025-03-02 15:01:33,218 - INFO - Step 1910 -- ðŸ”„ Training Metrics
2025-03-02 15:01:33,218 - INFO - â”œâ”€â”€ Loss: 7.1370
2025-03-02 15:01:33,218 - INFO - â”œâ”€â”€ Learning Rate: 2.86e-04
2025-03-02 15:01:33,218 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:01:33,893 - INFO - ðŸªœ Batch step - 1911 -- sub batch step 7644 -- lr 2.87e-04
2025-03-02 15:01:36,048 - INFO - ðŸªœ Batch step - 1911 -- sub batch step 7645 -- lr 2.87e-04
2025-03-02 15:01:38,423 - INFO - ðŸªœ Batch step - 1911 -- sub batch step 7646 -- lr 2.87e-04
2025-03-02 15:01:40,581 - INFO - ðŸªœ Batch step - 1911 -- sub batch step 7647 -- lr 2.87e-04
2025-03-02 15:01:42,449 - INFO - Step 1911 -- ðŸ”„ Training Metrics
2025-03-02 15:01:42,449 - INFO - â”œâ”€â”€ Loss: 7.1223
2025-03-02 15:01:42,449 - INFO - â”œâ”€â”€ Learning Rate: 2.87e-04
2025-03-02 15:01:42,450 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:01:43,119 - INFO - ðŸªœ Batch step - 1912 -- sub batch step 7648 -- lr 2.87e-04
2025-03-02 15:01:45,270 - INFO - ðŸªœ Batch step - 1912 -- sub batch step 7649 -- lr 2.87e-04
2025-03-02 15:01:47,446 - INFO - ðŸªœ Batch step - 1912 -- sub batch step 7650 -- lr 2.87e-04
2025-03-02 15:01:49,594 - INFO - ðŸªœ Batch step - 1912 -- sub batch step 7651 -- lr 2.87e-04
2025-03-02 15:01:51,143 - INFO - Step 1912 -- ðŸ”„ Training Metrics
2025-03-02 15:01:51,143 - INFO - â”œâ”€â”€ Loss: 7.1030
2025-03-02 15:01:51,143 - INFO - â”œâ”€â”€ Learning Rate: 2.87e-04
2025-03-02 15:01:51,143 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:01:51,821 - INFO - ðŸªœ Batch step - 1913 -- sub batch step 7652 -- lr 2.87e-04
2025-03-02 15:01:53,970 - INFO - ðŸªœ Batch step - 1913 -- sub batch step 7653 -- lr 2.87e-04
2025-03-02 15:01:56,586 - INFO - ðŸªœ Batch step - 1913 -- sub batch step 7654 -- lr 2.87e-04
2025-03-02 15:01:58,742 - INFO - ðŸªœ Batch step - 1913 -- sub batch step 7655 -- lr 2.87e-04
2025-03-02 15:02:00,360 - INFO - Step 1913 -- ðŸ”„ Training Metrics
2025-03-02 15:02:00,360 - INFO - â”œâ”€â”€ Loss: 7.1390
2025-03-02 15:02:00,360 - INFO - â”œâ”€â”€ Learning Rate: 2.87e-04
2025-03-02 15:02:00,360 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:02:01,029 - INFO - ðŸªœ Batch step - 1914 -- sub batch step 7656 -- lr 2.87e-04
2025-03-02 15:02:03,187 - INFO - ðŸªœ Batch step - 1914 -- sub batch step 7657 -- lr 2.87e-04
2025-03-02 15:02:05,350 - INFO - ðŸªœ Batch step - 1914 -- sub batch step 7658 -- lr 2.87e-04
2025-03-02 15:02:07,503 - INFO - ðŸªœ Batch step - 1914 -- sub batch step 7659 -- lr 2.87e-04
2025-03-02 15:02:09,056 - INFO - Step 1914 -- ðŸ”„ Training Metrics
2025-03-02 15:02:09,057 - INFO - â”œâ”€â”€ Loss: 7.1444
2025-03-02 15:02:09,057 - INFO - â”œâ”€â”€ Learning Rate: 2.87e-04
2025-03-02 15:02:09,057 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:02:09,730 - INFO - ðŸªœ Batch step - 1915 -- sub batch step 7660 -- lr 2.87e-04
2025-03-02 15:02:11,881 - INFO - ðŸªœ Batch step - 1915 -- sub batch step 7661 -- lr 2.87e-04
2025-03-02 15:02:14,561 - INFO - ðŸªœ Batch step - 1915 -- sub batch step 7662 -- lr 2.87e-04
2025-03-02 15:02:16,709 - INFO - ðŸªœ Batch step - 1915 -- sub batch step 7663 -- lr 2.87e-04
2025-03-02 15:02:18,344 - INFO - Step 1915 -- ðŸ”„ Training Metrics
2025-03-02 15:02:18,344 - INFO - â”œâ”€â”€ Loss: 7.1297
2025-03-02 15:02:18,345 - INFO - â”œâ”€â”€ Learning Rate: 2.87e-04
2025-03-02 15:02:18,345 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:02:19,020 - INFO - ðŸªœ Batch step - 1916 -- sub batch step 7664 -- lr 2.87e-04
2025-03-02 15:02:21,175 - INFO - ðŸªœ Batch step - 1916 -- sub batch step 7665 -- lr 2.87e-04
2025-03-02 15:02:23,338 - INFO - ðŸªœ Batch step - 1916 -- sub batch step 7666 -- lr 2.87e-04
2025-03-02 15:02:25,492 - INFO - ðŸªœ Batch step - 1916 -- sub batch step 7667 -- lr 2.87e-04
2025-03-02 15:02:27,045 - INFO - Step 1916 -- ðŸ”„ Training Metrics
2025-03-02 15:02:27,046 - INFO - â”œâ”€â”€ Loss: 7.1363
2025-03-02 15:02:27,046 - INFO - â”œâ”€â”€ Learning Rate: 2.87e-04
2025-03-02 15:02:27,046 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:02:27,719 - INFO - ðŸªœ Batch step - 1917 -- sub batch step 7668 -- lr 2.88e-04
2025-03-02 15:02:29,875 - INFO - ðŸªœ Batch step - 1917 -- sub batch step 7669 -- lr 2.88e-04
2025-03-02 15:02:32,621 - INFO - ðŸªœ Batch step - 1917 -- sub batch step 7670 -- lr 2.88e-04
2025-03-02 15:02:34,769 - INFO - ðŸªœ Batch step - 1917 -- sub batch step 7671 -- lr 2.88e-04
2025-03-02 15:02:36,286 - INFO - Step 1917 -- ðŸ”„ Training Metrics
2025-03-02 15:02:36,286 - INFO - â”œâ”€â”€ Loss: 7.1110
2025-03-02 15:02:36,286 - INFO - â”œâ”€â”€ Learning Rate: 2.88e-04
2025-03-02 15:02:36,286 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:02:36,961 - INFO - ðŸªœ Batch step - 1918 -- sub batch step 7672 -- lr 2.88e-04
2025-03-02 15:02:39,109 - INFO - ðŸªœ Batch step - 1918 -- sub batch step 7673 -- lr 2.88e-04
2025-03-02 15:02:41,281 - INFO - ðŸªœ Batch step - 1918 -- sub batch step 7674 -- lr 2.88e-04
2025-03-02 15:02:43,437 - INFO - ðŸªœ Batch step - 1918 -- sub batch step 7675 -- lr 2.88e-04
2025-03-02 15:02:44,989 - INFO - Step 1918 -- ðŸ”„ Training Metrics
2025-03-02 15:02:44,990 - INFO - â”œâ”€â”€ Loss: 7.1294
2025-03-02 15:02:44,990 - INFO - â”œâ”€â”€ Learning Rate: 2.88e-04
2025-03-02 15:02:44,990 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:02:45,661 - INFO - ðŸªœ Batch step - 1919 -- sub batch step 7676 -- lr 2.88e-04
2025-03-02 15:02:47,819 - INFO - ðŸªœ Batch step - 1919 -- sub batch step 7677 -- lr 2.88e-04
2025-03-02 15:02:50,104 - INFO - ðŸªœ Batch step - 1919 -- sub batch step 7678 -- lr 2.88e-04
2025-03-02 15:02:52,262 - INFO - ðŸªœ Batch step - 1919 -- sub batch step 7679 -- lr 2.88e-04
2025-03-02 15:02:53,977 - INFO - Step 1919 -- ðŸ”„ Training Metrics
2025-03-02 15:02:53,977 - INFO - â”œâ”€â”€ Loss: 7.1268
2025-03-02 15:02:53,977 - INFO - â”œâ”€â”€ Learning Rate: 2.88e-04
2025-03-02 15:02:53,977 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:02:55,273 - INFO - ðŸªœ Batch step - 1920 -- sub batch step 7680 -- lr 2.88e-04
2025-03-02 15:02:57,425 - INFO - ðŸªœ Batch step - 1920 -- sub batch step 7681 -- lr 2.88e-04
2025-03-02 15:02:59,578 - INFO - ðŸªœ Batch step - 1920 -- sub batch step 7682 -- lr 2.88e-04
2025-03-02 15:03:01,747 - INFO - ðŸªœ Batch step - 1920 -- sub batch step 7683 -- lr 2.88e-04
2025-03-02 15:03:03,279 - INFO - Step 1920 -- ðŸ”„ Training Metrics
2025-03-02 15:03:03,280 - INFO - â”œâ”€â”€ Loss: 7.1170
2025-03-02 15:03:03,280 - INFO - â”œâ”€â”€ Learning Rate: 2.88e-04
2025-03-02 15:03:03,280 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:03:03,955 - INFO - ðŸªœ Batch step - 1921 -- sub batch step 7684 -- lr 2.88e-04
2025-03-02 15:03:06,110 - INFO - ðŸªœ Batch step - 1921 -- sub batch step 7685 -- lr 2.88e-04
2025-03-02 15:03:08,258 - INFO - ðŸªœ Batch step - 1921 -- sub batch step 7686 -- lr 2.88e-04
2025-03-02 15:03:14,463 - INFO - ðŸªœ Batch step - 1921 -- sub batch step 7687 -- lr 2.88e-04
2025-03-02 15:03:15,980 - INFO - Step 1921 -- ðŸ”„ Training Metrics
2025-03-02 15:03:15,980 - INFO - â”œâ”€â”€ Loss: 7.1113
2025-03-02 15:03:15,980 - INFO - â”œâ”€â”€ Learning Rate: 2.88e-04
2025-03-02 15:03:15,980 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:03:16,650 - INFO - ðŸªœ Batch step - 1922 -- sub batch step 7688 -- lr 2.88e-04
2025-03-02 15:03:18,809 - INFO - ðŸªœ Batch step - 1922 -- sub batch step 7689 -- lr 2.88e-04
2025-03-02 15:03:20,965 - INFO - ðŸªœ Batch step - 1922 -- sub batch step 7690 -- lr 2.88e-04
2025-03-02 15:03:23,132 - INFO - ðŸªœ Batch step - 1922 -- sub batch step 7691 -- lr 2.88e-04
2025-03-02 15:03:24,676 - INFO - Step 1922 -- ðŸ”„ Training Metrics
2025-03-02 15:03:24,676 - INFO - â”œâ”€â”€ Loss: 7.1189
2025-03-02 15:03:24,676 - INFO - â”œâ”€â”€ Learning Rate: 2.88e-04
2025-03-02 15:03:24,676 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:03:25,354 - INFO - ðŸªœ Batch step - 1923 -- sub batch step 7692 -- lr 2.88e-04
2025-03-02 15:03:27,504 - INFO - ðŸªœ Batch step - 1923 -- sub batch step 7693 -- lr 2.88e-04
2025-03-02 15:03:29,655 - INFO - ðŸªœ Batch step - 1923 -- sub batch step 7694 -- lr 2.88e-04
2025-03-02 15:03:32,035 - INFO - ðŸªœ Batch step - 1923 -- sub batch step 7695 -- lr 2.88e-04
2025-03-02 15:03:33,837 - INFO - Step 1923 -- ðŸ”„ Training Metrics
2025-03-02 15:03:33,837 - INFO - â”œâ”€â”€ Loss: 7.1041
2025-03-02 15:03:33,838 - INFO - â”œâ”€â”€ Learning Rate: 2.88e-04
2025-03-02 15:03:33,838 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:03:34,510 - INFO - ðŸªœ Batch step - 1924 -- sub batch step 7696 -- lr 2.89e-04
2025-03-02 15:03:36,665 - INFO - ðŸªœ Batch step - 1924 -- sub batch step 7697 -- lr 2.89e-04
2025-03-02 15:03:38,813 - INFO - ðŸªœ Batch step - 1924 -- sub batch step 7698 -- lr 2.89e-04
2025-03-02 15:03:40,985 - INFO - ðŸªœ Batch step - 1924 -- sub batch step 7699 -- lr 2.89e-04
2025-03-02 15:03:42,539 - INFO - Step 1924 -- ðŸ”„ Training Metrics
2025-03-02 15:03:42,539 - INFO - â”œâ”€â”€ Loss: 7.1327
2025-03-02 15:03:42,539 - INFO - â”œâ”€â”€ Learning Rate: 2.89e-04
2025-03-02 15:03:42,539 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:03:43,214 - INFO - ðŸªœ Batch step - 1925 -- sub batch step 7700 -- lr 2.89e-04
2025-03-02 15:03:45,364 - INFO - ðŸªœ Batch step - 1925 -- sub batch step 7701 -- lr 2.89e-04
2025-03-02 15:03:47,520 - INFO - ðŸªœ Batch step - 1925 -- sub batch step 7702 -- lr 2.89e-04
2025-03-02 15:03:50,164 - INFO - ðŸªœ Batch step - 1925 -- sub batch step 7703 -- lr 2.89e-04
2025-03-02 15:03:51,724 - INFO - Step 1925 -- ðŸ”„ Training Metrics
2025-03-02 15:03:51,724 - INFO - â”œâ”€â”€ Loss: 7.1164
2025-03-02 15:03:51,724 - INFO - â”œâ”€â”€ Learning Rate: 2.89e-04
2025-03-02 15:03:51,724 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:03:52,400 - INFO - ðŸªœ Batch step - 1926 -- sub batch step 7704 -- lr 2.89e-04
2025-03-02 15:03:54,553 - INFO - ðŸªœ Batch step - 1926 -- sub batch step 7705 -- lr 2.89e-04
2025-03-02 15:03:56,700 - INFO - ðŸªœ Batch step - 1926 -- sub batch step 7706 -- lr 2.89e-04
2025-03-02 15:03:58,874 - INFO - ðŸªœ Batch step - 1926 -- sub batch step 7707 -- lr 2.89e-04
2025-03-02 15:04:00,438 - INFO - Step 1926 -- ðŸ”„ Training Metrics
2025-03-02 15:04:00,439 - INFO - â”œâ”€â”€ Loss: 7.0996
2025-03-02 15:04:00,439 - INFO - â”œâ”€â”€ Learning Rate: 2.89e-04
2025-03-02 15:04:00,439 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:04:01,110 - INFO - ðŸªœ Batch step - 1927 -- sub batch step 7708 -- lr 2.89e-04
2025-03-02 15:04:03,271 - INFO - ðŸªœ Batch step - 1927 -- sub batch step 7709 -- lr 2.89e-04
2025-03-02 15:04:05,427 - INFO - ðŸªœ Batch step - 1927 -- sub batch step 7710 -- lr 2.89e-04
2025-03-02 15:04:08,248 - INFO - ðŸªœ Batch step - 1927 -- sub batch step 7711 -- lr 2.89e-04
2025-03-02 15:04:10,423 - INFO - Step 1927 -- ðŸ”„ Training Metrics
2025-03-02 15:04:10,423 - INFO - â”œâ”€â”€ Loss: 7.1364
2025-03-02 15:04:10,423 - INFO - â”œâ”€â”€ Learning Rate: 2.89e-04
2025-03-02 15:04:10,423 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:04:11,095 - INFO - ðŸªœ Batch step - 1928 -- sub batch step 7712 -- lr 2.89e-04
2025-03-02 15:04:13,248 - INFO - ðŸªœ Batch step - 1928 -- sub batch step 7713 -- lr 2.89e-04
2025-03-02 15:04:15,408 - INFO - ðŸªœ Batch step - 1928 -- sub batch step 7714 -- lr 2.89e-04
2025-03-02 15:04:17,581 - INFO - ðŸªœ Batch step - 1928 -- sub batch step 7715 -- lr 2.89e-04
2025-03-02 15:04:19,141 - INFO - Step 1928 -- ðŸ”„ Training Metrics
2025-03-02 15:04:19,141 - INFO - â”œâ”€â”€ Loss: 7.1194
2025-03-02 15:04:19,141 - INFO - â”œâ”€â”€ Learning Rate: 2.89e-04
2025-03-02 15:04:19,142 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:04:19,808 - INFO - ðŸªœ Batch step - 1929 -- sub batch step 7716 -- lr 2.89e-04
2025-03-02 15:04:21,968 - INFO - ðŸªœ Batch step - 1929 -- sub batch step 7717 -- lr 2.89e-04
2025-03-02 15:04:24,123 - INFO - ðŸªœ Batch step - 1929 -- sub batch step 7718 -- lr 2.89e-04
2025-03-02 15:04:26,752 - INFO - ðŸªœ Batch step - 1929 -- sub batch step 7719 -- lr 2.89e-04
2025-03-02 15:04:29,661 - INFO - Step 1929 -- ðŸ”„ Training Metrics
2025-03-02 15:04:29,661 - INFO - â”œâ”€â”€ Loss: 7.1154
2025-03-02 15:04:29,661 - INFO - â”œâ”€â”€ Learning Rate: 2.89e-04
2025-03-02 15:04:29,661 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:04:30,334 - INFO - ðŸªœ Batch step - 1930 -- sub batch step 7720 -- lr 2.89e-04
2025-03-02 15:04:32,484 - INFO - ðŸªœ Batch step - 1930 -- sub batch step 7721 -- lr 2.89e-04
2025-03-02 15:04:34,642 - INFO - ðŸªœ Batch step - 1930 -- sub batch step 7722 -- lr 2.89e-04
2025-03-02 15:04:36,813 - INFO - ðŸªœ Batch step - 1930 -- sub batch step 7723 -- lr 2.89e-04
2025-03-02 15:04:38,372 - INFO - Step 1930 -- ðŸ”„ Training Metrics
2025-03-02 15:04:38,373 - INFO - â”œâ”€â”€ Loss: 7.1128
2025-03-02 15:04:38,373 - INFO - â”œâ”€â”€ Learning Rate: 2.89e-04
2025-03-02 15:04:38,373 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:04:39,049 - INFO - ðŸªœ Batch step - 1931 -- sub batch step 7724 -- lr 2.90e-04
2025-03-02 15:04:41,206 - INFO - ðŸªœ Batch step - 1931 -- sub batch step 7725 -- lr 2.90e-04
2025-03-02 15:04:43,871 - INFO - ðŸªœ Batch step - 1931 -- sub batch step 7726 -- lr 2.90e-04
2025-03-02 15:04:46,025 - INFO - ðŸªœ Batch step - 1931 -- sub batch step 7727 -- lr 2.90e-04
2025-03-02 15:04:47,560 - INFO - Step 1931 -- ðŸ”„ Training Metrics
2025-03-02 15:04:47,561 - INFO - â”œâ”€â”€ Loss: 7.1202
2025-03-02 15:04:47,561 - INFO - â”œâ”€â”€ Learning Rate: 2.90e-04
2025-03-02 15:04:47,561 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:04:48,230 - INFO - ðŸªœ Batch step - 1932 -- sub batch step 7728 -- lr 2.90e-04
2025-03-02 15:04:50,388 - INFO - ðŸªœ Batch step - 1932 -- sub batch step 7729 -- lr 2.90e-04
2025-03-02 15:04:52,557 - INFO - ðŸªœ Batch step - 1932 -- sub batch step 7730 -- lr 2.90e-04
2025-03-02 15:04:54,703 - INFO - ðŸªœ Batch step - 1932 -- sub batch step 7731 -- lr 2.90e-04
2025-03-02 15:04:56,249 - INFO - Step 1932 -- ðŸ”„ Training Metrics
2025-03-02 15:04:56,249 - INFO - â”œâ”€â”€ Loss: 7.1065
2025-03-02 15:04:56,250 - INFO - â”œâ”€â”€ Learning Rate: 2.90e-04
2025-03-02 15:04:56,250 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:04:56,921 - INFO - ðŸªœ Batch step - 1933 -- sub batch step 7732 -- lr 2.90e-04
2025-03-02 15:04:59,071 - INFO - ðŸªœ Batch step - 1933 -- sub batch step 7733 -- lr 2.90e-04
2025-03-02 15:05:01,805 - INFO - ðŸªœ Batch step - 1933 -- sub batch step 7734 -- lr 2.90e-04
2025-03-02 15:05:03,967 - INFO - ðŸªœ Batch step - 1933 -- sub batch step 7735 -- lr 2.90e-04
2025-03-02 15:05:05,469 - INFO - Step 1933 -- ðŸ”„ Training Metrics
2025-03-02 15:05:05,469 - INFO - â”œâ”€â”€ Loss: 7.1211
2025-03-02 15:05:05,469 - INFO - â”œâ”€â”€ Learning Rate: 2.90e-04
2025-03-02 15:05:05,469 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:05:06,137 - INFO - ðŸªœ Batch step - 1934 -- sub batch step 7736 -- lr 2.90e-04
2025-03-02 15:05:08,295 - INFO - ðŸªœ Batch step - 1934 -- sub batch step 7737 -- lr 2.90e-04
2025-03-02 15:05:10,461 - INFO - ðŸªœ Batch step - 1934 -- sub batch step 7738 -- lr 2.90e-04
2025-03-02 15:05:12,618 - INFO - ðŸªœ Batch step - 1934 -- sub batch step 7739 -- lr 2.90e-04
2025-03-02 15:05:14,157 - INFO - Step 1934 -- ðŸ”„ Training Metrics
2025-03-02 15:05:14,158 - INFO - â”œâ”€â”€ Loss: 7.1028
2025-03-02 15:05:14,158 - INFO - â”œâ”€â”€ Learning Rate: 2.90e-04
2025-03-02 15:05:14,158 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:05:14,830 - INFO - ðŸªœ Batch step - 1935 -- sub batch step 7740 -- lr 2.90e-04
2025-03-02 15:05:16,981 - INFO - ðŸªœ Batch step - 1935 -- sub batch step 7741 -- lr 2.90e-04
2025-03-02 15:05:19,637 - INFO - ðŸªœ Batch step - 1935 -- sub batch step 7742 -- lr 2.90e-04
2025-03-02 15:05:21,782 - INFO - ðŸªœ Batch step - 1935 -- sub batch step 7743 -- lr 2.90e-04
2025-03-02 15:05:23,314 - INFO - Step 1935 -- ðŸ”„ Training Metrics
2025-03-02 15:05:23,314 - INFO - â”œâ”€â”€ Loss: 7.1032
2025-03-02 15:05:23,314 - INFO - â”œâ”€â”€ Learning Rate: 2.90e-04
2025-03-02 15:05:23,314 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:05:23,990 - INFO - ðŸªœ Batch step - 1936 -- sub batch step 7744 -- lr 2.90e-04
2025-03-02 15:05:26,142 - INFO - ðŸªœ Batch step - 1936 -- sub batch step 7745 -- lr 2.90e-04
2025-03-02 15:05:28,310 - INFO - ðŸªœ Batch step - 1936 -- sub batch step 7746 -- lr 2.90e-04
2025-03-02 15:05:30,465 - INFO - ðŸªœ Batch step - 1936 -- sub batch step 7747 -- lr 2.90e-04
2025-03-02 15:05:31,996 - INFO - Step 1936 -- ðŸ”„ Training Metrics
2025-03-02 15:05:31,997 - INFO - â”œâ”€â”€ Loss: 7.1281
2025-03-02 15:05:31,997 - INFO - â”œâ”€â”€ Learning Rate: 2.90e-04
2025-03-02 15:05:31,997 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:05:32,667 - INFO - ðŸªœ Batch step - 1937 -- sub batch step 7748 -- lr 2.91e-04
2025-03-02 15:05:34,823 - INFO - ðŸªœ Batch step - 1937 -- sub batch step 7749 -- lr 2.91e-04
2025-03-02 15:05:37,879 - INFO - ðŸªœ Batch step - 1937 -- sub batch step 7750 -- lr 2.91e-04
2025-03-02 15:05:40,034 - INFO - ðŸªœ Batch step - 1937 -- sub batch step 7751 -- lr 2.91e-04
2025-03-02 15:05:41,524 - INFO - Step 1937 -- ðŸ”„ Training Metrics
2025-03-02 15:05:41,525 - INFO - â”œâ”€â”€ Loss: 7.1116
2025-03-02 15:05:41,525 - INFO - â”œâ”€â”€ Learning Rate: 2.91e-04
2025-03-02 15:05:41,525 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:05:42,202 - INFO - ðŸªœ Batch step - 1938 -- sub batch step 7752 -- lr 2.91e-04
2025-03-02 15:05:44,353 - INFO - ðŸªœ Batch step - 1938 -- sub batch step 7753 -- lr 2.91e-04
2025-03-02 15:05:46,523 - INFO - ðŸªœ Batch step - 1938 -- sub batch step 7754 -- lr 2.91e-04
2025-03-02 15:05:48,677 - INFO - ðŸªœ Batch step - 1938 -- sub batch step 7755 -- lr 2.91e-04
2025-03-02 15:05:50,215 - INFO - Step 1938 -- ðŸ”„ Training Metrics
2025-03-02 15:05:50,216 - INFO - â”œâ”€â”€ Loss: 7.1358
2025-03-02 15:05:50,216 - INFO - â”œâ”€â”€ Learning Rate: 2.91e-04
2025-03-02 15:05:50,216 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:05:50,888 - INFO - ðŸªœ Batch step - 1939 -- sub batch step 7756 -- lr 2.91e-04
2025-03-02 15:05:53,045 - INFO - ðŸªœ Batch step - 1939 -- sub batch step 7757 -- lr 2.91e-04
2025-03-02 15:05:55,348 - INFO - ðŸªœ Batch step - 1939 -- sub batch step 7758 -- lr 2.91e-04
2025-03-02 15:05:57,501 - INFO - ðŸªœ Batch step - 1939 -- sub batch step 7759 -- lr 2.91e-04
2025-03-02 15:05:59,089 - INFO - Step 1939 -- ðŸ”„ Training Metrics
2025-03-02 15:05:59,090 - INFO - â”œâ”€â”€ Loss: 7.0903
2025-03-02 15:05:59,090 - INFO - â”œâ”€â”€ Learning Rate: 2.91e-04
2025-03-02 15:05:59,090 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:06:00,366 - INFO - ðŸªœ Batch step - 1940 -- sub batch step 7760 -- lr 2.91e-04
2025-03-02 15:06:02,519 - INFO - ðŸªœ Batch step - 1940 -- sub batch step 7761 -- lr 2.91e-04
2025-03-02 15:06:04,676 - INFO - ðŸªœ Batch step - 1940 -- sub batch step 7762 -- lr 2.91e-04
2025-03-02 15:06:06,842 - INFO - ðŸªœ Batch step - 1940 -- sub batch step 7763 -- lr 2.91e-04
2025-03-02 15:06:09,448 - INFO - Step 1940 -- ðŸ”„ Training Metrics
2025-03-02 15:06:09,449 - INFO - â”œâ”€â”€ Loss: 7.1350
2025-03-02 15:06:09,449 - INFO - â”œâ”€â”€ Learning Rate: 2.91e-04
2025-03-02 15:06:09,449 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:06:10,124 - INFO - ðŸªœ Batch step - 1941 -- sub batch step 7764 -- lr 2.91e-04
2025-03-02 15:06:12,279 - INFO - ðŸªœ Batch step - 1941 -- sub batch step 7765 -- lr 2.91e-04
2025-03-02 15:06:14,425 - INFO - ðŸªœ Batch step - 1941 -- sub batch step 7766 -- lr 2.91e-04
2025-03-02 15:06:17,322 - INFO - ðŸªœ Batch step - 1941 -- sub batch step 7767 -- lr 2.91e-04
2025-03-02 15:06:18,812 - INFO - Step 1941 -- ðŸ”„ Training Metrics
2025-03-02 15:06:18,813 - INFO - â”œâ”€â”€ Loss: 7.0932
2025-03-02 15:06:18,813 - INFO - â”œâ”€â”€ Learning Rate: 2.91e-04
2025-03-02 15:06:18,813 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:06:19,480 - INFO - ðŸªœ Batch step - 1942 -- sub batch step 7768 -- lr 2.91e-04
2025-03-02 15:06:21,640 - INFO - ðŸªœ Batch step - 1942 -- sub batch step 7769 -- lr 2.91e-04
2025-03-02 15:06:23,791 - INFO - ðŸªœ Batch step - 1942 -- sub batch step 7770 -- lr 2.91e-04
2025-03-02 15:06:25,958 - INFO - ðŸªœ Batch step - 1942 -- sub batch step 7771 -- lr 2.91e-04
2025-03-02 15:06:27,490 - INFO - Step 1942 -- ðŸ”„ Training Metrics
2025-03-02 15:06:27,491 - INFO - â”œâ”€â”€ Loss: 7.1342
2025-03-02 15:06:27,491 - INFO - â”œâ”€â”€ Learning Rate: 2.91e-04
2025-03-02 15:06:27,491 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:06:28,170 - INFO - ðŸªœ Batch step - 1943 -- sub batch step 7772 -- lr 2.91e-04
2025-03-02 15:06:30,319 - INFO - ðŸªœ Batch step - 1943 -- sub batch step 7773 -- lr 2.91e-04
2025-03-02 15:06:32,474 - INFO - ðŸªœ Batch step - 1943 -- sub batch step 7774 -- lr 2.91e-04
2025-03-02 15:06:35,142 - INFO - ðŸªœ Batch step - 1943 -- sub batch step 7775 -- lr 2.91e-04
2025-03-02 15:06:36,691 - INFO - Step 1943 -- ðŸ”„ Training Metrics
2025-03-02 15:06:36,691 - INFO - â”œâ”€â”€ Loss: 7.1095
2025-03-02 15:06:36,691 - INFO - â”œâ”€â”€ Learning Rate: 2.91e-04
2025-03-02 15:06:36,691 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:06:37,364 - INFO - ðŸªœ Batch step - 1944 -- sub batch step 7776 -- lr 2.92e-04
2025-03-02 15:06:39,522 - INFO - ðŸªœ Batch step - 1944 -- sub batch step 7777 -- lr 2.92e-04
2025-03-02 15:06:41,670 - INFO - ðŸªœ Batch step - 1944 -- sub batch step 7778 -- lr 2.92e-04
2025-03-02 15:06:43,843 - INFO - ðŸªœ Batch step - 1944 -- sub batch step 7779 -- lr 2.92e-04
2025-03-02 15:06:45,374 - INFO - Step 1944 -- ðŸ”„ Training Metrics
2025-03-02 15:06:45,374 - INFO - â”œâ”€â”€ Loss: 7.0954
2025-03-02 15:06:45,374 - INFO - â”œâ”€â”€ Learning Rate: 2.92e-04
2025-03-02 15:06:45,374 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:06:46,053 - INFO - ðŸªœ Batch step - 1945 -- sub batch step 7780 -- lr 2.92e-04
2025-03-02 15:06:48,203 - INFO - ðŸªœ Batch step - 1945 -- sub batch step 7781 -- lr 2.92e-04
2025-03-02 15:06:50,362 - INFO - ðŸªœ Batch step - 1945 -- sub batch step 7782 -- lr 2.92e-04
2025-03-02 15:06:52,770 - INFO - ðŸªœ Batch step - 1945 -- sub batch step 7783 -- lr 2.92e-04
2025-03-02 15:06:54,471 - INFO - Step 1945 -- ðŸ”„ Training Metrics
2025-03-02 15:06:54,471 - INFO - â”œâ”€â”€ Loss: 7.1199
2025-03-02 15:06:54,471 - INFO - â”œâ”€â”€ Learning Rate: 2.92e-04
2025-03-02 15:06:54,471 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:06:55,147 - INFO - ðŸªœ Batch step - 1946 -- sub batch step 7784 -- lr 2.92e-04
2025-03-02 15:06:57,304 - INFO - ðŸªœ Batch step - 1946 -- sub batch step 7785 -- lr 2.92e-04
2025-03-02 15:06:59,452 - INFO - ðŸªœ Batch step - 1946 -- sub batch step 7786 -- lr 2.92e-04
2025-03-02 15:07:01,628 - INFO - ðŸªœ Batch step - 1946 -- sub batch step 7787 -- lr 2.92e-04
2025-03-02 15:07:03,156 - INFO - Step 1946 -- ðŸ”„ Training Metrics
2025-03-02 15:07:03,156 - INFO - â”œâ”€â”€ Loss: 7.1184
2025-03-02 15:07:03,156 - INFO - â”œâ”€â”€ Learning Rate: 2.92e-04
2025-03-02 15:07:03,157 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:07:03,827 - INFO - ðŸªœ Batch step - 1947 -- sub batch step 7788 -- lr 2.92e-04
2025-03-02 15:07:05,988 - INFO - ðŸªœ Batch step - 1947 -- sub batch step 7789 -- lr 2.92e-04
2025-03-02 15:07:08,141 - INFO - ðŸªœ Batch step - 1947 -- sub batch step 7790 -- lr 2.92e-04
2025-03-02 15:07:10,818 - INFO - ðŸªœ Batch step - 1947 -- sub batch step 7791 -- lr 2.92e-04
2025-03-02 15:07:12,314 - INFO - Step 1947 -- ðŸ”„ Training Metrics
2025-03-02 15:07:12,314 - INFO - â”œâ”€â”€ Loss: 7.1233
2025-03-02 15:07:12,314 - INFO - â”œâ”€â”€ Learning Rate: 2.92e-04
2025-03-02 15:07:12,314 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:07:12,992 - INFO - ðŸªœ Batch step - 1948 -- sub batch step 7792 -- lr 2.92e-04
2025-03-02 15:07:15,142 - INFO - ðŸªœ Batch step - 1948 -- sub batch step 7793 -- lr 2.92e-04
2025-03-02 15:07:17,298 - INFO - ðŸªœ Batch step - 1948 -- sub batch step 7794 -- lr 2.92e-04
2025-03-02 15:07:19,469 - INFO - ðŸªœ Batch step - 1948 -- sub batch step 7795 -- lr 2.92e-04
2025-03-02 15:07:21,000 - INFO - Step 1948 -- ðŸ”„ Training Metrics
2025-03-02 15:07:21,000 - INFO - â”œâ”€â”€ Loss: 7.0984
2025-03-02 15:07:21,000 - INFO - â”œâ”€â”€ Learning Rate: 2.92e-04
2025-03-02 15:07:21,001 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:07:21,674 - INFO - ðŸªœ Batch step - 1949 -- sub batch step 7796 -- lr 2.92e-04
2025-03-02 15:07:23,831 - INFO - ðŸªœ Batch step - 1949 -- sub batch step 7797 -- lr 2.92e-04
2025-03-02 15:07:25,977 - INFO - ðŸªœ Batch step - 1949 -- sub batch step 7798 -- lr 2.92e-04
2025-03-02 15:07:28,635 - INFO - ðŸªœ Batch step - 1949 -- sub batch step 7799 -- lr 2.92e-04
2025-03-02 15:07:30,189 - INFO - Step 1949 -- ðŸ”„ Training Metrics
2025-03-02 15:07:30,189 - INFO - â”œâ”€â”€ Loss: 7.1016
2025-03-02 15:07:30,189 - INFO - â”œâ”€â”€ Learning Rate: 2.92e-04
2025-03-02 15:07:30,190 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:07:30,865 - INFO - ðŸªœ Batch step - 1950 -- sub batch step 7800 -- lr 2.92e-04
2025-03-02 15:07:33,022 - INFO - ðŸªœ Batch step - 1950 -- sub batch step 7801 -- lr 2.92e-04
2025-03-02 15:07:35,175 - INFO - ðŸªœ Batch step - 1950 -- sub batch step 7802 -- lr 2.92e-04
2025-03-02 15:07:37,338 - INFO - ðŸªœ Batch step - 1950 -- sub batch step 7803 -- lr 2.92e-04
2025-03-02 15:07:38,876 - INFO - Step 1950 -- ðŸ”„ Training Metrics
2025-03-02 15:07:38,876 - INFO - â”œâ”€â”€ Loss: 7.0883
2025-03-02 15:07:38,876 - INFO - â”œâ”€â”€ Learning Rate: 2.92e-04
2025-03-02 15:07:38,876 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:07:39,560 - INFO - ðŸªœ Batch step - 1951 -- sub batch step 7804 -- lr 2.93e-04
2025-03-02 15:07:41,720 - INFO - ðŸªœ Batch step - 1951 -- sub batch step 7805 -- lr 2.93e-04
2025-03-02 15:07:44,339 - INFO - ðŸªœ Batch step - 1951 -- sub batch step 7806 -- lr 2.93e-04
2025-03-02 15:07:46,504 - INFO - ðŸªœ Batch step - 1951 -- sub batch step 7807 -- lr 2.93e-04
2025-03-02 15:07:48,040 - INFO - Step 1951 -- ðŸ”„ Training Metrics
2025-03-02 15:07:48,040 - INFO - â”œâ”€â”€ Loss: 7.0904
2025-03-02 15:07:48,040 - INFO - â”œâ”€â”€ Learning Rate: 2.93e-04
2025-03-02 15:07:48,040 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:07:48,722 - INFO - ðŸªœ Batch step - 1952 -- sub batch step 7808 -- lr 2.93e-04
2025-03-02 15:07:50,885 - INFO - ðŸªœ Batch step - 1952 -- sub batch step 7809 -- lr 2.93e-04
2025-03-02 15:07:53,066 - INFO - ðŸªœ Batch step - 1952 -- sub batch step 7810 -- lr 2.93e-04
2025-03-02 15:07:55,214 - INFO - ðŸªœ Batch step - 1952 -- sub batch step 7811 -- lr 2.93e-04
2025-03-02 15:07:56,733 - INFO - Step 1952 -- ðŸ”„ Training Metrics
2025-03-02 15:07:56,733 - INFO - â”œâ”€â”€ Loss: 7.1046
2025-03-02 15:07:56,733 - INFO - â”œâ”€â”€ Learning Rate: 2.93e-04
2025-03-02 15:07:56,733 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:07:57,412 - INFO - ðŸªœ Batch step - 1953 -- sub batch step 7812 -- lr 2.93e-04
2025-03-02 15:07:59,565 - INFO - ðŸªœ Batch step - 1953 -- sub batch step 7813 -- lr 2.93e-04
2025-03-02 15:08:01,945 - INFO - ðŸªœ Batch step - 1953 -- sub batch step 7814 -- lr 2.93e-04
2025-03-02 15:08:04,107 - INFO - ðŸªœ Batch step - 1953 -- sub batch step 7815 -- lr 2.93e-04
2025-03-02 15:08:05,937 - INFO - Step 1953 -- ðŸ”„ Training Metrics
2025-03-02 15:08:05,938 - INFO - â”œâ”€â”€ Loss: 7.1065
2025-03-02 15:08:05,938 - INFO - â”œâ”€â”€ Learning Rate: 2.93e-04
2025-03-02 15:08:05,938 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:08:06,612 - INFO - ðŸªœ Batch step - 1954 -- sub batch step 7816 -- lr 2.93e-04
2025-03-02 15:08:08,770 - INFO - ðŸªœ Batch step - 1954 -- sub batch step 7817 -- lr 2.93e-04
2025-03-02 15:08:10,939 - INFO - ðŸªœ Batch step - 1954 -- sub batch step 7818 -- lr 2.93e-04
2025-03-02 15:08:13,095 - INFO - ðŸªœ Batch step - 1954 -- sub batch step 7819 -- lr 2.93e-04
2025-03-02 15:08:14,625 - INFO - Step 1954 -- ðŸ”„ Training Metrics
2025-03-02 15:08:14,625 - INFO - â”œâ”€â”€ Loss: 7.1004
2025-03-02 15:08:14,625 - INFO - â”œâ”€â”€ Learning Rate: 2.93e-04
2025-03-02 15:08:14,626 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:08:15,298 - INFO - ðŸªœ Batch step - 1955 -- sub batch step 7820 -- lr 2.93e-04
2025-03-02 15:08:17,451 - INFO - ðŸªœ Batch step - 1955 -- sub batch step 7821 -- lr 2.93e-04
2025-03-02 15:08:19,820 - INFO - ðŸªœ Batch step - 1955 -- sub batch step 7822 -- lr 2.93e-04
2025-03-02 15:08:21,973 - INFO - ðŸªœ Batch step - 1955 -- sub batch step 7823 -- lr 2.93e-04
2025-03-02 15:08:23,778 - INFO - Step 1955 -- ðŸ”„ Training Metrics
2025-03-02 15:08:23,779 - INFO - â”œâ”€â”€ Loss: 7.0860
2025-03-02 15:08:23,779 - INFO - â”œâ”€â”€ Learning Rate: 2.93e-04
2025-03-02 15:08:23,779 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:08:24,456 - INFO - ðŸªœ Batch step - 1956 -- sub batch step 7824 -- lr 2.93e-04
2025-03-02 15:08:26,608 - INFO - ðŸªœ Batch step - 1956 -- sub batch step 7825 -- lr 2.93e-04
2025-03-02 15:08:28,777 - INFO - ðŸªœ Batch step - 1956 -- sub batch step 7826 -- lr 2.93e-04
2025-03-02 15:08:30,931 - INFO - ðŸªœ Batch step - 1956 -- sub batch step 7827 -- lr 2.93e-04
2025-03-02 15:08:32,459 - INFO - Step 1956 -- ðŸ”„ Training Metrics
2025-03-02 15:08:32,459 - INFO - â”œâ”€â”€ Loss: 7.1217
2025-03-02 15:08:32,459 - INFO - â”œâ”€â”€ Learning Rate: 2.93e-04
2025-03-02 15:08:32,459 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:08:33,130 - INFO - ðŸªœ Batch step - 1957 -- sub batch step 7828 -- lr 2.94e-04
2025-03-02 15:08:35,289 - INFO - ðŸªœ Batch step - 1957 -- sub batch step 7829 -- lr 2.94e-04
2025-03-02 15:08:37,761 - INFO - ðŸªœ Batch step - 1957 -- sub batch step 7830 -- lr 2.94e-04
2025-03-02 15:08:39,914 - INFO - ðŸªœ Batch step - 1957 -- sub batch step 7831 -- lr 2.94e-04
2025-03-02 15:08:41,627 - INFO - Step 1957 -- ðŸ”„ Training Metrics
2025-03-02 15:08:41,627 - INFO - â”œâ”€â”€ Loss: 7.1013
2025-03-02 15:08:41,628 - INFO - â”œâ”€â”€ Learning Rate: 2.94e-04
2025-03-02 15:08:41,628 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:08:42,306 - INFO - ðŸªœ Batch step - 1958 -- sub batch step 7832 -- lr 2.94e-04
2025-03-02 15:08:44,457 - INFO - ðŸªœ Batch step - 1958 -- sub batch step 7833 -- lr 2.94e-04
2025-03-02 15:08:46,633 - INFO - ðŸªœ Batch step - 1958 -- sub batch step 7834 -- lr 2.94e-04
2025-03-02 15:08:48,787 - INFO - ðŸªœ Batch step - 1958 -- sub batch step 7835 -- lr 2.94e-04
2025-03-02 15:08:50,321 - INFO - Step 1958 -- ðŸ”„ Training Metrics
2025-03-02 15:08:50,321 - INFO - â”œâ”€â”€ Loss: 7.0836
2025-03-02 15:08:50,321 - INFO - â”œâ”€â”€ Learning Rate: 2.94e-04
2025-03-02 15:08:50,321 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:08:50,992 - INFO - ðŸªœ Batch step - 1959 -- sub batch step 7836 -- lr 2.94e-04
2025-03-02 15:08:53,149 - INFO - ðŸªœ Batch step - 1959 -- sub batch step 7837 -- lr 2.94e-04
2025-03-02 15:08:55,431 - INFO - ðŸªœ Batch step - 1959 -- sub batch step 7838 -- lr 2.94e-04
2025-03-02 15:08:57,587 - INFO - ðŸªœ Batch step - 1959 -- sub batch step 7839 -- lr 2.94e-04
2025-03-02 15:08:59,248 - INFO - Step 1959 -- ðŸ”„ Training Metrics
2025-03-02 15:08:59,248 - INFO - â”œâ”€â”€ Loss: 7.0828
2025-03-02 15:08:59,248 - INFO - â”œâ”€â”€ Learning Rate: 2.94e-04
2025-03-02 15:08:59,248 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:09:00,409 - INFO - ðŸªœ Batch step - 1960 -- sub batch step 7840 -- lr 2.94e-04
2025-03-02 15:09:02,561 - INFO - ðŸªœ Batch step - 1960 -- sub batch step 7841 -- lr 2.94e-04
2025-03-02 15:09:04,718 - INFO - ðŸªœ Batch step - 1960 -- sub batch step 7842 -- lr 2.94e-04
2025-03-02 15:09:06,894 - INFO - ðŸªœ Batch step - 1960 -- sub batch step 7843 -- lr 2.94e-04
2025-03-02 15:09:08,567 - INFO - Step 1960 -- ðŸ”„ Training Metrics
2025-03-02 15:09:08,567 - INFO - â”œâ”€â”€ Loss: 7.0764
2025-03-02 15:09:08,567 - INFO - â”œâ”€â”€ Learning Rate: 2.94e-04
2025-03-02 15:09:08,567 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:09:09,245 - INFO - ðŸªœ Batch step - 1961 -- sub batch step 7844 -- lr 2.94e-04
2025-03-02 15:09:11,400 - INFO - ðŸªœ Batch step - 1961 -- sub batch step 7845 -- lr 2.94e-04
2025-03-02 15:09:13,548 - INFO - ðŸªœ Batch step - 1961 -- sub batch step 7846 -- lr 2.94e-04
2025-03-02 15:09:16,359 - INFO - ðŸªœ Batch step - 1961 -- sub batch step 7847 -- lr 2.94e-04
2025-03-02 15:09:17,850 - INFO - Step 1961 -- ðŸ”„ Training Metrics
2025-03-02 15:09:17,850 - INFO - â”œâ”€â”€ Loss: 7.0887
2025-03-02 15:09:17,850 - INFO - â”œâ”€â”€ Learning Rate: 2.94e-04
2025-03-02 15:09:17,850 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:09:18,518 - INFO - ðŸªœ Batch step - 1962 -- sub batch step 7848 -- lr 2.94e-04
2025-03-02 15:09:20,676 - INFO - ðŸªœ Batch step - 1962 -- sub batch step 7849 -- lr 2.94e-04
2025-03-02 15:09:22,833 - INFO - ðŸªœ Batch step - 1962 -- sub batch step 7850 -- lr 2.94e-04
2025-03-02 15:09:25,001 - INFO - ðŸªœ Batch step - 1962 -- sub batch step 7851 -- lr 2.94e-04
2025-03-02 15:09:26,559 - INFO - Step 1962 -- ðŸ”„ Training Metrics
2025-03-02 15:09:26,560 - INFO - â”œâ”€â”€ Loss: 7.0918
2025-03-02 15:09:26,560 - INFO - â”œâ”€â”€ Learning Rate: 2.94e-04
2025-03-02 15:09:26,560 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:09:27,235 - INFO - ðŸªœ Batch step - 1963 -- sub batch step 7852 -- lr 2.94e-04
2025-03-02 15:09:29,389 - INFO - ðŸªœ Batch step - 1963 -- sub batch step 7853 -- lr 2.94e-04
2025-03-02 15:09:31,544 - INFO - ðŸªœ Batch step - 1963 -- sub batch step 7854 -- lr 2.94e-04
2025-03-02 15:09:34,343 - INFO - ðŸªœ Batch step - 1963 -- sub batch step 7855 -- lr 2.94e-04
2025-03-02 15:09:35,834 - INFO - Step 1963 -- ðŸ”„ Training Metrics
2025-03-02 15:09:35,834 - INFO - â”œâ”€â”€ Loss: 7.0948
2025-03-02 15:09:35,834 - INFO - â”œâ”€â”€ Learning Rate: 2.94e-04
2025-03-02 15:09:35,834 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:09:36,506 - INFO - ðŸªœ Batch step - 1964 -- sub batch step 7856 -- lr 2.95e-04
2025-03-02 15:09:38,664 - INFO - ðŸªœ Batch step - 1964 -- sub batch step 7857 -- lr 2.95e-04
2025-03-02 15:09:40,814 - INFO - ðŸªœ Batch step - 1964 -- sub batch step 7858 -- lr 2.95e-04
2025-03-02 15:09:42,987 - INFO - ðŸªœ Batch step - 1964 -- sub batch step 7859 -- lr 2.95e-04
2025-03-02 15:09:44,517 - INFO - Step 1964 -- ðŸ”„ Training Metrics
2025-03-02 15:09:44,518 - INFO - â”œâ”€â”€ Loss: 7.0960
2025-03-02 15:09:44,518 - INFO - â”œâ”€â”€ Learning Rate: 2.95e-04
2025-03-02 15:09:44,518 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:09:45,193 - INFO - ðŸªœ Batch step - 1965 -- sub batch step 7860 -- lr 2.95e-04
2025-03-02 15:09:47,340 - INFO - ðŸªœ Batch step - 1965 -- sub batch step 7861 -- lr 2.95e-04
2025-03-02 15:09:49,493 - INFO - ðŸªœ Batch step - 1965 -- sub batch step 7862 -- lr 2.95e-04
2025-03-02 15:09:52,200 - INFO - ðŸªœ Batch step - 1965 -- sub batch step 7863 -- lr 2.95e-04
2025-03-02 15:09:53,702 - INFO - Step 1965 -- ðŸ”„ Training Metrics
2025-03-02 15:09:53,702 - INFO - â”œâ”€â”€ Loss: 7.1036
2025-03-02 15:09:53,703 - INFO - â”œâ”€â”€ Learning Rate: 2.95e-04
2025-03-02 15:09:53,703 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:09:54,376 - INFO - ðŸªœ Batch step - 1966 -- sub batch step 7864 -- lr 2.95e-04
2025-03-02 15:09:56,533 - INFO - ðŸªœ Batch step - 1966 -- sub batch step 7865 -- lr 2.95e-04
2025-03-02 15:09:58,682 - INFO - ðŸªœ Batch step - 1966 -- sub batch step 7866 -- lr 2.95e-04
2025-03-02 15:10:00,850 - INFO - ðŸªœ Batch step - 1966 -- sub batch step 7867 -- lr 2.95e-04
2025-03-02 15:10:02,383 - INFO - Step 1966 -- ðŸ”„ Training Metrics
2025-03-02 15:10:02,384 - INFO - â”œâ”€â”€ Loss: 7.0953
2025-03-02 15:10:02,384 - INFO - â”œâ”€â”€ Learning Rate: 2.95e-04
2025-03-02 15:10:02,384 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:10:03,063 - INFO - ðŸªœ Batch step - 1967 -- sub batch step 7868 -- lr 2.95e-04
2025-03-02 15:10:05,220 - INFO - ðŸªœ Batch step - 1967 -- sub batch step 7869 -- lr 2.95e-04
2025-03-02 15:10:07,380 - INFO - ðŸªœ Batch step - 1967 -- sub batch step 7870 -- lr 2.95e-04
2025-03-02 15:10:10,025 - INFO - ðŸªœ Batch step - 1967 -- sub batch step 7871 -- lr 2.95e-04
2025-03-02 15:10:11,589 - INFO - Step 1967 -- ðŸ”„ Training Metrics
2025-03-02 15:10:11,589 - INFO - â”œâ”€â”€ Loss: 7.0925
2025-03-02 15:10:11,589 - INFO - â”œâ”€â”€ Learning Rate: 2.95e-04
2025-03-02 15:10:11,589 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:10:12,268 - INFO - ðŸªœ Batch step - 1968 -- sub batch step 7872 -- lr 2.95e-04
2025-03-02 15:10:14,417 - INFO - ðŸªœ Batch step - 1968 -- sub batch step 7873 -- lr 2.95e-04
2025-03-02 15:10:16,572 - INFO - ðŸªœ Batch step - 1968 -- sub batch step 7874 -- lr 2.95e-04
2025-03-02 15:10:18,745 - INFO - ðŸªœ Batch step - 1968 -- sub batch step 7875 -- lr 2.95e-04
2025-03-02 15:10:20,285 - INFO - Step 1968 -- ðŸ”„ Training Metrics
2025-03-02 15:10:20,285 - INFO - â”œâ”€â”€ Loss: 7.1072
2025-03-02 15:10:20,285 - INFO - â”œâ”€â”€ Learning Rate: 2.95e-04
2025-03-02 15:10:20,285 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:10:20,957 - INFO - ðŸªœ Batch step - 1969 -- sub batch step 7876 -- lr 2.95e-04
2025-03-02 15:10:23,117 - INFO - ðŸªœ Batch step - 1969 -- sub batch step 7877 -- lr 2.95e-04
2025-03-02 15:10:25,265 - INFO - ðŸªœ Batch step - 1969 -- sub batch step 7878 -- lr 2.95e-04
2025-03-02 15:10:27,855 - INFO - ðŸªœ Batch step - 1969 -- sub batch step 7879 -- lr 2.95e-04
2025-03-02 15:10:29,850 - INFO - Step 1969 -- ðŸ”„ Training Metrics
2025-03-02 15:10:29,851 - INFO - â”œâ”€â”€ Loss: 7.0699
2025-03-02 15:10:29,851 - INFO - â”œâ”€â”€ Learning Rate: 2.95e-04
2025-03-02 15:10:29,851 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:10:30,529 - INFO - ðŸªœ Batch step - 1970 -- sub batch step 7880 -- lr 2.95e-04
2025-03-02 15:10:32,680 - INFO - ðŸªœ Batch step - 1970 -- sub batch step 7881 -- lr 2.95e-04
2025-03-02 15:10:34,835 - INFO - ðŸªœ Batch step - 1970 -- sub batch step 7882 -- lr 2.95e-04
2025-03-02 15:10:36,997 - INFO - ðŸªœ Batch step - 1970 -- sub batch step 7883 -- lr 2.95e-04
2025-03-02 15:10:38,531 - INFO - Step 1970 -- ðŸ”„ Training Metrics
2025-03-02 15:10:38,531 - INFO - â”œâ”€â”€ Loss: 7.0810
2025-03-02 15:10:38,531 - INFO - â”œâ”€â”€ Learning Rate: 2.95e-04
2025-03-02 15:10:38,531 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:10:39,209 - INFO - ðŸªœ Batch step - 1971 -- sub batch step 7884 -- lr 2.96e-04
2025-03-02 15:10:41,367 - INFO - ðŸªœ Batch step - 1971 -- sub batch step 7885 -- lr 2.96e-04
2025-03-02 15:10:44,172 - INFO - ðŸªœ Batch step - 1971 -- sub batch step 7886 -- lr 2.96e-04
2025-03-02 15:10:46,336 - INFO - ðŸªœ Batch step - 1971 -- sub batch step 7887 -- lr 2.96e-04
2025-03-02 15:10:47,880 - INFO - Step 1971 -- ðŸ”„ Training Metrics
2025-03-02 15:10:47,880 - INFO - â”œâ”€â”€ Loss: 7.0738
2025-03-02 15:10:47,880 - INFO - â”œâ”€â”€ Learning Rate: 2.96e-04
2025-03-02 15:10:47,880 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:10:48,548 - INFO - ðŸªœ Batch step - 1972 -- sub batch step 7888 -- lr 2.96e-04
2025-03-02 15:10:50,709 - INFO - ðŸªœ Batch step - 1972 -- sub batch step 7889 -- lr 2.96e-04
2025-03-02 15:10:52,880 - INFO - ðŸªœ Batch step - 1972 -- sub batch step 7890 -- lr 2.96e-04
2025-03-02 15:10:55,033 - INFO - ðŸªœ Batch step - 1972 -- sub batch step 7891 -- lr 2.96e-04
2025-03-02 15:10:56,565 - INFO - Step 1972 -- ðŸ”„ Training Metrics
2025-03-02 15:10:56,566 - INFO - â”œâ”€â”€ Loss: 7.0781
2025-03-02 15:10:56,566 - INFO - â”œâ”€â”€ Learning Rate: 2.96e-04
2025-03-02 15:10:56,566 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:10:57,245 - INFO - ðŸªœ Batch step - 1973 -- sub batch step 7892 -- lr 2.96e-04
2025-03-02 15:10:59,397 - INFO - ðŸªœ Batch step - 1973 -- sub batch step 7893 -- lr 2.96e-04
2025-03-02 15:11:02,206 - INFO - ðŸªœ Batch step - 1973 -- sub batch step 7894 -- lr 2.96e-04
2025-03-02 15:11:04,368 - INFO - ðŸªœ Batch step - 1973 -- sub batch step 7895 -- lr 2.96e-04
2025-03-02 15:11:05,859 - INFO - Step 1973 -- ðŸ”„ Training Metrics
2025-03-02 15:11:05,859 - INFO - â”œâ”€â”€ Loss: 7.1045
2025-03-02 15:11:05,860 - INFO - â”œâ”€â”€ Learning Rate: 2.96e-04
2025-03-02 15:11:05,860 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:11:06,533 - INFO - ðŸªœ Batch step - 1974 -- sub batch step 7896 -- lr 2.96e-04
2025-03-02 15:11:08,689 - INFO - ðŸªœ Batch step - 1974 -- sub batch step 7897 -- lr 2.96e-04
2025-03-02 15:11:10,852 - INFO - ðŸªœ Batch step - 1974 -- sub batch step 7898 -- lr 2.96e-04
2025-03-02 15:11:13,009 - INFO - ðŸªœ Batch step - 1974 -- sub batch step 7899 -- lr 2.96e-04
2025-03-02 15:11:14,541 - INFO - Step 1974 -- ðŸ”„ Training Metrics
2025-03-02 15:11:14,541 - INFO - â”œâ”€â”€ Loss: 7.0907
2025-03-02 15:11:14,542 - INFO - â”œâ”€â”€ Learning Rate: 2.96e-04
2025-03-02 15:11:14,542 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:11:15,219 - INFO - ðŸªœ Batch step - 1975 -- sub batch step 7900 -- lr 2.96e-04
2025-03-02 15:11:17,372 - INFO - ðŸªœ Batch step - 1975 -- sub batch step 7901 -- lr 2.96e-04
2025-03-02 15:11:20,222 - INFO - ðŸªœ Batch step - 1975 -- sub batch step 7902 -- lr 2.96e-04
2025-03-02 15:11:22,380 - INFO - ðŸªœ Batch step - 1975 -- sub batch step 7903 -- lr 2.96e-04
2025-03-02 15:11:23,870 - INFO - Step 1975 -- ðŸ”„ Training Metrics
2025-03-02 15:11:23,871 - INFO - â”œâ”€â”€ Loss: 7.0798
2025-03-02 15:11:23,871 - INFO - â”œâ”€â”€ Learning Rate: 2.96e-04
2025-03-02 15:11:23,871 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:11:24,548 - INFO - ðŸªœ Batch step - 1976 -- sub batch step 7904 -- lr 2.96e-04
2025-03-02 15:11:26,705 - INFO - ðŸªœ Batch step - 1976 -- sub batch step 7905 -- lr 2.96e-04
2025-03-02 15:11:28,868 - INFO - ðŸªœ Batch step - 1976 -- sub batch step 7906 -- lr 2.96e-04
2025-03-02 15:11:31,022 - INFO - ðŸªœ Batch step - 1976 -- sub batch step 7907 -- lr 2.96e-04
2025-03-02 15:11:32,566 - INFO - Step 1976 -- ðŸ”„ Training Metrics
2025-03-02 15:11:32,567 - INFO - â”œâ”€â”€ Loss: 7.0986
2025-03-02 15:11:32,567 - INFO - â”œâ”€â”€ Learning Rate: 2.96e-04
2025-03-02 15:11:32,567 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:11:33,241 - INFO - ðŸªœ Batch step - 1977 -- sub batch step 7908 -- lr 2.97e-04
2025-03-02 15:11:35,398 - INFO - ðŸªœ Batch step - 1977 -- sub batch step 7909 -- lr 2.97e-04
2025-03-02 15:11:38,118 - INFO - ðŸªœ Batch step - 1977 -- sub batch step 7910 -- lr 2.97e-04
2025-03-02 15:11:40,267 - INFO - ðŸªœ Batch step - 1977 -- sub batch step 7911 -- lr 2.97e-04
2025-03-02 15:11:41,818 - INFO - Step 1977 -- ðŸ”„ Training Metrics
2025-03-02 15:11:41,818 - INFO - â”œâ”€â”€ Loss: 7.0821
2025-03-02 15:11:41,818 - INFO - â”œâ”€â”€ Learning Rate: 2.97e-04
2025-03-02 15:11:41,819 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:11:42,497 - INFO - ðŸªœ Batch step - 1978 -- sub batch step 7912 -- lr 2.97e-04
2025-03-02 15:11:44,647 - INFO - ðŸªœ Batch step - 1978 -- sub batch step 7913 -- lr 2.97e-04
2025-03-02 15:11:46,815 - INFO - ðŸªœ Batch step - 1978 -- sub batch step 7914 -- lr 2.97e-04
2025-03-02 15:11:48,967 - INFO - ðŸªœ Batch step - 1978 -- sub batch step 7915 -- lr 2.97e-04
2025-03-02 15:11:50,521 - INFO - Step 1978 -- ðŸ”„ Training Metrics
2025-03-02 15:11:50,521 - INFO - â”œâ”€â”€ Loss: 7.1103
2025-03-02 15:11:50,521 - INFO - â”œâ”€â”€ Learning Rate: 2.97e-04
2025-03-02 15:11:50,521 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:11:51,191 - INFO - ðŸªœ Batch step - 1979 -- sub batch step 7916 -- lr 2.97e-04
2025-03-02 15:11:53,353 - INFO - ðŸªœ Batch step - 1979 -- sub batch step 7917 -- lr 2.97e-04
2025-03-02 15:11:55,632 - INFO - ðŸªœ Batch step - 1979 -- sub batch step 7918 -- lr 2.97e-04
2025-03-02 15:11:57,787 - INFO - ðŸªœ Batch step - 1979 -- sub batch step 7919 -- lr 2.97e-04
2025-03-02 15:11:59,533 - INFO - Step 1979 -- ðŸ”„ Training Metrics
2025-03-02 15:11:59,533 - INFO - â”œâ”€â”€ Loss: 7.0722
2025-03-02 15:11:59,533 - INFO - â”œâ”€â”€ Learning Rate: 2.97e-04
2025-03-02 15:11:59,533 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:12:00,812 - INFO - ðŸªœ Batch step - 1980 -- sub batch step 7920 -- lr 2.97e-04
2025-03-02 15:12:02,972 - INFO - ðŸªœ Batch step - 1980 -- sub batch step 7921 -- lr 2.97e-04
2025-03-02 15:12:05,133 - INFO - ðŸªœ Batch step - 1980 -- sub batch step 7922 -- lr 2.97e-04
2025-03-02 15:12:07,303 - INFO - ðŸªœ Batch step - 1980 -- sub batch step 7923 -- lr 2.97e-04
2025-03-02 15:12:08,853 - INFO - Step 1980 -- ðŸ”„ Training Metrics
2025-03-02 15:12:08,854 - INFO - â”œâ”€â”€ Loss: 7.0711
2025-03-02 15:12:08,854 - INFO - â”œâ”€â”€ Learning Rate: 2.97e-04
2025-03-02 15:12:08,854 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:12:09,530 - INFO - ðŸªœ Batch step - 1981 -- sub batch step 7924 -- lr 2.97e-04
2025-03-02 15:12:11,685 - INFO - ðŸªœ Batch step - 1981 -- sub batch step 7925 -- lr 2.97e-04
2025-03-02 15:12:13,832 - INFO - ðŸªœ Batch step - 1981 -- sub batch step 7926 -- lr 2.97e-04
2025-03-02 15:12:16,655 - INFO - ðŸªœ Batch step - 1981 -- sub batch step 7927 -- lr 2.97e-04
2025-03-02 15:12:18,146 - INFO - Step 1981 -- ðŸ”„ Training Metrics
2025-03-02 15:12:18,146 - INFO - â”œâ”€â”€ Loss: 7.0890
2025-03-02 15:12:18,146 - INFO - â”œâ”€â”€ Learning Rate: 2.97e-04
2025-03-02 15:12:18,146 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:12:18,817 - INFO - ðŸªœ Batch step - 1982 -- sub batch step 7928 -- lr 2.97e-04
2025-03-02 15:12:20,977 - INFO - ðŸªœ Batch step - 1982 -- sub batch step 7929 -- lr 2.97e-04
2025-03-02 15:12:23,134 - INFO - ðŸªœ Batch step - 1982 -- sub batch step 7930 -- lr 2.97e-04
2025-03-02 15:12:25,298 - INFO - ðŸªœ Batch step - 1982 -- sub batch step 7931 -- lr 2.97e-04
2025-03-02 15:12:26,827 - INFO - Step 1982 -- ðŸ”„ Training Metrics
2025-03-02 15:12:26,827 - INFO - â”œâ”€â”€ Loss: 7.0930
2025-03-02 15:12:26,827 - INFO - â”œâ”€â”€ Learning Rate: 2.97e-04
2025-03-02 15:12:26,827 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:12:27,505 - INFO - ðŸªœ Batch step - 1983 -- sub batch step 7932 -- lr 2.97e-04
2025-03-02 15:12:29,656 - INFO - ðŸªœ Batch step - 1983 -- sub batch step 7933 -- lr 2.97e-04
2025-03-02 15:12:31,812 - INFO - ðŸªœ Batch step - 1983 -- sub batch step 7934 -- lr 2.97e-04
2025-03-02 15:12:34,407 - INFO - ðŸªœ Batch step - 1983 -- sub batch step 7935 -- lr 2.97e-04
2025-03-02 15:12:36,148 - INFO - Step 1983 -- ðŸ”„ Training Metrics
2025-03-02 15:12:36,148 - INFO - â”œâ”€â”€ Loss: 7.0456
2025-03-02 15:12:36,148 - INFO - â”œâ”€â”€ Learning Rate: 2.97e-04
2025-03-02 15:12:36,148 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:12:36,821 - INFO - ðŸªœ Batch step - 1984 -- sub batch step 7936 -- lr 2.98e-04
2025-03-02 15:12:38,978 - INFO - ðŸªœ Batch step - 1984 -- sub batch step 7937 -- lr 2.98e-04
2025-03-02 15:12:41,128 - INFO - ðŸªœ Batch step - 1984 -- sub batch step 7938 -- lr 2.98e-04
2025-03-02 15:12:43,310 - INFO - ðŸªœ Batch step - 1984 -- sub batch step 7939 -- lr 2.98e-04
2025-03-02 15:12:44,841 - INFO - Step 1984 -- ðŸ”„ Training Metrics
2025-03-02 15:12:44,841 - INFO - â”œâ”€â”€ Loss: 7.0493
2025-03-02 15:12:44,841 - INFO - â”œâ”€â”€ Learning Rate: 2.98e-04
2025-03-02 15:12:44,841 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:12:45,520 - INFO - ðŸªœ Batch step - 1985 -- sub batch step 7940 -- lr 2.98e-04
2025-03-02 15:12:47,668 - INFO - ðŸªœ Batch step - 1985 -- sub batch step 7941 -- lr 2.98e-04
2025-03-02 15:12:49,824 - INFO - ðŸªœ Batch step - 1985 -- sub batch step 7942 -- lr 2.98e-04
2025-03-02 15:12:52,184 - INFO - ðŸªœ Batch step - 1985 -- sub batch step 7943 -- lr 2.98e-04
2025-03-02 15:12:54,116 - INFO - Step 1985 -- ðŸ”„ Training Metrics
2025-03-02 15:12:54,116 - INFO - â”œâ”€â”€ Loss: 7.0743
2025-03-02 15:12:54,117 - INFO - â”œâ”€â”€ Learning Rate: 2.98e-04
2025-03-02 15:12:54,117 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:12:54,790 - INFO - ðŸªœ Batch step - 1986 -- sub batch step 7944 -- lr 2.98e-04
2025-03-02 15:12:56,950 - INFO - ðŸªœ Batch step - 1986 -- sub batch step 7945 -- lr 2.98e-04
2025-03-02 15:12:59,098 - INFO - ðŸªœ Batch step - 1986 -- sub batch step 7946 -- lr 2.98e-04
2025-03-02 15:13:01,267 - INFO - ðŸªœ Batch step - 1986 -- sub batch step 7947 -- lr 2.98e-04
2025-03-02 15:13:02,804 - INFO - Step 1986 -- ðŸ”„ Training Metrics
2025-03-02 15:13:02,804 - INFO - â”œâ”€â”€ Loss: 7.0769
2025-03-02 15:13:02,805 - INFO - â”œâ”€â”€ Learning Rate: 2.98e-04
2025-03-02 15:13:02,805 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:13:03,477 - INFO - ðŸªœ Batch step - 1987 -- sub batch step 7948 -- lr 2.98e-04
2025-03-02 15:13:05,636 - INFO - ðŸªœ Batch step - 1987 -- sub batch step 7949 -- lr 2.98e-04
2025-03-02 15:13:07,791 - INFO - ðŸªœ Batch step - 1987 -- sub batch step 7950 -- lr 2.98e-04
2025-03-02 15:13:10,423 - INFO - ðŸªœ Batch step - 1987 -- sub batch step 7951 -- lr 2.98e-04
2025-03-02 15:13:12,060 - INFO - Step 1987 -- ðŸ”„ Training Metrics
2025-03-02 15:13:12,060 - INFO - â”œâ”€â”€ Loss: 7.0705
2025-03-02 15:13:12,060 - INFO - â”œâ”€â”€ Learning Rate: 2.98e-04
2025-03-02 15:13:12,060 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:13:12,737 - INFO - ðŸªœ Batch step - 1988 -- sub batch step 7952 -- lr 2.98e-04
2025-03-02 15:13:14,889 - INFO - ðŸªœ Batch step - 1988 -- sub batch step 7953 -- lr 2.98e-04
2025-03-02 15:13:17,045 - INFO - ðŸªœ Batch step - 1988 -- sub batch step 7954 -- lr 2.98e-04
2025-03-02 15:13:19,220 - INFO - ðŸªœ Batch step - 1988 -- sub batch step 7955 -- lr 2.98e-04
2025-03-02 15:13:20,757 - INFO - Step 1988 -- ðŸ”„ Training Metrics
2025-03-02 15:13:20,757 - INFO - â”œâ”€â”€ Loss: 7.0682
2025-03-02 15:13:20,757 - INFO - â”œâ”€â”€ Learning Rate: 2.98e-04
2025-03-02 15:13:20,757 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:13:21,426 - INFO - ðŸªœ Batch step - 1989 -- sub batch step 7956 -- lr 2.98e-04
2025-03-02 15:13:23,584 - INFO - ðŸªœ Batch step - 1989 -- sub batch step 7957 -- lr 2.98e-04
2025-03-02 15:13:25,733 - INFO - ðŸªœ Batch step - 1989 -- sub batch step 7958 -- lr 2.98e-04
2025-03-02 15:13:28,372 - INFO - ðŸªœ Batch step - 1989 -- sub batch step 7959 -- lr 2.98e-04
2025-03-02 15:13:29,889 - INFO - Step 1989 -- ðŸ”„ Training Metrics
2025-03-02 15:13:29,889 - INFO - â”œâ”€â”€ Loss: 7.0889
2025-03-02 15:13:29,889 - INFO - â”œâ”€â”€ Learning Rate: 2.98e-04
2025-03-02 15:13:29,890 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:13:30,564 - INFO - ðŸªœ Batch step - 1990 -- sub batch step 7960 -- lr 2.98e-04
2025-03-02 15:13:32,719 - INFO - ðŸªœ Batch step - 1990 -- sub batch step 7961 -- lr 2.98e-04
2025-03-02 15:13:34,872 - INFO - ðŸªœ Batch step - 1990 -- sub batch step 7962 -- lr 2.98e-04
2025-03-02 15:13:37,037 - INFO - ðŸªœ Batch step - 1990 -- sub batch step 7963 -- lr 2.98e-04
2025-03-02 15:13:38,583 - INFO - Step 1990 -- ðŸ”„ Training Metrics
2025-03-02 15:13:38,583 - INFO - â”œâ”€â”€ Loss: 7.0969
2025-03-02 15:13:38,583 - INFO - â”œâ”€â”€ Learning Rate: 2.98e-04
2025-03-02 15:13:38,583 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:13:39,259 - INFO - ðŸªœ Batch step - 1991 -- sub batch step 7964 -- lr 2.99e-04
2025-03-02 15:13:41,413 - INFO - ðŸªœ Batch step - 1991 -- sub batch step 7965 -- lr 2.99e-04
2025-03-02 15:13:44,105 - INFO - ðŸªœ Batch step - 1991 -- sub batch step 7966 -- lr 2.99e-04
2025-03-02 15:13:46,269 - INFO - ðŸªœ Batch step - 1991 -- sub batch step 7967 -- lr 2.99e-04
2025-03-02 15:13:47,779 - INFO - Step 1991 -- ðŸ”„ Training Metrics
2025-03-02 15:13:47,780 - INFO - â”œâ”€â”€ Loss: 7.0553
2025-03-02 15:13:47,780 - INFO - â”œâ”€â”€ Learning Rate: 2.99e-04
2025-03-02 15:13:47,780 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:13:48,450 - INFO - ðŸªœ Batch step - 1992 -- sub batch step 7968 -- lr 2.99e-04
2025-03-02 15:13:50,606 - INFO - ðŸªœ Batch step - 1992 -- sub batch step 7969 -- lr 2.99e-04
2025-03-02 15:13:52,780 - INFO - ðŸªœ Batch step - 1992 -- sub batch step 7970 -- lr 2.99e-04
2025-03-02 15:13:54,930 - INFO - ðŸªœ Batch step - 1992 -- sub batch step 7971 -- lr 2.99e-04
2025-03-02 15:13:56,464 - INFO - Step 1992 -- ðŸ”„ Training Metrics
2025-03-02 15:13:56,464 - INFO - â”œâ”€â”€ Loss: 7.0883
2025-03-02 15:13:56,464 - INFO - â”œâ”€â”€ Learning Rate: 2.99e-04
2025-03-02 15:13:56,464 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:13:57,141 - INFO - ðŸªœ Batch step - 1993 -- sub batch step 7972 -- lr 2.99e-04
2025-03-02 15:13:59,294 - INFO - ðŸªœ Batch step - 1993 -- sub batch step 7973 -- lr 2.99e-04
2025-03-02 15:14:02,060 - INFO - ðŸªœ Batch step - 1993 -- sub batch step 7974 -- lr 2.99e-04
2025-03-02 15:14:04,220 - INFO - ðŸªœ Batch step - 1993 -- sub batch step 7975 -- lr 2.99e-04
2025-03-02 15:14:05,711 - INFO - Step 1993 -- ðŸ”„ Training Metrics
2025-03-02 15:14:05,711 - INFO - â”œâ”€â”€ Loss: 7.0440
2025-03-02 15:14:05,711 - INFO - â”œâ”€â”€ Learning Rate: 2.99e-04
2025-03-02 15:14:05,711 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:14:06,381 - INFO - ðŸªœ Batch step - 1994 -- sub batch step 7976 -- lr 2.99e-04
2025-03-02 15:14:08,539 - INFO - ðŸªœ Batch step - 1994 -- sub batch step 7977 -- lr 2.99e-04
2025-03-02 15:14:10,703 - INFO - ðŸªœ Batch step - 1994 -- sub batch step 7978 -- lr 2.99e-04
2025-03-02 15:14:12,859 - INFO - ðŸªœ Batch step - 1994 -- sub batch step 7979 -- lr 2.99e-04
2025-03-02 15:14:14,395 - INFO - Step 1994 -- ðŸ”„ Training Metrics
2025-03-02 15:14:14,395 - INFO - â”œâ”€â”€ Loss: 7.0708
2025-03-02 15:14:14,395 - INFO - â”œâ”€â”€ Learning Rate: 2.99e-04
2025-03-02 15:14:14,395 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:14:15,071 - INFO - ðŸªœ Batch step - 1995 -- sub batch step 7980 -- lr 2.99e-04
2025-03-02 15:14:17,221 - INFO - ðŸªœ Batch step - 1995 -- sub batch step 7981 -- lr 2.99e-04
2025-03-02 15:14:19,770 - INFO - ðŸªœ Batch step - 1995 -- sub batch step 7982 -- lr 2.99e-04
2025-03-02 15:14:21,922 - INFO - ðŸªœ Batch step - 1995 -- sub batch step 7983 -- lr 2.99e-04
2025-03-02 15:14:23,642 - INFO - Step 1995 -- ðŸ”„ Training Metrics
2025-03-02 15:14:23,642 - INFO - â”œâ”€â”€ Loss: 7.0681
2025-03-02 15:14:23,642 - INFO - â”œâ”€â”€ Learning Rate: 2.99e-04
2025-03-02 15:14:23,642 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:14:24,319 - INFO - ðŸªœ Batch step - 1996 -- sub batch step 7984 -- lr 2.99e-04
2025-03-02 15:14:26,474 - INFO - ðŸªœ Batch step - 1996 -- sub batch step 7985 -- lr 2.99e-04
2025-03-02 15:14:28,636 - INFO - ðŸªœ Batch step - 1996 -- sub batch step 7986 -- lr 2.99e-04
2025-03-02 15:14:30,791 - INFO - ðŸªœ Batch step - 1996 -- sub batch step 7987 -- lr 2.99e-04
2025-03-02 15:14:32,327 - INFO - Step 1996 -- ðŸ”„ Training Metrics
2025-03-02 15:14:32,327 - INFO - â”œâ”€â”€ Loss: 7.0659
2025-03-02 15:14:32,327 - INFO - â”œâ”€â”€ Learning Rate: 2.99e-04
2025-03-02 15:14:32,327 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:14:32,997 - INFO - ðŸªœ Batch step - 1997 -- sub batch step 7988 -- lr 3.00e-04
2025-03-02 15:14:35,156 - INFO - ðŸªœ Batch step - 1997 -- sub batch step 7989 -- lr 3.00e-04
2025-03-02 15:14:37,548 - INFO - ðŸªœ Batch step - 1997 -- sub batch step 7990 -- lr 3.00e-04
2025-03-02 15:14:39,699 - INFO - ðŸªœ Batch step - 1997 -- sub batch step 7991 -- lr 3.00e-04
2025-03-02 15:14:41,525 - INFO - Step 1997 -- ðŸ”„ Training Metrics
2025-03-02 15:14:41,526 - INFO - â”œâ”€â”€ Loss: 7.0632
2025-03-02 15:14:41,526 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:14:41,526 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:14:42,204 - INFO - ðŸªœ Batch step - 1998 -- sub batch step 7992 -- lr 3.00e-04
2025-03-02 15:14:44,353 - INFO - ðŸªœ Batch step - 1998 -- sub batch step 7993 -- lr 3.00e-04
2025-03-02 15:14:46,527 - INFO - ðŸªœ Batch step - 1998 -- sub batch step 7994 -- lr 3.00e-04
2025-03-02 15:14:48,681 - INFO - ðŸªœ Batch step - 1998 -- sub batch step 7995 -- lr 3.00e-04
2025-03-02 15:14:50,207 - INFO - Step 1998 -- ðŸ”„ Training Metrics
2025-03-02 15:14:50,208 - INFO - â”œâ”€â”€ Loss: 7.0639
2025-03-02 15:14:50,208 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:14:50,208 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:14:50,878 - INFO - ðŸªœ Batch step - 1999 -- sub batch step 7996 -- lr 3.00e-04
2025-03-02 15:14:53,038 - INFO - ðŸªœ Batch step - 1999 -- sub batch step 7997 -- lr 3.00e-04
2025-03-02 15:14:55,311 - INFO - ðŸªœ Batch step - 1999 -- sub batch step 7998 -- lr 3.00e-04
2025-03-02 15:14:57,476 - INFO - ðŸªœ Batch step - 1999 -- sub batch step 7999 -- lr 3.00e-04
2025-03-02 15:14:59,009 - INFO - Step 1999 -- ðŸ”„ Training Metrics
2025-03-02 15:14:59,010 - INFO - â”œâ”€â”€ Loss: 7.0630
2025-03-02 15:14:59,010 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:14:59,010 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:14:59,015 - INFO - Step 2000 -- ðŸ’¾ Saving Checkpoint
model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]model.safetensors:  12%|â–ˆâ–        | 5.70M/46.8M [00:00<00:01, 34.1MB/s]model.safetensors:  20%|â–ˆâ–‰        | 9.13M/46.8M [00:00<00:01, 33.2MB/s]model.safetensors:  27%|â–ˆâ–ˆâ–‹       | 12.4M/46.8M [00:00<00:01, 22.5MB/s]model.safetensors:  34%|â–ˆâ–ˆâ–ˆâ–      | 16.0M/46.8M [00:00<00:02, 15.0MB/s]model.safetensors:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22.5M/46.8M [00:01<00:01, 22.4MB/s]model.safetensors:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 27.8M/46.8M [00:01<00:00, 22.8MB/s]model.safetensors:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 31.4M/46.8M [00:01<00:00, 24.6MB/s]model.safetensors:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 34.2M/46.8M [00:01<00:00, 16.8MB/s]model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46.8M/46.8M [00:02<00:00, 23.2MB/s]
No files have been modified since last commit. Skipping to prevent empty commit.
bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s]
bf16_zero_pp_rank_11_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][A

Upload 17 LFS files:   0%|          | 0/17 [00:00<?, ?it/s][A[A


bf16_zero_pp_rank_10_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][A[A[A



bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][A[A[A[A




bf16_zero_pp_rank_13_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][A[A[A[A[Abf16_zero_pp_rank_0_mp_rank_00_optim_states.pt:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 3.05M/7.55M [00:00<00:00, 27.5MB/s]
bf16_zero_pp_rank_11_mp_rank_00_optim_states.pt:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2.51M/7.55M [00:00<00:00, 22.9MB/s][A


bf16_zero_pp_rank_10_mp_rank_00_optim_states.pt:  21%|â–ˆâ–ˆ        | 1.59M/7.55M [00:00<00:00, 14.1MB/s][A[A[A



bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt:  19%|â–ˆâ–‰        | 1.43M/7.55M [00:00<00:00, 12.5MB/s][A[A[A[A




bf16_zero_pp_rank_13_mp_rank_00_optim_states.pt:  20%|â–ˆâ–ˆ        | 1.52M/7.55M [00:00<00:00, 13.2MB/s][A[A[A[A[A


bf16_zero_pp_rank_10_mp_rank_00_optim_states.pt:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 3.00M/7.55M [00:00<00:00, 11.0MB/s][A[A[A



bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2.69M/7.55M [00:00<00:00, 9.56MB/s][A[A[A[A




bf16_zero_pp_rank_13_mp_rank_00_optim_states.pt:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 2.85M/7.55M [00:00<00:00, 10.1MB/s][A[A[A[A[A
bf16_zero_pp_rank_11_mp_rank_00_optim_states.pt:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 4.80M/7.55M [00:00<00:00, 11.8MB/s][Abf16_zero_pp_rank_0_mp_rank_00_optim_states.pt:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 6.00M/7.55M [00:00<00:00, 14.2MB/s]




bf16_zero_pp_rank_13_mp_rank_00_optim_states.pt:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6.41M/7.55M [00:00<00:00, 18.0MB/s][A[A[A[A[A



bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 6.31M/7.55M [00:00<00:00, 17.8MB/s][A[A[A[A
bf16_zero_pp_rank_11_mp_rank_00_optim_states.pt:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 7.37M/7.55M [00:00<00:00, 15.0MB/s][Abf16_zero_pp_rank_11_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:00<00:00, 8.62MB/s]
bf16_zero_pp_rank_10_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:01<00:00, 7.17MB/s]
bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:01<00:00, 7.18MB/s]
bf16_zero_pp_rank_13_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:01<00:00, 7.16MB/s]

bf16_zero_pp_rank_14_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][A


bf16_zero_pp_rank_15_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][A[A[A



bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][A[A[A[A




bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][A[A[A[A[A
bf16_zero_pp_rank_14_mp_rank_00_optim_states.pt:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3.80M/7.55M [00:00<00:00, 21.8MB/s][A



bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 6.90M/7.55M [00:00<00:00, 56.5MB/s][A[A[A[A
bf16_zero_pp_rank_14_mp_rank_00_optim_states.pt:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 6.00M/7.55M [00:00<00:00, 21.8MB/s][A


bf16_zero_pp_rank_15_mp_rank_00_optim_states.pt:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 6.31M/7.55M [00:00<00:00, 44.7MB/s][A[A[A




bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4.33M/7.55M [00:00<00:00, 36.8MB/s][A[A[A[A[Abf16_zero_pp_rank_1_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:00<00:00, 15.3MB/s]
bf16_zero_pp_rank_14_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:00<00:00, 9.76MB/s]

bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][Abf16_zero_pp_rank_0_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:02<00:00, 3.67MB/s]
bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s]
bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3.19M/7.55M [00:00<00:00, 21.0MB/s][Abf16_zero_pp_rank_2_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:00<00:00, 8.73MB/s]


Upload 17 LFS files:   6%|â–Œ         | 1/17 [00:02<00:36,  2.26s/it][A[A



bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][A[A[A[Abf16_zero_pp_rank_15_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:01<00:00, 7.20MB/s]



bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][A[A[A

Upload 17 LFS files:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 7/17 [00:02<00:02,  3.67it/s][A[A




bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.56M [00:00<?, ?B/s][A[A[A[A[Abf16_zero_pp_rank_4_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:00<00:00, 15.2MB/s]
bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:00<00:00, 26.6MB/s]
bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:00<00:00, 19.7MB/s]
bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.56M/7.56M [00:00<00:00, 24.6MB/s]
bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.56M [00:00<?, ?B/s]


bf16_zero_pp_rank_9_mp_rank_00_optim_states.pt:   0%|          | 0.00/7.55M [00:00<?, ?B/s][A[A[Abf16_zero_pp_rank_3_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:01<00:00, 7.25MB/s]

mp_rank_00_model_states.pt:   0%|          | 0.00/26.7M [00:00<?, ?B/s][A
mp_rank_00_model_states.pt:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 12.2M/26.7M [00:00<00:00, 119MB/s][Abf16_zero_pp_rank_8_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.56M/7.56M [00:00<00:00, 24.3MB/s]
bf16_zero_pp_rank_9_mp_rank_00_optim_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.55M/7.55M [00:00<00:00, 23.7MB/s]


Upload 17 LFS files:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10/17 [00:03<00:01,  3.90it/s][A[A
mp_rank_00_model_states.pt:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 24.1M/26.7M [00:00<00:00, 54.1MB/s][Amp_rank_00_model_states.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26.7M/26.7M [00:00<00:00, 40.7MB/s]


Upload 17 LFS files:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:04<00:02,  2.27it/s][A[AUpload 17 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.67it/s]
2025-03-02 15:16:24,000 - INFO - Step 2000 -- ðŸ“Š Evaluation Results
2025-03-02 15:16:24,000 - INFO - â””â”€â”€ paloma: 1832.321936311622
2025-03-02 15:16:25,716 - INFO - ðŸªœ Batch step - 2000 -- sub batch step 8000 -- lr 0.00e+00
2025-03-02 15:16:32,278 - INFO - ðŸªœ Batch step - 2000 -- sub batch step 8001 -- lr 0.00e+00
2025-03-02 15:16:34,469 - INFO - ðŸªœ Batch step - 2000 -- sub batch step 8002 -- lr 0.00e+00
2025-03-02 15:16:36,665 - INFO - ðŸªœ Batch step - 2000 -- sub batch step 8003 -- lr 0.00e+00
2025-03-02 15:16:38,203 - INFO - Step 2000 -- ðŸ”„ Training Metrics
2025-03-02 15:16:38,203 - INFO - â”œâ”€â”€ Loss: 7.0831
2025-03-02 15:16:38,203 - INFO - â”œâ”€â”€ Learning Rate: 0.00e+00
2025-03-02 15:16:38,204 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:16:38,204 - INFO - Step 2000 -- ðŸ“ˆ Saving Learning Dynamics
[2025-03-02 15:16:39,413] [WARNING] [engine.py:1244:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****
Saving the dataset (0/1 shards):   0%|          | 0/1024 [00:00<?, ? examples/s]Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:00<00:00, 13288.35 examples/s]Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:00<00:00, 13231.85 examples/s]
Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]
train_activations.pt:   0%|          | 0.00/12.2M [00:00<?, ?B/s][A

data-00000-of-00001.arrow:   0%|          | 0.00/17.4M [00:00<?, ?B/s][A[A
train_activations.pt:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 5.69M/12.2M [00:00<00:00, 56.1MB/s][A

data-00000-of-00001.arrow:  32%|â–ˆâ–ˆâ–ˆâ–      | 5.55M/17.4M [00:00<00:00, 35.1MB/s][A[A

data-00000-of-00001.arrow:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 9.08M/17.4M [00:00<00:00, 33.0MB/s][A[Atrain_activations.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12.2M/12.2M [00:00<00:00, 34.2MB/s]


data-00000-of-00001.arrow:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12.4M/17.4M [00:00<00:00, 31.2MB/s][A[A

data-00000-of-00001.arrow:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 15.5M/17.4M [00:00<00:00, 30.0MB/s][A[AUpload 2 LFS files:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.75it/s]data-00000-of-00001.arrow: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17.4M/17.4M [00:01<00:00, 12.4MB/s]
Upload 2 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.21it/s]Upload 2 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.26it/s]
[2025-03-02 15:16:57,663] [WARNING] [engine.py:1244:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****
val_activations.pt:   0%|          | 0.00/17.2M [00:00<?, ?B/s]val_activations.pt:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 6.39M/17.2M [00:00<00:00, 37.7MB/s]val_activations.pt:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10.2M/17.2M [00:00<00:00, 36.8MB/s]val_activations.pt:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 13.8M/17.2M [00:00<00:00, 27.6MB/s]val_activations.pt:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 16.7M/17.2M [00:03<00:00, 3.24MB/s]val_activations.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17.2M/17.2M [00:03<00:00, 5.09MB/s]
2025-03-02 15:17:08,100 - INFO - Resetting ReLoRA and optimizer at step 2001
2025-03-02 15:17:08,100 - INFO - â”œâ”€â”€ Current learning rate is 3.00e-06
2025-03-02 15:17:08,100 - INFO - â”œâ”€â”€ Performing ReLoRA reset...
2025-03-02 15:17:08,426 - INFO - â”œâ”€â”€ ReLoRA reset successfully!
2025-03-02 15:17:08,427 - INFO - â”œâ”€â”€ Performing optimizer reset...
2025-03-02 15:17:08,688 - INFO - â””â”€â”€ Optimizer reset successfully! Zeroed nan%
2025-03-02 15:17:09,359 - INFO - ðŸªœ Batch step - 2001 -- sub batch step 8004 -- lr 3.00e-06
2025-03-02 15:17:11,521 - INFO - ðŸªœ Batch step - 2001 -- sub batch step 8005 -- lr 3.00e-06
2025-03-02 15:17:13,670 - INFO - ðŸªœ Batch step - 2001 -- sub batch step 8006 -- lr 3.00e-06
2025-03-02 15:17:16,172 - INFO - ðŸªœ Batch step - 2001 -- sub batch step 8007 -- lr 3.00e-06
2025-03-02 15:17:18,002 - INFO - Step 2001 -- ðŸ”„ Training Metrics
2025-03-02 15:17:18,002 - INFO - â”œâ”€â”€ Loss: 7.0682
2025-03-02 15:17:18,002 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-06
2025-03-02 15:17:18,003 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:17:18,674 - INFO - ðŸªœ Batch step - 2002 -- sub batch step 8008 -- lr 6.00e-06
2025-03-02 15:17:20,828 - INFO - ðŸªœ Batch step - 2002 -- sub batch step 8009 -- lr 6.00e-06
2025-03-02 15:17:22,983 - INFO - ðŸªœ Batch step - 2002 -- sub batch step 8010 -- lr 6.00e-06
2025-03-02 15:17:25,152 - INFO - ðŸªœ Batch step - 2002 -- sub batch step 8011 -- lr 6.00e-06
2025-03-02 15:17:26,690 - INFO - Step 2002 -- ðŸ”„ Training Metrics
2025-03-02 15:17:26,690 - INFO - â”œâ”€â”€ Loss: 7.0685
2025-03-02 15:17:26,690 - INFO - â”œâ”€â”€ Learning Rate: 6.00e-06
2025-03-02 15:17:26,690 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:17:27,361 - INFO - ðŸªœ Batch step - 2003 -- sub batch step 8012 -- lr 9.00e-06
2025-03-02 15:17:29,508 - INFO - ðŸªœ Batch step - 2003 -- sub batch step 8013 -- lr 9.00e-06
2025-03-02 15:17:31,658 - INFO - ðŸªœ Batch step - 2003 -- sub batch step 8014 -- lr 9.00e-06
2025-03-02 15:17:34,115 - INFO - ðŸªœ Batch step - 2003 -- sub batch step 8015 -- lr 9.00e-06
2025-03-02 15:17:35,871 - INFO - Step 2003 -- ðŸ”„ Training Metrics
2025-03-02 15:17:35,871 - INFO - â”œâ”€â”€ Loss: 7.0797
2025-03-02 15:17:35,871 - INFO - â”œâ”€â”€ Learning Rate: 9.00e-06
2025-03-02 15:17:35,871 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:17:36,537 - INFO - ðŸªœ Batch step - 2004 -- sub batch step 8016 -- lr 1.20e-05
2025-03-02 15:17:38,688 - INFO - ðŸªœ Batch step - 2004 -- sub batch step 8017 -- lr 1.20e-05
2025-03-02 15:17:40,831 - INFO - ðŸªœ Batch step - 2004 -- sub batch step 8018 -- lr 1.20e-05
2025-03-02 15:17:43,002 - INFO - ðŸªœ Batch step - 2004 -- sub batch step 8019 -- lr 1.20e-05
2025-03-02 15:17:44,544 - INFO - Step 2004 -- ðŸ”„ Training Metrics
2025-03-02 15:17:44,545 - INFO - â”œâ”€â”€ Loss: 7.0694
2025-03-02 15:17:44,545 - INFO - â”œâ”€â”€ Learning Rate: 1.20e-05
2025-03-02 15:17:44,545 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:17:45,217 - INFO - ðŸªœ Batch step - 2005 -- sub batch step 8020 -- lr 1.50e-05
2025-03-02 15:17:47,365 - INFO - ðŸªœ Batch step - 2005 -- sub batch step 8021 -- lr 1.50e-05
2025-03-02 15:17:49,519 - INFO - ðŸªœ Batch step - 2005 -- sub batch step 8022 -- lr 1.50e-05
2025-03-02 15:17:52,263 - INFO - ðŸªœ Batch step - 2005 -- sub batch step 8023 -- lr 1.50e-05
2025-03-02 15:17:53,751 - INFO - Step 2005 -- ðŸ”„ Training Metrics
2025-03-02 15:17:53,751 - INFO - â”œâ”€â”€ Loss: 7.0335
2025-03-02 15:17:53,751 - INFO - â”œâ”€â”€ Learning Rate: 1.50e-05
2025-03-02 15:17:53,751 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:17:54,421 - INFO - ðŸªœ Batch step - 2006 -- sub batch step 8024 -- lr 1.80e-05
2025-03-02 15:17:56,574 - INFO - ðŸªœ Batch step - 2006 -- sub batch step 8025 -- lr 1.80e-05
2025-03-02 15:17:58,722 - INFO - ðŸªœ Batch step - 2006 -- sub batch step 8026 -- lr 1.80e-05
2025-03-02 15:18:00,894 - INFO - ðŸªœ Batch step - 2006 -- sub batch step 8027 -- lr 1.80e-05
2025-03-02 15:18:02,431 - INFO - Step 2006 -- ðŸ”„ Training Metrics
2025-03-02 15:18:02,431 - INFO - â”œâ”€â”€ Loss: 7.0589
2025-03-02 15:18:02,431 - INFO - â”œâ”€â”€ Learning Rate: 1.80e-05
2025-03-02 15:18:02,431 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:18:03,100 - INFO - ðŸªœ Batch step - 2007 -- sub batch step 8028 -- lr 2.10e-05
2025-03-02 15:18:05,253 - INFO - ðŸªœ Batch step - 2007 -- sub batch step 8029 -- lr 2.10e-05
2025-03-02 15:18:07,405 - INFO - ðŸªœ Batch step - 2007 -- sub batch step 8030 -- lr 2.10e-05
2025-03-02 15:18:09,973 - INFO - ðŸªœ Batch step - 2007 -- sub batch step 8031 -- lr 2.10e-05
2025-03-02 15:18:11,766 - INFO - Step 2007 -- ðŸ”„ Training Metrics
2025-03-02 15:18:11,767 - INFO - â”œâ”€â”€ Loss: 7.0776
2025-03-02 15:18:11,767 - INFO - â”œâ”€â”€ Learning Rate: 2.10e-05
2025-03-02 15:18:11,767 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:18:12,440 - INFO - ðŸªœ Batch step - 2008 -- sub batch step 8032 -- lr 2.40e-05
2025-03-02 15:18:14,588 - INFO - ðŸªœ Batch step - 2008 -- sub batch step 8033 -- lr 2.40e-05
2025-03-02 15:18:16,740 - INFO - ðŸªœ Batch step - 2008 -- sub batch step 8034 -- lr 2.40e-05
2025-03-02 15:18:18,912 - INFO - ðŸªœ Batch step - 2008 -- sub batch step 8035 -- lr 2.40e-05
2025-03-02 15:18:20,452 - INFO - Step 2008 -- ðŸ”„ Training Metrics
2025-03-02 15:18:20,453 - INFO - â”œâ”€â”€ Loss: 7.0358
2025-03-02 15:18:20,453 - INFO - â”œâ”€â”€ Learning Rate: 2.40e-05
2025-03-02 15:18:20,453 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:18:21,119 - INFO - ðŸªœ Batch step - 2009 -- sub batch step 8036 -- lr 2.70e-05
2025-03-02 15:18:23,274 - INFO - ðŸªœ Batch step - 2009 -- sub batch step 8037 -- lr 2.70e-05
2025-03-02 15:18:25,422 - INFO - ðŸªœ Batch step - 2009 -- sub batch step 8038 -- lr 2.70e-05
2025-03-02 15:18:28,163 - INFO - ðŸªœ Batch step - 2009 -- sub batch step 8039 -- lr 2.70e-05
2025-03-02 15:18:29,669 - INFO - Step 2009 -- ðŸ”„ Training Metrics
2025-03-02 15:18:29,669 - INFO - â”œâ”€â”€ Loss: 7.1034
2025-03-02 15:18:29,669 - INFO - â”œâ”€â”€ Learning Rate: 2.70e-05
2025-03-02 15:18:29,669 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:18:30,342 - INFO - ðŸªœ Batch step - 2010 -- sub batch step 8040 -- lr 3.00e-05
2025-03-02 15:18:32,489 - INFO - ðŸªœ Batch step - 2010 -- sub batch step 8041 -- lr 3.00e-05
2025-03-02 15:18:34,642 - INFO - ðŸªœ Batch step - 2010 -- sub batch step 8042 -- lr 3.00e-05
2025-03-02 15:18:36,807 - INFO - ðŸªœ Batch step - 2010 -- sub batch step 8043 -- lr 3.00e-05
2025-03-02 15:18:38,346 - INFO - Step 2010 -- ðŸ”„ Training Metrics
2025-03-02 15:18:38,346 - INFO - â”œâ”€â”€ Loss: 7.0538
2025-03-02 15:18:38,347 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-05
2025-03-02 15:18:38,347 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:18:39,020 - INFO - ðŸªœ Batch step - 2011 -- sub batch step 8044 -- lr 3.30e-05
2025-03-02 15:18:41,170 - INFO - ðŸªœ Batch step - 2011 -- sub batch step 8045 -- lr 3.30e-05
2025-03-02 15:18:43,839 - INFO - ðŸªœ Batch step - 2011 -- sub batch step 8046 -- lr 3.30e-05
2025-03-02 15:18:45,997 - INFO - ðŸªœ Batch step - 2011 -- sub batch step 8047 -- lr 3.30e-05
2025-03-02 15:18:47,618 - INFO - Step 2011 -- ðŸ”„ Training Metrics
2025-03-02 15:18:47,619 - INFO - â”œâ”€â”€ Loss: 7.0702
2025-03-02 15:18:47,619 - INFO - â”œâ”€â”€ Learning Rate: 3.30e-05
2025-03-02 15:18:47,619 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:18:48,289 - INFO - ðŸªœ Batch step - 2012 -- sub batch step 8048 -- lr 3.60e-05
2025-03-02 15:18:50,443 - INFO - ðŸªœ Batch step - 2012 -- sub batch step 8049 -- lr 3.60e-05
2025-03-02 15:18:52,615 - INFO - ðŸªœ Batch step - 2012 -- sub batch step 8050 -- lr 3.60e-05
2025-03-02 15:18:54,762 - INFO - ðŸªœ Batch step - 2012 -- sub batch step 8051 -- lr 3.60e-05
2025-03-02 15:18:56,296 - INFO - Step 2012 -- ðŸ”„ Training Metrics
2025-03-02 15:18:56,296 - INFO - â”œâ”€â”€ Loss: 7.0544
2025-03-02 15:18:56,296 - INFO - â”œâ”€â”€ Learning Rate: 3.60e-05
2025-03-02 15:18:56,297 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:18:56,972 - INFO - ðŸªœ Batch step - 2013 -- sub batch step 8052 -- lr 3.90e-05
2025-03-02 15:18:59,121 - INFO - ðŸªœ Batch step - 2013 -- sub batch step 8053 -- lr 3.90e-05
2025-03-02 15:19:01,627 - INFO - ðŸªœ Batch step - 2013 -- sub batch step 8054 -- lr 3.90e-05
2025-03-02 15:19:03,781 - INFO - ðŸªœ Batch step - 2013 -- sub batch step 8055 -- lr 3.90e-05
2025-03-02 15:19:05,320 - INFO - Step 2013 -- ðŸ”„ Training Metrics
2025-03-02 15:19:05,320 - INFO - â”œâ”€â”€ Loss: 7.0655
2025-03-02 15:19:05,320 - INFO - â”œâ”€â”€ Learning Rate: 3.90e-05
2025-03-02 15:19:05,321 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:19:05,993 - INFO - ðŸªœ Batch step - 2014 -- sub batch step 8056 -- lr 4.20e-05
2025-03-02 15:19:08,146 - INFO - ðŸªœ Batch step - 2014 -- sub batch step 8057 -- lr 4.20e-05
2025-03-02 15:19:10,314 - INFO - ðŸªœ Batch step - 2014 -- sub batch step 8058 -- lr 4.20e-05
2025-03-02 15:19:12,470 - INFO - ðŸªœ Batch step - 2014 -- sub batch step 8059 -- lr 4.20e-05
2025-03-02 15:19:13,998 - INFO - Step 2014 -- ðŸ”„ Training Metrics
2025-03-02 15:19:13,999 - INFO - â”œâ”€â”€ Loss: 7.1012
2025-03-02 15:19:13,999 - INFO - â”œâ”€â”€ Learning Rate: 4.20e-05
2025-03-02 15:19:13,999 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:19:14,672 - INFO - ðŸªœ Batch step - 2015 -- sub batch step 8060 -- lr 4.50e-05
2025-03-02 15:19:16,821 - INFO - ðŸªœ Batch step - 2015 -- sub batch step 8061 -- lr 4.50e-05
2025-03-02 15:19:19,281 - INFO - ðŸªœ Batch step - 2015 -- sub batch step 8062 -- lr 4.50e-05
2025-03-02 15:19:21,434 - INFO - ðŸªœ Batch step - 2015 -- sub batch step 8063 -- lr 4.50e-05
2025-03-02 15:19:23,162 - INFO - Step 2015 -- ðŸ”„ Training Metrics
2025-03-02 15:19:23,162 - INFO - â”œâ”€â”€ Loss: 7.0559
2025-03-02 15:19:23,162 - INFO - â”œâ”€â”€ Learning Rate: 4.50e-05
2025-03-02 15:19:23,162 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:19:23,837 - INFO - ðŸªœ Batch step - 2016 -- sub batch step 8064 -- lr 4.80e-05
2025-03-02 15:19:25,989 - INFO - ðŸªœ Batch step - 2016 -- sub batch step 8065 -- lr 4.80e-05
2025-03-02 15:19:28,159 - INFO - ðŸªœ Batch step - 2016 -- sub batch step 8066 -- lr 4.80e-05
2025-03-02 15:19:30,309 - INFO - ðŸªœ Batch step - 2016 -- sub batch step 8067 -- lr 4.80e-05
2025-03-02 15:19:31,845 - INFO - Step 2016 -- ðŸ”„ Training Metrics
2025-03-02 15:19:31,845 - INFO - â”œâ”€â”€ Loss: 7.0553
2025-03-02 15:19:31,845 - INFO - â”œâ”€â”€ Learning Rate: 4.80e-05
2025-03-02 15:19:31,845 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:19:32,514 - INFO - ðŸªœ Batch step - 2017 -- sub batch step 8068 -- lr 5.10e-05
2025-03-02 15:19:34,669 - INFO - ðŸªœ Batch step - 2017 -- sub batch step 8069 -- lr 5.10e-05
2025-03-02 15:19:37,048 - INFO - ðŸªœ Batch step - 2017 -- sub batch step 8070 -- lr 5.10e-05
2025-03-02 15:19:39,203 - INFO - ðŸªœ Batch step - 2017 -- sub batch step 8071 -- lr 5.10e-05
2025-03-02 15:19:41,625 - INFO - Step 2017 -- ðŸ”„ Training Metrics
2025-03-02 15:19:41,625 - INFO - â”œâ”€â”€ Loss: 7.0837
2025-03-02 15:19:41,626 - INFO - â”œâ”€â”€ Learning Rate: 5.10e-05
2025-03-02 15:19:41,626 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:19:42,301 - INFO - ðŸªœ Batch step - 2018 -- sub batch step 8072 -- lr 5.40e-05
2025-03-02 15:19:44,448 - INFO - ðŸªœ Batch step - 2018 -- sub batch step 8073 -- lr 5.40e-05
2025-03-02 15:19:46,625 - INFO - ðŸªœ Batch step - 2018 -- sub batch step 8074 -- lr 5.40e-05
2025-03-02 15:19:48,776 - INFO - ðŸªœ Batch step - 2018 -- sub batch step 8075 -- lr 5.40e-05
2025-03-02 15:19:50,307 - INFO - Step 2018 -- ðŸ”„ Training Metrics
2025-03-02 15:19:50,308 - INFO - â”œâ”€â”€ Loss: 7.0651
2025-03-02 15:19:50,308 - INFO - â”œâ”€â”€ Learning Rate: 5.40e-05
2025-03-02 15:19:50,308 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:19:50,977 - INFO - ðŸªœ Batch step - 2019 -- sub batch step 8076 -- lr 5.70e-05
2025-03-02 15:19:53,133 - INFO - ðŸªœ Batch step - 2019 -- sub batch step 8077 -- lr 5.70e-05
2025-03-02 15:19:55,422 - INFO - ðŸªœ Batch step - 2019 -- sub batch step 8078 -- lr 5.70e-05
2025-03-02 15:19:57,576 - INFO - ðŸªœ Batch step - 2019 -- sub batch step 8079 -- lr 5.70e-05
2025-03-02 15:19:59,439 - INFO - Step 2019 -- ðŸ”„ Training Metrics
2025-03-02 15:19:59,439 - INFO - â”œâ”€â”€ Loss: 7.0475
2025-03-02 15:19:59,440 - INFO - â”œâ”€â”€ Learning Rate: 5.70e-05
2025-03-02 15:19:59,440 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:20:00,613 - INFO - ðŸªœ Batch step - 2020 -- sub batch step 8080 -- lr 6.00e-05
2025-03-02 15:20:02,768 - INFO - ðŸªœ Batch step - 2020 -- sub batch step 8081 -- lr 6.00e-05
2025-03-02 15:20:04,927 - INFO - ðŸªœ Batch step - 2020 -- sub batch step 8082 -- lr 6.00e-05
2025-03-02 15:20:07,101 - INFO - ðŸªœ Batch step - 2020 -- sub batch step 8083 -- lr 6.00e-05
2025-03-02 15:20:08,785 - INFO - Step 2020 -- ðŸ”„ Training Metrics
2025-03-02 15:20:08,786 - INFO - â”œâ”€â”€ Loss: 7.0635
2025-03-02 15:20:08,786 - INFO - â”œâ”€â”€ Learning Rate: 6.00e-05
2025-03-02 15:20:08,786 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:20:09,463 - INFO - ðŸªœ Batch step - 2021 -- sub batch step 8084 -- lr 6.30e-05
2025-03-02 15:20:11,622 - INFO - ðŸªœ Batch step - 2021 -- sub batch step 8085 -- lr 6.30e-05
2025-03-02 15:20:13,773 - INFO - ðŸªœ Batch step - 2021 -- sub batch step 8086 -- lr 6.30e-05
2025-03-02 15:20:16,402 - INFO - ðŸªœ Batch step - 2021 -- sub batch step 8087 -- lr 6.30e-05
2025-03-02 15:20:17,994 - INFO - Step 2021 -- ðŸ”„ Training Metrics
2025-03-02 15:20:17,994 - INFO - â”œâ”€â”€ Loss: 7.0715
2025-03-02 15:20:17,994 - INFO - â”œâ”€â”€ Learning Rate: 6.30e-05
2025-03-02 15:20:17,994 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:20:18,661 - INFO - ðŸªœ Batch step - 2022 -- sub batch step 8088 -- lr 6.60e-05
2025-03-02 15:20:20,822 - INFO - ðŸªœ Batch step - 2022 -- sub batch step 8089 -- lr 6.60e-05
2025-03-02 15:20:22,978 - INFO - ðŸªœ Batch step - 2022 -- sub batch step 8090 -- lr 6.60e-05
2025-03-02 15:20:25,147 - INFO - ðŸªœ Batch step - 2022 -- sub batch step 8091 -- lr 6.60e-05
2025-03-02 15:20:26,686 - INFO - Step 2022 -- ðŸ”„ Training Metrics
2025-03-02 15:20:26,686 - INFO - â”œâ”€â”€ Loss: 7.0654
2025-03-02 15:20:26,686 - INFO - â”œâ”€â”€ Learning Rate: 6.60e-05
2025-03-02 15:20:26,686 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:20:27,361 - INFO - ðŸªœ Batch step - 2023 -- sub batch step 8092 -- lr 6.90e-05
2025-03-02 15:20:29,516 - INFO - ðŸªœ Batch step - 2023 -- sub batch step 8093 -- lr 6.90e-05
2025-03-02 15:20:31,671 - INFO - ðŸªœ Batch step - 2023 -- sub batch step 8094 -- lr 6.90e-05
2025-03-02 15:20:34,274 - INFO - ðŸªœ Batch step - 2023 -- sub batch step 8095 -- lr 6.90e-05
2025-03-02 15:20:35,908 - INFO - Step 2023 -- ðŸ”„ Training Metrics
2025-03-02 15:20:35,909 - INFO - â”œâ”€â”€ Loss: 7.0714
2025-03-02 15:20:35,909 - INFO - â”œâ”€â”€ Learning Rate: 6.90e-05
2025-03-02 15:20:35,909 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:20:36,576 - INFO - ðŸªœ Batch step - 2024 -- sub batch step 8096 -- lr 7.20e-05
2025-03-02 15:20:38,734 - INFO - ðŸªœ Batch step - 2024 -- sub batch step 8097 -- lr 7.20e-05
2025-03-02 15:20:40,883 - INFO - ðŸªœ Batch step - 2024 -- sub batch step 8098 -- lr 7.20e-05
2025-03-02 15:20:43,051 - INFO - ðŸªœ Batch step - 2024 -- sub batch step 8099 -- lr 7.20e-05
2025-03-02 15:20:44,601 - INFO - Step 2024 -- ðŸ”„ Training Metrics
2025-03-02 15:20:44,601 - INFO - â”œâ”€â”€ Loss: 7.0620
2025-03-02 15:20:44,601 - INFO - â”œâ”€â”€ Learning Rate: 7.20e-05
2025-03-02 15:20:44,602 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:20:45,278 - INFO - ðŸªœ Batch step - 2025 -- sub batch step 8100 -- lr 7.50e-05
2025-03-02 15:20:47,428 - INFO - ðŸªœ Batch step - 2025 -- sub batch step 8101 -- lr 7.50e-05
2025-03-02 15:20:49,581 - INFO - ðŸªœ Batch step - 2025 -- sub batch step 8102 -- lr 7.50e-05
2025-03-02 15:20:52,420 - INFO - ðŸªœ Batch step - 2025 -- sub batch step 8103 -- lr 7.50e-05
2025-03-02 15:20:53,920 - INFO - Step 2025 -- ðŸ”„ Training Metrics
2025-03-02 15:20:53,921 - INFO - â”œâ”€â”€ Loss: 7.0430
2025-03-02 15:20:53,921 - INFO - â”œâ”€â”€ Learning Rate: 7.50e-05
2025-03-02 15:20:53,921 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:20:54,599 - INFO - ðŸªœ Batch step - 2026 -- sub batch step 8104 -- lr 7.80e-05
2025-03-02 15:20:56,754 - INFO - ðŸªœ Batch step - 2026 -- sub batch step 8105 -- lr 7.80e-05
2025-03-02 15:20:58,903 - INFO - ðŸªœ Batch step - 2026 -- sub batch step 8106 -- lr 7.80e-05
2025-03-02 15:21:01,075 - INFO - ðŸªœ Batch step - 2026 -- sub batch step 8107 -- lr 7.80e-05
2025-03-02 15:21:02,611 - INFO - Step 2026 -- ðŸ”„ Training Metrics
2025-03-02 15:21:02,611 - INFO - â”œâ”€â”€ Loss: 7.0353
2025-03-02 15:21:02,611 - INFO - â”œâ”€â”€ Learning Rate: 7.80e-05
2025-03-02 15:21:02,612 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:21:03,282 - INFO - ðŸªœ Batch step - 2027 -- sub batch step 8108 -- lr 8.10e-05
2025-03-02 15:21:05,442 - INFO - ðŸªœ Batch step - 2027 -- sub batch step 8109 -- lr 8.10e-05
2025-03-02 15:21:07,599 - INFO - ðŸªœ Batch step - 2027 -- sub batch step 8110 -- lr 8.10e-05
2025-03-02 15:21:10,230 - INFO - ðŸªœ Batch step - 2027 -- sub batch step 8111 -- lr 8.10e-05
2025-03-02 15:21:11,729 - INFO - Step 2027 -- ðŸ”„ Training Metrics
2025-03-02 15:21:11,729 - INFO - â”œâ”€â”€ Loss: 7.0410
2025-03-02 15:21:11,729 - INFO - â”œâ”€â”€ Learning Rate: 8.10e-05
2025-03-02 15:21:11,729 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:21:12,402 - INFO - ðŸªœ Batch step - 2028 -- sub batch step 8112 -- lr 8.40e-05
2025-03-02 15:21:14,558 - INFO - ðŸªœ Batch step - 2028 -- sub batch step 8113 -- lr 8.40e-05
2025-03-02 15:21:16,712 - INFO - ðŸªœ Batch step - 2028 -- sub batch step 8114 -- lr 8.40e-05
2025-03-02 15:21:18,888 - INFO - ðŸªœ Batch step - 2028 -- sub batch step 8115 -- lr 8.40e-05
2025-03-02 15:21:20,426 - INFO - Step 2028 -- ðŸ”„ Training Metrics
2025-03-02 15:21:20,426 - INFO - â”œâ”€â”€ Loss: 7.0308
2025-03-02 15:21:20,427 - INFO - â”œâ”€â”€ Learning Rate: 8.40e-05
2025-03-02 15:21:20,427 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:21:21,099 - INFO - ðŸªœ Batch step - 2029 -- sub batch step 8116 -- lr 8.70e-05
2025-03-02 15:21:23,261 - INFO - ðŸªœ Batch step - 2029 -- sub batch step 8117 -- lr 8.70e-05
2025-03-02 15:21:25,411 - INFO - ðŸªœ Batch step - 2029 -- sub batch step 8118 -- lr 8.70e-05
2025-03-02 15:21:27,833 - INFO - ðŸªœ Batch step - 2029 -- sub batch step 8119 -- lr 8.70e-05
2025-03-02 15:21:29,651 - INFO - Step 2029 -- ðŸ”„ Training Metrics
2025-03-02 15:21:29,652 - INFO - â”œâ”€â”€ Loss: 7.0440
2025-03-02 15:21:29,652 - INFO - â”œâ”€â”€ Learning Rate: 8.70e-05
2025-03-02 15:21:29,652 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:21:30,332 - INFO - ðŸªœ Batch step - 2030 -- sub batch step 8120 -- lr 9.00e-05
2025-03-02 15:21:32,480 - INFO - ðŸªœ Batch step - 2030 -- sub batch step 8121 -- lr 9.00e-05
2025-03-02 15:21:34,637 - INFO - ðŸªœ Batch step - 2030 -- sub batch step 8122 -- lr 9.00e-05
2025-03-02 15:21:36,802 - INFO - ðŸªœ Batch step - 2030 -- sub batch step 8123 -- lr 9.00e-05
2025-03-02 15:21:38,337 - INFO - Step 2030 -- ðŸ”„ Training Metrics
2025-03-02 15:21:38,337 - INFO - â”œâ”€â”€ Loss: 7.0280
2025-03-02 15:21:38,337 - INFO - â”œâ”€â”€ Learning Rate: 9.00e-05
2025-03-02 15:21:38,338 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:21:39,017 - INFO - ðŸªœ Batch step - 2031 -- sub batch step 8124 -- lr 9.30e-05
2025-03-02 15:21:41,176 - INFO - ðŸªœ Batch step - 2031 -- sub batch step 8125 -- lr 9.30e-05
2025-03-02 15:21:43,960 - INFO - ðŸªœ Batch step - 2031 -- sub batch step 8126 -- lr 9.30e-05
2025-03-02 15:21:46,122 - INFO - ðŸªœ Batch step - 2031 -- sub batch step 8127 -- lr 9.30e-05
2025-03-02 15:21:47,615 - INFO - Step 2031 -- ðŸ”„ Training Metrics
2025-03-02 15:21:47,615 - INFO - â”œâ”€â”€ Loss: 7.0219
2025-03-02 15:21:47,615 - INFO - â”œâ”€â”€ Learning Rate: 9.30e-05
2025-03-02 15:21:47,615 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:21:48,286 - INFO - ðŸªœ Batch step - 2032 -- sub batch step 8128 -- lr 9.60e-05
2025-03-02 15:21:50,449 - INFO - ðŸªœ Batch step - 2032 -- sub batch step 8129 -- lr 9.60e-05
2025-03-02 15:21:52,626 - INFO - ðŸªœ Batch step - 2032 -- sub batch step 8130 -- lr 9.60e-05
2025-03-02 15:21:54,777 - INFO - ðŸªœ Batch step - 2032 -- sub batch step 8131 -- lr 9.60e-05
2025-03-02 15:21:56,302 - INFO - Step 2032 -- ðŸ”„ Training Metrics
2025-03-02 15:21:56,302 - INFO - â”œâ”€â”€ Loss: 7.0273
2025-03-02 15:21:56,302 - INFO - â”œâ”€â”€ Learning Rate: 9.60e-05
2025-03-02 15:21:56,302 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:21:56,982 - INFO - ðŸªœ Batch step - 2033 -- sub batch step 8132 -- lr 9.90e-05
2025-03-02 15:21:59,132 - INFO - ðŸªœ Batch step - 2033 -- sub batch step 8133 -- lr 9.90e-05
2025-03-02 15:22:01,799 - INFO - ðŸªœ Batch step - 2033 -- sub batch step 8134 -- lr 9.90e-05
2025-03-02 15:22:03,965 - INFO - ðŸªœ Batch step - 2033 -- sub batch step 8135 -- lr 9.90e-05
2025-03-02 15:22:05,604 - INFO - Step 2033 -- ðŸ”„ Training Metrics
2025-03-02 15:22:05,604 - INFO - â”œâ”€â”€ Loss: 7.0315
2025-03-02 15:22:05,605 - INFO - â”œâ”€â”€ Learning Rate: 9.90e-05
2025-03-02 15:22:05,605 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:22:06,276 - INFO - ðŸªœ Batch step - 2034 -- sub batch step 8136 -- lr 1.02e-04
2025-03-02 15:22:08,434 - INFO - ðŸªœ Batch step - 2034 -- sub batch step 8137 -- lr 1.02e-04
2025-03-02 15:22:10,599 - INFO - ðŸªœ Batch step - 2034 -- sub batch step 8138 -- lr 1.02e-04
2025-03-02 15:22:12,754 - INFO - ðŸªœ Batch step - 2034 -- sub batch step 8139 -- lr 1.02e-04
2025-03-02 15:22:14,297 - INFO - Step 2034 -- ðŸ”„ Training Metrics
2025-03-02 15:22:14,298 - INFO - â”œâ”€â”€ Loss: 7.0565
2025-03-02 15:22:14,298 - INFO - â”œâ”€â”€ Learning Rate: 1.02e-04
2025-03-02 15:22:14,298 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:22:14,969 - INFO - ðŸªœ Batch step - 2035 -- sub batch step 8140 -- lr 1.05e-04
2025-03-02 15:22:17,125 - INFO - ðŸªœ Batch step - 2035 -- sub batch step 8141 -- lr 1.05e-04
2025-03-02 15:22:19,944 - INFO - ðŸªœ Batch step - 2035 -- sub batch step 8142 -- lr 1.05e-04
2025-03-02 15:22:22,108 - INFO - ðŸªœ Batch step - 2035 -- sub batch step 8143 -- lr 1.05e-04
2025-03-02 15:22:23,634 - INFO - Step 2035 -- ðŸ”„ Training Metrics
2025-03-02 15:22:23,634 - INFO - â”œâ”€â”€ Loss: 7.0122
2025-03-02 15:22:23,634 - INFO - â”œâ”€â”€ Learning Rate: 1.05e-04
2025-03-02 15:22:23,634 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:22:24,311 - INFO - ðŸªœ Batch step - 2036 -- sub batch step 8144 -- lr 1.08e-04
2025-03-02 15:22:26,467 - INFO - ðŸªœ Batch step - 2036 -- sub batch step 8145 -- lr 1.08e-04
2025-03-02 15:22:28,634 - INFO - ðŸªœ Batch step - 2036 -- sub batch step 8146 -- lr 1.08e-04
2025-03-02 15:22:30,788 - INFO - ðŸªœ Batch step - 2036 -- sub batch step 8147 -- lr 1.08e-04
2025-03-02 15:22:32,337 - INFO - Step 2036 -- ðŸ”„ Training Metrics
2025-03-02 15:22:32,337 - INFO - â”œâ”€â”€ Loss: 7.0065
2025-03-02 15:22:32,338 - INFO - â”œâ”€â”€ Learning Rate: 1.08e-04
2025-03-02 15:22:32,338 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:22:33,012 - INFO - ðŸªœ Batch step - 2037 -- sub batch step 8148 -- lr 1.11e-04
2025-03-02 15:22:35,174 - INFO - ðŸªœ Batch step - 2037 -- sub batch step 8149 -- lr 1.11e-04
2025-03-02 15:22:37,806 - INFO - ðŸªœ Batch step - 2037 -- sub batch step 8150 -- lr 1.11e-04
2025-03-02 15:22:39,968 - INFO - ðŸªœ Batch step - 2037 -- sub batch step 8151 -- lr 1.11e-04
2025-03-02 15:22:41,459 - INFO - Step 2037 -- ðŸ”„ Training Metrics
2025-03-02 15:22:41,460 - INFO - â”œâ”€â”€ Loss: 6.9893
2025-03-02 15:22:41,460 - INFO - â”œâ”€â”€ Learning Rate: 1.11e-04
2025-03-02 15:22:41,460 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:22:42,135 - INFO - ðŸªœ Batch step - 2038 -- sub batch step 8152 -- lr 1.14e-04
2025-03-02 15:22:44,288 - INFO - ðŸªœ Batch step - 2038 -- sub batch step 8153 -- lr 1.14e-04
2025-03-02 15:22:46,459 - INFO - ðŸªœ Batch step - 2038 -- sub batch step 8154 -- lr 1.14e-04
2025-03-02 15:22:48,618 - INFO - ðŸªœ Batch step - 2038 -- sub batch step 8155 -- lr 1.14e-04
2025-03-02 15:22:50,169 - INFO - Step 2038 -- ðŸ”„ Training Metrics
2025-03-02 15:22:50,169 - INFO - â”œâ”€â”€ Loss: 7.0267
2025-03-02 15:22:50,169 - INFO - â”œâ”€â”€ Learning Rate: 1.14e-04
2025-03-02 15:22:50,169 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:22:50,844 - INFO - ðŸªœ Batch step - 2039 -- sub batch step 8156 -- lr 1.17e-04
2025-03-02 15:22:53,002 - INFO - ðŸªœ Batch step - 2039 -- sub batch step 8157 -- lr 1.17e-04
2025-03-02 15:22:55,293 - INFO - ðŸªœ Batch step - 2039 -- sub batch step 8158 -- lr 1.17e-04
2025-03-02 15:22:57,449 - INFO - ðŸªœ Batch step - 2039 -- sub batch step 8159 -- lr 1.17e-04
2025-03-02 15:22:59,026 - INFO - Step 2039 -- ðŸ”„ Training Metrics
2025-03-02 15:22:59,027 - INFO - â”œâ”€â”€ Loss: 6.9994
2025-03-02 15:22:59,027 - INFO - â”œâ”€â”€ Learning Rate: 1.17e-04
2025-03-02 15:22:59,027 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:23:00,194 - INFO - ðŸªœ Batch step - 2040 -- sub batch step 8160 -- lr 1.20e-04
2025-03-02 15:23:02,355 - INFO - ðŸªœ Batch step - 2040 -- sub batch step 8161 -- lr 1.20e-04
2025-03-02 15:23:04,521 - INFO - ðŸªœ Batch step - 2040 -- sub batch step 8162 -- lr 1.20e-04
2025-03-02 15:23:06,699 - INFO - ðŸªœ Batch step - 2040 -- sub batch step 8163 -- lr 1.20e-04
2025-03-02 15:23:08,329 - INFO - Step 2040 -- ðŸ”„ Training Metrics
2025-03-02 15:23:08,329 - INFO - â”œâ”€â”€ Loss: 6.9931
2025-03-02 15:23:08,329 - INFO - â”œâ”€â”€ Learning Rate: 1.20e-04
2025-03-02 15:23:08,329 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:23:09,010 - INFO - ðŸªœ Batch step - 2041 -- sub batch step 8164 -- lr 1.23e-04
2025-03-02 15:23:11,167 - INFO - ðŸªœ Batch step - 2041 -- sub batch step 8165 -- lr 1.23e-04
2025-03-02 15:23:13,321 - INFO - ðŸªœ Batch step - 2041 -- sub batch step 8166 -- lr 1.23e-04
2025-03-02 15:23:15,756 - INFO - ðŸªœ Batch step - 2041 -- sub batch step 8167 -- lr 1.23e-04
2025-03-02 15:23:17,571 - INFO - Step 2041 -- ðŸ”„ Training Metrics
2025-03-02 15:23:17,571 - INFO - â”œâ”€â”€ Loss: 6.9876
2025-03-02 15:23:17,571 - INFO - â”œâ”€â”€ Learning Rate: 1.23e-04
2025-03-02 15:23:17,571 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:23:18,240 - INFO - ðŸªœ Batch step - 2042 -- sub batch step 8168 -- lr 1.26e-04
2025-03-02 15:23:20,395 - INFO - ðŸªœ Batch step - 2042 -- sub batch step 8169 -- lr 1.26e-04
2025-03-02 15:23:22,548 - INFO - ðŸªœ Batch step - 2042 -- sub batch step 8170 -- lr 1.26e-04
2025-03-02 15:23:24,713 - INFO - ðŸªœ Batch step - 2042 -- sub batch step 8171 -- lr 1.26e-04
2025-03-02 15:23:26,263 - INFO - Step 2042 -- ðŸ”„ Training Metrics
2025-03-02 15:23:26,264 - INFO - â”œâ”€â”€ Loss: 6.9886
2025-03-02 15:23:26,264 - INFO - â”œâ”€â”€ Learning Rate: 1.26e-04
2025-03-02 15:23:26,264 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:23:26,936 - INFO - ðŸªœ Batch step - 2043 -- sub batch step 8172 -- lr 1.29e-04
2025-03-02 15:23:29,085 - INFO - ðŸªœ Batch step - 2043 -- sub batch step 8173 -- lr 1.29e-04
2025-03-02 15:23:31,242 - INFO - ðŸªœ Batch step - 2043 -- sub batch step 8174 -- lr 1.29e-04
2025-03-02 15:23:33,920 - INFO - ðŸªœ Batch step - 2043 -- sub batch step 8175 -- lr 1.29e-04
2025-03-02 15:23:35,433 - INFO - Step 2043 -- ðŸ”„ Training Metrics
2025-03-02 15:23:35,433 - INFO - â”œâ”€â”€ Loss: 6.9859
2025-03-02 15:23:35,433 - INFO - â”œâ”€â”€ Learning Rate: 1.29e-04
2025-03-02 15:23:35,433 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:23:36,099 - INFO - ðŸªœ Batch step - 2044 -- sub batch step 8176 -- lr 1.32e-04
2025-03-02 15:23:38,258 - INFO - ðŸªœ Batch step - 2044 -- sub batch step 8177 -- lr 1.32e-04
2025-03-02 15:23:40,409 - INFO - ðŸªœ Batch step - 2044 -- sub batch step 8178 -- lr 1.32e-04
2025-03-02 15:23:42,583 - INFO - ðŸªœ Batch step - 2044 -- sub batch step 8179 -- lr 1.32e-04
2025-03-02 15:23:44,129 - INFO - Step 2044 -- ðŸ”„ Training Metrics
2025-03-02 15:23:44,130 - INFO - â”œâ”€â”€ Loss: 6.9804
2025-03-02 15:23:44,130 - INFO - â”œâ”€â”€ Learning Rate: 1.32e-04
2025-03-02 15:23:44,130 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:23:44,801 - INFO - ðŸªœ Batch step - 2045 -- sub batch step 8180 -- lr 1.35e-04
2025-03-02 15:23:46,948 - INFO - ðŸªœ Batch step - 2045 -- sub batch step 8181 -- lr 1.35e-04
2025-03-02 15:23:49,101 - INFO - ðŸªœ Batch step - 2045 -- sub batch step 8182 -- lr 1.35e-04
2025-03-02 15:23:51,771 - INFO - ðŸªœ Batch step - 2045 -- sub batch step 8183 -- lr 1.35e-04
2025-03-02 15:23:53,401 - INFO - Step 2045 -- ðŸ”„ Training Metrics
2025-03-02 15:23:53,401 - INFO - â”œâ”€â”€ Loss: 6.9530
2025-03-02 15:23:53,401 - INFO - â”œâ”€â”€ Learning Rate: 1.35e-04
2025-03-02 15:23:53,402 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:23:54,072 - INFO - ðŸªœ Batch step - 2046 -- sub batch step 8184 -- lr 1.38e-04
2025-03-02 15:23:56,226 - INFO - ðŸªœ Batch step - 2046 -- sub batch step 8185 -- lr 1.38e-04
2025-03-02 15:23:58,374 - INFO - ðŸªœ Batch step - 2046 -- sub batch step 8186 -- lr 1.38e-04
2025-03-02 15:24:00,546 - INFO - ðŸªœ Batch step - 2046 -- sub batch step 8187 -- lr 1.38e-04
2025-03-02 15:24:02,091 - INFO - Step 2046 -- ðŸ”„ Training Metrics
2025-03-02 15:24:02,091 - INFO - â”œâ”€â”€ Loss: 6.9728
2025-03-02 15:24:02,091 - INFO - â”œâ”€â”€ Learning Rate: 1.38e-04
2025-03-02 15:24:02,091 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:24:02,756 - INFO - ðŸªœ Batch step - 2047 -- sub batch step 8188 -- lr 1.41e-04
2025-03-02 15:24:04,913 - INFO - ðŸªœ Batch step - 2047 -- sub batch step 8189 -- lr 1.41e-04
2025-03-02 15:24:07,066 - INFO - ðŸªœ Batch step - 2047 -- sub batch step 8190 -- lr 1.41e-04
2025-03-02 15:24:09,735 - INFO - ðŸªœ Batch step - 2047 -- sub batch step 8191 -- lr 1.41e-04
2025-03-02 15:24:11,303 - INFO - Step 2047 -- ðŸ”„ Training Metrics
2025-03-02 15:24:11,304 - INFO - â”œâ”€â”€ Loss: 6.9868
2025-03-02 15:24:11,304 - INFO - â”œâ”€â”€ Learning Rate: 1.41e-04
2025-03-02 15:24:11,304 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:24:11,978 - INFO - ðŸªœ Batch step - 2048 -- sub batch step 8192 -- lr 1.44e-04
2025-03-02 15:24:14,126 - INFO - ðŸªœ Batch step - 2048 -- sub batch step 8193 -- lr 1.44e-04
2025-03-02 15:24:16,284 - INFO - ðŸªœ Batch step - 2048 -- sub batch step 8194 -- lr 1.44e-04
2025-03-02 15:24:18,454 - INFO - ðŸªœ Batch step - 2048 -- sub batch step 8195 -- lr 1.44e-04
2025-03-02 15:24:20,003 - INFO - Step 2048 -- ðŸ”„ Training Metrics
2025-03-02 15:24:20,003 - INFO - â”œâ”€â”€ Loss: 6.9762
2025-03-02 15:24:20,003 - INFO - â”œâ”€â”€ Learning Rate: 1.44e-04
2025-03-02 15:24:20,003 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:24:20,669 - INFO - ðŸªœ Batch step - 2049 -- sub batch step 8196 -- lr 1.47e-04
2025-03-02 15:24:22,824 - INFO - ðŸªœ Batch step - 2049 -- sub batch step 8197 -- lr 1.47e-04
2025-03-02 15:24:24,976 - INFO - ðŸªœ Batch step - 2049 -- sub batch step 8198 -- lr 1.47e-04
2025-03-02 15:24:27,633 - INFO - ðŸªœ Batch step - 2049 -- sub batch step 8199 -- lr 1.47e-04
2025-03-02 15:24:29,294 - INFO - Step 2049 -- ðŸ”„ Training Metrics
2025-03-02 15:24:29,294 - INFO - â”œâ”€â”€ Loss: 6.9739
2025-03-02 15:24:29,294 - INFO - â”œâ”€â”€ Learning Rate: 1.47e-04
2025-03-02 15:24:29,294 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:24:29,969 - INFO - ðŸªœ Batch step - 2050 -- sub batch step 8200 -- lr 1.50e-04
2025-03-02 15:24:32,121 - INFO - ðŸªœ Batch step - 2050 -- sub batch step 8201 -- lr 1.50e-04
2025-03-02 15:24:34,276 - INFO - ðŸªœ Batch step - 2050 -- sub batch step 8202 -- lr 1.50e-04
2025-03-02 15:24:36,435 - INFO - ðŸªœ Batch step - 2050 -- sub batch step 8203 -- lr 1.50e-04
2025-03-02 15:24:37,971 - INFO - Step 2050 -- ðŸ”„ Training Metrics
2025-03-02 15:24:37,972 - INFO - â”œâ”€â”€ Loss: 6.9576
2025-03-02 15:24:37,972 - INFO - â”œâ”€â”€ Learning Rate: 1.50e-04
2025-03-02 15:24:37,972 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:24:38,645 - INFO - ðŸªœ Batch step - 2051 -- sub batch step 8204 -- lr 1.53e-04
2025-03-02 15:24:40,799 - INFO - ðŸªœ Batch step - 2051 -- sub batch step 8205 -- lr 1.53e-04
2025-03-02 15:24:43,660 - INFO - ðŸªœ Batch step - 2051 -- sub batch step 8206 -- lr 1.53e-04
2025-03-02 15:24:45,822 - INFO - ðŸªœ Batch step - 2051 -- sub batch step 8207 -- lr 1.53e-04
2025-03-02 15:24:47,384 - INFO - Step 2051 -- ðŸ”„ Training Metrics
2025-03-02 15:24:47,384 - INFO - â”œâ”€â”€ Loss: 6.9398
2025-03-02 15:24:47,384 - INFO - â”œâ”€â”€ Learning Rate: 1.53e-04
2025-03-02 15:24:47,385 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:24:48,056 - INFO - ðŸªœ Batch step - 2052 -- sub batch step 8208 -- lr 1.56e-04
2025-03-02 15:24:50,212 - INFO - ðŸªœ Batch step - 2052 -- sub batch step 8209 -- lr 1.56e-04
2025-03-02 15:24:52,381 - INFO - ðŸªœ Batch step - 2052 -- sub batch step 8210 -- lr 1.56e-04
2025-03-02 15:24:54,528 - INFO - ðŸªœ Batch step - 2052 -- sub batch step 8211 -- lr 1.56e-04
2025-03-02 15:24:56,074 - INFO - Step 2052 -- ðŸ”„ Training Metrics
2025-03-02 15:24:56,074 - INFO - â”œâ”€â”€ Loss: 6.9487
2025-03-02 15:24:56,074 - INFO - â”œâ”€â”€ Learning Rate: 1.56e-04
2025-03-02 15:24:56,074 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:24:56,749 - INFO - ðŸªœ Batch step - 2053 -- sub batch step 8212 -- lr 1.59e-04
2025-03-02 15:24:58,897 - INFO - ðŸªœ Batch step - 2053 -- sub batch step 8213 -- lr 1.59e-04
2025-03-02 15:25:01,657 - INFO - ðŸªœ Batch step - 2053 -- sub batch step 8214 -- lr 1.59e-04
2025-03-02 15:25:03,818 - INFO - ðŸªœ Batch step - 2053 -- sub batch step 8215 -- lr 1.59e-04
2025-03-02 15:25:05,309 - INFO - Step 2053 -- ðŸ”„ Training Metrics
2025-03-02 15:25:05,309 - INFO - â”œâ”€â”€ Loss: 6.9632
2025-03-02 15:25:05,310 - INFO - â”œâ”€â”€ Learning Rate: 1.59e-04
2025-03-02 15:25:05,310 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:25:05,976 - INFO - ðŸªœ Batch step - 2054 -- sub batch step 8216 -- lr 1.62e-04
2025-03-02 15:25:08,130 - INFO - ðŸªœ Batch step - 2054 -- sub batch step 8217 -- lr 1.62e-04
2025-03-02 15:25:10,294 - INFO - ðŸªœ Batch step - 2054 -- sub batch step 8218 -- lr 1.62e-04
2025-03-02 15:25:12,447 - INFO - ðŸªœ Batch step - 2054 -- sub batch step 8219 -- lr 1.62e-04
2025-03-02 15:25:13,999 - INFO - Step 2054 -- ðŸ”„ Training Metrics
2025-03-02 15:25:13,999 - INFO - â”œâ”€â”€ Loss: 6.9049
2025-03-02 15:25:13,999 - INFO - â”œâ”€â”€ Learning Rate: 1.62e-04
2025-03-02 15:25:13,999 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:25:14,673 - INFO - ðŸªœ Batch step - 2055 -- sub batch step 8220 -- lr 1.65e-04
2025-03-02 15:25:16,821 - INFO - ðŸªœ Batch step - 2055 -- sub batch step 8221 -- lr 1.65e-04
2025-03-02 15:25:19,517 - INFO - ðŸªœ Batch step - 2055 -- sub batch step 8222 -- lr 1.65e-04
2025-03-02 15:25:21,667 - INFO - ðŸªœ Batch step - 2055 -- sub batch step 8223 -- lr 1.65e-04
2025-03-02 15:25:23,265 - INFO - Step 2055 -- ðŸ”„ Training Metrics
2025-03-02 15:25:23,265 - INFO - â”œâ”€â”€ Loss: 6.9768
2025-03-02 15:25:23,265 - INFO - â”œâ”€â”€ Learning Rate: 1.65e-04
2025-03-02 15:25:23,265 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:25:23,938 - INFO - ðŸªœ Batch step - 2056 -- sub batch step 8224 -- lr 1.68e-04
2025-03-02 15:25:26,092 - INFO - ðŸªœ Batch step - 2056 -- sub batch step 8225 -- lr 1.68e-04
2025-03-02 15:25:28,257 - INFO - ðŸªœ Batch step - 2056 -- sub batch step 8226 -- lr 1.68e-04
2025-03-02 15:25:30,409 - INFO - ðŸªœ Batch step - 2056 -- sub batch step 8227 -- lr 1.68e-04
2025-03-02 15:25:31,955 - INFO - Step 2056 -- ðŸ”„ Training Metrics
2025-03-02 15:25:31,955 - INFO - â”œâ”€â”€ Loss: 6.9653
2025-03-02 15:25:31,956 - INFO - â”œâ”€â”€ Learning Rate: 1.68e-04
2025-03-02 15:25:31,956 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:25:32,625 - INFO - ðŸªœ Batch step - 2057 -- sub batch step 8228 -- lr 1.71e-04
2025-03-02 15:25:34,779 - INFO - ðŸªœ Batch step - 2057 -- sub batch step 8229 -- lr 1.71e-04
2025-03-02 15:25:37,148 - INFO - ðŸªœ Batch step - 2057 -- sub batch step 8230 -- lr 1.71e-04
2025-03-02 15:25:39,302 - INFO - ðŸªœ Batch step - 2057 -- sub batch step 8231 -- lr 1.71e-04
2025-03-02 15:25:41,130 - INFO - Step 2057 -- ðŸ”„ Training Metrics
2025-03-02 15:25:41,131 - INFO - â”œâ”€â”€ Loss: 6.9444
2025-03-02 15:25:41,131 - INFO - â”œâ”€â”€ Learning Rate: 1.71e-04
2025-03-02 15:25:41,131 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:25:41,807 - INFO - ðŸªœ Batch step - 2058 -- sub batch step 8232 -- lr 1.74e-04
2025-03-02 15:25:43,958 - INFO - ðŸªœ Batch step - 2058 -- sub batch step 8233 -- lr 1.74e-04
2025-03-02 15:25:46,130 - INFO - ðŸªœ Batch step - 2058 -- sub batch step 8234 -- lr 1.74e-04
2025-03-02 15:25:48,284 - INFO - ðŸªœ Batch step - 2058 -- sub batch step 8235 -- lr 1.74e-04
2025-03-02 15:25:49,830 - INFO - Step 2058 -- ðŸ”„ Training Metrics
2025-03-02 15:25:49,831 - INFO - â”œâ”€â”€ Loss: 6.9609
2025-03-02 15:25:49,831 - INFO - â”œâ”€â”€ Learning Rate: 1.74e-04
2025-03-02 15:25:49,831 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:25:50,502 - INFO - ðŸªœ Batch step - 2059 -- sub batch step 8236 -- lr 1.77e-04
2025-03-02 15:25:52,656 - INFO - ðŸªœ Batch step - 2059 -- sub batch step 8237 -- lr 1.77e-04
2025-03-02 15:25:54,930 - INFO - ðŸªœ Batch step - 2059 -- sub batch step 8238 -- lr 1.77e-04
2025-03-02 15:25:57,083 - INFO - ðŸªœ Batch step - 2059 -- sub batch step 8239 -- lr 1.77e-04
2025-03-02 15:25:58,786 - INFO - Step 2059 -- ðŸ”„ Training Metrics
2025-03-02 15:25:58,786 - INFO - â”œâ”€â”€ Loss: 6.9308
2025-03-02 15:25:58,786 - INFO - â”œâ”€â”€ Learning Rate: 1.77e-04
2025-03-02 15:25:58,786 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:25:59,943 - INFO - ðŸªœ Batch step - 2060 -- sub batch step 8240 -- lr 1.80e-04
2025-03-02 15:26:02,097 - INFO - ðŸªœ Batch step - 2060 -- sub batch step 8241 -- lr 1.80e-04
2025-03-02 15:26:04,255 - INFO - ðŸªœ Batch step - 2060 -- sub batch step 8242 -- lr 1.80e-04
2025-03-02 15:26:06,423 - INFO - ðŸªœ Batch step - 2060 -- sub batch step 8243 -- lr 1.80e-04
2025-03-02 15:26:08,086 - INFO - Step 2060 -- ðŸ”„ Training Metrics
2025-03-02 15:26:08,086 - INFO - â”œâ”€â”€ Loss: 6.9349
2025-03-02 15:26:08,086 - INFO - â”œâ”€â”€ Learning Rate: 1.80e-04
2025-03-02 15:26:08,087 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:26:08,759 - INFO - ðŸªœ Batch step - 2061 -- sub batch step 8244 -- lr 1.83e-04
2025-03-02 15:26:10,912 - INFO - ðŸªœ Batch step - 2061 -- sub batch step 8245 -- lr 1.83e-04
2025-03-02 15:26:13,062 - INFO - ðŸªœ Batch step - 2061 -- sub batch step 8246 -- lr 1.83e-04
2025-03-02 15:26:15,727 - INFO - ðŸªœ Batch step - 2061 -- sub batch step 8247 -- lr 1.83e-04
2025-03-02 15:26:17,326 - INFO - Step 2061 -- ðŸ”„ Training Metrics
2025-03-02 15:26:17,327 - INFO - â”œâ”€â”€ Loss: 6.9239
2025-03-02 15:26:17,327 - INFO - â”œâ”€â”€ Learning Rate: 1.83e-04
2025-03-02 15:26:17,327 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:26:17,995 - INFO - ðŸªœ Batch step - 2062 -- sub batch step 8248 -- lr 1.86e-04
2025-03-02 15:26:20,150 - INFO - ðŸªœ Batch step - 2062 -- sub batch step 8249 -- lr 1.86e-04
2025-03-02 15:26:22,304 - INFO - ðŸªœ Batch step - 2062 -- sub batch step 8250 -- lr 1.86e-04
2025-03-02 15:26:24,469 - INFO - ðŸªœ Batch step - 2062 -- sub batch step 8251 -- lr 1.86e-04
2025-03-02 15:26:26,021 - INFO - Step 2062 -- ðŸ”„ Training Metrics
2025-03-02 15:26:26,021 - INFO - â”œâ”€â”€ Loss: 6.9501
2025-03-02 15:26:26,021 - INFO - â”œâ”€â”€ Learning Rate: 1.86e-04
2025-03-02 15:26:26,021 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:26:26,696 - INFO - ðŸªœ Batch step - 2063 -- sub batch step 8252 -- lr 1.89e-04
2025-03-02 15:26:28,845 - INFO - ðŸªœ Batch step - 2063 -- sub batch step 8253 -- lr 1.89e-04
2025-03-02 15:26:30,997 - INFO - ðŸªœ Batch step - 2063 -- sub batch step 8254 -- lr 1.89e-04
2025-03-02 15:26:33,434 - INFO - ðŸªœ Batch step - 2063 -- sub batch step 8255 -- lr 1.89e-04
2025-03-02 15:26:35,175 - INFO - Step 2063 -- ðŸ”„ Training Metrics
2025-03-02 15:26:35,175 - INFO - â”œâ”€â”€ Loss: 6.9714
2025-03-02 15:26:35,176 - INFO - â”œâ”€â”€ Learning Rate: 1.89e-04
2025-03-02 15:26:35,176 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:26:35,844 - INFO - ðŸªœ Batch step - 2064 -- sub batch step 8256 -- lr 1.92e-04
2025-03-02 15:26:38,001 - INFO - ðŸªœ Batch step - 2064 -- sub batch step 8257 -- lr 1.92e-04
2025-03-02 15:26:40,150 - INFO - ðŸªœ Batch step - 2064 -- sub batch step 8258 -- lr 1.92e-04
2025-03-02 15:26:42,323 - INFO - ðŸªœ Batch step - 2064 -- sub batch step 8259 -- lr 1.92e-04
2025-03-02 15:26:43,871 - INFO - Step 2064 -- ðŸ”„ Training Metrics
2025-03-02 15:26:43,871 - INFO - â”œâ”€â”€ Loss: 6.9200
2025-03-02 15:26:43,872 - INFO - â”œâ”€â”€ Learning Rate: 1.92e-04
2025-03-02 15:26:43,872 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:26:44,546 - INFO - ðŸªœ Batch step - 2065 -- sub batch step 8260 -- lr 1.95e-04
2025-03-02 15:26:46,698 - INFO - ðŸªœ Batch step - 2065 -- sub batch step 8261 -- lr 1.95e-04
2025-03-02 15:26:48,852 - INFO - ðŸªœ Batch step - 2065 -- sub batch step 8262 -- lr 1.95e-04
2025-03-02 15:26:51,547 - INFO - ðŸªœ Batch step - 2065 -- sub batch step 8263 -- lr 1.95e-04
2025-03-02 15:26:53,474 - INFO - Step 2065 -- ðŸ”„ Training Metrics
2025-03-02 15:26:53,474 - INFO - â”œâ”€â”€ Loss: 6.9523
2025-03-02 15:26:53,474 - INFO - â”œâ”€â”€ Learning Rate: 1.95e-04
2025-03-02 15:26:53,475 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:26:54,151 - INFO - ðŸªœ Batch step - 2066 -- sub batch step 8264 -- lr 1.98e-04
2025-03-02 15:26:56,304 - INFO - ðŸªœ Batch step - 2066 -- sub batch step 8265 -- lr 1.98e-04
2025-03-02 15:26:58,450 - INFO - ðŸªœ Batch step - 2066 -- sub batch step 8266 -- lr 1.98e-04
2025-03-02 15:27:00,623 - INFO - ðŸªœ Batch step - 2066 -- sub batch step 8267 -- lr 1.98e-04
2025-03-02 15:27:02,175 - INFO - Step 2066 -- ðŸ”„ Training Metrics
2025-03-02 15:27:02,175 - INFO - â”œâ”€â”€ Loss: 6.9087
2025-03-02 15:27:02,176 - INFO - â”œâ”€â”€ Learning Rate: 1.98e-04
2025-03-02 15:27:02,176 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:27:02,845 - INFO - ðŸªœ Batch step - 2067 -- sub batch step 8268 -- lr 2.01e-04
2025-03-02 15:27:04,999 - INFO - ðŸªœ Batch step - 2067 -- sub batch step 8269 -- lr 2.01e-04
2025-03-02 15:27:07,155 - INFO - ðŸªœ Batch step - 2067 -- sub batch step 8270 -- lr 2.01e-04
2025-03-02 15:27:09,818 - INFO - ðŸªœ Batch step - 2067 -- sub batch step 8271 -- lr 2.01e-04
2025-03-02 15:27:11,416 - INFO - Step 2067 -- ðŸ”„ Training Metrics
2025-03-02 15:27:11,417 - INFO - â”œâ”€â”€ Loss: 6.9281
2025-03-02 15:27:11,417 - INFO - â”œâ”€â”€ Learning Rate: 2.01e-04
2025-03-02 15:27:11,417 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:27:12,090 - INFO - ðŸªœ Batch step - 2068 -- sub batch step 8272 -- lr 2.04e-04
2025-03-02 15:27:14,238 - INFO - ðŸªœ Batch step - 2068 -- sub batch step 8273 -- lr 2.04e-04
2025-03-02 15:27:16,393 - INFO - ðŸªœ Batch step - 2068 -- sub batch step 8274 -- lr 2.04e-04
2025-03-02 15:27:18,561 - INFO - ðŸªœ Batch step - 2068 -- sub batch step 8275 -- lr 2.04e-04
2025-03-02 15:27:20,119 - INFO - Step 2068 -- ðŸ”„ Training Metrics
2025-03-02 15:27:20,119 - INFO - â”œâ”€â”€ Loss: 6.9424
2025-03-02 15:27:20,120 - INFO - â”œâ”€â”€ Learning Rate: 2.04e-04
2025-03-02 15:27:20,120 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:27:20,789 - INFO - ðŸªœ Batch step - 2069 -- sub batch step 8276 -- lr 2.07e-04
2025-03-02 15:27:22,944 - INFO - ðŸªœ Batch step - 2069 -- sub batch step 8277 -- lr 2.07e-04
2025-03-02 15:27:25,093 - INFO - ðŸªœ Batch step - 2069 -- sub batch step 8278 -- lr 2.07e-04
2025-03-02 15:27:27,770 - INFO - ðŸªœ Batch step - 2069 -- sub batch step 8279 -- lr 2.07e-04
2025-03-02 15:27:29,276 - INFO - Step 2069 -- ðŸ”„ Training Metrics
2025-03-02 15:27:29,276 - INFO - â”œâ”€â”€ Loss: 6.9081
2025-03-02 15:27:29,276 - INFO - â”œâ”€â”€ Learning Rate: 2.07e-04
2025-03-02 15:27:29,277 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:27:29,949 - INFO - ðŸªœ Batch step - 2070 -- sub batch step 8280 -- lr 2.10e-04
2025-03-02 15:27:32,099 - INFO - ðŸªœ Batch step - 2070 -- sub batch step 8281 -- lr 2.10e-04
2025-03-02 15:27:34,253 - INFO - ðŸªœ Batch step - 2070 -- sub batch step 8282 -- lr 2.10e-04
2025-03-02 15:27:36,421 - INFO - ðŸªœ Batch step - 2070 -- sub batch step 8283 -- lr 2.10e-04
2025-03-02 15:27:37,972 - INFO - Step 2070 -- ðŸ”„ Training Metrics
2025-03-02 15:27:37,972 - INFO - â”œâ”€â”€ Loss: 6.9017
2025-03-02 15:27:37,972 - INFO - â”œâ”€â”€ Learning Rate: 2.10e-04
2025-03-02 15:27:37,973 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:27:38,649 - INFO - ðŸªœ Batch step - 2071 -- sub batch step 8284 -- lr 2.13e-04
2025-03-02 15:27:40,803 - INFO - ðŸªœ Batch step - 2071 -- sub batch step 8285 -- lr 2.13e-04
2025-03-02 15:27:43,541 - INFO - ðŸªœ Batch step - 2071 -- sub batch step 8286 -- lr 2.13e-04
2025-03-02 15:27:45,702 - INFO - ðŸªœ Batch step - 2071 -- sub batch step 8287 -- lr 2.13e-04
2025-03-02 15:27:47,334 - INFO - Step 2071 -- ðŸ”„ Training Metrics
2025-03-02 15:27:47,334 - INFO - â”œâ”€â”€ Loss: 6.9293
2025-03-02 15:27:47,334 - INFO - â”œâ”€â”€ Learning Rate: 2.13e-04
2025-03-02 15:27:47,335 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:27:48,003 - INFO - ðŸªœ Batch step - 2072 -- sub batch step 8288 -- lr 2.16e-04
2025-03-02 15:27:50,158 - INFO - ðŸªœ Batch step - 2072 -- sub batch step 8289 -- lr 2.16e-04
2025-03-02 15:27:52,329 - INFO - ðŸªœ Batch step - 2072 -- sub batch step 8290 -- lr 2.16e-04
2025-03-02 15:27:54,475 - INFO - ðŸªœ Batch step - 2072 -- sub batch step 8291 -- lr 2.16e-04
2025-03-02 15:27:56,029 - INFO - Step 2072 -- ðŸ”„ Training Metrics
2025-03-02 15:27:56,029 - INFO - â”œâ”€â”€ Loss: 6.8942
2025-03-02 15:27:56,029 - INFO - â”œâ”€â”€ Learning Rate: 2.16e-04
2025-03-02 15:27:56,029 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:27:56,702 - INFO - ðŸªœ Batch step - 2073 -- sub batch step 8292 -- lr 2.19e-04
2025-03-02 15:27:58,850 - INFO - ðŸªœ Batch step - 2073 -- sub batch step 8293 -- lr 2.19e-04
2025-03-02 15:28:01,540 - INFO - ðŸªœ Batch step - 2073 -- sub batch step 8294 -- lr 2.19e-04
2025-03-02 15:28:03,705 - INFO - ðŸªœ Batch step - 2073 -- sub batch step 8295 -- lr 2.19e-04
2025-03-02 15:28:05,196 - INFO - Step 2073 -- ðŸ”„ Training Metrics
2025-03-02 15:28:05,196 - INFO - â”œâ”€â”€ Loss: 6.8926
2025-03-02 15:28:05,197 - INFO - â”œâ”€â”€ Learning Rate: 2.19e-04
2025-03-02 15:28:05,197 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:28:05,866 - INFO - ðŸªœ Batch step - 2074 -- sub batch step 8296 -- lr 2.22e-04
2025-03-02 15:28:08,021 - INFO - ðŸªœ Batch step - 2074 -- sub batch step 8297 -- lr 2.22e-04
2025-03-02 15:28:10,185 - INFO - ðŸªœ Batch step - 2074 -- sub batch step 8298 -- lr 2.22e-04
2025-03-02 15:28:12,337 - INFO - ðŸªœ Batch step - 2074 -- sub batch step 8299 -- lr 2.22e-04
2025-03-02 15:28:13,891 - INFO - Step 2074 -- ðŸ”„ Training Metrics
2025-03-02 15:28:13,891 - INFO - â”œâ”€â”€ Loss: 6.8934
2025-03-02 15:28:13,891 - INFO - â”œâ”€â”€ Learning Rate: 2.22e-04
2025-03-02 15:28:13,891 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:28:14,563 - INFO - ðŸªœ Batch step - 2075 -- sub batch step 8300 -- lr 2.25e-04
2025-03-02 15:28:16,711 - INFO - ðŸªœ Batch step - 2075 -- sub batch step 8301 -- lr 2.25e-04
2025-03-02 15:28:19,541 - INFO - ðŸªœ Batch step - 2075 -- sub batch step 8302 -- lr 2.25e-04
2025-03-02 15:28:21,696 - INFO - ðŸªœ Batch step - 2075 -- sub batch step 8303 -- lr 2.25e-04
2025-03-02 15:28:23,775 - INFO - Step 2075 -- ðŸ”„ Training Metrics
2025-03-02 15:28:23,776 - INFO - â”œâ”€â”€ Loss: 6.9030
2025-03-02 15:28:23,776 - INFO - â”œâ”€â”€ Learning Rate: 2.25e-04
2025-03-02 15:28:23,776 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:28:24,447 - INFO - ðŸªœ Batch step - 2076 -- sub batch step 8304 -- lr 2.28e-04
2025-03-02 15:28:26,604 - INFO - ðŸªœ Batch step - 2076 -- sub batch step 8305 -- lr 2.28e-04
2025-03-02 15:28:28,764 - INFO - ðŸªœ Batch step - 2076 -- sub batch step 8306 -- lr 2.28e-04
2025-03-02 15:28:30,915 - INFO - ðŸªœ Batch step - 2076 -- sub batch step 8307 -- lr 2.28e-04
2025-03-02 15:28:32,468 - INFO - Step 2076 -- ðŸ”„ Training Metrics
2025-03-02 15:28:32,469 - INFO - â”œâ”€â”€ Loss: 6.9221
2025-03-02 15:28:32,469 - INFO - â”œâ”€â”€ Learning Rate: 2.28e-04
2025-03-02 15:28:32,469 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:28:33,140 - INFO - ðŸªœ Batch step - 2077 -- sub batch step 8308 -- lr 2.31e-04
2025-03-02 15:28:35,295 - INFO - ðŸªœ Batch step - 2077 -- sub batch step 8309 -- lr 2.31e-04
2025-03-02 15:28:37,911 - INFO - ðŸªœ Batch step - 2077 -- sub batch step 8310 -- lr 2.31e-04
2025-03-02 15:28:40,058 - INFO - ðŸªœ Batch step - 2077 -- sub batch step 8311 -- lr 2.31e-04
2025-03-02 15:28:42,017 - INFO - Step 2077 -- ðŸ”„ Training Metrics
2025-03-02 15:28:42,017 - INFO - â”œâ”€â”€ Loss: 6.9038
2025-03-02 15:28:42,017 - INFO - â”œâ”€â”€ Learning Rate: 2.31e-04
2025-03-02 15:28:42,018 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:28:42,689 - INFO - ðŸªœ Batch step - 2078 -- sub batch step 8312 -- lr 2.34e-04
2025-03-02 15:28:44,839 - INFO - ðŸªœ Batch step - 2078 -- sub batch step 8313 -- lr 2.34e-04
2025-03-02 15:28:47,010 - INFO - ðŸªœ Batch step - 2078 -- sub batch step 8314 -- lr 2.34e-04
2025-03-02 15:28:49,162 - INFO - ðŸªœ Batch step - 2078 -- sub batch step 8315 -- lr 2.34e-04
2025-03-02 15:28:50,709 - INFO - Step 2078 -- ðŸ”„ Training Metrics
2025-03-02 15:28:50,709 - INFO - â”œâ”€â”€ Loss: 6.9060
2025-03-02 15:28:50,709 - INFO - â”œâ”€â”€ Learning Rate: 2.34e-04
2025-03-02 15:28:50,709 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:28:51,378 - INFO - ðŸªœ Batch step - 2079 -- sub batch step 8316 -- lr 2.37e-04
2025-03-02 15:28:53,533 - INFO - ðŸªœ Batch step - 2079 -- sub batch step 8317 -- lr 2.37e-04
2025-03-02 15:28:55,816 - INFO - ðŸªœ Batch step - 2079 -- sub batch step 8318 -- lr 2.37e-04
HTTP Error 502 thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00103-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 15:28:57,969 - INFO - ðŸªœ Batch step - 2079 -- sub batch step 8319 -- lr 2.37e-04
2025-03-02 15:29:01,276 - INFO - Step 2079 -- ðŸ”„ Training Metrics
2025-03-02 15:29:01,276 - INFO - â”œâ”€â”€ Loss: 6.8729
2025-03-02 15:29:01,276 - INFO - â”œâ”€â”€ Learning Rate: 2.37e-04
2025-03-02 15:29:01,276 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:29:02,304 - INFO - ðŸªœ Batch step - 2080 -- sub batch step 8320 -- lr 2.40e-04
2025-03-02 15:29:04,467 - INFO - ðŸªœ Batch step - 2080 -- sub batch step 8321 -- lr 2.40e-04
2025-03-02 15:29:06,633 - INFO - ðŸªœ Batch step - 2080 -- sub batch step 8322 -- lr 2.40e-04
2025-03-02 15:29:08,813 - INFO - ðŸªœ Batch step - 2080 -- sub batch step 8323 -- lr 2.40e-04
2025-03-02 15:29:10,845 - INFO - Step 2080 -- ðŸ”„ Training Metrics
2025-03-02 15:29:10,845 - INFO - â”œâ”€â”€ Loss: 6.8481
2025-03-02 15:29:10,845 - INFO - â”œâ”€â”€ Learning Rate: 2.40e-04
2025-03-02 15:29:10,845 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:29:11,528 - INFO - ðŸªœ Batch step - 2081 -- sub batch step 8324 -- lr 2.43e-04
2025-03-02 15:29:13,691 - INFO - ðŸªœ Batch step - 2081 -- sub batch step 8325 -- lr 2.43e-04
2025-03-02 15:29:15,843 - INFO - ðŸªœ Batch step - 2081 -- sub batch step 8326 -- lr 2.43e-04
2025-03-02 15:29:18,429 - INFO - ðŸªœ Batch step - 2081 -- sub batch step 8327 -- lr 2.43e-04
2025-03-02 15:29:20,068 - INFO - Step 2081 -- ðŸ”„ Training Metrics
2025-03-02 15:29:20,068 - INFO - â”œâ”€â”€ Loss: 6.8645
2025-03-02 15:29:20,068 - INFO - â”œâ”€â”€ Learning Rate: 2.43e-04
2025-03-02 15:29:20,068 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:29:20,738 - INFO - ðŸªœ Batch step - 2082 -- sub batch step 8328 -- lr 2.46e-04
2025-03-02 15:29:22,896 - INFO - ðŸªœ Batch step - 2082 -- sub batch step 8329 -- lr 2.46e-04
2025-03-02 15:29:25,050 - INFO - ðŸªœ Batch step - 2082 -- sub batch step 8330 -- lr 2.46e-04
2025-03-02 15:29:27,218 - INFO - ðŸªœ Batch step - 2082 -- sub batch step 8331 -- lr 2.46e-04
2025-03-02 15:29:28,760 - INFO - Step 2082 -- ðŸ”„ Training Metrics
2025-03-02 15:29:28,760 - INFO - â”œâ”€â”€ Loss: 6.8904
2025-03-02 15:29:28,760 - INFO - â”œâ”€â”€ Learning Rate: 2.46e-04
2025-03-02 15:29:28,760 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:29:29,433 - INFO - ðŸªœ Batch step - 2083 -- sub batch step 8332 -- lr 2.49e-04
2025-03-02 15:29:31,580 - INFO - ðŸªœ Batch step - 2083 -- sub batch step 8333 -- lr 2.49e-04
2025-03-02 15:29:33,731 - INFO - ðŸªœ Batch step - 2083 -- sub batch step 8334 -- lr 2.49e-04
2025-03-02 15:29:36,088 - INFO - ðŸªœ Batch step - 2083 -- sub batch step 8335 -- lr 2.49e-04
2025-03-02 15:29:37,840 - INFO - Step 2083 -- ðŸ”„ Training Metrics
2025-03-02 15:29:37,841 - INFO - â”œâ”€â”€ Loss: 6.8637
2025-03-02 15:29:37,841 - INFO - â”œâ”€â”€ Learning Rate: 2.49e-04
2025-03-02 15:29:37,841 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:29:38,508 - INFO - ðŸªœ Batch step - 2084 -- sub batch step 8336 -- lr 2.52e-04
2025-03-02 15:29:40,665 - INFO - ðŸªœ Batch step - 2084 -- sub batch step 8337 -- lr 2.52e-04
2025-03-02 15:29:42,814 - INFO - ðŸªœ Batch step - 2084 -- sub batch step 8338 -- lr 2.52e-04
2025-03-02 15:29:44,987 - INFO - ðŸªœ Batch step - 2084 -- sub batch step 8339 -- lr 2.52e-04
2025-03-02 15:29:46,531 - INFO - Step 2084 -- ðŸ”„ Training Metrics
2025-03-02 15:29:46,532 - INFO - â”œâ”€â”€ Loss: 6.8871
2025-03-02 15:29:46,532 - INFO - â”œâ”€â”€ Learning Rate: 2.52e-04
2025-03-02 15:29:46,532 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:29:47,205 - INFO - ðŸªœ Batch step - 2085 -- sub batch step 8340 -- lr 2.55e-04
2025-03-02 15:29:49,354 - INFO - ðŸªœ Batch step - 2085 -- sub batch step 8341 -- lr 2.55e-04
2025-03-02 15:29:51,507 - INFO - ðŸªœ Batch step - 2085 -- sub batch step 8342 -- lr 2.55e-04
2025-03-02 15:29:54,100 - INFO - ðŸªœ Batch step - 2085 -- sub batch step 8343 -- lr 2.55e-04
2025-03-02 15:29:55,699 - INFO - Step 2085 -- ðŸ”„ Training Metrics
2025-03-02 15:29:55,699 - INFO - â”œâ”€â”€ Loss: 6.8544
2025-03-02 15:29:55,699 - INFO - â”œâ”€â”€ Learning Rate: 2.55e-04
2025-03-02 15:29:55,700 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:29:56,371 - INFO - ðŸªœ Batch step - 2086 -- sub batch step 8344 -- lr 2.58e-04
2025-03-02 15:29:58,525 - INFO - ðŸªœ Batch step - 2086 -- sub batch step 8345 -- lr 2.58e-04
2025-03-02 15:30:00,673 - INFO - ðŸªœ Batch step - 2086 -- sub batch step 8346 -- lr 2.58e-04
2025-03-02 15:30:02,843 - INFO - ðŸªœ Batch step - 2086 -- sub batch step 8347 -- lr 2.58e-04
2025-03-02 15:30:04,395 - INFO - Step 2086 -- ðŸ”„ Training Metrics
2025-03-02 15:30:04,395 - INFO - â”œâ”€â”€ Loss: 6.8558
2025-03-02 15:30:04,396 - INFO - â”œâ”€â”€ Learning Rate: 2.58e-04
2025-03-02 15:30:04,396 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:30:05,065 - INFO - ðŸªœ Batch step - 2087 -- sub batch step 8348 -- lr 2.61e-04
2025-03-02 15:30:07,219 - INFO - ðŸªœ Batch step - 2087 -- sub batch step 8349 -- lr 2.61e-04
2025-03-02 15:30:09,372 - INFO - ðŸªœ Batch step - 2087 -- sub batch step 8350 -- lr 2.61e-04
2025-03-02 15:30:11,774 - INFO - ðŸªœ Batch step - 2087 -- sub batch step 8351 -- lr 2.61e-04
2025-03-02 15:30:13,663 - INFO - Step 2087 -- ðŸ”„ Training Metrics
2025-03-02 15:30:13,664 - INFO - â”œâ”€â”€ Loss: 6.8603
2025-03-02 15:30:13,664 - INFO - â”œâ”€â”€ Learning Rate: 2.61e-04
2025-03-02 15:30:13,664 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:30:14,339 - INFO - ðŸªœ Batch step - 2088 -- sub batch step 8352 -- lr 2.64e-04
2025-03-02 15:30:16,488 - INFO - ðŸªœ Batch step - 2088 -- sub batch step 8353 -- lr 2.64e-04
2025-03-02 15:30:18,644 - INFO - ðŸªœ Batch step - 2088 -- sub batch step 8354 -- lr 2.64e-04
2025-03-02 15:30:20,819 - INFO - ðŸªœ Batch step - 2088 -- sub batch step 8355 -- lr 2.64e-04
2025-03-02 15:30:22,359 - INFO - Step 2088 -- ðŸ”„ Training Metrics
2025-03-02 15:30:22,360 - INFO - â”œâ”€â”€ Loss: 6.8576
2025-03-02 15:30:22,360 - INFO - â”œâ”€â”€ Learning Rate: 2.64e-04
2025-03-02 15:30:22,360 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:30:23,032 - INFO - ðŸªœ Batch step - 2089 -- sub batch step 8356 -- lr 2.67e-04
2025-03-02 15:30:25,191 - INFO - ðŸªœ Batch step - 2089 -- sub batch step 8357 -- lr 2.67e-04
2025-03-02 15:30:27,341 - INFO - ðŸªœ Batch step - 2089 -- sub batch step 8358 -- lr 2.67e-04
2025-03-02 15:30:29,805 - INFO - ðŸªœ Batch step - 2089 -- sub batch step 8359 -- lr 2.67e-04
2025-03-02 15:30:37,822 - INFO - Step 2089 -- ðŸ”„ Training Metrics
2025-03-02 15:30:37,822 - INFO - â”œâ”€â”€ Loss: 6.8727
2025-03-02 15:30:37,822 - INFO - â”œâ”€â”€ Learning Rate: 2.67e-04
2025-03-02 15:30:37,822 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:30:38,499 - INFO - ðŸªœ Batch step - 2090 -- sub batch step 8360 -- lr 2.70e-04
2025-03-02 15:30:40,649 - INFO - ðŸªœ Batch step - 2090 -- sub batch step 8361 -- lr 2.70e-04
2025-03-02 15:30:42,803 - INFO - ðŸªœ Batch step - 2090 -- sub batch step 8362 -- lr 2.70e-04
2025-03-02 15:30:44,967 - INFO - ðŸªœ Batch step - 2090 -- sub batch step 8363 -- lr 2.70e-04
2025-03-02 15:30:46,515 - INFO - Step 2090 -- ðŸ”„ Training Metrics
2025-03-02 15:30:46,516 - INFO - â”œâ”€â”€ Loss: 6.8723
2025-03-02 15:30:46,516 - INFO - â”œâ”€â”€ Learning Rate: 2.70e-04
2025-03-02 15:30:46,516 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:30:47,191 - INFO - ðŸªœ Batch step - 2091 -- sub batch step 8364 -- lr 2.73e-04
2025-03-02 15:30:49,344 - INFO - ðŸªœ Batch step - 2091 -- sub batch step 8365 -- lr 2.73e-04
2025-03-02 15:30:51,729 - INFO - ðŸªœ Batch step - 2091 -- sub batch step 8366 -- lr 2.73e-04
2025-03-02 15:30:53,882 - INFO - ðŸªœ Batch step - 2091 -- sub batch step 8367 -- lr 2.73e-04
2025-03-02 15:30:56,033 - INFO - Step 2091 -- ðŸ”„ Training Metrics
2025-03-02 15:30:56,034 - INFO - â”œâ”€â”€ Loss: 6.8722
2025-03-02 15:30:56,034 - INFO - â”œâ”€â”€ Learning Rate: 2.73e-04
2025-03-02 15:30:56,034 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:30:56,704 - INFO - ðŸªœ Batch step - 2092 -- sub batch step 8368 -- lr 2.76e-04
2025-03-02 15:30:58,859 - INFO - ðŸªœ Batch step - 2092 -- sub batch step 8369 -- lr 2.76e-04
2025-03-02 15:31:01,030 - INFO - ðŸªœ Batch step - 2092 -- sub batch step 8370 -- lr 2.76e-04
2025-03-02 15:31:03,181 - INFO - ðŸªœ Batch step - 2092 -- sub batch step 8371 -- lr 2.76e-04
2025-03-02 15:31:04,846 - INFO - Step 2092 -- ðŸ”„ Training Metrics
2025-03-02 15:31:04,847 - INFO - â”œâ”€â”€ Loss: 6.8587
2025-03-02 15:31:04,847 - INFO - â”œâ”€â”€ Learning Rate: 2.76e-04
2025-03-02 15:31:04,847 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:31:05,522 - INFO - ðŸªœ Batch step - 2093 -- sub batch step 8372 -- lr 2.79e-04
2025-03-02 15:31:07,670 - INFO - ðŸªœ Batch step - 2093 -- sub batch step 8373 -- lr 2.79e-04
2025-03-02 15:31:10,351 - INFO - ðŸªœ Batch step - 2093 -- sub batch step 8374 -- lr 2.79e-04
2025-03-02 15:31:12,503 - INFO - ðŸªœ Batch step - 2093 -- sub batch step 8375 -- lr 2.79e-04
2025-03-02 15:31:14,045 - INFO - Step 2093 -- ðŸ”„ Training Metrics
2025-03-02 15:31:14,046 - INFO - â”œâ”€â”€ Loss: 6.8684
2025-03-02 15:31:14,046 - INFO - â”œâ”€â”€ Learning Rate: 2.79e-04
2025-03-02 15:31:14,046 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:31:14,715 - INFO - ðŸªœ Batch step - 2094 -- sub batch step 8376 -- lr 2.82e-04
2025-03-02 15:31:16,871 - INFO - ðŸªœ Batch step - 2094 -- sub batch step 8377 -- lr 2.82e-04
2025-03-02 15:31:19,036 - INFO - ðŸªœ Batch step - 2094 -- sub batch step 8378 -- lr 2.82e-04
2025-03-02 15:31:21,190 - INFO - ðŸªœ Batch step - 2094 -- sub batch step 8379 -- lr 2.82e-04
2025-03-02 15:31:22,907 - INFO - Step 2094 -- ðŸ”„ Training Metrics
2025-03-02 15:31:22,907 - INFO - â”œâ”€â”€ Loss: 6.8313
2025-03-02 15:31:22,907 - INFO - â”œâ”€â”€ Learning Rate: 2.82e-04
2025-03-02 15:31:22,907 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:31:23,585 - INFO - ðŸªœ Batch step - 2095 -- sub batch step 8380 -- lr 2.85e-04
2025-03-02 15:31:25,731 - INFO - ðŸªœ Batch step - 2095 -- sub batch step 8381 -- lr 2.85e-04
2025-03-02 15:31:28,413 - INFO - ðŸªœ Batch step - 2095 -- sub batch step 8382 -- lr 2.85e-04
2025-03-02 15:31:30,567 - INFO - ðŸªœ Batch step - 2095 -- sub batch step 8383 -- lr 2.85e-04
2025-03-02 15:31:32,089 - INFO - Step 2095 -- ðŸ”„ Training Metrics
2025-03-02 15:31:32,089 - INFO - â”œâ”€â”€ Loss: 6.8509
2025-03-02 15:31:32,089 - INFO - â”œâ”€â”€ Learning Rate: 2.85e-04
2025-03-02 15:31:32,089 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:31:32,764 - INFO - ðŸªœ Batch step - 2096 -- sub batch step 8384 -- lr 2.88e-04
2025-03-02 15:31:34,918 - INFO - ðŸªœ Batch step - 2096 -- sub batch step 8385 -- lr 2.88e-04
2025-03-02 15:31:37,085 - INFO - ðŸªœ Batch step - 2096 -- sub batch step 8386 -- lr 2.88e-04
2025-03-02 15:31:39,237 - INFO - ðŸªœ Batch step - 2096 -- sub batch step 8387 -- lr 2.88e-04
2025-03-02 15:31:41,144 - INFO - Step 2096 -- ðŸ”„ Training Metrics
2025-03-02 15:31:41,144 - INFO - â”œâ”€â”€ Loss: 6.8584
2025-03-02 15:31:41,145 - INFO - â”œâ”€â”€ Learning Rate: 2.88e-04
2025-03-02 15:31:41,145 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:31:41,906 - INFO - ðŸªœ Batch step - 2097 -- sub batch step 8388 -- lr 2.91e-04
2025-03-02 15:31:44,059 - INFO - ðŸªœ Batch step - 2097 -- sub batch step 8389 -- lr 2.91e-04
2025-03-02 15:31:46,709 - INFO - ðŸªœ Batch step - 2097 -- sub batch step 8390 -- lr 2.91e-04
2025-03-02 15:31:48,858 - INFO - ðŸªœ Batch step - 2097 -- sub batch step 8391 -- lr 2.91e-04
2025-03-02 15:31:51,799 - INFO - Step 2097 -- ðŸ”„ Training Metrics
2025-03-02 15:31:51,799 - INFO - â”œâ”€â”€ Loss: 6.8447
2025-03-02 15:31:51,799 - INFO - â”œâ”€â”€ Learning Rate: 2.91e-04
2025-03-02 15:31:51,799 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:31:52,574 - INFO - ðŸªœ Batch step - 2098 -- sub batch step 8392 -- lr 2.94e-04
2025-03-02 15:31:54,721 - INFO - ðŸªœ Batch step - 2098 -- sub batch step 8393 -- lr 2.94e-04
2025-03-02 15:31:56,890 - INFO - ðŸªœ Batch step - 2098 -- sub batch step 8394 -- lr 2.94e-04
2025-03-02 15:31:59,042 - INFO - ðŸªœ Batch step - 2098 -- sub batch step 8395 -- lr 2.94e-04
2025-03-02 15:32:00,770 - INFO - Step 2098 -- ðŸ”„ Training Metrics
2025-03-02 15:32:00,770 - INFO - â”œâ”€â”€ Loss: 6.8060
2025-03-02 15:32:00,770 - INFO - â”œâ”€â”€ Learning Rate: 2.94e-04
2025-03-02 15:32:00,771 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:32:01,440 - INFO - ðŸªœ Batch step - 2099 -- sub batch step 8396 -- lr 2.97e-04
2025-03-02 15:32:03,596 - INFO - ðŸªœ Batch step - 2099 -- sub batch step 8397 -- lr 2.97e-04
2025-03-02 15:32:05,880 - INFO - ðŸªœ Batch step - 2099 -- sub batch step 8398 -- lr 2.97e-04
2025-03-02 15:32:08,036 - INFO - ðŸªœ Batch step - 2099 -- sub batch step 8399 -- lr 2.97e-04
2025-03-02 15:32:09,715 - INFO - Step 2099 -- ðŸ”„ Training Metrics
2025-03-02 15:32:09,715 - INFO - â”œâ”€â”€ Loss: 6.8192
2025-03-02 15:32:09,715 - INFO - â”œâ”€â”€ Learning Rate: 2.97e-04
2025-03-02 15:32:09,715 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:32:10,714 - INFO - ðŸªœ Batch step - 2100 -- sub batch step 8400 -- lr 3.00e-04
2025-03-02 15:32:12,870 - INFO - ðŸªœ Batch step - 2100 -- sub batch step 8401 -- lr 3.00e-04
2025-03-02 15:32:15,031 - INFO - ðŸªœ Batch step - 2100 -- sub batch step 8402 -- lr 3.00e-04
2025-03-02 15:32:17,202 - INFO - ðŸªœ Batch step - 2100 -- sub batch step 8403 -- lr 3.00e-04
2025-03-02 15:32:19,009 - INFO - Step 2100 -- ðŸ”„ Training Metrics
2025-03-02 15:32:19,009 - INFO - â”œâ”€â”€ Loss: 6.8227
2025-03-02 15:32:19,009 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:32:19,009 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:32:19,685 - INFO - ðŸªœ Batch step - 2101 -- sub batch step 8404 -- lr 3.00e-04
2025-03-02 15:32:21,838 - INFO - ðŸªœ Batch step - 2101 -- sub batch step 8405 -- lr 3.00e-04
2025-03-02 15:32:23,986 - INFO - ðŸªœ Batch step - 2101 -- sub batch step 8406 -- lr 3.00e-04
2025-03-02 15:32:26,633 - INFO - ðŸªœ Batch step - 2101 -- sub batch step 8407 -- lr 3.00e-04
2025-03-02 15:32:33,328 - INFO - Step 2101 -- ðŸ”„ Training Metrics
2025-03-02 15:32:33,328 - INFO - â”œâ”€â”€ Loss: 6.8497
2025-03-02 15:32:33,328 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:32:33,329 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:32:33,994 - INFO - ðŸªœ Batch step - 2102 -- sub batch step 8408 -- lr 3.00e-04
2025-03-02 15:32:36,150 - INFO - ðŸªœ Batch step - 2102 -- sub batch step 8409 -- lr 3.00e-04
2025-03-02 15:32:38,305 - INFO - ðŸªœ Batch step - 2102 -- sub batch step 8410 -- lr 3.00e-04
2025-03-02 15:32:40,470 - INFO - ðŸªœ Batch step - 2102 -- sub batch step 8411 -- lr 3.00e-04
2025-03-02 15:32:42,027 - INFO - Step 2102 -- ðŸ”„ Training Metrics
2025-03-02 15:32:42,027 - INFO - â”œâ”€â”€ Loss: 6.8270
2025-03-02 15:32:42,027 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:32:42,027 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:32:42,701 - INFO - ðŸªœ Batch step - 2103 -- sub batch step 8412 -- lr 3.00e-04
2025-03-02 15:32:44,851 - INFO - ðŸªœ Batch step - 2103 -- sub batch step 8413 -- lr 3.00e-04
2025-03-02 15:32:47,005 - INFO - ðŸªœ Batch step - 2103 -- sub batch step 8414 -- lr 3.00e-04
2025-03-02 15:32:49,716 - INFO - ðŸªœ Batch step - 2103 -- sub batch step 8415 -- lr 3.00e-04
2025-03-02 15:32:51,284 - INFO - Step 2103 -- ðŸ”„ Training Metrics
2025-03-02 15:32:51,285 - INFO - â”œâ”€â”€ Loss: 6.8142
2025-03-02 15:32:51,285 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:32:51,285 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:32:51,954 - INFO - ðŸªœ Batch step - 2104 -- sub batch step 8416 -- lr 3.00e-04
2025-03-02 15:32:54,109 - INFO - ðŸªœ Batch step - 2104 -- sub batch step 8417 -- lr 3.00e-04
2025-03-02 15:32:56,256 - INFO - ðŸªœ Batch step - 2104 -- sub batch step 8418 -- lr 3.00e-04
2025-03-02 15:32:58,428 - INFO - ðŸªœ Batch step - 2104 -- sub batch step 8419 -- lr 3.00e-04
2025-03-02 15:32:59,984 - INFO - Step 2104 -- ðŸ”„ Training Metrics
2025-03-02 15:32:59,984 - INFO - â”œâ”€â”€ Loss: 6.8235
2025-03-02 15:32:59,984 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:32:59,985 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:33:00,659 - INFO - ðŸªœ Batch step - 2105 -- sub batch step 8420 -- lr 3.00e-04
2025-03-02 15:33:02,807 - INFO - ðŸªœ Batch step - 2105 -- sub batch step 8421 -- lr 3.00e-04
2025-03-02 15:33:04,961 - INFO - ðŸªœ Batch step - 2105 -- sub batch step 8422 -- lr 3.00e-04
2025-03-02 15:33:13,845 - INFO - ðŸªœ Batch step - 2105 -- sub batch step 8423 -- lr 3.00e-04
2025-03-02 15:33:15,351 - INFO - Step 2105 -- ðŸ”„ Training Metrics
2025-03-02 15:33:15,352 - INFO - â”œâ”€â”€ Loss: 6.7934
2025-03-02 15:33:15,352 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:33:15,352 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:33:16,029 - INFO - ðŸªœ Batch step - 2106 -- sub batch step 8424 -- lr 3.00e-04
2025-03-02 15:33:18,184 - INFO - ðŸªœ Batch step - 2106 -- sub batch step 8425 -- lr 3.00e-04
2025-03-02 15:33:20,333 - INFO - ðŸªœ Batch step - 2106 -- sub batch step 8426 -- lr 3.00e-04
2025-03-02 15:33:22,508 - INFO - ðŸªœ Batch step - 2106 -- sub batch step 8427 -- lr 3.00e-04
2025-03-02 15:33:24,061 - INFO - Step 2106 -- ðŸ”„ Training Metrics
2025-03-02 15:33:24,062 - INFO - â”œâ”€â”€ Loss: 6.8114
2025-03-02 15:33:24,062 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:33:24,062 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:33:24,732 - INFO - ðŸªœ Batch step - 2107 -- sub batch step 8428 -- lr 3.00e-04
2025-03-02 15:33:26,889 - INFO - ðŸªœ Batch step - 2107 -- sub batch step 8429 -- lr 3.00e-04
2025-03-02 15:33:29,043 - INFO - ðŸªœ Batch step - 2107 -- sub batch step 8430 -- lr 3.00e-04
2025-03-02 15:33:31,854 - INFO - ðŸªœ Batch step - 2107 -- sub batch step 8431 -- lr 3.00e-04
2025-03-02 15:33:33,344 - INFO - Step 2107 -- ðŸ”„ Training Metrics
2025-03-02 15:33:33,345 - INFO - â”œâ”€â”€ Loss: 6.8034
2025-03-02 15:33:33,345 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:33:33,345 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:33:34,018 - INFO - ðŸªœ Batch step - 2108 -- sub batch step 8432 -- lr 3.00e-04
2025-03-02 15:33:36,164 - INFO - ðŸªœ Batch step - 2108 -- sub batch step 8433 -- lr 3.00e-04
2025-03-02 15:33:38,319 - INFO - ðŸªœ Batch step - 2108 -- sub batch step 8434 -- lr 3.00e-04
2025-03-02 15:33:40,494 - INFO - ðŸªœ Batch step - 2108 -- sub batch step 8435 -- lr 3.00e-04
2025-03-02 15:33:42,047 - INFO - Step 2108 -- ðŸ”„ Training Metrics
2025-03-02 15:33:42,047 - INFO - â”œâ”€â”€ Loss: 6.7872
2025-03-02 15:33:42,047 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:33:42,047 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:33:42,719 - INFO - ðŸªœ Batch step - 2109 -- sub batch step 8436 -- lr 3.00e-04
2025-03-02 15:33:44,876 - INFO - ðŸªœ Batch step - 2109 -- sub batch step 8437 -- lr 3.00e-04
2025-03-02 15:33:47,024 - INFO - ðŸªœ Batch step - 2109 -- sub batch step 8438 -- lr 3.00e-04
2025-03-02 15:33:49,673 - INFO - ðŸªœ Batch step - 2109 -- sub batch step 8439 -- lr 3.00e-04
2025-03-02 15:33:57,884 - INFO - Step 2109 -- ðŸ”„ Training Metrics
2025-03-02 15:33:57,884 - INFO - â”œâ”€â”€ Loss: 6.8167
2025-03-02 15:33:57,884 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:33:57,884 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:33:58,558 - INFO - ðŸªœ Batch step - 2110 -- sub batch step 8440 -- lr 3.00e-04
2025-03-02 15:34:00,707 - INFO - ðŸªœ Batch step - 2110 -- sub batch step 8441 -- lr 3.00e-04
2025-03-02 15:34:02,862 - INFO - ðŸªœ Batch step - 2110 -- sub batch step 8442 -- lr 3.00e-04
2025-03-02 15:34:05,028 - INFO - ðŸªœ Batch step - 2110 -- sub batch step 8443 -- lr 3.00e-04
2025-03-02 15:34:06,720 - INFO - Step 2110 -- ðŸ”„ Training Metrics
2025-03-02 15:34:06,721 - INFO - â”œâ”€â”€ Loss: 6.8006
2025-03-02 15:34:06,721 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:34:06,721 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:34:07,407 - INFO - ðŸªœ Batch step - 2111 -- sub batch step 8444 -- lr 3.00e-04
2025-03-02 15:34:09,562 - INFO - ðŸªœ Batch step - 2111 -- sub batch step 8445 -- lr 3.00e-04
2025-03-02 15:34:12,355 - INFO - ðŸªœ Batch step - 2111 -- sub batch step 8446 -- lr 3.00e-04
2025-03-02 15:34:14,517 - INFO - ðŸªœ Batch step - 2111 -- sub batch step 8447 -- lr 3.00e-04
2025-03-02 15:34:16,084 - INFO - Step 2111 -- ðŸ”„ Training Metrics
2025-03-02 15:34:16,084 - INFO - â”œâ”€â”€ Loss: 6.8076
2025-03-02 15:34:16,084 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:34:16,084 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:34:16,759 - INFO - ðŸªœ Batch step - 2112 -- sub batch step 8448 -- lr 3.00e-04
2025-03-02 15:34:18,913 - INFO - ðŸªœ Batch step - 2112 -- sub batch step 8449 -- lr 3.00e-04
2025-03-02 15:34:21,085 - INFO - ðŸªœ Batch step - 2112 -- sub batch step 8450 -- lr 3.00e-04
2025-03-02 15:34:23,236 - INFO - ðŸªœ Batch step - 2112 -- sub batch step 8451 -- lr 3.00e-04
2025-03-02 15:34:24,790 - INFO - Step 2112 -- ðŸ”„ Training Metrics
2025-03-02 15:34:24,790 - INFO - â”œâ”€â”€ Loss: 6.8242
2025-03-02 15:34:24,791 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:34:24,791 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:34:25,466 - INFO - ðŸªœ Batch step - 2113 -- sub batch step 8452 -- lr 3.00e-04
2025-03-02 15:34:27,613 - INFO - ðŸªœ Batch step - 2113 -- sub batch step 8453 -- lr 3.00e-04
2025-03-02 15:34:30,021 - INFO - ðŸªœ Batch step - 2113 -- sub batch step 8454 -- lr 3.00e-04
2025-03-02 15:34:32,177 - INFO - ðŸªœ Batch step - 2113 -- sub batch step 8455 -- lr 3.00e-04
2025-03-02 15:34:35,567 - INFO - Step 2113 -- ðŸ”„ Training Metrics
2025-03-02 15:34:35,568 - INFO - â”œâ”€â”€ Loss: 6.8117
2025-03-02 15:34:35,568 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:34:35,568 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:34:36,239 - INFO - ðŸªœ Batch step - 2114 -- sub batch step 8456 -- lr 3.00e-04
2025-03-02 15:34:38,394 - INFO - ðŸªœ Batch step - 2114 -- sub batch step 8457 -- lr 3.00e-04
2025-03-02 15:34:40,558 - INFO - ðŸªœ Batch step - 2114 -- sub batch step 8458 -- lr 3.00e-04
2025-03-02 15:34:42,716 - INFO - ðŸªœ Batch step - 2114 -- sub batch step 8459 -- lr 3.00e-04
2025-03-02 15:34:44,266 - INFO - Step 2114 -- ðŸ”„ Training Metrics
2025-03-02 15:34:44,267 - INFO - â”œâ”€â”€ Loss: 6.7855
2025-03-02 15:34:44,267 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:34:44,267 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:34:44,942 - INFO - ðŸªœ Batch step - 2115 -- sub batch step 8460 -- lr 3.00e-04
2025-03-02 15:34:47,091 - INFO - ðŸªœ Batch step - 2115 -- sub batch step 8461 -- lr 3.00e-04
2025-03-02 15:34:49,461 - INFO - ðŸªœ Batch step - 2115 -- sub batch step 8462 -- lr 3.00e-04
2025-03-02 15:34:51,617 - INFO - ðŸªœ Batch step - 2115 -- sub batch step 8463 -- lr 3.00e-04
2025-03-02 15:34:53,453 - INFO - Step 2115 -- ðŸ”„ Training Metrics
2025-03-02 15:34:53,454 - INFO - â”œâ”€â”€ Loss: 6.8023
2025-03-02 15:34:53,454 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:34:53,454 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:34:54,131 - INFO - ðŸªœ Batch step - 2116 -- sub batch step 8464 -- lr 3.00e-04
2025-03-02 15:34:56,288 - INFO - ðŸªœ Batch step - 2116 -- sub batch step 8465 -- lr 3.00e-04
2025-03-02 15:34:58,458 - INFO - ðŸªœ Batch step - 2116 -- sub batch step 8466 -- lr 3.00e-04
2025-03-02 15:35:00,614 - INFO - ðŸªœ Batch step - 2116 -- sub batch step 8467 -- lr 3.00e-04
2025-03-02 15:35:02,171 - INFO - Step 2116 -- ðŸ”„ Training Metrics
2025-03-02 15:35:02,171 - INFO - â”œâ”€â”€ Loss: 6.7740
2025-03-02 15:35:02,171 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:35:02,171 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:35:02,844 - INFO - ðŸªœ Batch step - 2117 -- sub batch step 8468 -- lr 3.00e-04
2025-03-02 15:35:05,001 - INFO - ðŸªœ Batch step - 2117 -- sub batch step 8469 -- lr 3.00e-04
2025-03-02 15:35:14,233 - INFO - ðŸªœ Batch step - 2117 -- sub batch step 8470 -- lr 3.00e-04
2025-03-02 15:35:16,386 - INFO - ðŸªœ Batch step - 2117 -- sub batch step 8471 -- lr 3.00e-04
2025-03-02 15:35:17,878 - INFO - Step 2117 -- ðŸ”„ Training Metrics
2025-03-02 15:35:17,878 - INFO - â”œâ”€â”€ Loss: 6.7735
2025-03-02 15:35:17,878 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:35:17,878 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:35:18,554 - INFO - ðŸªœ Batch step - 2118 -- sub batch step 8472 -- lr 3.00e-04
2025-03-02 15:35:20,703 - INFO - ðŸªœ Batch step - 2118 -- sub batch step 8473 -- lr 3.00e-04
2025-03-02 15:35:22,873 - INFO - ðŸªœ Batch step - 2118 -- sub batch step 8474 -- lr 3.00e-04
2025-03-02 15:35:25,027 - INFO - ðŸªœ Batch step - 2118 -- sub batch step 8475 -- lr 3.00e-04
2025-03-02 15:35:26,579 - INFO - Step 2118 -- ðŸ”„ Training Metrics
2025-03-02 15:35:26,579 - INFO - â”œâ”€â”€ Loss: 6.7670
2025-03-02 15:35:26,579 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:35:26,579 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:35:27,250 - INFO - ðŸªœ Batch step - 2119 -- sub batch step 8476 -- lr 3.00e-04
2025-03-02 15:35:29,411 - INFO - ðŸªœ Batch step - 2119 -- sub batch step 8477 -- lr 3.00e-04
2025-03-02 15:35:31,695 - INFO - ðŸªœ Batch step - 2119 -- sub batch step 8478 -- lr 3.00e-04
2025-03-02 15:35:33,852 - INFO - ðŸªœ Batch step - 2119 -- sub batch step 8479 -- lr 3.00e-04
2025-03-02 15:35:35,869 - INFO - Step 2119 -- ðŸ”„ Training Metrics
2025-03-02 15:35:35,869 - INFO - â”œâ”€â”€ Loss: 6.7749
2025-03-02 15:35:35,869 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:35:35,869 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:35:45,155 - INFO - ðŸªœ Batch step - 2120 -- sub batch step 8480 -- lr 3.00e-04
2025-03-02 15:35:47,314 - INFO - ðŸªœ Batch step - 2120 -- sub batch step 8481 -- lr 3.00e-04
2025-03-02 15:35:49,479 - INFO - ðŸªœ Batch step - 2120 -- sub batch step 8482 -- lr 3.00e-04
2025-03-02 15:35:51,653 - INFO - ðŸªœ Batch step - 2120 -- sub batch step 8483 -- lr 3.00e-04
2025-03-02 15:35:53,182 - INFO - Step 2120 -- ðŸ”„ Training Metrics
2025-03-02 15:35:53,182 - INFO - â”œâ”€â”€ Loss: 6.7746
2025-03-02 15:35:53,182 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:35:53,182 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:35:53,860 - INFO - ðŸªœ Batch step - 2121 -- sub batch step 8484 -- lr 3.00e-04
2025-03-02 15:35:56,020 - INFO - ðŸªœ Batch step - 2121 -- sub batch step 8485 -- lr 3.00e-04
2025-03-02 15:35:58,177 - INFO - ðŸªœ Batch step - 2121 -- sub batch step 8486 -- lr 3.00e-04
2025-03-02 15:36:00,822 - INFO - ðŸªœ Batch step - 2121 -- sub batch step 8487 -- lr 3.00e-04
2025-03-02 15:36:02,415 - INFO - Step 2121 -- ðŸ”„ Training Metrics
2025-03-02 15:36:02,416 - INFO - â”œâ”€â”€ Loss: 6.7956
2025-03-02 15:36:02,416 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:36:02,416 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:36:03,090 - INFO - ðŸªœ Batch step - 2122 -- sub batch step 8488 -- lr 3.00e-04
2025-03-02 15:36:05,253 - INFO - ðŸªœ Batch step - 2122 -- sub batch step 8489 -- lr 3.00e-04
2025-03-02 15:36:07,410 - INFO - ðŸªœ Batch step - 2122 -- sub batch step 8490 -- lr 3.00e-04
2025-03-02 15:36:09,583 - INFO - ðŸªœ Batch step - 2122 -- sub batch step 8491 -- lr 3.00e-04
2025-03-02 15:36:11,105 - INFO - Step 2122 -- ðŸ”„ Training Metrics
2025-03-02 15:36:11,105 - INFO - â”œâ”€â”€ Loss: 6.7681
2025-03-02 15:36:11,105 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:36:11,106 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:36:11,783 - INFO - ðŸªœ Batch step - 2123 -- sub batch step 8492 -- lr 3.00e-04
2025-03-02 15:36:13,936 - INFO - ðŸªœ Batch step - 2123 -- sub batch step 8493 -- lr 3.00e-04
2025-03-02 15:36:16,095 - INFO - ðŸªœ Batch step - 2123 -- sub batch step 8494 -- lr 3.00e-04
2025-03-02 15:36:18,909 - INFO - ðŸªœ Batch step - 2123 -- sub batch step 8495 -- lr 3.00e-04
2025-03-02 15:36:20,400 - INFO - Step 2123 -- ðŸ”„ Training Metrics
2025-03-02 15:36:20,400 - INFO - â”œâ”€â”€ Loss: 6.7667
2025-03-02 15:36:20,400 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:36:20,400 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:36:21,073 - INFO - ðŸªœ Batch step - 2124 -- sub batch step 8496 -- lr 3.00e-04
2025-03-02 15:36:23,235 - INFO - ðŸªœ Batch step - 2124 -- sub batch step 8497 -- lr 3.00e-04
2025-03-02 15:36:25,387 - INFO - ðŸªœ Batch step - 2124 -- sub batch step 8498 -- lr 3.00e-04
2025-03-02 15:36:27,563 - INFO - ðŸªœ Batch step - 2124 -- sub batch step 8499 -- lr 3.00e-04
2025-03-02 15:36:29,097 - INFO - Step 2124 -- ðŸ”„ Training Metrics
2025-03-02 15:36:29,098 - INFO - â”œâ”€â”€ Loss: 6.7810
2025-03-02 15:36:29,098 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:36:29,098 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:36:29,774 - INFO - ðŸªœ Batch step - 2125 -- sub batch step 8500 -- lr 3.00e-04
2025-03-02 15:36:31,932 - INFO - ðŸªœ Batch step - 2125 -- sub batch step 8501 -- lr 3.00e-04
2025-03-02 15:36:34,087 - INFO - ðŸªœ Batch step - 2125 -- sub batch step 8502 -- lr 3.00e-04
2025-03-02 15:36:36,794 - INFO - ðŸªœ Batch step - 2125 -- sub batch step 8503 -- lr 3.00e-04
2025-03-02 15:36:38,428 - INFO - Step 2125 -- ðŸ”„ Training Metrics
2025-03-02 15:36:38,428 - INFO - â”œâ”€â”€ Loss: 6.7740
2025-03-02 15:36:38,428 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:36:38,428 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:36:39,107 - INFO - ðŸªœ Batch step - 2126 -- sub batch step 8504 -- lr 3.00e-04
2025-03-02 15:36:41,266 - INFO - ðŸªœ Batch step - 2126 -- sub batch step 8505 -- lr 3.00e-04
2025-03-02 15:36:43,423 - INFO - ðŸªœ Batch step - 2126 -- sub batch step 8506 -- lr 3.00e-04
2025-03-02 15:36:45,600 - INFO - ðŸªœ Batch step - 2126 -- sub batch step 8507 -- lr 3.00e-04
2025-03-02 15:36:47,126 - INFO - Step 2126 -- ðŸ”„ Training Metrics
2025-03-02 15:36:47,127 - INFO - â”œâ”€â”€ Loss: 6.7544
2025-03-02 15:36:47,127 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:36:47,127 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:36:47,800 - INFO - ðŸªœ Batch step - 2127 -- sub batch step 8508 -- lr 3.00e-04
2025-03-02 15:36:49,965 - INFO - ðŸªœ Batch step - 2127 -- sub batch step 8509 -- lr 3.00e-04
2025-03-02 15:36:52,121 - INFO - ðŸªœ Batch step - 2127 -- sub batch step 8510 -- lr 3.00e-04
2025-03-02 15:36:54,835 - INFO - ðŸªœ Batch step - 2127 -- sub batch step 8511 -- lr 3.00e-04
2025-03-02 15:36:56,699 - INFO - Step 2127 -- ðŸ”„ Training Metrics
2025-03-02 15:36:56,700 - INFO - â”œâ”€â”€ Loss: 6.7850
2025-03-02 15:36:56,700 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:36:56,700 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:36:57,375 - INFO - ðŸªœ Batch step - 2128 -- sub batch step 8512 -- lr 3.00e-04
2025-03-02 15:36:59,534 - INFO - ðŸªœ Batch step - 2128 -- sub batch step 8513 -- lr 3.00e-04
2025-03-02 15:37:01,693 - INFO - ðŸªœ Batch step - 2128 -- sub batch step 8514 -- lr 3.00e-04
2025-03-02 15:37:03,871 - INFO - ðŸªœ Batch step - 2128 -- sub batch step 8515 -- lr 3.00e-04
2025-03-02 15:37:05,393 - INFO - Step 2128 -- ðŸ”„ Training Metrics
2025-03-02 15:37:05,393 - INFO - â”œâ”€â”€ Loss: 6.7695
2025-03-02 15:37:05,393 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:37:05,393 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:37:06,069 - INFO - ðŸªœ Batch step - 2129 -- sub batch step 8516 -- lr 3.00e-04
2025-03-02 15:37:08,230 - INFO - ðŸªœ Batch step - 2129 -- sub batch step 8517 -- lr 3.00e-04
2025-03-02 15:37:10,381 - INFO - ðŸªœ Batch step - 2129 -- sub batch step 8518 -- lr 3.00e-04
2025-03-02 15:37:13,085 - INFO - ðŸªœ Batch step - 2129 -- sub batch step 8519 -- lr 3.00e-04
2025-03-02 15:37:14,585 - INFO - Step 2129 -- ðŸ”„ Training Metrics
2025-03-02 15:37:14,585 - INFO - â”œâ”€â”€ Loss: 6.7542
2025-03-02 15:37:14,585 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:37:14,585 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:37:15,264 - INFO - ðŸªœ Batch step - 2130 -- sub batch step 8520 -- lr 3.00e-04
2025-03-02 15:37:17,418 - INFO - ðŸªœ Batch step - 2130 -- sub batch step 8521 -- lr 3.00e-04
2025-03-02 15:37:19,578 - INFO - ðŸªœ Batch step - 2130 -- sub batch step 8522 -- lr 3.00e-04
2025-03-02 15:37:21,749 - INFO - ðŸªœ Batch step - 2130 -- sub batch step 8523 -- lr 3.00e-04
2025-03-02 15:37:23,273 - INFO - Step 2130 -- ðŸ”„ Training Metrics
2025-03-02 15:37:23,273 - INFO - â”œâ”€â”€ Loss: 6.7892
2025-03-02 15:37:23,273 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:37:23,273 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:37:23,950 - INFO - ðŸªœ Batch step - 2131 -- sub batch step 8524 -- lr 3.00e-04
2025-03-02 15:37:26,108 - INFO - ðŸªœ Batch step - 2131 -- sub batch step 8525 -- lr 3.00e-04
2025-03-02 15:37:28,480 - INFO - ðŸªœ Batch step - 2131 -- sub batch step 8526 -- lr 3.00e-04
2025-03-02 15:37:30,642 - INFO - ðŸªœ Batch step - 2131 -- sub batch step 8527 -- lr 3.00e-04
2025-03-02 15:37:32,541 - INFO - Step 2131 -- ðŸ”„ Training Metrics
2025-03-02 15:37:32,541 - INFO - â”œâ”€â”€ Loss: 6.7875
2025-03-02 15:37:32,541 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:37:32,542 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:37:33,216 - INFO - ðŸªœ Batch step - 2132 -- sub batch step 8528 -- lr 3.00e-04
2025-03-02 15:37:35,378 - INFO - ðŸªœ Batch step - 2132 -- sub batch step 8529 -- lr 3.00e-04
2025-03-02 15:37:37,555 - INFO - ðŸªœ Batch step - 2132 -- sub batch step 8530 -- lr 3.00e-04
2025-03-02 15:37:39,708 - INFO - ðŸªœ Batch step - 2132 -- sub batch step 8531 -- lr 3.00e-04
2025-03-02 15:37:41,230 - INFO - Step 2132 -- ðŸ”„ Training Metrics
2025-03-02 15:37:41,230 - INFO - â”œâ”€â”€ Loss: 6.7637
2025-03-02 15:37:41,231 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:37:41,231 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:37:41,906 - INFO - ðŸªœ Batch step - 2133 -- sub batch step 8532 -- lr 3.00e-04
2025-03-02 15:37:44,064 - INFO - ðŸªœ Batch step - 2133 -- sub batch step 8533 -- lr 3.00e-04
2025-03-02 15:37:46,428 - INFO - ðŸªœ Batch step - 2133 -- sub batch step 8534 -- lr 3.00e-04
2025-03-02 15:37:48,590 - INFO - ðŸªœ Batch step - 2133 -- sub batch step 8535 -- lr 3.00e-04
2025-03-02 15:37:50,455 - INFO - Step 2133 -- ðŸ”„ Training Metrics
2025-03-02 15:37:50,455 - INFO - â”œâ”€â”€ Loss: 6.7482
2025-03-02 15:37:50,455 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:37:50,455 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:37:51,128 - INFO - ðŸªœ Batch step - 2134 -- sub batch step 8536 -- lr 3.00e-04
2025-03-02 15:37:53,293 - INFO - ðŸªœ Batch step - 2134 -- sub batch step 8537 -- lr 3.00e-04
2025-03-02 15:37:55,464 - INFO - ðŸªœ Batch step - 2134 -- sub batch step 8538 -- lr 3.00e-04
2025-03-02 15:37:57,623 - INFO - ðŸªœ Batch step - 2134 -- sub batch step 8539 -- lr 3.00e-04
2025-03-02 15:37:59,151 - INFO - Step 2134 -- ðŸ”„ Training Metrics
2025-03-02 15:37:59,152 - INFO - â”œâ”€â”€ Loss: 6.7422
2025-03-02 15:37:59,152 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:37:59,152 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:37:59,831 - INFO - ðŸªœ Batch step - 2135 -- sub batch step 8540 -- lr 3.00e-04
2025-03-02 15:38:01,986 - INFO - ðŸªœ Batch step - 2135 -- sub batch step 8541 -- lr 3.00e-04
2025-03-02 15:38:04,360 - INFO - ðŸªœ Batch step - 2135 -- sub batch step 8542 -- lr 3.00e-04
2025-03-02 15:38:06,510 - INFO - ðŸªœ Batch step - 2135 -- sub batch step 8543 -- lr 3.00e-04
2025-03-02 15:38:08,370 - INFO - Step 2135 -- ðŸ”„ Training Metrics
2025-03-02 15:38:08,370 - INFO - â”œâ”€â”€ Loss: 6.7395
2025-03-02 15:38:08,370 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:38:08,370 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:38:09,050 - INFO - ðŸªœ Batch step - 2136 -- sub batch step 8544 -- lr 3.00e-04
2025-03-02 15:38:11,209 - INFO - ðŸªœ Batch step - 2136 -- sub batch step 8545 -- lr 3.00e-04
2025-03-02 15:38:13,379 - INFO - ðŸªœ Batch step - 2136 -- sub batch step 8546 -- lr 3.00e-04
2025-03-02 15:38:15,537 - INFO - ðŸªœ Batch step - 2136 -- sub batch step 8547 -- lr 3.00e-04
2025-03-02 15:38:17,062 - INFO - Step 2136 -- ðŸ”„ Training Metrics
2025-03-02 15:38:17,063 - INFO - â”œâ”€â”€ Loss: 6.7521
2025-03-02 15:38:17,063 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:38:17,063 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:38:17,732 - INFO - ðŸªœ Batch step - 2137 -- sub batch step 8548 -- lr 3.00e-04
2025-03-02 15:38:19,892 - INFO - ðŸªœ Batch step - 2137 -- sub batch step 8549 -- lr 3.00e-04
2025-03-02 15:38:22,299 - INFO - ðŸªœ Batch step - 2137 -- sub batch step 8550 -- lr 3.00e-04
2025-03-02 15:38:24,454 - INFO - ðŸªœ Batch step - 2137 -- sub batch step 8551 -- lr 3.00e-04
2025-03-02 15:38:26,228 - INFO - Step 2137 -- ðŸ”„ Training Metrics
2025-03-02 15:38:26,245 - INFO - â”œâ”€â”€ Loss: 6.7693
2025-03-02 15:38:26,245 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:38:26,245 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:38:26,926 - INFO - ðŸªœ Batch step - 2138 -- sub batch step 8552 -- lr 3.00e-04
2025-03-02 15:38:29,081 - INFO - ðŸªœ Batch step - 2138 -- sub batch step 8553 -- lr 3.00e-04
2025-03-02 15:38:31,256 - INFO - ðŸªœ Batch step - 2138 -- sub batch step 8554 -- lr 3.00e-04
2025-03-02 15:38:33,416 - INFO - ðŸªœ Batch step - 2138 -- sub batch step 8555 -- lr 3.00e-04
2025-03-02 15:38:34,938 - INFO - Step 2138 -- ðŸ”„ Training Metrics
2025-03-02 15:38:34,939 - INFO - â”œâ”€â”€ Loss: 6.7600
2025-03-02 15:38:34,939 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:38:34,939 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:38:35,611 - INFO - ðŸªœ Batch step - 2139 -- sub batch step 8556 -- lr 3.00e-04
2025-03-02 15:38:37,773 - INFO - ðŸªœ Batch step - 2139 -- sub batch step 8557 -- lr 3.00e-04
2025-03-02 15:38:40,153 - INFO - ðŸªœ Batch step - 2139 -- sub batch step 8558 -- lr 3.00e-04
2025-03-02 15:38:42,312 - INFO - ðŸªœ Batch step - 2139 -- sub batch step 8559 -- lr 3.00e-04
2025-03-02 15:38:43,804 - INFO - Step 2139 -- ðŸ”„ Training Metrics
2025-03-02 15:38:43,805 - INFO - â”œâ”€â”€ Loss: 6.7340
2025-03-02 15:38:43,805 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:38:43,805 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:38:45,042 - INFO - ðŸªœ Batch step - 2140 -- sub batch step 8560 -- lr 3.00e-04
2025-03-02 15:38:47,196 - INFO - ðŸªœ Batch step - 2140 -- sub batch step 8561 -- lr 3.00e-04
2025-03-02 15:38:49,356 - INFO - ðŸªœ Batch step - 2140 -- sub batch step 8562 -- lr 3.00e-04
2025-03-02 15:38:51,531 - INFO - ðŸªœ Batch step - 2140 -- sub batch step 8563 -- lr 3.00e-04
2025-03-02 15:38:59,372 - INFO - Step 2140 -- ðŸ”„ Training Metrics
2025-03-02 15:38:59,372 - INFO - â”œâ”€â”€ Loss: 6.7677
2025-03-02 15:38:59,372 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:38:59,372 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:39:00,050 - INFO - ðŸªœ Batch step - 2141 -- sub batch step 8564 -- lr 3.00e-04
2025-03-02 15:39:02,206 - INFO - ðŸªœ Batch step - 2141 -- sub batch step 8565 -- lr 3.00e-04
2025-03-02 15:39:04,356 - INFO - ðŸªœ Batch step - 2141 -- sub batch step 8566 -- lr 3.00e-04
2025-03-02 15:39:07,008 - INFO - ðŸªœ Batch step - 2141 -- sub batch step 8567 -- lr 3.00e-04
2025-03-02 15:39:08,500 - INFO - Step 2141 -- ðŸ”„ Training Metrics
2025-03-02 15:39:08,500 - INFO - â”œâ”€â”€ Loss: 6.7507
2025-03-02 15:39:08,500 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:39:08,500 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:39:09,168 - INFO - ðŸªœ Batch step - 2142 -- sub batch step 8568 -- lr 3.00e-04
2025-03-02 15:39:11,328 - INFO - ðŸªœ Batch step - 2142 -- sub batch step 8569 -- lr 3.00e-04
2025-03-02 15:39:13,488 - INFO - ðŸªœ Batch step - 2142 -- sub batch step 8570 -- lr 3.00e-04
2025-03-02 15:39:15,659 - INFO - ðŸªœ Batch step - 2142 -- sub batch step 8571 -- lr 3.00e-04
2025-03-02 15:39:17,188 - INFO - Step 2142 -- ðŸ”„ Training Metrics
2025-03-02 15:39:17,188 - INFO - â”œâ”€â”€ Loss: 6.7186
2025-03-02 15:39:17,189 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:39:17,189 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:39:17,869 - INFO - ðŸªœ Batch step - 2143 -- sub batch step 8572 -- lr 3.00e-04
2025-03-02 15:39:20,025 - INFO - ðŸªœ Batch step - 2143 -- sub batch step 8573 -- lr 3.00e-04
2025-03-02 15:39:22,183 - INFO - ðŸªœ Batch step - 2143 -- sub batch step 8574 -- lr 3.00e-04
2025-03-02 15:39:24,919 - INFO - ðŸªœ Batch step - 2143 -- sub batch step 8575 -- lr 3.00e-04
2025-03-02 15:39:26,412 - INFO - Step 2143 -- ðŸ”„ Training Metrics
2025-03-02 15:39:26,413 - INFO - â”œâ”€â”€ Loss: 6.7353
2025-03-02 15:39:26,413 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:39:26,413 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:39:27,087 - INFO - ðŸªœ Batch step - 2144 -- sub batch step 8576 -- lr 3.00e-04
2025-03-02 15:39:29,244 - INFO - ðŸªœ Batch step - 2144 -- sub batch step 8577 -- lr 3.00e-04
2025-03-02 15:39:31,395 - INFO - ðŸªœ Batch step - 2144 -- sub batch step 8578 -- lr 3.00e-04
2025-03-02 15:39:33,572 - INFO - ðŸªœ Batch step - 2144 -- sub batch step 8579 -- lr 3.00e-04
2025-03-02 15:39:35,110 - INFO - Step 2144 -- ðŸ”„ Training Metrics
2025-03-02 15:39:35,110 - INFO - â”œâ”€â”€ Loss: 6.7365
2025-03-02 15:39:35,110 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:39:35,110 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:39:35,786 - INFO - ðŸªœ Batch step - 2145 -- sub batch step 8580 -- lr 3.00e-04
2025-03-02 15:39:37,943 - INFO - ðŸªœ Batch step - 2145 -- sub batch step 8581 -- lr 3.00e-04
2025-03-02 15:39:40,100 - INFO - ðŸªœ Batch step - 2145 -- sub batch step 8582 -- lr 3.00e-04
2025-03-02 15:39:42,804 - INFO - ðŸªœ Batch step - 2145 -- sub batch step 8583 -- lr 3.00e-04
2025-03-02 15:39:44,410 - INFO - Step 2145 -- ðŸ”„ Training Metrics
2025-03-02 15:39:44,410 - INFO - â”œâ”€â”€ Loss: 6.7187
2025-03-02 15:39:44,410 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:39:44,411 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:39:45,087 - INFO - ðŸªœ Batch step - 2146 -- sub batch step 8584 -- lr 3.00e-04
2025-03-02 15:39:47,243 - INFO - ðŸªœ Batch step - 2146 -- sub batch step 8585 -- lr 3.00e-04
2025-03-02 15:39:49,397 - INFO - ðŸªœ Batch step - 2146 -- sub batch step 8586 -- lr 3.00e-04
2025-03-02 15:39:51,573 - INFO - ðŸªœ Batch step - 2146 -- sub batch step 8587 -- lr 3.00e-04
2025-03-02 15:39:53,097 - INFO - Step 2146 -- ðŸ”„ Training Metrics
2025-03-02 15:39:53,097 - INFO - â”œâ”€â”€ Loss: 6.7414
2025-03-02 15:39:53,097 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:39:53,098 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:39:53,765 - INFO - ðŸªœ Batch step - 2147 -- sub batch step 8588 -- lr 3.00e-04
2025-03-02 15:39:55,927 - INFO - ðŸªœ Batch step - 2147 -- sub batch step 8589 -- lr 3.00e-04
2025-03-02 15:39:58,084 - INFO - ðŸªœ Batch step - 2147 -- sub batch step 8590 -- lr 3.00e-04
2025-03-02 15:40:01,217 - INFO - ðŸªœ Batch step - 2147 -- sub batch step 8591 -- lr 3.00e-04
2025-03-02 15:40:02,708 - INFO - Step 2147 -- ðŸ”„ Training Metrics
2025-03-02 15:40:02,708 - INFO - â”œâ”€â”€ Loss: 6.7457
2025-03-02 15:40:02,708 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:40:02,708 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:40:03,388 - INFO - ðŸªœ Batch step - 2148 -- sub batch step 8592 -- lr 3.00e-04
2025-03-02 15:40:05,542 - INFO - ðŸªœ Batch step - 2148 -- sub batch step 8593 -- lr 3.00e-04
2025-03-02 15:40:07,697 - INFO - ðŸªœ Batch step - 2148 -- sub batch step 8594 -- lr 3.00e-04
2025-03-02 15:40:09,871 - INFO - ðŸªœ Batch step - 2148 -- sub batch step 8595 -- lr 3.00e-04
2025-03-02 15:40:11,401 - INFO - Step 2148 -- ðŸ”„ Training Metrics
2025-03-02 15:40:11,401 - INFO - â”œâ”€â”€ Loss: 6.7412
2025-03-02 15:40:11,401 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:40:11,401 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:40:12,069 - INFO - ðŸªœ Batch step - 2149 -- sub batch step 8596 -- lr 3.00e-04
2025-03-02 15:40:14,234 - INFO - ðŸªœ Batch step - 2149 -- sub batch step 8597 -- lr 3.00e-04
2025-03-02 15:40:16,390 - INFO - ðŸªœ Batch step - 2149 -- sub batch step 8598 -- lr 3.00e-04
2025-03-02 15:40:19,138 - INFO - ðŸªœ Batch step - 2149 -- sub batch step 8599 -- lr 3.00e-04
2025-03-02 15:40:20,627 - INFO - Step 2149 -- ðŸ”„ Training Metrics
2025-03-02 15:40:20,628 - INFO - â”œâ”€â”€ Loss: 6.7560
2025-03-02 15:40:20,628 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:40:20,628 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:40:21,302 - INFO - ðŸªœ Batch step - 2150 -- sub batch step 8600 -- lr 3.00e-04
2025-03-02 15:40:23,465 - INFO - ðŸªœ Batch step - 2150 -- sub batch step 8601 -- lr 3.00e-04
2025-03-02 15:40:25,622 - INFO - ðŸªœ Batch step - 2150 -- sub batch step 8602 -- lr 3.00e-04
2025-03-02 15:40:27,786 - INFO - ðŸªœ Batch step - 2150 -- sub batch step 8603 -- lr 3.00e-04
2025-03-02 15:40:29,309 - INFO - Step 2150 -- ðŸ”„ Training Metrics
2025-03-02 15:40:29,310 - INFO - â”œâ”€â”€ Loss: 6.7079
2025-03-02 15:40:29,310 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:40:29,310 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:40:29,988 - INFO - ðŸªœ Batch step - 2151 -- sub batch step 8604 -- lr 3.00e-04
2025-03-02 15:40:32,147 - INFO - ðŸªœ Batch step - 2151 -- sub batch step 8605 -- lr 3.00e-04
2025-03-02 15:40:34,795 - INFO - ðŸªœ Batch step - 2151 -- sub batch step 8606 -- lr 3.00e-04
2025-03-02 15:40:36,960 - INFO - ðŸªœ Batch step - 2151 -- sub batch step 8607 -- lr 3.00e-04
2025-03-02 15:40:38,540 - INFO - Step 2151 -- ðŸ”„ Training Metrics
2025-03-02 15:40:38,541 - INFO - â”œâ”€â”€ Loss: 6.7364
2025-03-02 15:40:38,541 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:40:38,541 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:40:39,208 - INFO - ðŸªœ Batch step - 2152 -- sub batch step 8608 -- lr 3.00e-04
2025-03-02 15:40:41,371 - INFO - ðŸªœ Batch step - 2152 -- sub batch step 8609 -- lr 3.00e-04
2025-03-02 15:40:43,550 - INFO - ðŸªœ Batch step - 2152 -- sub batch step 8610 -- lr 3.00e-04
2025-03-02 15:40:45,707 - INFO - ðŸªœ Batch step - 2152 -- sub batch step 8611 -- lr 3.00e-04
2025-03-02 15:40:47,253 - INFO - Step 2152 -- ðŸ”„ Training Metrics
2025-03-02 15:40:47,253 - INFO - â”œâ”€â”€ Loss: 6.7178
2025-03-02 15:40:47,253 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:40:47,254 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:40:47,934 - INFO - ðŸªœ Batch step - 2153 -- sub batch step 8612 -- lr 3.00e-04
2025-03-02 15:40:50,088 - INFO - ðŸªœ Batch step - 2153 -- sub batch step 8613 -- lr 3.00e-04
2025-03-02 15:40:52,742 - INFO - ðŸªœ Batch step - 2153 -- sub batch step 8614 -- lr 3.00e-04
2025-03-02 15:40:54,903 - INFO - ðŸªœ Batch step - 2153 -- sub batch step 8615 -- lr 3.00e-04
2025-03-02 15:40:56,459 - INFO - Step 2153 -- ðŸ”„ Training Metrics
2025-03-02 15:40:56,459 - INFO - â”œâ”€â”€ Loss: 6.7181
2025-03-02 15:40:56,459 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:40:56,459 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:40:57,133 - INFO - ðŸªœ Batch step - 2154 -- sub batch step 8616 -- lr 3.00e-04
2025-03-02 15:40:59,295 - INFO - ðŸªœ Batch step - 2154 -- sub batch step 8617 -- lr 3.00e-04
2025-03-02 15:41:01,464 - INFO - ðŸªœ Batch step - 2154 -- sub batch step 8618 -- lr 3.00e-04
2025-03-02 15:41:03,624 - INFO - ðŸªœ Batch step - 2154 -- sub batch step 8619 -- lr 3.00e-04
2025-03-02 15:41:05,178 - INFO - Step 2154 -- ðŸ”„ Training Metrics
2025-03-02 15:41:05,178 - INFO - â”œâ”€â”€ Loss: 6.7234
2025-03-02 15:41:05,178 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:41:05,179 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:41:05,856 - INFO - ðŸªœ Batch step - 2155 -- sub batch step 8620 -- lr 3.00e-04
2025-03-02 15:41:08,007 - INFO - ðŸªœ Batch step - 2155 -- sub batch step 8621 -- lr 3.00e-04
2025-03-02 15:41:10,867 - INFO - ðŸªœ Batch step - 2155 -- sub batch step 8622 -- lr 3.00e-04
2025-03-02 15:41:13,022 - INFO - ðŸªœ Batch step - 2155 -- sub batch step 8623 -- lr 3.00e-04
2025-03-02 15:41:14,513 - INFO - Step 2155 -- ðŸ”„ Training Metrics
2025-03-02 15:41:14,513 - INFO - â”œâ”€â”€ Loss: 6.7275
2025-03-02 15:41:14,513 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:41:14,513 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:41:15,188 - INFO - ðŸªœ Batch step - 2156 -- sub batch step 8624 -- lr 3.00e-04
2025-03-02 15:41:17,343 - INFO - ðŸªœ Batch step - 2156 -- sub batch step 8625 -- lr 3.00e-04
2025-03-02 15:41:19,513 - INFO - ðŸªœ Batch step - 2156 -- sub batch step 8626 -- lr 3.00e-04
2025-03-02 15:41:21,667 - INFO - ðŸªœ Batch step - 2156 -- sub batch step 8627 -- lr 3.00e-04
2025-03-02 15:41:23,228 - INFO - Step 2156 -- ðŸ”„ Training Metrics
2025-03-02 15:41:23,228 - INFO - â”œâ”€â”€ Loss: 6.7197
2025-03-02 15:41:23,228 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:41:23,228 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:41:23,894 - INFO - ðŸªœ Batch step - 2157 -- sub batch step 8628 -- lr 3.00e-04
2025-03-02 15:41:26,054 - INFO - ðŸªœ Batch step - 2157 -- sub batch step 8629 -- lr 3.00e-04
2025-03-02 15:41:28,756 - INFO - ðŸªœ Batch step - 2157 -- sub batch step 8630 -- lr 3.00e-04
2025-03-02 15:41:30,911 - INFO - ðŸªœ Batch step - 2157 -- sub batch step 8631 -- lr 3.00e-04
2025-03-02 15:41:32,550 - INFO - Step 2157 -- ðŸ”„ Training Metrics
2025-03-02 15:41:32,551 - INFO - â”œâ”€â”€ Loss: 6.7248
2025-03-02 15:41:32,551 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:41:32,551 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:41:33,231 - INFO - ðŸªœ Batch step - 2158 -- sub batch step 8632 -- lr 3.00e-04
2025-03-02 15:41:35,384 - INFO - ðŸªœ Batch step - 2158 -- sub batch step 8633 -- lr 3.00e-04
2025-03-02 15:41:37,558 - INFO - ðŸªœ Batch step - 2158 -- sub batch step 8634 -- lr 3.00e-04
2025-03-02 15:41:39,713 - INFO - ðŸªœ Batch step - 2158 -- sub batch step 8635 -- lr 3.00e-04
2025-03-02 15:41:41,265 - INFO - Step 2158 -- ðŸ”„ Training Metrics
2025-03-02 15:41:41,265 - INFO - â”œâ”€â”€ Loss: 6.7579
2025-03-02 15:41:41,265 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:41:41,265 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:41:41,937 - INFO - ðŸªœ Batch step - 2159 -- sub batch step 8636 -- lr 3.00e-04
2025-03-02 15:41:44,093 - INFO - ðŸªœ Batch step - 2159 -- sub batch step 8637 -- lr 3.00e-04
2025-03-02 15:41:46,481 - INFO - ðŸªœ Batch step - 2159 -- sub batch step 8638 -- lr 3.00e-04
2025-03-02 15:41:48,633 - INFO - ðŸªœ Batch step - 2159 -- sub batch step 8639 -- lr 3.00e-04
2025-03-02 15:41:50,327 - INFO - Step 2159 -- ðŸ”„ Training Metrics
2025-03-02 15:41:50,327 - INFO - â”œâ”€â”€ Loss: 6.7422
2025-03-02 15:41:50,327 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:41:50,327 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:41:51,533 - INFO - ðŸªœ Batch step - 2160 -- sub batch step 8640 -- lr 3.00e-04
2025-03-02 15:41:53,695 - INFO - ðŸªœ Batch step - 2160 -- sub batch step 8641 -- lr 3.00e-04
2025-03-02 15:41:55,862 - INFO - ðŸªœ Batch step - 2160 -- sub batch step 8642 -- lr 3.00e-04
2025-03-02 15:41:58,040 - INFO - ðŸªœ Batch step - 2160 -- sub batch step 8643 -- lr 3.00e-04
2025-03-02 15:41:59,708 - INFO - Step 2160 -- ðŸ”„ Training Metrics
2025-03-02 15:41:59,709 - INFO - â”œâ”€â”€ Loss: 6.7351
2025-03-02 15:41:59,709 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:41:59,709 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:42:00,386 - INFO - ðŸªœ Batch step - 2161 -- sub batch step 8644 -- lr 3.00e-04
2025-03-02 15:42:02,548 - INFO - ðŸªœ Batch step - 2161 -- sub batch step 8645 -- lr 3.00e-04
2025-03-02 15:42:04,705 - INFO - ðŸªœ Batch step - 2161 -- sub batch step 8646 -- lr 3.00e-04
2025-03-02 15:42:07,136 - INFO - ðŸªœ Batch step - 2161 -- sub batch step 8647 -- lr 3.00e-04
2025-03-02 15:42:08,790 - INFO - Step 2161 -- ðŸ”„ Training Metrics
2025-03-02 15:42:08,791 - INFO - â”œâ”€â”€ Loss: 6.7177
2025-03-02 15:42:08,791 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:42:08,791 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:42:09,463 - INFO - ðŸªœ Batch step - 2162 -- sub batch step 8648 -- lr 3.00e-04
2025-03-02 15:42:11,626 - INFO - ðŸªœ Batch step - 2162 -- sub batch step 8649 -- lr 3.00e-04
2025-03-02 15:42:13,783 - INFO - ðŸªœ Batch step - 2162 -- sub batch step 8650 -- lr 3.00e-04
2025-03-02 15:42:15,957 - INFO - ðŸªœ Batch step - 2162 -- sub batch step 8651 -- lr 3.00e-04
2025-03-02 15:42:17,489 - INFO - Step 2162 -- ðŸ”„ Training Metrics
2025-03-02 15:42:17,489 - INFO - â”œâ”€â”€ Loss: 6.7245
2025-03-02 15:42:17,489 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:42:17,489 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:42:18,169 - INFO - ðŸªœ Batch step - 2163 -- sub batch step 8652 -- lr 3.00e-04
2025-03-02 15:42:20,322 - INFO - ðŸªœ Batch step - 2163 -- sub batch step 8653 -- lr 3.00e-04
2025-03-02 15:42:22,479 - INFO - ðŸªœ Batch step - 2163 -- sub batch step 8654 -- lr 3.00e-04
2025-03-02 15:42:25,141 - INFO - ðŸªœ Batch step - 2163 -- sub batch step 8655 -- lr 3.00e-04
2025-03-02 15:42:27,145 - INFO - Step 2163 -- ðŸ”„ Training Metrics
2025-03-02 15:42:27,145 - INFO - â”œâ”€â”€ Loss: 6.6968
2025-03-02 15:42:27,145 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:42:27,145 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:42:27,812 - INFO - ðŸªœ Batch step - 2164 -- sub batch step 8656 -- lr 3.00e-04
2025-03-02 15:42:29,973 - INFO - ðŸªœ Batch step - 2164 -- sub batch step 8657 -- lr 3.00e-04
2025-03-02 15:42:32,124 - INFO - ðŸªœ Batch step - 2164 -- sub batch step 8658 -- lr 3.00e-04
2025-03-02 15:42:34,300 - INFO - ðŸªœ Batch step - 2164 -- sub batch step 8659 -- lr 3.00e-04
2025-03-02 15:42:35,850 - INFO - Step 2164 -- ðŸ”„ Training Metrics
2025-03-02 15:42:35,851 - INFO - â”œâ”€â”€ Loss: 6.6995
2025-03-02 15:42:35,851 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:42:35,851 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:42:36,530 - INFO - ðŸªœ Batch step - 2165 -- sub batch step 8660 -- lr 3.00e-04
2025-03-02 15:42:38,684 - INFO - ðŸªœ Batch step - 2165 -- sub batch step 8661 -- lr 3.00e-04
2025-03-02 15:42:40,841 - INFO - ðŸªœ Batch step - 2165 -- sub batch step 8662 -- lr 3.00e-04
2025-03-02 15:42:43,231 - INFO - ðŸªœ Batch step - 2165 -- sub batch step 8663 -- lr 3.00e-04
2025-03-02 15:42:45,157 - INFO - Step 2165 -- ðŸ”„ Training Metrics
2025-03-02 15:42:45,157 - INFO - â”œâ”€â”€ Loss: 6.7015
2025-03-02 15:42:45,157 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:42:45,158 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:42:45,835 - INFO - ðŸªœ Batch step - 2166 -- sub batch step 8664 -- lr 3.00e-04
2025-03-02 15:42:47,993 - INFO - ðŸªœ Batch step - 2166 -- sub batch step 8665 -- lr 3.00e-04
2025-03-02 15:42:50,142 - INFO - ðŸªœ Batch step - 2166 -- sub batch step 8666 -- lr 3.00e-04
2025-03-02 15:42:52,316 - INFO - ðŸªœ Batch step - 2166 -- sub batch step 8667 -- lr 3.00e-04
2025-03-02 15:42:53,861 - INFO - Step 2166 -- ðŸ”„ Training Metrics
2025-03-02 15:42:53,861 - INFO - â”œâ”€â”€ Loss: 6.6924
2025-03-02 15:42:53,861 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:42:53,862 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:42:54,529 - INFO - ðŸªœ Batch step - 2167 -- sub batch step 8668 -- lr 3.00e-04
2025-03-02 15:42:56,687 - INFO - ðŸªœ Batch step - 2167 -- sub batch step 8669 -- lr 3.00e-04
2025-03-02 15:42:58,842 - INFO - ðŸªœ Batch step - 2167 -- sub batch step 8670 -- lr 3.00e-04
2025-03-02 15:43:01,250 - INFO - ðŸªœ Batch step - 2167 -- sub batch step 8671 -- lr 3.00e-04
2025-03-02 15:43:03,030 - INFO - Step 2167 -- ðŸ”„ Training Metrics
2025-03-02 15:43:03,031 - INFO - â”œâ”€â”€ Loss: 6.7003
2025-03-02 15:43:03,031 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:43:03,031 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:43:03,705 - INFO - ðŸªœ Batch step - 2168 -- sub batch step 8672 -- lr 3.00e-04
2025-03-02 15:43:05,862 - INFO - ðŸªœ Batch step - 2168 -- sub batch step 8673 -- lr 3.00e-04
2025-03-02 15:43:08,017 - INFO - ðŸªœ Batch step - 2168 -- sub batch step 8674 -- lr 3.00e-04
2025-03-02 15:43:10,187 - INFO - ðŸªœ Batch step - 2168 -- sub batch step 8675 -- lr 3.00e-04
2025-03-02 15:43:11,737 - INFO - Step 2168 -- ðŸ”„ Training Metrics
2025-03-02 15:43:11,738 - INFO - â”œâ”€â”€ Loss: 6.6838
2025-03-02 15:43:11,738 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:43:11,738 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:43:12,407 - INFO - ðŸªœ Batch step - 2169 -- sub batch step 8676 -- lr 3.00e-04
2025-03-02 15:43:14,571 - INFO - ðŸªœ Batch step - 2169 -- sub batch step 8677 -- lr 3.00e-04
2025-03-02 15:43:16,723 - INFO - ðŸªœ Batch step - 2169 -- sub batch step 8678 -- lr 3.00e-04
2025-03-02 15:43:19,077 - INFO - ðŸªœ Batch step - 2169 -- sub batch step 8679 -- lr 3.00e-04
2025-03-02 15:43:20,899 - INFO - Step 2169 -- ðŸ”„ Training Metrics
2025-03-02 15:43:20,900 - INFO - â”œâ”€â”€ Loss: 6.6975
2025-03-02 15:43:20,900 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:43:20,900 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:43:21,573 - INFO - ðŸªœ Batch step - 2170 -- sub batch step 8680 -- lr 3.00e-04
2025-03-02 15:43:23,729 - INFO - ðŸªœ Batch step - 2170 -- sub batch step 8681 -- lr 3.00e-04
2025-03-02 15:43:25,885 - INFO - ðŸªœ Batch step - 2170 -- sub batch step 8682 -- lr 3.00e-04
2025-03-02 15:43:28,050 - INFO - ðŸªœ Batch step - 2170 -- sub batch step 8683 -- lr 3.00e-04
2025-03-02 15:43:29,592 - INFO - Step 2170 -- ðŸ”„ Training Metrics
2025-03-02 15:43:29,592 - INFO - â”œâ”€â”€ Loss: 6.7277
2025-03-02 15:43:29,592 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:43:29,592 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:43:30,269 - INFO - ðŸªœ Batch step - 2171 -- sub batch step 8684 -- lr 3.00e-04
2025-03-02 15:43:32,425 - INFO - ðŸªœ Batch step - 2171 -- sub batch step 8685 -- lr 3.00e-04
2025-03-02 15:43:34,776 - INFO - ðŸªœ Batch step - 2171 -- sub batch step 8686 -- lr 3.00e-04
2025-03-02 15:43:36,936 - INFO - ðŸªœ Batch step - 2171 -- sub batch step 8687 -- lr 3.00e-04
2025-03-02 15:43:43,717 - INFO - Step 2171 -- ðŸ”„ Training Metrics
2025-03-02 15:43:43,718 - INFO - â”œâ”€â”€ Loss: 6.6734
2025-03-02 15:43:43,718 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:43:43,718 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:43:44,386 - INFO - ðŸªœ Batch step - 2172 -- sub batch step 8688 -- lr 3.00e-04
2025-03-02 15:43:46,547 - INFO - ðŸªœ Batch step - 2172 -- sub batch step 8689 -- lr 3.00e-04
2025-03-02 15:43:48,721 - INFO - ðŸªœ Batch step - 2172 -- sub batch step 8690 -- lr 3.00e-04
2025-03-02 15:43:50,871 - INFO - ðŸªœ Batch step - 2172 -- sub batch step 8691 -- lr 3.00e-04
2025-03-02 15:43:52,421 - INFO - Step 2172 -- ðŸ”„ Training Metrics
2025-03-02 15:43:52,422 - INFO - â”œâ”€â”€ Loss: 6.7202
2025-03-02 15:43:52,422 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:43:52,422 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:43:53,103 - INFO - ðŸªœ Batch step - 2173 -- sub batch step 8692 -- lr 3.00e-04
2025-03-02 15:43:55,254 - INFO - ðŸªœ Batch step - 2173 -- sub batch step 8693 -- lr 3.00e-04
2025-03-02 15:43:57,939 - INFO - ðŸªœ Batch step - 2173 -- sub batch step 8694 -- lr 3.00e-04
2025-03-02 15:44:00,093 - INFO - ðŸªœ Batch step - 2173 -- sub batch step 8695 -- lr 3.00e-04
2025-03-02 15:44:01,756 - INFO - Step 2173 -- ðŸ”„ Training Metrics
2025-03-02 15:44:01,756 - INFO - â”œâ”€â”€ Loss: 6.7176
2025-03-02 15:44:01,756 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:44:01,756 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:44:02,431 - INFO - ðŸªœ Batch step - 2174 -- sub batch step 8696 -- lr 3.00e-04
2025-03-02 15:44:04,591 - INFO - ðŸªœ Batch step - 2174 -- sub batch step 8697 -- lr 3.00e-04
2025-03-02 15:44:06,757 - INFO - ðŸªœ Batch step - 2174 -- sub batch step 8698 -- lr 3.00e-04
2025-03-02 15:44:08,914 - INFO - ðŸªœ Batch step - 2174 -- sub batch step 8699 -- lr 3.00e-04
2025-03-02 15:44:10,465 - INFO - Step 2174 -- ðŸ”„ Training Metrics
2025-03-02 15:44:10,465 - INFO - â”œâ”€â”€ Loss: 6.7041
2025-03-02 15:44:10,465 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:44:10,466 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:44:11,139 - INFO - ðŸªœ Batch step - 2175 -- sub batch step 8700 -- lr 3.00e-04
2025-03-02 15:44:13,295 - INFO - ðŸªœ Batch step - 2175 -- sub batch step 8701 -- lr 3.00e-04
2025-03-02 15:44:16,028 - INFO - ðŸªœ Batch step - 2175 -- sub batch step 8702 -- lr 3.00e-04
2025-03-02 15:44:18,187 - INFO - ðŸªœ Batch step - 2175 -- sub batch step 8703 -- lr 3.00e-04
2025-03-02 15:44:19,681 - INFO - Step 2175 -- ðŸ”„ Training Metrics
2025-03-02 15:44:19,682 - INFO - â”œâ”€â”€ Loss: 6.7069
2025-03-02 15:44:19,682 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:44:19,682 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:44:20,361 - INFO - ðŸªœ Batch step - 2176 -- sub batch step 8704 -- lr 3.00e-04
2025-03-02 15:44:22,519 - INFO - ðŸªœ Batch step - 2176 -- sub batch step 8705 -- lr 3.00e-04
2025-03-02 15:44:24,689 - INFO - ðŸªœ Batch step - 2176 -- sub batch step 8706 -- lr 3.00e-04
2025-03-02 15:44:26,847 - INFO - ðŸªœ Batch step - 2176 -- sub batch step 8707 -- lr 3.00e-04
2025-03-02 15:44:28,386 - INFO - Step 2176 -- ðŸ”„ Training Metrics
2025-03-02 15:44:28,386 - INFO - â”œâ”€â”€ Loss: 6.6744
2025-03-02 15:44:28,386 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:44:28,386 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:44:29,058 - INFO - ðŸªœ Batch step - 2177 -- sub batch step 8708 -- lr 3.00e-04
2025-03-02 15:44:31,217 - INFO - ðŸªœ Batch step - 2177 -- sub batch step 8709 -- lr 3.00e-04
2025-03-02 15:44:33,945 - INFO - ðŸªœ Batch step - 2177 -- sub batch step 8710 -- lr 3.00e-04
2025-03-02 15:44:36,099 - INFO - ðŸªœ Batch step - 2177 -- sub batch step 8711 -- lr 3.00e-04
2025-03-02 15:44:37,644 - INFO - Step 2177 -- ðŸ”„ Training Metrics
2025-03-02 15:44:37,644 - INFO - â”œâ”€â”€ Loss: 6.6898
2025-03-02 15:44:37,644 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:44:37,644 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:44:38,320 - INFO - ðŸªœ Batch step - 2178 -- sub batch step 8712 -- lr 3.00e-04
2025-03-02 15:44:40,475 - INFO - ðŸªœ Batch step - 2178 -- sub batch step 8713 -- lr 3.00e-04
2025-03-02 15:44:42,653 - INFO - ðŸªœ Batch step - 2178 -- sub batch step 8714 -- lr 3.00e-04
2025-03-02 15:44:44,807 - INFO - ðŸªœ Batch step - 2178 -- sub batch step 8715 -- lr 3.00e-04
2025-03-02 15:44:46,353 - INFO - Step 2178 -- ðŸ”„ Training Metrics
2025-03-02 15:44:46,353 - INFO - â”œâ”€â”€ Loss: 6.6933
2025-03-02 15:44:46,354 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:44:46,354 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:44:47,021 - INFO - ðŸªœ Batch step - 2179 -- sub batch step 8716 -- lr 3.00e-04
2025-03-02 15:44:49,180 - INFO - ðŸªœ Batch step - 2179 -- sub batch step 8717 -- lr 3.00e-04
2025-03-02 15:44:51,469 - INFO - ðŸªœ Batch step - 2179 -- sub batch step 8718 -- lr 3.00e-04
2025-03-02 15:44:53,624 - INFO - ðŸªœ Batch step - 2179 -- sub batch step 8719 -- lr 3.00e-04
2025-03-02 15:44:55,655 - INFO - Step 2179 -- ðŸ”„ Training Metrics
2025-03-02 15:44:55,655 - INFO - â”œâ”€â”€ Loss: 6.6958
2025-03-02 15:44:55,655 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:44:55,656 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:44:56,849 - INFO - ðŸªœ Batch step - 2180 -- sub batch step 8720 -- lr 3.00e-04
2025-03-02 15:44:59,000 - INFO - ðŸªœ Batch step - 2180 -- sub batch step 8721 -- lr 3.00e-04
2025-03-02 15:45:01,158 - INFO - ðŸªœ Batch step - 2180 -- sub batch step 8722 -- lr 3.00e-04
2025-03-02 15:45:03,332 - INFO - ðŸªœ Batch step - 2180 -- sub batch step 8723 -- lr 3.00e-04
2025-03-02 15:45:05,039 - INFO - Step 2180 -- ðŸ”„ Training Metrics
2025-03-02 15:45:05,039 - INFO - â”œâ”€â”€ Loss: 6.6799
2025-03-02 15:45:05,039 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:45:05,039 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:45:05,715 - INFO - ðŸªœ Batch step - 2181 -- sub batch step 8724 -- lr 3.00e-04
2025-03-02 15:45:07,872 - INFO - ðŸªœ Batch step - 2181 -- sub batch step 8725 -- lr 3.00e-04
2025-03-02 15:45:10,024 - INFO - ðŸªœ Batch step - 2181 -- sub batch step 8726 -- lr 3.00e-04
2025-03-02 15:45:12,529 - INFO - ðŸªœ Batch step - 2181 -- sub batch step 8727 -- lr 3.00e-04
2025-03-02 15:45:14,263 - INFO - Step 2181 -- ðŸ”„ Training Metrics
2025-03-02 15:45:14,264 - INFO - â”œâ”€â”€ Loss: 6.6729
2025-03-02 15:45:14,264 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:45:14,264 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:45:14,932 - INFO - ðŸªœ Batch step - 2182 -- sub batch step 8728 -- lr 3.00e-04
2025-03-02 15:45:17,096 - INFO - ðŸªœ Batch step - 2182 -- sub batch step 8729 -- lr 3.00e-04
2025-03-02 15:45:19,254 - INFO - ðŸªœ Batch step - 2182 -- sub batch step 8730 -- lr 3.00e-04
2025-03-02 15:45:21,424 - INFO - ðŸªœ Batch step - 2182 -- sub batch step 8731 -- lr 3.00e-04
2025-03-02 15:45:22,955 - INFO - Step 2182 -- ðŸ”„ Training Metrics
2025-03-02 15:45:22,955 - INFO - â”œâ”€â”€ Loss: 6.6914
2025-03-02 15:45:22,955 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:45:22,955 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:45:23,633 - INFO - ðŸªœ Batch step - 2183 -- sub batch step 8732 -- lr 3.00e-04
2025-03-02 15:45:25,789 - INFO - ðŸªœ Batch step - 2183 -- sub batch step 8733 -- lr 3.00e-04
2025-03-02 15:45:27,945 - INFO - ðŸªœ Batch step - 2183 -- sub batch step 8734 -- lr 3.00e-04
2025-03-02 15:45:30,396 - INFO - ðŸªœ Batch step - 2183 -- sub batch step 8735 -- lr 3.00e-04
2025-03-02 15:45:32,232 - INFO - Step 2183 -- ðŸ”„ Training Metrics
2025-03-02 15:45:32,232 - INFO - â”œâ”€â”€ Loss: 6.6728
2025-03-02 15:45:32,232 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:45:32,232 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:45:32,901 - INFO - ðŸªœ Batch step - 2184 -- sub batch step 8736 -- lr 3.00e-04
2025-03-02 15:45:35,066 - INFO - ðŸªœ Batch step - 2184 -- sub batch step 8737 -- lr 3.00e-04
2025-03-02 15:45:37,216 - INFO - ðŸªœ Batch step - 2184 -- sub batch step 8738 -- lr 3.00e-04
2025-03-02 15:45:39,393 - INFO - ðŸªœ Batch step - 2184 -- sub batch step 8739 -- lr 3.00e-04
2025-03-02 15:45:40,916 - INFO - Step 2184 -- ðŸ”„ Training Metrics
2025-03-02 15:45:40,917 - INFO - â”œâ”€â”€ Loss: 6.6819
2025-03-02 15:45:40,917 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:45:40,917 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:45:41,590 - INFO - ðŸªœ Batch step - 2185 -- sub batch step 8740 -- lr 3.00e-04
2025-03-02 15:45:43,748 - INFO - ðŸªœ Batch step - 2185 -- sub batch step 8741 -- lr 3.00e-04
2025-03-02 15:45:45,900 - INFO - ðŸªœ Batch step - 2185 -- sub batch step 8742 -- lr 3.00e-04
2025-03-02 15:45:48,615 - INFO - ðŸªœ Batch step - 2185 -- sub batch step 8743 -- lr 3.00e-04
2025-03-02 15:45:50,287 - INFO - Step 2185 -- ðŸ”„ Training Metrics
2025-03-02 15:45:50,287 - INFO - â”œâ”€â”€ Loss: 6.6802
2025-03-02 15:45:50,287 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:45:50,287 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:45:50,960 - INFO - ðŸªœ Batch step - 2186 -- sub batch step 8744 -- lr 3.00e-04
2025-03-02 15:45:53,117 - INFO - ðŸªœ Batch step - 2186 -- sub batch step 8745 -- lr 3.00e-04
2025-03-02 15:45:55,266 - INFO - ðŸªœ Batch step - 2186 -- sub batch step 8746 -- lr 3.00e-04
2025-03-02 15:45:57,440 - INFO - ðŸªœ Batch step - 2186 -- sub batch step 8747 -- lr 3.00e-04
2025-03-02 15:45:58,977 - INFO - Step 2186 -- ðŸ”„ Training Metrics
2025-03-02 15:45:58,977 - INFO - â”œâ”€â”€ Loss: 6.6714
2025-03-02 15:45:58,977 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:45:58,977 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:45:59,646 - INFO - ðŸªœ Batch step - 2187 -- sub batch step 8748 -- lr 3.00e-04
2025-03-02 15:46:01,804 - INFO - ðŸªœ Batch step - 2187 -- sub batch step 8749 -- lr 3.00e-04
2025-03-02 15:46:03,957 - INFO - ðŸªœ Batch step - 2187 -- sub batch step 8750 -- lr 3.00e-04
2025-03-02 15:46:06,631 - INFO - ðŸªœ Batch step - 2187 -- sub batch step 8751 -- lr 3.00e-04
2025-03-02 15:46:08,328 - INFO - Step 2187 -- ðŸ”„ Training Metrics
2025-03-02 15:46:08,329 - INFO - â”œâ”€â”€ Loss: 6.6903
2025-03-02 15:46:08,329 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:46:08,329 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:46:09,007 - INFO - ðŸªœ Batch step - 2188 -- sub batch step 8752 -- lr 3.00e-04
2025-03-02 15:46:11,156 - INFO - ðŸªœ Batch step - 2188 -- sub batch step 8753 -- lr 3.00e-04
2025-03-02 15:46:13,313 - INFO - ðŸªœ Batch step - 2188 -- sub batch step 8754 -- lr 3.00e-04
2025-03-02 15:46:15,489 - INFO - ðŸªœ Batch step - 2188 -- sub batch step 8755 -- lr 3.00e-04
2025-03-02 15:46:17,018 - INFO - Step 2188 -- ðŸ”„ Training Metrics
2025-03-02 15:46:17,018 - INFO - â”œâ”€â”€ Loss: 6.6857
2025-03-02 15:46:17,019 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:46:17,019 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:46:17,690 - INFO - ðŸªœ Batch step - 2189 -- sub batch step 8756 -- lr 3.00e-04
2025-03-02 15:46:19,845 - INFO - ðŸªœ Batch step - 2189 -- sub batch step 8757 -- lr 3.00e-04
2025-03-02 15:46:21,993 - INFO - ðŸªœ Batch step - 2189 -- sub batch step 8758 -- lr 3.00e-04
2025-03-02 15:46:24,718 - INFO - ðŸªœ Batch step - 2189 -- sub batch step 8759 -- lr 3.00e-04
2025-03-02 15:46:26,423 - INFO - Step 2189 -- ðŸ”„ Training Metrics
2025-03-02 15:46:26,424 - INFO - â”œâ”€â”€ Loss: 6.6371
2025-03-02 15:46:26,424 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:46:26,424 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:46:27,100 - INFO - ðŸªœ Batch step - 2190 -- sub batch step 8760 -- lr 3.00e-04
2025-03-02 15:46:29,252 - INFO - ðŸªœ Batch step - 2190 -- sub batch step 8761 -- lr 3.00e-04
2025-03-02 15:46:31,406 - INFO - ðŸªœ Batch step - 2190 -- sub batch step 8762 -- lr 3.00e-04
2025-03-02 15:46:33,572 - INFO - ðŸªœ Batch step - 2190 -- sub batch step 8763 -- lr 3.00e-04
2025-03-02 15:46:35,099 - INFO - Step 2190 -- ðŸ”„ Training Metrics
2025-03-02 15:46:35,099 - INFO - â”œâ”€â”€ Loss: 6.6751
2025-03-02 15:46:35,100 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:46:35,100 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:46:35,778 - INFO - ðŸªœ Batch step - 2191 -- sub batch step 8764 -- lr 3.00e-04
2025-03-02 15:46:37,931 - INFO - ðŸªœ Batch step - 2191 -- sub batch step 8765 -- lr 3.00e-04
2025-03-02 15:46:40,581 - INFO - ðŸªœ Batch step - 2191 -- sub batch step 8766 -- lr 3.00e-04
2025-03-02 15:46:42,739 - INFO - ðŸªœ Batch step - 2191 -- sub batch step 8767 -- lr 3.00e-04
2025-03-02 15:46:44,324 - INFO - Step 2191 -- ðŸ”„ Training Metrics
2025-03-02 15:46:44,324 - INFO - â”œâ”€â”€ Loss: 6.6717
2025-03-02 15:46:44,324 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:46:44,324 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:46:44,991 - INFO - ðŸªœ Batch step - 2192 -- sub batch step 8768 -- lr 3.00e-04
2025-03-02 15:46:47,144 - INFO - ðŸªœ Batch step - 2192 -- sub batch step 8769 -- lr 3.00e-04
2025-03-02 15:46:49,317 - INFO - ðŸªœ Batch step - 2192 -- sub batch step 8770 -- lr 3.00e-04
2025-03-02 15:46:51,468 - INFO - ðŸªœ Batch step - 2192 -- sub batch step 8771 -- lr 3.00e-04
2025-03-02 15:46:53,007 - INFO - Step 2192 -- ðŸ”„ Training Metrics
2025-03-02 15:46:53,007 - INFO - â”œâ”€â”€ Loss: 6.7063
2025-03-02 15:46:53,007 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:46:53,007 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:46:53,684 - INFO - ðŸªœ Batch step - 2193 -- sub batch step 8772 -- lr 3.00e-04
2025-03-02 15:46:55,837 - INFO - ðŸªœ Batch step - 2193 -- sub batch step 8773 -- lr 3.00e-04
2025-03-02 15:46:58,525 - INFO - ðŸªœ Batch step - 2193 -- sub batch step 8774 -- lr 3.00e-04
2025-03-02 15:47:00,684 - INFO - ðŸªœ Batch step - 2193 -- sub batch step 8775 -- lr 3.00e-04
2025-03-02 15:47:02,175 - INFO - Step 2193 -- ðŸ”„ Training Metrics
2025-03-02 15:47:02,175 - INFO - â”œâ”€â”€ Loss: 6.6482
2025-03-02 15:47:02,176 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:47:02,176 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:47:02,846 - INFO - ðŸªœ Batch step - 2194 -- sub batch step 8776 -- lr 3.00e-04
2025-03-02 15:47:05,001 - INFO - ðŸªœ Batch step - 2194 -- sub batch step 8777 -- lr 3.00e-04
2025-03-02 15:47:07,171 - INFO - ðŸªœ Batch step - 2194 -- sub batch step 8778 -- lr 3.00e-04
2025-03-02 15:47:09,327 - INFO - ðŸªœ Batch step - 2194 -- sub batch step 8779 -- lr 3.00e-04
2025-03-02 15:47:10,850 - INFO - Step 2194 -- ðŸ”„ Training Metrics
2025-03-02 15:47:10,850 - INFO - â”œâ”€â”€ Loss: 6.6832
2025-03-02 15:47:10,850 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:47:10,851 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:47:11,526 - INFO - ðŸªœ Batch step - 2195 -- sub batch step 8780 -- lr 3.00e-04
2025-03-02 15:47:13,675 - INFO - ðŸªœ Batch step - 2195 -- sub batch step 8781 -- lr 3.00e-04
2025-03-02 15:47:16,281 - INFO - ðŸªœ Batch step - 2195 -- sub batch step 8782 -- lr 3.00e-04
2025-03-02 15:47:18,433 - INFO - ðŸªœ Batch step - 2195 -- sub batch step 8783 -- lr 3.00e-04
2025-03-02 15:47:20,009 - INFO - Step 2195 -- ðŸ”„ Training Metrics
2025-03-02 15:47:20,009 - INFO - â”œâ”€â”€ Loss: 6.6720
2025-03-02 15:47:20,009 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:47:20,009 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:47:20,683 - INFO - ðŸªœ Batch step - 2196 -- sub batch step 8784 -- lr 3.00e-04
2025-03-02 15:47:22,840 - INFO - ðŸªœ Batch step - 2196 -- sub batch step 8785 -- lr 3.00e-04
2025-03-02 15:47:25,008 - INFO - ðŸªœ Batch step - 2196 -- sub batch step 8786 -- lr 3.00e-04
2025-03-02 15:47:27,162 - INFO - ðŸªœ Batch step - 2196 -- sub batch step 8787 -- lr 3.00e-04
2025-03-02 15:47:28,702 - INFO - Step 2196 -- ðŸ”„ Training Metrics
2025-03-02 15:47:28,702 - INFO - â”œâ”€â”€ Loss: 6.6604
2025-03-02 15:47:28,703 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:47:28,703 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:47:29,372 - INFO - ðŸªœ Batch step - 2197 -- sub batch step 8788 -- lr 3.00e-04
2025-03-02 15:47:31,528 - INFO - ðŸªœ Batch step - 2197 -- sub batch step 8789 -- lr 3.00e-04
2025-03-02 15:47:34,004 - INFO - ðŸªœ Batch step - 2197 -- sub batch step 8790 -- lr 3.00e-04
2025-03-02 15:47:36,156 - INFO - ðŸªœ Batch step - 2197 -- sub batch step 8791 -- lr 3.00e-04
2025-03-02 15:47:37,955 - INFO - Step 2197 -- ðŸ”„ Training Metrics
2025-03-02 15:47:37,955 - INFO - â”œâ”€â”€ Loss: 6.6905
2025-03-02 15:47:37,956 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:47:37,956 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:47:38,631 - INFO - ðŸªœ Batch step - 2198 -- sub batch step 8792 -- lr 3.00e-04
2025-03-02 15:47:40,778 - INFO - ðŸªœ Batch step - 2198 -- sub batch step 8793 -- lr 3.00e-04
2025-03-02 15:47:42,952 - INFO - ðŸªœ Batch step - 2198 -- sub batch step 8794 -- lr 3.00e-04
2025-03-02 15:47:45,105 - INFO - ðŸªœ Batch step - 2198 -- sub batch step 8795 -- lr 3.00e-04
2025-03-02 15:47:46,643 - INFO - Step 2198 -- ðŸ”„ Training Metrics
2025-03-02 15:47:46,644 - INFO - â”œâ”€â”€ Loss: 6.6626
2025-03-02 15:47:46,644 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:47:46,644 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:47:47,312 - INFO - ðŸªœ Batch step - 2199 -- sub batch step 8796 -- lr 3.00e-04
2025-03-02 15:47:49,468 - INFO - ðŸªœ Batch step - 2199 -- sub batch step 8797 -- lr 3.00e-04
2025-03-02 15:47:51,751 - INFO - ðŸªœ Batch step - 2199 -- sub batch step 8798 -- lr 3.00e-04
2025-03-02 15:47:53,908 - INFO - ðŸªœ Batch step - 2199 -- sub batch step 8799 -- lr 3.00e-04
2025-03-02 15:47:55,527 - INFO - Step 2199 -- ðŸ”„ Training Metrics
2025-03-02 15:47:55,528 - INFO - â”œâ”€â”€ Loss: 6.6779
2025-03-02 15:47:55,528 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:47:55,528 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:47:56,669 - INFO - ðŸªœ Batch step - 2200 -- sub batch step 8800 -- lr 3.00e-04
2025-03-02 15:47:58,826 - INFO - ðŸªœ Batch step - 2200 -- sub batch step 8801 -- lr 3.00e-04
2025-03-02 15:48:00,987 - INFO - ðŸªœ Batch step - 2200 -- sub batch step 8802 -- lr 3.00e-04
2025-03-02 15:48:03,167 - INFO - ðŸªœ Batch step - 2200 -- sub batch step 8803 -- lr 3.00e-04
2025-03-02 15:48:04,854 - INFO - Step 2200 -- ðŸ”„ Training Metrics
2025-03-02 15:48:04,855 - INFO - â”œâ”€â”€ Loss: 6.6544
2025-03-02 15:48:04,855 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:48:04,855 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:48:05,536 - INFO - ðŸªœ Batch step - 2201 -- sub batch step 8804 -- lr 3.00e-04
2025-03-02 15:48:07,699 - INFO - ðŸªœ Batch step - 2201 -- sub batch step 8805 -- lr 3.00e-04
2025-03-02 15:48:09,852 - INFO - ðŸªœ Batch step - 2201 -- sub batch step 8806 -- lr 3.00e-04
2025-03-02 15:48:12,455 - INFO - ðŸªœ Batch step - 2201 -- sub batch step 8807 -- lr 3.00e-04
2025-03-02 15:48:14,111 - INFO - Step 2201 -- ðŸ”„ Training Metrics
2025-03-02 15:48:14,111 - INFO - â”œâ”€â”€ Loss: 6.6517
2025-03-02 15:48:14,111 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:48:14,111 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:48:14,779 - INFO - ðŸªœ Batch step - 2202 -- sub batch step 8808 -- lr 3.00e-04
2025-03-02 15:48:16,939 - INFO - ðŸªœ Batch step - 2202 -- sub batch step 8809 -- lr 3.00e-04
2025-03-02 15:48:19,097 - INFO - ðŸªœ Batch step - 2202 -- sub batch step 8810 -- lr 3.00e-04
2025-03-02 15:48:21,268 - INFO - ðŸªœ Batch step - 2202 -- sub batch step 8811 -- lr 3.00e-04
2025-03-02 15:48:22,803 - INFO - Step 2202 -- ðŸ”„ Training Metrics
2025-03-02 15:48:22,804 - INFO - â”œâ”€â”€ Loss: 6.6674
2025-03-02 15:48:22,804 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:48:22,804 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:48:23,484 - INFO - ðŸªœ Batch step - 2203 -- sub batch step 8812 -- lr 3.00e-04
2025-03-02 15:48:25,638 - INFO - ðŸªœ Batch step - 2203 -- sub batch step 8813 -- lr 3.00e-04
2025-03-02 15:48:27,789 - INFO - ðŸªœ Batch step - 2203 -- sub batch step 8814 -- lr 3.00e-04
2025-03-02 15:48:30,491 - INFO - ðŸªœ Batch step - 2203 -- sub batch step 8815 -- lr 3.00e-04
2025-03-02 15:48:32,003 - INFO - Step 2203 -- ðŸ”„ Training Metrics
2025-03-02 15:48:32,004 - INFO - â”œâ”€â”€ Loss: 6.6735
2025-03-02 15:48:32,004 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:48:32,004 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:48:32,674 - INFO - ðŸªœ Batch step - 2204 -- sub batch step 8816 -- lr 3.00e-04
2025-03-02 15:48:34,831 - INFO - ðŸªœ Batch step - 2204 -- sub batch step 8817 -- lr 3.00e-04
2025-03-02 15:48:36,980 - INFO - ðŸªœ Batch step - 2204 -- sub batch step 8818 -- lr 3.00e-04
2025-03-02 15:48:39,154 - INFO - ðŸªœ Batch step - 2204 -- sub batch step 8819 -- lr 3.00e-04
2025-03-02 15:48:40,693 - INFO - Step 2204 -- ðŸ”„ Training Metrics
2025-03-02 15:48:40,694 - INFO - â”œâ”€â”€ Loss: 6.6651
2025-03-02 15:48:40,694 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:48:40,694 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:48:41,371 - INFO - ðŸªœ Batch step - 2205 -- sub batch step 8820 -- lr 3.00e-04
2025-03-02 15:48:43,520 - INFO - ðŸªœ Batch step - 2205 -- sub batch step 8821 -- lr 3.00e-04
2025-03-02 15:48:45,673 - INFO - ðŸªœ Batch step - 2205 -- sub batch step 8822 -- lr 3.00e-04
2025-03-02 15:48:48,310 - INFO - ðŸªœ Batch step - 2205 -- sub batch step 8823 -- lr 3.00e-04
2025-03-02 15:48:49,869 - INFO - Step 2205 -- ðŸ”„ Training Metrics
2025-03-02 15:48:49,870 - INFO - â”œâ”€â”€ Loss: 6.6572
2025-03-02 15:48:49,870 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:48:49,870 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:48:50,544 - INFO - ðŸªœ Batch step - 2206 -- sub batch step 8824 -- lr 3.00e-04
2025-03-02 15:48:52,696 - INFO - ðŸªœ Batch step - 2206 -- sub batch step 8825 -- lr 3.00e-04
2025-03-02 15:48:54,844 - INFO - ðŸªœ Batch step - 2206 -- sub batch step 8826 -- lr 3.00e-04
2025-03-02 15:48:57,011 - INFO - ðŸªœ Batch step - 2206 -- sub batch step 8827 -- lr 3.00e-04
2025-03-02 15:48:58,552 - INFO - Step 2206 -- ðŸ”„ Training Metrics
2025-03-02 15:48:58,552 - INFO - â”œâ”€â”€ Loss: 6.6310
2025-03-02 15:48:58,552 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:48:58,552 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:48:59,220 - INFO - ðŸªœ Batch step - 2207 -- sub batch step 8828 -- lr 3.00e-04
2025-03-02 15:49:01,373 - INFO - ðŸªœ Batch step - 2207 -- sub batch step 8829 -- lr 3.00e-04
2025-03-02 15:49:03,527 - INFO - ðŸªœ Batch step - 2207 -- sub batch step 8830 -- lr 3.00e-04
2025-03-02 15:49:06,194 - INFO - ðŸªœ Batch step - 2207 -- sub batch step 8831 -- lr 3.00e-04
2025-03-02 15:49:07,693 - INFO - Step 2207 -- ðŸ”„ Training Metrics
2025-03-02 15:49:07,694 - INFO - â”œâ”€â”€ Loss: 6.6477
2025-03-02 15:49:07,694 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:49:07,694 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:49:08,368 - INFO - ðŸªœ Batch step - 2208 -- sub batch step 8832 -- lr 3.00e-04
2025-03-02 15:49:10,517 - INFO - ðŸªœ Batch step - 2208 -- sub batch step 8833 -- lr 3.00e-04
2025-03-02 15:49:12,672 - INFO - ðŸªœ Batch step - 2208 -- sub batch step 8834 -- lr 3.00e-04
2025-03-02 15:49:14,838 - INFO - ðŸªœ Batch step - 2208 -- sub batch step 8835 -- lr 3.00e-04
2025-03-02 15:49:16,383 - INFO - Step 2208 -- ðŸ”„ Training Metrics
2025-03-02 15:49:16,384 - INFO - â”œâ”€â”€ Loss: 6.6512
2025-03-02 15:49:16,384 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:49:16,384 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:49:17,053 - INFO - ðŸªœ Batch step - 2209 -- sub batch step 8836 -- lr 3.00e-04
2025-03-02 15:49:19,206 - INFO - ðŸªœ Batch step - 2209 -- sub batch step 8837 -- lr 3.00e-04
2025-03-02 15:49:21,353 - INFO - ðŸªœ Batch step - 2209 -- sub batch step 8838 -- lr 3.00e-04
2025-03-02 15:49:23,721 - INFO - ðŸªœ Batch step - 2209 -- sub batch step 8839 -- lr 3.00e-04
2025-03-02 15:49:25,666 - INFO - Step 2209 -- ðŸ”„ Training Metrics
2025-03-02 15:49:25,667 - INFO - â”œâ”€â”€ Loss: 6.6189
2025-03-02 15:49:25,667 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:49:25,667 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:49:26,343 - INFO - ðŸªœ Batch step - 2210 -- sub batch step 8840 -- lr 3.00e-04
2025-03-02 15:49:28,491 - INFO - ðŸªœ Batch step - 2210 -- sub batch step 8841 -- lr 3.00e-04
2025-03-02 15:49:30,644 - INFO - ðŸªœ Batch step - 2210 -- sub batch step 8842 -- lr 3.00e-04
2025-03-02 15:49:32,805 - INFO - ðŸªœ Batch step - 2210 -- sub batch step 8843 -- lr 3.00e-04
2025-03-02 15:49:34,341 - INFO - Step 2210 -- ðŸ”„ Training Metrics
2025-03-02 15:49:34,341 - INFO - â”œâ”€â”€ Loss: 6.6170
2025-03-02 15:49:34,341 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:49:34,341 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:49:35,014 - INFO - ðŸªœ Batch step - 2211 -- sub batch step 8844 -- lr 3.00e-04
2025-03-02 15:49:37,167 - INFO - ðŸªœ Batch step - 2211 -- sub batch step 8845 -- lr 3.00e-04
2025-03-02 15:49:39,850 - INFO - ðŸªœ Batch step - 2211 -- sub batch step 8846 -- lr 3.00e-04
2025-03-02 15:49:42,008 - INFO - ðŸªœ Batch step - 2211 -- sub batch step 8847 -- lr 3.00e-04
2025-03-02 15:49:43,566 - INFO - Step 2211 -- ðŸ”„ Training Metrics
2025-03-02 15:49:43,566 - INFO - â”œâ”€â”€ Loss: 6.6417
2025-03-02 15:49:43,567 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:49:43,567 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:49:44,234 - INFO - ðŸªœ Batch step - 2212 -- sub batch step 8848 -- lr 3.00e-04
2025-03-02 15:49:46,393 - INFO - ðŸªœ Batch step - 2212 -- sub batch step 8849 -- lr 3.00e-04
2025-03-02 15:49:48,562 - INFO - ðŸªœ Batch step - 2212 -- sub batch step 8850 -- lr 3.00e-04
2025-03-02 15:49:50,710 - INFO - ðŸªœ Batch step - 2212 -- sub batch step 8851 -- lr 3.00e-04
2025-03-02 15:49:52,257 - INFO - Step 2212 -- ðŸ”„ Training Metrics
2025-03-02 15:49:52,257 - INFO - â”œâ”€â”€ Loss: 6.6298
2025-03-02 15:49:52,258 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:49:52,258 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:49:52,931 - INFO - ðŸªœ Batch step - 2213 -- sub batch step 8852 -- lr 3.00e-04
2025-03-02 15:49:55,079 - INFO - ðŸªœ Batch step - 2213 -- sub batch step 8853 -- lr 3.00e-04
2025-03-02 15:49:57,842 - INFO - ðŸªœ Batch step - 2213 -- sub batch step 8854 -- lr 3.00e-04
2025-03-02 15:50:00,001 - INFO - ðŸªœ Batch step - 2213 -- sub batch step 8855 -- lr 3.00e-04
2025-03-02 15:50:01,506 - INFO - Step 2213 -- ðŸ”„ Training Metrics
2025-03-02 15:50:01,507 - INFO - â”œâ”€â”€ Loss: 6.6304
2025-03-02 15:50:01,507 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:50:01,507 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:50:02,180 - INFO - ðŸªœ Batch step - 2214 -- sub batch step 8856 -- lr 3.00e-04
2025-03-02 15:50:04,334 - INFO - ðŸªœ Batch step - 2214 -- sub batch step 8857 -- lr 3.00e-04
2025-03-02 15:50:06,501 - INFO - ðŸªœ Batch step - 2214 -- sub batch step 8858 -- lr 3.00e-04
2025-03-02 15:50:08,657 - INFO - ðŸªœ Batch step - 2214 -- sub batch step 8859 -- lr 3.00e-04
2025-03-02 15:50:10,192 - INFO - Step 2214 -- ðŸ”„ Training Metrics
2025-03-02 15:50:10,192 - INFO - â”œâ”€â”€ Loss: 6.6223
2025-03-02 15:50:10,192 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:50:10,192 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:50:10,870 - INFO - ðŸªœ Batch step - 2215 -- sub batch step 8860 -- lr 3.00e-04
2025-03-02 15:50:13,021 - INFO - ðŸªœ Batch step - 2215 -- sub batch step 8861 -- lr 3.00e-04
2025-03-02 15:50:15,656 - INFO - ðŸªœ Batch step - 2215 -- sub batch step 8862 -- lr 3.00e-04
2025-03-02 15:50:17,806 - INFO - ðŸªœ Batch step - 2215 -- sub batch step 8863 -- lr 3.00e-04
2025-03-02 15:50:19,432 - INFO - Step 2215 -- ðŸ”„ Training Metrics
2025-03-02 15:50:19,432 - INFO - â”œâ”€â”€ Loss: 6.6521
2025-03-02 15:50:19,432 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:50:19,433 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:50:20,106 - INFO - ðŸªœ Batch step - 2216 -- sub batch step 8864 -- lr 3.00e-04
2025-03-02 15:50:22,259 - INFO - ðŸªœ Batch step - 2216 -- sub batch step 8865 -- lr 3.00e-04
2025-03-02 15:50:24,424 - INFO - ðŸªœ Batch step - 2216 -- sub batch step 8866 -- lr 3.00e-04
2025-03-02 15:50:26,577 - INFO - ðŸªœ Batch step - 2216 -- sub batch step 8867 -- lr 3.00e-04
2025-03-02 15:50:28,129 - INFO - Step 2216 -- ðŸ”„ Training Metrics
2025-03-02 15:50:28,129 - INFO - â”œâ”€â”€ Loss: 6.6444
2025-03-02 15:50:28,129 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:50:28,129 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:50:28,798 - INFO - ðŸªœ Batch step - 2217 -- sub batch step 8868 -- lr 3.00e-04
2025-03-02 15:50:30,957 - INFO - ðŸªœ Batch step - 2217 -- sub batch step 8869 -- lr 3.00e-04
2025-03-02 15:50:34,018 - INFO - ðŸªœ Batch step - 2217 -- sub batch step 8870 -- lr 3.00e-04
2025-03-02 15:50:36,176 - INFO - ðŸªœ Batch step - 2217 -- sub batch step 8871 -- lr 3.00e-04
2025-03-02 15:50:37,669 - INFO - Step 2217 -- ðŸ”„ Training Metrics
2025-03-02 15:50:37,669 - INFO - â”œâ”€â”€ Loss: 6.6211
2025-03-02 15:50:37,669 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:50:37,669 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:50:38,346 - INFO - ðŸªœ Batch step - 2218 -- sub batch step 8872 -- lr 3.00e-04
2025-03-02 15:50:40,496 - INFO - ðŸªœ Batch step - 2218 -- sub batch step 8873 -- lr 3.00e-04
2025-03-02 15:50:42,664 - INFO - ðŸªœ Batch step - 2218 -- sub batch step 8874 -- lr 3.00e-04
2025-03-02 15:50:44,815 - INFO - ðŸªœ Batch step - 2218 -- sub batch step 8875 -- lr 3.00e-04
2025-03-02 15:50:46,360 - INFO - Step 2218 -- ðŸ”„ Training Metrics
2025-03-02 15:50:46,361 - INFO - â”œâ”€â”€ Loss: 6.6164
2025-03-02 15:50:46,361 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:50:46,361 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:50:47,028 - INFO - ðŸªœ Batch step - 2219 -- sub batch step 8876 -- lr 3.00e-04
2025-03-02 15:50:49,181 - INFO - ðŸªœ Batch step - 2219 -- sub batch step 8877 -- lr 3.00e-04
2025-03-02 15:50:51,456 - INFO - ðŸªœ Batch step - 2219 -- sub batch step 8878 -- lr 3.00e-04
2025-03-02 15:50:53,612 - INFO - ðŸªœ Batch step - 2219 -- sub batch step 8879 -- lr 3.00e-04
2025-03-02 15:50:55,323 - INFO - Step 2219 -- ðŸ”„ Training Metrics
2025-03-02 15:50:55,323 - INFO - â”œâ”€â”€ Loss: 6.6482
2025-03-02 15:50:55,323 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:50:55,323 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:50:56,578 - INFO - ðŸªœ Batch step - 2220 -- sub batch step 8880 -- lr 3.00e-04
2025-03-02 15:50:58,728 - INFO - ðŸªœ Batch step - 2220 -- sub batch step 8881 -- lr 3.00e-04
2025-03-02 15:51:00,886 - INFO - ðŸªœ Batch step - 2220 -- sub batch step 8882 -- lr 3.00e-04
2025-03-02 15:51:03,054 - INFO - ðŸªœ Batch step - 2220 -- sub batch step 8883 -- lr 3.00e-04
2025-03-02 15:51:04,612 - INFO - Step 2220 -- ðŸ”„ Training Metrics
2025-03-02 15:51:04,612 - INFO - â”œâ”€â”€ Loss: 6.6376
2025-03-02 15:51:04,612 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:51:04,612 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:51:05,285 - INFO - ðŸªœ Batch step - 2221 -- sub batch step 8884 -- lr 3.00e-04
2025-03-02 15:51:07,438 - INFO - ðŸªœ Batch step - 2221 -- sub batch step 8885 -- lr 3.00e-04
2025-03-02 15:51:09,585 - INFO - ðŸªœ Batch step - 2221 -- sub batch step 8886 -- lr 3.00e-04
2025-03-02 15:51:11,976 - INFO - ðŸªœ Batch step - 2221 -- sub batch step 8887 -- lr 3.00e-04
2025-03-02 15:51:13,914 - INFO - Step 2221 -- ðŸ”„ Training Metrics
2025-03-02 15:51:13,915 - INFO - â”œâ”€â”€ Loss: 6.6555
2025-03-02 15:51:13,915 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:51:13,915 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:51:14,582 - INFO - ðŸªœ Batch step - 2222 -- sub batch step 8888 -- lr 3.00e-04
2025-03-02 15:51:16,742 - INFO - ðŸªœ Batch step - 2222 -- sub batch step 8889 -- lr 3.00e-04
2025-03-02 15:51:18,892 - INFO - ðŸªœ Batch step - 2222 -- sub batch step 8890 -- lr 3.00e-04
2025-03-02 15:51:21,058 - INFO - ðŸªœ Batch step - 2222 -- sub batch step 8891 -- lr 3.00e-04
2025-03-02 15:51:22,595 - INFO - Step 2222 -- ðŸ”„ Training Metrics
2025-03-02 15:51:22,595 - INFO - â”œâ”€â”€ Loss: 6.6391
2025-03-02 15:51:22,595 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:51:22,595 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:51:23,270 - INFO - ðŸªœ Batch step - 2223 -- sub batch step 8892 -- lr 3.00e-04
2025-03-02 15:51:25,420 - INFO - ðŸªœ Batch step - 2223 -- sub batch step 8893 -- lr 3.00e-04
2025-03-02 15:51:27,575 - INFO - ðŸªœ Batch step - 2223 -- sub batch step 8894 -- lr 3.00e-04
2025-03-02 15:51:30,213 - INFO - ðŸªœ Batch step - 2223 -- sub batch step 8895 -- lr 3.00e-04
2025-03-02 15:51:31,833 - INFO - Step 2223 -- ðŸ”„ Training Metrics
2025-03-02 15:51:31,833 - INFO - â”œâ”€â”€ Loss: 6.6379
2025-03-02 15:51:31,833 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:51:31,833 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:51:32,500 - INFO - ðŸªœ Batch step - 2224 -- sub batch step 8896 -- lr 3.00e-04
2025-03-02 15:51:34,654 - INFO - ðŸªœ Batch step - 2224 -- sub batch step 8897 -- lr 3.00e-04
2025-03-02 15:51:36,801 - INFO - ðŸªœ Batch step - 2224 -- sub batch step 8898 -- lr 3.00e-04
2025-03-02 15:51:38,968 - INFO - ðŸªœ Batch step - 2224 -- sub batch step 8899 -- lr 3.00e-04
2025-03-02 15:51:40,506 - INFO - Step 2224 -- ðŸ”„ Training Metrics
2025-03-02 15:51:40,506 - INFO - â”œâ”€â”€ Loss: 6.6398
2025-03-02 15:51:40,506 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:51:40,507 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:51:41,180 - INFO - ðŸªœ Batch step - 2225 -- sub batch step 8900 -- lr 3.00e-04
2025-03-02 15:51:43,328 - INFO - ðŸªœ Batch step - 2225 -- sub batch step 8901 -- lr 3.00e-04
2025-03-02 15:51:45,480 - INFO - ðŸªœ Batch step - 2225 -- sub batch step 8902 -- lr 3.00e-04
2025-03-02 15:51:47,902 - INFO - ðŸªœ Batch step - 2225 -- sub batch step 8903 -- lr 3.00e-04
2025-03-02 15:51:55,087 - INFO - Step 2225 -- ðŸ”„ Training Metrics
2025-03-02 15:51:55,087 - INFO - â”œâ”€â”€ Loss: 6.6374
2025-03-02 15:51:55,087 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:51:55,087 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:51:55,761 - INFO - ðŸªœ Batch step - 2226 -- sub batch step 8904 -- lr 3.00e-04
2025-03-02 15:51:57,919 - INFO - ðŸªœ Batch step - 2226 -- sub batch step 8905 -- lr 3.00e-04
2025-03-02 15:52:00,064 - INFO - ðŸªœ Batch step - 2226 -- sub batch step 8906 -- lr 3.00e-04
2025-03-02 15:52:02,237 - INFO - ðŸªœ Batch step - 2226 -- sub batch step 8907 -- lr 3.00e-04
2025-03-02 15:52:03,783 - INFO - Step 2226 -- ðŸ”„ Training Metrics
2025-03-02 15:52:03,783 - INFO - â”œâ”€â”€ Loss: 6.6259
2025-03-02 15:52:03,783 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:52:03,783 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:52:04,451 - INFO - ðŸªœ Batch step - 2227 -- sub batch step 8908 -- lr 3.00e-04
2025-03-02 15:52:06,606 - INFO - ðŸªœ Batch step - 2227 -- sub batch step 8909 -- lr 3.00e-04
2025-03-02 15:52:08,762 - INFO - ðŸªœ Batch step - 2227 -- sub batch step 8910 -- lr 3.00e-04
2025-03-02 15:52:11,179 - INFO - ðŸªœ Batch step - 2227 -- sub batch step 8911 -- lr 3.00e-04
2025-03-02 15:52:13,050 - INFO - Step 2227 -- ðŸ”„ Training Metrics
2025-03-02 15:52:13,050 - INFO - â”œâ”€â”€ Loss: 6.5931
2025-03-02 15:52:13,050 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:52:13,050 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:52:13,728 - INFO - ðŸªœ Batch step - 2228 -- sub batch step 8912 -- lr 3.00e-04
2025-03-02 15:52:15,877 - INFO - ðŸªœ Batch step - 2228 -- sub batch step 8913 -- lr 3.00e-04
2025-03-02 15:52:18,029 - INFO - ðŸªœ Batch step - 2228 -- sub batch step 8914 -- lr 3.00e-04
2025-03-02 15:52:20,199 - INFO - ðŸªœ Batch step - 2228 -- sub batch step 8915 -- lr 3.00e-04
2025-03-02 15:52:21,743 - INFO - Step 2228 -- ðŸ”„ Training Metrics
2025-03-02 15:52:21,743 - INFO - â”œâ”€â”€ Loss: 6.6243
2025-03-02 15:52:21,743 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:52:21,743 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:52:22,411 - INFO - ðŸªœ Batch step - 2229 -- sub batch step 8916 -- lr 3.00e-04
2025-03-02 15:52:24,564 - INFO - ðŸªœ Batch step - 2229 -- sub batch step 8917 -- lr 3.00e-04
2025-03-02 15:52:26,711 - INFO - ðŸªœ Batch step - 2229 -- sub batch step 8918 -- lr 3.00e-04
2025-03-02 15:52:29,102 - INFO - ðŸªœ Batch step - 2229 -- sub batch step 8919 -- lr 3.00e-04
2025-03-02 15:52:31,339 - INFO - Step 2229 -- ðŸ”„ Training Metrics
2025-03-02 15:52:31,340 - INFO - â”œâ”€â”€ Loss: 6.6329
2025-03-02 15:52:31,340 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:52:31,340 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:52:32,012 - INFO - ðŸªœ Batch step - 2230 -- sub batch step 8920 -- lr 3.00e-04
2025-03-02 15:52:34,161 - INFO - ðŸªœ Batch step - 2230 -- sub batch step 8921 -- lr 3.00e-04
2025-03-02 15:52:36,314 - INFO - ðŸªœ Batch step - 2230 -- sub batch step 8922 -- lr 3.00e-04
2025-03-02 15:52:38,479 - INFO - ðŸªœ Batch step - 2230 -- sub batch step 8923 -- lr 3.00e-04
2025-03-02 15:52:40,008 - INFO - Step 2230 -- ðŸ”„ Training Metrics
2025-03-02 15:52:40,008 - INFO - â”œâ”€â”€ Loss: 6.6269
2025-03-02 15:52:40,008 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:52:40,008 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:52:40,682 - INFO - ðŸªœ Batch step - 2231 -- sub batch step 8924 -- lr 3.00e-04
2025-03-02 15:52:42,835 - INFO - ðŸªœ Batch step - 2231 -- sub batch step 8925 -- lr 3.00e-04
2025-03-02 15:52:45,412 - INFO - ðŸªœ Batch step - 2231 -- sub batch step 8926 -- lr 3.00e-04
2025-03-02 15:52:47,563 - INFO - ðŸªœ Batch step - 2231 -- sub batch step 8927 -- lr 3.00e-04
2025-03-02 15:52:49,156 - INFO - Step 2231 -- ðŸ”„ Training Metrics
2025-03-02 15:52:49,156 - INFO - â”œâ”€â”€ Loss: 6.6216
2025-03-02 15:52:49,156 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:52:49,157 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:52:49,825 - INFO - ðŸªœ Batch step - 2232 -- sub batch step 8928 -- lr 3.00e-04
2025-03-02 15:52:51,979 - INFO - ðŸªœ Batch step - 2232 -- sub batch step 8929 -- lr 3.00e-04
2025-03-02 15:52:54,151 - INFO - ðŸªœ Batch step - 2232 -- sub batch step 8930 -- lr 3.00e-04
2025-03-02 15:52:56,297 - INFO - ðŸªœ Batch step - 2232 -- sub batch step 8931 -- lr 3.00e-04
2025-03-02 15:52:57,837 - INFO - Step 2232 -- ðŸ”„ Training Metrics
2025-03-02 15:52:57,837 - INFO - â”œâ”€â”€ Loss: 6.6236
2025-03-02 15:52:57,837 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:52:57,837 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:52:58,512 - INFO - ðŸªœ Batch step - 2233 -- sub batch step 8932 -- lr 3.00e-04
2025-03-02 15:53:00,664 - INFO - ðŸªœ Batch step - 2233 -- sub batch step 8933 -- lr 3.00e-04
2025-03-02 15:53:03,352 - INFO - ðŸªœ Batch step - 2233 -- sub batch step 8934 -- lr 3.00e-04
2025-03-02 15:53:05,503 - INFO - ðŸªœ Batch step - 2233 -- sub batch step 8935 -- lr 3.00e-04
2025-03-02 15:53:06,989 - INFO - Step 2233 -- ðŸ”„ Training Metrics
2025-03-02 15:53:06,989 - INFO - â”œâ”€â”€ Loss: 6.6129
2025-03-02 15:53:06,989 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:53:06,989 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:53:07,657 - INFO - ðŸªœ Batch step - 2234 -- sub batch step 8936 -- lr 3.00e-04
2025-03-02 15:53:09,811 - INFO - ðŸªœ Batch step - 2234 -- sub batch step 8937 -- lr 3.00e-04
2025-03-02 15:53:11,976 - INFO - ðŸªœ Batch step - 2234 -- sub batch step 8938 -- lr 3.00e-04
2025-03-02 15:53:14,132 - INFO - ðŸªœ Batch step - 2234 -- sub batch step 8939 -- lr 3.00e-04
2025-03-02 15:53:15,671 - INFO - Step 2234 -- ðŸ”„ Training Metrics
2025-03-02 15:53:15,672 - INFO - â”œâ”€â”€ Loss: 6.6351
2025-03-02 15:53:15,672 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:53:15,672 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:53:16,344 - INFO - ðŸªœ Batch step - 2235 -- sub batch step 8940 -- lr 3.00e-04
2025-03-02 15:53:18,492 - INFO - ðŸªœ Batch step - 2235 -- sub batch step 8941 -- lr 3.00e-04
2025-03-02 15:53:21,079 - INFO - ðŸªœ Batch step - 2235 -- sub batch step 8942 -- lr 3.00e-04
2025-03-02 15:53:23,229 - INFO - ðŸªœ Batch step - 2235 -- sub batch step 8943 -- lr 3.00e-04
2025-03-02 15:53:24,906 - INFO - Step 2235 -- ðŸ”„ Training Metrics
2025-03-02 15:53:24,907 - INFO - â”œâ”€â”€ Loss: 6.6227
2025-03-02 15:53:24,907 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:53:24,907 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:53:25,581 - INFO - ðŸªœ Batch step - 2236 -- sub batch step 8944 -- lr 3.00e-04
2025-03-02 15:53:27,734 - INFO - ðŸªœ Batch step - 2236 -- sub batch step 8945 -- lr 3.00e-04
2025-03-02 15:53:29,898 - INFO - ðŸªœ Batch step - 2236 -- sub batch step 8946 -- lr 3.00e-04
2025-03-02 15:53:32,048 - INFO - ðŸªœ Batch step - 2236 -- sub batch step 8947 -- lr 3.00e-04
2025-03-02 15:53:33,587 - INFO - Step 2236 -- ðŸ”„ Training Metrics
2025-03-02 15:53:33,587 - INFO - â”œâ”€â”€ Loss: 6.6223
2025-03-02 15:53:33,587 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:53:33,588 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:53:34,254 - INFO - ðŸªœ Batch step - 2237 -- sub batch step 8948 -- lr 3.00e-04
2025-03-02 15:53:36,409 - INFO - ðŸªœ Batch step - 2237 -- sub batch step 8949 -- lr 3.00e-04
2025-03-02 15:53:39,046 - INFO - ðŸªœ Batch step - 2237 -- sub batch step 8950 -- lr 3.00e-04
2025-03-02 15:53:41,192 - INFO - ðŸªœ Batch step - 2237 -- sub batch step 8951 -- lr 3.00e-04
2025-03-02 15:53:43,085 - INFO - Step 2237 -- ðŸ”„ Training Metrics
2025-03-02 15:53:43,086 - INFO - â”œâ”€â”€ Loss: 6.6114
2025-03-02 15:53:43,086 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:53:43,086 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:53:43,758 - INFO - ðŸªœ Batch step - 2238 -- sub batch step 8952 -- lr 3.00e-04
2025-03-02 15:53:45,904 - INFO - ðŸªœ Batch step - 2238 -- sub batch step 8953 -- lr 3.00e-04
2025-03-02 15:53:48,079 - INFO - ðŸªœ Batch step - 2238 -- sub batch step 8954 -- lr 3.00e-04
2025-03-02 15:53:50,231 - INFO - ðŸªœ Batch step - 2238 -- sub batch step 8955 -- lr 3.00e-04
2025-03-02 15:53:51,785 - INFO - Step 2238 -- ðŸ”„ Training Metrics
2025-03-02 15:53:51,785 - INFO - â”œâ”€â”€ Loss: 6.6376
2025-03-02 15:53:51,785 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:53:51,785 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:53:52,450 - INFO - ðŸªœ Batch step - 2239 -- sub batch step 8956 -- lr 3.00e-04
2025-03-02 15:53:54,602 - INFO - ðŸªœ Batch step - 2239 -- sub batch step 8957 -- lr 3.00e-04
2025-03-02 15:53:56,881 - INFO - ðŸªœ Batch step - 2239 -- sub batch step 8958 -- lr 3.00e-04
2025-03-02 15:53:59,032 - INFO - ðŸªœ Batch step - 2239 -- sub batch step 8959 -- lr 3.00e-04
2025-03-02 15:54:00,594 - INFO - Step 2239 -- ðŸ”„ Training Metrics
2025-03-02 15:54:00,594 - INFO - â”œâ”€â”€ Loss: 6.6208
2025-03-02 15:54:00,594 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:54:00,594 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:54:01,866 - INFO - ðŸªœ Batch step - 2240 -- sub batch step 8960 -- lr 3.00e-04
2025-03-02 15:54:04,028 - INFO - ðŸªœ Batch step - 2240 -- sub batch step 8961 -- lr 3.00e-04
2025-03-02 15:54:06,193 - INFO - ðŸªœ Batch step - 2240 -- sub batch step 8962 -- lr 3.00e-04
2025-03-02 15:54:08,369 - INFO - ðŸªœ Batch step - 2240 -- sub batch step 8963 -- lr 3.00e-04
2025-03-02 15:54:09,913 - INFO - Step 2240 -- ðŸ”„ Training Metrics
2025-03-02 15:54:09,914 - INFO - â”œâ”€â”€ Loss: 6.6057
2025-03-02 15:54:09,914 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:54:09,914 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:54:10,595 - INFO - ðŸªœ Batch step - 2241 -- sub batch step 8964 -- lr 3.00e-04
2025-03-02 15:54:12,757 - INFO - ðŸªœ Batch step - 2241 -- sub batch step 8965 -- lr 3.00e-04
2025-03-02 15:54:14,914 - INFO - ðŸªœ Batch step - 2241 -- sub batch step 8966 -- lr 3.00e-04
2025-03-02 15:54:17,748 - INFO - ðŸªœ Batch step - 2241 -- sub batch step 8967 -- lr 3.00e-04
2025-03-02 15:54:19,239 - INFO - Step 2241 -- ðŸ”„ Training Metrics
2025-03-02 15:54:19,239 - INFO - â”œâ”€â”€ Loss: 6.5890
2025-03-02 15:54:19,240 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:54:19,240 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:54:19,912 - INFO - ðŸªœ Batch step - 2242 -- sub batch step 8968 -- lr 3.00e-04
2025-03-02 15:54:22,076 - INFO - ðŸªœ Batch step - 2242 -- sub batch step 8969 -- lr 3.00e-04
2025-03-02 15:54:24,234 - INFO - ðŸªœ Batch step - 2242 -- sub batch step 8970 -- lr 3.00e-04
2025-03-02 15:54:26,404 - INFO - ðŸªœ Batch step - 2242 -- sub batch step 8971 -- lr 3.00e-04
2025-03-02 15:54:27,930 - INFO - Step 2242 -- ðŸ”„ Training Metrics
2025-03-02 15:54:27,931 - INFO - â”œâ”€â”€ Loss: 6.5916
2025-03-02 15:54:27,931 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:54:27,931 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:54:28,606 - INFO - ðŸªœ Batch step - 2243 -- sub batch step 8972 -- lr 3.00e-04
2025-03-02 15:54:30,764 - INFO - ðŸªœ Batch step - 2243 -- sub batch step 8973 -- lr 3.00e-04
2025-03-02 15:54:32,923 - INFO - ðŸªœ Batch step - 2243 -- sub batch step 8974 -- lr 3.00e-04
2025-03-02 15:54:35,365 - INFO - ðŸªœ Batch step - 2243 -- sub batch step 8975 -- lr 3.00e-04
2025-03-02 15:54:37,459 - INFO - Step 2243 -- ðŸ”„ Training Metrics
2025-03-02 15:54:37,459 - INFO - â”œâ”€â”€ Loss: 6.6045
2025-03-02 15:54:37,459 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:54:37,459 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:54:38,132 - INFO - ðŸªœ Batch step - 2244 -- sub batch step 8976 -- lr 3.00e-04
2025-03-02 15:54:40,293 - INFO - ðŸªœ Batch step - 2244 -- sub batch step 8977 -- lr 3.00e-04
2025-03-02 15:54:42,444 - INFO - ðŸªœ Batch step - 2244 -- sub batch step 8978 -- lr 3.00e-04
2025-03-02 15:54:44,616 - INFO - ðŸªœ Batch step - 2244 -- sub batch step 8979 -- lr 3.00e-04
2025-03-02 15:54:46,154 - INFO - Step 2244 -- ðŸ”„ Training Metrics
2025-03-02 15:54:46,154 - INFO - â”œâ”€â”€ Loss: 6.6227
2025-03-02 15:54:46,154 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:54:46,154 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:54:46,830 - INFO - ðŸªœ Batch step - 2245 -- sub batch step 8980 -- lr 3.00e-04
2025-03-02 15:54:48,985 - INFO - ðŸªœ Batch step - 2245 -- sub batch step 8981 -- lr 3.00e-04
2025-03-02 15:54:51,144 - INFO - ðŸªœ Batch step - 2245 -- sub batch step 8982 -- lr 3.00e-04
2025-03-02 15:54:53,502 - INFO - ðŸªœ Batch step - 2245 -- sub batch step 8983 -- lr 3.00e-04
2025-03-02 15:54:55,512 - INFO - Step 2245 -- ðŸ”„ Training Metrics
2025-03-02 15:54:55,512 - INFO - â”œâ”€â”€ Loss: 6.6187
2025-03-02 15:54:55,512 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:54:55,512 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:54:56,191 - INFO - ðŸªœ Batch step - 2246 -- sub batch step 8984 -- lr 3.00e-04
2025-03-02 15:54:58,348 - INFO - ðŸªœ Batch step - 2246 -- sub batch step 8985 -- lr 3.00e-04
2025-03-02 15:55:00,500 - INFO - ðŸªœ Batch step - 2246 -- sub batch step 8986 -- lr 3.00e-04
2025-03-02 15:55:02,672 - INFO - ðŸªœ Batch step - 2246 -- sub batch step 8987 -- lr 3.00e-04
2025-03-02 15:55:04,209 - INFO - Step 2246 -- ðŸ”„ Training Metrics
2025-03-02 15:55:04,209 - INFO - â”œâ”€â”€ Loss: 6.6102
2025-03-02 15:55:04,209 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:55:04,209 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:55:04,879 - INFO - ðŸªœ Batch step - 2247 -- sub batch step 8988 -- lr 3.00e-04
2025-03-02 15:55:07,036 - INFO - ðŸªœ Batch step - 2247 -- sub batch step 8989 -- lr 3.00e-04
2025-03-02 15:55:09,199 - INFO - ðŸªœ Batch step - 2247 -- sub batch step 8990 -- lr 3.00e-04
2025-03-02 15:55:11,598 - INFO - ðŸªœ Batch step - 2247 -- sub batch step 8991 -- lr 3.00e-04
2025-03-02 15:55:13,650 - INFO - Step 2247 -- ðŸ”„ Training Metrics
2025-03-02 15:55:13,651 - INFO - â”œâ”€â”€ Loss: 6.6125
2025-03-02 15:55:13,651 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:55:13,651 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:55:14,325 - INFO - ðŸªœ Batch step - 2248 -- sub batch step 8992 -- lr 3.00e-04
2025-03-02 15:55:16,477 - INFO - ðŸªœ Batch step - 2248 -- sub batch step 8993 -- lr 3.00e-04
2025-03-02 15:55:18,638 - INFO - ðŸªœ Batch step - 2248 -- sub batch step 8994 -- lr 3.00e-04
2025-03-02 15:55:20,811 - INFO - ðŸªœ Batch step - 2248 -- sub batch step 8995 -- lr 3.00e-04
2025-03-02 15:55:22,352 - INFO - Step 2248 -- ðŸ”„ Training Metrics
2025-03-02 15:55:22,352 - INFO - â”œâ”€â”€ Loss: 6.6219
2025-03-02 15:55:22,353 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:55:22,353 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:55:23,028 - INFO - ðŸªœ Batch step - 2249 -- sub batch step 8996 -- lr 3.00e-04
2025-03-02 15:55:25,184 - INFO - ðŸªœ Batch step - 2249 -- sub batch step 8997 -- lr 3.00e-04
2025-03-02 15:55:27,334 - INFO - ðŸªœ Batch step - 2249 -- sub batch step 8998 -- lr 3.00e-04
2025-03-02 15:55:30,042 - INFO - ðŸªœ Batch step - 2249 -- sub batch step 8999 -- lr 3.00e-04
2025-03-02 15:55:31,652 - INFO - Step 2249 -- ðŸ”„ Training Metrics
2025-03-02 15:55:31,652 - INFO - â”œâ”€â”€ Loss: 6.5986
2025-03-02 15:55:31,652 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:55:31,652 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:55:32,330 - INFO - ðŸªœ Batch step - 2250 -- sub batch step 9000 -- lr 3.00e-04
2025-03-02 15:55:34,483 - INFO - ðŸªœ Batch step - 2250 -- sub batch step 9001 -- lr 3.00e-04
2025-03-02 15:55:36,640 - INFO - ðŸªœ Batch step - 2250 -- sub batch step 9002 -- lr 3.00e-04
2025-03-02 15:55:38,810 - INFO - ðŸªœ Batch step - 2250 -- sub batch step 9003 -- lr 3.00e-04
2025-03-02 15:55:40,343 - INFO - Step 2250 -- ðŸ”„ Training Metrics
2025-03-02 15:55:40,343 - INFO - â”œâ”€â”€ Loss: 6.5832
2025-03-02 15:55:40,343 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:55:40,343 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:55:41,019 - INFO - ðŸªœ Batch step - 2251 -- sub batch step 9004 -- lr 3.00e-04
2025-03-02 15:55:43,174 - INFO - ðŸªœ Batch step - 2251 -- sub batch step 9005 -- lr 3.00e-04
2025-03-02 15:55:45,894 - INFO - ðŸªœ Batch step - 2251 -- sub batch step 9006 -- lr 3.00e-04
2025-03-02 15:55:48,053 - INFO - ðŸªœ Batch step - 2251 -- sub batch step 9007 -- lr 3.00e-04
2025-03-02 15:55:49,623 - INFO - Step 2251 -- ðŸ”„ Training Metrics
2025-03-02 15:55:49,623 - INFO - â”œâ”€â”€ Loss: 6.6234
2025-03-02 15:55:49,623 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:55:49,623 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:55:50,291 - INFO - ðŸªœ Batch step - 2252 -- sub batch step 9008 -- lr 3.00e-04
2025-03-02 15:55:52,446 - INFO - ðŸªœ Batch step - 2252 -- sub batch step 9009 -- lr 3.00e-04
2025-03-02 15:55:54,625 - INFO - ðŸªœ Batch step - 2252 -- sub batch step 9010 -- lr 3.00e-04
2025-03-02 15:55:56,777 - INFO - ðŸªœ Batch step - 2252 -- sub batch step 9011 -- lr 3.00e-04
2025-03-02 15:55:58,318 - INFO - Step 2252 -- ðŸ”„ Training Metrics
2025-03-02 15:55:58,318 - INFO - â”œâ”€â”€ Loss: 6.5851
2025-03-02 15:55:58,318 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:55:58,318 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:55:58,993 - INFO - ðŸªœ Batch step - 2253 -- sub batch step 9012 -- lr 3.00e-04
2025-03-02 15:56:01,144 - INFO - ðŸªœ Batch step - 2253 -- sub batch step 9013 -- lr 3.00e-04
2025-03-02 15:56:03,828 - INFO - ðŸªœ Batch step - 2253 -- sub batch step 9014 -- lr 3.00e-04
2025-03-02 15:56:05,987 - INFO - ðŸªœ Batch step - 2253 -- sub batch step 9015 -- lr 3.00e-04
2025-03-02 15:56:09,639 - INFO - Step 2253 -- ðŸ”„ Training Metrics
2025-03-02 15:56:09,639 - INFO - â”œâ”€â”€ Loss: 6.5857
2025-03-02 15:56:09,639 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:56:09,639 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:56:10,307 - INFO - ðŸªœ Batch step - 2254 -- sub batch step 9016 -- lr 3.00e-04
2025-03-02 15:56:12,460 - INFO - ðŸªœ Batch step - 2254 -- sub batch step 9017 -- lr 3.00e-04
2025-03-02 15:56:14,624 - INFO - ðŸªœ Batch step - 2254 -- sub batch step 9018 -- lr 3.00e-04
2025-03-02 15:56:16,777 - INFO - ðŸªœ Batch step - 2254 -- sub batch step 9019 -- lr 3.00e-04
2025-03-02 15:56:18,322 - INFO - Step 2254 -- ðŸ”„ Training Metrics
2025-03-02 15:56:18,323 - INFO - â”œâ”€â”€ Loss: 6.5969
2025-03-02 15:56:18,323 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:56:18,323 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:56:19,013 - INFO - ðŸªœ Batch step - 2255 -- sub batch step 9020 -- lr 3.00e-04
2025-03-02 15:56:21,167 - INFO - ðŸªœ Batch step - 2255 -- sub batch step 9021 -- lr 3.00e-04
2025-03-02 15:56:23,828 - INFO - ðŸªœ Batch step - 2255 -- sub batch step 9022 -- lr 3.00e-04
2025-03-02 15:56:25,979 - INFO - ðŸªœ Batch step - 2255 -- sub batch step 9023 -- lr 3.00e-04
2025-03-02 15:56:28,596 - INFO - Step 2255 -- ðŸ”„ Training Metrics
2025-03-02 15:56:28,597 - INFO - â”œâ”€â”€ Loss: 6.6067
2025-03-02 15:56:28,597 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:56:28,597 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:56:29,273 - INFO - ðŸªœ Batch step - 2256 -- sub batch step 9024 -- lr 3.00e-04
2025-03-02 15:56:31,426 - INFO - ðŸªœ Batch step - 2256 -- sub batch step 9025 -- lr 3.00e-04
2025-03-02 15:56:33,593 - INFO - ðŸªœ Batch step - 2256 -- sub batch step 9026 -- lr 3.00e-04
2025-03-02 15:56:35,745 - INFO - ðŸªœ Batch step - 2256 -- sub batch step 9027 -- lr 3.00e-04
2025-03-02 15:56:37,287 - INFO - Step 2256 -- ðŸ”„ Training Metrics
2025-03-02 15:56:37,287 - INFO - â”œâ”€â”€ Loss: 6.6014
2025-03-02 15:56:37,287 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:56:37,287 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:56:37,955 - INFO - ðŸªœ Batch step - 2257 -- sub batch step 9028 -- lr 3.00e-04
2025-03-02 15:56:40,110 - INFO - ðŸªœ Batch step - 2257 -- sub batch step 9029 -- lr 3.00e-04
2025-03-02 15:56:42,540 - INFO - ðŸªœ Batch step - 2257 -- sub batch step 9030 -- lr 3.00e-04
2025-03-02 15:56:44,687 - INFO - ðŸªœ Batch step - 2257 -- sub batch step 9031 -- lr 3.00e-04
2025-03-02 15:56:46,548 - INFO - Step 2257 -- ðŸ”„ Training Metrics
2025-03-02 15:56:46,548 - INFO - â”œâ”€â”€ Loss: 6.5784
2025-03-02 15:56:46,548 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:56:46,548 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:56:47,222 - INFO - ðŸªœ Batch step - 2258 -- sub batch step 9032 -- lr 3.00e-04
2025-03-02 15:56:49,368 - INFO - ðŸªœ Batch step - 2258 -- sub batch step 9033 -- lr 3.00e-04
2025-03-02 15:56:51,539 - INFO - ðŸªœ Batch step - 2258 -- sub batch step 9034 -- lr 3.00e-04
2025-03-02 15:56:53,696 - INFO - ðŸªœ Batch step - 2258 -- sub batch step 9035 -- lr 3.00e-04
2025-03-02 15:56:55,239 - INFO - Step 2258 -- ðŸ”„ Training Metrics
2025-03-02 15:56:55,239 - INFO - â”œâ”€â”€ Loss: 6.5827
2025-03-02 15:56:55,239 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:56:55,239 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:56:55,912 - INFO - ðŸªœ Batch step - 2259 -- sub batch step 9036 -- lr 3.00e-04
2025-03-02 15:56:58,067 - INFO - ðŸªœ Batch step - 2259 -- sub batch step 9037 -- lr 3.00e-04
2025-03-02 15:57:00,337 - INFO - ðŸªœ Batch step - 2259 -- sub batch step 9038 -- lr 3.00e-04
2025-03-02 15:57:02,493 - INFO - ðŸªœ Batch step - 2259 -- sub batch step 9039 -- lr 3.00e-04
2025-03-02 15:57:04,029 - INFO - Step 2259 -- ðŸ”„ Training Metrics
2025-03-02 15:57:04,029 - INFO - â”œâ”€â”€ Loss: 6.6249
2025-03-02 15:57:04,029 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:57:04,029 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:57:05,274 - INFO - ðŸªœ Batch step - 2260 -- sub batch step 9040 -- lr 3.00e-04
2025-03-02 15:57:07,429 - INFO - ðŸªœ Batch step - 2260 -- sub batch step 9041 -- lr 3.00e-04
2025-03-02 15:57:09,588 - INFO - ðŸªœ Batch step - 2260 -- sub batch step 9042 -- lr 3.00e-04
2025-03-02 15:57:11,761 - INFO - ðŸªœ Batch step - 2260 -- sub batch step 9043 -- lr 3.00e-04
2025-03-02 15:57:13,370 - INFO - Step 2260 -- ðŸ”„ Training Metrics
2025-03-02 15:57:13,370 - INFO - â”œâ”€â”€ Loss: 6.6070
2025-03-02 15:57:13,371 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:57:13,371 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:57:14,049 - INFO - ðŸªœ Batch step - 2261 -- sub batch step 9044 -- lr 3.00e-04
2025-03-02 15:57:16,208 - INFO - ðŸªœ Batch step - 2261 -- sub batch step 9045 -- lr 3.00e-04
2025-03-02 15:57:18,355 - INFO - ðŸªœ Batch step - 2261 -- sub batch step 9046 -- lr 3.00e-04
2025-03-02 15:57:21,021 - INFO - ðŸªœ Batch step - 2261 -- sub batch step 9047 -- lr 3.00e-04
2025-03-02 15:57:22,627 - INFO - Step 2261 -- ðŸ”„ Training Metrics
2025-03-02 15:57:22,627 - INFO - â”œâ”€â”€ Loss: 6.5938
2025-03-02 15:57:22,628 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:57:22,628 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:57:23,296 - INFO - ðŸªœ Batch step - 2262 -- sub batch step 9048 -- lr 3.00e-04
2025-03-02 15:57:25,451 - INFO - ðŸªœ Batch step - 2262 -- sub batch step 9049 -- lr 3.00e-04
2025-03-02 15:57:27,605 - INFO - ðŸªœ Batch step - 2262 -- sub batch step 9050 -- lr 3.00e-04
2025-03-02 15:57:29,771 - INFO - ðŸªœ Batch step - 2262 -- sub batch step 9051 -- lr 3.00e-04
2025-03-02 15:57:31,332 - INFO - Step 2262 -- ðŸ”„ Training Metrics
2025-03-02 15:57:31,332 - INFO - â”œâ”€â”€ Loss: 6.6089
2025-03-02 15:57:31,332 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:57:31,332 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:57:32,008 - INFO - ðŸªœ Batch step - 2263 -- sub batch step 9052 -- lr 3.00e-04
2025-03-02 15:57:34,156 - INFO - ðŸªœ Batch step - 2263 -- sub batch step 9053 -- lr 3.00e-04
2025-03-02 15:57:36,309 - INFO - ðŸªœ Batch step - 2263 -- sub batch step 9054 -- lr 3.00e-04
2025-03-02 15:57:38,894 - INFO - ðŸªœ Batch step - 2263 -- sub batch step 9055 -- lr 3.00e-04
2025-03-02 15:57:40,599 - INFO - Step 2263 -- ðŸ”„ Training Metrics
2025-03-02 15:57:40,599 - INFO - â”œâ”€â”€ Loss: 6.5951
2025-03-02 15:57:40,599 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:57:40,599 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:57:41,268 - INFO - ðŸªœ Batch step - 2264 -- sub batch step 9056 -- lr 3.00e-04
2025-03-02 15:57:43,424 - INFO - ðŸªœ Batch step - 2264 -- sub batch step 9057 -- lr 3.00e-04
2025-03-02 15:57:45,573 - INFO - ðŸªœ Batch step - 2264 -- sub batch step 9058 -- lr 3.00e-04
2025-03-02 15:57:47,747 - INFO - ðŸªœ Batch step - 2264 -- sub batch step 9059 -- lr 3.00e-04
2025-03-02 15:57:49,303 - INFO - Step 2264 -- ðŸ”„ Training Metrics
2025-03-02 15:57:49,303 - INFO - â”œâ”€â”€ Loss: 6.5737
2025-03-02 15:57:49,303 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:57:49,303 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:57:49,979 - INFO - ðŸªœ Batch step - 2265 -- sub batch step 9060 -- lr 3.00e-04
2025-03-02 15:57:52,127 - INFO - ðŸªœ Batch step - 2265 -- sub batch step 9061 -- lr 3.00e-04
2025-03-02 15:57:54,283 - INFO - ðŸªœ Batch step - 2265 -- sub batch step 9062 -- lr 3.00e-04
2025-03-02 15:57:56,718 - INFO - ðŸªœ Batch step - 2265 -- sub batch step 9063 -- lr 3.00e-04
2025-03-02 15:57:58,480 - INFO - Step 2265 -- ðŸ”„ Training Metrics
2025-03-02 15:57:58,480 - INFO - â”œâ”€â”€ Loss: 6.5964
2025-03-02 15:57:58,480 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:57:58,480 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:57:59,155 - INFO - ðŸªœ Batch step - 2266 -- sub batch step 9064 -- lr 3.00e-04
2025-03-02 15:58:01,310 - INFO - ðŸªœ Batch step - 2266 -- sub batch step 9065 -- lr 3.00e-04
2025-03-02 15:58:03,459 - INFO - ðŸªœ Batch step - 2266 -- sub batch step 9066 -- lr 3.00e-04
2025-03-02 15:58:05,630 - INFO - ðŸªœ Batch step - 2266 -- sub batch step 9067 -- lr 3.00e-04
2025-03-02 15:58:07,179 - INFO - Step 2266 -- ðŸ”„ Training Metrics
2025-03-02 15:58:07,180 - INFO - â”œâ”€â”€ Loss: 6.6160
2025-03-02 15:58:07,180 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:58:07,180 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:58:07,927 - INFO - ðŸªœ Batch step - 2267 -- sub batch step 9068 -- lr 3.00e-04
2025-03-02 15:58:10,083 - INFO - ðŸªœ Batch step - 2267 -- sub batch step 9069 -- lr 3.00e-04
2025-03-02 15:58:12,242 - INFO - ðŸªœ Batch step - 2267 -- sub batch step 9070 -- lr 3.00e-04
2025-03-02 15:58:14,722 - INFO - ðŸªœ Batch step - 2267 -- sub batch step 9071 -- lr 3.00e-04
2025-03-02 15:58:16,681 - INFO - Step 2267 -- ðŸ”„ Training Metrics
2025-03-02 15:58:16,681 - INFO - â”œâ”€â”€ Loss: 6.5679
2025-03-02 15:58:16,681 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:58:16,681 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:58:17,381 - INFO - ðŸªœ Batch step - 2268 -- sub batch step 9072 -- lr 3.00e-04
2025-03-02 15:58:19,535 - INFO - ðŸªœ Batch step - 2268 -- sub batch step 9073 -- lr 3.00e-04
2025-03-02 15:58:21,692 - INFO - ðŸªœ Batch step - 2268 -- sub batch step 9074 -- lr 3.00e-04
2025-03-02 15:58:23,876 - INFO - ðŸªœ Batch step - 2268 -- sub batch step 9075 -- lr 3.00e-04
2025-03-02 15:58:25,407 - INFO - Step 2268 -- ðŸ”„ Training Metrics
2025-03-02 15:58:25,407 - INFO - â”œâ”€â”€ Loss: 6.6140
2025-03-02 15:58:25,407 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:58:25,407 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:58:26,077 - INFO - ðŸªœ Batch step - 2269 -- sub batch step 9076 -- lr 3.00e-04
2025-03-02 15:58:28,236 - INFO - ðŸªœ Batch step - 2269 -- sub batch step 9077 -- lr 3.00e-04
2025-03-02 15:58:30,387 - INFO - ðŸªœ Batch step - 2269 -- sub batch step 9078 -- lr 3.00e-04
2025-03-02 15:58:33,005 - INFO - ðŸªœ Batch step - 2269 -- sub batch step 9079 -- lr 3.00e-04
2025-03-02 15:58:35,080 - INFO - Step 2269 -- ðŸ”„ Training Metrics
2025-03-02 15:58:35,080 - INFO - â”œâ”€â”€ Loss: 6.5645
2025-03-02 15:58:35,080 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:58:35,080 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:58:35,755 - INFO - ðŸªœ Batch step - 2270 -- sub batch step 9080 -- lr 3.00e-04
2025-03-02 15:58:37,903 - INFO - ðŸªœ Batch step - 2270 -- sub batch step 9081 -- lr 3.00e-04
2025-03-02 15:58:40,057 - INFO - ðŸªœ Batch step - 2270 -- sub batch step 9082 -- lr 3.00e-04
2025-03-02 15:58:42,220 - INFO - ðŸªœ Batch step - 2270 -- sub batch step 9083 -- lr 3.00e-04
2025-03-02 15:58:43,769 - INFO - Step 2270 -- ðŸ”„ Training Metrics
2025-03-02 15:58:43,770 - INFO - â”œâ”€â”€ Loss: 6.5851
2025-03-02 15:58:43,770 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:58:43,770 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:58:44,445 - INFO - ðŸªœ Batch step - 2271 -- sub batch step 9084 -- lr 3.00e-04
2025-03-02 15:58:46,598 - INFO - ðŸªœ Batch step - 2271 -- sub batch step 9085 -- lr 3.00e-04
2025-03-02 15:58:49,281 - INFO - ðŸªœ Batch step - 2271 -- sub batch step 9086 -- lr 3.00e-04
2025-03-02 15:58:51,433 - INFO - ðŸªœ Batch step - 2271 -- sub batch step 9087 -- lr 3.00e-04
2025-03-02 15:58:52,962 - INFO - Step 2271 -- ðŸ”„ Training Metrics
2025-03-02 15:58:52,962 - INFO - â”œâ”€â”€ Loss: 6.6085
2025-03-02 15:58:52,962 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:58:52,962 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:58:53,633 - INFO - ðŸªœ Batch step - 2272 -- sub batch step 9088 -- lr 3.00e-04
2025-03-02 15:58:55,791 - INFO - ðŸªœ Batch step - 2272 -- sub batch step 9089 -- lr 3.00e-04
2025-03-02 15:58:57,961 - INFO - ðŸªœ Batch step - 2272 -- sub batch step 9090 -- lr 3.00e-04
2025-03-02 15:59:00,108 - INFO - ðŸªœ Batch step - 2272 -- sub batch step 9091 -- lr 3.00e-04
2025-03-02 15:59:01,652 - INFO - Step 2272 -- ðŸ”„ Training Metrics
2025-03-02 15:59:01,652 - INFO - â”œâ”€â”€ Loss: 6.5882
2025-03-02 15:59:01,652 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:59:01,652 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:59:02,328 - INFO - ðŸªœ Batch step - 2273 -- sub batch step 9092 -- lr 3.00e-04
2025-03-02 15:59:04,476 - INFO - ðŸªœ Batch step - 2273 -- sub batch step 9093 -- lr 3.00e-04
2025-03-02 15:59:07,079 - INFO - ðŸªœ Batch step - 2273 -- sub batch step 9094 -- lr 3.00e-04
2025-03-02 15:59:09,236 - INFO - ðŸªœ Batch step - 2273 -- sub batch step 9095 -- lr 3.00e-04
2025-03-02 15:59:11,078 - INFO - Step 2273 -- ðŸ”„ Training Metrics
2025-03-02 15:59:11,078 - INFO - â”œâ”€â”€ Loss: 6.5860
2025-03-02 15:59:11,079 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:59:11,079 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:59:11,750 - INFO - ðŸªœ Batch step - 2274 -- sub batch step 9096 -- lr 3.00e-04
2025-03-02 15:59:13,908 - INFO - ðŸªœ Batch step - 2274 -- sub batch step 9097 -- lr 3.00e-04
2025-03-02 15:59:16,073 - INFO - ðŸªœ Batch step - 2274 -- sub batch step 9098 -- lr 3.00e-04
2025-03-02 15:59:18,228 - INFO - ðŸªœ Batch step - 2274 -- sub batch step 9099 -- lr 3.00e-04
2025-03-02 15:59:19,759 - INFO - Step 2274 -- ðŸ”„ Training Metrics
2025-03-02 15:59:19,759 - INFO - â”œâ”€â”€ Loss: 6.5690
2025-03-02 15:59:19,759 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:59:19,759 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:59:20,435 - INFO - ðŸªœ Batch step - 2275 -- sub batch step 9100 -- lr 3.00e-04
2025-03-02 15:59:22,587 - INFO - ðŸªœ Batch step - 2275 -- sub batch step 9101 -- lr 3.00e-04
2025-03-02 15:59:25,263 - INFO - ðŸªœ Batch step - 2275 -- sub batch step 9102 -- lr 3.00e-04
2025-03-02 15:59:27,415 - INFO - ðŸªœ Batch step - 2275 -- sub batch step 9103 -- lr 3.00e-04
2025-03-02 15:59:28,906 - INFO - Step 2275 -- ðŸ”„ Training Metrics
2025-03-02 15:59:28,907 - INFO - â”œâ”€â”€ Loss: 6.5739
2025-03-02 15:59:28,907 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:59:28,907 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:59:29,586 - INFO - ðŸªœ Batch step - 2276 -- sub batch step 9104 -- lr 3.00e-04
2025-03-02 15:59:31,738 - INFO - ðŸªœ Batch step - 2276 -- sub batch step 9105 -- lr 3.00e-04
2025-03-02 15:59:33,900 - INFO - ðŸªœ Batch step - 2276 -- sub batch step 9106 -- lr 3.00e-04
2025-03-02 15:59:36,056 - INFO - ðŸªœ Batch step - 2276 -- sub batch step 9107 -- lr 3.00e-04
2025-03-02 15:59:37,680 - INFO - Step 2276 -- ðŸ”„ Training Metrics
2025-03-02 15:59:37,680 - INFO - â”œâ”€â”€ Loss: 6.5628
2025-03-02 15:59:37,680 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:59:37,680 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:59:38,363 - INFO - ðŸªœ Batch step - 2277 -- sub batch step 9108 -- lr 3.00e-04
2025-03-02 15:59:40,522 - INFO - ðŸªœ Batch step - 2277 -- sub batch step 9109 -- lr 3.00e-04
2025-03-02 15:59:43,214 - INFO - ðŸªœ Batch step - 2277 -- sub batch step 9110 -- lr 3.00e-04
2025-03-02 15:59:45,369 - INFO - ðŸªœ Batch step - 2277 -- sub batch step 9111 -- lr 3.00e-04
2025-03-02 15:59:46,902 - INFO - Step 2277 -- ðŸ”„ Training Metrics
2025-03-02 15:59:46,902 - INFO - â”œâ”€â”€ Loss: 6.5722
2025-03-02 15:59:46,902 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:59:46,902 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:59:47,581 - INFO - ðŸªœ Batch step - 2278 -- sub batch step 9112 -- lr 3.00e-04
2025-03-02 15:59:49,728 - INFO - ðŸªœ Batch step - 2278 -- sub batch step 9113 -- lr 3.00e-04
2025-03-02 15:59:51,901 - INFO - ðŸªœ Batch step - 2278 -- sub batch step 9114 -- lr 3.00e-04
2025-03-02 15:59:54,055 - INFO - ðŸªœ Batch step - 2278 -- sub batch step 9115 -- lr 3.00e-04
2025-03-02 15:59:55,596 - INFO - Step 2278 -- ðŸ”„ Training Metrics
2025-03-02 15:59:55,596 - INFO - â”œâ”€â”€ Loss: 6.5757
2025-03-02 15:59:55,596 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 15:59:55,596 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 15:59:56,270 - INFO - ðŸªœ Batch step - 2279 -- sub batch step 9116 -- lr 3.00e-04
2025-03-02 15:59:58,425 - INFO - ðŸªœ Batch step - 2279 -- sub batch step 9117 -- lr 3.00e-04
2025-03-02 16:00:00,732 - INFO - ðŸªœ Batch step - 2279 -- sub batch step 9118 -- lr 3.00e-04
2025-03-02 16:00:02,884 - INFO - ðŸªœ Batch step - 2279 -- sub batch step 9119 -- lr 3.00e-04
2025-03-02 16:00:04,604 - INFO - Step 2279 -- ðŸ”„ Training Metrics
2025-03-02 16:00:04,605 - INFO - â”œâ”€â”€ Loss: 6.5763
2025-03-02 16:00:04,605 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:00:04,605 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:00:05,856 - INFO - ðŸªœ Batch step - 2280 -- sub batch step 9120 -- lr 3.00e-04
2025-03-02 16:00:08,012 - INFO - ðŸªœ Batch step - 2280 -- sub batch step 9121 -- lr 3.00e-04
2025-03-02 16:00:10,173 - INFO - ðŸªœ Batch step - 2280 -- sub batch step 9122 -- lr 3.00e-04
2025-03-02 16:00:12,347 - INFO - ðŸªœ Batch step - 2280 -- sub batch step 9123 -- lr 3.00e-04
2025-03-02 16:00:13,970 - INFO - Step 2280 -- ðŸ”„ Training Metrics
2025-03-02 16:00:13,971 - INFO - â”œâ”€â”€ Loss: 6.5574
2025-03-02 16:00:13,971 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:00:13,971 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:00:14,647 - INFO - ðŸªœ Batch step - 2281 -- sub batch step 9124 -- lr 3.00e-04
2025-03-02 16:00:16,802 - INFO - ðŸªœ Batch step - 2281 -- sub batch step 9125 -- lr 3.00e-04
2025-03-02 16:00:18,952 - INFO - ðŸªœ Batch step - 2281 -- sub batch step 9126 -- lr 3.00e-04
2025-03-02 16:00:21,556 - INFO - ðŸªœ Batch step - 2281 -- sub batch step 9127 -- lr 3.00e-04
2025-03-02 16:00:23,258 - INFO - Step 2281 -- ðŸ”„ Training Metrics
2025-03-02 16:00:23,259 - INFO - â”œâ”€â”€ Loss: 6.5896
2025-03-02 16:00:23,259 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:00:23,259 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:00:23,930 - INFO - ðŸªœ Batch step - 2282 -- sub batch step 9128 -- lr 3.00e-04
2025-03-02 16:00:26,086 - INFO - ðŸªœ Batch step - 2282 -- sub batch step 9129 -- lr 3.00e-04
2025-03-02 16:00:28,243 - INFO - ðŸªœ Batch step - 2282 -- sub batch step 9130 -- lr 3.00e-04
2025-03-02 16:00:30,412 - INFO - ðŸªœ Batch step - 2282 -- sub batch step 9131 -- lr 3.00e-04
2025-03-02 16:00:31,968 - INFO - Step 2282 -- ðŸ”„ Training Metrics
2025-03-02 16:00:31,969 - INFO - â”œâ”€â”€ Loss: 6.5605
2025-03-02 16:00:31,969 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:00:31,969 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:00:32,647 - INFO - ðŸªœ Batch step - 2283 -- sub batch step 9132 -- lr 3.00e-04
2025-03-02 16:00:34,797 - INFO - ðŸªœ Batch step - 2283 -- sub batch step 9133 -- lr 3.00e-04
2025-03-02 16:00:36,950 - INFO - ðŸªœ Batch step - 2283 -- sub batch step 9134 -- lr 3.00e-04
2025-03-02 16:00:39,621 - INFO - ðŸªœ Batch step - 2283 -- sub batch step 9135 -- lr 3.00e-04
2025-03-02 16:00:43,202 - INFO - Step 2283 -- ðŸ”„ Training Metrics
2025-03-02 16:00:43,203 - INFO - â”œâ”€â”€ Loss: 6.5899
2025-03-02 16:00:43,203 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:00:43,203 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:00:43,875 - INFO - ðŸªœ Batch step - 2284 -- sub batch step 9136 -- lr 3.00e-04
2025-03-02 16:00:46,028 - INFO - ðŸªœ Batch step - 2284 -- sub batch step 9137 -- lr 3.00e-04
2025-03-02 16:00:48,177 - INFO - ðŸªœ Batch step - 2284 -- sub batch step 9138 -- lr 3.00e-04
2025-03-02 16:00:50,352 - INFO - ðŸªœ Batch step - 2284 -- sub batch step 9139 -- lr 3.00e-04
2025-03-02 16:00:51,900 - INFO - Step 2284 -- ðŸ”„ Training Metrics
2025-03-02 16:00:51,900 - INFO - â”œâ”€â”€ Loss: 6.5582
2025-03-02 16:00:51,900 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:00:51,900 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:00:52,577 - INFO - ðŸªœ Batch step - 2285 -- sub batch step 9140 -- lr 3.00e-04
2025-03-02 16:00:54,726 - INFO - ðŸªœ Batch step - 2285 -- sub batch step 9141 -- lr 3.00e-04
2025-03-02 16:00:56,880 - INFO - ðŸªœ Batch step - 2285 -- sub batch step 9142 -- lr 3.00e-04
2025-03-02 16:00:59,602 - INFO - ðŸªœ Batch step - 2285 -- sub batch step 9143 -- lr 3.00e-04
2025-03-02 16:01:01,098 - INFO - Step 2285 -- ðŸ”„ Training Metrics
2025-03-02 16:01:01,098 - INFO - â”œâ”€â”€ Loss: 6.5442
2025-03-02 16:01:01,098 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:01:01,098 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:01:01,773 - INFO - ðŸªœ Batch step - 2286 -- sub batch step 9144 -- lr 3.00e-04
2025-03-02 16:01:03,930 - INFO - ðŸªœ Batch step - 2286 -- sub batch step 9145 -- lr 3.00e-04
2025-03-02 16:01:06,078 - INFO - ðŸªœ Batch step - 2286 -- sub batch step 9146 -- lr 3.00e-04
2025-03-02 16:01:08,255 - INFO - ðŸªœ Batch step - 2286 -- sub batch step 9147 -- lr 3.00e-04
2025-03-02 16:01:09,806 - INFO - Step 2286 -- ðŸ”„ Training Metrics
2025-03-02 16:01:09,806 - INFO - â”œâ”€â”€ Loss: 6.5702
2025-03-02 16:01:09,806 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:01:09,807 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:01:10,476 - INFO - ðŸªœ Batch step - 2287 -- sub batch step 9148 -- lr 3.00e-04
2025-03-02 16:01:12,629 - INFO - ðŸªœ Batch step - 2287 -- sub batch step 9149 -- lr 3.00e-04
2025-03-02 16:01:14,785 - INFO - ðŸªœ Batch step - 2287 -- sub batch step 9150 -- lr 3.00e-04
2025-03-02 16:01:17,420 - INFO - ðŸªœ Batch step - 2287 -- sub batch step 9151 -- lr 3.00e-04
2025-03-02 16:01:19,076 - INFO - Step 2287 -- ðŸ”„ Training Metrics
2025-03-02 16:01:19,077 - INFO - â”œâ”€â”€ Loss: 6.5839
2025-03-02 16:01:19,077 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:01:19,077 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:01:19,753 - INFO - ðŸªœ Batch step - 2288 -- sub batch step 9152 -- lr 3.00e-04
2025-03-02 16:01:21,905 - INFO - ðŸªœ Batch step - 2288 -- sub batch step 9153 -- lr 3.00e-04
2025-03-02 16:01:24,063 - INFO - ðŸªœ Batch step - 2288 -- sub batch step 9154 -- lr 3.00e-04
2025-03-02 16:01:26,234 - INFO - ðŸªœ Batch step - 2288 -- sub batch step 9155 -- lr 3.00e-04
2025-03-02 16:01:27,796 - INFO - Step 2288 -- ðŸ”„ Training Metrics
2025-03-02 16:01:27,796 - INFO - â”œâ”€â”€ Loss: 6.5615
2025-03-02 16:01:27,796 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:01:27,796 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:01:28,468 - INFO - ðŸªœ Batch step - 2289 -- sub batch step 9156 -- lr 3.00e-04
2025-03-02 16:01:30,620 - INFO - ðŸªœ Batch step - 2289 -- sub batch step 9157 -- lr 3.00e-04
2025-03-02 16:01:32,766 - INFO - ðŸªœ Batch step - 2289 -- sub batch step 9158 -- lr 3.00e-04
2025-03-02 16:01:35,137 - INFO - ðŸªœ Batch step - 2289 -- sub batch step 9159 -- lr 3.00e-04
2025-03-02 16:01:37,036 - INFO - Step 2289 -- ðŸ”„ Training Metrics
2025-03-02 16:01:37,037 - INFO - â”œâ”€â”€ Loss: 6.5431
2025-03-02 16:01:37,037 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:01:37,037 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:01:37,713 - INFO - ðŸªœ Batch step - 2290 -- sub batch step 9160 -- lr 3.00e-04
2025-03-02 16:01:39,861 - INFO - ðŸªœ Batch step - 2290 -- sub batch step 9161 -- lr 3.00e-04
2025-03-02 16:01:42,014 - INFO - ðŸªœ Batch step - 2290 -- sub batch step 9162 -- lr 3.00e-04
2025-03-02 16:01:44,178 - INFO - ðŸªœ Batch step - 2290 -- sub batch step 9163 -- lr 3.00e-04
2025-03-02 16:01:45,742 - INFO - Step 2290 -- ðŸ”„ Training Metrics
2025-03-02 16:01:45,742 - INFO - â”œâ”€â”€ Loss: 6.5740
2025-03-02 16:01:45,743 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:01:45,743 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:01:46,417 - INFO - ðŸªœ Batch step - 2291 -- sub batch step 9164 -- lr 3.00e-04
2025-03-02 16:01:48,571 - INFO - ðŸªœ Batch step - 2291 -- sub batch step 9165 -- lr 3.00e-04
2025-03-02 16:01:51,177 - INFO - ðŸªœ Batch step - 2291 -- sub batch step 9166 -- lr 3.00e-04
2025-03-02 16:01:53,329 - INFO - ðŸªœ Batch step - 2291 -- sub batch step 9167 -- lr 3.00e-04
2025-03-02 16:01:55,076 - INFO - Step 2291 -- ðŸ”„ Training Metrics
2025-03-02 16:01:55,076 - INFO - â”œâ”€â”€ Loss: 6.5456
2025-03-02 16:01:55,076 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:01:55,076 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:01:55,746 - INFO - ðŸªœ Batch step - 2292 -- sub batch step 9168 -- lr 3.00e-04
2025-03-02 16:01:57,915 - INFO - ðŸªœ Batch step - 2292 -- sub batch step 9169 -- lr 3.00e-04
2025-03-02 16:02:00,216 - INFO - ðŸªœ Batch step - 2292 -- sub batch step 9170 -- lr 3.00e-04
2025-03-02 16:02:02,367 - INFO - ðŸªœ Batch step - 2292 -- sub batch step 9171 -- lr 3.00e-04
2025-03-02 16:02:03,881 - INFO - Step 2292 -- ðŸ”„ Training Metrics
2025-03-02 16:02:03,881 - INFO - â”œâ”€â”€ Loss: 6.5671
2025-03-02 16:02:03,881 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:02:03,881 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:02:04,554 - INFO - ðŸªœ Batch step - 2293 -- sub batch step 9172 -- lr 3.00e-04
2025-03-02 16:02:06,703 - INFO - ðŸªœ Batch step - 2293 -- sub batch step 9173 -- lr 3.00e-04
2025-03-02 16:02:09,316 - INFO - ðŸªœ Batch step - 2293 -- sub batch step 9174 -- lr 3.00e-04
2025-03-02 16:02:11,468 - INFO - ðŸªœ Batch step - 2293 -- sub batch step 9175 -- lr 3.00e-04
2025-03-02 16:02:13,055 - INFO - Step 2293 -- ðŸ”„ Training Metrics
2025-03-02 16:02:13,055 - INFO - â”œâ”€â”€ Loss: 6.5564
2025-03-02 16:02:13,055 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:02:13,056 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:02:13,726 - INFO - ðŸªœ Batch step - 2294 -- sub batch step 9176 -- lr 3.00e-04
2025-03-02 16:02:15,877 - INFO - ðŸªœ Batch step - 2294 -- sub batch step 9177 -- lr 3.00e-04
2025-03-02 16:02:18,042 - INFO - ðŸªœ Batch step - 2294 -- sub batch step 9178 -- lr 3.00e-04
2025-03-02 16:02:20,193 - INFO - ðŸªœ Batch step - 2294 -- sub batch step 9179 -- lr 3.00e-04
2025-03-02 16:02:21,746 - INFO - Step 2294 -- ðŸ”„ Training Metrics
2025-03-02 16:02:21,747 - INFO - â”œâ”€â”€ Loss: 6.5330
2025-03-02 16:02:21,747 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:02:21,747 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:02:22,418 - INFO - ðŸªœ Batch step - 2295 -- sub batch step 9180 -- lr 3.00e-04
2025-03-02 16:02:24,565 - INFO - ðŸªœ Batch step - 2295 -- sub batch step 9181 -- lr 3.00e-04
2025-03-02 16:02:26,994 - INFO - ðŸªœ Batch step - 2295 -- sub batch step 9182 -- lr 3.00e-04
2025-03-02 16:02:29,141 - INFO - ðŸªœ Batch step - 2295 -- sub batch step 9183 -- lr 3.00e-04
2025-03-02 16:02:31,106 - INFO - Step 2295 -- ðŸ”„ Training Metrics
2025-03-02 16:02:31,106 - INFO - â”œâ”€â”€ Loss: 6.5491
2025-03-02 16:02:31,107 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:02:31,107 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:02:31,780 - INFO - ðŸªœ Batch step - 2296 -- sub batch step 9184 -- lr 3.00e-04
2025-03-02 16:02:33,933 - INFO - ðŸªœ Batch step - 2296 -- sub batch step 9185 -- lr 3.00e-04
2025-03-02 16:02:36,099 - INFO - ðŸªœ Batch step - 2296 -- sub batch step 9186 -- lr 3.00e-04
2025-03-02 16:02:38,249 - INFO - ðŸªœ Batch step - 2296 -- sub batch step 9187 -- lr 3.00e-04
2025-03-02 16:02:39,801 - INFO - Step 2296 -- ðŸ”„ Training Metrics
2025-03-02 16:02:39,801 - INFO - â”œâ”€â”€ Loss: 6.5365
2025-03-02 16:02:39,801 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:02:39,801 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:02:40,468 - INFO - ðŸªœ Batch step - 2297 -- sub batch step 9188 -- lr 3.00e-04
2025-03-02 16:02:42,624 - INFO - ðŸªœ Batch step - 2297 -- sub batch step 9189 -- lr 3.00e-04
2025-03-02 16:02:45,003 - INFO - ðŸªœ Batch step - 2297 -- sub batch step 9190 -- lr 3.00e-04
2025-03-02 16:02:47,153 - INFO - ðŸªœ Batch step - 2297 -- sub batch step 9191 -- lr 3.00e-04
2025-03-02 16:02:49,086 - INFO - Step 2297 -- ðŸ”„ Training Metrics
2025-03-02 16:02:49,086 - INFO - â”œâ”€â”€ Loss: 6.5285
2025-03-02 16:02:49,086 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:02:49,087 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:02:49,760 - INFO - ðŸªœ Batch step - 2298 -- sub batch step 9192 -- lr 3.00e-04
2025-03-02 16:02:51,907 - INFO - ðŸªœ Batch step - 2298 -- sub batch step 9193 -- lr 3.00e-04
2025-03-02 16:02:54,081 - INFO - ðŸªœ Batch step - 2298 -- sub batch step 9194 -- lr 3.00e-04
2025-03-02 16:02:56,238 - INFO - ðŸªœ Batch step - 2298 -- sub batch step 9195 -- lr 3.00e-04
2025-03-02 16:02:57,790 - INFO - Step 2298 -- ðŸ”„ Training Metrics
2025-03-02 16:02:57,790 - INFO - â”œâ”€â”€ Loss: 6.5681
2025-03-02 16:02:57,790 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:02:57,791 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:02:58,460 - INFO - ðŸªœ Batch step - 2299 -- sub batch step 9196 -- lr 3.00e-04
2025-03-02 16:03:00,613 - INFO - ðŸªœ Batch step - 2299 -- sub batch step 9197 -- lr 3.00e-04
2025-03-02 16:03:02,881 - INFO - ðŸªœ Batch step - 2299 -- sub batch step 9198 -- lr 3.00e-04
2025-03-02 16:03:05,035 - INFO - ðŸªœ Batch step - 2299 -- sub batch step 9199 -- lr 3.00e-04
2025-03-02 16:03:06,659 - INFO - Step 2299 -- ðŸ”„ Training Metrics
2025-03-02 16:03:06,659 - INFO - â”œâ”€â”€ Loss: 6.5452
2025-03-02 16:03:06,659 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:03:06,660 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:03:07,846 - INFO - ðŸªœ Batch step - 2300 -- sub batch step 9200 -- lr 3.00e-04
2025-03-02 16:03:10,000 - INFO - ðŸªœ Batch step - 2300 -- sub batch step 9201 -- lr 3.00e-04
2025-03-02 16:03:12,158 - INFO - ðŸªœ Batch step - 2300 -- sub batch step 9202 -- lr 3.00e-04
2025-03-02 16:03:14,330 - INFO - ðŸªœ Batch step - 2300 -- sub batch step 9203 -- lr 3.00e-04
2025-03-02 16:03:15,983 - INFO - Step 2300 -- ðŸ”„ Training Metrics
2025-03-02 16:03:15,983 - INFO - â”œâ”€â”€ Loss: 6.5507
2025-03-02 16:03:15,983 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:03:15,983 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:03:16,662 - INFO - ðŸªœ Batch step - 2301 -- sub batch step 9204 -- lr 3.00e-04
2025-03-02 16:03:18,821 - INFO - ðŸªœ Batch step - 2301 -- sub batch step 9205 -- lr 3.00e-04
2025-03-02 16:03:20,978 - INFO - ðŸªœ Batch step - 2301 -- sub batch step 9206 -- lr 3.00e-04
2025-03-02 16:03:23,563 - INFO - ðŸªœ Batch step - 2301 -- sub batch step 9207 -- lr 3.00e-04
2025-03-02 16:03:25,250 - INFO - Step 2301 -- ðŸ”„ Training Metrics
2025-03-02 16:03:25,250 - INFO - â”œâ”€â”€ Loss: 6.5521
2025-03-02 16:03:25,250 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:03:25,251 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:03:25,921 - INFO - ðŸªœ Batch step - 2302 -- sub batch step 9208 -- lr 3.00e-04
2025-03-02 16:03:28,084 - INFO - ðŸªœ Batch step - 2302 -- sub batch step 9209 -- lr 3.00e-04
2025-03-02 16:03:30,241 - INFO - ðŸªœ Batch step - 2302 -- sub batch step 9210 -- lr 3.00e-04
2025-03-02 16:03:32,408 - INFO - ðŸªœ Batch step - 2302 -- sub batch step 9211 -- lr 3.00e-04
2025-03-02 16:03:33,966 - INFO - Step 2302 -- ðŸ”„ Training Metrics
2025-03-02 16:03:33,966 - INFO - â”œâ”€â”€ Loss: 6.5422
2025-03-02 16:03:33,966 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:03:33,966 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:03:34,647 - INFO - ðŸªœ Batch step - 2303 -- sub batch step 9212 -- lr 3.00e-04
2025-03-02 16:03:36,801 - INFO - ðŸªœ Batch step - 2303 -- sub batch step 9213 -- lr 3.00e-04
2025-03-02 16:03:38,956 - INFO - ðŸªœ Batch step - 2303 -- sub batch step 9214 -- lr 3.00e-04
2025-03-02 16:03:41,311 - INFO - ðŸªœ Batch step - 2303 -- sub batch step 9215 -- lr 3.00e-04
2025-03-02 16:03:43,211 - INFO - Step 2303 -- ðŸ”„ Training Metrics
2025-03-02 16:03:43,212 - INFO - â”œâ”€â”€ Loss: 6.5488
2025-03-02 16:03:43,212 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:03:43,212 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:03:43,880 - INFO - ðŸªœ Batch step - 2304 -- sub batch step 9216 -- lr 3.00e-04
2025-03-02 16:03:46,040 - INFO - ðŸªœ Batch step - 2304 -- sub batch step 9217 -- lr 3.00e-04
2025-03-02 16:03:48,190 - INFO - ðŸªœ Batch step - 2304 -- sub batch step 9218 -- lr 3.00e-04
2025-03-02 16:03:50,365 - INFO - ðŸªœ Batch step - 2304 -- sub batch step 9219 -- lr 3.00e-04
2025-03-02 16:03:51,936 - INFO - Step 2304 -- ðŸ”„ Training Metrics
2025-03-02 16:03:51,936 - INFO - â”œâ”€â”€ Loss: 6.5775
2025-03-02 16:03:51,936 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:03:51,937 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:03:52,611 - INFO - ðŸªœ Batch step - 2305 -- sub batch step 9220 -- lr 3.00e-04
2025-03-02 16:03:54,764 - INFO - ðŸªœ Batch step - 2305 -- sub batch step 9221 -- lr 3.00e-04
2025-03-02 16:03:56,918 - INFO - ðŸªœ Batch step - 2305 -- sub batch step 9222 -- lr 3.00e-04
2025-03-02 16:03:59,266 - INFO - ðŸªœ Batch step - 2305 -- sub batch step 9223 -- lr 3.00e-04
2025-03-02 16:04:06,805 - INFO - Step 2305 -- ðŸ”„ Training Metrics
2025-03-02 16:04:06,805 - INFO - â”œâ”€â”€ Loss: 6.5332
2025-03-02 16:04:06,805 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:04:06,806 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:04:07,478 - INFO - ðŸªœ Batch step - 2306 -- sub batch step 9224 -- lr 3.00e-04
2025-03-02 16:04:09,633 - INFO - ðŸªœ Batch step - 2306 -- sub batch step 9225 -- lr 3.00e-04
2025-03-02 16:04:11,779 - INFO - ðŸªœ Batch step - 2306 -- sub batch step 9226 -- lr 3.00e-04
2025-03-02 16:04:13,947 - INFO - ðŸªœ Batch step - 2306 -- sub batch step 9227 -- lr 3.00e-04
2025-03-02 16:04:15,516 - INFO - Step 2306 -- ðŸ”„ Training Metrics
2025-03-02 16:04:15,517 - INFO - â”œâ”€â”€ Loss: 6.5452
2025-03-02 16:04:15,517 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:04:15,517 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:04:16,184 - INFO - ðŸªœ Batch step - 2307 -- sub batch step 9228 -- lr 3.00e-04
2025-03-02 16:04:18,337 - INFO - ðŸªœ Batch step - 2307 -- sub batch step 9229 -- lr 3.00e-04
2025-03-02 16:04:20,490 - INFO - ðŸªœ Batch step - 2307 -- sub batch step 9230 -- lr 3.00e-04
2025-03-02 16:04:23,156 - INFO - ðŸªœ Batch step - 2307 -- sub batch step 9231 -- lr 3.00e-04
2025-03-02 16:04:24,675 - INFO - Step 2307 -- ðŸ”„ Training Metrics
2025-03-02 16:04:24,675 - INFO - â”œâ”€â”€ Loss: 6.5499
2025-03-02 16:04:24,675 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:04:24,675 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:04:25,350 - INFO - ðŸªœ Batch step - 2308 -- sub batch step 9232 -- lr 3.00e-04
2025-03-02 16:04:27,497 - INFO - ðŸªœ Batch step - 2308 -- sub batch step 9233 -- lr 3.00e-04
2025-03-02 16:04:29,649 - INFO - ðŸªœ Batch step - 2308 -- sub batch step 9234 -- lr 3.00e-04
2025-03-02 16:04:31,815 - INFO - ðŸªœ Batch step - 2308 -- sub batch step 9235 -- lr 3.00e-04
2025-03-02 16:04:33,374 - INFO - Step 2308 -- ðŸ”„ Training Metrics
2025-03-02 16:04:33,375 - INFO - â”œâ”€â”€ Loss: 6.5594
2025-03-02 16:04:33,375 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:04:33,375 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:04:34,042 - INFO - ðŸªœ Batch step - 2309 -- sub batch step 9236 -- lr 3.00e-04
2025-03-02 16:04:36,195 - INFO - ðŸªœ Batch step - 2309 -- sub batch step 9237 -- lr 3.00e-04
2025-03-02 16:04:38,339 - INFO - ðŸªœ Batch step - 2309 -- sub batch step 9238 -- lr 3.00e-04
2025-03-02 16:04:41,062 - INFO - ðŸªœ Batch step - 2309 -- sub batch step 9239 -- lr 3.00e-04
2025-03-02 16:04:42,575 - INFO - Step 2309 -- ðŸ”„ Training Metrics
2025-03-02 16:04:42,575 - INFO - â”œâ”€â”€ Loss: 6.5510
2025-03-02 16:04:42,575 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:04:42,575 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:04:43,252 - INFO - ðŸªœ Batch step - 2310 -- sub batch step 9240 -- lr 3.00e-04
2025-03-02 16:04:45,402 - INFO - ðŸªœ Batch step - 2310 -- sub batch step 9241 -- lr 3.00e-04
2025-03-02 16:04:47,557 - INFO - ðŸªœ Batch step - 2310 -- sub batch step 9242 -- lr 3.00e-04
2025-03-02 16:04:49,718 - INFO - ðŸªœ Batch step - 2310 -- sub batch step 9243 -- lr 3.00e-04
2025-03-02 16:04:51,272 - INFO - Step 2310 -- ðŸ”„ Training Metrics
2025-03-02 16:04:51,273 - INFO - â”œâ”€â”€ Loss: 6.5517
2025-03-02 16:04:51,273 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:04:51,273 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:04:51,950 - INFO - ðŸªœ Batch step - 2311 -- sub batch step 9244 -- lr 3.00e-04
2025-03-02 16:04:54,102 - INFO - ðŸªœ Batch step - 2311 -- sub batch step 9245 -- lr 3.00e-04
2025-03-02 16:04:56,712 - INFO - ðŸªœ Batch step - 2311 -- sub batch step 9246 -- lr 3.00e-04
2025-03-02 16:04:58,870 - INFO - ðŸªœ Batch step - 2311 -- sub batch step 9247 -- lr 3.00e-04
2025-03-02 16:05:00,402 - INFO - Step 2311 -- ðŸ”„ Training Metrics
2025-03-02 16:05:00,403 - INFO - â”œâ”€â”€ Loss: 6.5438
2025-03-02 16:05:00,403 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:05:00,403 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:05:01,073 - INFO - ðŸªœ Batch step - 2312 -- sub batch step 9248 -- lr 3.00e-04
2025-03-02 16:05:03,227 - INFO - ðŸªœ Batch step - 2312 -- sub batch step 9249 -- lr 3.00e-04
2025-03-02 16:05:05,394 - INFO - ðŸªœ Batch step - 2312 -- sub batch step 9250 -- lr 3.00e-04
2025-03-02 16:05:07,540 - INFO - ðŸªœ Batch step - 2312 -- sub batch step 9251 -- lr 3.00e-04
2025-03-02 16:05:09,093 - INFO - Step 2312 -- ðŸ”„ Training Metrics
2025-03-02 16:05:09,093 - INFO - â”œâ”€â”€ Loss: 6.5378
2025-03-02 16:05:09,094 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:05:09,094 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:05:09,769 - INFO - ðŸªœ Batch step - 2313 -- sub batch step 9252 -- lr 3.00e-04
2025-03-02 16:05:11,918 - INFO - ðŸªœ Batch step - 2313 -- sub batch step 9253 -- lr 3.00e-04
2025-03-02 16:05:14,280 - INFO - ðŸªœ Batch step - 2313 -- sub batch step 9254 -- lr 3.00e-04
2025-03-02 16:05:16,429 - INFO - ðŸªœ Batch step - 2313 -- sub batch step 9255 -- lr 3.00e-04
2025-03-02 16:05:18,274 - INFO - Step 2313 -- ðŸ”„ Training Metrics
2025-03-02 16:05:18,274 - INFO - â”œâ”€â”€ Loss: 6.5598
2025-03-02 16:05:18,274 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:05:18,274 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:05:18,945 - INFO - ðŸªœ Batch step - 2314 -- sub batch step 9256 -- lr 3.00e-04
2025-03-02 16:05:21,101 - INFO - ðŸªœ Batch step - 2314 -- sub batch step 9257 -- lr 3.00e-04
2025-03-02 16:05:23,268 - INFO - ðŸªœ Batch step - 2314 -- sub batch step 9258 -- lr 3.00e-04
2025-03-02 16:05:25,420 - INFO - ðŸªœ Batch step - 2314 -- sub batch step 9259 -- lr 3.00e-04
2025-03-02 16:05:26,961 - INFO - Step 2314 -- ðŸ”„ Training Metrics
2025-03-02 16:05:26,962 - INFO - â”œâ”€â”€ Loss: 6.5085
2025-03-02 16:05:26,962 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:05:26,962 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:05:27,638 - INFO - ðŸªœ Batch step - 2315 -- sub batch step 9260 -- lr 3.00e-04
2025-03-02 16:05:29,788 - INFO - ðŸªœ Batch step - 2315 -- sub batch step 9261 -- lr 3.00e-04
2025-03-02 16:05:32,466 - INFO - ðŸªœ Batch step - 2315 -- sub batch step 9262 -- lr 3.00e-04
2025-03-02 16:05:34,615 - INFO - ðŸªœ Batch step - 2315 -- sub batch step 9263 -- lr 3.00e-04
2025-03-02 16:05:36,212 - INFO - Step 2315 -- ðŸ”„ Training Metrics
2025-03-02 16:05:36,213 - INFO - â”œâ”€â”€ Loss: 6.5339
2025-03-02 16:05:36,213 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:05:36,213 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:05:36,890 - INFO - ðŸªœ Batch step - 2316 -- sub batch step 9264 -- lr 3.00e-04
2025-03-02 16:05:39,047 - INFO - ðŸªœ Batch step - 2316 -- sub batch step 9265 -- lr 3.00e-04
2025-03-02 16:05:41,210 - INFO - ðŸªœ Batch step - 2316 -- sub batch step 9266 -- lr 3.00e-04
2025-03-02 16:05:43,364 - INFO - ðŸªœ Batch step - 2316 -- sub batch step 9267 -- lr 3.00e-04
2025-03-02 16:05:44,913 - INFO - Step 2316 -- ðŸ”„ Training Metrics
2025-03-02 16:05:44,914 - INFO - â”œâ”€â”€ Loss: 6.5351
2025-03-02 16:05:44,914 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:05:44,914 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:05:45,586 - INFO - ðŸªœ Batch step - 2317 -- sub batch step 9268 -- lr 3.00e-04
2025-03-02 16:05:47,742 - INFO - ðŸªœ Batch step - 2317 -- sub batch step 9269 -- lr 3.00e-04
2025-03-02 16:05:50,168 - INFO - ðŸªœ Batch step - 2317 -- sub batch step 9270 -- lr 3.00e-04
2025-03-02 16:05:52,312 - INFO - ðŸªœ Batch step - 2317 -- sub batch step 9271 -- lr 3.00e-04
2025-03-02 16:05:54,081 - INFO - Step 2317 -- ðŸ”„ Training Metrics
2025-03-02 16:05:54,081 - INFO - â”œâ”€â”€ Loss: 6.5615
2025-03-02 16:05:54,081 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:05:54,081 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:05:54,754 - INFO - ðŸªœ Batch step - 2318 -- sub batch step 9272 -- lr 3.00e-04
2025-03-02 16:05:56,902 - INFO - ðŸªœ Batch step - 2318 -- sub batch step 9273 -- lr 3.00e-04
2025-03-02 16:05:59,068 - INFO - ðŸªœ Batch step - 2318 -- sub batch step 9274 -- lr 3.00e-04
2025-03-02 16:06:01,219 - INFO - ðŸªœ Batch step - 2318 -- sub batch step 9275 -- lr 3.00e-04
2025-03-02 16:06:02,781 - INFO - Step 2318 -- ðŸ”„ Training Metrics
2025-03-02 16:06:02,782 - INFO - â”œâ”€â”€ Loss: 6.5466
2025-03-02 16:06:02,782 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:06:02,782 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:06:03,453 - INFO - ðŸªœ Batch step - 2319 -- sub batch step 9276 -- lr 3.00e-04
2025-03-02 16:06:05,606 - INFO - ðŸªœ Batch step - 2319 -- sub batch step 9277 -- lr 3.00e-04
2025-03-02 16:06:07,906 - INFO - ðŸªœ Batch step - 2319 -- sub batch step 9278 -- lr 3.00e-04
2025-03-02 16:06:10,058 - INFO - ðŸªœ Batch step - 2319 -- sub batch step 9279 -- lr 3.00e-04
2025-03-02 16:06:11,591 - INFO - Step 2319 -- ðŸ”„ Training Metrics
2025-03-02 16:06:11,591 - INFO - â”œâ”€â”€ Loss: 6.5297
2025-03-02 16:06:11,591 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:06:11,591 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:06:12,708 - INFO - ðŸªœ Batch step - 2320 -- sub batch step 9280 -- lr 3.00e-04
2025-03-02 16:06:14,861 - INFO - ðŸªœ Batch step - 2320 -- sub batch step 9281 -- lr 3.00e-04
2025-03-02 16:06:17,014 - INFO - ðŸªœ Batch step - 2320 -- sub batch step 9282 -- lr 3.00e-04
2025-03-02 16:06:19,182 - INFO - ðŸªœ Batch step - 2320 -- sub batch step 9283 -- lr 3.00e-04
2025-03-02 16:06:20,891 - INFO - Step 2320 -- ðŸ”„ Training Metrics
2025-03-02 16:06:20,891 - INFO - â”œâ”€â”€ Loss: 6.5277
2025-03-02 16:06:20,891 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:06:20,891 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:06:21,566 - INFO - ðŸªœ Batch step - 2321 -- sub batch step 9284 -- lr 3.00e-04
2025-03-02 16:06:23,719 - INFO - ðŸªœ Batch step - 2321 -- sub batch step 9285 -- lr 3.00e-04
2025-03-02 16:06:25,864 - INFO - ðŸªœ Batch step - 2321 -- sub batch step 9286 -- lr 3.00e-04
2025-03-02 16:06:28,673 - INFO - ðŸªœ Batch step - 2321 -- sub batch step 9287 -- lr 3.00e-04
2025-03-02 16:06:30,163 - INFO - Step 2321 -- ðŸ”„ Training Metrics
2025-03-02 16:06:30,163 - INFO - â”œâ”€â”€ Loss: 6.5004
2025-03-02 16:06:30,163 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:06:30,163 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:06:30,831 - INFO - ðŸªœ Batch step - 2322 -- sub batch step 9288 -- lr 3.00e-04
2025-03-02 16:06:32,982 - INFO - ðŸªœ Batch step - 2322 -- sub batch step 9289 -- lr 3.00e-04
2025-03-02 16:06:35,132 - INFO - ðŸªœ Batch step - 2322 -- sub batch step 9290 -- lr 3.00e-04
2025-03-02 16:06:37,296 - INFO - ðŸªœ Batch step - 2322 -- sub batch step 9291 -- lr 3.00e-04
2025-03-02 16:06:38,864 - INFO - Step 2322 -- ðŸ”„ Training Metrics
2025-03-02 16:06:38,865 - INFO - â”œâ”€â”€ Loss: 6.5421
2025-03-02 16:06:38,865 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:06:38,865 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:06:39,540 - INFO - ðŸªœ Batch step - 2323 -- sub batch step 9292 -- lr 3.00e-04
2025-03-02 16:06:41,687 - INFO - ðŸªœ Batch step - 2323 -- sub batch step 9293 -- lr 3.00e-04
2025-03-02 16:06:43,843 - INFO - ðŸªœ Batch step - 2323 -- sub batch step 9294 -- lr 3.00e-04
2025-03-02 16:06:46,569 - INFO - ðŸªœ Batch step - 2323 -- sub batch step 9295 -- lr 3.00e-04
2025-03-02 16:06:48,055 - INFO - Step 2323 -- ðŸ”„ Training Metrics
2025-03-02 16:06:48,055 - INFO - â”œâ”€â”€ Loss: 6.5312
2025-03-02 16:06:48,056 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:06:48,056 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:06:48,723 - INFO - ðŸªœ Batch step - 2324 -- sub batch step 9296 -- lr 3.00e-04
2025-03-02 16:06:50,876 - INFO - ðŸªœ Batch step - 2324 -- sub batch step 9297 -- lr 3.00e-04
2025-03-02 16:06:53,023 - INFO - ðŸªœ Batch step - 2324 -- sub batch step 9298 -- lr 3.00e-04
2025-03-02 16:06:55,194 - INFO - ðŸªœ Batch step - 2324 -- sub batch step 9299 -- lr 3.00e-04
2025-03-02 16:06:56,740 - INFO - Step 2324 -- ðŸ”„ Training Metrics
2025-03-02 16:06:56,740 - INFO - â”œâ”€â”€ Loss: 6.5048
2025-03-02 16:06:56,740 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:06:56,740 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:06:57,412 - INFO - ðŸªœ Batch step - 2325 -- sub batch step 9300 -- lr 3.00e-04
2025-03-02 16:06:59,561 - INFO - ðŸªœ Batch step - 2325 -- sub batch step 9301 -- lr 3.00e-04
2025-03-02 16:07:01,711 - INFO - ðŸªœ Batch step - 2325 -- sub batch step 9302 -- lr 3.00e-04
2025-03-02 16:07:04,075 - INFO - ðŸªœ Batch step - 2325 -- sub batch step 9303 -- lr 3.00e-04
2025-03-02 16:07:06,201 - INFO - Step 2325 -- ðŸ”„ Training Metrics
2025-03-02 16:07:06,201 - INFO - â”œâ”€â”€ Loss: 6.5239
2025-03-02 16:07:06,202 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:07:06,202 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:07:06,875 - INFO - ðŸªœ Batch step - 2326 -- sub batch step 9304 -- lr 3.00e-04
2025-03-02 16:07:09,027 - INFO - ðŸªœ Batch step - 2326 -- sub batch step 9305 -- lr 3.00e-04
2025-03-02 16:07:11,172 - INFO - ðŸªœ Batch step - 2326 -- sub batch step 9306 -- lr 3.00e-04
2025-03-02 16:07:13,341 - INFO - ðŸªœ Batch step - 2326 -- sub batch step 9307 -- lr 3.00e-04
2025-03-02 16:07:14,889 - INFO - Step 2326 -- ðŸ”„ Training Metrics
2025-03-02 16:07:14,889 - INFO - â”œâ”€â”€ Loss: 6.5235
2025-03-02 16:07:14,889 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:07:14,889 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:07:15,555 - INFO - ðŸªœ Batch step - 2327 -- sub batch step 9308 -- lr 3.00e-04
2025-03-02 16:07:17,710 - INFO - ðŸªœ Batch step - 2327 -- sub batch step 9309 -- lr 3.00e-04
2025-03-02 16:07:19,862 - INFO - ðŸªœ Batch step - 2327 -- sub batch step 9310 -- lr 3.00e-04
2025-03-02 16:07:22,432 - INFO - ðŸªœ Batch step - 2327 -- sub batch step 9311 -- lr 3.00e-04
2025-03-02 16:07:25,186 - INFO - Step 2327 -- ðŸ”„ Training Metrics
2025-03-02 16:07:25,187 - INFO - â”œâ”€â”€ Loss: 6.5345
2025-03-02 16:07:25,187 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:07:25,187 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:07:25,859 - INFO - ðŸªœ Batch step - 2328 -- sub batch step 9312 -- lr 3.00e-04
2025-03-02 16:07:28,006 - INFO - ðŸªœ Batch step - 2328 -- sub batch step 9313 -- lr 3.00e-04
2025-03-02 16:07:30,157 - INFO - ðŸªœ Batch step - 2328 -- sub batch step 9314 -- lr 3.00e-04
2025-03-02 16:07:32,330 - INFO - ðŸªœ Batch step - 2328 -- sub batch step 9315 -- lr 3.00e-04
2025-03-02 16:07:33,882 - INFO - Step 2328 -- ðŸ”„ Training Metrics
2025-03-02 16:07:33,882 - INFO - â”œâ”€â”€ Loss: 6.5148
2025-03-02 16:07:33,882 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:07:33,882 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:07:34,553 - INFO - ðŸªœ Batch step - 2329 -- sub batch step 9316 -- lr 3.00e-04
2025-03-02 16:07:36,706 - INFO - ðŸªœ Batch step - 2329 -- sub batch step 9317 -- lr 3.00e-04
2025-03-02 16:07:38,851 - INFO - ðŸªœ Batch step - 2329 -- sub batch step 9318 -- lr 3.00e-04
2025-03-02 16:07:41,697 - INFO - ðŸªœ Batch step - 2329 -- sub batch step 9319 -- lr 3.00e-04
2025-03-02 16:07:43,197 - INFO - Step 2329 -- ðŸ”„ Training Metrics
2025-03-02 16:07:43,197 - INFO - â”œâ”€â”€ Loss: 6.5241
2025-03-02 16:07:43,198 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:07:43,198 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:07:43,871 - INFO - ðŸªœ Batch step - 2330 -- sub batch step 9320 -- lr 3.00e-04
2025-03-02 16:07:46,017 - INFO - ðŸªœ Batch step - 2330 -- sub batch step 9321 -- lr 3.00e-04
2025-03-02 16:07:48,169 - INFO - ðŸªœ Batch step - 2330 -- sub batch step 9322 -- lr 3.00e-04
2025-03-02 16:07:50,330 - INFO - ðŸªœ Batch step - 2330 -- sub batch step 9323 -- lr 3.00e-04
2025-03-02 16:07:51,881 - INFO - Step 2330 -- ðŸ”„ Training Metrics
2025-03-02 16:07:51,881 - INFO - â”œâ”€â”€ Loss: 6.5251
2025-03-02 16:07:51,882 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:07:51,882 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:07:52,553 - INFO - ðŸªœ Batch step - 2331 -- sub batch step 9324 -- lr 3.00e-04
2025-03-02 16:07:54,704 - INFO - ðŸªœ Batch step - 2331 -- sub batch step 9325 -- lr 3.00e-04
2025-03-02 16:07:57,415 - INFO - ðŸªœ Batch step - 2331 -- sub batch step 9326 -- lr 3.00e-04
2025-03-02 16:07:59,566 - INFO - ðŸªœ Batch step - 2331 -- sub batch step 9327 -- lr 3.00e-04
2025-03-02 16:08:01,094 - INFO - Step 2331 -- ðŸ”„ Training Metrics
2025-03-02 16:08:01,094 - INFO - â”œâ”€â”€ Loss: 6.5232
2025-03-02 16:08:01,094 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:08:01,094 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:08:01,764 - INFO - ðŸªœ Batch step - 2332 -- sub batch step 9328 -- lr 3.00e-04
2025-03-02 16:08:03,919 - INFO - ðŸªœ Batch step - 2332 -- sub batch step 9329 -- lr 3.00e-04
2025-03-02 16:08:06,086 - INFO - ðŸªœ Batch step - 2332 -- sub batch step 9330 -- lr 3.00e-04
2025-03-02 16:08:08,231 - INFO - ðŸªœ Batch step - 2332 -- sub batch step 9331 -- lr 3.00e-04
2025-03-02 16:08:09,777 - INFO - Step 2332 -- ðŸ”„ Training Metrics
2025-03-02 16:08:09,777 - INFO - â”œâ”€â”€ Loss: 6.5568
2025-03-02 16:08:09,777 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:08:09,778 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:08:10,452 - INFO - ðŸªœ Batch step - 2333 -- sub batch step 9332 -- lr 3.00e-04
2025-03-02 16:08:12,596 - INFO - ðŸªœ Batch step - 2333 -- sub batch step 9333 -- lr 3.00e-04
2025-03-02 16:08:15,361 - INFO - ðŸªœ Batch step - 2333 -- sub batch step 9334 -- lr 3.00e-04
2025-03-02 16:08:17,513 - INFO - ðŸªœ Batch step - 2333 -- sub batch step 9335 -- lr 3.00e-04
2025-03-02 16:08:19,033 - INFO - Step 2333 -- ðŸ”„ Training Metrics
2025-03-02 16:08:19,033 - INFO - â”œâ”€â”€ Loss: 6.5110
2025-03-02 16:08:19,033 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:08:19,033 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:08:19,703 - INFO - ðŸªœ Batch step - 2334 -- sub batch step 9336 -- lr 3.00e-04
2025-03-02 16:08:21,855 - INFO - ðŸªœ Batch step - 2334 -- sub batch step 9337 -- lr 3.00e-04
2025-03-02 16:08:24,017 - INFO - ðŸªœ Batch step - 2334 -- sub batch step 9338 -- lr 3.00e-04
2025-03-02 16:08:26,170 - INFO - ðŸªœ Batch step - 2334 -- sub batch step 9339 -- lr 3.00e-04
2025-03-02 16:08:27,726 - INFO - Step 2334 -- ðŸ”„ Training Metrics
2025-03-02 16:08:27,726 - INFO - â”œâ”€â”€ Loss: 6.5174
2025-03-02 16:08:27,726 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:08:27,727 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:08:28,402 - INFO - ðŸªœ Batch step - 2335 -- sub batch step 9340 -- lr 3.00e-04
2025-03-02 16:08:30,547 - INFO - ðŸªœ Batch step - 2335 -- sub batch step 9341 -- lr 3.00e-04
2025-03-02 16:08:33,326 - INFO - ðŸªœ Batch step - 2335 -- sub batch step 9342 -- lr 3.00e-04
2025-03-02 16:08:35,475 - INFO - ðŸªœ Batch step - 2335 -- sub batch step 9343 -- lr 3.00e-04
2025-03-02 16:08:36,966 - INFO - Step 2335 -- ðŸ”„ Training Metrics
2025-03-02 16:08:36,966 - INFO - â”œâ”€â”€ Loss: 6.5251
2025-03-02 16:08:36,966 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:08:36,966 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:08:37,638 - INFO - ðŸªœ Batch step - 2336 -- sub batch step 9344 -- lr 3.00e-04
2025-03-02 16:08:39,791 - INFO - ðŸªœ Batch step - 2336 -- sub batch step 9345 -- lr 3.00e-04
2025-03-02 16:08:41,951 - INFO - ðŸªœ Batch step - 2336 -- sub batch step 9346 -- lr 3.00e-04
2025-03-02 16:08:44,101 - INFO - ðŸªœ Batch step - 2336 -- sub batch step 9347 -- lr 3.00e-04
2025-03-02 16:08:45,669 - INFO - Step 2336 -- ðŸ”„ Training Metrics
2025-03-02 16:08:45,669 - INFO - â”œâ”€â”€ Loss: 6.5316
2025-03-02 16:08:45,669 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:08:45,669 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:08:46,337 - INFO - ðŸªœ Batch step - 2337 -- sub batch step 9348 -- lr 3.00e-04
2025-03-02 16:08:48,495 - INFO - ðŸªœ Batch step - 2337 -- sub batch step 9349 -- lr 3.00e-04
2025-03-02 16:08:51,618 - INFO - ðŸªœ Batch step - 2337 -- sub batch step 9350 -- lr 3.00e-04
2025-03-02 16:08:53,773 - INFO - ðŸªœ Batch step - 2337 -- sub batch step 9351 -- lr 3.00e-04
2025-03-02 16:08:55,263 - INFO - Step 2337 -- ðŸ”„ Training Metrics
2025-03-02 16:08:55,264 - INFO - â”œâ”€â”€ Loss: 6.5329
2025-03-02 16:08:55,264 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:08:55,264 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:08:55,938 - INFO - ðŸªœ Batch step - 2338 -- sub batch step 9352 -- lr 3.00e-04
2025-03-02 16:08:58,084 - INFO - ðŸªœ Batch step - 2338 -- sub batch step 9353 -- lr 3.00e-04
2025-03-02 16:09:00,249 - INFO - ðŸªœ Batch step - 2338 -- sub batch step 9354 -- lr 3.00e-04
2025-03-02 16:09:02,400 - INFO - ðŸªœ Batch step - 2338 -- sub batch step 9355 -- lr 3.00e-04
2025-03-02 16:09:03,961 - INFO - Step 2338 -- ðŸ”„ Training Metrics
2025-03-02 16:09:03,962 - INFO - â”œâ”€â”€ Loss: 6.5150
2025-03-02 16:09:03,962 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:09:03,962 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:09:04,629 - INFO - ðŸªœ Batch step - 2339 -- sub batch step 9356 -- lr 3.00e-04
2025-03-02 16:09:06,780 - INFO - ðŸªœ Batch step - 2339 -- sub batch step 9357 -- lr 3.00e-04
2025-03-02 16:09:09,057 - INFO - ðŸªœ Batch step - 2339 -- sub batch step 9358 -- lr 3.00e-04
2025-03-02 16:09:11,204 - INFO - ðŸªœ Batch step - 2339 -- sub batch step 9359 -- lr 3.00e-04
2025-03-02 16:09:12,855 - INFO - Step 2339 -- ðŸ”„ Training Metrics
2025-03-02 16:09:12,856 - INFO - â”œâ”€â”€ Loss: 6.5167
2025-03-02 16:09:12,856 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:09:12,856 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:09:13,876 - INFO - ðŸªœ Batch step - 2340 -- sub batch step 9360 -- lr 3.00e-04
2025-03-02 16:09:16,028 - INFO - ðŸªœ Batch step - 2340 -- sub batch step 9361 -- lr 3.00e-04
2025-03-02 16:09:18,188 - INFO - ðŸªœ Batch step - 2340 -- sub batch step 9362 -- lr 3.00e-04
2025-03-02 16:09:20,358 - INFO - ðŸªœ Batch step - 2340 -- sub batch step 9363 -- lr 3.00e-04
2025-03-02 16:09:22,132 - INFO - Step 2340 -- ðŸ”„ Training Metrics
2025-03-02 16:09:22,132 - INFO - â”œâ”€â”€ Loss: 6.5181
2025-03-02 16:09:22,132 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:09:22,133 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:09:22,812 - INFO - ðŸªœ Batch step - 2341 -- sub batch step 9364 -- lr 3.00e-04
2025-03-02 16:09:24,967 - INFO - ðŸªœ Batch step - 2341 -- sub batch step 9365 -- lr 3.00e-04
2025-03-02 16:09:27,119 - INFO - ðŸªœ Batch step - 2341 -- sub batch step 9366 -- lr 3.00e-04
2025-03-02 16:09:29,506 - INFO - ðŸªœ Batch step - 2341 -- sub batch step 9367 -- lr 3.00e-04
2025-03-02 16:09:31,254 - INFO - Step 2341 -- ðŸ”„ Training Metrics
2025-03-02 16:09:31,254 - INFO - â”œâ”€â”€ Loss: 6.4959
2025-03-02 16:09:31,255 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:09:31,255 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:09:31,924 - INFO - ðŸªœ Batch step - 2342 -- sub batch step 9368 -- lr 3.00e-04
2025-03-02 16:09:34,083 - INFO - ðŸªœ Batch step - 2342 -- sub batch step 9369 -- lr 3.00e-04
2025-03-02 16:09:36,237 - INFO - ðŸªœ Batch step - 2342 -- sub batch step 9370 -- lr 3.00e-04
2025-03-02 16:09:38,405 - INFO - ðŸªœ Batch step - 2342 -- sub batch step 9371 -- lr 3.00e-04
2025-03-02 16:09:39,962 - INFO - Step 2342 -- ðŸ”„ Training Metrics
2025-03-02 16:09:39,962 - INFO - â”œâ”€â”€ Loss: 6.5072
2025-03-02 16:09:39,962 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:09:39,963 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:09:40,637 - INFO - ðŸªœ Batch step - 2343 -- sub batch step 9372 -- lr 3.00e-04
2025-03-02 16:09:42,791 - INFO - ðŸªœ Batch step - 2343 -- sub batch step 9373 -- lr 3.00e-04
2025-03-02 16:09:44,952 - INFO - ðŸªœ Batch step - 2343 -- sub batch step 9374 -- lr 3.00e-04
2025-03-02 16:09:47,519 - INFO - ðŸªœ Batch step - 2343 -- sub batch step 9375 -- lr 3.00e-04
2025-03-02 16:09:49,312 - INFO - Step 2343 -- ðŸ”„ Training Metrics
2025-03-02 16:09:49,313 - INFO - â”œâ”€â”€ Loss: 6.5117
2025-03-02 16:09:49,313 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:09:49,313 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:09:49,984 - INFO - ðŸªœ Batch step - 2344 -- sub batch step 9376 -- lr 3.00e-04
2025-03-02 16:09:52,147 - INFO - ðŸªœ Batch step - 2344 -- sub batch step 9377 -- lr 3.00e-04
2025-03-02 16:09:54,299 - INFO - ðŸªœ Batch step - 2344 -- sub batch step 9378 -- lr 3.00e-04
2025-03-02 16:09:56,475 - INFO - ðŸªœ Batch step - 2344 -- sub batch step 9379 -- lr 3.00e-04
2025-03-02 16:09:58,011 - INFO - Step 2344 -- ðŸ”„ Training Metrics
2025-03-02 16:09:58,012 - INFO - â”œâ”€â”€ Loss: 6.5190
2025-03-02 16:09:58,012 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:09:58,012 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:09:58,690 - INFO - ðŸªœ Batch step - 2345 -- sub batch step 9380 -- lr 3.00e-04
2025-03-02 16:10:00,845 - INFO - ðŸªœ Batch step - 2345 -- sub batch step 9381 -- lr 3.00e-04
2025-03-02 16:10:03,000 - INFO - ðŸªœ Batch step - 2345 -- sub batch step 9382 -- lr 3.00e-04
2025-03-02 16:10:05,971 - INFO - ðŸªœ Batch step - 2345 -- sub batch step 9383 -- lr 3.00e-04
2025-03-02 16:10:07,462 - INFO - Step 2345 -- ðŸ”„ Training Metrics
2025-03-02 16:10:07,463 - INFO - â”œâ”€â”€ Loss: 6.5389
2025-03-02 16:10:07,463 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:10:07,463 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:10:08,140 - INFO - ðŸªœ Batch step - 2346 -- sub batch step 9384 -- lr 3.00e-04
2025-03-02 16:10:10,294 - INFO - ðŸªœ Batch step - 2346 -- sub batch step 9385 -- lr 3.00e-04
2025-03-02 16:10:12,445 - INFO - ðŸªœ Batch step - 2346 -- sub batch step 9386 -- lr 3.00e-04
2025-03-02 16:10:14,616 - INFO - ðŸªœ Batch step - 2346 -- sub batch step 9387 -- lr 3.00e-04
2025-03-02 16:10:16,164 - INFO - Step 2346 -- ðŸ”„ Training Metrics
2025-03-02 16:10:16,164 - INFO - â”œâ”€â”€ Loss: 6.4765
2025-03-02 16:10:16,164 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:10:16,165 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:10:16,834 - INFO - ðŸªœ Batch step - 2347 -- sub batch step 9388 -- lr 3.00e-04
2025-03-02 16:10:18,993 - INFO - ðŸªœ Batch step - 2347 -- sub batch step 9389 -- lr 3.00e-04
2025-03-02 16:10:21,147 - INFO - ðŸªœ Batch step - 2347 -- sub batch step 9390 -- lr 3.00e-04
2025-03-02 16:10:23,563 - INFO - ðŸªœ Batch step - 2347 -- sub batch step 9391 -- lr 3.00e-04
2025-03-02 16:10:25,343 - INFO - Step 2347 -- ðŸ”„ Training Metrics
2025-03-02 16:10:25,343 - INFO - â”œâ”€â”€ Loss: 6.5064
2025-03-02 16:10:25,343 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:10:25,343 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:10:26,021 - INFO - ðŸªœ Batch step - 2348 -- sub batch step 9392 -- lr 3.00e-04
2025-03-02 16:10:28,173 - INFO - ðŸªœ Batch step - 2348 -- sub batch step 9393 -- lr 3.00e-04
2025-03-02 16:10:30,332 - INFO - ðŸªœ Batch step - 2348 -- sub batch step 9394 -- lr 3.00e-04
2025-03-02 16:10:32,507 - INFO - ðŸªœ Batch step - 2348 -- sub batch step 9395 -- lr 3.00e-04
2025-03-02 16:10:34,047 - INFO - Step 2348 -- ðŸ”„ Training Metrics
2025-03-02 16:10:34,047 - INFO - â”œâ”€â”€ Loss: 6.5196
2025-03-02 16:10:34,048 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:10:34,048 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:10:34,716 - INFO - ðŸªœ Batch step - 2349 -- sub batch step 9396 -- lr 3.00e-04
2025-03-02 16:10:36,881 - INFO - ðŸªœ Batch step - 2349 -- sub batch step 9397 -- lr 3.00e-04
2025-03-02 16:10:39,031 - INFO - ðŸªœ Batch step - 2349 -- sub batch step 9398 -- lr 3.00e-04
2025-03-02 16:10:41,403 - INFO - ðŸªœ Batch step - 2349 -- sub batch step 9399 -- lr 3.00e-04
2025-03-02 16:10:43,231 - INFO - Step 2349 -- ðŸ”„ Training Metrics
2025-03-02 16:10:43,231 - INFO - â”œâ”€â”€ Loss: 6.5067
2025-03-02 16:10:43,231 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:10:43,231 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:10:43,909 - INFO - ðŸªœ Batch step - 2350 -- sub batch step 9400 -- lr 3.00e-04
2025-03-02 16:10:46,064 - INFO - ðŸªœ Batch step - 2350 -- sub batch step 9401 -- lr 3.00e-04
2025-03-02 16:10:48,219 - INFO - ðŸªœ Batch step - 2350 -- sub batch step 9402 -- lr 3.00e-04
2025-03-02 16:10:50,388 - INFO - ðŸªœ Batch step - 2350 -- sub batch step 9403 -- lr 3.00e-04
2025-03-02 16:10:51,943 - INFO - Step 2350 -- ðŸ”„ Training Metrics
2025-03-02 16:10:51,943 - INFO - â”œâ”€â”€ Loss: 6.5021
2025-03-02 16:10:51,943 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:10:51,943 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:10:52,620 - INFO - ðŸªœ Batch step - 2351 -- sub batch step 9404 -- lr 3.00e-04
2025-03-02 16:10:54,777 - INFO - ðŸªœ Batch step - 2351 -- sub batch step 9405 -- lr 3.00e-04
2025-03-02 16:10:57,132 - INFO - ðŸªœ Batch step - 2351 -- sub batch step 9406 -- lr 3.00e-04
2025-03-02 16:10:59,289 - INFO - ðŸªœ Batch step - 2351 -- sub batch step 9407 -- lr 3.00e-04
2025-03-02 16:11:01,092 - INFO - Step 2351 -- ðŸ”„ Training Metrics
2025-03-02 16:11:01,093 - INFO - â”œâ”€â”€ Loss: 6.5025
2025-03-02 16:11:01,093 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:11:01,093 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:11:01,760 - INFO - ðŸªœ Batch step - 2352 -- sub batch step 9408 -- lr 3.00e-04
2025-03-02 16:11:03,919 - INFO - ðŸªœ Batch step - 2352 -- sub batch step 9409 -- lr 3.00e-04
2025-03-02 16:11:06,097 - INFO - ðŸªœ Batch step - 2352 -- sub batch step 9410 -- lr 3.00e-04
2025-03-02 16:11:08,246 - INFO - ðŸªœ Batch step - 2352 -- sub batch step 9411 -- lr 3.00e-04
2025-03-02 16:11:09,797 - INFO - Step 2352 -- ðŸ”„ Training Metrics
2025-03-02 16:11:09,797 - INFO - â”œâ”€â”€ Loss: 6.5007
2025-03-02 16:11:09,798 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:11:09,798 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:11:10,471 - INFO - ðŸªœ Batch step - 2353 -- sub batch step 9412 -- lr 3.00e-04
2025-03-02 16:11:12,620 - INFO - ðŸªœ Batch step - 2353 -- sub batch step 9413 -- lr 3.00e-04
2025-03-02 16:11:15,010 - INFO - ðŸªœ Batch step - 2353 -- sub batch step 9414 -- lr 3.00e-04
2025-03-02 16:11:17,171 - INFO - ðŸªœ Batch step - 2353 -- sub batch step 9415 -- lr 3.00e-04
2025-03-02 16:11:18,942 - INFO - Step 2353 -- ðŸ”„ Training Metrics
2025-03-02 16:11:18,942 - INFO - â”œâ”€â”€ Loss: 6.5078
2025-03-02 16:11:18,942 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:11:18,942 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:11:19,619 - INFO - ðŸªœ Batch step - 2354 -- sub batch step 9416 -- lr 3.00e-04
2025-03-02 16:11:21,787 - INFO - ðŸªœ Batch step - 2354 -- sub batch step 9417 -- lr 3.00e-04
2025-03-02 16:11:23,959 - INFO - ðŸªœ Batch step - 2354 -- sub batch step 9418 -- lr 3.00e-04
2025-03-02 16:11:26,123 - INFO - ðŸªœ Batch step - 2354 -- sub batch step 9419 -- lr 3.00e-04
2025-03-02 16:11:27,650 - INFO - Step 2354 -- ðŸ”„ Training Metrics
2025-03-02 16:11:27,650 - INFO - â”œâ”€â”€ Loss: 6.4927
2025-03-02 16:11:27,650 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:11:27,650 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:11:28,334 - INFO - ðŸªœ Batch step - 2355 -- sub batch step 9420 -- lr 3.00e-04
2025-03-02 16:11:30,491 - INFO - ðŸªœ Batch step - 2355 -- sub batch step 9421 -- lr 3.00e-04
2025-03-02 16:11:33,127 - INFO - ðŸªœ Batch step - 2355 -- sub batch step 9422 -- lr 3.00e-04
2025-03-02 16:11:35,282 - INFO - ðŸªœ Batch step - 2355 -- sub batch step 9423 -- lr 3.00e-04
2025-03-02 16:11:36,823 - INFO - Step 2355 -- ðŸ”„ Training Metrics
2025-03-02 16:11:36,823 - INFO - â”œâ”€â”€ Loss: 6.5153
2025-03-02 16:11:36,823 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:11:36,824 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:11:37,500 - INFO - ðŸªœ Batch step - 2356 -- sub batch step 9424 -- lr 3.00e-04
2025-03-02 16:11:39,657 - INFO - ðŸªœ Batch step - 2356 -- sub batch step 9425 -- lr 3.00e-04
2025-03-02 16:11:41,826 - INFO - ðŸªœ Batch step - 2356 -- sub batch step 9426 -- lr 3.00e-04
2025-03-02 16:11:43,984 - INFO - ðŸªœ Batch step - 2356 -- sub batch step 9427 -- lr 3.00e-04
2025-03-02 16:11:45,534 - INFO - Step 2356 -- ðŸ”„ Training Metrics
2025-03-02 16:11:45,534 - INFO - â”œâ”€â”€ Loss: 6.5111
2025-03-02 16:11:45,534 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:11:45,535 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:11:46,205 - INFO - ðŸªœ Batch step - 2357 -- sub batch step 9428 -- lr 3.00e-04
2025-03-02 16:11:48,364 - INFO - ðŸªœ Batch step - 2357 -- sub batch step 9429 -- lr 3.00e-04
2025-03-02 16:11:50,750 - INFO - ðŸªœ Batch step - 2357 -- sub batch step 9430 -- lr 3.00e-04
2025-03-02 16:11:52,903 - INFO - ðŸªœ Batch step - 2357 -- sub batch step 9431 -- lr 3.00e-04
2025-03-02 16:11:54,753 - INFO - Step 2357 -- ðŸ”„ Training Metrics
2025-03-02 16:11:54,753 - INFO - â”œâ”€â”€ Loss: 6.5022
2025-03-02 16:11:54,753 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:11:54,754 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:11:55,427 - INFO - ðŸªœ Batch step - 2358 -- sub batch step 9432 -- lr 3.00e-04
2025-03-02 16:11:57,579 - INFO - ðŸªœ Batch step - 2358 -- sub batch step 9433 -- lr 3.00e-04
2025-03-02 16:11:59,760 - INFO - ðŸªœ Batch step - 2358 -- sub batch step 9434 -- lr 3.00e-04
2025-03-02 16:12:01,920 - INFO - ðŸªœ Batch step - 2358 -- sub batch step 9435 -- lr 3.00e-04
2025-03-02 16:12:03,477 - INFO - Step 2358 -- ðŸ”„ Training Metrics
2025-03-02 16:12:03,477 - INFO - â”œâ”€â”€ Loss: 6.4921
2025-03-02 16:12:03,477 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:12:03,477 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:12:04,151 - INFO - ðŸªœ Batch step - 2359 -- sub batch step 9436 -- lr 3.00e-04
2025-03-02 16:12:06,306 - INFO - ðŸªœ Batch step - 2359 -- sub batch step 9437 -- lr 3.00e-04
2025-03-02 16:12:08,577 - INFO - ðŸªœ Batch step - 2359 -- sub batch step 9438 -- lr 3.00e-04
2025-03-02 16:12:10,736 - INFO - ðŸªœ Batch step - 2359 -- sub batch step 9439 -- lr 3.00e-04
2025-03-02 16:12:12,296 - INFO - Step 2359 -- ðŸ”„ Training Metrics
2025-03-02 16:12:12,296 - INFO - â”œâ”€â”€ Loss: 6.5032
2025-03-02 16:12:12,296 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:12:12,297 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:12:13,426 - INFO - ðŸªœ Batch step - 2360 -- sub batch step 9440 -- lr 3.00e-04
2025-03-02 16:12:15,573 - INFO - ðŸªœ Batch step - 2360 -- sub batch step 9441 -- lr 3.00e-04
2025-03-02 16:12:17,729 - INFO - ðŸªœ Batch step - 2360 -- sub batch step 9442 -- lr 3.00e-04
2025-03-02 16:12:19,897 - INFO - ðŸªœ Batch step - 2360 -- sub batch step 9443 -- lr 3.00e-04
2025-03-02 16:12:21,572 - INFO - Step 2360 -- ðŸ”„ Training Metrics
2025-03-02 16:12:21,572 - INFO - â”œâ”€â”€ Loss: 6.4842
2025-03-02 16:12:21,572 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:12:21,572 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:12:22,247 - INFO - ðŸªœ Batch step - 2361 -- sub batch step 9444 -- lr 3.00e-04
2025-03-02 16:12:24,402 - INFO - ðŸªœ Batch step - 2361 -- sub batch step 9445 -- lr 3.00e-04
2025-03-02 16:12:26,549 - INFO - ðŸªœ Batch step - 2361 -- sub batch step 9446 -- lr 3.00e-04
2025-03-02 16:12:28,969 - INFO - ðŸªœ Batch step - 2361 -- sub batch step 9447 -- lr 3.00e-04
2025-03-02 16:12:30,841 - INFO - Step 2361 -- ðŸ”„ Training Metrics
2025-03-02 16:12:30,842 - INFO - â”œâ”€â”€ Loss: 6.5174
2025-03-02 16:12:30,842 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:12:30,842 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:12:31,512 - INFO - ðŸªœ Batch step - 2362 -- sub batch step 9448 -- lr 3.00e-04
2025-03-02 16:12:33,668 - INFO - ðŸªœ Batch step - 2362 -- sub batch step 9449 -- lr 3.00e-04
2025-03-02 16:12:35,823 - INFO - ðŸªœ Batch step - 2362 -- sub batch step 9450 -- lr 3.00e-04
2025-03-02 16:12:37,989 - INFO - ðŸªœ Batch step - 2362 -- sub batch step 9451 -- lr 3.00e-04
2025-03-02 16:12:39,532 - INFO - Step 2362 -- ðŸ”„ Training Metrics
2025-03-02 16:12:39,532 - INFO - â”œâ”€â”€ Loss: 6.4928
2025-03-02 16:12:39,532 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:12:39,532 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:12:40,205 - INFO - ðŸªœ Batch step - 2363 -- sub batch step 9452 -- lr 3.00e-04
2025-03-02 16:12:42,354 - INFO - ðŸªœ Batch step - 2363 -- sub batch step 9453 -- lr 3.00e-04
2025-03-02 16:12:44,510 - INFO - ðŸªœ Batch step - 2363 -- sub batch step 9454 -- lr 3.00e-04
2025-03-02 16:12:47,127 - INFO - ðŸªœ Batch step - 2363 -- sub batch step 9455 -- lr 3.00e-04
2025-03-02 16:12:51,063 - INFO - Step 2363 -- ðŸ”„ Training Metrics
2025-03-02 16:12:51,063 - INFO - â”œâ”€â”€ Loss: 6.5103
2025-03-02 16:12:51,064 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:12:51,064 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:12:51,733 - INFO - ðŸªœ Batch step - 2364 -- sub batch step 9456 -- lr 3.00e-04
2025-03-02 16:12:53,891 - INFO - ðŸªœ Batch step - 2364 -- sub batch step 9457 -- lr 3.00e-04
2025-03-02 16:12:56,042 - INFO - ðŸªœ Batch step - 2364 -- sub batch step 9458 -- lr 3.00e-04
2025-03-02 16:12:58,215 - INFO - ðŸªœ Batch step - 2364 -- sub batch step 9459 -- lr 3.00e-04
2025-03-02 16:12:59,754 - INFO - Step 2364 -- ðŸ”„ Training Metrics
2025-03-02 16:12:59,754 - INFO - â”œâ”€â”€ Loss: 6.5126
2025-03-02 16:12:59,754 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:12:59,754 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:13:00,432 - INFO - ðŸªœ Batch step - 2365 -- sub batch step 9460 -- lr 3.00e-04
2025-03-02 16:13:02,585 - INFO - ðŸªœ Batch step - 2365 -- sub batch step 9461 -- lr 3.00e-04
2025-03-02 16:13:04,740 - INFO - ðŸªœ Batch step - 2365 -- sub batch step 9462 -- lr 3.00e-04
2025-03-02 16:13:07,214 - INFO - ðŸªœ Batch step - 2365 -- sub batch step 9463 -- lr 3.00e-04
2025-03-02 16:13:08,819 - INFO - Step 2365 -- ðŸ”„ Training Metrics
2025-03-02 16:13:08,819 - INFO - â”œâ”€â”€ Loss: 6.4882
2025-03-02 16:13:08,819 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:13:08,819 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:13:09,496 - INFO - ðŸªœ Batch step - 2366 -- sub batch step 9464 -- lr 3.00e-04
2025-03-02 16:13:11,652 - INFO - ðŸªœ Batch step - 2366 -- sub batch step 9465 -- lr 3.00e-04
2025-03-02 16:13:13,802 - INFO - ðŸªœ Batch step - 2366 -- sub batch step 9466 -- lr 3.00e-04
2025-03-02 16:13:15,973 - INFO - ðŸªœ Batch step - 2366 -- sub batch step 9467 -- lr 3.00e-04
2025-03-02 16:13:17,520 - INFO - Step 2366 -- ðŸ”„ Training Metrics
2025-03-02 16:13:17,520 - INFO - â”œâ”€â”€ Loss: 6.4912
2025-03-02 16:13:17,520 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:13:17,520 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:13:18,191 - INFO - ðŸªœ Batch step - 2367 -- sub batch step 9468 -- lr 3.00e-04
2025-03-02 16:13:20,349 - INFO - ðŸªœ Batch step - 2367 -- sub batch step 9469 -- lr 3.00e-04
2025-03-02 16:13:22,505 - INFO - ðŸªœ Batch step - 2367 -- sub batch step 9470 -- lr 3.00e-04
2025-03-02 16:13:25,032 - INFO - ðŸªœ Batch step - 2367 -- sub batch step 9471 -- lr 3.00e-04
2025-03-02 16:13:26,710 - INFO - Step 2367 -- ðŸ”„ Training Metrics
2025-03-02 16:13:26,710 - INFO - â”œâ”€â”€ Loss: 6.5098
2025-03-02 16:13:26,711 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:13:26,711 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:13:27,385 - INFO - ðŸªœ Batch step - 2368 -- sub batch step 9472 -- lr 3.00e-04
2025-03-02 16:13:29,533 - INFO - ðŸªœ Batch step - 2368 -- sub batch step 9473 -- lr 3.00e-04
2025-03-02 16:13:31,689 - INFO - ðŸªœ Batch step - 2368 -- sub batch step 9474 -- lr 3.00e-04
2025-03-02 16:13:33,860 - INFO - ðŸªœ Batch step - 2368 -- sub batch step 9475 -- lr 3.00e-04
2025-03-02 16:13:35,404 - INFO - Step 2368 -- ðŸ”„ Training Metrics
2025-03-02 16:13:35,405 - INFO - â”œâ”€â”€ Loss: 6.4791
2025-03-02 16:13:35,405 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:13:35,405 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:13:36,075 - INFO - ðŸªœ Batch step - 2369 -- sub batch step 9476 -- lr 3.00e-04
2025-03-02 16:13:38,234 - INFO - ðŸªœ Batch step - 2369 -- sub batch step 9477 -- lr 3.00e-04
2025-03-02 16:13:40,381 - INFO - ðŸªœ Batch step - 2369 -- sub batch step 9478 -- lr 3.00e-04
2025-03-02 16:13:42,951 - INFO - ðŸªœ Batch step - 2369 -- sub batch step 9479 -- lr 3.00e-04
2025-03-02 16:13:44,546 - INFO - Step 2369 -- ðŸ”„ Training Metrics
2025-03-02 16:13:44,546 - INFO - â”œâ”€â”€ Loss: 6.4972
2025-03-02 16:13:44,546 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:13:44,546 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:13:45,221 - INFO - ðŸªœ Batch step - 2370 -- sub batch step 9480 -- lr 3.00e-04
2025-03-02 16:13:47,370 - INFO - ðŸªœ Batch step - 2370 -- sub batch step 9481 -- lr 3.00e-04
2025-03-02 16:13:49,524 - INFO - ðŸªœ Batch step - 2370 -- sub batch step 9482 -- lr 3.00e-04
2025-03-02 16:13:51,688 - INFO - ðŸªœ Batch step - 2370 -- sub batch step 9483 -- lr 3.00e-04
2025-03-02 16:13:53,225 - INFO - Step 2370 -- ðŸ”„ Training Metrics
2025-03-02 16:13:53,225 - INFO - â”œâ”€â”€ Loss: 6.5040
2025-03-02 16:13:53,226 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:13:53,226 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:13:53,899 - INFO - ðŸªœ Batch step - 2371 -- sub batch step 9484 -- lr 3.00e-04
2025-03-02 16:13:56,056 - INFO - ðŸªœ Batch step - 2371 -- sub batch step 9485 -- lr 3.00e-04
2025-03-02 16:13:58,604 - INFO - ðŸªœ Batch step - 2371 -- sub batch step 9486 -- lr 3.00e-04
2025-03-02 16:14:00,763 - INFO - ðŸªœ Batch step - 2371 -- sub batch step 9487 -- lr 3.00e-04
2025-03-02 16:14:02,255 - INFO - Step 2371 -- ðŸ”„ Training Metrics
2025-03-02 16:14:02,255 - INFO - â”œâ”€â”€ Loss: 6.4936
2025-03-02 16:14:02,255 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:14:02,255 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:14:02,924 - INFO - ðŸªœ Batch step - 2372 -- sub batch step 9488 -- lr 3.00e-04
2025-03-02 16:14:05,082 - INFO - ðŸªœ Batch step - 2372 -- sub batch step 9489 -- lr 3.00e-04
2025-03-02 16:14:07,255 - INFO - ðŸªœ Batch step - 2372 -- sub batch step 9490 -- lr 3.00e-04
2025-03-02 16:14:09,404 - INFO - ðŸªœ Batch step - 2372 -- sub batch step 9491 -- lr 3.00e-04
2025-03-02 16:14:10,959 - INFO - Step 2372 -- ðŸ”„ Training Metrics
2025-03-02 16:14:10,959 - INFO - â”œâ”€â”€ Loss: 6.4797
2025-03-02 16:14:10,959 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:14:10,959 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:14:11,633 - INFO - ðŸªœ Batch step - 2373 -- sub batch step 9492 -- lr 3.00e-04
2025-03-02 16:14:13,785 - INFO - ðŸªœ Batch step - 2373 -- sub batch step 9493 -- lr 3.00e-04
2025-03-02 16:14:16,337 - INFO - ðŸªœ Batch step - 2373 -- sub batch step 9494 -- lr 3.00e-04
2025-03-02 16:14:18,492 - INFO - ðŸªœ Batch step - 2373 -- sub batch step 9495 -- lr 3.00e-04
2025-03-02 16:14:26,433 - INFO - Step 2373 -- ðŸ”„ Training Metrics
2025-03-02 16:14:26,433 - INFO - â”œâ”€â”€ Loss: 6.5177
2025-03-02 16:14:26,433 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:14:26,434 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:14:27,102 - INFO - ðŸªœ Batch step - 2374 -- sub batch step 9496 -- lr 3.00e-04
2025-03-02 16:14:29,256 - INFO - ðŸªœ Batch step - 2374 -- sub batch step 9497 -- lr 3.00e-04
2025-03-02 16:14:31,425 - INFO - ðŸªœ Batch step - 2374 -- sub batch step 9498 -- lr 3.00e-04
2025-03-02 16:14:33,584 - INFO - ðŸªœ Batch step - 2374 -- sub batch step 9499 -- lr 3.00e-04
2025-03-02 16:14:35,118 - INFO - Step 2374 -- ðŸ”„ Training Metrics
2025-03-02 16:14:35,118 - INFO - â”œâ”€â”€ Loss: 6.4826
2025-03-02 16:14:35,119 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:14:35,119 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:14:35,792 - INFO - ðŸªœ Batch step - 2375 -- sub batch step 9500 -- lr 3.00e-04
2025-03-02 16:14:37,943 - INFO - ðŸªœ Batch step - 2375 -- sub batch step 9501 -- lr 3.00e-04
2025-03-02 16:14:40,419 - INFO - ðŸªœ Batch step - 2375 -- sub batch step 9502 -- lr 3.00e-04
2025-03-02 16:14:42,572 - INFO - ðŸªœ Batch step - 2375 -- sub batch step 9503 -- lr 3.00e-04
2025-03-02 16:14:50,191 - INFO - Step 2375 -- ðŸ”„ Training Metrics
2025-03-02 16:14:50,191 - INFO - â”œâ”€â”€ Loss: 6.4914
2025-03-02 16:14:50,191 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:14:50,192 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:14:50,867 - INFO - ðŸªœ Batch step - 2376 -- sub batch step 9504 -- lr 3.00e-04
2025-03-02 16:14:53,022 - INFO - ðŸªœ Batch step - 2376 -- sub batch step 9505 -- lr 3.00e-04
2025-03-02 16:14:55,190 - INFO - ðŸªœ Batch step - 2376 -- sub batch step 9506 -- lr 3.00e-04
2025-03-02 16:14:57,349 - INFO - ðŸªœ Batch step - 2376 -- sub batch step 9507 -- lr 3.00e-04
2025-03-02 16:14:58,885 - INFO - Step 2376 -- ðŸ”„ Training Metrics
2025-03-02 16:14:58,885 - INFO - â”œâ”€â”€ Loss: 6.4704
2025-03-02 16:14:58,885 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:14:58,885 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:14:59,553 - INFO - ðŸªœ Batch step - 2377 -- sub batch step 9508 -- lr 3.00e-04
2025-03-02 16:15:01,713 - INFO - ðŸªœ Batch step - 2377 -- sub batch step 9509 -- lr 3.00e-04
2025-03-02 16:15:04,192 - INFO - ðŸªœ Batch step - 2377 -- sub batch step 9510 -- lr 3.00e-04
2025-03-02 16:15:06,340 - INFO - ðŸªœ Batch step - 2377 -- sub batch step 9511 -- lr 3.00e-04
2025-03-02 16:15:08,047 - INFO - Step 2377 -- ðŸ”„ Training Metrics
2025-03-02 16:15:08,048 - INFO - â”œâ”€â”€ Loss: 6.4812
2025-03-02 16:15:08,048 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:15:08,048 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:15:08,720 - INFO - ðŸªœ Batch step - 2378 -- sub batch step 9512 -- lr 3.00e-04
2025-03-02 16:15:10,873 - INFO - ðŸªœ Batch step - 2378 -- sub batch step 9513 -- lr 3.00e-04
2025-03-02 16:15:13,046 - INFO - ðŸªœ Batch step - 2378 -- sub batch step 9514 -- lr 3.00e-04
2025-03-02 16:15:15,198 - INFO - ðŸªœ Batch step - 2378 -- sub batch step 9515 -- lr 3.00e-04
2025-03-02 16:15:16,738 - INFO - Step 2378 -- ðŸ”„ Training Metrics
2025-03-02 16:15:16,738 - INFO - â”œâ”€â”€ Loss: 6.4673
2025-03-02 16:15:16,738 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:15:16,738 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:15:17,405 - INFO - ðŸªœ Batch step - 2379 -- sub batch step 9516 -- lr 3.00e-04
2025-03-02 16:15:19,559 - INFO - ðŸªœ Batch step - 2379 -- sub batch step 9517 -- lr 3.00e-04
2025-03-02 16:15:21,842 - INFO - ðŸªœ Batch step - 2379 -- sub batch step 9518 -- lr 3.00e-04
2025-03-02 16:15:24,002 - INFO - ðŸªœ Batch step - 2379 -- sub batch step 9519 -- lr 3.00e-04
2025-03-02 16:15:25,915 - INFO - Step 2379 -- ðŸ”„ Training Metrics
2025-03-02 16:15:25,915 - INFO - â”œâ”€â”€ Loss: 6.4823
2025-03-02 16:15:25,916 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:15:25,916 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:15:27,074 - INFO - ðŸªœ Batch step - 2380 -- sub batch step 9520 -- lr 3.00e-04
2025-03-02 16:15:29,229 - INFO - ðŸªœ Batch step - 2380 -- sub batch step 9521 -- lr 3.00e-04
2025-03-02 16:15:31,388 - INFO - ðŸªœ Batch step - 2380 -- sub batch step 9522 -- lr 3.00e-04
2025-03-02 16:15:33,565 - INFO - ðŸªœ Batch step - 2380 -- sub batch step 9523 -- lr 3.00e-04
2025-03-02 16:15:35,202 - INFO - Step 2380 -- ðŸ”„ Training Metrics
2025-03-02 16:15:35,203 - INFO - â”œâ”€â”€ Loss: 6.4795
2025-03-02 16:15:35,203 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:15:35,203 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:15:35,882 - INFO - ðŸªœ Batch step - 2381 -- sub batch step 9524 -- lr 3.00e-04
2025-03-02 16:15:38,042 - INFO - ðŸªœ Batch step - 2381 -- sub batch step 9525 -- lr 3.00e-04
2025-03-02 16:15:40,189 - INFO - ðŸªœ Batch step - 2381 -- sub batch step 9526 -- lr 3.00e-04
2025-03-02 16:15:42,634 - INFO - ðŸªœ Batch step - 2381 -- sub batch step 9527 -- lr 3.00e-04
2025-03-02 16:15:44,471 - INFO - Step 2381 -- ðŸ”„ Training Metrics
2025-03-02 16:15:44,471 - INFO - â”œâ”€â”€ Loss: 6.4851
2025-03-02 16:15:44,471 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:15:44,471 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:15:45,140 - INFO - ðŸªœ Batch step - 2382 -- sub batch step 9528 -- lr 3.00e-04
2025-03-02 16:15:47,297 - INFO - ðŸªœ Batch step - 2382 -- sub batch step 9529 -- lr 3.00e-04
2025-03-02 16:15:49,450 - INFO - ðŸªœ Batch step - 2382 -- sub batch step 9530 -- lr 3.00e-04
2025-03-02 16:15:51,615 - INFO - ðŸªœ Batch step - 2382 -- sub batch step 9531 -- lr 3.00e-04
2025-03-02 16:15:53,169 - INFO - Step 2382 -- ðŸ”„ Training Metrics
2025-03-02 16:15:53,169 - INFO - â”œâ”€â”€ Loss: 6.4783
2025-03-02 16:15:53,170 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:15:53,170 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:15:53,847 - INFO - ðŸªœ Batch step - 2383 -- sub batch step 9532 -- lr 3.00e-04
2025-03-02 16:15:55,996 - INFO - ðŸªœ Batch step - 2383 -- sub batch step 9533 -- lr 3.00e-04
2025-03-02 16:15:58,147 - INFO - ðŸªœ Batch step - 2383 -- sub batch step 9534 -- lr 3.00e-04
2025-03-02 16:16:00,611 - INFO - ðŸªœ Batch step - 2383 -- sub batch step 9535 -- lr 3.00e-04
2025-03-02 16:16:02,501 - INFO - Step 2383 -- ðŸ”„ Training Metrics
2025-03-02 16:16:02,502 - INFO - â”œâ”€â”€ Loss: 6.4708
2025-03-02 16:16:02,502 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:16:02,502 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:16:03,173 - INFO - ðŸªœ Batch step - 2384 -- sub batch step 9536 -- lr 3.00e-04
2025-03-02 16:16:05,325 - INFO - ðŸªœ Batch step - 2384 -- sub batch step 9537 -- lr 3.00e-04
2025-03-02 16:16:07,472 - INFO - ðŸªœ Batch step - 2384 -- sub batch step 9538 -- lr 3.00e-04
2025-03-02 16:16:09,647 - INFO - ðŸªœ Batch step - 2384 -- sub batch step 9539 -- lr 3.00e-04
2025-03-02 16:16:11,195 - INFO - Step 2384 -- ðŸ”„ Training Metrics
2025-03-02 16:16:11,195 - INFO - â”œâ”€â”€ Loss: 6.5050
2025-03-02 16:16:11,195 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:16:11,195 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:16:11,872 - INFO - ðŸªœ Batch step - 2385 -- sub batch step 9540 -- lr 3.00e-04
2025-03-02 16:16:14,024 - INFO - ðŸªœ Batch step - 2385 -- sub batch step 9541 -- lr 3.00e-04
2025-03-02 16:16:16,179 - INFO - ðŸªœ Batch step - 2385 -- sub batch step 9542 -- lr 3.00e-04
2025-03-02 16:16:18,598 - INFO - ðŸªœ Batch step - 2385 -- sub batch step 9543 -- lr 3.00e-04
2025-03-02 16:16:20,293 - INFO - Step 2385 -- ðŸ”„ Training Metrics
2025-03-02 16:16:20,294 - INFO - â”œâ”€â”€ Loss: 6.4785
2025-03-02 16:16:20,294 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:16:20,294 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:16:20,969 - INFO - ðŸªœ Batch step - 2386 -- sub batch step 9544 -- lr 3.00e-04
2025-03-02 16:16:23,121 - INFO - ðŸªœ Batch step - 2386 -- sub batch step 9545 -- lr 3.00e-04
2025-03-02 16:16:25,269 - INFO - ðŸªœ Batch step - 2386 -- sub batch step 9546 -- lr 3.00e-04
2025-03-02 16:16:27,437 - INFO - ðŸªœ Batch step - 2386 -- sub batch step 9547 -- lr 3.00e-04
2025-03-02 16:16:28,985 - INFO - Step 2386 -- ðŸ”„ Training Metrics
2025-03-02 16:16:28,985 - INFO - â”œâ”€â”€ Loss: 6.4739
2025-03-02 16:16:28,985 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:16:28,985 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:16:29,656 - INFO - ðŸªœ Batch step - 2387 -- sub batch step 9548 -- lr 3.00e-04
2025-03-02 16:16:31,811 - INFO - ðŸªœ Batch step - 2387 -- sub batch step 9549 -- lr 3.00e-04
2025-03-02 16:16:33,967 - INFO - ðŸªœ Batch step - 2387 -- sub batch step 9550 -- lr 3.00e-04
2025-03-02 16:16:38,654 - INFO - ðŸªœ Batch step - 2387 -- sub batch step 9551 -- lr 3.00e-04
2025-03-02 16:16:40,146 - INFO - Step 2387 -- ðŸ”„ Training Metrics
2025-03-02 16:16:40,147 - INFO - â”œâ”€â”€ Loss: 6.4728
2025-03-02 16:16:40,147 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:16:40,147 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:16:40,820 - INFO - ðŸªœ Batch step - 2388 -- sub batch step 9552 -- lr 3.00e-04
2025-03-02 16:16:42,969 - INFO - ðŸªœ Batch step - 2388 -- sub batch step 9553 -- lr 3.00e-04
2025-03-02 16:16:45,125 - INFO - ðŸªœ Batch step - 2388 -- sub batch step 9554 -- lr 3.00e-04
2025-03-02 16:16:47,299 - INFO - ðŸªœ Batch step - 2388 -- sub batch step 9555 -- lr 3.00e-04
2025-03-02 16:16:48,849 - INFO - Step 2388 -- ðŸ”„ Training Metrics
2025-03-02 16:16:48,849 - INFO - â”œâ”€â”€ Loss: 6.4728
2025-03-02 16:16:48,849 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:16:48,849 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:16:49,518 - INFO - ðŸªœ Batch step - 2389 -- sub batch step 9556 -- lr 3.00e-04
2025-03-02 16:16:51,674 - INFO - ðŸªœ Batch step - 2389 -- sub batch step 9557 -- lr 3.00e-04
2025-03-02 16:16:53,823 - INFO - ðŸªœ Batch step - 2389 -- sub batch step 9558 -- lr 3.00e-04
2025-03-02 16:16:56,433 - INFO - ðŸªœ Batch step - 2389 -- sub batch step 9559 -- lr 3.00e-04
2025-03-02 16:16:58,054 - INFO - Step 2389 -- ðŸ”„ Training Metrics
2025-03-02 16:16:58,054 - INFO - â”œâ”€â”€ Loss: 6.4985
2025-03-02 16:16:58,054 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:16:58,055 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:16:58,727 - INFO - ðŸªœ Batch step - 2390 -- sub batch step 9560 -- lr 3.00e-04
2025-03-02 16:17:00,875 - INFO - ðŸªœ Batch step - 2390 -- sub batch step 9561 -- lr 3.00e-04
2025-03-02 16:17:03,031 - INFO - ðŸªœ Batch step - 2390 -- sub batch step 9562 -- lr 3.00e-04
2025-03-02 16:17:05,199 - INFO - ðŸªœ Batch step - 2390 -- sub batch step 9563 -- lr 3.00e-04
2025-03-02 16:17:06,744 - INFO - Step 2390 -- ðŸ”„ Training Metrics
2025-03-02 16:17:06,744 - INFO - â”œâ”€â”€ Loss: 6.4984
2025-03-02 16:17:06,744 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:17:06,744 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:17:07,420 - INFO - ðŸªœ Batch step - 2391 -- sub batch step 9564 -- lr 3.00e-04
2025-03-02 16:17:09,576 - INFO - ðŸªœ Batch step - 2391 -- sub batch step 9565 -- lr 3.00e-04
2025-03-02 16:17:12,835 - INFO - ðŸªœ Batch step - 2391 -- sub batch step 9566 -- lr 3.00e-04
2025-03-02 16:17:15,003 - INFO - ðŸªœ Batch step - 2391 -- sub batch step 9567 -- lr 3.00e-04
2025-03-02 16:17:16,633 - INFO - Step 2391 -- ðŸ”„ Training Metrics
2025-03-02 16:17:16,633 - INFO - â”œâ”€â”€ Loss: 6.4785
2025-03-02 16:17:16,633 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:17:16,633 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:17:17,309 - INFO - ðŸªœ Batch step - 2392 -- sub batch step 9568 -- lr 3.00e-04
2025-03-02 16:17:19,472 - INFO - ðŸªœ Batch step - 2392 -- sub batch step 9569 -- lr 3.00e-04
2025-03-02 16:17:21,650 - INFO - ðŸªœ Batch step - 2392 -- sub batch step 9570 -- lr 3.00e-04
2025-03-02 16:17:23,803 - INFO - ðŸªœ Batch step - 2392 -- sub batch step 9571 -- lr 3.00e-04
2025-03-02 16:17:25,331 - INFO - Step 2392 -- ðŸ”„ Training Metrics
2025-03-02 16:17:25,331 - INFO - â”œâ”€â”€ Loss: 6.4756
2025-03-02 16:17:25,331 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:17:25,331 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:17:26,012 - INFO - ðŸªœ Batch step - 2393 -- sub batch step 9572 -- lr 3.00e-04
2025-03-02 16:17:28,166 - INFO - ðŸªœ Batch step - 2393 -- sub batch step 9573 -- lr 3.00e-04
2025-03-02 16:17:30,622 - INFO - ðŸªœ Batch step - 2393 -- sub batch step 9574 -- lr 3.00e-04
2025-03-02 16:17:32,787 - INFO - ðŸªœ Batch step - 2393 -- sub batch step 9575 -- lr 3.00e-04
2025-03-02 16:17:34,448 - INFO - Step 2393 -- ðŸ”„ Training Metrics
2025-03-02 16:17:34,448 - INFO - â”œâ”€â”€ Loss: 6.4768
2025-03-02 16:17:34,448 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:17:34,448 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:17:35,118 - INFO - ðŸªœ Batch step - 2394 -- sub batch step 9576 -- lr 3.00e-04
2025-03-02 16:17:37,273 - INFO - ðŸªœ Batch step - 2394 -- sub batch step 9577 -- lr 3.00e-04
2025-03-02 16:17:39,439 - INFO - ðŸªœ Batch step - 2394 -- sub batch step 9578 -- lr 3.00e-04
2025-03-02 16:17:41,593 - INFO - ðŸªœ Batch step - 2394 -- sub batch step 9579 -- lr 3.00e-04
2025-03-02 16:17:43,134 - INFO - Step 2394 -- ðŸ”„ Training Metrics
2025-03-02 16:17:43,134 - INFO - â”œâ”€â”€ Loss: 6.4540
2025-03-02 16:17:43,134 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:17:43,134 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:17:43,810 - INFO - ðŸªœ Batch step - 2395 -- sub batch step 9580 -- lr 3.00e-04
2025-03-02 16:17:45,961 - INFO - ðŸªœ Batch step - 2395 -- sub batch step 9581 -- lr 3.00e-04
2025-03-02 16:17:48,620 - INFO - ðŸªœ Batch step - 2395 -- sub batch step 9582 -- lr 3.00e-04
2025-03-02 16:17:50,773 - INFO - ðŸªœ Batch step - 2395 -- sub batch step 9583 -- lr 3.00e-04
2025-03-02 16:17:57,352 - INFO - Step 2395 -- ðŸ”„ Training Metrics
2025-03-02 16:17:57,353 - INFO - â”œâ”€â”€ Loss: 6.4981
2025-03-02 16:17:57,353 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:17:57,353 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:17:58,028 - INFO - ðŸªœ Batch step - 2396 -- sub batch step 9584 -- lr 3.00e-04
2025-03-02 16:18:00,183 - INFO - ðŸªœ Batch step - 2396 -- sub batch step 9585 -- lr 3.00e-04
2025-03-02 16:18:02,346 - INFO - ðŸªœ Batch step - 2396 -- sub batch step 9586 -- lr 3.00e-04
2025-03-02 16:18:04,502 - INFO - ðŸªœ Batch step - 2396 -- sub batch step 9587 -- lr 3.00e-04
2025-03-02 16:18:06,043 - INFO - Step 2396 -- ðŸ”„ Training Metrics
2025-03-02 16:18:06,043 - INFO - â”œâ”€â”€ Loss: 6.4675
2025-03-02 16:18:06,043 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:18:06,043 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:18:06,713 - INFO - ðŸªœ Batch step - 2397 -- sub batch step 9588 -- lr 3.00e-04
2025-03-02 16:18:08,870 - INFO - ðŸªœ Batch step - 2397 -- sub batch step 9589 -- lr 3.00e-04
2025-03-02 16:18:11,521 - INFO - ðŸªœ Batch step - 2397 -- sub batch step 9590 -- lr 3.00e-04
2025-03-02 16:18:13,672 - INFO - ðŸªœ Batch step - 2397 -- sub batch step 9591 -- lr 3.00e-04
2025-03-02 16:18:15,254 - INFO - Step 2397 -- ðŸ”„ Training Metrics
2025-03-02 16:18:15,254 - INFO - â”œâ”€â”€ Loss: 6.4742
2025-03-02 16:18:15,255 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:18:15,255 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:18:15,931 - INFO - ðŸªœ Batch step - 2398 -- sub batch step 9592 -- lr 3.00e-04
2025-03-02 16:18:18,078 - INFO - ðŸªœ Batch step - 2398 -- sub batch step 9593 -- lr 3.00e-04
2025-03-02 16:18:20,251 - INFO - ðŸªœ Batch step - 2398 -- sub batch step 9594 -- lr 3.00e-04
2025-03-02 16:18:22,407 - INFO - ðŸªœ Batch step - 2398 -- sub batch step 9595 -- lr 3.00e-04
2025-03-02 16:18:23,952 - INFO - Step 2398 -- ðŸ”„ Training Metrics
2025-03-02 16:18:23,953 - INFO - â”œâ”€â”€ Loss: 6.4712
2025-03-02 16:18:23,953 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:18:23,953 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:18:24,622 - INFO - ðŸªœ Batch step - 2399 -- sub batch step 9596 -- lr 3.00e-04
2025-03-02 16:18:26,780 - INFO - ðŸªœ Batch step - 2399 -- sub batch step 9597 -- lr 3.00e-04
2025-03-02 16:18:29,058 - INFO - ðŸªœ Batch step - 2399 -- sub batch step 9598 -- lr 3.00e-04
2025-03-02 16:18:31,211 - INFO - ðŸªœ Batch step - 2399 -- sub batch step 9599 -- lr 3.00e-04
2025-03-02 16:18:32,803 - INFO - Step 2399 -- ðŸ”„ Training Metrics
2025-03-02 16:18:32,803 - INFO - â”œâ”€â”€ Loss: 6.4572
2025-03-02 16:18:32,803 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:18:32,803 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:18:33,954 - INFO - ðŸªœ Batch step - 2400 -- sub batch step 9600 -- lr 3.00e-04
2025-03-02 16:18:36,109 - INFO - ðŸªœ Batch step - 2400 -- sub batch step 9601 -- lr 3.00e-04
2025-03-02 16:18:38,267 - INFO - ðŸªœ Batch step - 2400 -- sub batch step 9602 -- lr 3.00e-04
2025-03-02 16:18:40,441 - INFO - ðŸªœ Batch step - 2400 -- sub batch step 9603 -- lr 3.00e-04
2025-03-02 16:18:42,048 - INFO - Step 2400 -- ðŸ”„ Training Metrics
2025-03-02 16:18:42,048 - INFO - â”œâ”€â”€ Loss: 6.4945
2025-03-02 16:18:42,048 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:18:42,048 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:18:42,725 - INFO - ðŸªœ Batch step - 2401 -- sub batch step 9604 -- lr 3.00e-04
2025-03-02 16:18:44,881 - INFO - ðŸªœ Batch step - 2401 -- sub batch step 9605 -- lr 3.00e-04
2025-03-02 16:18:47,032 - INFO - ðŸªœ Batch step - 2401 -- sub batch step 9606 -- lr 3.00e-04
2025-03-02 16:18:49,692 - INFO - ðŸªœ Batch step - 2401 -- sub batch step 9607 -- lr 3.00e-04
2025-03-02 16:18:51,184 - INFO - Step 2401 -- ðŸ”„ Training Metrics
2025-03-02 16:18:51,185 - INFO - â”œâ”€â”€ Loss: 6.4578
2025-03-02 16:18:51,185 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:18:51,185 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:18:51,853 - INFO - ðŸªœ Batch step - 2402 -- sub batch step 9608 -- lr 3.00e-04
2025-03-02 16:18:54,015 - INFO - ðŸªœ Batch step - 2402 -- sub batch step 9609 -- lr 3.00e-04
2025-03-02 16:18:56,176 - INFO - ðŸªœ Batch step - 2402 -- sub batch step 9610 -- lr 3.00e-04
2025-03-02 16:18:58,348 - INFO - ðŸªœ Batch step - 2402 -- sub batch step 9611 -- lr 3.00e-04
2025-03-02 16:18:59,905 - INFO - Step 2402 -- ðŸ”„ Training Metrics
2025-03-02 16:18:59,906 - INFO - â”œâ”€â”€ Loss: 6.4734
2025-03-02 16:18:59,906 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:18:59,906 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:19:00,581 - INFO - ðŸªœ Batch step - 2403 -- sub batch step 9612 -- lr 3.00e-04
2025-03-02 16:19:02,735 - INFO - ðŸªœ Batch step - 2403 -- sub batch step 9613 -- lr 3.00e-04
2025-03-02 16:19:04,899 - INFO - ðŸªœ Batch step - 2403 -- sub batch step 9614 -- lr 3.00e-04
2025-03-02 16:19:07,564 - INFO - ðŸªœ Batch step - 2403 -- sub batch step 9615 -- lr 3.00e-04
2025-03-02 16:19:09,166 - INFO - Step 2403 -- ðŸ”„ Training Metrics
2025-03-02 16:19:09,166 - INFO - â”œâ”€â”€ Loss: 6.4576
2025-03-02 16:19:09,166 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:19:09,166 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:19:09,836 - INFO - ðŸªœ Batch step - 2404 -- sub batch step 9616 -- lr 3.00e-04
2025-03-02 16:19:12,000 - INFO - ðŸªœ Batch step - 2404 -- sub batch step 9617 -- lr 3.00e-04
2025-03-02 16:19:14,153 - INFO - ðŸªœ Batch step - 2404 -- sub batch step 9618 -- lr 3.00e-04
2025-03-02 16:19:16,340 - INFO - ðŸªœ Batch step - 2404 -- sub batch step 9619 -- lr 3.00e-04
2025-03-02 16:19:17,873 - INFO - Step 2404 -- ðŸ”„ Training Metrics
2025-03-02 16:19:17,874 - INFO - â”œâ”€â”€ Loss: 6.4946
2025-03-02 16:19:17,874 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:19:17,874 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:19:18,554 - INFO - ðŸªœ Batch step - 2405 -- sub batch step 9620 -- lr 3.00e-04
2025-03-02 16:19:20,705 - INFO - ðŸªœ Batch step - 2405 -- sub batch step 9621 -- lr 3.00e-04
2025-03-02 16:19:22,862 - INFO - ðŸªœ Batch step - 2405 -- sub batch step 9622 -- lr 3.00e-04
2025-03-02 16:19:25,576 - INFO - ðŸªœ Batch step - 2405 -- sub batch step 9623 -- lr 3.00e-04
2025-03-02 16:19:27,231 - INFO - Step 2405 -- ðŸ”„ Training Metrics
2025-03-02 16:19:27,231 - INFO - â”œâ”€â”€ Loss: 6.4635
2025-03-02 16:19:27,231 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:19:27,232 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:19:27,910 - INFO - ðŸªœ Batch step - 2406 -- sub batch step 9624 -- lr 3.00e-04
2025-03-02 16:19:30,068 - INFO - ðŸªœ Batch step - 2406 -- sub batch step 9625 -- lr 3.00e-04
2025-03-02 16:19:32,222 - INFO - ðŸªœ Batch step - 2406 -- sub batch step 9626 -- lr 3.00e-04
2025-03-02 16:19:34,408 - INFO - ðŸªœ Batch step - 2406 -- sub batch step 9627 -- lr 3.00e-04
2025-03-02 16:19:35,951 - INFO - Step 2406 -- ðŸ”„ Training Metrics
2025-03-02 16:19:35,951 - INFO - â”œâ”€â”€ Loss: 6.4684
2025-03-02 16:19:35,951 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:19:35,951 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:19:36,624 - INFO - ðŸªœ Batch step - 2407 -- sub batch step 9628 -- lr 3.00e-04
2025-03-02 16:19:38,786 - INFO - ðŸªœ Batch step - 2407 -- sub batch step 9629 -- lr 3.00e-04
2025-03-02 16:19:40,944 - INFO - ðŸªœ Batch step - 2407 -- sub batch step 9630 -- lr 3.00e-04
2025-03-02 16:19:43,648 - INFO - ðŸªœ Batch step - 2407 -- sub batch step 9631 -- lr 3.00e-04
2025-03-02 16:19:46,654 - INFO - Step 2407 -- ðŸ”„ Training Metrics
2025-03-02 16:19:46,654 - INFO - â”œâ”€â”€ Loss: 6.4726
2025-03-02 16:19:46,655 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:19:46,655 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:19:47,331 - INFO - ðŸªœ Batch step - 2408 -- sub batch step 9632 -- lr 3.00e-04
2025-03-02 16:19:49,488 - INFO - ðŸªœ Batch step - 2408 -- sub batch step 9633 -- lr 3.00e-04
2025-03-02 16:19:51,645 - INFO - ðŸªœ Batch step - 2408 -- sub batch step 9634 -- lr 3.00e-04
2025-03-02 16:19:53,820 - INFO - ðŸªœ Batch step - 2408 -- sub batch step 9635 -- lr 3.00e-04
2025-03-02 16:19:55,349 - INFO - Step 2408 -- ðŸ”„ Training Metrics
2025-03-02 16:19:55,349 - INFO - â”œâ”€â”€ Loss: 6.4443
2025-03-02 16:19:55,349 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:19:55,349 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:19:56,021 - INFO - ðŸªœ Batch step - 2409 -- sub batch step 9636 -- lr 3.00e-04
2025-03-02 16:19:58,181 - INFO - ðŸªœ Batch step - 2409 -- sub batch step 9637 -- lr 3.00e-04
2025-03-02 16:20:00,331 - INFO - ðŸªœ Batch step - 2409 -- sub batch step 9638 -- lr 3.00e-04
2025-03-02 16:20:02,693 - INFO - ðŸªœ Batch step - 2409 -- sub batch step 9639 -- lr 3.00e-04
2025-03-02 16:20:04,685 - INFO - Step 2409 -- ðŸ”„ Training Metrics
2025-03-02 16:20:04,685 - INFO - â”œâ”€â”€ Loss: 6.4654
2025-03-02 16:20:04,685 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:20:04,686 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:20:05,358 - INFO - ðŸªœ Batch step - 2410 -- sub batch step 9640 -- lr 3.00e-04
2025-03-02 16:20:07,512 - INFO - ðŸªœ Batch step - 2410 -- sub batch step 9641 -- lr 3.00e-04
2025-03-02 16:20:09,673 - INFO - ðŸªœ Batch step - 2410 -- sub batch step 9642 -- lr 3.00e-04
2025-03-02 16:20:11,844 - INFO - ðŸªœ Batch step - 2410 -- sub batch step 9643 -- lr 3.00e-04
2025-03-02 16:20:13,380 - INFO - Step 2410 -- ðŸ”„ Training Metrics
2025-03-02 16:20:13,381 - INFO - â”œâ”€â”€ Loss: 6.4681
2025-03-02 16:20:13,381 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:20:13,381 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:20:14,060 - INFO - ðŸªœ Batch step - 2411 -- sub batch step 9644 -- lr 3.00e-04
2025-03-02 16:20:16,429 - INFO - ðŸªœ Batch step - 2411 -- sub batch step 9645 -- lr 3.00e-04
2025-03-02 16:20:19,433 - INFO - ðŸªœ Batch step - 2411 -- sub batch step 9646 -- lr 3.00e-04
2025-03-02 16:20:21,619 - INFO - ðŸªœ Batch step - 2411 -- sub batch step 9647 -- lr 3.00e-04
2025-03-02 16:20:23,134 - INFO - Step 2411 -- ðŸ”„ Training Metrics
2025-03-02 16:20:23,134 - INFO - â”œâ”€â”€ Loss: 6.4595
2025-03-02 16:20:23,134 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:20:23,134 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:20:23,806 - INFO - ðŸªœ Batch step - 2412 -- sub batch step 9648 -- lr 3.00e-04
2025-03-02 16:20:25,968 - INFO - ðŸªœ Batch step - 2412 -- sub batch step 9649 -- lr 3.00e-04
2025-03-02 16:20:28,330 - INFO - ðŸªœ Batch step - 2412 -- sub batch step 9650 -- lr 3.00e-04
2025-03-02 16:20:30,485 - INFO - ðŸªœ Batch step - 2412 -- sub batch step 9651 -- lr 3.00e-04
2025-03-02 16:20:31,997 - INFO - Step 2412 -- ðŸ”„ Training Metrics
2025-03-02 16:20:31,998 - INFO - â”œâ”€â”€ Loss: 6.4435
2025-03-02 16:20:31,998 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:20:31,998 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:20:32,673 - INFO - ðŸªœ Batch step - 2413 -- sub batch step 9652 -- lr 3.00e-04
2025-03-02 16:20:34,829 - INFO - ðŸªœ Batch step - 2413 -- sub batch step 9653 -- lr 3.00e-04
2025-03-02 16:20:37,456 - INFO - ðŸªœ Batch step - 2413 -- sub batch step 9654 -- lr 3.00e-04
2025-03-02 16:20:39,615 - INFO - ðŸªœ Batch step - 2413 -- sub batch step 9655 -- lr 3.00e-04
2025-03-02 16:20:41,324 - INFO - Step 2413 -- ðŸ”„ Training Metrics
2025-03-02 16:20:41,325 - INFO - â”œâ”€â”€ Loss: 6.4745
2025-03-02 16:20:41,325 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:20:41,325 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:20:41,993 - INFO - ðŸªœ Batch step - 2414 -- sub batch step 9656 -- lr 3.00e-04
2025-03-02 16:20:44,156 - INFO - ðŸªœ Batch step - 2414 -- sub batch step 9657 -- lr 3.00e-04
2025-03-02 16:20:46,328 - INFO - ðŸªœ Batch step - 2414 -- sub batch step 9658 -- lr 3.00e-04
2025-03-02 16:20:48,490 - INFO - ðŸªœ Batch step - 2414 -- sub batch step 9659 -- lr 3.00e-04
2025-03-02 16:20:50,011 - INFO - Step 2414 -- ðŸ”„ Training Metrics
2025-03-02 16:20:50,011 - INFO - â”œâ”€â”€ Loss: 6.4604
2025-03-02 16:20:50,012 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:20:50,012 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:20:50,693 - INFO - ðŸªœ Batch step - 2415 -- sub batch step 9660 -- lr 3.00e-04
2025-03-02 16:20:52,846 - INFO - ðŸªœ Batch step - 2415 -- sub batch step 9661 -- lr 3.00e-04
2025-03-02 16:20:55,482 - INFO - ðŸªœ Batch step - 2415 -- sub batch step 9662 -- lr 3.00e-04
2025-03-02 16:20:57,640 - INFO - ðŸªœ Batch step - 2415 -- sub batch step 9663 -- lr 3.00e-04
2025-03-02 16:20:59,273 - INFO - Step 2415 -- ðŸ”„ Training Metrics
2025-03-02 16:20:59,274 - INFO - â”œâ”€â”€ Loss: 6.4454
2025-03-02 16:20:59,274 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:20:59,274 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:20:59,950 - INFO - ðŸªœ Batch step - 2416 -- sub batch step 9664 -- lr 3.00e-04
2025-03-02 16:21:02,106 - INFO - ðŸªœ Batch step - 2416 -- sub batch step 9665 -- lr 3.00e-04
2025-03-02 16:21:04,280 - INFO - ðŸªœ Batch step - 2416 -- sub batch step 9666 -- lr 3.00e-04
2025-03-02 16:21:06,439 - INFO - ðŸªœ Batch step - 2416 -- sub batch step 9667 -- lr 3.00e-04
2025-03-02 16:21:07,971 - INFO - Step 2416 -- ðŸ”„ Training Metrics
2025-03-02 16:21:07,971 - INFO - â”œâ”€â”€ Loss: 6.4606
2025-03-02 16:21:07,971 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:21:07,971 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:21:08,642 - INFO - ðŸªœ Batch step - 2417 -- sub batch step 9668 -- lr 3.00e-04
2025-03-02 16:21:10,803 - INFO - ðŸªœ Batch step - 2417 -- sub batch step 9669 -- lr 3.00e-04
2025-03-02 16:21:13,453 - INFO - ðŸªœ Batch step - 2417 -- sub batch step 9670 -- lr 3.00e-04
2025-03-02 16:21:15,608 - INFO - ðŸªœ Batch step - 2417 -- sub batch step 9671 -- lr 3.00e-04
2025-03-02 16:21:17,128 - INFO - Step 2417 -- ðŸ”„ Training Metrics
2025-03-02 16:21:17,128 - INFO - â”œâ”€â”€ Loss: 6.4624
2025-03-02 16:21:17,128 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:21:17,128 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:21:17,807 - INFO - ðŸªœ Batch step - 2418 -- sub batch step 9672 -- lr 3.00e-04
2025-03-02 16:21:19,956 - INFO - ðŸªœ Batch step - 2418 -- sub batch step 9673 -- lr 3.00e-04
2025-03-02 16:21:22,130 - INFO - ðŸªœ Batch step - 2418 -- sub batch step 9674 -- lr 3.00e-04
2025-03-02 16:21:24,288 - INFO - ðŸªœ Batch step - 2418 -- sub batch step 9675 -- lr 3.00e-04
2025-03-02 16:21:25,828 - INFO - Step 2418 -- ðŸ”„ Training Metrics
2025-03-02 16:21:25,829 - INFO - â”œâ”€â”€ Loss: 6.4591
2025-03-02 16:21:25,829 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:21:25,829 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:21:26,497 - INFO - ðŸªœ Batch step - 2419 -- sub batch step 9676 -- lr 3.00e-04
2025-03-02 16:21:28,656 - INFO - ðŸªœ Batch step - 2419 -- sub batch step 9677 -- lr 3.00e-04
2025-03-02 16:21:30,940 - INFO - ðŸªœ Batch step - 2419 -- sub batch step 9678 -- lr 3.00e-04
2025-03-02 16:21:33,100 - INFO - ðŸªœ Batch step - 2419 -- sub batch step 9679 -- lr 3.00e-04
2025-03-02 16:21:34,710 - INFO - Step 2419 -- ðŸ”„ Training Metrics
2025-03-02 16:21:34,710 - INFO - â”œâ”€â”€ Loss: 6.4569
2025-03-02 16:21:34,710 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:21:34,710 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:21:35,886 - INFO - ðŸªœ Batch step - 2420 -- sub batch step 9680 -- lr 3.00e-04
2025-03-02 16:21:38,040 - INFO - ðŸªœ Batch step - 2420 -- sub batch step 9681 -- lr 3.00e-04
2025-03-02 16:21:40,196 - INFO - ðŸªœ Batch step - 2420 -- sub batch step 9682 -- lr 3.00e-04
2025-03-02 16:21:42,372 - INFO - ðŸªœ Batch step - 2420 -- sub batch step 9683 -- lr 3.00e-04
2025-03-02 16:21:44,096 - INFO - Step 2420 -- ðŸ”„ Training Metrics
2025-03-02 16:21:44,096 - INFO - â”œâ”€â”€ Loss: 6.4745
2025-03-02 16:21:44,096 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:21:44,097 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:21:44,773 - INFO - ðŸªœ Batch step - 2421 -- sub batch step 9684 -- lr 3.00e-04
2025-03-02 16:21:47,335 - INFO - ðŸªœ Batch step - 2421 -- sub batch step 9685 -- lr 3.00e-04
2025-03-02 16:21:50,632 - INFO - ðŸªœ Batch step - 2421 -- sub batch step 9686 -- lr 3.00e-04
2025-03-02 16:21:53,070 - INFO - ðŸªœ Batch step - 2421 -- sub batch step 9687 -- lr 3.00e-04
2025-03-02 16:21:54,835 - INFO - Step 2421 -- ðŸ”„ Training Metrics
2025-03-02 16:21:54,835 - INFO - â”œâ”€â”€ Loss: 6.4259
2025-03-02 16:21:54,835 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:21:54,835 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:21:55,678 - INFO - ðŸªœ Batch step - 2422 -- sub batch step 9688 -- lr 3.00e-04
2025-03-02 16:21:57,837 - INFO - ðŸªœ Batch step - 2422 -- sub batch step 9689 -- lr 3.00e-04
2025-03-02 16:21:59,993 - INFO - ðŸªœ Batch step - 2422 -- sub batch step 9690 -- lr 3.00e-04
2025-03-02 16:22:02,163 - INFO - ðŸªœ Batch step - 2422 -- sub batch step 9691 -- lr 3.00e-04
2025-03-02 16:22:03,692 - INFO - Step 2422 -- ðŸ”„ Training Metrics
2025-03-02 16:22:03,693 - INFO - â”œâ”€â”€ Loss: 6.4383
2025-03-02 16:22:03,693 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:22:03,693 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:22:04,367 - INFO - ðŸªœ Batch step - 2423 -- sub batch step 9692 -- lr 3.00e-04
2025-03-02 16:22:06,519 - INFO - ðŸªœ Batch step - 2423 -- sub batch step 9693 -- lr 3.00e-04
2025-03-02 16:22:08,678 - INFO - ðŸªœ Batch step - 2423 -- sub batch step 9694 -- lr 3.00e-04
2025-03-02 16:22:11,351 - INFO - ðŸªœ Batch step - 2423 -- sub batch step 9695 -- lr 3.00e-04
2025-03-02 16:22:12,858 - INFO - Step 2423 -- ðŸ”„ Training Metrics
2025-03-02 16:22:12,858 - INFO - â”œâ”€â”€ Loss: 6.4299
2025-03-02 16:22:12,858 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:22:12,858 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:22:13,606 - INFO - ðŸªœ Batch step - 2424 -- sub batch step 9696 -- lr 3.00e-04
2025-03-02 16:22:15,766 - INFO - ðŸªœ Batch step - 2424 -- sub batch step 9697 -- lr 3.00e-04
2025-03-02 16:22:17,915 - INFO - ðŸªœ Batch step - 2424 -- sub batch step 9698 -- lr 3.00e-04
2025-03-02 16:22:20,096 - INFO - ðŸªœ Batch step - 2424 -- sub batch step 9699 -- lr 3.00e-04
2025-03-02 16:22:21,783 - INFO - Step 2424 -- ðŸ”„ Training Metrics
2025-03-02 16:22:21,783 - INFO - â”œâ”€â”€ Loss: 6.4466
2025-03-02 16:22:21,783 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:22:21,783 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:22:22,459 - INFO - ðŸªœ Batch step - 2425 -- sub batch step 9700 -- lr 3.00e-04
2025-03-02 16:22:24,616 - INFO - ðŸªœ Batch step - 2425 -- sub batch step 9701 -- lr 3.00e-04
2025-03-02 16:22:26,771 - INFO - ðŸªœ Batch step - 2425 -- sub batch step 9702 -- lr 3.00e-04
2025-03-02 16:22:29,398 - INFO - ðŸªœ Batch step - 2425 -- sub batch step 9703 -- lr 3.00e-04
2025-03-02 16:22:31,017 - INFO - Step 2425 -- ðŸ”„ Training Metrics
2025-03-02 16:22:31,017 - INFO - â”œâ”€â”€ Loss: 6.4343
2025-03-02 16:22:31,017 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:22:31,017 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:22:31,693 - INFO - ðŸªœ Batch step - 2426 -- sub batch step 9704 -- lr 3.00e-04
2025-03-02 16:22:33,851 - INFO - ðŸªœ Batch step - 2426 -- sub batch step 9705 -- lr 3.00e-04
2025-03-02 16:22:36,000 - INFO - ðŸªœ Batch step - 2426 -- sub batch step 9706 -- lr 3.00e-04
2025-03-02 16:22:38,172 - INFO - ðŸªœ Batch step - 2426 -- sub batch step 9707 -- lr 3.00e-04
2025-03-02 16:22:39,711 - INFO - Step 2426 -- ðŸ”„ Training Metrics
2025-03-02 16:22:39,711 - INFO - â”œâ”€â”€ Loss: 6.4706
2025-03-02 16:22:39,711 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:22:39,711 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:22:40,378 - INFO - ðŸªœ Batch step - 2427 -- sub batch step 9708 -- lr 3.00e-04
2025-03-02 16:22:42,538 - INFO - ðŸªœ Batch step - 2427 -- sub batch step 9709 -- lr 3.00e-04
2025-03-02 16:22:44,698 - INFO - ðŸªœ Batch step - 2427 -- sub batch step 9710 -- lr 3.00e-04
2025-03-02 16:22:47,370 - INFO - ðŸªœ Batch step - 2427 -- sub batch step 9711 -- lr 3.00e-04
2025-03-02 16:22:48,966 - INFO - Step 2427 -- ðŸ”„ Training Metrics
2025-03-02 16:22:48,967 - INFO - â”œâ”€â”€ Loss: 6.4466
2025-03-02 16:22:48,967 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:22:48,967 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:22:49,640 - INFO - ðŸªœ Batch step - 2428 -- sub batch step 9712 -- lr 3.00e-04
2025-03-02 16:22:51,794 - INFO - ðŸªœ Batch step - 2428 -- sub batch step 9713 -- lr 3.00e-04
2025-03-02 16:22:53,955 - INFO - ðŸªœ Batch step - 2428 -- sub batch step 9714 -- lr 3.00e-04
2025-03-02 16:22:56,130 - INFO - ðŸªœ Batch step - 2428 -- sub batch step 9715 -- lr 3.00e-04
2025-03-02 16:22:57,651 - INFO - Step 2428 -- ðŸ”„ Training Metrics
2025-03-02 16:22:57,651 - INFO - â”œâ”€â”€ Loss: 6.4453
2025-03-02 16:22:57,651 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:22:57,652 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:22:58,320 - INFO - ðŸªœ Batch step - 2429 -- sub batch step 9716 -- lr 3.00e-04
2025-03-02 16:23:00,479 - INFO - ðŸªœ Batch step - 2429 -- sub batch step 9717 -- lr 3.00e-04
2025-03-02 16:23:02,627 - INFO - ðŸªœ Batch step - 2429 -- sub batch step 9718 -- lr 3.00e-04
2025-03-02 16:23:05,000 - INFO - ðŸªœ Batch step - 2429 -- sub batch step 9719 -- lr 3.00e-04
2025-03-02 16:23:06,831 - INFO - Step 2429 -- ðŸ”„ Training Metrics
2025-03-02 16:23:06,832 - INFO - â”œâ”€â”€ Loss: 6.4427
2025-03-02 16:23:06,832 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:23:06,832 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:23:07,515 - INFO - ðŸªœ Batch step - 2430 -- sub batch step 9720 -- lr 3.00e-04
2025-03-02 16:23:09,670 - INFO - ðŸªœ Batch step - 2430 -- sub batch step 9721 -- lr 3.00e-04
2025-03-02 16:23:11,834 - INFO - ðŸªœ Batch step - 2430 -- sub batch step 9722 -- lr 3.00e-04
2025-03-02 16:23:14,006 - INFO - ðŸªœ Batch step - 2430 -- sub batch step 9723 -- lr 3.00e-04
2025-03-02 16:23:15,516 - INFO - Step 2430 -- ðŸ”„ Training Metrics
2025-03-02 16:23:15,533 - INFO - â”œâ”€â”€ Loss: 6.4747
2025-03-02 16:23:15,533 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:23:15,534 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:23:16,215 - INFO - ðŸªœ Batch step - 2431 -- sub batch step 9724 -- lr 3.00e-04
2025-03-02 16:23:18,384 - INFO - ðŸªœ Batch step - 2431 -- sub batch step 9725 -- lr 3.00e-04
2025-03-02 16:23:21,022 - INFO - ðŸªœ Batch step - 2431 -- sub batch step 9726 -- lr 3.00e-04
2025-03-02 16:23:23,181 - INFO - ðŸªœ Batch step - 2431 -- sub batch step 9727 -- lr 3.00e-04
2025-03-02 16:23:24,824 - INFO - Step 2431 -- ðŸ”„ Training Metrics
2025-03-02 16:23:24,824 - INFO - â”œâ”€â”€ Loss: 6.4784
2025-03-02 16:23:24,824 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:23:24,824 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:23:25,497 - INFO - ðŸªœ Batch step - 2432 -- sub batch step 9728 -- lr 3.00e-04
2025-03-02 16:23:27,659 - INFO - ðŸªœ Batch step - 2432 -- sub batch step 9729 -- lr 3.00e-04
2025-03-02 16:23:29,838 - INFO - ðŸªœ Batch step - 2432 -- sub batch step 9730 -- lr 3.00e-04
2025-03-02 16:23:31,992 - INFO - ðŸªœ Batch step - 2432 -- sub batch step 9731 -- lr 3.00e-04
2025-03-02 16:23:33,513 - INFO - Step 2432 -- ðŸ”„ Training Metrics
2025-03-02 16:23:33,513 - INFO - â”œâ”€â”€ Loss: 6.4804
2025-03-02 16:23:33,513 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:23:33,513 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:23:34,190 - INFO - ðŸªœ Batch step - 2433 -- sub batch step 9732 -- lr 3.00e-04
2025-03-02 16:23:36,344 - INFO - ðŸªœ Batch step - 2433 -- sub batch step 9733 -- lr 3.00e-04
2025-03-02 16:23:39,139 - INFO - ðŸªœ Batch step - 2433 -- sub batch step 9734 -- lr 3.00e-04
2025-03-02 16:23:41,299 - INFO - ðŸªœ Batch step - 2433 -- sub batch step 9735 -- lr 3.00e-04
2025-03-02 16:23:42,895 - INFO - Step 2433 -- ðŸ”„ Training Metrics
2025-03-02 16:23:42,895 - INFO - â”œâ”€â”€ Loss: 6.4394
2025-03-02 16:23:42,895 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:23:42,895 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:23:43,565 - INFO - ðŸªœ Batch step - 2434 -- sub batch step 9736 -- lr 3.00e-04
2025-03-02 16:23:45,725 - INFO - ðŸªœ Batch step - 2434 -- sub batch step 9737 -- lr 3.00e-04
2025-03-02 16:23:47,895 - INFO - ðŸªœ Batch step - 2434 -- sub batch step 9738 -- lr 3.00e-04
2025-03-02 16:23:50,053 - INFO - ðŸªœ Batch step - 2434 -- sub batch step 9739 -- lr 3.00e-04
2025-03-02 16:23:51,580 - INFO - Step 2434 -- ðŸ”„ Training Metrics
2025-03-02 16:23:51,580 - INFO - â”œâ”€â”€ Loss: 6.4662
2025-03-02 16:23:51,580 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:23:51,580 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:23:52,253 - INFO - ðŸªœ Batch step - 2435 -- sub batch step 9740 -- lr 3.00e-04
2025-03-02 16:23:54,408 - INFO - ðŸªœ Batch step - 2435 -- sub batch step 9741 -- lr 3.00e-04
2025-03-02 16:23:56,825 - INFO - ðŸªœ Batch step - 2435 -- sub batch step 9742 -- lr 3.00e-04
2025-03-02 16:23:58,979 - INFO - ðŸªœ Batch step - 2435 -- sub batch step 9743 -- lr 3.00e-04
2025-03-02 16:24:01,040 - INFO - Step 2435 -- ðŸ”„ Training Metrics
2025-03-02 16:24:01,041 - INFO - â”œâ”€â”€ Loss: 6.4319
2025-03-02 16:24:01,041 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:24:01,041 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:24:01,717 - INFO - ðŸªœ Batch step - 2436 -- sub batch step 9744 -- lr 3.00e-04
2025-03-02 16:24:03,874 - INFO - ðŸªœ Batch step - 2436 -- sub batch step 9745 -- lr 3.00e-04
2025-03-02 16:24:06,044 - INFO - ðŸªœ Batch step - 2436 -- sub batch step 9746 -- lr 3.00e-04
2025-03-02 16:24:08,198 - INFO - ðŸªœ Batch step - 2436 -- sub batch step 9747 -- lr 3.00e-04
2025-03-02 16:24:09,733 - INFO - Step 2436 -- ðŸ”„ Training Metrics
2025-03-02 16:24:09,734 - INFO - â”œâ”€â”€ Loss: 6.4410
2025-03-02 16:24:09,734 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:24:09,734 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:24:10,400 - INFO - ðŸªœ Batch step - 2437 -- sub batch step 9748 -- lr 3.00e-04
2025-03-02 16:24:12,552 - INFO - ðŸªœ Batch step - 2437 -- sub batch step 9749 -- lr 3.00e-04
2025-03-02 16:24:15,074 - INFO - ðŸªœ Batch step - 2437 -- sub batch step 9750 -- lr 3.00e-04
2025-03-02 16:24:17,226 - INFO - ðŸªœ Batch step - 2437 -- sub batch step 9751 -- lr 3.00e-04
2025-03-02 16:24:18,941 - INFO - Step 2437 -- ðŸ”„ Training Metrics
2025-03-02 16:24:18,942 - INFO - â”œâ”€â”€ Loss: 6.4629
2025-03-02 16:24:18,942 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:24:18,942 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:24:19,616 - INFO - ðŸªœ Batch step - 2438 -- sub batch step 9752 -- lr 3.00e-04
2025-03-02 16:24:21,768 - INFO - ðŸªœ Batch step - 2438 -- sub batch step 9753 -- lr 3.00e-04
2025-03-02 16:24:23,951 - INFO - ðŸªœ Batch step - 2438 -- sub batch step 9754 -- lr 3.00e-04
2025-03-02 16:24:26,105 - INFO - ðŸªœ Batch step - 2438 -- sub batch step 9755 -- lr 3.00e-04
2025-03-02 16:24:27,642 - INFO - Step 2438 -- ðŸ”„ Training Metrics
2025-03-02 16:24:27,642 - INFO - â”œâ”€â”€ Loss: 6.4510
2025-03-02 16:24:27,643 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:24:27,643 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:24:28,310 - INFO - ðŸªœ Batch step - 2439 -- sub batch step 9756 -- lr 3.00e-04
2025-03-02 16:24:30,466 - INFO - ðŸªœ Batch step - 2439 -- sub batch step 9757 -- lr 3.00e-04
2025-03-02 16:24:32,748 - INFO - ðŸªœ Batch step - 2439 -- sub batch step 9758 -- lr 3.00e-04
2025-03-02 16:24:34,909 - INFO - ðŸªœ Batch step - 2439 -- sub batch step 9759 -- lr 3.00e-04
2025-03-02 16:24:36,444 - INFO - Step 2439 -- ðŸ”„ Training Metrics
2025-03-02 16:24:36,444 - INFO - â”œâ”€â”€ Loss: 6.4216
2025-03-02 16:24:36,444 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:24:36,445 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:24:37,564 - INFO - ðŸªœ Batch step - 2440 -- sub batch step 9760 -- lr 3.00e-04
2025-03-02 16:24:39,716 - INFO - ðŸªœ Batch step - 2440 -- sub batch step 9761 -- lr 3.00e-04
2025-03-02 16:24:41,876 - INFO - ðŸªœ Batch step - 2440 -- sub batch step 9762 -- lr 3.00e-04
2025-03-02 16:24:44,053 - INFO - ðŸªœ Batch step - 2440 -- sub batch step 9763 -- lr 3.00e-04
2025-03-02 16:24:46,143 - INFO - Step 2440 -- ðŸ”„ Training Metrics
2025-03-02 16:24:46,143 - INFO - â”œâ”€â”€ Loss: 6.4296
2025-03-02 16:24:46,143 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:24:46,144 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:24:46,822 - INFO - ðŸªœ Batch step - 2441 -- sub batch step 9764 -- lr 3.00e-04
2025-03-02 16:24:48,978 - INFO - ðŸªœ Batch step - 2441 -- sub batch step 9765 -- lr 3.00e-04
2025-03-02 16:24:51,129 - INFO - ðŸªœ Batch step - 2441 -- sub batch step 9766 -- lr 3.00e-04
2025-03-02 16:24:53,579 - INFO - ðŸªœ Batch step - 2441 -- sub batch step 9767 -- lr 3.00e-04
2025-03-02 16:24:55,324 - INFO - Step 2441 -- ðŸ”„ Training Metrics
2025-03-02 16:24:55,324 - INFO - â”œâ”€â”€ Loss: 6.4636
2025-03-02 16:24:55,324 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:24:55,325 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:24:55,992 - INFO - ðŸªœ Batch step - 2442 -- sub batch step 9768 -- lr 3.00e-04
2025-03-02 16:24:58,150 - INFO - ðŸªœ Batch step - 2442 -- sub batch step 9769 -- lr 3.00e-04
2025-03-02 16:25:00,312 - INFO - ðŸªœ Batch step - 2442 -- sub batch step 9770 -- lr 3.00e-04
2025-03-02 16:25:02,481 - INFO - ðŸªœ Batch step - 2442 -- sub batch step 9771 -- lr 3.00e-04
2025-03-02 16:25:04,027 - INFO - Step 2442 -- ðŸ”„ Training Metrics
2025-03-02 16:25:04,027 - INFO - â”œâ”€â”€ Loss: 6.4451
2025-03-02 16:25:04,027 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:25:04,028 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:25:04,703 - INFO - ðŸªœ Batch step - 2443 -- sub batch step 9772 -- lr 3.00e-04
2025-03-02 16:25:06,856 - INFO - ðŸªœ Batch step - 2443 -- sub batch step 9773 -- lr 3.00e-04
2025-03-02 16:25:09,017 - INFO - ðŸªœ Batch step - 2443 -- sub batch step 9774 -- lr 3.00e-04
2025-03-02 16:25:11,375 - INFO - ðŸªœ Batch step - 2443 -- sub batch step 9775 -- lr 3.00e-04
2025-03-02 16:25:13,273 - INFO - Step 2443 -- ðŸ”„ Training Metrics
2025-03-02 16:25:13,273 - INFO - â”œâ”€â”€ Loss: 6.4509
2025-03-02 16:25:13,273 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:25:13,273 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:25:13,944 - INFO - ðŸªœ Batch step - 2444 -- sub batch step 9776 -- lr 3.00e-04
2025-03-02 16:25:16,104 - INFO - ðŸªœ Batch step - 2444 -- sub batch step 9777 -- lr 3.00e-04
2025-03-02 16:25:18,256 - INFO - ðŸªœ Batch step - 2444 -- sub batch step 9778 -- lr 3.00e-04
2025-03-02 16:25:20,436 - INFO - ðŸªœ Batch step - 2444 -- sub batch step 9779 -- lr 3.00e-04
2025-03-02 16:25:21,973 - INFO - Step 2444 -- ðŸ”„ Training Metrics
2025-03-02 16:25:21,974 - INFO - â”œâ”€â”€ Loss: 6.4096
2025-03-02 16:25:21,974 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:25:21,974 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:25:22,650 - INFO - ðŸªœ Batch step - 2445 -- sub batch step 9780 -- lr 3.00e-04
2025-03-02 16:25:24,805 - INFO - ðŸªœ Batch step - 2445 -- sub batch step 9781 -- lr 3.00e-04
2025-03-02 16:25:26,963 - INFO - ðŸªœ Batch step - 2445 -- sub batch step 9782 -- lr 3.00e-04
2025-03-02 16:25:29,651 - INFO - ðŸªœ Batch step - 2445 -- sub batch step 9783 -- lr 3.00e-04
2025-03-02 16:25:31,202 - INFO - Step 2445 -- ðŸ”„ Training Metrics
2025-03-02 16:25:31,202 - INFO - â”œâ”€â”€ Loss: 6.4676
2025-03-02 16:25:31,202 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:25:31,202 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:25:31,881 - INFO - ðŸªœ Batch step - 2446 -- sub batch step 9784 -- lr 3.00e-04
2025-03-02 16:25:34,040 - INFO - ðŸªœ Batch step - 2446 -- sub batch step 9785 -- lr 3.00e-04
2025-03-02 16:25:36,190 - INFO - ðŸªœ Batch step - 2446 -- sub batch step 9786 -- lr 3.00e-04
2025-03-02 16:25:38,369 - INFO - ðŸªœ Batch step - 2446 -- sub batch step 9787 -- lr 3.00e-04
2025-03-02 16:25:39,895 - INFO - Step 2446 -- ðŸ”„ Training Metrics
2025-03-02 16:25:39,895 - INFO - â”œâ”€â”€ Loss: 6.4404
2025-03-02 16:25:39,895 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:25:39,895 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:25:40,564 - INFO - ðŸªœ Batch step - 2447 -- sub batch step 9788 -- lr 3.00e-04
2025-03-02 16:25:42,728 - INFO - ðŸªœ Batch step - 2447 -- sub batch step 9789 -- lr 3.00e-04
2025-03-02 16:25:44,885 - INFO - ðŸªœ Batch step - 2447 -- sub batch step 9790 -- lr 3.00e-04
2025-03-02 16:25:47,468 - INFO - ðŸªœ Batch step - 2447 -- sub batch step 9791 -- lr 3.00e-04
2025-03-02 16:25:49,213 - INFO - Step 2447 -- ðŸ”„ Training Metrics
2025-03-02 16:25:49,213 - INFO - â”œâ”€â”€ Loss: 6.4399
2025-03-02 16:25:49,213 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:25:49,214 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:25:49,892 - INFO - ðŸªœ Batch step - 2448 -- sub batch step 9792 -- lr 3.00e-04
2025-03-02 16:25:52,045 - INFO - ðŸªœ Batch step - 2448 -- sub batch step 9793 -- lr 3.00e-04
2025-03-02 16:25:54,201 - INFO - ðŸªœ Batch step - 2448 -- sub batch step 9794 -- lr 3.00e-04
2025-03-02 16:25:56,376 - INFO - ðŸªœ Batch step - 2448 -- sub batch step 9795 -- lr 3.00e-04
2025-03-02 16:25:57,903 - INFO - Step 2448 -- ðŸ”„ Training Metrics
2025-03-02 16:25:57,903 - INFO - â”œâ”€â”€ Loss: 6.4794
2025-03-02 16:25:57,903 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:25:57,903 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:25:58,573 - INFO - ðŸªœ Batch step - 2449 -- sub batch step 9796 -- lr 3.00e-04
2025-03-02 16:26:00,732 - INFO - ðŸªœ Batch step - 2449 -- sub batch step 9797 -- lr 3.00e-04
2025-03-02 16:26:02,881 - INFO - ðŸªœ Batch step - 2449 -- sub batch step 9798 -- lr 3.00e-04
2025-03-02 16:26:05,264 - INFO - ðŸªœ Batch step - 2449 -- sub batch step 9799 -- lr 3.00e-04
2025-03-02 16:26:07,422 - INFO - Step 2449 -- ðŸ”„ Training Metrics
2025-03-02 16:26:07,423 - INFO - â”œâ”€â”€ Loss: 6.4785
2025-03-02 16:26:07,423 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:26:07,423 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:26:08,098 - INFO - ðŸªœ Batch step - 2450 -- sub batch step 9800 -- lr 3.00e-04
2025-03-02 16:26:10,250 - INFO - ðŸªœ Batch step - 2450 -- sub batch step 9801 -- lr 3.00e-04
2025-03-02 16:26:12,411 - INFO - ðŸªœ Batch step - 2450 -- sub batch step 9802 -- lr 3.00e-04
2025-03-02 16:26:14,584 - INFO - ðŸªœ Batch step - 2450 -- sub batch step 9803 -- lr 3.00e-04
2025-03-02 16:26:16,111 - INFO - Step 2450 -- ðŸ”„ Training Metrics
2025-03-02 16:26:16,111 - INFO - â”œâ”€â”€ Loss: 6.4259
2025-03-02 16:26:16,111 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:26:16,112 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:26:16,788 - INFO - ðŸªœ Batch step - 2451 -- sub batch step 9804 -- lr 3.00e-04
2025-03-02 16:26:18,945 - INFO - ðŸªœ Batch step - 2451 -- sub batch step 9805 -- lr 3.00e-04
2025-03-02 16:26:21,315 - INFO - ðŸªœ Batch step - 2451 -- sub batch step 9806 -- lr 3.00e-04
2025-03-02 16:26:23,472 - INFO - ðŸªœ Batch step - 2451 -- sub batch step 9807 -- lr 3.00e-04
2025-03-02 16:26:25,381 - INFO - Step 2451 -- ðŸ”„ Training Metrics
2025-03-02 16:26:25,381 - INFO - â”œâ”€â”€ Loss: 6.4578
2025-03-02 16:26:25,381 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:26:25,381 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:26:26,049 - INFO - ðŸªœ Batch step - 2452 -- sub batch step 9808 -- lr 3.00e-04
2025-03-02 16:26:28,212 - INFO - ðŸªœ Batch step - 2452 -- sub batch step 9809 -- lr 3.00e-04
2025-03-02 16:26:30,395 - INFO - ðŸªœ Batch step - 2452 -- sub batch step 9810 -- lr 3.00e-04
2025-03-02 16:26:32,547 - INFO - ðŸªœ Batch step - 2452 -- sub batch step 9811 -- lr 3.00e-04
2025-03-02 16:26:34,058 - INFO - Step 2452 -- ðŸ”„ Training Metrics
2025-03-02 16:26:34,059 - INFO - â”œâ”€â”€ Loss: 6.4400
2025-03-02 16:26:34,059 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:26:34,059 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:26:34,734 - INFO - ðŸªœ Batch step - 2453 -- sub batch step 9812 -- lr 3.00e-04
2025-03-02 16:26:36,885 - INFO - ðŸªœ Batch step - 2453 -- sub batch step 9813 -- lr 3.00e-04
2025-03-02 16:26:39,560 - INFO - ðŸªœ Batch step - 2453 -- sub batch step 9814 -- lr 3.00e-04
2025-03-02 16:26:41,721 - INFO - ðŸªœ Batch step - 2453 -- sub batch step 9815 -- lr 3.00e-04
2025-03-02 16:26:48,482 - INFO - Step 2453 -- ðŸ”„ Training Metrics
2025-03-02 16:26:48,482 - INFO - â”œâ”€â”€ Loss: 6.4365
2025-03-02 16:26:48,482 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:26:48,482 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:26:49,151 - INFO - ðŸªœ Batch step - 2454 -- sub batch step 9816 -- lr 3.00e-04
2025-03-02 16:26:51,307 - INFO - ðŸªœ Batch step - 2454 -- sub batch step 9817 -- lr 3.00e-04
2025-03-02 16:26:53,469 - INFO - ðŸªœ Batch step - 2454 -- sub batch step 9818 -- lr 3.00e-04
2025-03-02 16:26:55,627 - INFO - ðŸªœ Batch step - 2454 -- sub batch step 9819 -- lr 3.00e-04
2025-03-02 16:26:57,155 - INFO - Step 2454 -- ðŸ”„ Training Metrics
2025-03-02 16:26:57,155 - INFO - â”œâ”€â”€ Loss: 6.4455
2025-03-02 16:26:57,155 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:26:57,155 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:26:57,831 - INFO - ðŸªœ Batch step - 2455 -- sub batch step 9820 -- lr 3.00e-04
2025-03-02 16:26:59,980 - INFO - ðŸªœ Batch step - 2455 -- sub batch step 9821 -- lr 3.00e-04
2025-03-02 16:27:02,416 - INFO - ðŸªœ Batch step - 2455 -- sub batch step 9822 -- lr 3.00e-04
2025-03-02 16:27:04,567 - INFO - ðŸªœ Batch step - 2455 -- sub batch step 9823 -- lr 3.00e-04
2025-03-02 16:27:06,332 - INFO - Step 2455 -- ðŸ”„ Training Metrics
2025-03-02 16:27:06,333 - INFO - â”œâ”€â”€ Loss: 6.4291
2025-03-02 16:27:06,333 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:27:06,333 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:27:07,013 - INFO - ðŸªœ Batch step - 2456 -- sub batch step 9824 -- lr 3.00e-04
2025-03-02 16:27:09,166 - INFO - ðŸªœ Batch step - 2456 -- sub batch step 9825 -- lr 3.00e-04
2025-03-02 16:27:11,329 - INFO - ðŸªœ Batch step - 2456 -- sub batch step 9826 -- lr 3.00e-04
2025-03-02 16:27:13,484 - INFO - ðŸªœ Batch step - 2456 -- sub batch step 9827 -- lr 3.00e-04
2025-03-02 16:27:15,022 - INFO - Step 2456 -- ðŸ”„ Training Metrics
2025-03-02 16:27:15,023 - INFO - â”œâ”€â”€ Loss: 6.4158
2025-03-02 16:27:15,023 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:27:15,023 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:27:15,689 - INFO - ðŸªœ Batch step - 2457 -- sub batch step 9828 -- lr 3.00e-04
2025-03-02 16:27:17,848 - INFO - ðŸªœ Batch step - 2457 -- sub batch step 9829 -- lr 3.00e-04
2025-03-02 16:27:20,217 - INFO - ðŸªœ Batch step - 2457 -- sub batch step 9830 -- lr 3.00e-04
2025-03-02 16:27:22,370 - INFO - ðŸªœ Batch step - 2457 -- sub batch step 9831 -- lr 3.00e-04
2025-03-02 16:27:24,999 - INFO - Step 2457 -- ðŸ”„ Training Metrics
2025-03-02 16:27:24,999 - INFO - â”œâ”€â”€ Loss: 6.4353
2025-03-02 16:27:24,999 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:27:24,999 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:27:25,674 - INFO - ðŸªœ Batch step - 2458 -- sub batch step 9832 -- lr 3.00e-04
2025-03-02 16:27:27,821 - INFO - ðŸªœ Batch step - 2458 -- sub batch step 9833 -- lr 3.00e-04
2025-03-02 16:27:29,997 - INFO - ðŸªœ Batch step - 2458 -- sub batch step 9834 -- lr 3.00e-04
2025-03-02 16:27:32,151 - INFO - ðŸªœ Batch step - 2458 -- sub batch step 9835 -- lr 3.00e-04
2025-03-02 16:27:33,697 - INFO - Step 2458 -- ðŸ”„ Training Metrics
2025-03-02 16:27:33,697 - INFO - â”œâ”€â”€ Loss: 6.4328
2025-03-02 16:27:33,698 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:27:33,698 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:27:34,366 - INFO - ðŸªœ Batch step - 2459 -- sub batch step 9836 -- lr 3.00e-04
2025-03-02 16:27:36,521 - INFO - ðŸªœ Batch step - 2459 -- sub batch step 9837 -- lr 3.00e-04
2025-03-02 16:27:38,803 - INFO - ðŸªœ Batch step - 2459 -- sub batch step 9838 -- lr 3.00e-04
2025-03-02 16:27:40,959 - INFO - ðŸªœ Batch step - 2459 -- sub batch step 9839 -- lr 3.00e-04
2025-03-02 16:27:45,092 - INFO - Step 2459 -- ðŸ”„ Training Metrics
2025-03-02 16:27:45,092 - INFO - â”œâ”€â”€ Loss: 6.4130
2025-03-02 16:27:45,092 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:27:45,092 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:27:46,208 - INFO - ðŸªœ Batch step - 2460 -- sub batch step 9840 -- lr 3.00e-04
2025-03-02 16:27:48,363 - INFO - ðŸªœ Batch step - 2460 -- sub batch step 9841 -- lr 3.00e-04
2025-03-02 16:27:50,520 - INFO - ðŸªœ Batch step - 2460 -- sub batch step 9842 -- lr 3.00e-04
2025-03-02 16:27:52,687 - INFO - ðŸªœ Batch step - 2460 -- sub batch step 9843 -- lr 3.00e-04
2025-03-02 16:27:54,354 - INFO - Step 2460 -- ðŸ”„ Training Metrics
2025-03-02 16:27:54,355 - INFO - â”œâ”€â”€ Loss: 6.4380
2025-03-02 16:27:54,355 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:27:54,355 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:27:55,030 - INFO - ðŸªœ Batch step - 2461 -- sub batch step 9844 -- lr 3.00e-04
2025-03-02 16:27:57,183 - INFO - ðŸªœ Batch step - 2461 -- sub batch step 9845 -- lr 3.00e-04
2025-03-02 16:27:59,332 - INFO - ðŸªœ Batch step - 2461 -- sub batch step 9846 -- lr 3.00e-04
2025-03-02 16:28:01,948 - INFO - ðŸªœ Batch step - 2461 -- sub batch step 9847 -- lr 3.00e-04
2025-03-02 16:28:03,483 - INFO - Step 2461 -- ðŸ”„ Training Metrics
2025-03-02 16:28:03,483 - INFO - â”œâ”€â”€ Loss: 6.4238
2025-03-02 16:28:03,483 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:28:03,483 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:28:04,151 - INFO - ðŸªœ Batch step - 2462 -- sub batch step 9848 -- lr 3.00e-04
2025-03-02 16:28:06,309 - INFO - ðŸªœ Batch step - 2462 -- sub batch step 9849 -- lr 3.00e-04
2025-03-02 16:28:08,464 - INFO - ðŸªœ Batch step - 2462 -- sub batch step 9850 -- lr 3.00e-04
2025-03-02 16:28:10,629 - INFO - ðŸªœ Batch step - 2462 -- sub batch step 9851 -- lr 3.00e-04
2025-03-02 16:28:12,174 - INFO - Step 2462 -- ðŸ”„ Training Metrics
2025-03-02 16:28:12,174 - INFO - â”œâ”€â”€ Loss: 6.4187
2025-03-02 16:28:12,174 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:28:12,174 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:28:12,849 - INFO - ðŸªœ Batch step - 2463 -- sub batch step 9852 -- lr 3.00e-04
2025-03-02 16:28:14,998 - INFO - ðŸªœ Batch step - 2463 -- sub batch step 9853 -- lr 3.00e-04
2025-03-02 16:28:17,160 - INFO - ðŸªœ Batch step - 2463 -- sub batch step 9854 -- lr 3.00e-04
2025-03-02 16:28:19,836 - INFO - ðŸªœ Batch step - 2463 -- sub batch step 9855 -- lr 3.00e-04
2025-03-02 16:28:21,339 - INFO - Step 2463 -- ðŸ”„ Training Metrics
2025-03-02 16:28:21,340 - INFO - â”œâ”€â”€ Loss: 6.4194
2025-03-02 16:28:21,340 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:28:21,340 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:28:22,007 - INFO - ðŸªœ Batch step - 2464 -- sub batch step 9856 -- lr 3.00e-04
2025-03-02 16:28:24,163 - INFO - ðŸªœ Batch step - 2464 -- sub batch step 9857 -- lr 3.00e-04
2025-03-02 16:28:26,308 - INFO - ðŸªœ Batch step - 2464 -- sub batch step 9858 -- lr 3.00e-04
2025-03-02 16:28:28,477 - INFO - ðŸªœ Batch step - 2464 -- sub batch step 9859 -- lr 3.00e-04
2025-03-02 16:28:30,026 - INFO - Step 2464 -- ðŸ”„ Training Metrics
2025-03-02 16:28:30,026 - INFO - â”œâ”€â”€ Loss: 6.4654
2025-03-02 16:28:30,026 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:28:30,026 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:28:30,698 - INFO - ðŸªœ Batch step - 2465 -- sub batch step 9860 -- lr 3.00e-04
2025-03-02 16:28:32,848 - INFO - ðŸªœ Batch step - 2465 -- sub batch step 9861 -- lr 3.00e-04
2025-03-02 16:28:35,001 - INFO - ðŸªœ Batch step - 2465 -- sub batch step 9862 -- lr 3.00e-04
2025-03-02 16:28:37,823 - INFO - ðŸªœ Batch step - 2465 -- sub batch step 9863 -- lr 3.00e-04
2025-03-02 16:28:44,963 - INFO - Step 2465 -- ðŸ”„ Training Metrics
2025-03-02 16:28:44,963 - INFO - â”œâ”€â”€ Loss: 6.4127
2025-03-02 16:28:44,963 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:28:44,963 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:28:45,635 - INFO - ðŸªœ Batch step - 2466 -- sub batch step 9864 -- lr 3.00e-04
2025-03-02 16:28:47,788 - INFO - ðŸªœ Batch step - 2466 -- sub batch step 9865 -- lr 3.00e-04
2025-03-02 16:28:49,935 - INFO - ðŸªœ Batch step - 2466 -- sub batch step 9866 -- lr 3.00e-04
2025-03-02 16:28:52,103 - INFO - ðŸªœ Batch step - 2466 -- sub batch step 9867 -- lr 3.00e-04
2025-03-02 16:28:53,653 - INFO - Step 2466 -- ðŸ”„ Training Metrics
2025-03-02 16:28:53,653 - INFO - â”œâ”€â”€ Loss: 6.4215
2025-03-02 16:28:53,654 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:28:53,654 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:28:54,321 - INFO - ðŸªœ Batch step - 2467 -- sub batch step 9868 -- lr 3.00e-04
2025-03-02 16:28:56,478 - INFO - ðŸªœ Batch step - 2467 -- sub batch step 9869 -- lr 3.00e-04
2025-03-02 16:28:58,631 - INFO - ðŸªœ Batch step - 2467 -- sub batch step 9870 -- lr 3.00e-04
2025-03-02 16:29:01,294 - INFO - ðŸªœ Batch step - 2467 -- sub batch step 9871 -- lr 3.00e-04
2025-03-02 16:29:02,843 - INFO - Step 2467 -- ðŸ”„ Training Metrics
2025-03-02 16:29:02,843 - INFO - â”œâ”€â”€ Loss: 6.4169
2025-03-02 16:29:02,843 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:29:02,843 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:29:03,528 - INFO - ðŸªœ Batch step - 2468 -- sub batch step 9872 -- lr 3.00e-04
2025-03-02 16:29:05,694 - INFO - ðŸªœ Batch step - 2468 -- sub batch step 9873 -- lr 3.00e-04
2025-03-02 16:29:07,855 - INFO - ðŸªœ Batch step - 2468 -- sub batch step 9874 -- lr 3.00e-04
2025-03-02 16:29:10,035 - INFO - ðŸªœ Batch step - 2468 -- sub batch step 9875 -- lr 3.00e-04
2025-03-02 16:29:11,547 - INFO - Step 2468 -- ðŸ”„ Training Metrics
2025-03-02 16:29:11,547 - INFO - â”œâ”€â”€ Loss: 6.3894
2025-03-02 16:29:11,547 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:29:11,547 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:29:12,224 - INFO - ðŸªœ Batch step - 2469 -- sub batch step 9876 -- lr 3.00e-04
2025-03-02 16:29:14,383 - INFO - ðŸªœ Batch step - 2469 -- sub batch step 9877 -- lr 3.00e-04
2025-03-02 16:29:16,539 - INFO - ðŸªœ Batch step - 2469 -- sub batch step 9878 -- lr 3.00e-04
2025-03-02 16:29:19,182 - INFO - ðŸªœ Batch step - 2469 -- sub batch step 9879 -- lr 3.00e-04
2025-03-02 16:29:21,158 - INFO - Step 2469 -- ðŸ”„ Training Metrics
2025-03-02 16:29:21,159 - INFO - â”œâ”€â”€ Loss: 6.3953
2025-03-02 16:29:21,159 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:29:21,159 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:29:21,839 - INFO - ðŸªœ Batch step - 2470 -- sub batch step 9880 -- lr 3.00e-04
2025-03-02 16:29:23,993 - INFO - ðŸªœ Batch step - 2470 -- sub batch step 9881 -- lr 3.00e-04
2025-03-02 16:29:26,149 - INFO - ðŸªœ Batch step - 2470 -- sub batch step 9882 -- lr 3.00e-04
2025-03-02 16:29:28,314 - INFO - ðŸªœ Batch step - 2470 -- sub batch step 9883 -- lr 3.00e-04
2025-03-02 16:29:29,842 - INFO - Step 2470 -- ðŸ”„ Training Metrics
2025-03-02 16:29:29,843 - INFO - â”œâ”€â”€ Loss: 6.4170
2025-03-02 16:29:29,843 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:29:29,843 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:29:30,519 - INFO - ðŸªœ Batch step - 2471 -- sub batch step 9884 -- lr 3.00e-04
2025-03-02 16:29:32,681 - INFO - ðŸªœ Batch step - 2471 -- sub batch step 9885 -- lr 3.00e-04
2025-03-02 16:29:35,335 - INFO - ðŸªœ Batch step - 2471 -- sub batch step 9886 -- lr 3.00e-04
2025-03-02 16:29:37,488 - INFO - ðŸªœ Batch step - 2471 -- sub batch step 9887 -- lr 3.00e-04
2025-03-02 16:29:44,787 - INFO - Step 2471 -- ðŸ”„ Training Metrics
2025-03-02 16:29:44,787 - INFO - â”œâ”€â”€ Loss: 6.4234
2025-03-02 16:29:44,788 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:29:44,788 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:29:45,458 - INFO - ðŸªœ Batch step - 2472 -- sub batch step 9888 -- lr 3.00e-04
2025-03-02 16:29:47,613 - INFO - ðŸªœ Batch step - 2472 -- sub batch step 9889 -- lr 3.00e-04
2025-03-02 16:29:49,784 - INFO - ðŸªœ Batch step - 2472 -- sub batch step 9890 -- lr 3.00e-04
2025-03-02 16:29:51,930 - INFO - ðŸªœ Batch step - 2472 -- sub batch step 9891 -- lr 3.00e-04
2025-03-02 16:29:53,477 - INFO - Step 2472 -- ðŸ”„ Training Metrics
2025-03-02 16:29:53,477 - INFO - â”œâ”€â”€ Loss: 6.3911
2025-03-02 16:29:53,477 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:29:53,477 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:29:54,150 - INFO - ðŸªœ Batch step - 2473 -- sub batch step 9892 -- lr 3.00e-04
2025-03-02 16:29:56,298 - INFO - ðŸªœ Batch step - 2473 -- sub batch step 9893 -- lr 3.00e-04
2025-03-02 16:29:58,969 - INFO - ðŸªœ Batch step - 2473 -- sub batch step 9894 -- lr 3.00e-04
2025-03-02 16:30:01,121 - INFO - ðŸªœ Batch step - 2473 -- sub batch step 9895 -- lr 3.00e-04
2025-03-02 16:30:02,649 - INFO - Step 2473 -- ðŸ”„ Training Metrics
2025-03-02 16:30:02,650 - INFO - â”œâ”€â”€ Loss: 6.4269
2025-03-02 16:30:02,650 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:30:02,650 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:30:03,321 - INFO - ðŸªœ Batch step - 2474 -- sub batch step 9896 -- lr 3.00e-04
2025-03-02 16:30:05,472 - INFO - ðŸªœ Batch step - 2474 -- sub batch step 9897 -- lr 3.00e-04
2025-03-02 16:30:07,637 - INFO - ðŸªœ Batch step - 2474 -- sub batch step 9898 -- lr 3.00e-04
2025-03-02 16:30:09,791 - INFO - ðŸªœ Batch step - 2474 -- sub batch step 9899 -- lr 3.00e-04
2025-03-02 16:30:11,343 - INFO - Step 2474 -- ðŸ”„ Training Metrics
2025-03-02 16:30:11,344 - INFO - â”œâ”€â”€ Loss: 6.4468
2025-03-02 16:30:11,344 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:30:11,344 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:30:12,016 - INFO - ðŸªœ Batch step - 2475 -- sub batch step 9900 -- lr 3.00e-04
2025-03-02 16:30:14,163 - INFO - ðŸªœ Batch step - 2475 -- sub batch step 9901 -- lr 3.00e-04
2025-03-02 16:30:16,846 - INFO - ðŸªœ Batch step - 2475 -- sub batch step 9902 -- lr 3.00e-04
2025-03-02 16:30:18,994 - INFO - ðŸªœ Batch step - 2475 -- sub batch step 9903 -- lr 3.00e-04
2025-03-02 16:30:25,387 - INFO - Step 2475 -- ðŸ”„ Training Metrics
2025-03-02 16:30:25,387 - INFO - â”œâ”€â”€ Loss: 6.4352
2025-03-02 16:30:25,387 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:30:25,387 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:30:26,059 - INFO - ðŸªœ Batch step - 2476 -- sub batch step 9904 -- lr 3.00e-04
2025-03-02 16:30:28,212 - INFO - ðŸªœ Batch step - 2476 -- sub batch step 9905 -- lr 3.00e-04
2025-03-02 16:30:30,378 - INFO - ðŸªœ Batch step - 2476 -- sub batch step 9906 -- lr 3.00e-04
2025-03-02 16:30:32,531 - INFO - ðŸªœ Batch step - 2476 -- sub batch step 9907 -- lr 3.00e-04
2025-03-02 16:30:34,086 - INFO - Step 2476 -- ðŸ”„ Training Metrics
2025-03-02 16:30:34,086 - INFO - â”œâ”€â”€ Loss: 6.4452
2025-03-02 16:30:34,086 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:30:34,086 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:30:34,752 - INFO - ðŸªœ Batch step - 2477 -- sub batch step 9908 -- lr 3.00e-04
2025-03-02 16:30:36,910 - INFO - ðŸªœ Batch step - 2477 -- sub batch step 9909 -- lr 3.00e-04
2025-03-02 16:30:39,593 - INFO - ðŸªœ Batch step - 2477 -- sub batch step 9910 -- lr 3.00e-04
2025-03-02 16:30:41,739 - INFO - ðŸªœ Batch step - 2477 -- sub batch step 9911 -- lr 3.00e-04
2025-03-02 16:30:43,224 - INFO - Step 2477 -- ðŸ”„ Training Metrics
2025-03-02 16:30:43,225 - INFO - â”œâ”€â”€ Loss: 6.4037
2025-03-02 16:30:43,225 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:30:43,225 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:30:43,900 - INFO - ðŸªœ Batch step - 2478 -- sub batch step 9912 -- lr 3.00e-04
2025-03-02 16:30:46,046 - INFO - ðŸªœ Batch step - 2478 -- sub batch step 9913 -- lr 3.00e-04
2025-03-02 16:30:48,217 - INFO - ðŸªœ Batch step - 2478 -- sub batch step 9914 -- lr 3.00e-04
2025-03-02 16:30:50,370 - INFO - ðŸªœ Batch step - 2478 -- sub batch step 9915 -- lr 3.00e-04
2025-03-02 16:30:51,924 - INFO - Step 2478 -- ðŸ”„ Training Metrics
2025-03-02 16:30:51,924 - INFO - â”œâ”€â”€ Loss: 6.4067
2025-03-02 16:30:51,924 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:30:51,924 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:30:52,593 - INFO - ðŸªœ Batch step - 2479 -- sub batch step 9916 -- lr 3.00e-04
2025-03-02 16:30:54,747 - INFO - ðŸªœ Batch step - 2479 -- sub batch step 9917 -- lr 3.00e-04
2025-03-02 16:30:57,022 - INFO - ðŸªœ Batch step - 2479 -- sub batch step 9918 -- lr 3.00e-04
2025-03-02 16:30:59,176 - INFO - ðŸªœ Batch step - 2479 -- sub batch step 9919 -- lr 3.00e-04
2025-03-02 16:31:00,719 - INFO - Step 2479 -- ðŸ”„ Training Metrics
2025-03-02 16:31:00,719 - INFO - â”œâ”€â”€ Loss: 6.4079
2025-03-02 16:31:00,719 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:31:00,719 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:31:02,005 - INFO - ðŸªœ Batch step - 2480 -- sub batch step 9920 -- lr 3.00e-04
2025-03-02 16:31:04,161 - INFO - ðŸªœ Batch step - 2480 -- sub batch step 9921 -- lr 3.00e-04
2025-03-02 16:31:06,322 - INFO - ðŸªœ Batch step - 2480 -- sub batch step 9922 -- lr 3.00e-04
2025-03-02 16:31:08,492 - INFO - ðŸªœ Batch step - 2480 -- sub batch step 9923 -- lr 3.00e-04
2025-03-02 16:31:10,123 - INFO - Step 2480 -- ðŸ”„ Training Metrics
2025-03-02 16:31:10,123 - INFO - â”œâ”€â”€ Loss: 6.4261
2025-03-02 16:31:10,123 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:31:10,123 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:31:10,802 - INFO - ðŸªœ Batch step - 2481 -- sub batch step 9924 -- lr 3.00e-04
2025-03-02 16:31:12,958 - INFO - ðŸªœ Batch step - 2481 -- sub batch step 9925 -- lr 3.00e-04
2025-03-02 16:31:15,107 - INFO - ðŸªœ Batch step - 2481 -- sub batch step 9926 -- lr 3.00e-04
2025-03-02 16:31:17,468 - INFO - ðŸªœ Batch step - 2481 -- sub batch step 9927 -- lr 3.00e-04
2025-03-02 16:31:19,214 - INFO - Step 2481 -- ðŸ”„ Training Metrics
2025-03-02 16:31:19,215 - INFO - â”œâ”€â”€ Loss: 6.4154
2025-03-02 16:31:19,215 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:31:19,215 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:31:19,882 - INFO - ðŸªœ Batch step - 2482 -- sub batch step 9928 -- lr 3.00e-04
2025-03-02 16:31:22,035 - INFO - ðŸªœ Batch step - 2482 -- sub batch step 9929 -- lr 3.00e-04
2025-03-02 16:31:24,185 - INFO - ðŸªœ Batch step - 2482 -- sub batch step 9930 -- lr 3.00e-04
2025-03-02 16:31:26,349 - INFO - ðŸªœ Batch step - 2482 -- sub batch step 9931 -- lr 3.00e-04
2025-03-02 16:31:27,920 - INFO - Step 2482 -- ðŸ”„ Training Metrics
2025-03-02 16:31:27,920 - INFO - â”œâ”€â”€ Loss: 6.4159
2025-03-02 16:31:27,920 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:31:27,921 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:31:28,592 - INFO - ðŸªœ Batch step - 2483 -- sub batch step 9932 -- lr 3.00e-04
2025-03-02 16:31:30,736 - INFO - ðŸªœ Batch step - 2483 -- sub batch step 9933 -- lr 3.00e-04
2025-03-02 16:31:32,890 - INFO - ðŸªœ Batch step - 2483 -- sub batch step 9934 -- lr 3.00e-04
2025-03-02 16:31:35,242 - INFO - ðŸªœ Batch step - 2483 -- sub batch step 9935 -- lr 3.00e-04
2025-03-02 16:31:42,147 - INFO - Step 2483 -- ðŸ”„ Training Metrics
2025-03-02 16:31:42,147 - INFO - â”œâ”€â”€ Loss: 6.4031
2025-03-02 16:31:42,147 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:31:42,148 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:31:42,817 - INFO - ðŸªœ Batch step - 2484 -- sub batch step 9936 -- lr 3.00e-04
2025-03-02 16:31:44,968 - INFO - ðŸªœ Batch step - 2484 -- sub batch step 9937 -- lr 3.00e-04
2025-03-02 16:31:47,115 - INFO - ðŸªœ Batch step - 2484 -- sub batch step 9938 -- lr 3.00e-04
2025-03-02 16:31:49,283 - INFO - ðŸªœ Batch step - 2484 -- sub batch step 9939 -- lr 3.00e-04
2025-03-02 16:31:50,852 - INFO - Step 2484 -- ðŸ”„ Training Metrics
2025-03-02 16:31:50,852 - INFO - â”œâ”€â”€ Loss: 6.4134
2025-03-02 16:31:50,852 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:31:50,852 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:31:51,529 - INFO - ðŸªœ Batch step - 2485 -- sub batch step 9940 -- lr 3.00e-04
2025-03-02 16:31:53,675 - INFO - ðŸªœ Batch step - 2485 -- sub batch step 9941 -- lr 3.00e-04
2025-03-02 16:31:55,827 - INFO - ðŸªœ Batch step - 2485 -- sub batch step 9942 -- lr 3.00e-04
2025-03-02 16:31:58,440 - INFO - ðŸªœ Batch step - 2485 -- sub batch step 9943 -- lr 3.00e-04
2025-03-02 16:32:00,404 - INFO - Step 2485 -- ðŸ”„ Training Metrics
2025-03-02 16:32:00,405 - INFO - â”œâ”€â”€ Loss: 6.4053
2025-03-02 16:32:00,405 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:32:00,405 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:32:01,080 - INFO - ðŸªœ Batch step - 2486 -- sub batch step 9944 -- lr 3.00e-04
2025-03-02 16:32:03,233 - INFO - ðŸªœ Batch step - 2486 -- sub batch step 9945 -- lr 3.00e-04
2025-03-02 16:32:05,378 - INFO - ðŸªœ Batch step - 2486 -- sub batch step 9946 -- lr 3.00e-04
2025-03-02 16:32:07,545 - INFO - ðŸªœ Batch step - 2486 -- sub batch step 9947 -- lr 3.00e-04
2025-03-02 16:32:09,125 - INFO - Step 2486 -- ðŸ”„ Training Metrics
2025-03-02 16:32:09,125 - INFO - â”œâ”€â”€ Loss: 6.3871
2025-03-02 16:32:09,125 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:32:09,125 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:32:09,791 - INFO - ðŸªœ Batch step - 2487 -- sub batch step 9948 -- lr 3.00e-04
2025-03-02 16:32:11,949 - INFO - ðŸªœ Batch step - 2487 -- sub batch step 9949 -- lr 3.00e-04
2025-03-02 16:32:14,105 - INFO - ðŸªœ Batch step - 2487 -- sub batch step 9950 -- lr 3.00e-04
2025-03-02 16:32:16,519 - INFO - ðŸªœ Batch step - 2487 -- sub batch step 9951 -- lr 3.00e-04
2025-03-02 16:32:18,483 - INFO - Step 2487 -- ðŸ”„ Training Metrics
2025-03-02 16:32:18,484 - INFO - â”œâ”€â”€ Loss: 6.4036
2025-03-02 16:32:18,484 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:32:18,484 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:32:19,156 - INFO - ðŸªœ Batch step - 2488 -- sub batch step 9952 -- lr 3.00e-04
2025-03-02 16:32:21,300 - INFO - ðŸªœ Batch step - 2488 -- sub batch step 9953 -- lr 3.00e-04
2025-03-02 16:32:23,454 - INFO - ðŸªœ Batch step - 2488 -- sub batch step 9954 -- lr 3.00e-04
2025-03-02 16:32:25,626 - INFO - ðŸªœ Batch step - 2488 -- sub batch step 9955 -- lr 3.00e-04
2025-03-02 16:32:27,183 - INFO - Step 2488 -- ðŸ”„ Training Metrics
2025-03-02 16:32:27,211 - INFO - â”œâ”€â”€ Loss: 6.4092
2025-03-02 16:32:27,211 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:32:27,211 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:32:27,879 - INFO - ðŸªœ Batch step - 2489 -- sub batch step 9956 -- lr 3.00e-04
2025-03-02 16:32:30,036 - INFO - ðŸªœ Batch step - 2489 -- sub batch step 9957 -- lr 3.00e-04
2025-03-02 16:32:32,182 - INFO - ðŸªœ Batch step - 2489 -- sub batch step 9958 -- lr 3.00e-04
2025-03-02 16:32:34,866 - INFO - ðŸªœ Batch step - 2489 -- sub batch step 9959 -- lr 3.00e-04
2025-03-02 16:32:36,424 - INFO - Step 2489 -- ðŸ”„ Training Metrics
2025-03-02 16:32:36,425 - INFO - â”œâ”€â”€ Loss: 6.4049
2025-03-02 16:32:36,425 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:32:36,425 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:32:37,098 - INFO - ðŸªœ Batch step - 2490 -- sub batch step 9960 -- lr 3.00e-04
2025-03-02 16:32:39,247 - INFO - ðŸªœ Batch step - 2490 -- sub batch step 9961 -- lr 3.00e-04
2025-03-02 16:32:41,401 - INFO - ðŸªœ Batch step - 2490 -- sub batch step 9962 -- lr 3.00e-04
2025-03-02 16:32:43,566 - INFO - ðŸªœ Batch step - 2490 -- sub batch step 9963 -- lr 3.00e-04
2025-03-02 16:32:45,127 - INFO - Step 2490 -- ðŸ”„ Training Metrics
2025-03-02 16:32:45,127 - INFO - â”œâ”€â”€ Loss: 6.3727
2025-03-02 16:32:45,127 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:32:45,127 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:32:45,800 - INFO - ðŸªœ Batch step - 2491 -- sub batch step 9964 -- lr 3.00e-04
2025-03-02 16:32:47,953 - INFO - ðŸªœ Batch step - 2491 -- sub batch step 9965 -- lr 3.00e-04
2025-03-02 16:32:50,796 - INFO - ðŸªœ Batch step - 2491 -- sub batch step 9966 -- lr 3.00e-04
2025-03-02 16:32:52,950 - INFO - ðŸªœ Batch step - 2491 -- sub batch step 9967 -- lr 3.00e-04
2025-03-02 16:32:54,450 - INFO - Step 2491 -- ðŸ”„ Training Metrics
2025-03-02 16:32:54,450 - INFO - â”œâ”€â”€ Loss: 6.4124
2025-03-02 16:32:54,450 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:32:54,450 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:32:55,119 - INFO - ðŸªœ Batch step - 2492 -- sub batch step 9968 -- lr 3.00e-04
2025-03-02 16:32:57,272 - INFO - ðŸªœ Batch step - 2492 -- sub batch step 9969 -- lr 3.00e-04
2025-03-02 16:32:59,438 - INFO - ðŸªœ Batch step - 2492 -- sub batch step 9970 -- lr 3.00e-04
2025-03-02 16:33:01,587 - INFO - ðŸªœ Batch step - 2492 -- sub batch step 9971 -- lr 3.00e-04
2025-03-02 16:33:03,156 - INFO - Step 2492 -- ðŸ”„ Training Metrics
2025-03-02 16:33:03,156 - INFO - â”œâ”€â”€ Loss: 6.3791
2025-03-02 16:33:03,157 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:33:03,157 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:33:03,832 - INFO - ðŸªœ Batch step - 2493 -- sub batch step 9972 -- lr 3.00e-04
2025-03-02 16:33:05,981 - INFO - ðŸªœ Batch step - 2493 -- sub batch step 9973 -- lr 3.00e-04
2025-03-02 16:33:08,691 - INFO - ðŸªœ Batch step - 2493 -- sub batch step 9974 -- lr 3.00e-04
2025-03-02 16:33:10,845 - INFO - ðŸªœ Batch step - 2493 -- sub batch step 9975 -- lr 3.00e-04
2025-03-02 16:33:12,498 - INFO - Step 2493 -- ðŸ”„ Training Metrics
2025-03-02 16:33:12,498 - INFO - â”œâ”€â”€ Loss: 6.4202
2025-03-02 16:33:12,498 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:33:12,498 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:33:13,165 - INFO - ðŸªœ Batch step - 2494 -- sub batch step 9976 -- lr 3.00e-04
2025-03-02 16:33:15,313 - INFO - ðŸªœ Batch step - 2494 -- sub batch step 9977 -- lr 3.00e-04
2025-03-02 16:33:17,474 - INFO - ðŸªœ Batch step - 2494 -- sub batch step 9978 -- lr 3.00e-04
2025-03-02 16:33:19,631 - INFO - ðŸªœ Batch step - 2494 -- sub batch step 9979 -- lr 3.00e-04
2025-03-02 16:33:21,188 - INFO - Step 2494 -- ðŸ”„ Training Metrics
2025-03-02 16:33:21,189 - INFO - â”œâ”€â”€ Loss: 6.3814
2025-03-02 16:33:21,189 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:33:21,189 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:33:21,859 - INFO - ðŸªœ Batch step - 2495 -- sub batch step 9980 -- lr 3.00e-04
2025-03-02 16:33:24,008 - INFO - ðŸªœ Batch step - 2495 -- sub batch step 9981 -- lr 3.00e-04
2025-03-02 16:33:26,656 - INFO - ðŸªœ Batch step - 2495 -- sub batch step 9982 -- lr 3.00e-04
2025-03-02 16:33:28,803 - INFO - ðŸªœ Batch step - 2495 -- sub batch step 9983 -- lr 3.00e-04
2025-03-02 16:33:30,330 - INFO - Step 2495 -- ðŸ”„ Training Metrics
2025-03-02 16:33:30,330 - INFO - â”œâ”€â”€ Loss: 6.3884
2025-03-02 16:33:30,330 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:33:30,330 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:33:31,003 - INFO - ðŸªœ Batch step - 2496 -- sub batch step 9984 -- lr 3.00e-04
2025-03-02 16:33:33,151 - INFO - ðŸªœ Batch step - 2496 -- sub batch step 9985 -- lr 3.00e-04
2025-03-02 16:33:35,310 - INFO - ðŸªœ Batch step - 2496 -- sub batch step 9986 -- lr 3.00e-04
2025-03-02 16:33:37,461 - INFO - ðŸªœ Batch step - 2496 -- sub batch step 9987 -- lr 3.00e-04
2025-03-02 16:33:39,030 - INFO - Step 2496 -- ðŸ”„ Training Metrics
2025-03-02 16:33:39,031 - INFO - â”œâ”€â”€ Loss: 6.3950
2025-03-02 16:33:39,031 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:33:39,031 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:33:39,700 - INFO - ðŸªœ Batch step - 2497 -- sub batch step 9988 -- lr 3.00e-04
2025-03-02 16:33:41,851 - INFO - ðŸªœ Batch step - 2497 -- sub batch step 9989 -- lr 3.00e-04
2025-03-02 16:33:44,471 - INFO - ðŸªœ Batch step - 2497 -- sub batch step 9990 -- lr 3.00e-04
2025-03-02 16:33:46,614 - INFO - ðŸªœ Batch step - 2497 -- sub batch step 9991 -- lr 3.00e-04
2025-03-02 16:33:48,338 - INFO - Step 2497 -- ðŸ”„ Training Metrics
2025-03-02 16:33:48,339 - INFO - â”œâ”€â”€ Loss: 6.4310
2025-03-02 16:33:48,339 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:33:48,339 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:33:49,012 - INFO - ðŸªœ Batch step - 2498 -- sub batch step 9992 -- lr 3.00e-04
2025-03-02 16:33:51,157 - INFO - ðŸªœ Batch step - 2498 -- sub batch step 9993 -- lr 3.00e-04
2025-03-02 16:33:53,324 - INFO - ðŸªœ Batch step - 2498 -- sub batch step 9994 -- lr 3.00e-04
2025-03-02 16:33:55,474 - INFO - ðŸªœ Batch step - 2498 -- sub batch step 9995 -- lr 3.00e-04
2025-03-02 16:33:57,037 - INFO - Step 2498 -- ðŸ”„ Training Metrics
2025-03-02 16:33:57,037 - INFO - â”œâ”€â”€ Loss: 6.3915
2025-03-02 16:33:57,037 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:33:57,037 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:33:57,702 - INFO - ðŸªœ Batch step - 2499 -- sub batch step 9996 -- lr 3.00e-04
2025-03-02 16:33:59,852 - INFO - ðŸªœ Batch step - 2499 -- sub batch step 9997 -- lr 3.00e-04
2025-03-02 16:34:02,432 - INFO - ðŸªœ Batch step - 2499 -- sub batch step 9998 -- lr 3.00e-04
2025-03-02 16:34:04,584 - INFO - ðŸªœ Batch step - 2499 -- sub batch step 9999 -- lr 3.00e-04
2025-03-02 16:34:06,079 - INFO - Step 2499 -- ðŸ”„ Training Metrics
2025-03-02 16:34:06,080 - INFO - â”œâ”€â”€ Loss: 6.3894
2025-03-02 16:34:06,080 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:34:06,080 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:34:07,323 - INFO - ðŸªœ Batch step - 2500 -- sub batch step 10000 -- lr 3.00e-04
2025-03-02 16:34:09,480 - INFO - ðŸªœ Batch step - 2500 -- sub batch step 10001 -- lr 3.00e-04
2025-03-02 16:34:11,640 - INFO - ðŸªœ Batch step - 2500 -- sub batch step 10002 -- lr 3.00e-04
2025-03-02 16:34:13,816 - INFO - ðŸªœ Batch step - 2500 -- sub batch step 10003 -- lr 3.00e-04
2025-03-02 16:34:21,186 - INFO - Step 2500 -- ðŸ”„ Training Metrics
2025-03-02 16:34:21,186 - INFO - â”œâ”€â”€ Loss: 6.4270
2025-03-02 16:34:21,187 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:34:21,187 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:34:21,861 - INFO - ðŸªœ Batch step - 2501 -- sub batch step 10004 -- lr 3.00e-04
2025-03-02 16:34:24,016 - INFO - ðŸªœ Batch step - 2501 -- sub batch step 10005 -- lr 3.00e-04
2025-03-02 16:34:26,162 - INFO - ðŸªœ Batch step - 2501 -- sub batch step 10006 -- lr 3.00e-04
2025-03-02 16:34:28,775 - INFO - ðŸªœ Batch step - 2501 -- sub batch step 10007 -- lr 3.00e-04
2025-03-02 16:34:30,279 - INFO - Step 2501 -- ðŸ”„ Training Metrics
2025-03-02 16:34:30,279 - INFO - â”œâ”€â”€ Loss: 6.3994
2025-03-02 16:34:30,279 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:34:30,280 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:34:30,945 - INFO - ðŸªœ Batch step - 2502 -- sub batch step 10008 -- lr 3.00e-04
2025-03-02 16:34:33,105 - INFO - ðŸªœ Batch step - 2502 -- sub batch step 10009 -- lr 3.00e-04
2025-03-02 16:34:35,263 - INFO - ðŸªœ Batch step - 2502 -- sub batch step 10010 -- lr 3.00e-04
2025-03-02 16:34:37,426 - INFO - ðŸªœ Batch step - 2502 -- sub batch step 10011 -- lr 3.00e-04
2025-03-02 16:34:38,976 - INFO - Step 2502 -- ðŸ”„ Training Metrics
2025-03-02 16:34:38,976 - INFO - â”œâ”€â”€ Loss: 6.3847
2025-03-02 16:34:38,977 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:34:38,977 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:34:39,651 - INFO - ðŸªœ Batch step - 2503 -- sub batch step 10012 -- lr 3.00e-04
2025-03-02 16:34:41,803 - INFO - ðŸªœ Batch step - 2503 -- sub batch step 10013 -- lr 3.00e-04
2025-03-02 16:34:43,959 - INFO - ðŸªœ Batch step - 2503 -- sub batch step 10014 -- lr 3.00e-04
2025-03-02 16:34:46,637 - INFO - ðŸªœ Batch step - 2503 -- sub batch step 10015 -- lr 3.00e-04
2025-03-02 16:34:54,243 - INFO - Step 2503 -- ðŸ”„ Training Metrics
2025-03-02 16:34:54,244 - INFO - â”œâ”€â”€ Loss: 6.3911
2025-03-02 16:34:54,244 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:34:54,244 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:34:54,910 - INFO - ðŸªœ Batch step - 2504 -- sub batch step 10016 -- lr 3.00e-04
2025-03-02 16:34:57,064 - INFO - ðŸªœ Batch step - 2504 -- sub batch step 10017 -- lr 3.00e-04
2025-03-02 16:34:59,214 - INFO - ðŸªœ Batch step - 2504 -- sub batch step 10018 -- lr 3.00e-04
2025-03-02 16:35:01,391 - INFO - ðŸªœ Batch step - 2504 -- sub batch step 10019 -- lr 3.00e-04
2025-03-02 16:35:02,932 - INFO - Step 2504 -- ðŸ”„ Training Metrics
2025-03-02 16:35:02,933 - INFO - â”œâ”€â”€ Loss: 6.4236
2025-03-02 16:35:02,933 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:35:02,933 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:35:03,608 - INFO - ðŸªœ Batch step - 2505 -- sub batch step 10020 -- lr 3.00e-04
2025-03-02 16:35:05,759 - INFO - ðŸªœ Batch step - 2505 -- sub batch step 10021 -- lr 3.00e-04
2025-03-02 16:35:07,911 - INFO - ðŸªœ Batch step - 2505 -- sub batch step 10022 -- lr 3.00e-04
2025-03-02 16:35:10,546 - INFO - ðŸªœ Batch step - 2505 -- sub batch step 10023 -- lr 3.00e-04
2025-03-02 16:35:12,242 - INFO - Step 2505 -- ðŸ”„ Training Metrics
2025-03-02 16:35:12,242 - INFO - â”œâ”€â”€ Loss: 6.3951
2025-03-02 16:35:12,242 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:35:12,243 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:35:12,925 - INFO - ðŸªœ Batch step - 2506 -- sub batch step 10024 -- lr 3.00e-04
2025-03-02 16:35:15,090 - INFO - ðŸªœ Batch step - 2506 -- sub batch step 10025 -- lr 3.00e-04
2025-03-02 16:35:17,246 - INFO - ðŸªœ Batch step - 2506 -- sub batch step 10026 -- lr 3.00e-04
2025-03-02 16:35:19,431 - INFO - ðŸªœ Batch step - 2506 -- sub batch step 10027 -- lr 3.00e-04
2025-03-02 16:35:20,943 - INFO - Step 2506 -- ðŸ”„ Training Metrics
2025-03-02 16:35:20,943 - INFO - â”œâ”€â”€ Loss: 6.3929
2025-03-02 16:35:20,943 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:35:20,943 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:35:21,617 - INFO - ðŸªœ Batch step - 2507 -- sub batch step 10028 -- lr 3.00e-04
2025-03-02 16:35:23,784 - INFO - ðŸªœ Batch step - 2507 -- sub batch step 10029 -- lr 3.00e-04
2025-03-02 16:35:25,945 - INFO - ðŸªœ Batch step - 2507 -- sub batch step 10030 -- lr 3.00e-04
2025-03-02 16:35:28,340 - INFO - ðŸªœ Batch step - 2507 -- sub batch step 10031 -- lr 3.00e-04
2025-03-02 16:35:30,134 - INFO - Step 2507 -- ðŸ”„ Training Metrics
2025-03-02 16:35:30,134 - INFO - â”œâ”€â”€ Loss: 6.3992
2025-03-02 16:35:30,134 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:35:30,134 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:35:30,815 - INFO - ðŸªœ Batch step - 2508 -- sub batch step 10032 -- lr 3.00e-04
2025-03-02 16:35:32,967 - INFO - ðŸªœ Batch step - 2508 -- sub batch step 10033 -- lr 3.00e-04
2025-03-02 16:35:35,124 - INFO - ðŸªœ Batch step - 2508 -- sub batch step 10034 -- lr 3.00e-04
2025-03-02 16:35:37,303 - INFO - ðŸªœ Batch step - 2508 -- sub batch step 10035 -- lr 3.00e-04
2025-03-02 16:35:38,838 - INFO - Step 2508 -- ðŸ”„ Training Metrics
2025-03-02 16:35:38,838 - INFO - â”œâ”€â”€ Loss: 6.4077
2025-03-02 16:35:38,838 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:35:38,838 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:35:39,512 - INFO - ðŸªœ Batch step - 2509 -- sub batch step 10036 -- lr 3.00e-04
2025-03-02 16:35:41,668 - INFO - ðŸªœ Batch step - 2509 -- sub batch step 10037 -- lr 3.00e-04
2025-03-02 16:35:43,818 - INFO - ðŸªœ Batch step - 2509 -- sub batch step 10038 -- lr 3.00e-04
2025-03-02 16:35:46,515 - INFO - ðŸªœ Batch step - 2509 -- sub batch step 10039 -- lr 3.00e-04
2025-03-02 16:35:48,148 - INFO - Step 2509 -- ðŸ”„ Training Metrics
2025-03-02 16:35:48,149 - INFO - â”œâ”€â”€ Loss: 6.3991
2025-03-02 16:35:48,149 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:35:48,149 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:35:48,820 - INFO - ðŸªœ Batch step - 2510 -- sub batch step 10040 -- lr 3.00e-04
2025-03-02 16:35:50,971 - INFO - ðŸªœ Batch step - 2510 -- sub batch step 10041 -- lr 3.00e-04
2025-03-02 16:35:53,128 - INFO - ðŸªœ Batch step - 2510 -- sub batch step 10042 -- lr 3.00e-04
2025-03-02 16:35:55,294 - INFO - ðŸªœ Batch step - 2510 -- sub batch step 10043 -- lr 3.00e-04
2025-03-02 16:35:56,843 - INFO - Step 2510 -- ðŸ”„ Training Metrics
2025-03-02 16:35:56,843 - INFO - â”œâ”€â”€ Loss: 6.3744
2025-03-02 16:35:56,843 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:35:56,843 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:35:57,514 - INFO - ðŸªœ Batch step - 2511 -- sub batch step 10044 -- lr 3.00e-04
2025-03-02 16:35:59,670 - INFO - ðŸªœ Batch step - 2511 -- sub batch step 10045 -- lr 3.00e-04
2025-03-02 16:36:02,311 - INFO - ðŸªœ Batch step - 2511 -- sub batch step 10046 -- lr 3.00e-04
2025-03-02 16:36:04,467 - INFO - ðŸªœ Batch step - 2511 -- sub batch step 10047 -- lr 3.00e-04
2025-03-02 16:36:06,427 - INFO - Step 2511 -- ðŸ”„ Training Metrics
2025-03-02 16:36:06,427 - INFO - â”œâ”€â”€ Loss: 6.3839
2025-03-02 16:36:06,428 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:36:06,428 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:36:07,094 - INFO - ðŸªœ Batch step - 2512 -- sub batch step 10048 -- lr 3.00e-04
2025-03-02 16:36:09,249 - INFO - ðŸªœ Batch step - 2512 -- sub batch step 10049 -- lr 3.00e-04
2025-03-02 16:36:11,423 - INFO - ðŸªœ Batch step - 2512 -- sub batch step 10050 -- lr 3.00e-04
2025-03-02 16:36:13,571 - INFO - ðŸªœ Batch step - 2512 -- sub batch step 10051 -- lr 3.00e-04
2025-03-02 16:36:15,124 - INFO - Step 2512 -- ðŸ”„ Training Metrics
2025-03-02 16:36:15,125 - INFO - â”œâ”€â”€ Loss: 6.4055
2025-03-02 16:36:15,125 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:36:15,125 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:36:15,794 - INFO - ðŸªœ Batch step - 2513 -- sub batch step 10052 -- lr 3.00e-04
2025-03-02 16:36:18,275 - INFO - ðŸªœ Batch step - 2513 -- sub batch step 10053 -- lr 3.00e-04
2025-03-02 16:36:20,913 - INFO - ðŸªœ Batch step - 2513 -- sub batch step 10054 -- lr 3.00e-04
2025-03-02 16:36:23,065 - INFO - ðŸªœ Batch step - 2513 -- sub batch step 10055 -- lr 3.00e-04
2025-03-02 16:36:24,897 - INFO - Step 2513 -- ðŸ”„ Training Metrics
2025-03-02 16:36:24,897 - INFO - â”œâ”€â”€ Loss: 6.4127
2025-03-02 16:36:24,897 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:36:24,897 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:36:25,894 - INFO - ðŸªœ Batch step - 2514 -- sub batch step 10056 -- lr 3.00e-04
2025-03-02 16:36:28,049 - INFO - ðŸªœ Batch step - 2514 -- sub batch step 10057 -- lr 3.00e-04
2025-03-02 16:36:30,217 - INFO - ðŸªœ Batch step - 2514 -- sub batch step 10058 -- lr 3.00e-04
2025-03-02 16:36:32,377 - INFO - ðŸªœ Batch step - 2514 -- sub batch step 10059 -- lr 3.00e-04
2025-03-02 16:36:33,926 - INFO - Step 2514 -- ðŸ”„ Training Metrics
2025-03-02 16:36:33,926 - INFO - â”œâ”€â”€ Loss: 6.3906
2025-03-02 16:36:33,926 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:36:33,926 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:36:34,598 - INFO - ðŸªœ Batch step - 2515 -- sub batch step 10060 -- lr 3.00e-04
2025-03-02 16:36:36,754 - INFO - ðŸªœ Batch step - 2515 -- sub batch step 10061 -- lr 3.00e-04
2025-03-02 16:36:39,152 - INFO - ðŸªœ Batch step - 2515 -- sub batch step 10062 -- lr 3.00e-04
2025-03-02 16:36:41,299 - INFO - ðŸªœ Batch step - 2515 -- sub batch step 10063 -- lr 3.00e-04
2025-03-02 16:36:43,275 - INFO - Step 2515 -- ðŸ”„ Training Metrics
2025-03-02 16:36:43,276 - INFO - â”œâ”€â”€ Loss: 6.3970
2025-03-02 16:36:43,276 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:36:43,276 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:36:43,951 - INFO - ðŸªœ Batch step - 2516 -- sub batch step 10064 -- lr 3.00e-04
2025-03-02 16:36:46,102 - INFO - ðŸªœ Batch step - 2516 -- sub batch step 10065 -- lr 3.00e-04
2025-03-02 16:36:48,268 - INFO - ðŸªœ Batch step - 2516 -- sub batch step 10066 -- lr 3.00e-04
2025-03-02 16:36:50,420 - INFO - ðŸªœ Batch step - 2516 -- sub batch step 10067 -- lr 3.00e-04
2025-03-02 16:36:51,973 - INFO - Step 2516 -- ðŸ”„ Training Metrics
2025-03-02 16:36:51,974 - INFO - â”œâ”€â”€ Loss: 6.3907
2025-03-02 16:36:51,974 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:36:51,974 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:36:52,643 - INFO - ðŸªœ Batch step - 2517 -- sub batch step 10068 -- lr 3.00e-04
2025-03-02 16:36:54,804 - INFO - ðŸªœ Batch step - 2517 -- sub batch step 10069 -- lr 3.00e-04
2025-03-02 16:36:57,184 - INFO - ðŸªœ Batch step - 2517 -- sub batch step 10070 -- lr 3.00e-04
2025-03-02 16:36:59,334 - INFO - ðŸªœ Batch step - 2517 -- sub batch step 10071 -- lr 3.00e-04
2025-03-02 16:37:01,278 - INFO - Step 2517 -- ðŸ”„ Training Metrics
2025-03-02 16:37:01,279 - INFO - â”œâ”€â”€ Loss: 6.4077
2025-03-02 16:37:01,279 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:37:01,279 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:37:01,950 - INFO - ðŸªœ Batch step - 2518 -- sub batch step 10072 -- lr 3.00e-04
2025-03-02 16:37:04,101 - INFO - ðŸªœ Batch step - 2518 -- sub batch step 10073 -- lr 3.00e-04
2025-03-02 16:37:06,276 - INFO - ðŸªœ Batch step - 2518 -- sub batch step 10074 -- lr 3.00e-04
2025-03-02 16:37:08,442 - INFO - ðŸªœ Batch step - 2518 -- sub batch step 10075 -- lr 3.00e-04
2025-03-02 16:37:09,971 - INFO - Step 2518 -- ðŸ”„ Training Metrics
2025-03-02 16:37:09,971 - INFO - â”œâ”€â”€ Loss: 6.3837
2025-03-02 16:37:09,971 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:37:09,972 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:37:10,642 - INFO - ðŸªœ Batch step - 2519 -- sub batch step 10076 -- lr 3.00e-04
2025-03-02 16:37:12,796 - INFO - ðŸªœ Batch step - 2519 -- sub batch step 10077 -- lr 3.00e-04
2025-03-02 16:37:15,066 - INFO - ðŸªœ Batch step - 2519 -- sub batch step 10078 -- lr 3.00e-04
2025-03-02 16:37:17,226 - INFO - ðŸªœ Batch step - 2519 -- sub batch step 10079 -- lr 3.00e-04
2025-03-02 16:37:18,773 - INFO - Step 2519 -- ðŸ”„ Training Metrics
2025-03-02 16:37:18,774 - INFO - â”œâ”€â”€ Loss: 6.3735
2025-03-02 16:37:18,774 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:37:18,774 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:37:20,047 - INFO - ðŸªœ Batch step - 2520 -- sub batch step 10080 -- lr 3.00e-04
2025-03-02 16:37:22,196 - INFO - ðŸªœ Batch step - 2520 -- sub batch step 10081 -- lr 3.00e-04
2025-03-02 16:37:24,347 - INFO - ðŸªœ Batch step - 2520 -- sub batch step 10082 -- lr 3.00e-04
2025-03-02 16:37:26,507 - INFO - ðŸªœ Batch step - 2520 -- sub batch step 10083 -- lr 3.00e-04
2025-03-02 16:37:28,120 - INFO - Step 2520 -- ðŸ”„ Training Metrics
2025-03-02 16:37:28,120 - INFO - â”œâ”€â”€ Loss: 6.3879
2025-03-02 16:37:28,120 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:37:28,120 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:37:28,791 - INFO - ðŸªœ Batch step - 2521 -- sub batch step 10084 -- lr 3.00e-04
2025-03-02 16:37:30,940 - INFO - ðŸªœ Batch step - 2521 -- sub batch step 10085 -- lr 3.00e-04
2025-03-02 16:37:33,083 - INFO - ðŸªœ Batch step - 2521 -- sub batch step 10086 -- lr 3.00e-04
2025-03-02 16:37:35,701 - INFO - ðŸªœ Batch step - 2521 -- sub batch step 10087 -- lr 3.00e-04
2025-03-02 16:37:41,053 - INFO - Step 2521 -- ðŸ”„ Training Metrics
2025-03-02 16:37:41,053 - INFO - â”œâ”€â”€ Loss: 6.3740
2025-03-02 16:37:41,053 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:37:41,053 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:37:41,718 - INFO - ðŸªœ Batch step - 2522 -- sub batch step 10088 -- lr 3.00e-04
2025-03-02 16:37:43,876 - INFO - ðŸªœ Batch step - 2522 -- sub batch step 10089 -- lr 3.00e-04
2025-03-02 16:37:46,029 - INFO - ðŸªœ Batch step - 2522 -- sub batch step 10090 -- lr 3.00e-04
2025-03-02 16:37:48,191 - INFO - ðŸªœ Batch step - 2522 -- sub batch step 10091 -- lr 3.00e-04
2025-03-02 16:37:49,757 - INFO - Step 2522 -- ðŸ”„ Training Metrics
2025-03-02 16:37:49,757 - INFO - â”œâ”€â”€ Loss: 6.3754
2025-03-02 16:37:49,757 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:37:49,757 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:37:50,431 - INFO - ðŸªœ Batch step - 2523 -- sub batch step 10092 -- lr 3.00e-04
2025-03-02 16:37:52,576 - INFO - ðŸªœ Batch step - 2523 -- sub batch step 10093 -- lr 3.00e-04
2025-03-02 16:37:54,730 - INFO - ðŸªœ Batch step - 2523 -- sub batch step 10094 -- lr 3.00e-04
2025-03-02 16:37:57,181 - INFO - ðŸªœ Batch step - 2523 -- sub batch step 10095 -- lr 3.00e-04
2025-03-02 16:37:58,961 - INFO - Step 2523 -- ðŸ”„ Training Metrics
2025-03-02 16:37:58,961 - INFO - â”œâ”€â”€ Loss: 6.3640
2025-03-02 16:37:58,961 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:37:58,961 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:37:59,628 - INFO - ðŸªœ Batch step - 2524 -- sub batch step 10096 -- lr 3.00e-04
2025-03-02 16:38:01,778 - INFO - ðŸªœ Batch step - 2524 -- sub batch step 10097 -- lr 3.00e-04
2025-03-02 16:38:03,924 - INFO - ðŸªœ Batch step - 2524 -- sub batch step 10098 -- lr 3.00e-04
2025-03-02 16:38:06,094 - INFO - ðŸªœ Batch step - 2524 -- sub batch step 10099 -- lr 3.00e-04
2025-03-02 16:38:07,660 - INFO - Step 2524 -- ðŸ”„ Training Metrics
2025-03-02 16:38:07,661 - INFO - â”œâ”€â”€ Loss: 6.3999
2025-03-02 16:38:07,661 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:38:07,661 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:38:08,334 - INFO - ðŸªœ Batch step - 2525 -- sub batch step 10100 -- lr 3.00e-04
2025-03-02 16:38:10,480 - INFO - ðŸªœ Batch step - 2525 -- sub batch step 10101 -- lr 3.00e-04
2025-03-02 16:38:12,633 - INFO - ðŸªœ Batch step - 2525 -- sub batch step 10102 -- lr 3.00e-04
2025-03-02 16:38:15,062 - INFO - ðŸªœ Batch step - 2525 -- sub batch step 10103 -- lr 3.00e-04
2025-03-02 16:38:16,902 - INFO - Step 2525 -- ðŸ”„ Training Metrics
2025-03-02 16:38:16,902 - INFO - â”œâ”€â”€ Loss: 6.3813
2025-03-02 16:38:16,902 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:38:16,902 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:38:17,574 - INFO - ðŸªœ Batch step - 2526 -- sub batch step 10104 -- lr 3.00e-04
2025-03-02 16:38:19,724 - INFO - ðŸªœ Batch step - 2526 -- sub batch step 10105 -- lr 3.00e-04
2025-03-02 16:38:21,868 - INFO - ðŸªœ Batch step - 2526 -- sub batch step 10106 -- lr 3.00e-04
2025-03-02 16:38:24,037 - INFO - ðŸªœ Batch step - 2526 -- sub batch step 10107 -- lr 3.00e-04
2025-03-02 16:38:25,608 - INFO - Step 2526 -- ðŸ”„ Training Metrics
2025-03-02 16:38:25,608 - INFO - â”œâ”€â”€ Loss: 6.4114
2025-03-02 16:38:25,608 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:38:25,609 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:38:26,275 - INFO - ðŸªœ Batch step - 2527 -- sub batch step 10108 -- lr 3.00e-04
2025-03-02 16:38:28,426 - INFO - ðŸªœ Batch step - 2527 -- sub batch step 10109 -- lr 3.00e-04
2025-03-02 16:38:30,576 - INFO - ðŸªœ Batch step - 2527 -- sub batch step 10110 -- lr 3.00e-04
2025-03-02 16:38:33,153 - INFO - ðŸªœ Batch step - 2527 -- sub batch step 10111 -- lr 3.00e-04
2025-03-02 16:38:34,840 - INFO - Step 2527 -- ðŸ”„ Training Metrics
2025-03-02 16:38:34,840 - INFO - â”œâ”€â”€ Loss: 6.3961
2025-03-02 16:38:34,840 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:38:34,840 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:38:35,510 - INFO - ðŸªœ Batch step - 2528 -- sub batch step 10112 -- lr 3.00e-04
2025-03-02 16:38:37,654 - INFO - ðŸªœ Batch step - 2528 -- sub batch step 10113 -- lr 3.00e-04
2025-03-02 16:38:39,809 - INFO - ðŸªœ Batch step - 2528 -- sub batch step 10114 -- lr 3.00e-04
2025-03-02 16:38:41,977 - INFO - ðŸªœ Batch step - 2528 -- sub batch step 10115 -- lr 3.00e-04
2025-03-02 16:38:43,549 - INFO - Step 2528 -- ðŸ”„ Training Metrics
2025-03-02 16:38:43,550 - INFO - â”œâ”€â”€ Loss: 6.3914
2025-03-02 16:38:43,550 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:38:43,550 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:38:44,220 - INFO - ðŸªœ Batch step - 2529 -- sub batch step 10116 -- lr 3.00e-04
2025-03-02 16:38:46,373 - INFO - ðŸªœ Batch step - 2529 -- sub batch step 10117 -- lr 3.00e-04
2025-03-02 16:38:48,517 - INFO - ðŸªœ Batch step - 2529 -- sub batch step 10118 -- lr 3.00e-04
2025-03-02 16:38:51,097 - INFO - ðŸªœ Batch step - 2529 -- sub batch step 10119 -- lr 3.00e-04
2025-03-02 16:38:52,707 - INFO - Step 2529 -- ðŸ”„ Training Metrics
2025-03-02 16:38:52,707 - INFO - â”œâ”€â”€ Loss: 6.3623
2025-03-02 16:38:52,708 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:38:52,708 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:38:53,380 - INFO - ðŸªœ Batch step - 2530 -- sub batch step 10120 -- lr 3.00e-04
2025-03-02 16:38:55,522 - INFO - ðŸªœ Batch step - 2530 -- sub batch step 10121 -- lr 3.00e-04
2025-03-02 16:38:57,676 - INFO - ðŸªœ Batch step - 2530 -- sub batch step 10122 -- lr 3.00e-04
2025-03-02 16:38:59,837 - INFO - ðŸªœ Batch step - 2530 -- sub batch step 10123 -- lr 3.00e-04
2025-03-02 16:39:01,395 - INFO - Step 2530 -- ðŸ”„ Training Metrics
2025-03-02 16:39:01,396 - INFO - â”œâ”€â”€ Loss: 6.3645
2025-03-02 16:39:01,396 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:39:01,396 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:39:02,070 - INFO - ðŸªœ Batch step - 2531 -- sub batch step 10124 -- lr 3.00e-04
2025-03-02 16:39:04,222 - INFO - ðŸªœ Batch step - 2531 -- sub batch step 10125 -- lr 3.00e-04
2025-03-02 16:39:06,825 - INFO - ðŸªœ Batch step - 2531 -- sub batch step 10126 -- lr 3.00e-04
2025-03-02 16:39:08,975 - INFO - ðŸªœ Batch step - 2531 -- sub batch step 10127 -- lr 3.00e-04
2025-03-02 16:39:10,570 - INFO - Step 2531 -- ðŸ”„ Training Metrics
2025-03-02 16:39:10,571 - INFO - â”œâ”€â”€ Loss: 6.4148
2025-03-02 16:39:10,571 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:39:10,571 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:39:11,245 - INFO - ðŸªœ Batch step - 2532 -- sub batch step 10128 -- lr 3.00e-04
2025-03-02 16:39:13,397 - INFO - ðŸªœ Batch step - 2532 -- sub batch step 10129 -- lr 3.00e-04
2025-03-02 16:39:15,575 - INFO - ðŸªœ Batch step - 2532 -- sub batch step 10130 -- lr 3.00e-04
2025-03-02 16:39:17,725 - INFO - ðŸªœ Batch step - 2532 -- sub batch step 10131 -- lr 3.00e-04
2025-03-02 16:39:19,279 - INFO - Step 2532 -- ðŸ”„ Training Metrics
2025-03-02 16:39:19,280 - INFO - â”œâ”€â”€ Loss: 6.3686
2025-03-02 16:39:19,280 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:39:19,280 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:39:19,951 - INFO - ðŸªœ Batch step - 2533 -- sub batch step 10132 -- lr 3.00e-04
2025-03-02 16:39:22,096 - INFO - ðŸªœ Batch step - 2533 -- sub batch step 10133 -- lr 3.00e-04
2025-03-02 16:39:24,693 - INFO - ðŸªœ Batch step - 2533 -- sub batch step 10134 -- lr 3.00e-04
2025-03-02 16:39:26,847 - INFO - ðŸªœ Batch step - 2533 -- sub batch step 10135 -- lr 3.00e-04
2025-03-02 16:39:28,474 - INFO - Step 2533 -- ðŸ”„ Training Metrics
2025-03-02 16:39:28,475 - INFO - â”œâ”€â”€ Loss: 6.3625
2025-03-02 16:39:28,475 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:39:28,475 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:39:29,141 - INFO - ðŸªœ Batch step - 2534 -- sub batch step 10136 -- lr 3.00e-04
2025-03-02 16:39:31,291 - INFO - ðŸªœ Batch step - 2534 -- sub batch step 10137 -- lr 3.00e-04
2025-03-02 16:39:33,455 - INFO - ðŸªœ Batch step - 2534 -- sub batch step 10138 -- lr 3.00e-04
2025-03-02 16:39:35,609 - INFO - ðŸªœ Batch step - 2534 -- sub batch step 10139 -- lr 3.00e-04
2025-03-02 16:39:37,185 - INFO - Step 2534 -- ðŸ”„ Training Metrics
2025-03-02 16:39:37,185 - INFO - â”œâ”€â”€ Loss: 6.3570
2025-03-02 16:39:37,185 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:39:37,185 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:39:37,857 - INFO - ðŸªœ Batch step - 2535 -- sub batch step 10140 -- lr 3.00e-04
2025-03-02 16:39:40,005 - INFO - ðŸªœ Batch step - 2535 -- sub batch step 10141 -- lr 3.00e-04
2025-03-02 16:39:42,374 - INFO - ðŸªœ Batch step - 2535 -- sub batch step 10142 -- lr 3.00e-04
2025-03-02 16:39:44,521 - INFO - ðŸªœ Batch step - 2535 -- sub batch step 10143 -- lr 3.00e-04
2025-03-02 16:39:46,339 - INFO - Step 2535 -- ðŸ”„ Training Metrics
2025-03-02 16:39:46,340 - INFO - â”œâ”€â”€ Loss: 6.3719
2025-03-02 16:39:46,340 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:39:46,340 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:39:47,010 - INFO - ðŸªœ Batch step - 2536 -- sub batch step 10144 -- lr 3.00e-04
2025-03-02 16:39:49,159 - INFO - ðŸªœ Batch step - 2536 -- sub batch step 10145 -- lr 3.00e-04
2025-03-02 16:39:51,324 - INFO - ðŸªœ Batch step - 2536 -- sub batch step 10146 -- lr 3.00e-04
2025-03-02 16:39:53,476 - INFO - ðŸªœ Batch step - 2536 -- sub batch step 10147 -- lr 3.00e-04
2025-03-02 16:39:55,044 - INFO - Step 2536 -- ðŸ”„ Training Metrics
2025-03-02 16:39:55,044 - INFO - â”œâ”€â”€ Loss: 6.3840
2025-03-02 16:39:55,044 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:39:55,044 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:39:55,709 - INFO - ðŸªœ Batch step - 2537 -- sub batch step 10148 -- lr 3.00e-04
2025-03-02 16:39:57,863 - INFO - ðŸªœ Batch step - 2537 -- sub batch step 10149 -- lr 3.00e-04
2025-03-02 16:40:00,275 - INFO - ðŸªœ Batch step - 2537 -- sub batch step 10150 -- lr 3.00e-04
2025-03-02 16:40:02,421 - INFO - ðŸªœ Batch step - 2537 -- sub batch step 10151 -- lr 3.00e-04
2025-03-02 16:40:04,251 - INFO - Step 2537 -- ðŸ”„ Training Metrics
2025-03-02 16:40:04,251 - INFO - â”œâ”€â”€ Loss: 6.3962
2025-03-02 16:40:04,252 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:40:04,252 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:40:04,928 - INFO - ðŸªœ Batch step - 2538 -- sub batch step 10152 -- lr 3.00e-04
2025-03-02 16:40:07,074 - INFO - ðŸªœ Batch step - 2538 -- sub batch step 10153 -- lr 3.00e-04
2025-03-02 16:40:09,243 - INFO - ðŸªœ Batch step - 2538 -- sub batch step 10154 -- lr 3.00e-04
2025-03-02 16:40:11,394 - INFO - ðŸªœ Batch step - 2538 -- sub batch step 10155 -- lr 3.00e-04
2025-03-02 16:40:12,974 - INFO - Step 2538 -- ðŸ”„ Training Metrics
2025-03-02 16:40:12,974 - INFO - â”œâ”€â”€ Loss: 6.3782
2025-03-02 16:40:12,974 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:40:12,974 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:40:13,642 - INFO - ðŸªœ Batch step - 2539 -- sub batch step 10156 -- lr 3.00e-04
2025-03-02 16:40:15,793 - INFO - ðŸªœ Batch step - 2539 -- sub batch step 10157 -- lr 3.00e-04
2025-03-02 16:40:18,084 - INFO - ðŸªœ Batch step - 2539 -- sub batch step 10158 -- lr 3.00e-04
2025-03-02 16:40:20,238 - INFO - ðŸªœ Batch step - 2539 -- sub batch step 10159 -- lr 3.00e-04
2025-03-02 16:40:21,993 - INFO - Step 2539 -- ðŸ”„ Training Metrics
2025-03-02 16:40:21,994 - INFO - â”œâ”€â”€ Loss: 6.3849
2025-03-02 16:40:21,994 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:40:21,994 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:40:23,215 - INFO - ðŸªœ Batch step - 2540 -- sub batch step 10160 -- lr 3.00e-04
2025-03-02 16:40:25,365 - INFO - ðŸªœ Batch step - 2540 -- sub batch step 10161 -- lr 3.00e-04
2025-03-02 16:40:27,519 - INFO - ðŸªœ Batch step - 2540 -- sub batch step 10162 -- lr 3.00e-04
2025-03-02 16:40:29,685 - INFO - ðŸªœ Batch step - 2540 -- sub batch step 10163 -- lr 3.00e-04
2025-03-02 16:40:31,328 - INFO - Step 2540 -- ðŸ”„ Training Metrics
2025-03-02 16:40:31,328 - INFO - â”œâ”€â”€ Loss: 6.3541
2025-03-02 16:40:31,328 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:40:31,329 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:40:31,997 - INFO - ðŸªœ Batch step - 2541 -- sub batch step 10164 -- lr 3.00e-04
2025-03-02 16:40:34,148 - INFO - ðŸªœ Batch step - 2541 -- sub batch step 10165 -- lr 3.00e-04
2025-03-02 16:40:36,291 - INFO - ðŸªœ Batch step - 2541 -- sub batch step 10166 -- lr 3.00e-04
2025-03-02 16:40:38,933 - INFO - ðŸªœ Batch step - 2541 -- sub batch step 10167 -- lr 3.00e-04
2025-03-02 16:40:40,420 - INFO - Step 2541 -- ðŸ”„ Training Metrics
2025-03-02 16:40:40,420 - INFO - â”œâ”€â”€ Loss: 6.3749
2025-03-02 16:40:40,420 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:40:40,420 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:40:41,083 - INFO - ðŸªœ Batch step - 2542 -- sub batch step 10168 -- lr 3.00e-04
2025-03-02 16:40:43,239 - INFO - ðŸªœ Batch step - 2542 -- sub batch step 10169 -- lr 3.00e-04
2025-03-02 16:40:45,390 - INFO - ðŸªœ Batch step - 2542 -- sub batch step 10170 -- lr 3.00e-04
2025-03-02 16:40:47,553 - INFO - ðŸªœ Batch step - 2542 -- sub batch step 10171 -- lr 3.00e-04
2025-03-02 16:40:49,109 - INFO - Step 2542 -- ðŸ”„ Training Metrics
2025-03-02 16:40:49,109 - INFO - â”œâ”€â”€ Loss: 6.3912
2025-03-02 16:40:49,109 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:40:49,109 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:40:49,782 - INFO - ðŸªœ Batch step - 2543 -- sub batch step 10172 -- lr 3.00e-04
2025-03-02 16:40:51,926 - INFO - ðŸªœ Batch step - 2543 -- sub batch step 10173 -- lr 3.00e-04
2025-03-02 16:40:54,080 - INFO - ðŸªœ Batch step - 2543 -- sub batch step 10174 -- lr 3.00e-04
2025-03-02 16:40:57,106 - INFO - ðŸªœ Batch step - 2543 -- sub batch step 10175 -- lr 3.00e-04
2025-03-02 16:40:58,600 - INFO - Step 2543 -- ðŸ”„ Training Metrics
2025-03-02 16:40:58,600 - INFO - â”œâ”€â”€ Loss: 6.3733
2025-03-02 16:40:58,600 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:40:58,600 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:40:59,271 - INFO - ðŸªœ Batch step - 2544 -- sub batch step 10176 -- lr 3.00e-04
2025-03-02 16:41:01,431 - INFO - ðŸªœ Batch step - 2544 -- sub batch step 10177 -- lr 3.00e-04
2025-03-02 16:41:03,587 - INFO - ðŸªœ Batch step - 2544 -- sub batch step 10178 -- lr 3.00e-04
2025-03-02 16:41:05,765 - INFO - ðŸªœ Batch step - 2544 -- sub batch step 10179 -- lr 3.00e-04
2025-03-02 16:41:07,286 - INFO - Step 2544 -- ðŸ”„ Training Metrics
2025-03-02 16:41:07,286 - INFO - â”œâ”€â”€ Loss: 6.3688
2025-03-02 16:41:07,286 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:41:07,286 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:41:07,965 - INFO - ðŸªœ Batch step - 2545 -- sub batch step 10180 -- lr 3.00e-04
2025-03-02 16:41:10,117 - INFO - ðŸªœ Batch step - 2545 -- sub batch step 10181 -- lr 3.00e-04
2025-03-02 16:41:12,275 - INFO - ðŸªœ Batch step - 2545 -- sub batch step 10182 -- lr 3.00e-04
2025-03-02 16:41:14,950 - INFO - ðŸªœ Batch step - 2545 -- sub batch step 10183 -- lr 3.00e-04
2025-03-02 16:41:16,498 - INFO - Step 2545 -- ðŸ”„ Training Metrics
2025-03-02 16:41:16,498 - INFO - â”œâ”€â”€ Loss: 6.3743
2025-03-02 16:41:16,498 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:41:16,498 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:41:17,173 - INFO - ðŸªœ Batch step - 2546 -- sub batch step 10184 -- lr 3.00e-04
2025-03-02 16:41:19,332 - INFO - ðŸªœ Batch step - 2546 -- sub batch step 10185 -- lr 3.00e-04
2025-03-02 16:41:21,482 - INFO - ðŸªœ Batch step - 2546 -- sub batch step 10186 -- lr 3.00e-04
2025-03-02 16:41:23,657 - INFO - ðŸªœ Batch step - 2546 -- sub batch step 10187 -- lr 3.00e-04
2025-03-02 16:41:25,188 - INFO - Step 2546 -- ðŸ”„ Training Metrics
2025-03-02 16:41:25,188 - INFO - â”œâ”€â”€ Loss: 6.3732
2025-03-02 16:41:25,211 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:41:25,211 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:41:25,875 - INFO - ðŸªœ Batch step - 2547 -- sub batch step 10188 -- lr 3.00e-04
2025-03-02 16:41:28,033 - INFO - ðŸªœ Batch step - 2547 -- sub batch step 10189 -- lr 3.00e-04
2025-03-02 16:41:30,188 - INFO - ðŸªœ Batch step - 2547 -- sub batch step 10190 -- lr 3.00e-04
2025-03-02 16:41:32,881 - INFO - ðŸªœ Batch step - 2547 -- sub batch step 10191 -- lr 3.00e-04
2025-03-02 16:41:39,459 - INFO - Step 2547 -- ðŸ”„ Training Metrics
2025-03-02 16:41:39,460 - INFO - â”œâ”€â”€ Loss: 6.3593
2025-03-02 16:41:39,460 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:41:39,460 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:41:40,132 - INFO - ðŸªœ Batch step - 2548 -- sub batch step 10192 -- lr 3.00e-04
2025-03-02 16:41:42,277 - INFO - ðŸªœ Batch step - 2548 -- sub batch step 10193 -- lr 3.00e-04
2025-03-02 16:41:44,430 - INFO - ðŸªœ Batch step - 2548 -- sub batch step 10194 -- lr 3.00e-04
2025-03-02 16:41:46,599 - INFO - ðŸªœ Batch step - 2548 -- sub batch step 10195 -- lr 3.00e-04
2025-03-02 16:41:48,146 - INFO - Step 2548 -- ðŸ”„ Training Metrics
2025-03-02 16:41:48,146 - INFO - â”œâ”€â”€ Loss: 6.3709
2025-03-02 16:41:48,146 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:41:48,146 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:41:48,812 - INFO - ðŸªœ Batch step - 2549 -- sub batch step 10196 -- lr 3.00e-04
2025-03-02 16:41:50,962 - INFO - ðŸªœ Batch step - 2549 -- sub batch step 10197 -- lr 3.00e-04
2025-03-02 16:41:53,103 - INFO - ðŸªœ Batch step - 2549 -- sub batch step 10198 -- lr 3.00e-04
2025-03-02 16:41:55,719 - INFO - ðŸªœ Batch step - 2549 -- sub batch step 10199 -- lr 3.00e-04
2025-03-02 16:41:57,309 - INFO - Step 2549 -- ðŸ”„ Training Metrics
2025-03-02 16:41:57,310 - INFO - â”œâ”€â”€ Loss: 6.3602
2025-03-02 16:41:57,310 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:41:57,310 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:41:57,981 - INFO - ðŸªœ Batch step - 2550 -- sub batch step 10200 -- lr 3.00e-04
2025-03-02 16:42:00,125 - INFO - ðŸªœ Batch step - 2550 -- sub batch step 10201 -- lr 3.00e-04
2025-03-02 16:42:02,273 - INFO - ðŸªœ Batch step - 2550 -- sub batch step 10202 -- lr 3.00e-04
2025-03-02 16:42:04,436 - INFO - ðŸªœ Batch step - 2550 -- sub batch step 10203 -- lr 3.00e-04
2025-03-02 16:42:05,982 - INFO - Step 2550 -- ðŸ”„ Training Metrics
2025-03-02 16:42:05,982 - INFO - â”œâ”€â”€ Loss: 6.3491
2025-03-02 16:42:05,982 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:42:05,982 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:42:06,655 - INFO - ðŸªœ Batch step - 2551 -- sub batch step 10204 -- lr 3.00e-04
2025-03-02 16:42:08,804 - INFO - ðŸªœ Batch step - 2551 -- sub batch step 10205 -- lr 3.00e-04
2025-03-02 16:42:11,477 - INFO - ðŸªœ Batch step - 2551 -- sub batch step 10206 -- lr 3.00e-04
2025-03-02 16:42:13,635 - INFO - ðŸªœ Batch step - 2551 -- sub batch step 10207 -- lr 3.00e-04
2025-03-02 16:42:15,218 - INFO - Step 2551 -- ðŸ”„ Training Metrics
2025-03-02 16:42:15,219 - INFO - â”œâ”€â”€ Loss: 6.3968
2025-03-02 16:42:15,219 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:42:15,219 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:42:15,881 - INFO - ðŸªœ Batch step - 2552 -- sub batch step 10208 -- lr 3.00e-04
2025-03-02 16:42:18,036 - INFO - ðŸªœ Batch step - 2552 -- sub batch step 10209 -- lr 3.00e-04
2025-03-02 16:42:20,202 - INFO - ðŸªœ Batch step - 2552 -- sub batch step 10210 -- lr 3.00e-04
2025-03-02 16:42:22,351 - INFO - ðŸªœ Batch step - 2552 -- sub batch step 10211 -- lr 3.00e-04
2025-03-02 16:42:23,908 - INFO - Step 2552 -- ðŸ”„ Training Metrics
2025-03-02 16:42:23,908 - INFO - â”œâ”€â”€ Loss: 6.3436
2025-03-02 16:42:23,908 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:42:23,908 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:42:24,579 - INFO - ðŸªœ Batch step - 2553 -- sub batch step 10212 -- lr 3.00e-04
2025-03-02 16:42:26,726 - INFO - ðŸªœ Batch step - 2553 -- sub batch step 10213 -- lr 3.00e-04
2025-03-02 16:42:29,434 - INFO - ðŸªœ Batch step - 2553 -- sub batch step 10214 -- lr 3.00e-04
2025-03-02 16:42:31,592 - INFO - ðŸªœ Batch step - 2553 -- sub batch step 10215 -- lr 3.00e-04
2025-03-02 16:42:33,172 - INFO - Step 2553 -- ðŸ”„ Training Metrics
2025-03-02 16:42:33,173 - INFO - â”œâ”€â”€ Loss: 6.3778
2025-03-02 16:42:33,173 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:42:33,173 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:42:33,839 - INFO - ðŸªœ Batch step - 2554 -- sub batch step 10216 -- lr 3.00e-04
2025-03-02 16:42:35,989 - INFO - ðŸªœ Batch step - 2554 -- sub batch step 10217 -- lr 3.00e-04
2025-03-02 16:42:38,153 - INFO - ðŸªœ Batch step - 2554 -- sub batch step 10218 -- lr 3.00e-04
2025-03-02 16:42:40,307 - INFO - ðŸªœ Batch step - 2554 -- sub batch step 10219 -- lr 3.00e-04
2025-03-02 16:42:41,856 - INFO - Step 2554 -- ðŸ”„ Training Metrics
2025-03-02 16:42:41,856 - INFO - â”œâ”€â”€ Loss: 6.3821
2025-03-02 16:42:41,856 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:42:41,856 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:42:42,526 - INFO - ðŸªœ Batch step - 2555 -- sub batch step 10220 -- lr 3.00e-04
2025-03-02 16:42:44,670 - INFO - ðŸªœ Batch step - 2555 -- sub batch step 10221 -- lr 3.00e-04
2025-03-02 16:42:47,021 - INFO - ðŸªœ Batch step - 2555 -- sub batch step 10222 -- lr 3.00e-04
2025-03-02 16:42:49,172 - INFO - ðŸªœ Batch step - 2555 -- sub batch step 10223 -- lr 3.00e-04
2025-03-02 16:42:51,319 - INFO - Step 2555 -- ðŸ”„ Training Metrics
2025-03-02 16:42:51,319 - INFO - â”œâ”€â”€ Loss: 6.3925
2025-03-02 16:42:51,319 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:42:51,319 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:42:51,990 - INFO - ðŸªœ Batch step - 2556 -- sub batch step 10224 -- lr 3.00e-04
2025-03-02 16:42:54,141 - INFO - ðŸªœ Batch step - 2556 -- sub batch step 10225 -- lr 3.00e-04
2025-03-02 16:42:56,307 - INFO - ðŸªœ Batch step - 2556 -- sub batch step 10226 -- lr 3.00e-04
2025-03-02 16:42:58,457 - INFO - ðŸªœ Batch step - 2556 -- sub batch step 10227 -- lr 3.00e-04
2025-03-02 16:43:00,004 - INFO - Step 2556 -- ðŸ”„ Training Metrics
2025-03-02 16:43:00,005 - INFO - â”œâ”€â”€ Loss: 6.3485
2025-03-02 16:43:00,005 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:43:00,005 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:43:00,669 - INFO - ðŸªœ Batch step - 2557 -- sub batch step 10228 -- lr 3.00e-04
2025-03-02 16:43:02,823 - INFO - ðŸªœ Batch step - 2557 -- sub batch step 10229 -- lr 3.00e-04
2025-03-02 16:43:05,648 - INFO - ðŸªœ Batch step - 2557 -- sub batch step 10230 -- lr 3.00e-04
2025-03-02 16:43:07,801 - INFO - ðŸªœ Batch step - 2557 -- sub batch step 10231 -- lr 3.00e-04
2025-03-02 16:43:09,296 - INFO - Step 2557 -- ðŸ”„ Training Metrics
2025-03-02 16:43:09,296 - INFO - â”œâ”€â”€ Loss: 6.3599
2025-03-02 16:43:09,296 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:43:09,297 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:43:09,967 - INFO - ðŸªœ Batch step - 2558 -- sub batch step 10232 -- lr 3.00e-04
2025-03-02 16:43:12,115 - INFO - ðŸªœ Batch step - 2558 -- sub batch step 10233 -- lr 3.00e-04
2025-03-02 16:43:14,290 - INFO - ðŸªœ Batch step - 2558 -- sub batch step 10234 -- lr 3.00e-04
2025-03-02 16:43:16,446 - INFO - ðŸªœ Batch step - 2558 -- sub batch step 10235 -- lr 3.00e-04
2025-03-02 16:43:17,987 - INFO - Step 2558 -- ðŸ”„ Training Metrics
2025-03-02 16:43:17,987 - INFO - â”œâ”€â”€ Loss: 6.3817
2025-03-02 16:43:17,987 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:43:17,987 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:43:18,656 - INFO - ðŸªœ Batch step - 2559 -- sub batch step 10236 -- lr 3.00e-04
2025-03-02 16:43:20,808 - INFO - ðŸªœ Batch step - 2559 -- sub batch step 10237 -- lr 3.00e-04
2025-03-02 16:43:23,081 - INFO - ðŸªœ Batch step - 2559 -- sub batch step 10238 -- lr 3.00e-04
2025-03-02 16:43:25,233 - INFO - ðŸªœ Batch step - 2559 -- sub batch step 10239 -- lr 3.00e-04
2025-03-02 16:43:29,598 - INFO - Step 2559 -- ðŸ”„ Training Metrics
2025-03-02 16:43:29,598 - INFO - â”œâ”€â”€ Loss: 6.3759
2025-03-02 16:43:29,598 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:43:29,598 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:43:30,819 - INFO - ðŸªœ Batch step - 2560 -- sub batch step 10240 -- lr 3.00e-04
2025-03-02 16:43:32,967 - INFO - ðŸªœ Batch step - 2560 -- sub batch step 10241 -- lr 3.00e-04
2025-03-02 16:43:35,121 - INFO - ðŸªœ Batch step - 2560 -- sub batch step 10242 -- lr 3.00e-04
2025-03-02 16:43:37,291 - INFO - ðŸªœ Batch step - 2560 -- sub batch step 10243 -- lr 3.00e-04
2025-03-02 16:43:38,936 - INFO - Step 2560 -- ðŸ”„ Training Metrics
2025-03-02 16:43:38,937 - INFO - â”œâ”€â”€ Loss: 6.3533
2025-03-02 16:43:38,937 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:43:38,937 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:43:39,616 - INFO - ðŸªœ Batch step - 2561 -- sub batch step 10244 -- lr 3.00e-04
2025-03-02 16:43:41,768 - INFO - ðŸªœ Batch step - 2561 -- sub batch step 10245 -- lr 3.00e-04
2025-03-02 16:43:43,920 - INFO - ðŸªœ Batch step - 2561 -- sub batch step 10246 -- lr 3.00e-04
2025-03-02 16:43:46,751 - INFO - ðŸªœ Batch step - 2561 -- sub batch step 10247 -- lr 3.00e-04
2025-03-02 16:43:48,242 - INFO - Step 2561 -- ðŸ”„ Training Metrics
2025-03-02 16:43:48,243 - INFO - â”œâ”€â”€ Loss: 6.3846
2025-03-02 16:43:48,243 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:43:48,243 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:43:48,908 - INFO - ðŸªœ Batch step - 2562 -- sub batch step 10248 -- lr 3.00e-04
2025-03-02 16:43:51,070 - INFO - ðŸªœ Batch step - 2562 -- sub batch step 10249 -- lr 3.00e-04
2025-03-02 16:43:53,225 - INFO - ðŸªœ Batch step - 2562 -- sub batch step 10250 -- lr 3.00e-04
2025-03-02 16:43:55,392 - INFO - ðŸªœ Batch step - 2562 -- sub batch step 10251 -- lr 3.00e-04
2025-03-02 16:43:56,965 - INFO - Step 2562 -- ðŸ”„ Training Metrics
2025-03-02 16:43:56,965 - INFO - â”œâ”€â”€ Loss: 6.3494
2025-03-02 16:43:56,965 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:43:56,965 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:43:57,641 - INFO - ðŸªœ Batch step - 2563 -- sub batch step 10252 -- lr 3.00e-04
2025-03-02 16:43:59,790 - INFO - ðŸªœ Batch step - 2563 -- sub batch step 10253 -- lr 3.00e-04
2025-03-02 16:44:01,947 - INFO - ðŸªœ Batch step - 2563 -- sub batch step 10254 -- lr 3.00e-04
2025-03-02 16:44:04,578 - INFO - ðŸªœ Batch step - 2563 -- sub batch step 10255 -- lr 3.00e-04
2025-03-02 16:44:06,245 - INFO - Step 2563 -- ðŸ”„ Training Metrics
2025-03-02 16:44:06,245 - INFO - â”œâ”€â”€ Loss: 6.3471
2025-03-02 16:44:06,245 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:44:06,246 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:44:06,915 - INFO - ðŸªœ Batch step - 2564 -- sub batch step 10256 -- lr 3.00e-04
2025-03-02 16:44:09,074 - INFO - ðŸªœ Batch step - 2564 -- sub batch step 10257 -- lr 3.00e-04
2025-03-02 16:44:11,223 - INFO - ðŸªœ Batch step - 2564 -- sub batch step 10258 -- lr 3.00e-04
2025-03-02 16:44:13,398 - INFO - ðŸªœ Batch step - 2564 -- sub batch step 10259 -- lr 3.00e-04
2025-03-02 16:44:14,949 - INFO - Step 2564 -- ðŸ”„ Training Metrics
2025-03-02 16:44:14,950 - INFO - â”œâ”€â”€ Loss: 6.3893
2025-03-02 16:44:14,950 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:44:14,950 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:44:15,623 - INFO - ðŸªœ Batch step - 2565 -- sub batch step 10260 -- lr 3.00e-04
2025-03-02 16:44:17,773 - INFO - ðŸªœ Batch step - 2565 -- sub batch step 10261 -- lr 3.00e-04
2025-03-02 16:44:19,932 - INFO - ðŸªœ Batch step - 2565 -- sub batch step 10262 -- lr 3.00e-04
2025-03-02 16:44:22,296 - INFO - ðŸªœ Batch step - 2565 -- sub batch step 10263 -- lr 3.00e-04
2025-03-02 16:44:24,108 - INFO - Step 2565 -- ðŸ”„ Training Metrics
2025-03-02 16:44:24,108 - INFO - â”œâ”€â”€ Loss: 6.3534
2025-03-02 16:44:24,109 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:44:24,109 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:44:24,780 - INFO - ðŸªœ Batch step - 2566 -- sub batch step 10264 -- lr 3.00e-04
2025-03-02 16:44:26,934 - INFO - ðŸªœ Batch step - 2566 -- sub batch step 10265 -- lr 3.00e-04
2025-03-02 16:44:29,086 - INFO - ðŸªœ Batch step - 2566 -- sub batch step 10266 -- lr 3.00e-04
2025-03-02 16:44:31,260 - INFO - ðŸªœ Batch step - 2566 -- sub batch step 10267 -- lr 3.00e-04
2025-03-02 16:44:32,795 - INFO - Step 2566 -- ðŸ”„ Training Metrics
2025-03-02 16:44:32,796 - INFO - â”œâ”€â”€ Loss: 6.3623
2025-03-02 16:44:32,796 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:44:32,796 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:44:33,467 - INFO - ðŸªœ Batch step - 2567 -- sub batch step 10268 -- lr 3.00e-04
2025-03-02 16:44:35,627 - INFO - ðŸªœ Batch step - 2567 -- sub batch step 10269 -- lr 3.00e-04
2025-03-02 16:44:37,779 - INFO - ðŸªœ Batch step - 2567 -- sub batch step 10270 -- lr 3.00e-04
2025-03-02 16:44:40,574 - INFO - ðŸªœ Batch step - 2567 -- sub batch step 10271 -- lr 3.00e-04
2025-03-02 16:44:42,066 - INFO - Step 2567 -- ðŸ”„ Training Metrics
2025-03-02 16:44:42,066 - INFO - â”œâ”€â”€ Loss: 6.3812
2025-03-02 16:44:42,066 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:44:42,066 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:44:42,739 - INFO - ðŸªœ Batch step - 2568 -- sub batch step 10272 -- lr 3.00e-04
2025-03-02 16:44:44,889 - INFO - ðŸªœ Batch step - 2568 -- sub batch step 10273 -- lr 3.00e-04
2025-03-02 16:44:47,047 - INFO - ðŸªœ Batch step - 2568 -- sub batch step 10274 -- lr 3.00e-04
2025-03-02 16:44:49,220 - INFO - ðŸªœ Batch step - 2568 -- sub batch step 10275 -- lr 3.00e-04
2025-03-02 16:44:50,754 - INFO - Step 2568 -- ðŸ”„ Training Metrics
2025-03-02 16:44:50,754 - INFO - â”œâ”€â”€ Loss: 6.3735
2025-03-02 16:44:50,754 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:44:50,754 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:44:51,422 - INFO - ðŸªœ Batch step - 2569 -- sub batch step 10276 -- lr 3.00e-04
2025-03-02 16:44:53,581 - INFO - ðŸªœ Batch step - 2569 -- sub batch step 10277 -- lr 3.00e-04
2025-03-02 16:44:55,730 - INFO - ðŸªœ Batch step - 2569 -- sub batch step 10278 -- lr 3.00e-04
2025-03-02 16:44:58,340 - INFO - ðŸªœ Batch step - 2569 -- sub batch step 10279 -- lr 3.00e-04
2025-03-02 16:45:00,001 - INFO - Step 2569 -- ðŸ”„ Training Metrics
2025-03-02 16:45:00,001 - INFO - â”œâ”€â”€ Loss: 6.3577
2025-03-02 16:45:00,001 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:45:00,002 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:45:00,671 - INFO - ðŸªœ Batch step - 2570 -- sub batch step 10280 -- lr 3.00e-04
2025-03-02 16:45:02,818 - INFO - ðŸªœ Batch step - 2570 -- sub batch step 10281 -- lr 3.00e-04
2025-03-02 16:45:04,977 - INFO - ðŸªœ Batch step - 2570 -- sub batch step 10282 -- lr 3.00e-04
2025-03-02 16:45:07,139 - INFO - ðŸªœ Batch step - 2570 -- sub batch step 10283 -- lr 3.00e-04
2025-03-02 16:45:08,696 - INFO - Step 2570 -- ðŸ”„ Training Metrics
2025-03-02 16:45:08,696 - INFO - â”œâ”€â”€ Loss: 6.3575
2025-03-02 16:45:08,696 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:45:08,696 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:45:09,371 - INFO - ðŸªœ Batch step - 2571 -- sub batch step 10284 -- lr 3.00e-04
2025-03-02 16:45:11,526 - INFO - ðŸªœ Batch step - 2571 -- sub batch step 10285 -- lr 3.00e-04
2025-03-02 16:45:14,240 - INFO - ðŸªœ Batch step - 2571 -- sub batch step 10286 -- lr 3.00e-04
2025-03-02 16:45:16,390 - INFO - ðŸªœ Batch step - 2571 -- sub batch step 10287 -- lr 3.00e-04
2025-03-02 16:45:18,026 - INFO - Step 2571 -- ðŸ”„ Training Metrics
2025-03-02 16:45:18,026 - INFO - â”œâ”€â”€ Loss: 6.3693
2025-03-02 16:45:18,026 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:45:18,026 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:45:18,694 - INFO - ðŸªœ Batch step - 2572 -- sub batch step 10288 -- lr 3.00e-04
2025-03-02 16:45:20,849 - INFO - ðŸªœ Batch step - 2572 -- sub batch step 10289 -- lr 3.00e-04
2025-03-02 16:45:23,020 - INFO - ðŸªœ Batch step - 2572 -- sub batch step 10290 -- lr 3.00e-04
2025-03-02 16:45:25,173 - INFO - ðŸªœ Batch step - 2572 -- sub batch step 10291 -- lr 3.00e-04
2025-03-02 16:45:26,715 - INFO - Step 2572 -- ðŸ”„ Training Metrics
2025-03-02 16:45:26,715 - INFO - â”œâ”€â”€ Loss: 6.3432
2025-03-02 16:45:26,715 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:45:26,715 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:45:27,393 - INFO - ðŸªœ Batch step - 2573 -- sub batch step 10292 -- lr 3.00e-04
2025-03-02 16:45:29,540 - INFO - ðŸªœ Batch step - 2573 -- sub batch step 10293 -- lr 3.00e-04
2025-03-02 16:45:31,979 - INFO - ðŸªœ Batch step - 2573 -- sub batch step 10294 -- lr 3.00e-04
2025-03-02 16:45:34,131 - INFO - ðŸªœ Batch step - 2573 -- sub batch step 10295 -- lr 3.00e-04
2025-03-02 16:45:35,962 - INFO - Step 2573 -- ðŸ”„ Training Metrics
2025-03-02 16:45:35,963 - INFO - â”œâ”€â”€ Loss: 6.3604
2025-03-02 16:45:35,963 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:45:35,963 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:45:36,630 - INFO - ðŸªœ Batch step - 2574 -- sub batch step 10296 -- lr 3.00e-04
2025-03-02 16:45:38,790 - INFO - ðŸªœ Batch step - 2574 -- sub batch step 10297 -- lr 3.00e-04
2025-03-02 16:45:40,953 - INFO - ðŸªœ Batch step - 2574 -- sub batch step 10298 -- lr 3.00e-04
2025-03-02 16:45:43,112 - INFO - ðŸªœ Batch step - 2574 -- sub batch step 10299 -- lr 3.00e-04
2025-03-02 16:45:44,645 - INFO - Step 2574 -- ðŸ”„ Training Metrics
2025-03-02 16:45:44,646 - INFO - â”œâ”€â”€ Loss: 6.3501
2025-03-02 16:45:44,646 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:45:44,646 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:45:45,317 - INFO - ðŸªœ Batch step - 2575 -- sub batch step 10300 -- lr 3.00e-04
2025-03-02 16:45:47,468 - INFO - ðŸªœ Batch step - 2575 -- sub batch step 10301 -- lr 3.00e-04
2025-03-02 16:45:50,267 - INFO - ðŸªœ Batch step - 2575 -- sub batch step 10302 -- lr 3.00e-04
2025-03-02 16:45:52,422 - INFO - ðŸªœ Batch step - 2575 -- sub batch step 10303 -- lr 3.00e-04
2025-03-02 16:45:54,000 - INFO - Step 2575 -- ðŸ”„ Training Metrics
2025-03-02 16:45:54,000 - INFO - â”œâ”€â”€ Loss: 6.3522
2025-03-02 16:45:54,000 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:45:54,000 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:45:54,675 - INFO - ðŸªœ Batch step - 2576 -- sub batch step 10304 -- lr 3.00e-04
2025-03-02 16:45:56,831 - INFO - ðŸªœ Batch step - 2576 -- sub batch step 10305 -- lr 3.00e-04
2025-03-02 16:45:58,997 - INFO - ðŸªœ Batch step - 2576 -- sub batch step 10306 -- lr 3.00e-04
2025-03-02 16:46:01,153 - INFO - ðŸªœ Batch step - 2576 -- sub batch step 10307 -- lr 3.00e-04
2025-03-02 16:46:02,694 - INFO - Step 2576 -- ðŸ”„ Training Metrics
2025-03-02 16:46:02,694 - INFO - â”œâ”€â”€ Loss: 6.3463
2025-03-02 16:46:02,694 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:46:02,694 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:46:03,360 - INFO - ðŸªœ Batch step - 2577 -- sub batch step 10308 -- lr 3.00e-04
2025-03-02 16:46:05,523 - INFO - ðŸªœ Batch step - 2577 -- sub batch step 10309 -- lr 3.00e-04
2025-03-02 16:46:08,157 - INFO - ðŸªœ Batch step - 2577 -- sub batch step 10310 -- lr 3.00e-04
2025-03-02 16:46:10,307 - INFO - ðŸªœ Batch step - 2577 -- sub batch step 10311 -- lr 3.00e-04
2025-03-02 16:46:13,023 - INFO - Step 2577 -- ðŸ”„ Training Metrics
2025-03-02 16:46:13,023 - INFO - â”œâ”€â”€ Loss: 6.3573
2025-03-02 16:46:13,024 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:46:13,024 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:46:13,701 - INFO - ðŸªœ Batch step - 2578 -- sub batch step 10312 -- lr 3.00e-04
2025-03-02 16:46:15,853 - INFO - ðŸªœ Batch step - 2578 -- sub batch step 10313 -- lr 3.00e-04
2025-03-02 16:46:18,029 - INFO - ðŸªœ Batch step - 2578 -- sub batch step 10314 -- lr 3.00e-04
2025-03-02 16:46:20,184 - INFO - ðŸªœ Batch step - 2578 -- sub batch step 10315 -- lr 3.00e-04
2025-03-02 16:46:21,716 - INFO - Step 2578 -- ðŸ”„ Training Metrics
2025-03-02 16:46:21,716 - INFO - â”œâ”€â”€ Loss: 6.3619
2025-03-02 16:46:21,716 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:46:21,716 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:46:22,383 - INFO - ðŸªœ Batch step - 2579 -- sub batch step 10316 -- lr 3.00e-04
2025-03-02 16:46:24,538 - INFO - ðŸªœ Batch step - 2579 -- sub batch step 10317 -- lr 3.00e-04
2025-03-02 16:46:26,820 - INFO - ðŸªœ Batch step - 2579 -- sub batch step 10318 -- lr 3.00e-04
2025-03-02 16:46:28,978 - INFO - ðŸªœ Batch step - 2579 -- sub batch step 10319 -- lr 3.00e-04
2025-03-02 16:46:30,518 - INFO - Step 2579 -- ðŸ”„ Training Metrics
2025-03-02 16:46:30,518 - INFO - â”œâ”€â”€ Loss: 6.3553
2025-03-02 16:46:30,518 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:46:30,518 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:46:31,816 - INFO - ðŸªœ Batch step - 2580 -- sub batch step 10320 -- lr 3.00e-04
2025-03-02 16:46:33,969 - INFO - ðŸªœ Batch step - 2580 -- sub batch step 10321 -- lr 3.00e-04
2025-03-02 16:46:36,122 - INFO - ðŸªœ Batch step - 2580 -- sub batch step 10322 -- lr 3.00e-04
2025-03-02 16:46:38,291 - INFO - ðŸªœ Batch step - 2580 -- sub batch step 10323 -- lr 3.00e-04
2025-03-02 16:46:39,900 - INFO - Step 2580 -- ðŸ”„ Training Metrics
2025-03-02 16:46:39,900 - INFO - â”œâ”€â”€ Loss: 6.3490
2025-03-02 16:46:39,900 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:46:39,900 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:46:40,574 - INFO - ðŸªœ Batch step - 2581 -- sub batch step 10324 -- lr 3.00e-04
2025-03-02 16:46:42,732 - INFO - ðŸªœ Batch step - 2581 -- sub batch step 10325 -- lr 3.00e-04
2025-03-02 16:46:44,880 - INFO - ðŸªœ Batch step - 2581 -- sub batch step 10326 -- lr 3.00e-04
2025-03-02 16:46:47,538 - INFO - ðŸªœ Batch step - 2581 -- sub batch step 10327 -- lr 3.00e-04
2025-03-02 16:46:49,027 - INFO - Step 2581 -- ðŸ”„ Training Metrics
2025-03-02 16:46:49,028 - INFO - â”œâ”€â”€ Loss: 6.3189
2025-03-02 16:46:49,028 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:46:49,028 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:46:49,701 - INFO - ðŸªœ Batch step - 2582 -- sub batch step 10328 -- lr 3.00e-04
2025-03-02 16:46:51,868 - INFO - ðŸªœ Batch step - 2582 -- sub batch step 10329 -- lr 3.00e-04
2025-03-02 16:46:54,026 - INFO - ðŸªœ Batch step - 2582 -- sub batch step 10330 -- lr 3.00e-04
2025-03-02 16:46:56,199 - INFO - ðŸªœ Batch step - 2582 -- sub batch step 10331 -- lr 3.00e-04
2025-03-02 16:46:57,722 - INFO - Step 2582 -- ðŸ”„ Training Metrics
2025-03-02 16:46:57,723 - INFO - â”œâ”€â”€ Loss: 6.3555
2025-03-02 16:46:57,723 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:46:57,723 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:46:58,402 - INFO - ðŸªœ Batch step - 2583 -- sub batch step 10332 -- lr 3.00e-04
2025-03-02 16:47:00,556 - INFO - ðŸªœ Batch step - 2583 -- sub batch step 10333 -- lr 3.00e-04
2025-03-02 16:47:02,712 - INFO - ðŸªœ Batch step - 2583 -- sub batch step 10334 -- lr 3.00e-04
2025-03-02 16:47:05,347 - INFO - ðŸªœ Batch step - 2583 -- sub batch step 10335 -- lr 3.00e-04
2025-03-02 16:47:06,892 - INFO - Step 2583 -- ðŸ”„ Training Metrics
2025-03-02 16:47:06,892 - INFO - â”œâ”€â”€ Loss: 6.3704
2025-03-02 16:47:06,892 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:47:06,892 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:47:07,566 - INFO - ðŸªœ Batch step - 2584 -- sub batch step 10336 -- lr 3.00e-04
2025-03-02 16:47:09,723 - INFO - ðŸªœ Batch step - 2584 -- sub batch step 10337 -- lr 3.00e-04
2025-03-02 16:47:11,874 - INFO - ðŸªœ Batch step - 2584 -- sub batch step 10338 -- lr 3.00e-04
2025-03-02 16:47:14,053 - INFO - ðŸªœ Batch step - 2584 -- sub batch step 10339 -- lr 3.00e-04
2025-03-02 16:47:15,616 - INFO - Step 2584 -- ðŸ”„ Training Metrics
2025-03-02 16:47:15,616 - INFO - â”œâ”€â”€ Loss: 6.3803
2025-03-02 16:47:15,616 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:47:15,616 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:47:16,293 - INFO - ðŸªœ Batch step - 2585 -- sub batch step 10340 -- lr 3.00e-04
2025-03-02 16:47:18,443 - INFO - ðŸªœ Batch step - 2585 -- sub batch step 10341 -- lr 3.00e-04
2025-03-02 16:47:20,596 - INFO - ðŸªœ Batch step - 2585 -- sub batch step 10342 -- lr 3.00e-04
2025-03-02 16:47:23,210 - INFO - ðŸªœ Batch step - 2585 -- sub batch step 10343 -- lr 3.00e-04
2025-03-02 16:47:25,049 - INFO - Step 2585 -- ðŸ”„ Training Metrics
2025-03-02 16:47:25,050 - INFO - â”œâ”€â”€ Loss: 6.3549
2025-03-02 16:47:25,050 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:47:25,050 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:47:25,723 - INFO - ðŸªœ Batch step - 2586 -- sub batch step 10344 -- lr 3.00e-04
2025-03-02 16:47:27,876 - INFO - ðŸªœ Batch step - 2586 -- sub batch step 10345 -- lr 3.00e-04
2025-03-02 16:47:30,025 - INFO - ðŸªœ Batch step - 2586 -- sub batch step 10346 -- lr 3.00e-04
2025-03-02 16:47:32,203 - INFO - ðŸªœ Batch step - 2586 -- sub batch step 10347 -- lr 3.00e-04
2025-03-02 16:47:33,772 - INFO - Step 2586 -- ðŸ”„ Training Metrics
2025-03-02 16:47:33,773 - INFO - â”œâ”€â”€ Loss: 6.3456
2025-03-02 16:47:33,773 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:47:33,773 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:47:34,444 - INFO - ðŸªœ Batch step - 2587 -- sub batch step 10348 -- lr 3.00e-04
2025-03-02 16:47:36,597 - INFO - ðŸªœ Batch step - 2587 -- sub batch step 10349 -- lr 3.00e-04
2025-03-02 16:47:38,749 - INFO - ðŸªœ Batch step - 2587 -- sub batch step 10350 -- lr 3.00e-04
2025-03-02 16:47:41,358 - INFO - ðŸªœ Batch step - 2587 -- sub batch step 10351 -- lr 3.00e-04
2025-03-02 16:47:42,967 - INFO - Step 2587 -- ðŸ”„ Training Metrics
2025-03-02 16:47:42,967 - INFO - â”œâ”€â”€ Loss: 6.3713
2025-03-02 16:47:42,967 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:47:42,968 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:47:43,641 - INFO - ðŸªœ Batch step - 2588 -- sub batch step 10352 -- lr 3.00e-04
2025-03-02 16:47:45,788 - INFO - ðŸªœ Batch step - 2588 -- sub batch step 10353 -- lr 3.00e-04
2025-03-02 16:47:47,939 - INFO - ðŸªœ Batch step - 2588 -- sub batch step 10354 -- lr 3.00e-04
2025-03-02 16:47:50,106 - INFO - ðŸªœ Batch step - 2588 -- sub batch step 10355 -- lr 3.00e-04
2025-03-02 16:47:51,679 - INFO - Step 2588 -- ðŸ”„ Training Metrics
2025-03-02 16:47:51,679 - INFO - â”œâ”€â”€ Loss: 6.3483
2025-03-02 16:47:51,679 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:47:51,679 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:47:52,348 - INFO - ðŸªœ Batch step - 2589 -- sub batch step 10356 -- lr 3.00e-04
2025-03-02 16:47:54,505 - INFO - ðŸªœ Batch step - 2589 -- sub batch step 10357 -- lr 3.00e-04
2025-03-02 16:47:56,650 - INFO - ðŸªœ Batch step - 2589 -- sub batch step 10358 -- lr 3.00e-04
2025-03-02 16:47:59,289 - INFO - ðŸªœ Batch step - 2589 -- sub batch step 10359 -- lr 3.00e-04
2025-03-02 16:48:01,171 - INFO - Step 2589 -- ðŸ”„ Training Metrics
2025-03-02 16:48:01,171 - INFO - â”œâ”€â”€ Loss: 6.3460
2025-03-02 16:48:01,171 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:48:01,171 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:48:01,841 - INFO - ðŸªœ Batch step - 2590 -- sub batch step 10360 -- lr 3.00e-04
2025-03-02 16:48:03,987 - INFO - ðŸªœ Batch step - 2590 -- sub batch step 10361 -- lr 3.00e-04
2025-03-02 16:48:06,140 - INFO - ðŸªœ Batch step - 2590 -- sub batch step 10362 -- lr 3.00e-04
2025-03-02 16:48:08,301 - INFO - ðŸªœ Batch step - 2590 -- sub batch step 10363 -- lr 3.00e-04
2025-03-02 16:48:09,874 - INFO - Step 2590 -- ðŸ”„ Training Metrics
2025-03-02 16:48:09,874 - INFO - â”œâ”€â”€ Loss: 6.3495
2025-03-02 16:48:09,874 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:48:09,875 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:48:10,546 - INFO - ðŸªœ Batch step - 2591 -- sub batch step 10364 -- lr 3.00e-04
2025-03-02 16:48:12,695 - INFO - ðŸªœ Batch step - 2591 -- sub batch step 10365 -- lr 3.00e-04
2025-03-02 16:48:15,367 - INFO - ðŸªœ Batch step - 2591 -- sub batch step 10366 -- lr 3.00e-04
2025-03-02 16:48:17,521 - INFO - ðŸªœ Batch step - 2591 -- sub batch step 10367 -- lr 3.00e-04
2025-03-02 16:48:19,488 - INFO - Step 2591 -- ðŸ”„ Training Metrics
2025-03-02 16:48:19,488 - INFO - â”œâ”€â”€ Loss: 6.3348
2025-03-02 16:48:19,488 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:48:19,488 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:48:20,155 - INFO - ðŸªœ Batch step - 2592 -- sub batch step 10368 -- lr 3.00e-04
2025-03-02 16:48:22,306 - INFO - ðŸªœ Batch step - 2592 -- sub batch step 10369 -- lr 3.00e-04
2025-03-02 16:48:24,478 - INFO - ðŸªœ Batch step - 2592 -- sub batch step 10370 -- lr 3.00e-04
2025-03-02 16:48:26,625 - INFO - ðŸªœ Batch step - 2592 -- sub batch step 10371 -- lr 3.00e-04
2025-03-02 16:48:28,201 - INFO - Step 2592 -- ðŸ”„ Training Metrics
2025-03-02 16:48:28,201 - INFO - â”œâ”€â”€ Loss: 6.3215
2025-03-02 16:48:28,201 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:48:28,201 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:48:28,876 - INFO - ðŸªœ Batch step - 2593 -- sub batch step 10372 -- lr 3.00e-04
2025-03-02 16:48:31,021 - INFO - ðŸªœ Batch step - 2593 -- sub batch step 10373 -- lr 3.00e-04
2025-03-02 16:48:33,727 - INFO - ðŸªœ Batch step - 2593 -- sub batch step 10374 -- lr 3.00e-04
2025-03-02 16:48:35,878 - INFO - ðŸªœ Batch step - 2593 -- sub batch step 10375 -- lr 3.00e-04
2025-03-02 16:48:37,451 - INFO - Step 2593 -- ðŸ”„ Training Metrics
2025-03-02 16:48:37,451 - INFO - â”œâ”€â”€ Loss: 6.3614
2025-03-02 16:48:37,451 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:48:37,451 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:48:38,118 - INFO - ðŸªœ Batch step - 2594 -- sub batch step 10376 -- lr 3.00e-04
2025-03-02 16:48:40,271 - INFO - ðŸªœ Batch step - 2594 -- sub batch step 10377 -- lr 3.00e-04
2025-03-02 16:48:42,436 - INFO - ðŸªœ Batch step - 2594 -- sub batch step 10378 -- lr 3.00e-04
2025-03-02 16:48:44,592 - INFO - ðŸªœ Batch step - 2594 -- sub batch step 10379 -- lr 3.00e-04
2025-03-02 16:48:46,162 - INFO - Step 2594 -- ðŸ”„ Training Metrics
2025-03-02 16:48:46,163 - INFO - â”œâ”€â”€ Loss: 6.3426
2025-03-02 16:48:46,163 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:48:46,163 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:48:46,836 - INFO - ðŸªœ Batch step - 2595 -- sub batch step 10380 -- lr 3.00e-04
2025-03-02 16:48:48,984 - INFO - ðŸªœ Batch step - 2595 -- sub batch step 10381 -- lr 3.00e-04
2025-03-02 16:48:51,689 - INFO - ðŸªœ Batch step - 2595 -- sub batch step 10382 -- lr 3.00e-04
2025-03-02 16:48:53,835 - INFO - ðŸªœ Batch step - 2595 -- sub batch step 10383 -- lr 3.00e-04
2025-03-02 16:48:55,392 - INFO - Step 2595 -- ðŸ”„ Training Metrics
2025-03-02 16:48:55,392 - INFO - â”œâ”€â”€ Loss: 6.3492
2025-03-02 16:48:55,392 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:48:55,392 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:48:56,066 - INFO - ðŸªœ Batch step - 2596 -- sub batch step 10384 -- lr 3.00e-04
2025-03-02 16:48:58,218 - INFO - ðŸªœ Batch step - 2596 -- sub batch step 10385 -- lr 3.00e-04
2025-03-02 16:49:00,384 - INFO - ðŸªœ Batch step - 2596 -- sub batch step 10386 -- lr 3.00e-04
2025-03-02 16:49:02,536 - INFO - ðŸªœ Batch step - 2596 -- sub batch step 10387 -- lr 3.00e-04
2025-03-02 16:49:04,093 - INFO - Step 2596 -- ðŸ”„ Training Metrics
2025-03-02 16:49:04,093 - INFO - â”œâ”€â”€ Loss: 6.3346
2025-03-02 16:49:04,093 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:49:04,093 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:49:04,764 - INFO - ðŸªœ Batch step - 2597 -- sub batch step 10388 -- lr 3.00e-04
2025-03-02 16:49:06,917 - INFO - ðŸªœ Batch step - 2597 -- sub batch step 10389 -- lr 3.00e-04
2025-03-02 16:49:09,553 - INFO - ðŸªœ Batch step - 2597 -- sub batch step 10390 -- lr 3.00e-04
2025-03-02 16:49:11,708 - INFO - ðŸªœ Batch step - 2597 -- sub batch step 10391 -- lr 3.00e-04
2025-03-02 16:49:14,034 - INFO - Step 2597 -- ðŸ”„ Training Metrics
2025-03-02 16:49:14,034 - INFO - â”œâ”€â”€ Loss: 6.3391
2025-03-02 16:49:14,034 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:49:14,034 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:49:14,705 - INFO - ðŸªœ Batch step - 2598 -- sub batch step 10392 -- lr 3.00e-04
2025-03-02 16:49:16,856 - INFO - ðŸªœ Batch step - 2598 -- sub batch step 10393 -- lr 3.00e-04
2025-03-02 16:49:19,032 - INFO - ðŸªœ Batch step - 2598 -- sub batch step 10394 -- lr 3.00e-04
2025-03-02 16:49:21,188 - INFO - ðŸªœ Batch step - 2598 -- sub batch step 10395 -- lr 3.00e-04
2025-03-02 16:49:22,760 - INFO - Step 2598 -- ðŸ”„ Training Metrics
2025-03-02 16:49:22,760 - INFO - â”œâ”€â”€ Loss: 6.3438
2025-03-02 16:49:22,760 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:49:22,760 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:49:23,426 - INFO - ðŸªœ Batch step - 2599 -- sub batch step 10396 -- lr 3.00e-04
2025-03-02 16:49:25,579 - INFO - ðŸªœ Batch step - 2599 -- sub batch step 10397 -- lr 3.00e-04
2025-03-02 16:49:27,856 - INFO - ðŸªœ Batch step - 2599 -- sub batch step 10398 -- lr 3.00e-04
2025-03-02 16:49:30,012 - INFO - ðŸªœ Batch step - 2599 -- sub batch step 10399 -- lr 3.00e-04
2025-03-02 16:49:31,620 - INFO - Step 2599 -- ðŸ”„ Training Metrics
2025-03-02 16:49:31,620 - INFO - â”œâ”€â”€ Loss: 6.3568
2025-03-02 16:49:31,620 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:49:31,620 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:49:32,949 - INFO - ðŸªœ Batch step - 2600 -- sub batch step 10400 -- lr 3.00e-04
2025-03-02 16:49:35,098 - INFO - ðŸªœ Batch step - 2600 -- sub batch step 10401 -- lr 3.00e-04
2025-03-02 16:49:37,251 - INFO - ðŸªœ Batch step - 2600 -- sub batch step 10402 -- lr 3.00e-04
2025-03-02 16:49:39,421 - INFO - ðŸªœ Batch step - 2600 -- sub batch step 10403 -- lr 3.00e-04
2025-03-02 16:49:41,044 - INFO - Step 2600 -- ðŸ”„ Training Metrics
2025-03-02 16:49:41,044 - INFO - â”œâ”€â”€ Loss: 6.3248
2025-03-02 16:49:41,044 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:49:41,045 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:49:41,720 - INFO - ðŸªœ Batch step - 2601 -- sub batch step 10404 -- lr 3.00e-04
2025-03-02 16:49:43,873 - INFO - ðŸªœ Batch step - 2601 -- sub batch step 10405 -- lr 3.00e-04
2025-03-02 16:49:46,019 - INFO - ðŸªœ Batch step - 2601 -- sub batch step 10406 -- lr 3.00e-04
2025-03-02 16:49:48,648 - INFO - ðŸªœ Batch step - 2601 -- sub batch step 10407 -- lr 3.00e-04
2025-03-02 16:49:50,343 - INFO - Step 2601 -- ðŸ”„ Training Metrics
2025-03-02 16:49:50,343 - INFO - â”œâ”€â”€ Loss: 6.3378
2025-03-02 16:49:50,343 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:49:50,343 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:49:51,008 - INFO - ðŸªœ Batch step - 2602 -- sub batch step 10408 -- lr 3.00e-04
2025-03-02 16:49:53,168 - INFO - ðŸªœ Batch step - 2602 -- sub batch step 10409 -- lr 3.00e-04
2025-03-02 16:49:55,323 - INFO - ðŸªœ Batch step - 2602 -- sub batch step 10410 -- lr 3.00e-04
2025-03-02 16:49:57,493 - INFO - ðŸªœ Batch step - 2602 -- sub batch step 10411 -- lr 3.00e-04
2025-03-02 16:49:59,043 - INFO - Step 2602 -- ðŸ”„ Training Metrics
2025-03-02 16:49:59,043 - INFO - â”œâ”€â”€ Loss: 6.3373
2025-03-02 16:49:59,044 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:49:59,044 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:49:59,716 - INFO - ðŸªœ Batch step - 2603 -- sub batch step 10412 -- lr 3.00e-04
2025-03-02 16:50:01,866 - INFO - ðŸªœ Batch step - 2603 -- sub batch step 10413 -- lr 3.00e-04
2025-03-02 16:50:04,023 - INFO - ðŸªœ Batch step - 2603 -- sub batch step 10414 -- lr 3.00e-04
2025-03-02 16:50:06,885 - INFO - ðŸªœ Batch step - 2603 -- sub batch step 10415 -- lr 3.00e-04
2025-03-02 16:50:08,378 - INFO - Step 2603 -- ðŸ”„ Training Metrics
2025-03-02 16:50:08,379 - INFO - â”œâ”€â”€ Loss: 6.3398
2025-03-02 16:50:08,379 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:50:08,379 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:50:09,047 - INFO - ðŸªœ Batch step - 2604 -- sub batch step 10416 -- lr 3.00e-04
2025-03-02 16:50:11,208 - INFO - ðŸªœ Batch step - 2604 -- sub batch step 10417 -- lr 3.00e-04
2025-03-02 16:50:13,356 - INFO - ðŸªœ Batch step - 2604 -- sub batch step 10418 -- lr 3.00e-04
2025-03-02 16:50:15,537 - INFO - ðŸªœ Batch step - 2604 -- sub batch step 10419 -- lr 3.00e-04
2025-03-02 16:50:17,088 - INFO - Step 2604 -- ðŸ”„ Training Metrics
2025-03-02 16:50:17,088 - INFO - â”œâ”€â”€ Loss: 6.3536
2025-03-02 16:50:17,088 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:50:17,088 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:50:17,758 - INFO - ðŸªœ Batch step - 2605 -- sub batch step 10420 -- lr 3.00e-04
2025-03-02 16:50:19,909 - INFO - ðŸªœ Batch step - 2605 -- sub batch step 10421 -- lr 3.00e-04
2025-03-02 16:50:22,065 - INFO - ðŸªœ Batch step - 2605 -- sub batch step 10422 -- lr 3.00e-04
2025-03-02 16:50:24,732 - INFO - ðŸªœ Batch step - 2605 -- sub batch step 10423 -- lr 3.00e-04
2025-03-02 16:50:26,288 - INFO - Step 2605 -- ðŸ”„ Training Metrics
2025-03-02 16:50:26,288 - INFO - â”œâ”€â”€ Loss: 6.3242
2025-03-02 16:50:26,288 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:50:26,288 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:50:26,963 - INFO - ðŸªœ Batch step - 2606 -- sub batch step 10424 -- lr 3.00e-04
2025-03-02 16:50:29,116 - INFO - ðŸªœ Batch step - 2606 -- sub batch step 10425 -- lr 3.00e-04
2025-03-02 16:50:31,263 - INFO - ðŸªœ Batch step - 2606 -- sub batch step 10426 -- lr 3.00e-04
2025-03-02 16:50:33,443 - INFO - ðŸªœ Batch step - 2606 -- sub batch step 10427 -- lr 3.00e-04
2025-03-02 16:50:34,989 - INFO - Step 2606 -- ðŸ”„ Training Metrics
2025-03-02 16:50:34,990 - INFO - â”œâ”€â”€ Loss: 6.3264
2025-03-02 16:50:34,990 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:50:34,990 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:50:35,657 - INFO - ðŸªœ Batch step - 2607 -- sub batch step 10428 -- lr 3.00e-04
2025-03-02 16:50:37,816 - INFO - ðŸªœ Batch step - 2607 -- sub batch step 10429 -- lr 3.00e-04
2025-03-02 16:50:39,969 - INFO - ðŸªœ Batch step - 2607 -- sub batch step 10430 -- lr 3.00e-04
2025-03-02 16:50:42,674 - INFO - ðŸªœ Batch step - 2607 -- sub batch step 10431 -- lr 3.00e-04
2025-03-02 16:50:44,167 - INFO - Step 2607 -- ðŸ”„ Training Metrics
2025-03-02 16:50:44,167 - INFO - â”œâ”€â”€ Loss: 6.3414
2025-03-02 16:50:44,167 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:50:44,167 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:50:44,837 - INFO - ðŸªœ Batch step - 2608 -- sub batch step 10432 -- lr 3.00e-04
2025-03-02 16:50:46,988 - INFO - ðŸªœ Batch step - 2608 -- sub batch step 10433 -- lr 3.00e-04
2025-03-02 16:50:49,141 - INFO - ðŸªœ Batch step - 2608 -- sub batch step 10434 -- lr 3.00e-04
2025-03-02 16:50:51,323 - INFO - ðŸªœ Batch step - 2608 -- sub batch step 10435 -- lr 3.00e-04
2025-03-02 16:50:52,871 - INFO - Step 2608 -- ðŸ”„ Training Metrics
2025-03-02 16:50:52,872 - INFO - â”œâ”€â”€ Loss: 6.3371
2025-03-02 16:50:52,872 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:50:52,872 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:50:53,539 - INFO - ðŸªœ Batch step - 2609 -- sub batch step 10436 -- lr 3.00e-04
2025-03-02 16:50:55,693 - INFO - ðŸªœ Batch step - 2609 -- sub batch step 10437 -- lr 3.00e-04
2025-03-02 16:50:57,840 - INFO - ðŸªœ Batch step - 2609 -- sub batch step 10438 -- lr 3.00e-04
2025-03-02 16:51:00,560 - INFO - ðŸªœ Batch step - 2609 -- sub batch step 10439 -- lr 3.00e-04
2025-03-02 16:51:02,071 - INFO - Step 2609 -- ðŸ”„ Training Metrics
2025-03-02 16:51:02,071 - INFO - â”œâ”€â”€ Loss: 6.3590
2025-03-02 16:51:02,071 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:51:02,071 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:51:02,744 - INFO - ðŸªœ Batch step - 2610 -- sub batch step 10440 -- lr 3.00e-04
2025-03-02 16:51:04,897 - INFO - ðŸªœ Batch step - 2610 -- sub batch step 10441 -- lr 3.00e-04
2025-03-02 16:51:07,048 - INFO - ðŸªœ Batch step - 2610 -- sub batch step 10442 -- lr 3.00e-04
2025-03-02 16:51:09,214 - INFO - ðŸªœ Batch step - 2610 -- sub batch step 10443 -- lr 3.00e-04
2025-03-02 16:51:10,766 - INFO - Step 2610 -- ðŸ”„ Training Metrics
2025-03-02 16:51:10,766 - INFO - â”œâ”€â”€ Loss: 6.3013
2025-03-02 16:51:10,767 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:51:10,767 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:51:11,442 - INFO - ðŸªœ Batch step - 2611 -- sub batch step 10444 -- lr 3.00e-04
2025-03-02 16:51:13,594 - INFO - ðŸªœ Batch step - 2611 -- sub batch step 10445 -- lr 3.00e-04
2025-03-02 16:51:16,286 - INFO - ðŸªœ Batch step - 2611 -- sub batch step 10446 -- lr 3.00e-04
2025-03-02 16:51:18,443 - INFO - ðŸªœ Batch step - 2611 -- sub batch step 10447 -- lr 3.00e-04
2025-03-02 16:51:19,967 - INFO - Step 2611 -- ðŸ”„ Training Metrics
2025-03-02 16:51:19,968 - INFO - â”œâ”€â”€ Loss: 6.3497
2025-03-02 16:51:19,968 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:51:19,968 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:51:20,632 - INFO - ðŸªœ Batch step - 2612 -- sub batch step 10448 -- lr 3.00e-04
2025-03-02 16:51:22,793 - INFO - ðŸªœ Batch step - 2612 -- sub batch step 10449 -- lr 3.00e-04
2025-03-02 16:51:24,965 - INFO - ðŸªœ Batch step - 2612 -- sub batch step 10450 -- lr 3.00e-04
2025-03-02 16:51:27,120 - INFO - ðŸªœ Batch step - 2612 -- sub batch step 10451 -- lr 3.00e-04
2025-03-02 16:51:28,675 - INFO - Step 2612 -- ðŸ”„ Training Metrics
2025-03-02 16:51:28,676 - INFO - â”œâ”€â”€ Loss: 6.3391
2025-03-02 16:51:28,676 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:51:28,676 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:51:29,346 - INFO - ðŸªœ Batch step - 2613 -- sub batch step 10452 -- lr 3.00e-04
2025-03-02 16:51:31,494 - INFO - ðŸªœ Batch step - 2613 -- sub batch step 10453 -- lr 3.00e-04
2025-03-02 16:51:34,219 - INFO - ðŸªœ Batch step - 2613 -- sub batch step 10454 -- lr 3.00e-04
2025-03-02 16:51:36,370 - INFO - ðŸªœ Batch step - 2613 -- sub batch step 10455 -- lr 3.00e-04
2025-03-02 16:51:37,944 - INFO - Step 2613 -- ðŸ”„ Training Metrics
2025-03-02 16:51:37,944 - INFO - â”œâ”€â”€ Loss: 6.3170
2025-03-02 16:51:37,944 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:51:37,945 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:51:38,612 - INFO - ðŸªœ Batch step - 2614 -- sub batch step 10456 -- lr 3.00e-04
2025-03-02 16:51:40,769 - INFO - ðŸªœ Batch step - 2614 -- sub batch step 10457 -- lr 3.00e-04
2025-03-02 16:51:42,934 - INFO - ðŸªœ Batch step - 2614 -- sub batch step 10458 -- lr 3.00e-04
2025-03-02 16:51:45,092 - INFO - ðŸªœ Batch step - 2614 -- sub batch step 10459 -- lr 3.00e-04
2025-03-02 16:51:46,647 - INFO - Step 2614 -- ðŸ”„ Training Metrics
2025-03-02 16:51:46,647 - INFO - â”œâ”€â”€ Loss: 6.3435
2025-03-02 16:51:46,647 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:51:46,647 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:51:47,317 - INFO - ðŸªœ Batch step - 2615 -- sub batch step 10460 -- lr 3.00e-04
2025-03-02 16:51:49,473 - INFO - ðŸªœ Batch step - 2615 -- sub batch step 10461 -- lr 3.00e-04
2025-03-02 16:51:51,850 - INFO - ðŸªœ Batch step - 2615 -- sub batch step 10462 -- lr 3.00e-04
2025-03-02 16:51:54,005 - INFO - ðŸªœ Batch step - 2615 -- sub batch step 10463 -- lr 3.00e-04
2025-03-02 16:51:55,943 - INFO - Step 2615 -- ðŸ”„ Training Metrics
2025-03-02 16:51:55,943 - INFO - â”œâ”€â”€ Loss: 6.3604
2025-03-02 16:51:55,944 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:51:55,944 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:51:56,618 - INFO - ðŸªœ Batch step - 2616 -- sub batch step 10464 -- lr 3.00e-04
2025-03-02 16:51:58,772 - INFO - ðŸªœ Batch step - 2616 -- sub batch step 10465 -- lr 3.00e-04
2025-03-02 16:52:00,943 - INFO - ðŸªœ Batch step - 2616 -- sub batch step 10466 -- lr 3.00e-04
2025-03-02 16:52:03,098 - INFO - ðŸªœ Batch step - 2616 -- sub batch step 10467 -- lr 3.00e-04
2025-03-02 16:52:04,659 - INFO - Step 2616 -- ðŸ”„ Training Metrics
2025-03-02 16:52:04,660 - INFO - â”œâ”€â”€ Loss: 6.3491
2025-03-02 16:52:04,660 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:52:04,660 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:52:05,324 - INFO - ðŸªœ Batch step - 2617 -- sub batch step 10468 -- lr 3.00e-04
2025-03-02 16:52:07,486 - INFO - ðŸªœ Batch step - 2617 -- sub batch step 10469 -- lr 3.00e-04
2025-03-02 16:52:10,116 - INFO - ðŸªœ Batch step - 2617 -- sub batch step 10470 -- lr 3.00e-04
2025-03-02 16:52:12,268 - INFO - ðŸªœ Batch step - 2617 -- sub batch step 10471 -- lr 3.00e-04
2025-03-02 16:52:13,944 - INFO - Step 2617 -- ðŸ”„ Training Metrics
2025-03-02 16:52:13,945 - INFO - â”œâ”€â”€ Loss: 6.3150
2025-03-02 16:52:13,945 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:52:13,945 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:52:14,616 - INFO - ðŸªœ Batch step - 2618 -- sub batch step 10472 -- lr 3.00e-04
2025-03-02 16:52:16,763 - INFO - ðŸªœ Batch step - 2618 -- sub batch step 10473 -- lr 3.00e-04
2025-03-02 16:52:18,938 - INFO - ðŸªœ Batch step - 2618 -- sub batch step 10474 -- lr 3.00e-04
2025-03-02 16:52:21,090 - INFO - ðŸªœ Batch step - 2618 -- sub batch step 10475 -- lr 3.00e-04
2025-03-02 16:52:22,660 - INFO - Step 2618 -- ðŸ”„ Training Metrics
2025-03-02 16:52:22,661 - INFO - â”œâ”€â”€ Loss: 6.2974
2025-03-02 16:52:22,661 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:52:22,661 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:52:23,327 - INFO - ðŸªœ Batch step - 2619 -- sub batch step 10476 -- lr 3.00e-04
2025-03-02 16:52:25,479 - INFO - ðŸªœ Batch step - 2619 -- sub batch step 10477 -- lr 3.00e-04
2025-03-02 16:52:27,754 - INFO - ðŸªœ Batch step - 2619 -- sub batch step 10478 -- lr 3.00e-04
2025-03-02 16:52:29,911 - INFO - ðŸªœ Batch step - 2619 -- sub batch step 10479 -- lr 3.00e-04
2025-03-02 16:52:31,485 - INFO - Step 2619 -- ðŸ”„ Training Metrics
2025-03-02 16:52:31,486 - INFO - â”œâ”€â”€ Loss: 6.3141
2025-03-02 16:52:31,486 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:52:31,486 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:52:32,775 - INFO - ðŸªœ Batch step - 2620 -- sub batch step 10480 -- lr 3.00e-04
2025-03-02 16:52:34,928 - INFO - ðŸªœ Batch step - 2620 -- sub batch step 10481 -- lr 3.00e-04
2025-03-02 16:52:37,080 - INFO - ðŸªœ Batch step - 2620 -- sub batch step 10482 -- lr 3.00e-04
2025-03-02 16:52:39,249 - INFO - ðŸªœ Batch step - 2620 -- sub batch step 10483 -- lr 3.00e-04
2025-03-02 16:52:46,334 - INFO - Step 2620 -- ðŸ”„ Training Metrics
2025-03-02 16:52:46,334 - INFO - â”œâ”€â”€ Loss: 6.3375
2025-03-02 16:52:46,334 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:52:46,334 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:52:47,013 - INFO - ðŸªœ Batch step - 2621 -- sub batch step 10484 -- lr 3.00e-04
2025-03-02 16:52:49,172 - INFO - ðŸªœ Batch step - 2621 -- sub batch step 10485 -- lr 3.00e-04
2025-03-02 16:52:51,324 - INFO - ðŸªœ Batch step - 2621 -- sub batch step 10486 -- lr 3.00e-04
2025-03-02 16:52:53,836 - INFO - ðŸªœ Batch step - 2621 -- sub batch step 10487 -- lr 3.00e-04
2025-03-02 16:52:55,922 - INFO - Step 2621 -- ðŸ”„ Training Metrics
2025-03-02 16:52:55,923 - INFO - â”œâ”€â”€ Loss: 6.3421
2025-03-02 16:52:55,923 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:52:55,923 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:52:56,592 - INFO - ðŸªœ Batch step - 2622 -- sub batch step 10488 -- lr 3.00e-04
2025-03-02 16:52:58,755 - INFO - ðŸªœ Batch step - 2622 -- sub batch step 10489 -- lr 3.00e-04
2025-03-02 16:53:00,914 - INFO - ðŸªœ Batch step - 2622 -- sub batch step 10490 -- lr 3.00e-04
2025-03-02 16:53:03,085 - INFO - ðŸªœ Batch step - 2622 -- sub batch step 10491 -- lr 3.00e-04
2025-03-02 16:53:04,623 - INFO - Step 2622 -- ðŸ”„ Training Metrics
2025-03-02 16:53:04,623 - INFO - â”œâ”€â”€ Loss: 6.3255
2025-03-02 16:53:04,623 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:53:04,624 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:53:05,301 - INFO - ðŸªœ Batch step - 2623 -- sub batch step 10492 -- lr 3.00e-04
2025-03-02 16:53:07,451 - INFO - ðŸªœ Batch step - 2623 -- sub batch step 10493 -- lr 3.00e-04
2025-03-02 16:53:09,608 - INFO - ðŸªœ Batch step - 2623 -- sub batch step 10494 -- lr 3.00e-04
2025-03-02 16:53:12,289 - INFO - ðŸªœ Batch step - 2623 -- sub batch step 10495 -- lr 3.00e-04
2025-03-02 16:53:14,108 - INFO - Step 2623 -- ðŸ”„ Training Metrics
2025-03-02 16:53:14,108 - INFO - â”œâ”€â”€ Loss: 6.3149
2025-03-02 16:53:14,108 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:53:14,108 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:53:14,777 - INFO - ðŸªœ Batch step - 2624 -- sub batch step 10496 -- lr 3.00e-04
2025-03-02 16:53:16,932 - INFO - ðŸªœ Batch step - 2624 -- sub batch step 10497 -- lr 3.00e-04
2025-03-02 16:53:19,082 - INFO - ðŸªœ Batch step - 2624 -- sub batch step 10498 -- lr 3.00e-04
2025-03-02 16:53:21,250 - INFO - ðŸªœ Batch step - 2624 -- sub batch step 10499 -- lr 3.00e-04
2025-03-02 16:53:22,815 - INFO - Step 2624 -- ðŸ”„ Training Metrics
2025-03-02 16:53:22,815 - INFO - â”œâ”€â”€ Loss: 6.3178
2025-03-02 16:53:22,815 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:53:22,815 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:53:23,485 - INFO - ðŸªœ Batch step - 2625 -- sub batch step 10500 -- lr 3.00e-04
2025-03-02 16:53:25,631 - INFO - ðŸªœ Batch step - 2625 -- sub batch step 10501 -- lr 3.00e-04
2025-03-02 16:53:27,781 - INFO - ðŸªœ Batch step - 2625 -- sub batch step 10502 -- lr 3.00e-04
2025-03-02 16:53:30,617 - INFO - ðŸªœ Batch step - 2625 -- sub batch step 10503 -- lr 3.00e-04
2025-03-02 16:53:32,111 - INFO - Step 2625 -- ðŸ”„ Training Metrics
2025-03-02 16:53:32,111 - INFO - â”œâ”€â”€ Loss: 6.3300
2025-03-02 16:53:32,111 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:53:32,112 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:53:32,781 - INFO - ðŸªœ Batch step - 2626 -- sub batch step 10504 -- lr 3.00e-04
2025-03-02 16:53:34,932 - INFO - ðŸªœ Batch step - 2626 -- sub batch step 10505 -- lr 3.00e-04
2025-03-02 16:53:37,077 - INFO - ðŸªœ Batch step - 2626 -- sub batch step 10506 -- lr 3.00e-04
2025-03-02 16:53:39,249 - INFO - ðŸªœ Batch step - 2626 -- sub batch step 10507 -- lr 3.00e-04
2025-03-02 16:53:40,818 - INFO - Step 2626 -- ðŸ”„ Training Metrics
2025-03-02 16:53:40,818 - INFO - â”œâ”€â”€ Loss: 6.3427
2025-03-02 16:53:40,818 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:53:40,819 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:53:41,486 - INFO - ðŸªœ Batch step - 2627 -- sub batch step 10508 -- lr 3.00e-04
2025-03-02 16:53:43,639 - INFO - ðŸªœ Batch step - 2627 -- sub batch step 10509 -- lr 3.00e-04
2025-03-02 16:53:45,792 - INFO - ðŸªœ Batch step - 2627 -- sub batch step 10510 -- lr 3.00e-04
2025-03-02 16:53:48,464 - INFO - ðŸªœ Batch step - 2627 -- sub batch step 10511 -- lr 3.00e-04
2025-03-02 16:53:50,227 - INFO - Step 2627 -- ðŸ”„ Training Metrics
2025-03-02 16:53:50,227 - INFO - â”œâ”€â”€ Loss: 6.2940
2025-03-02 16:53:50,227 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:53:50,227 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:53:50,898 - INFO - ðŸªœ Batch step - 2628 -- sub batch step 10512 -- lr 3.00e-04
2025-03-02 16:53:53,042 - INFO - ðŸªœ Batch step - 2628 -- sub batch step 10513 -- lr 3.00e-04
2025-03-02 16:53:55,197 - INFO - ðŸªœ Batch step - 2628 -- sub batch step 10514 -- lr 3.00e-04
2025-03-02 16:53:57,368 - INFO - ðŸªœ Batch step - 2628 -- sub batch step 10515 -- lr 3.00e-04
2025-03-02 16:53:58,938 - INFO - Step 2628 -- ðŸ”„ Training Metrics
2025-03-02 16:53:58,938 - INFO - â”œâ”€â”€ Loss: 6.2987
2025-03-02 16:53:58,939 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:53:58,939 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:53:59,605 - INFO - ðŸªœ Batch step - 2629 -- sub batch step 10516 -- lr 3.00e-04
2025-03-02 16:54:01,757 - INFO - ðŸªœ Batch step - 2629 -- sub batch step 10517 -- lr 3.00e-04
2025-03-02 16:54:03,903 - INFO - ðŸªœ Batch step - 2629 -- sub batch step 10518 -- lr 3.00e-04
2025-03-02 16:54:06,573 - INFO - ðŸªœ Batch step - 2629 -- sub batch step 10519 -- lr 3.00e-04
2025-03-02 16:54:08,179 - INFO - Step 2629 -- ðŸ”„ Training Metrics
2025-03-02 16:54:08,179 - INFO - â”œâ”€â”€ Loss: 6.3055
2025-03-02 16:54:08,179 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:54:08,180 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:54:08,853 - INFO - ðŸªœ Batch step - 2630 -- sub batch step 10520 -- lr 3.00e-04
2025-03-02 16:54:10,999 - INFO - ðŸªœ Batch step - 2630 -- sub batch step 10521 -- lr 3.00e-04
2025-03-02 16:54:13,150 - INFO - ðŸªœ Batch step - 2630 -- sub batch step 10522 -- lr 3.00e-04
2025-03-02 16:54:15,310 - INFO - ðŸªœ Batch step - 2630 -- sub batch step 10523 -- lr 3.00e-04
2025-03-02 16:54:16,878 - INFO - Step 2630 -- ðŸ”„ Training Metrics
2025-03-02 16:54:16,878 - INFO - â”œâ”€â”€ Loss: 6.3151
2025-03-02 16:54:16,878 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:54:16,878 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:54:17,547 - INFO - ðŸªœ Batch step - 2631 -- sub batch step 10524 -- lr 3.00e-04
2025-03-02 16:54:19,696 - INFO - ðŸªœ Batch step - 2631 -- sub batch step 10525 -- lr 3.00e-04
2025-03-02 16:54:22,499 - INFO - ðŸªœ Batch step - 2631 -- sub batch step 10526 -- lr 3.00e-04
2025-03-02 16:54:24,654 - INFO - ðŸªœ Batch step - 2631 -- sub batch step 10527 -- lr 3.00e-04
2025-03-02 16:54:26,145 - INFO - Step 2631 -- ðŸ”„ Training Metrics
2025-03-02 16:54:26,146 - INFO - â”œâ”€â”€ Loss: 6.3447
2025-03-02 16:54:26,146 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:54:26,146 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:54:26,810 - INFO - ðŸªœ Batch step - 2632 -- sub batch step 10528 -- lr 3.00e-04
2025-03-02 16:54:28,965 - INFO - ðŸªœ Batch step - 2632 -- sub batch step 10529 -- lr 3.00e-04
2025-03-02 16:54:31,135 - INFO - ðŸªœ Batch step - 2632 -- sub batch step 10530 -- lr 3.00e-04
2025-03-02 16:54:33,282 - INFO - ðŸªœ Batch step - 2632 -- sub batch step 10531 -- lr 3.00e-04
2025-03-02 16:54:34,848 - INFO - Step 2632 -- ðŸ”„ Training Metrics
2025-03-02 16:54:34,849 - INFO - â”œâ”€â”€ Loss: 6.3051
2025-03-02 16:54:34,849 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:54:34,849 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:54:35,519 - INFO - ðŸªœ Batch step - 2633 -- sub batch step 10532 -- lr 3.00e-04
2025-03-02 16:54:37,665 - INFO - ðŸªœ Batch step - 2633 -- sub batch step 10533 -- lr 3.00e-04
2025-03-02 16:54:40,502 - INFO - ðŸªœ Batch step - 2633 -- sub batch step 10534 -- lr 3.00e-04
2025-03-02 16:54:42,657 - INFO - ðŸªœ Batch step - 2633 -- sub batch step 10535 -- lr 3.00e-04
2025-03-02 16:54:44,259 - INFO - Step 2633 -- ðŸ”„ Training Metrics
2025-03-02 16:54:44,260 - INFO - â”œâ”€â”€ Loss: 6.3449
2025-03-02 16:54:44,260 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:54:44,260 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:54:44,925 - INFO - ðŸªœ Batch step - 2634 -- sub batch step 10536 -- lr 3.00e-04
2025-03-02 16:54:47,077 - INFO - ðŸªœ Batch step - 2634 -- sub batch step 10537 -- lr 3.00e-04
2025-03-02 16:54:49,243 - INFO - ðŸªœ Batch step - 2634 -- sub batch step 10538 -- lr 3.00e-04
2025-03-02 16:54:51,398 - INFO - ðŸªœ Batch step - 2634 -- sub batch step 10539 -- lr 3.00e-04
2025-03-02 16:54:52,962 - INFO - Step 2634 -- ðŸ”„ Training Metrics
2025-03-02 16:54:52,962 - INFO - â”œâ”€â”€ Loss: 6.3185
2025-03-02 16:54:52,962 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:54:52,962 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:54:53,632 - INFO - ðŸªœ Batch step - 2635 -- sub batch step 10540 -- lr 3.00e-04
2025-03-02 16:54:55,779 - INFO - ðŸªœ Batch step - 2635 -- sub batch step 10541 -- lr 3.00e-04
2025-03-02 16:54:58,422 - INFO - ðŸªœ Batch step - 2635 -- sub batch step 10542 -- lr 3.00e-04
2025-03-02 16:55:00,565 - INFO - ðŸªœ Batch step - 2635 -- sub batch step 10543 -- lr 3.00e-04
2025-03-02 16:55:02,336 - INFO - Step 2635 -- ðŸ”„ Training Metrics
2025-03-02 16:55:02,336 - INFO - â”œâ”€â”€ Loss: 6.3351
2025-03-02 16:55:02,336 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:55:02,336 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:55:03,008 - INFO - ðŸªœ Batch step - 2636 -- sub batch step 10544 -- lr 3.00e-04
2025-03-02 16:55:05,159 - INFO - ðŸªœ Batch step - 2636 -- sub batch step 10545 -- lr 3.00e-04
2025-03-02 16:55:07,324 - INFO - ðŸªœ Batch step - 2636 -- sub batch step 10546 -- lr 3.00e-04
2025-03-02 16:55:09,473 - INFO - ðŸªœ Batch step - 2636 -- sub batch step 10547 -- lr 3.00e-04
2025-03-02 16:55:11,036 - INFO - Step 2636 -- ðŸ”„ Training Metrics
2025-03-02 16:55:11,037 - INFO - â”œâ”€â”€ Loss: 6.3301
2025-03-02 16:55:11,037 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:55:11,037 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:55:11,702 - INFO - ðŸªœ Batch step - 2637 -- sub batch step 10548 -- lr 3.00e-04
2025-03-02 16:55:13,856 - INFO - ðŸªœ Batch step - 2637 -- sub batch step 10549 -- lr 3.00e-04
2025-03-02 16:55:16,539 - INFO - ðŸªœ Batch step - 2637 -- sub batch step 10550 -- lr 3.00e-04
2025-03-02 16:55:18,688 - INFO - ðŸªœ Batch step - 2637 -- sub batch step 10551 -- lr 3.00e-04
2025-03-02 16:55:20,235 - INFO - Step 2637 -- ðŸ”„ Training Metrics
2025-03-02 16:55:20,235 - INFO - â”œâ”€â”€ Loss: 6.3241
2025-03-02 16:55:20,235 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:55:20,235 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:55:20,905 - INFO - ðŸªœ Batch step - 2638 -- sub batch step 10552 -- lr 3.00e-04
2025-03-02 16:55:23,050 - INFO - ðŸªœ Batch step - 2638 -- sub batch step 10553 -- lr 3.00e-04
2025-03-02 16:55:25,220 - INFO - ðŸªœ Batch step - 2638 -- sub batch step 10554 -- lr 3.00e-04
2025-03-02 16:55:27,372 - INFO - ðŸªœ Batch step - 2638 -- sub batch step 10555 -- lr 3.00e-04
2025-03-02 16:55:28,938 - INFO - Step 2638 -- ðŸ”„ Training Metrics
2025-03-02 16:55:28,939 - INFO - â”œâ”€â”€ Loss: 6.3081
2025-03-02 16:55:28,939 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:55:28,939 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:55:29,605 - INFO - ðŸªœ Batch step - 2639 -- sub batch step 10556 -- lr 3.00e-04
2025-03-02 16:55:31,755 - INFO - ðŸªœ Batch step - 2639 -- sub batch step 10557 -- lr 3.00e-04
2025-03-02 16:55:34,028 - INFO - ðŸªœ Batch step - 2639 -- sub batch step 10558 -- lr 3.00e-04
2025-03-02 16:55:36,185 - INFO - ðŸªœ Batch step - 2639 -- sub batch step 10559 -- lr 3.00e-04
2025-03-02 16:55:38,358 - INFO - Step 2639 -- ðŸ”„ Training Metrics
2025-03-02 16:55:38,359 - INFO - â”œâ”€â”€ Loss: 6.3211
2025-03-02 16:55:38,359 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:55:38,359 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:55:39,785 - INFO - ðŸªœ Batch step - 2640 -- sub batch step 10560 -- lr 3.00e-04
2025-03-02 16:55:41,942 - INFO - ðŸªœ Batch step - 2640 -- sub batch step 10561 -- lr 3.00e-04
2025-03-02 16:55:44,097 - INFO - ðŸªœ Batch step - 2640 -- sub batch step 10562 -- lr 3.00e-04
2025-03-02 16:55:46,269 - INFO - ðŸªœ Batch step - 2640 -- sub batch step 10563 -- lr 3.00e-04
2025-03-02 16:55:47,758 - INFO - Step 2640 -- ðŸ”„ Training Metrics
2025-03-02 16:55:47,758 - INFO - â”œâ”€â”€ Loss: 6.3253
2025-03-02 16:55:47,758 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:55:47,759 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:55:48,433 - INFO - ðŸªœ Batch step - 2641 -- sub batch step 10564 -- lr 3.00e-04
2025-03-02 16:55:50,586 - INFO - ðŸªœ Batch step - 2641 -- sub batch step 10565 -- lr 3.00e-04
2025-03-02 16:55:52,733 - INFO - ðŸªœ Batch step - 2641 -- sub batch step 10566 -- lr 3.00e-04
2025-03-02 16:55:55,524 - INFO - ðŸªœ Batch step - 2641 -- sub batch step 10567 -- lr 3.00e-04
2025-03-02 16:55:57,014 - INFO - Step 2641 -- ðŸ”„ Training Metrics
2025-03-02 16:55:57,014 - INFO - â”œâ”€â”€ Loss: 6.3446
2025-03-02 16:55:57,014 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:55:57,015 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:55:57,682 - INFO - ðŸªœ Batch step - 2642 -- sub batch step 10568 -- lr 3.00e-04
2025-03-02 16:55:59,835 - INFO - ðŸªœ Batch step - 2642 -- sub batch step 10569 -- lr 3.00e-04
2025-03-02 16:56:01,993 - INFO - ðŸªœ Batch step - 2642 -- sub batch step 10570 -- lr 3.00e-04
2025-03-02 16:56:04,159 - INFO - ðŸªœ Batch step - 2642 -- sub batch step 10571 -- lr 3.00e-04
2025-03-02 16:56:05,726 - INFO - Step 2642 -- ðŸ”„ Training Metrics
2025-03-02 16:56:05,726 - INFO - â”œâ”€â”€ Loss: 6.2790
2025-03-02 16:56:05,726 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:56:05,726 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:56:06,399 - INFO - ðŸªœ Batch step - 2643 -- sub batch step 10572 -- lr 3.00e-04
2025-03-02 16:56:08,545 - INFO - ðŸªœ Batch step - 2643 -- sub batch step 10573 -- lr 3.00e-04
2025-03-02 16:56:10,697 - INFO - ðŸªœ Batch step - 2643 -- sub batch step 10574 -- lr 3.00e-04
2025-03-02 16:56:13,119 - INFO - ðŸªœ Batch step - 2643 -- sub batch step 10575 -- lr 3.00e-04
2025-03-02 16:56:15,062 - INFO - Step 2643 -- ðŸ”„ Training Metrics
2025-03-02 16:56:15,062 - INFO - â”œâ”€â”€ Loss: 6.3445
2025-03-02 16:56:15,062 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:56:15,062 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:56:15,725 - INFO - ðŸªœ Batch step - 2644 -- sub batch step 10576 -- lr 3.00e-04
2025-03-02 16:56:17,881 - INFO - ðŸªœ Batch step - 2644 -- sub batch step 10577 -- lr 3.00e-04
2025-03-02 16:56:20,029 - INFO - ðŸªœ Batch step - 2644 -- sub batch step 10578 -- lr 3.00e-04
2025-03-02 16:56:22,213 - INFO - ðŸªœ Batch step - 2644 -- sub batch step 10579 -- lr 3.00e-04
2025-03-02 16:56:23,784 - INFO - Step 2644 -- ðŸ”„ Training Metrics
2025-03-02 16:56:23,784 - INFO - â”œâ”€â”€ Loss: 6.3193
2025-03-02 16:56:23,784 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:56:23,784 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:56:24,456 - INFO - ðŸªœ Batch step - 2645 -- sub batch step 10580 -- lr 3.00e-04
2025-03-02 16:56:26,606 - INFO - ðŸªœ Batch step - 2645 -- sub batch step 10581 -- lr 3.00e-04
2025-03-02 16:56:28,760 - INFO - ðŸªœ Batch step - 2645 -- sub batch step 10582 -- lr 3.00e-04
2025-03-02 16:56:31,424 - INFO - ðŸªœ Batch step - 2645 -- sub batch step 10583 -- lr 3.00e-04
2025-03-02 16:56:33,474 - INFO - Step 2645 -- ðŸ”„ Training Metrics
2025-03-02 16:56:33,474 - INFO - â”œâ”€â”€ Loss: 6.3016
2025-03-02 16:56:33,474 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:56:33,474 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:56:34,149 - INFO - ðŸªœ Batch step - 2646 -- sub batch step 10584 -- lr 3.00e-04
2025-03-02 16:56:36,302 - INFO - ðŸªœ Batch step - 2646 -- sub batch step 10585 -- lr 3.00e-04
2025-03-02 16:56:38,448 - INFO - ðŸªœ Batch step - 2646 -- sub batch step 10586 -- lr 3.00e-04
2025-03-02 16:56:40,620 - INFO - ðŸªœ Batch step - 2646 -- sub batch step 10587 -- lr 3.00e-04
2025-03-02 16:56:42,194 - INFO - Step 2646 -- ðŸ”„ Training Metrics
2025-03-02 16:56:42,195 - INFO - â”œâ”€â”€ Loss: 6.3146
2025-03-02 16:56:42,195 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:56:42,195 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:56:42,861 - INFO - ðŸªœ Batch step - 2647 -- sub batch step 10588 -- lr 3.00e-04
2025-03-02 16:56:45,020 - INFO - ðŸªœ Batch step - 2647 -- sub batch step 10589 -- lr 3.00e-04
2025-03-02 16:56:47,175 - INFO - ðŸªœ Batch step - 2647 -- sub batch step 10590 -- lr 3.00e-04
2025-03-02 16:56:49,983 - INFO - ðŸªœ Batch step - 2647 -- sub batch step 10591 -- lr 3.00e-04
2025-03-02 16:56:51,477 - INFO - Step 2647 -- ðŸ”„ Training Metrics
2025-03-02 16:56:51,478 - INFO - â”œâ”€â”€ Loss: 6.3141
2025-03-02 16:56:51,478 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:56:51,478 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:56:52,156 - INFO - ðŸªœ Batch step - 2648 -- sub batch step 10592 -- lr 3.00e-04
2025-03-02 16:56:54,305 - INFO - ðŸªœ Batch step - 2648 -- sub batch step 10593 -- lr 3.00e-04
2025-03-02 16:56:56,461 - INFO - ðŸªœ Batch step - 2648 -- sub batch step 10594 -- lr 3.00e-04
2025-03-02 16:56:58,643 - INFO - ðŸªœ Batch step - 2648 -- sub batch step 10595 -- lr 3.00e-04
2025-03-02 16:57:00,197 - INFO - Step 2648 -- ðŸ”„ Training Metrics
2025-03-02 16:57:00,197 - INFO - â”œâ”€â”€ Loss: 6.3099
2025-03-02 16:57:00,197 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:57:00,197 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:57:00,864 - INFO - ðŸªœ Batch step - 2649 -- sub batch step 10596 -- lr 3.00e-04
2025-03-02 16:57:03,022 - INFO - ðŸªœ Batch step - 2649 -- sub batch step 10597 -- lr 3.00e-04
2025-03-02 16:57:05,171 - INFO - ðŸªœ Batch step - 2649 -- sub batch step 10598 -- lr 3.00e-04
2025-03-02 16:57:07,853 - INFO - ðŸªœ Batch step - 2649 -- sub batch step 10599 -- lr 3.00e-04
2025-03-02 16:57:09,430 - INFO - Step 2649 -- ðŸ”„ Training Metrics
2025-03-02 16:57:09,431 - INFO - â”œâ”€â”€ Loss: 6.3172
2025-03-02 16:57:09,431 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:57:09,431 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:57:10,101 - INFO - ðŸªœ Batch step - 2650 -- sub batch step 10600 -- lr 3.00e-04
2025-03-02 16:57:12,248 - INFO - ðŸªœ Batch step - 2650 -- sub batch step 10601 -- lr 3.00e-04
2025-03-02 16:57:14,404 - INFO - ðŸªœ Batch step - 2650 -- sub batch step 10602 -- lr 3.00e-04
2025-03-02 16:57:16,571 - INFO - ðŸªœ Batch step - 2650 -- sub batch step 10603 -- lr 3.00e-04
2025-03-02 16:57:18,145 - INFO - Step 2650 -- ðŸ”„ Training Metrics
2025-03-02 16:57:18,145 - INFO - â”œâ”€â”€ Loss: 6.3153
2025-03-02 16:57:18,145 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:57:18,145 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:57:18,821 - INFO - ðŸªœ Batch step - 2651 -- sub batch step 10604 -- lr 3.00e-04
2025-03-02 16:57:20,975 - INFO - ðŸªœ Batch step - 2651 -- sub batch step 10605 -- lr 3.00e-04
2025-03-02 16:57:23,590 - INFO - ðŸªœ Batch step - 2651 -- sub batch step 10606 -- lr 3.00e-04
2025-03-02 16:57:25,753 - INFO - ðŸªœ Batch step - 2651 -- sub batch step 10607 -- lr 3.00e-04
2025-03-02 16:57:27,612 - INFO - Step 2651 -- ðŸ”„ Training Metrics
2025-03-02 16:57:27,613 - INFO - â”œâ”€â”€ Loss: 6.3206
2025-03-02 16:57:27,613 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:57:27,613 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:57:28,279 - INFO - ðŸªœ Batch step - 2652 -- sub batch step 10608 -- lr 3.00e-04
2025-03-02 16:57:30,433 - INFO - ðŸªœ Batch step - 2652 -- sub batch step 10609 -- lr 3.00e-04
2025-03-02 16:57:32,606 - INFO - ðŸªœ Batch step - 2652 -- sub batch step 10610 -- lr 3.00e-04
2025-03-02 16:57:34,758 - INFO - ðŸªœ Batch step - 2652 -- sub batch step 10611 -- lr 3.00e-04
2025-03-02 16:57:36,341 - INFO - Step 2652 -- ðŸ”„ Training Metrics
2025-03-02 16:57:36,342 - INFO - â”œâ”€â”€ Loss: 6.3311
2025-03-02 16:57:36,342 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:57:36,342 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:57:37,015 - INFO - ðŸªœ Batch step - 2653 -- sub batch step 10612 -- lr 3.00e-04
2025-03-02 16:57:39,165 - INFO - ðŸªœ Batch step - 2653 -- sub batch step 10613 -- lr 3.00e-04
2025-03-02 16:57:41,542 - INFO - ðŸªœ Batch step - 2653 -- sub batch step 10614 -- lr 3.00e-04
2025-03-02 16:57:43,696 - INFO - ðŸªœ Batch step - 2653 -- sub batch step 10615 -- lr 3.00e-04
2025-03-02 16:57:45,520 - INFO - Step 2653 -- ðŸ”„ Training Metrics
2025-03-02 16:57:45,520 - INFO - â”œâ”€â”€ Loss: 6.3194
2025-03-02 16:57:45,520 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:57:45,520 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:57:46,185 - INFO - ðŸªœ Batch step - 2654 -- sub batch step 10616 -- lr 3.00e-04
2025-03-02 16:57:48,340 - INFO - ðŸªœ Batch step - 2654 -- sub batch step 10617 -- lr 3.00e-04
2025-03-02 16:57:50,512 - INFO - ðŸªœ Batch step - 2654 -- sub batch step 10618 -- lr 3.00e-04
2025-03-02 16:57:52,665 - INFO - ðŸªœ Batch step - 2654 -- sub batch step 10619 -- lr 3.00e-04
2025-03-02 16:57:54,235 - INFO - Step 2654 -- ðŸ”„ Training Metrics
2025-03-02 16:57:54,236 - INFO - â”œâ”€â”€ Loss: 6.3307
2025-03-02 16:57:54,236 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:57:54,236 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:57:54,910 - INFO - ðŸªœ Batch step - 2655 -- sub batch step 10620 -- lr 3.00e-04
2025-03-02 16:57:57,063 - INFO - ðŸªœ Batch step - 2655 -- sub batch step 10621 -- lr 3.00e-04
2025-03-02 16:57:59,742 - INFO - ðŸªœ Batch step - 2655 -- sub batch step 10622 -- lr 3.00e-04
2025-03-02 16:58:01,897 - INFO - ðŸªœ Batch step - 2655 -- sub batch step 10623 -- lr 3.00e-04
2025-03-02 16:58:03,519 - INFO - Step 2655 -- ðŸ”„ Training Metrics
2025-03-02 16:58:03,519 - INFO - â”œâ”€â”€ Loss: 6.3005
2025-03-02 16:58:03,520 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:58:03,520 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:58:04,197 - INFO - ðŸªœ Batch step - 2656 -- sub batch step 10624 -- lr 3.00e-04
2025-03-02 16:58:06,351 - INFO - ðŸªœ Batch step - 2656 -- sub batch step 10625 -- lr 3.00e-04
2025-03-02 16:58:08,523 - INFO - ðŸªœ Batch step - 2656 -- sub batch step 10626 -- lr 3.00e-04
2025-03-02 16:58:10,675 - INFO - ðŸªœ Batch step - 2656 -- sub batch step 10627 -- lr 3.00e-04
2025-03-02 16:58:12,234 - INFO - Step 2656 -- ðŸ”„ Training Metrics
2025-03-02 16:58:12,234 - INFO - â”œâ”€â”€ Loss: 6.2932
2025-03-02 16:58:12,234 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:58:12,234 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:58:12,898 - INFO - ðŸªœ Batch step - 2657 -- sub batch step 10628 -- lr 3.00e-04
2025-03-02 16:58:15,052 - INFO - ðŸªœ Batch step - 2657 -- sub batch step 10629 -- lr 3.00e-04
2025-03-02 16:58:17,710 - INFO - ðŸªœ Batch step - 2657 -- sub batch step 10630 -- lr 3.00e-04
2025-03-02 16:58:19,857 - INFO - ðŸªœ Batch step - 2657 -- sub batch step 10631 -- lr 3.00e-04
2025-03-02 16:58:21,489 - INFO - Step 2657 -- ðŸ”„ Training Metrics
2025-03-02 16:58:21,489 - INFO - â”œâ”€â”€ Loss: 6.3101
2025-03-02 16:58:21,489 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:58:21,490 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:58:22,160 - INFO - ðŸªœ Batch step - 2658 -- sub batch step 10632 -- lr 3.00e-04
2025-03-02 16:58:24,314 - INFO - ðŸªœ Batch step - 2658 -- sub batch step 10633 -- lr 3.00e-04
2025-03-02 16:58:26,490 - INFO - ðŸªœ Batch step - 2658 -- sub batch step 10634 -- lr 3.00e-04
2025-03-02 16:58:28,642 - INFO - ðŸªœ Batch step - 2658 -- sub batch step 10635 -- lr 3.00e-04
2025-03-02 16:58:30,216 - INFO - Step 2658 -- ðŸ”„ Training Metrics
2025-03-02 16:58:30,216 - INFO - â”œâ”€â”€ Loss: 6.3008
2025-03-02 16:58:30,216 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:58:30,217 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:58:30,883 - INFO - ðŸªœ Batch step - 2659 -- sub batch step 10636 -- lr 3.00e-04
2025-03-02 16:58:33,037 - INFO - ðŸªœ Batch step - 2659 -- sub batch step 10637 -- lr 3.00e-04
2025-03-02 16:58:35,326 - INFO - ðŸªœ Batch step - 2659 -- sub batch step 10638 -- lr 3.00e-04
2025-03-02 16:58:37,484 - INFO - ðŸªœ Batch step - 2659 -- sub batch step 10639 -- lr 3.00e-04
2025-03-02 16:58:39,148 - INFO - Step 2659 -- ðŸ”„ Training Metrics
2025-03-02 16:58:39,148 - INFO - â”œâ”€â”€ Loss: 6.3540
2025-03-02 16:58:39,148 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:58:39,148 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:58:41,152 - INFO - ðŸªœ Batch step - 2660 -- sub batch step 10640 -- lr 3.00e-04
2025-03-02 16:58:43,312 - INFO - ðŸªœ Batch step - 2660 -- sub batch step 10641 -- lr 3.00e-04
2025-03-02 16:58:45,480 - INFO - ðŸªœ Batch step - 2660 -- sub batch step 10642 -- lr 3.00e-04
2025-03-02 16:58:47,661 - INFO - ðŸªœ Batch step - 2660 -- sub batch step 10643 -- lr 3.00e-04
2025-03-02 16:58:55,032 - INFO - Step 2660 -- ðŸ”„ Training Metrics
2025-03-02 16:58:55,032 - INFO - â”œâ”€â”€ Loss: 6.3021
2025-03-02 16:58:55,032 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:58:55,032 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:58:55,718 - INFO - ðŸªœ Batch step - 2661 -- sub batch step 10644 -- lr 3.00e-04
2025-03-02 16:58:57,884 - INFO - ðŸªœ Batch step - 2661 -- sub batch step 10645 -- lr 3.00e-04
2025-03-02 16:59:00,042 - INFO - ðŸªœ Batch step - 2661 -- sub batch step 10646 -- lr 3.00e-04
2025-03-02 16:59:02,637 - INFO - ðŸªœ Batch step - 2661 -- sub batch step 10647 -- lr 3.00e-04
2025-03-02 16:59:04,397 - INFO - Step 2661 -- ðŸ”„ Training Metrics
2025-03-02 16:59:04,398 - INFO - â”œâ”€â”€ Loss: 6.3151
2025-03-02 16:59:04,398 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:59:04,398 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:59:05,071 - INFO - ðŸªœ Batch step - 2662 -- sub batch step 10648 -- lr 3.00e-04
2025-03-02 16:59:07,245 - INFO - ðŸªœ Batch step - 2662 -- sub batch step 10649 -- lr 3.00e-04
2025-03-02 16:59:09,408 - INFO - ðŸªœ Batch step - 2662 -- sub batch step 10650 -- lr 3.00e-04
2025-03-02 16:59:11,585 - INFO - ðŸªœ Batch step - 2662 -- sub batch step 10651 -- lr 3.00e-04
2025-03-02 16:59:13,086 - INFO - Step 2662 -- ðŸ”„ Training Metrics
2025-03-02 16:59:13,086 - INFO - â”œâ”€â”€ Loss: 6.3144
2025-03-02 16:59:13,086 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:59:13,087 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:59:13,757 - INFO - ðŸªœ Batch step - 2663 -- sub batch step 10652 -- lr 3.00e-04
2025-03-02 16:59:15,918 - INFO - ðŸªœ Batch step - 2663 -- sub batch step 10653 -- lr 3.00e-04
2025-03-02 16:59:18,084 - INFO - ðŸªœ Batch step - 2663 -- sub batch step 10654 -- lr 3.00e-04
2025-03-02 16:59:20,722 - INFO - ðŸªœ Batch step - 2663 -- sub batch step 10655 -- lr 3.00e-04
2025-03-02 16:59:22,492 - INFO - Step 2663 -- ðŸ”„ Training Metrics
2025-03-02 16:59:22,493 - INFO - â”œâ”€â”€ Loss: 6.3192
2025-03-02 16:59:22,493 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:59:22,493 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:59:23,157 - INFO - ðŸªœ Batch step - 2664 -- sub batch step 10656 -- lr 3.00e-04
2025-03-02 16:59:25,322 - INFO - ðŸªœ Batch step - 2664 -- sub batch step 10657 -- lr 3.00e-04
2025-03-02 16:59:27,477 - INFO - ðŸªœ Batch step - 2664 -- sub batch step 10658 -- lr 3.00e-04
2025-03-02 16:59:29,654 - INFO - ðŸªœ Batch step - 2664 -- sub batch step 10659 -- lr 3.00e-04
2025-03-02 16:59:31,179 - INFO - Step 2664 -- ðŸ”„ Training Metrics
2025-03-02 16:59:31,179 - INFO - â”œâ”€â”€ Loss: 6.3003
2025-03-02 16:59:31,179 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:59:31,180 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:59:31,851 - INFO - ðŸªœ Batch step - 2665 -- sub batch step 10660 -- lr 3.00e-04
2025-03-02 16:59:34,005 - INFO - ðŸªœ Batch step - 2665 -- sub batch step 10661 -- lr 3.00e-04
2025-03-02 16:59:36,163 - INFO - ðŸªœ Batch step - 2665 -- sub batch step 10662 -- lr 3.00e-04
2025-03-02 16:59:38,822 - INFO - ðŸªœ Batch step - 2665 -- sub batch step 10663 -- lr 3.00e-04
2025-03-02 16:59:40,469 - INFO - Step 2665 -- ðŸ”„ Training Metrics
2025-03-02 16:59:40,470 - INFO - â”œâ”€â”€ Loss: 6.2879
2025-03-02 16:59:40,470 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:59:40,470 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:59:41,145 - INFO - ðŸªœ Batch step - 2666 -- sub batch step 10664 -- lr 3.00e-04
2025-03-02 16:59:43,302 - INFO - ðŸªœ Batch step - 2666 -- sub batch step 10665 -- lr 3.00e-04
2025-03-02 16:59:45,456 - INFO - ðŸªœ Batch step - 2666 -- sub batch step 10666 -- lr 3.00e-04
2025-03-02 16:59:47,639 - INFO - ðŸªœ Batch step - 2666 -- sub batch step 10667 -- lr 3.00e-04
2025-03-02 16:59:49,172 - INFO - Step 2666 -- ðŸ”„ Training Metrics
2025-03-02 16:59:49,173 - INFO - â”œâ”€â”€ Loss: 6.3050
2025-03-02 16:59:49,173 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:59:49,173 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:59:49,841 - INFO - ðŸªœ Batch step - 2667 -- sub batch step 10668 -- lr 3.00e-04
2025-03-02 16:59:51,995 - INFO - ðŸªœ Batch step - 2667 -- sub batch step 10669 -- lr 3.00e-04
2025-03-02 16:59:54,155 - INFO - ðŸªœ Batch step - 2667 -- sub batch step 10670 -- lr 3.00e-04
2025-03-02 16:59:56,856 - INFO - ðŸªœ Batch step - 2667 -- sub batch step 10671 -- lr 3.00e-04
2025-03-02 16:59:58,344 - INFO - Step 2667 -- ðŸ”„ Training Metrics
2025-03-02 16:59:58,345 - INFO - â”œâ”€â”€ Loss: 6.3499
2025-03-02 16:59:58,345 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 16:59:58,345 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 16:59:59,028 - INFO - ðŸªœ Batch step - 2668 -- sub batch step 10672 -- lr 3.00e-04
2025-03-02 17:00:01,182 - INFO - ðŸªœ Batch step - 2668 -- sub batch step 10673 -- lr 3.00e-04
2025-03-02 17:00:03,340 - INFO - ðŸªœ Batch step - 2668 -- sub batch step 10674 -- lr 3.00e-04
2025-03-02 17:00:05,520 - INFO - ðŸªœ Batch step - 2668 -- sub batch step 10675 -- lr 3.00e-04
2025-03-02 17:00:07,039 - INFO - Step 2668 -- ðŸ”„ Training Metrics
2025-03-02 17:00:07,040 - INFO - â”œâ”€â”€ Loss: 6.3119
2025-03-02 17:00:07,040 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:00:07,040 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:00:07,711 - INFO - ðŸªœ Batch step - 2669 -- sub batch step 10676 -- lr 3.00e-04
2025-03-02 17:00:09,867 - INFO - ðŸªœ Batch step - 2669 -- sub batch step 10677 -- lr 3.00e-04
2025-03-02 17:00:12,022 - INFO - ðŸªœ Batch step - 2669 -- sub batch step 10678 -- lr 3.00e-04
2025-03-02 17:00:14,679 - INFO - ðŸªœ Batch step - 2669 -- sub batch step 10679 -- lr 3.00e-04
2025-03-02 17:00:22,729 - INFO - Step 2669 -- ðŸ”„ Training Metrics
2025-03-02 17:00:22,729 - INFO - â”œâ”€â”€ Loss: 6.3077
2025-03-02 17:00:22,730 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:00:22,730 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:00:23,409 - INFO - ðŸªœ Batch step - 2670 -- sub batch step 10680 -- lr 3.00e-04
2025-03-02 17:00:25,560 - INFO - ðŸªœ Batch step - 2670 -- sub batch step 10681 -- lr 3.00e-04
2025-03-02 17:00:27,718 - INFO - ðŸªœ Batch step - 2670 -- sub batch step 10682 -- lr 3.00e-04
2025-03-02 17:00:29,883 - INFO - ðŸªœ Batch step - 2670 -- sub batch step 10683 -- lr 3.00e-04
2025-03-02 17:00:31,413 - INFO - Step 2670 -- ðŸ”„ Training Metrics
2025-03-02 17:00:31,414 - INFO - â”œâ”€â”€ Loss: 6.2914
2025-03-02 17:00:31,414 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:00:31,414 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:00:32,093 - INFO - ðŸªœ Batch step - 2671 -- sub batch step 10684 -- lr 3.00e-04
2025-03-02 17:00:34,246 - INFO - ðŸªœ Batch step - 2671 -- sub batch step 10685 -- lr 3.00e-04
2025-03-02 17:00:36,656 - INFO - ðŸªœ Batch step - 2671 -- sub batch step 10686 -- lr 3.00e-04
2025-03-02 17:00:38,817 - INFO - ðŸªœ Batch step - 2671 -- sub batch step 10687 -- lr 3.00e-04
2025-03-02 17:00:40,885 - INFO - Step 2671 -- ðŸ”„ Training Metrics
2025-03-02 17:00:40,885 - INFO - â”œâ”€â”€ Loss: 6.3132
2025-03-02 17:00:40,885 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:00:40,886 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:00:41,557 - INFO - ðŸªœ Batch step - 2672 -- sub batch step 10688 -- lr 3.00e-04
2025-03-02 17:00:43,708 - INFO - ðŸªœ Batch step - 2672 -- sub batch step 10689 -- lr 3.00e-04
2025-03-02 17:00:45,880 - INFO - ðŸªœ Batch step - 2672 -- sub batch step 10690 -- lr 3.00e-04
2025-03-02 17:00:48,028 - INFO - ðŸªœ Batch step - 2672 -- sub batch step 10691 -- lr 3.00e-04
2025-03-02 17:00:49,583 - INFO - Step 2672 -- ðŸ”„ Training Metrics
2025-03-02 17:00:49,584 - INFO - â”œâ”€â”€ Loss: 6.2938
2025-03-02 17:00:49,584 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:00:49,584 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:00:50,258 - INFO - ðŸªœ Batch step - 2673 -- sub batch step 10692 -- lr 3.00e-04
2025-03-02 17:00:52,406 - INFO - ðŸªœ Batch step - 2673 -- sub batch step 10693 -- lr 3.00e-04
2025-03-02 17:00:55,074 - INFO - ðŸªœ Batch step - 2673 -- sub batch step 10694 -- lr 3.00e-04
2025-03-02 17:00:57,230 - INFO - ðŸªœ Batch step - 2673 -- sub batch step 10695 -- lr 3.00e-04
2025-03-02 17:01:04,933 - INFO - Step 2673 -- ðŸ”„ Training Metrics
2025-03-02 17:01:04,933 - INFO - â”œâ”€â”€ Loss: 6.3100
2025-03-02 17:01:04,933 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:01:04,933 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:01:05,605 - INFO - ðŸªœ Batch step - 2674 -- sub batch step 10696 -- lr 3.00e-04
2025-03-02 17:01:07,763 - INFO - ðŸªœ Batch step - 2674 -- sub batch step 10697 -- lr 3.00e-04
2025-03-02 17:01:09,929 - INFO - ðŸªœ Batch step - 2674 -- sub batch step 10698 -- lr 3.00e-04
2025-03-02 17:01:12,088 - INFO - ðŸªœ Batch step - 2674 -- sub batch step 10699 -- lr 3.00e-04
2025-03-02 17:01:13,624 - INFO - Step 2674 -- ðŸ”„ Training Metrics
2025-03-02 17:01:13,625 - INFO - â”œâ”€â”€ Loss: 6.2884
2025-03-02 17:01:13,625 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:01:13,625 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:01:14,303 - INFO - ðŸªœ Batch step - 2675 -- sub batch step 10700 -- lr 3.00e-04
2025-03-02 17:01:16,457 - INFO - ðŸªœ Batch step - 2675 -- sub batch step 10701 -- lr 3.00e-04
2025-03-02 17:01:19,091 - INFO - ðŸªœ Batch step - 2675 -- sub batch step 10702 -- lr 3.00e-04
2025-03-02 17:01:21,249 - INFO - ðŸªœ Batch step - 2675 -- sub batch step 10703 -- lr 3.00e-04
2025-03-02 17:01:23,590 - INFO - Step 2675 -- ðŸ”„ Training Metrics
2025-03-02 17:01:23,591 - INFO - â”œâ”€â”€ Loss: 6.3015
2025-03-02 17:01:23,591 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:01:23,591 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:01:24,270 - INFO - ðŸªœ Batch step - 2676 -- sub batch step 10704 -- lr 3.00e-04
2025-03-02 17:01:26,426 - INFO - ðŸªœ Batch step - 2676 -- sub batch step 10705 -- lr 3.00e-04
2025-03-02 17:01:28,607 - INFO - ðŸªœ Batch step - 2676 -- sub batch step 10706 -- lr 3.00e-04
2025-03-02 17:01:30,764 - INFO - ðŸªœ Batch step - 2676 -- sub batch step 10707 -- lr 3.00e-04
2025-03-02 17:01:32,283 - INFO - Step 2676 -- ðŸ”„ Training Metrics
2025-03-02 17:01:32,283 - INFO - â”œâ”€â”€ Loss: 6.2973
2025-03-02 17:01:32,283 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:01:32,283 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:01:32,952 - INFO - ðŸªœ Batch step - 2677 -- sub batch step 10708 -- lr 3.00e-04
2025-03-02 17:01:35,105 - INFO - ðŸªœ Batch step - 2677 -- sub batch step 10709 -- lr 3.00e-04
2025-03-02 17:01:37,797 - INFO - ðŸªœ Batch step - 2677 -- sub batch step 10710 -- lr 3.00e-04
2025-03-02 17:01:39,951 - INFO - ðŸªœ Batch step - 2677 -- sub batch step 10711 -- lr 3.00e-04
2025-03-02 17:01:45,973 - INFO - Step 2677 -- ðŸ”„ Training Metrics
2025-03-02 17:01:45,974 - INFO - â”œâ”€â”€ Loss: 6.3028
2025-03-02 17:01:45,974 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:01:45,974 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:01:46,649 - INFO - ðŸªœ Batch step - 2678 -- sub batch step 10712 -- lr 3.00e-04
2025-03-02 17:01:48,803 - INFO - ðŸªœ Batch step - 2678 -- sub batch step 10713 -- lr 3.00e-04
2025-03-02 17:01:50,974 - INFO - ðŸªœ Batch step - 2678 -- sub batch step 10714 -- lr 3.00e-04
2025-03-02 17:01:53,128 - INFO - ðŸªœ Batch step - 2678 -- sub batch step 10715 -- lr 3.00e-04
2025-03-02 17:01:54,664 - INFO - Step 2678 -- ðŸ”„ Training Metrics
2025-03-02 17:01:54,664 - INFO - â”œâ”€â”€ Loss: 6.2817
2025-03-02 17:01:54,664 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:01:54,664 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:01:55,334 - INFO - ðŸªœ Batch step - 2679 -- sub batch step 10716 -- lr 3.00e-04
2025-03-02 17:01:57,492 - INFO - ðŸªœ Batch step - 2679 -- sub batch step 10717 -- lr 3.00e-04
2025-03-02 17:01:59,786 - INFO - ðŸªœ Batch step - 2679 -- sub batch step 10718 -- lr 3.00e-04
2025-03-02 17:02:01,945 - INFO - ðŸªœ Batch step - 2679 -- sub batch step 10719 -- lr 3.00e-04
2025-03-02 17:02:03,569 - INFO - Step 2679 -- ðŸ”„ Training Metrics
2025-03-02 17:02:03,569 - INFO - â”œâ”€â”€ Loss: 6.2967
2025-03-02 17:02:03,569 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:02:03,569 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:02:04,804 - INFO - ðŸªœ Batch step - 2680 -- sub batch step 10720 -- lr 3.00e-04
2025-03-02 17:02:06,968 - INFO - ðŸªœ Batch step - 2680 -- sub batch step 10721 -- lr 3.00e-04
2025-03-02 17:02:09,130 - INFO - ðŸªœ Batch step - 2680 -- sub batch step 10722 -- lr 3.00e-04
2025-03-02 17:02:11,311 - INFO - ðŸªœ Batch step - 2680 -- sub batch step 10723 -- lr 3.00e-04
2025-03-02 17:02:12,880 - INFO - Step 2680 -- ðŸ”„ Training Metrics
2025-03-02 17:02:12,880 - INFO - â”œâ”€â”€ Loss: 6.3059
2025-03-02 17:02:12,880 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:02:12,881 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:02:13,561 - INFO - ðŸªœ Batch step - 2681 -- sub batch step 10724 -- lr 3.00e-04
2025-03-02 17:02:15,718 - INFO - ðŸªœ Batch step - 2681 -- sub batch step 10725 -- lr 3.00e-04
2025-03-02 17:02:17,868 - INFO - ðŸªœ Batch step - 2681 -- sub batch step 10726 -- lr 3.00e-04
2025-03-02 17:02:20,679 - INFO - ðŸªœ Batch step - 2681 -- sub batch step 10727 -- lr 3.00e-04
2025-03-02 17:02:22,311 - INFO - Step 2681 -- ðŸ”„ Training Metrics
2025-03-02 17:02:22,311 - INFO - â”œâ”€â”€ Loss: 6.2955
2025-03-02 17:02:22,311 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:02:22,311 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:02:22,980 - INFO - ðŸªœ Batch step - 2682 -- sub batch step 10728 -- lr 3.00e-04
2025-03-02 17:02:25,132 - INFO - ðŸªœ Batch step - 2682 -- sub batch step 10729 -- lr 3.00e-04
2025-03-02 17:02:27,294 - INFO - ðŸªœ Batch step - 2682 -- sub batch step 10730 -- lr 3.00e-04
2025-03-02 17:02:29,464 - INFO - ðŸªœ Batch step - 2682 -- sub batch step 10731 -- lr 3.00e-04
2025-03-02 17:02:31,022 - INFO - Step 2682 -- ðŸ”„ Training Metrics
2025-03-02 17:02:31,022 - INFO - â”œâ”€â”€ Loss: 6.3157
2025-03-02 17:02:31,022 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:02:31,022 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:02:31,693 - INFO - ðŸªœ Batch step - 2683 -- sub batch step 10732 -- lr 3.00e-04
2025-03-02 17:02:33,845 - INFO - ðŸªœ Batch step - 2683 -- sub batch step 10733 -- lr 3.00e-04
2025-03-02 17:02:36,000 - INFO - ðŸªœ Batch step - 2683 -- sub batch step 10734 -- lr 3.00e-04
2025-03-02 17:02:38,413 - INFO - ðŸªœ Batch step - 2683 -- sub batch step 10735 -- lr 3.00e-04
2025-03-02 17:02:40,288 - INFO - Step 2683 -- ðŸ”„ Training Metrics
2025-03-02 17:02:40,288 - INFO - â”œâ”€â”€ Loss: 6.3173
2025-03-02 17:02:40,288 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:02:40,289 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:02:40,963 - INFO - ðŸªœ Batch step - 2684 -- sub batch step 10736 -- lr 3.00e-04
2025-03-02 17:02:43,124 - INFO - ðŸªœ Batch step - 2684 -- sub batch step 10737 -- lr 3.00e-04
2025-03-02 17:02:45,278 - INFO - ðŸªœ Batch step - 2684 -- sub batch step 10738 -- lr 3.00e-04
2025-03-02 17:02:47,455 - INFO - ðŸªœ Batch step - 2684 -- sub batch step 10739 -- lr 3.00e-04
2025-03-02 17:02:48,998 - INFO - Step 2684 -- ðŸ”„ Training Metrics
2025-03-02 17:02:48,998 - INFO - â”œâ”€â”€ Loss: 6.2988
2025-03-02 17:02:48,998 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:02:48,998 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:02:49,671 - INFO - ðŸªœ Batch step - 2685 -- sub batch step 10740 -- lr 3.00e-04
2025-03-02 17:02:51,830 - INFO - ðŸªœ Batch step - 2685 -- sub batch step 10741 -- lr 3.00e-04
2025-03-02 17:02:53,986 - INFO - ðŸªœ Batch step - 2685 -- sub batch step 10742 -- lr 3.00e-04
2025-03-02 17:02:56,336 - INFO - ðŸªœ Batch step - 2685 -- sub batch step 10743 -- lr 3.00e-04
2025-03-02 17:02:58,256 - INFO - Step 2685 -- ðŸ”„ Training Metrics
2025-03-02 17:02:58,256 - INFO - â”œâ”€â”€ Loss: 6.3139
2025-03-02 17:02:58,256 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:02:58,256 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:02:58,926 - INFO - ðŸªœ Batch step - 2686 -- sub batch step 10744 -- lr 3.00e-04
2025-03-02 17:03:01,084 - INFO - ðŸªœ Batch step - 2686 -- sub batch step 10745 -- lr 3.00e-04
2025-03-02 17:03:03,235 - INFO - ðŸªœ Batch step - 2686 -- sub batch step 10746 -- lr 3.00e-04
2025-03-02 17:03:05,408 - INFO - ðŸªœ Batch step - 2686 -- sub batch step 10747 -- lr 3.00e-04
2025-03-02 17:03:06,957 - INFO - Step 2686 -- ðŸ”„ Training Metrics
2025-03-02 17:03:06,957 - INFO - â”œâ”€â”€ Loss: 6.3029
2025-03-02 17:03:06,957 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:03:06,957 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:03:07,711 - INFO - ðŸªœ Batch step - 2687 -- sub batch step 10748 -- lr 3.00e-04
2025-03-02 17:03:09,871 - INFO - ðŸªœ Batch step - 2687 -- sub batch step 10749 -- lr 3.00e-04
2025-03-02 17:03:12,122 - INFO - ðŸªœ Batch step - 2687 -- sub batch step 10750 -- lr 3.00e-04
2025-03-02 17:03:14,752 - INFO - ðŸªœ Batch step - 2687 -- sub batch step 10751 -- lr 3.00e-04
2025-03-02 17:03:16,277 - INFO - Step 2687 -- ðŸ”„ Training Metrics
2025-03-02 17:03:16,277 - INFO - â”œâ”€â”€ Loss: 6.3115
2025-03-02 17:03:16,277 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:03:16,277 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:03:16,949 - INFO - ðŸªœ Batch step - 2688 -- sub batch step 10752 -- lr 3.00e-04
2025-03-02 17:03:19,109 - INFO - ðŸªœ Batch step - 2688 -- sub batch step 10753 -- lr 3.00e-04
2025-03-02 17:03:21,332 - INFO - ðŸªœ Batch step - 2688 -- sub batch step 10754 -- lr 3.00e-04
2025-03-02 17:03:23,520 - INFO - ðŸªœ Batch step - 2688 -- sub batch step 10755 -- lr 3.00e-04
2025-03-02 17:03:25,026 - INFO - Step 2688 -- ðŸ”„ Training Metrics
2025-03-02 17:03:25,026 - INFO - â”œâ”€â”€ Loss: 6.3295
2025-03-02 17:03:25,026 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:03:25,026 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:03:25,701 - INFO - ðŸªœ Batch step - 2689 -- sub batch step 10756 -- lr 3.00e-04
2025-03-02 17:03:27,856 - INFO - ðŸªœ Batch step - 2689 -- sub batch step 10757 -- lr 3.00e-04
2025-03-02 17:03:30,010 - INFO - ðŸªœ Batch step - 2689 -- sub batch step 10758 -- lr 3.00e-04
2025-03-02 17:03:32,828 - INFO - ðŸªœ Batch step - 2689 -- sub batch step 10759 -- lr 3.00e-04
2025-03-02 17:03:34,320 - INFO - Step 2689 -- ðŸ”„ Training Metrics
2025-03-02 17:03:34,321 - INFO - â”œâ”€â”€ Loss: 6.2882
2025-03-02 17:03:34,321 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:03:34,321 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:03:34,996 - INFO - ðŸªœ Batch step - 2690 -- sub batch step 10760 -- lr 3.00e-04
2025-03-02 17:03:37,151 - INFO - ðŸªœ Batch step - 2690 -- sub batch step 10761 -- lr 3.00e-04
2025-03-02 17:03:39,308 - INFO - ðŸªœ Batch step - 2690 -- sub batch step 10762 -- lr 3.00e-04
2025-03-02 17:03:41,480 - INFO - ðŸªœ Batch step - 2690 -- sub batch step 10763 -- lr 3.00e-04
2025-03-02 17:03:43,016 - INFO - Step 2690 -- ðŸ”„ Training Metrics
2025-03-02 17:03:43,017 - INFO - â”œâ”€â”€ Loss: 6.3094
2025-03-02 17:03:43,017 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:03:43,017 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:03:43,697 - INFO - ðŸªœ Batch step - 2691 -- sub batch step 10764 -- lr 3.00e-04
2025-03-02 17:03:45,855 - INFO - ðŸªœ Batch step - 2691 -- sub batch step 10765 -- lr 3.00e-04
2025-03-02 17:03:48,446 - INFO - ðŸªœ Batch step - 2691 -- sub batch step 10766 -- lr 3.00e-04
2025-03-02 17:03:50,607 - INFO - ðŸªœ Batch step - 2691 -- sub batch step 10767 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 67966c8b-04f0-4993-a711-840608e92f02)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00134-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:04:03,031 - INFO - Step 2691 -- ðŸ”„ Training Metrics
2025-03-02 17:04:03,032 - INFO - â”œâ”€â”€ Loss: 6.3086
2025-03-02 17:04:03,032 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:04:03,032 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:04:03,699 - INFO - ðŸªœ Batch step - 2692 -- sub batch step 10768 -- lr 3.00e-04
2025-03-02 17:04:05,851 - INFO - ðŸªœ Batch step - 2692 -- sub batch step 10769 -- lr 3.00e-04
2025-03-02 17:04:08,023 - INFO - ðŸªœ Batch step - 2692 -- sub batch step 10770 -- lr 3.00e-04
2025-03-02 17:04:10,177 - INFO - ðŸªœ Batch step - 2692 -- sub batch step 10771 -- lr 3.00e-04
2025-03-02 17:04:11,727 - INFO - Step 2692 -- ðŸ”„ Training Metrics
2025-03-02 17:04:11,727 - INFO - â”œâ”€â”€ Loss: 6.2884
2025-03-02 17:04:11,728 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:04:11,728 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:04:12,406 - INFO - ðŸªœ Batch step - 2693 -- sub batch step 10772 -- lr 3.00e-04
2025-03-02 17:04:14,560 - INFO - ðŸªœ Batch step - 2693 -- sub batch step 10773 -- lr 3.00e-04
2025-03-02 17:04:17,071 - INFO - ðŸªœ Batch step - 2693 -- sub batch step 10774 -- lr 3.00e-04
2025-03-02 17:04:19,235 - INFO - ðŸªœ Batch step - 2693 -- sub batch step 10775 -- lr 3.00e-04
2025-03-02 17:04:20,839 - INFO - Step 2693 -- ðŸ”„ Training Metrics
2025-03-02 17:04:20,839 - INFO - â”œâ”€â”€ Loss: 6.2884
2025-03-02 17:04:20,839 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:04:20,839 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:04:21,512 - INFO - ðŸªœ Batch step - 2694 -- sub batch step 10776 -- lr 3.00e-04
2025-03-02 17:04:23,662 - INFO - ðŸªœ Batch step - 2694 -- sub batch step 10777 -- lr 3.00e-04
2025-03-02 17:04:25,833 - INFO - ðŸªœ Batch step - 2694 -- sub batch step 10778 -- lr 3.00e-04
2025-03-02 17:04:27,992 - INFO - ðŸªœ Batch step - 2694 -- sub batch step 10779 -- lr 3.00e-04
2025-03-02 17:04:29,535 - INFO - Step 2694 -- ðŸ”„ Training Metrics
2025-03-02 17:04:29,536 - INFO - â”œâ”€â”€ Loss: 6.2714
2025-03-02 17:04:29,536 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:04:29,536 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:04:30,218 - INFO - ðŸªœ Batch step - 2695 -- sub batch step 10780 -- lr 3.00e-04
2025-03-02 17:04:32,370 - INFO - ðŸªœ Batch step - 2695 -- sub batch step 10781 -- lr 3.00e-04
2025-03-02 17:04:34,821 - INFO - ðŸªœ Batch step - 2695 -- sub batch step 10782 -- lr 3.00e-04
2025-03-02 17:04:36,980 - INFO - ðŸªœ Batch step - 2695 -- sub batch step 10783 -- lr 3.00e-04
2025-03-02 17:04:42,037 - INFO - Step 2695 -- ðŸ”„ Training Metrics
2025-03-02 17:04:42,038 - INFO - â”œâ”€â”€ Loss: 6.2794
2025-03-02 17:04:42,038 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:04:42,038 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:04:42,719 - INFO - ðŸªœ Batch step - 2696 -- sub batch step 10784 -- lr 3.00e-04
2025-03-02 17:04:44,877 - INFO - ðŸªœ Batch step - 2696 -- sub batch step 10785 -- lr 3.00e-04
2025-03-02 17:04:47,050 - INFO - ðŸªœ Batch step - 2696 -- sub batch step 10786 -- lr 3.00e-04
2025-03-02 17:04:49,207 - INFO - ðŸªœ Batch step - 2696 -- sub batch step 10787 -- lr 3.00e-04
2025-03-02 17:04:50,741 - INFO - Step 2696 -- ðŸ”„ Training Metrics
2025-03-02 17:04:50,741 - INFO - â”œâ”€â”€ Loss: 6.2991
2025-03-02 17:04:50,741 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:04:50,741 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:04:51,412 - INFO - ðŸªœ Batch step - 2697 -- sub batch step 10788 -- lr 3.00e-04
2025-03-02 17:04:53,573 - INFO - ðŸªœ Batch step - 2697 -- sub batch step 10789 -- lr 3.00e-04
2025-03-02 17:04:56,241 - INFO - ðŸªœ Batch step - 2697 -- sub batch step 10790 -- lr 3.00e-04
2025-03-02 17:04:58,391 - INFO - ðŸªœ Batch step - 2697 -- sub batch step 10791 -- lr 3.00e-04
2025-03-02 17:05:00,548 - INFO - Step 2697 -- ðŸ”„ Training Metrics
2025-03-02 17:05:00,548 - INFO - â”œâ”€â”€ Loss: 6.3083
2025-03-02 17:05:00,548 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:05:00,548 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:05:01,220 - INFO - ðŸªœ Batch step - 2698 -- sub batch step 10792 -- lr 3.00e-04
2025-03-02 17:05:03,367 - INFO - ðŸªœ Batch step - 2698 -- sub batch step 10793 -- lr 3.00e-04
2025-03-02 17:05:05,537 - INFO - ðŸªœ Batch step - 2698 -- sub batch step 10794 -- lr 3.00e-04
2025-03-02 17:05:07,688 - INFO - ðŸªœ Batch step - 2698 -- sub batch step 10795 -- lr 3.00e-04
2025-03-02 17:05:09,249 - INFO - Step 2698 -- ðŸ”„ Training Metrics
2025-03-02 17:05:09,249 - INFO - â”œâ”€â”€ Loss: 6.2554
2025-03-02 17:05:09,249 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:05:09,250 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:05:09,917 - INFO - ðŸªœ Batch step - 2699 -- sub batch step 10796 -- lr 3.00e-04
2025-03-02 17:05:12,068 - INFO - ðŸªœ Batch step - 2699 -- sub batch step 10797 -- lr 3.00e-04
2025-03-02 17:05:14,347 - INFO - ðŸªœ Batch step - 2699 -- sub batch step 10798 -- lr 3.00e-04
2025-03-02 17:05:16,497 - INFO - ðŸªœ Batch step - 2699 -- sub batch step 10799 -- lr 3.00e-04
2025-03-02 17:05:24,673 - INFO - Step 2699 -- ðŸ”„ Training Metrics
2025-03-02 17:05:24,674 - INFO - â”œâ”€â”€ Loss: 6.3087
2025-03-02 17:05:24,674 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:05:24,674 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:05:26,014 - INFO - ðŸªœ Batch step - 2700 -- sub batch step 10800 -- lr 3.00e-04
2025-03-02 17:05:28,173 - INFO - ðŸªœ Batch step - 2700 -- sub batch step 10801 -- lr 3.00e-04
2025-03-02 17:05:30,339 - INFO - ðŸªœ Batch step - 2700 -- sub batch step 10802 -- lr 3.00e-04
2025-03-02 17:05:32,526 - INFO - ðŸªœ Batch step - 2700 -- sub batch step 10803 -- lr 3.00e-04
2025-03-02 17:05:38,697 - INFO - Step 2700 -- ðŸ”„ Training Metrics
2025-03-02 17:05:38,698 - INFO - â”œâ”€â”€ Loss: 6.2827
2025-03-02 17:05:38,698 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:05:38,698 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:05:39,376 - INFO - ðŸªœ Batch step - 2701 -- sub batch step 10804 -- lr 3.00e-04
2025-03-02 17:05:41,532 - INFO - ðŸªœ Batch step - 2701 -- sub batch step 10805 -- lr 3.00e-04
2025-03-02 17:05:43,688 - INFO - ðŸªœ Batch step - 2701 -- sub batch step 10806 -- lr 3.00e-04
2025-03-02 17:05:46,191 - INFO - ðŸªœ Batch step - 2701 -- sub batch step 10807 -- lr 3.00e-04
2025-03-02 17:05:47,925 - INFO - Step 2701 -- ðŸ”„ Training Metrics
2025-03-02 17:05:47,925 - INFO - â”œâ”€â”€ Loss: 6.3075
2025-03-02 17:05:47,925 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:05:47,925 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:05:48,598 - INFO - ðŸªœ Batch step - 2702 -- sub batch step 10808 -- lr 3.00e-04
2025-03-02 17:05:50,758 - INFO - ðŸªœ Batch step - 2702 -- sub batch step 10809 -- lr 3.00e-04
2025-03-02 17:05:52,914 - INFO - ðŸªœ Batch step - 2702 -- sub batch step 10810 -- lr 3.00e-04
2025-03-02 17:05:55,085 - INFO - ðŸªœ Batch step - 2702 -- sub batch step 10811 -- lr 3.00e-04
2025-03-02 17:05:56,614 - INFO - Step 2702 -- ðŸ”„ Training Metrics
2025-03-02 17:05:56,614 - INFO - â”œâ”€â”€ Loss: 6.2816
2025-03-02 17:05:56,614 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:05:56,615 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:05:57,292 - INFO - ðŸªœ Batch step - 2703 -- sub batch step 10812 -- lr 3.00e-04
2025-03-02 17:05:59,439 - INFO - ðŸªœ Batch step - 2703 -- sub batch step 10813 -- lr 3.00e-04
2025-03-02 17:06:01,596 - INFO - ðŸªœ Batch step - 2703 -- sub batch step 10814 -- lr 3.00e-04
2025-03-02 17:06:03,971 - INFO - ðŸªœ Batch step - 2703 -- sub batch step 10815 -- lr 3.00e-04
2025-03-02 17:06:05,990 - INFO - Step 2703 -- ðŸ”„ Training Metrics
2025-03-02 17:06:05,990 - INFO - â”œâ”€â”€ Loss: 6.3075
2025-03-02 17:06:05,991 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:06:05,991 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:06:06,659 - INFO - ðŸªœ Batch step - 2704 -- sub batch step 10816 -- lr 3.00e-04
2025-03-02 17:06:08,814 - INFO - ðŸªœ Batch step - 2704 -- sub batch step 10817 -- lr 3.00e-04
2025-03-02 17:06:10,965 - INFO - ðŸªœ Batch step - 2704 -- sub batch step 10818 -- lr 3.00e-04
2025-03-02 17:06:13,140 - INFO - ðŸªœ Batch step - 2704 -- sub batch step 10819 -- lr 3.00e-04
2025-03-02 17:06:14,684 - INFO - Step 2704 -- ðŸ”„ Training Metrics
2025-03-02 17:06:14,684 - INFO - â”œâ”€â”€ Loss: 6.2829
2025-03-02 17:06:14,685 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:06:14,685 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:06:15,357 - INFO - ðŸªœ Batch step - 2705 -- sub batch step 10820 -- lr 3.00e-04
2025-03-02 17:06:17,503 - INFO - ðŸªœ Batch step - 2705 -- sub batch step 10821 -- lr 3.00e-04
2025-03-02 17:06:19,656 - INFO - ðŸªœ Batch step - 2705 -- sub batch step 10822 -- lr 3.00e-04
2025-03-02 17:06:22,113 - INFO - ðŸªœ Batch step - 2705 -- sub batch step 10823 -- lr 3.00e-04
2025-03-02 17:06:26,255 - INFO - Step 2705 -- ðŸ”„ Training Metrics
2025-03-02 17:06:26,255 - INFO - â”œâ”€â”€ Loss: 6.2759
2025-03-02 17:06:26,255 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:06:26,256 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:06:26,928 - INFO - ðŸªœ Batch step - 2706 -- sub batch step 10824 -- lr 3.00e-04
2025-03-02 17:06:29,082 - INFO - ðŸªœ Batch step - 2706 -- sub batch step 10825 -- lr 3.00e-04
2025-03-02 17:06:31,229 - INFO - ðŸªœ Batch step - 2706 -- sub batch step 10826 -- lr 3.00e-04
2025-03-02 17:06:33,402 - INFO - ðŸªœ Batch step - 2706 -- sub batch step 10827 -- lr 3.00e-04
2025-03-02 17:06:34,958 - INFO - Step 2706 -- ðŸ”„ Training Metrics
2025-03-02 17:06:34,958 - INFO - â”œâ”€â”€ Loss: 6.2861
2025-03-02 17:06:34,958 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:06:34,958 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:06:35,623 - INFO - ðŸªœ Batch step - 2707 -- sub batch step 10828 -- lr 3.00e-04
2025-03-02 17:06:37,777 - INFO - ðŸªœ Batch step - 2707 -- sub batch step 10829 -- lr 3.00e-04
2025-03-02 17:06:39,930 - INFO - ðŸªœ Batch step - 2707 -- sub batch step 10830 -- lr 3.00e-04
2025-03-02 17:06:42,363 - INFO - ðŸªœ Batch step - 2707 -- sub batch step 10831 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: af986bd8-63d5-4654-9ec2-907c261fd92a)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00135-of-10000.parquet
Retrying in 1s [Retry 1/5].
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: af8a6167-4646-473c-9f8a-2c789c7f4741)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00135-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:06:54,975 - INFO - Step 2707 -- ðŸ”„ Training Metrics
2025-03-02 17:06:54,976 - INFO - â”œâ”€â”€ Loss: 6.3052
2025-03-02 17:06:54,976 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:06:54,976 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:06:55,647 - INFO - ðŸªœ Batch step - 2708 -- sub batch step 10832 -- lr 3.00e-04
2025-03-02 17:06:57,791 - INFO - ðŸªœ Batch step - 2708 -- sub batch step 10833 -- lr 3.00e-04
2025-03-02 17:06:59,947 - INFO - ðŸªœ Batch step - 2708 -- sub batch step 10834 -- lr 3.00e-04
2025-03-02 17:07:02,123 - INFO - ðŸªœ Batch step - 2708 -- sub batch step 10835 -- lr 3.00e-04
2025-03-02 17:07:03,676 - INFO - Step 2708 -- ðŸ”„ Training Metrics
2025-03-02 17:07:03,676 - INFO - â”œâ”€â”€ Loss: 6.2898
2025-03-02 17:07:03,676 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:07:03,676 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:07:04,344 - INFO - ðŸªœ Batch step - 2709 -- sub batch step 10836 -- lr 3.00e-04
2025-03-02 17:07:06,496 - INFO - ðŸªœ Batch step - 2709 -- sub batch step 10837 -- lr 3.00e-04
2025-03-02 17:07:08,644 - INFO - ðŸªœ Batch step - 2709 -- sub batch step 10838 -- lr 3.00e-04
2025-03-02 17:07:11,024 - INFO - ðŸªœ Batch step - 2709 -- sub batch step 10839 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: c731b097-952b-482d-b7c4-0d0d5d052b43)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00135-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:07:23,520 - INFO - Step 2709 -- ðŸ”„ Training Metrics
2025-03-02 17:07:23,521 - INFO - â”œâ”€â”€ Loss: 6.2708
2025-03-02 17:07:23,521 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:07:23,521 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:07:24,193 - INFO - ðŸªœ Batch step - 2710 -- sub batch step 10840 -- lr 3.00e-04
2025-03-02 17:07:26,342 - INFO - ðŸªœ Batch step - 2710 -- sub batch step 10841 -- lr 3.00e-04
2025-03-02 17:07:28,492 - INFO - ðŸªœ Batch step - 2710 -- sub batch step 10842 -- lr 3.00e-04
2025-03-02 17:07:30,658 - INFO - ðŸªœ Batch step - 2710 -- sub batch step 10843 -- lr 3.00e-04
2025-03-02 17:07:32,215 - INFO - Step 2710 -- ðŸ”„ Training Metrics
2025-03-02 17:07:32,215 - INFO - â”œâ”€â”€ Loss: 6.3015
2025-03-02 17:07:32,215 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:07:32,215 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:07:32,887 - INFO - ðŸªœ Batch step - 2711 -- sub batch step 10844 -- lr 3.00e-04
2025-03-02 17:07:35,039 - INFO - ðŸªœ Batch step - 2711 -- sub batch step 10845 -- lr 3.00e-04
2025-03-02 17:07:37,831 - INFO - ðŸªœ Batch step - 2711 -- sub batch step 10846 -- lr 3.00e-04
2025-03-02 17:07:39,994 - INFO - ðŸªœ Batch step - 2711 -- sub batch step 10847 -- lr 3.00e-04
2025-03-02 17:07:41,486 - INFO - Step 2711 -- ðŸ”„ Training Metrics
2025-03-02 17:07:41,487 - INFO - â”œâ”€â”€ Loss: 6.2795
2025-03-02 17:07:41,487 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:07:41,487 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:07:42,153 - INFO - ðŸªœ Batch step - 2712 -- sub batch step 10848 -- lr 3.00e-04
2025-03-02 17:07:44,308 - INFO - ðŸªœ Batch step - 2712 -- sub batch step 10849 -- lr 3.00e-04
2025-03-02 17:07:46,479 - INFO - ðŸªœ Batch step - 2712 -- sub batch step 10850 -- lr 3.00e-04
2025-03-02 17:07:48,626 - INFO - ðŸªœ Batch step - 2712 -- sub batch step 10851 -- lr 3.00e-04
2025-03-02 17:07:50,185 - INFO - Step 2712 -- ðŸ”„ Training Metrics
2025-03-02 17:07:50,186 - INFO - â”œâ”€â”€ Loss: 6.2695
2025-03-02 17:07:50,186 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:07:50,186 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:07:50,858 - INFO - ðŸªœ Batch step - 2713 -- sub batch step 10852 -- lr 3.00e-04
2025-03-02 17:07:53,004 - INFO - ðŸªœ Batch step - 2713 -- sub batch step 10853 -- lr 3.00e-04
2025-03-02 17:07:56,154 - INFO - ðŸªœ Batch step - 2713 -- sub batch step 10854 -- lr 3.00e-04
2025-03-02 17:07:58,313 - INFO - ðŸªœ Batch step - 2713 -- sub batch step 10855 -- lr 3.00e-04
2025-03-02 17:07:59,806 - INFO - Step 2713 -- ðŸ”„ Training Metrics
2025-03-02 17:07:59,806 - INFO - â”œâ”€â”€ Loss: 6.3052
2025-03-02 17:07:59,806 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:07:59,806 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:08:00,473 - INFO - ðŸªœ Batch step - 2714 -- sub batch step 10856 -- lr 3.00e-04
2025-03-02 17:08:02,624 - INFO - ðŸªœ Batch step - 2714 -- sub batch step 10857 -- lr 3.00e-04
2025-03-02 17:08:04,791 - INFO - ðŸªœ Batch step - 2714 -- sub batch step 10858 -- lr 3.00e-04
2025-03-02 17:08:06,944 - INFO - ðŸªœ Batch step - 2714 -- sub batch step 10859 -- lr 3.00e-04
2025-03-02 17:08:08,499 - INFO - Step 2714 -- ðŸ”„ Training Metrics
2025-03-02 17:08:08,500 - INFO - â”œâ”€â”€ Loss: 6.2820
2025-03-02 17:08:08,500 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:08:08,500 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:08:09,172 - INFO - ðŸªœ Batch step - 2715 -- sub batch step 10860 -- lr 3.00e-04
2025-03-02 17:08:11,320 - INFO - ðŸªœ Batch step - 2715 -- sub batch step 10861 -- lr 3.00e-04
2025-03-02 17:08:14,109 - INFO - ðŸªœ Batch step - 2715 -- sub batch step 10862 -- lr 3.00e-04
2025-03-02 17:08:16,262 - INFO - ðŸªœ Batch step - 2715 -- sub batch step 10863 -- lr 3.00e-04
2025-03-02 17:08:17,753 - INFO - Step 2715 -- ðŸ”„ Training Metrics
2025-03-02 17:08:17,753 - INFO - â”œâ”€â”€ Loss: 6.2774
2025-03-02 17:08:17,754 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:08:17,754 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:08:18,428 - INFO - ðŸªœ Batch step - 2716 -- sub batch step 10864 -- lr 3.00e-04
2025-03-02 17:08:20,577 - INFO - ðŸªœ Batch step - 2716 -- sub batch step 10865 -- lr 3.00e-04
2025-03-02 17:08:22,742 - INFO - ðŸªœ Batch step - 2716 -- sub batch step 10866 -- lr 3.00e-04
2025-03-02 17:08:24,894 - INFO - ðŸªœ Batch step - 2716 -- sub batch step 10867 -- lr 3.00e-04
2025-03-02 17:08:26,465 - INFO - Step 2716 -- ðŸ”„ Training Metrics
2025-03-02 17:08:26,466 - INFO - â”œâ”€â”€ Loss: 6.2793
2025-03-02 17:08:26,466 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:08:26,466 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:08:27,132 - INFO - ðŸªœ Batch step - 2717 -- sub batch step 10868 -- lr 3.00e-04
2025-03-02 17:08:29,283 - INFO - ðŸªœ Batch step - 2717 -- sub batch step 10869 -- lr 3.00e-04
2025-03-02 17:08:31,878 - INFO - ðŸªœ Batch step - 2717 -- sub batch step 10870 -- lr 3.00e-04
2025-03-02 17:08:34,030 - INFO - ðŸªœ Batch step - 2717 -- sub batch step 10871 -- lr 3.00e-04
2025-03-02 17:08:35,828 - INFO - Step 2717 -- ðŸ”„ Training Metrics
2025-03-02 17:08:35,828 - INFO - â”œâ”€â”€ Loss: 6.2778
2025-03-02 17:08:35,828 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:08:35,829 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:08:36,502 - INFO - ðŸªœ Batch step - 2718 -- sub batch step 10872 -- lr 3.00e-04
2025-03-02 17:08:38,651 - INFO - ðŸªœ Batch step - 2718 -- sub batch step 10873 -- lr 3.00e-04
2025-03-02 17:08:40,826 - INFO - ðŸªœ Batch step - 2718 -- sub batch step 10874 -- lr 3.00e-04
2025-03-02 17:08:42,975 - INFO - ðŸªœ Batch step - 2718 -- sub batch step 10875 -- lr 3.00e-04
2025-03-02 17:08:44,537 - INFO - Step 2718 -- ðŸ”„ Training Metrics
2025-03-02 17:08:44,538 - INFO - â”œâ”€â”€ Loss: 6.2923
2025-03-02 17:08:44,538 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:08:44,538 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:08:45,206 - INFO - ðŸªœ Batch step - 2719 -- sub batch step 10876 -- lr 3.00e-04
2025-03-02 17:08:47,359 - INFO - ðŸªœ Batch step - 2719 -- sub batch step 10877 -- lr 3.00e-04
2025-03-02 17:08:49,630 - INFO - ðŸªœ Batch step - 2719 -- sub batch step 10878 -- lr 3.00e-04
2025-03-02 17:08:51,785 - INFO - ðŸªœ Batch step - 2719 -- sub batch step 10879 -- lr 3.00e-04
2025-03-02 17:08:53,426 - INFO - Step 2719 -- ðŸ”„ Training Metrics
2025-03-02 17:08:53,426 - INFO - â”œâ”€â”€ Loss: 6.3028
2025-03-02 17:08:53,427 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:08:53,427 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:08:54,711 - INFO - ðŸªœ Batch step - 2720 -- sub batch step 10880 -- lr 3.00e-04
2025-03-02 17:08:56,862 - INFO - ðŸªœ Batch step - 2720 -- sub batch step 10881 -- lr 3.00e-04
2025-03-02 17:08:59,018 - INFO - ðŸªœ Batch step - 2720 -- sub batch step 10882 -- lr 3.00e-04
2025-03-02 17:09:01,195 - INFO - ðŸªœ Batch step - 2720 -- sub batch step 10883 -- lr 3.00e-04
2025-03-02 17:09:04,540 - INFO - Step 2720 -- ðŸ”„ Training Metrics
2025-03-02 17:09:04,557 - INFO - â”œâ”€â”€ Loss: 6.2805
2025-03-02 17:09:04,557 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:09:04,557 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:09:05,230 - INFO - ðŸªœ Batch step - 2721 -- sub batch step 10884 -- lr 3.00e-04
2025-03-02 17:09:07,386 - INFO - ðŸªœ Batch step - 2721 -- sub batch step 10885 -- lr 3.00e-04
2025-03-02 17:09:09,536 - INFO - ðŸªœ Batch step - 2721 -- sub batch step 10886 -- lr 3.00e-04
2025-03-02 17:09:11,945 - INFO - ðŸªœ Batch step - 2721 -- sub batch step 10887 -- lr 3.00e-04
2025-03-02 17:09:14,282 - INFO - Step 2721 -- ðŸ”„ Training Metrics
2025-03-02 17:09:14,282 - INFO - â”œâ”€â”€ Loss: 6.2934
2025-03-02 17:09:14,282 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:09:14,283 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:09:14,947 - INFO - ðŸªœ Batch step - 2722 -- sub batch step 10888 -- lr 3.00e-04
2025-03-02 17:09:17,099 - INFO - ðŸªœ Batch step - 2722 -- sub batch step 10889 -- lr 3.00e-04
2025-03-02 17:09:19,251 - INFO - ðŸªœ Batch step - 2722 -- sub batch step 10890 -- lr 3.00e-04
2025-03-02 17:09:21,417 - INFO - ðŸªœ Batch step - 2722 -- sub batch step 10891 -- lr 3.00e-04
2025-03-02 17:09:22,996 - INFO - Step 2722 -- ðŸ”„ Training Metrics
2025-03-02 17:09:22,997 - INFO - â”œâ”€â”€ Loss: 6.2551
2025-03-02 17:09:22,997 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:09:22,997 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:09:23,668 - INFO - ðŸªœ Batch step - 2723 -- sub batch step 10892 -- lr 3.00e-04
2025-03-02 17:09:25,815 - INFO - ðŸªœ Batch step - 2723 -- sub batch step 10893 -- lr 3.00e-04
2025-03-02 17:09:27,967 - INFO - ðŸªœ Batch step - 2723 -- sub batch step 10894 -- lr 3.00e-04
2025-03-02 17:09:30,592 - INFO - ðŸªœ Batch step - 2723 -- sub batch step 10895 -- lr 3.00e-04
2025-03-02 17:09:32,132 - INFO - Step 2723 -- ðŸ”„ Training Metrics
2025-03-02 17:09:32,132 - INFO - â”œâ”€â”€ Loss: 6.2738
2025-03-02 17:09:32,133 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:09:32,133 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:09:32,799 - INFO - ðŸªœ Batch step - 2724 -- sub batch step 10896 -- lr 3.00e-04
2025-03-02 17:09:34,951 - INFO - ðŸªœ Batch step - 2724 -- sub batch step 10897 -- lr 3.00e-04
2025-03-02 17:09:37,095 - INFO - ðŸªœ Batch step - 2724 -- sub batch step 10898 -- lr 3.00e-04
2025-03-02 17:09:39,268 - INFO - ðŸªœ Batch step - 2724 -- sub batch step 10899 -- lr 3.00e-04
2025-03-02 17:09:40,829 - INFO - Step 2724 -- ðŸ”„ Training Metrics
2025-03-02 17:09:40,829 - INFO - â”œâ”€â”€ Loss: 6.2856
2025-03-02 17:09:40,829 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:09:40,829 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:09:41,502 - INFO - ðŸªœ Batch step - 2725 -- sub batch step 10900 -- lr 3.00e-04
2025-03-02 17:09:43,650 - INFO - ðŸªœ Batch step - 2725 -- sub batch step 10901 -- lr 3.00e-04
2025-03-02 17:09:45,801 - INFO - ðŸªœ Batch step - 2725 -- sub batch step 10902 -- lr 3.00e-04
2025-03-02 17:09:48,292 - INFO - ðŸªœ Batch step - 2725 -- sub batch step 10903 -- lr 3.00e-04
2025-03-02 17:09:55,981 - INFO - Step 2725 -- ðŸ”„ Training Metrics
2025-03-02 17:09:55,982 - INFO - â”œâ”€â”€ Loss: 6.2757
2025-03-02 17:09:55,982 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:09:55,982 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:09:56,652 - INFO - ðŸªœ Batch step - 2726 -- sub batch step 10904 -- lr 3.00e-04
2025-03-02 17:09:58,802 - INFO - ðŸªœ Batch step - 2726 -- sub batch step 10905 -- lr 3.00e-04
2025-03-02 17:10:00,946 - INFO - ðŸªœ Batch step - 2726 -- sub batch step 10906 -- lr 3.00e-04
2025-03-02 17:10:03,121 - INFO - ðŸªœ Batch step - 2726 -- sub batch step 10907 -- lr 3.00e-04
2025-03-02 17:10:04,675 - INFO - Step 2726 -- ðŸ”„ Training Metrics
2025-03-02 17:10:04,675 - INFO - â”œâ”€â”€ Loss: 6.2783
2025-03-02 17:10:04,675 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:10:04,676 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:10:05,344 - INFO - ðŸªœ Batch step - 2727 -- sub batch step 10908 -- lr 3.00e-04
2025-03-02 17:10:07,496 - INFO - ðŸªœ Batch step - 2727 -- sub batch step 10909 -- lr 3.00e-04
2025-03-02 17:10:09,647 - INFO - ðŸªœ Batch step - 2727 -- sub batch step 10910 -- lr 3.00e-04
2025-03-02 17:10:12,495 - INFO - ðŸªœ Batch step - 2727 -- sub batch step 10911 -- lr 3.00e-04
2025-03-02 17:10:14,210 - INFO - Step 2727 -- ðŸ”„ Training Metrics
2025-03-02 17:10:14,210 - INFO - â”œâ”€â”€ Loss: 6.2933
2025-03-02 17:10:14,210 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:10:14,211 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:10:14,881 - INFO - ðŸªœ Batch step - 2728 -- sub batch step 10912 -- lr 3.00e-04
2025-03-02 17:10:17,028 - INFO - ðŸªœ Batch step - 2728 -- sub batch step 10913 -- lr 3.00e-04
2025-03-02 17:10:19,184 - INFO - ðŸªœ Batch step - 2728 -- sub batch step 10914 -- lr 3.00e-04
2025-03-02 17:10:21,354 - INFO - ðŸªœ Batch step - 2728 -- sub batch step 10915 -- lr 3.00e-04
2025-03-02 17:10:22,913 - INFO - Step 2728 -- ðŸ”„ Training Metrics
2025-03-02 17:10:22,914 - INFO - â”œâ”€â”€ Loss: 6.2797
2025-03-02 17:10:22,914 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:10:22,914 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:10:23,580 - INFO - ðŸªœ Batch step - 2729 -- sub batch step 10916 -- lr 3.00e-04
2025-03-02 17:10:25,730 - INFO - ðŸªœ Batch step - 2729 -- sub batch step 10917 -- lr 3.00e-04
2025-03-02 17:10:27,874 - INFO - ðŸªœ Batch step - 2729 -- sub batch step 10918 -- lr 3.00e-04
2025-03-02 17:10:30,344 - INFO - ðŸªœ Batch step - 2729 -- sub batch step 10919 -- lr 3.00e-04
2025-03-02 17:10:32,127 - INFO - Step 2729 -- ðŸ”„ Training Metrics
2025-03-02 17:10:32,127 - INFO - â”œâ”€â”€ Loss: 6.2813
2025-03-02 17:10:32,127 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:10:32,127 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:10:32,798 - INFO - ðŸªœ Batch step - 2730 -- sub batch step 10920 -- lr 3.00e-04
2025-03-02 17:10:34,946 - INFO - ðŸªœ Batch step - 2730 -- sub batch step 10921 -- lr 3.00e-04
2025-03-02 17:10:37,099 - INFO - ðŸªœ Batch step - 2730 -- sub batch step 10922 -- lr 3.00e-04
2025-03-02 17:10:39,265 - INFO - ðŸªœ Batch step - 2730 -- sub batch step 10923 -- lr 3.00e-04
2025-03-02 17:10:40,821 - INFO - Step 2730 -- ðŸ”„ Training Metrics
2025-03-02 17:10:40,821 - INFO - â”œâ”€â”€ Loss: 6.2911
2025-03-02 17:10:40,821 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:10:40,821 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:10:41,491 - INFO - ðŸªœ Batch step - 2731 -- sub batch step 10924 -- lr 3.00e-04
2025-03-02 17:10:43,645 - INFO - ðŸªœ Batch step - 2731 -- sub batch step 10925 -- lr 3.00e-04
2025-03-02 17:10:46,059 - INFO - ðŸªœ Batch step - 2731 -- sub batch step 10926 -- lr 3.00e-04
2025-03-02 17:10:48,213 - INFO - ðŸªœ Batch step - 2731 -- sub batch step 10927 -- lr 3.00e-04
2025-03-02 17:10:50,113 - INFO - Step 2731 -- ðŸ”„ Training Metrics
2025-03-02 17:10:50,113 - INFO - â”œâ”€â”€ Loss: 6.2431
2025-03-02 17:10:50,114 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:10:50,114 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:10:50,778 - INFO - ðŸªœ Batch step - 2732 -- sub batch step 10928 -- lr 3.00e-04
2025-03-02 17:10:52,935 - INFO - ðŸªœ Batch step - 2732 -- sub batch step 10929 -- lr 3.00e-04
2025-03-02 17:10:55,105 - INFO - ðŸªœ Batch step - 2732 -- sub batch step 10930 -- lr 3.00e-04
2025-03-02 17:10:57,249 - INFO - ðŸªœ Batch step - 2732 -- sub batch step 10931 -- lr 3.00e-04
2025-03-02 17:10:58,805 - INFO - Step 2732 -- ðŸ”„ Training Metrics
2025-03-02 17:10:58,805 - INFO - â”œâ”€â”€ Loss: 6.2484
2025-03-02 17:10:58,805 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:10:58,805 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:10:59,473 - INFO - ðŸªœ Batch step - 2733 -- sub batch step 10932 -- lr 3.00e-04
2025-03-02 17:11:01,617 - INFO - ðŸªœ Batch step - 2733 -- sub batch step 10933 -- lr 3.00e-04
2025-03-02 17:11:04,032 - INFO - ðŸªœ Batch step - 2733 -- sub batch step 10934 -- lr 3.00e-04
2025-03-02 17:11:06,185 - INFO - ðŸªœ Batch step - 2733 -- sub batch step 10935 -- lr 3.00e-04
2025-03-02 17:11:14,855 - INFO - Step 2733 -- ðŸ”„ Training Metrics
2025-03-02 17:11:14,855 - INFO - â”œâ”€â”€ Loss: 6.3007
2025-03-02 17:11:14,855 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:11:14,855 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:11:15,518 - INFO - ðŸªœ Batch step - 2734 -- sub batch step 10936 -- lr 3.00e-04
2025-03-02 17:11:17,671 - INFO - ðŸªœ Batch step - 2734 -- sub batch step 10937 -- lr 3.00e-04
2025-03-02 17:11:19,834 - INFO - ðŸªœ Batch step - 2734 -- sub batch step 10938 -- lr 3.00e-04
2025-03-02 17:11:21,989 - INFO - ðŸªœ Batch step - 2734 -- sub batch step 10939 -- lr 3.00e-04
2025-03-02 17:11:23,547 - INFO - Step 2734 -- ðŸ”„ Training Metrics
2025-03-02 17:11:23,547 - INFO - â”œâ”€â”€ Loss: 6.3110
2025-03-02 17:11:23,547 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:11:23,548 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:11:24,221 - INFO - ðŸªœ Batch step - 2735 -- sub batch step 10940 -- lr 3.00e-04
2025-03-02 17:11:26,367 - INFO - ðŸªœ Batch step - 2735 -- sub batch step 10941 -- lr 3.00e-04
2025-03-02 17:11:28,784 - INFO - ðŸªœ Batch step - 2735 -- sub batch step 10942 -- lr 3.00e-04
2025-03-02 17:11:30,931 - INFO - ðŸªœ Batch step - 2735 -- sub batch step 10943 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: d84e981f-9b4f-49a0-93cd-26dc300514aa)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00136-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:11:43,600 - INFO - Step 2735 -- ðŸ”„ Training Metrics
2025-03-02 17:11:43,600 - INFO - â”œâ”€â”€ Loss: 6.2780
2025-03-02 17:11:43,600 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:11:43,600 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:11:44,273 - INFO - ðŸªœ Batch step - 2736 -- sub batch step 10944 -- lr 3.00e-04
2025-03-02 17:11:46,424 - INFO - ðŸªœ Batch step - 2736 -- sub batch step 10945 -- lr 3.00e-04
2025-03-02 17:11:48,588 - INFO - ðŸªœ Batch step - 2736 -- sub batch step 10946 -- lr 3.00e-04
2025-03-02 17:11:50,737 - INFO - ðŸªœ Batch step - 2736 -- sub batch step 10947 -- lr 3.00e-04
2025-03-02 17:11:52,298 - INFO - Step 2736 -- ðŸ”„ Training Metrics
2025-03-02 17:11:52,298 - INFO - â”œâ”€â”€ Loss: 6.2650
2025-03-02 17:11:52,299 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:11:52,299 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:11:52,964 - INFO - ðŸªœ Batch step - 2737 -- sub batch step 10948 -- lr 3.00e-04
2025-03-02 17:11:55,115 - INFO - ðŸªœ Batch step - 2737 -- sub batch step 10949 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 5dbd6061-ad95-495c-9fc5-342de3510c77)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00136-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:12:08,494 - INFO - ðŸªœ Batch step - 2737 -- sub batch step 10950 -- lr 3.00e-04
2025-03-02 17:12:10,667 - INFO - ðŸªœ Batch step - 2737 -- sub batch step 10951 -- lr 3.00e-04
2025-03-02 17:12:12,161 - INFO - Step 2737 -- ðŸ”„ Training Metrics
2025-03-02 17:12:12,161 - INFO - â”œâ”€â”€ Loss: 6.2760
2025-03-02 17:12:12,161 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:12:12,161 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:12:12,851 - INFO - ðŸªœ Batch step - 2738 -- sub batch step 10952 -- lr 3.00e-04
2025-03-02 17:12:15,015 - INFO - ðŸªœ Batch step - 2738 -- sub batch step 10953 -- lr 3.00e-04
2025-03-02 17:12:17,198 - INFO - ðŸªœ Batch step - 2738 -- sub batch step 10954 -- lr 3.00e-04
2025-03-02 17:12:19,355 - INFO - ðŸªœ Batch step - 2738 -- sub batch step 10955 -- lr 3.00e-04
2025-03-02 17:12:20,866 - INFO - Step 2738 -- ðŸ”„ Training Metrics
2025-03-02 17:12:20,866 - INFO - â”œâ”€â”€ Loss: 6.2795
2025-03-02 17:12:20,866 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:12:20,866 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:12:21,539 - INFO - ðŸªœ Batch step - 2739 -- sub batch step 10956 -- lr 3.00e-04
2025-03-02 17:12:23,697 - INFO - ðŸªœ Batch step - 2739 -- sub batch step 10957 -- lr 3.00e-04
2025-03-02 17:12:25,986 - INFO - ðŸªœ Batch step - 2739 -- sub batch step 10958 -- lr 3.00e-04
2025-03-02 17:12:28,148 - INFO - ðŸªœ Batch step - 2739 -- sub batch step 10959 -- lr 3.00e-04
2025-03-02 17:12:35,701 - INFO - Step 2739 -- ðŸ”„ Training Metrics
2025-03-02 17:12:35,701 - INFO - â”œâ”€â”€ Loss: 6.2670
2025-03-02 17:12:35,701 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:12:35,701 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:12:39,584 - INFO - ðŸªœ Batch step - 2740 -- sub batch step 10960 -- lr 3.00e-04
2025-03-02 17:12:41,736 - INFO - ðŸªœ Batch step - 2740 -- sub batch step 10961 -- lr 3.00e-04
2025-03-02 17:12:43,900 - INFO - ðŸªœ Batch step - 2740 -- sub batch step 10962 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 29302e45-21d3-4f56-8f81-d7fd95e124eb)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00137-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:12:46,074 - INFO - ðŸªœ Batch step - 2740 -- sub batch step 10963 -- lr 3.00e-04
2025-03-02 17:12:55,902 - INFO - Step 2740 -- ðŸ”„ Training Metrics
2025-03-02 17:12:55,903 - INFO - â”œâ”€â”€ Loss: 6.2622
2025-03-02 17:12:55,903 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:12:55,903 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:12:56,576 - INFO - ðŸªœ Batch step - 2741 -- sub batch step 10964 -- lr 3.00e-04
2025-03-02 17:12:58,730 - INFO - ðŸªœ Batch step - 2741 -- sub batch step 10965 -- lr 3.00e-04
2025-03-02 17:13:00,880 - INFO - ðŸªœ Batch step - 2741 -- sub batch step 10966 -- lr 3.00e-04
2025-03-02 17:13:03,362 - INFO - ðŸªœ Batch step - 2741 -- sub batch step 10967 -- lr 3.00e-04
2025-03-02 17:13:05,155 - INFO - Step 2741 -- ðŸ”„ Training Metrics
2025-03-02 17:13:05,155 - INFO - â”œâ”€â”€ Loss: 6.2878
2025-03-02 17:13:05,155 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:13:05,155 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:13:05,819 - INFO - ðŸªœ Batch step - 2742 -- sub batch step 10968 -- lr 3.00e-04
2025-03-02 17:13:07,971 - INFO - ðŸªœ Batch step - 2742 -- sub batch step 10969 -- lr 3.00e-04
2025-03-02 17:13:10,123 - INFO - ðŸªœ Batch step - 2742 -- sub batch step 10970 -- lr 3.00e-04
2025-03-02 17:13:12,289 - INFO - ðŸªœ Batch step - 2742 -- sub batch step 10971 -- lr 3.00e-04
2025-03-02 17:13:13,858 - INFO - Step 2742 -- ðŸ”„ Training Metrics
2025-03-02 17:13:13,858 - INFO - â”œâ”€â”€ Loss: 6.2912
2025-03-02 17:13:13,858 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:13:13,858 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:13:14,527 - INFO - ðŸªœ Batch step - 2743 -- sub batch step 10972 -- lr 3.00e-04
2025-03-02 17:13:16,674 - INFO - ðŸªœ Batch step - 2743 -- sub batch step 10973 -- lr 3.00e-04
2025-03-02 17:13:18,825 - INFO - ðŸªœ Batch step - 2743 -- sub batch step 10974 -- lr 3.00e-04
2025-03-02 17:13:21,248 - INFO - ðŸªœ Batch step - 2743 -- sub batch step 10975 -- lr 3.00e-04
2025-03-02 17:13:23,191 - INFO - Step 2743 -- ðŸ”„ Training Metrics
2025-03-02 17:13:23,191 - INFO - â”œâ”€â”€ Loss: 6.2799
2025-03-02 17:13:23,191 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:13:23,191 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:13:23,858 - INFO - ðŸªœ Batch step - 2744 -- sub batch step 10976 -- lr 3.00e-04
2025-03-02 17:13:26,011 - INFO - ðŸªœ Batch step - 2744 -- sub batch step 10977 -- lr 3.00e-04
2025-03-02 17:13:28,157 - INFO - ðŸªœ Batch step - 2744 -- sub batch step 10978 -- lr 3.00e-04
2025-03-02 17:13:30,330 - INFO - ðŸªœ Batch step - 2744 -- sub batch step 10979 -- lr 3.00e-04
2025-03-02 17:13:31,910 - INFO - Step 2744 -- ðŸ”„ Training Metrics
2025-03-02 17:13:31,911 - INFO - â”œâ”€â”€ Loss: 6.2781
2025-03-02 17:13:31,911 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:13:31,911 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:13:32,584 - INFO - ðŸªœ Batch step - 2745 -- sub batch step 10980 -- lr 3.00e-04
2025-03-02 17:13:34,733 - INFO - ðŸªœ Batch step - 2745 -- sub batch step 10981 -- lr 3.00e-04
2025-03-02 17:13:36,887 - INFO - ðŸªœ Batch step - 2745 -- sub batch step 10982 -- lr 3.00e-04
2025-03-02 17:13:40,140 - INFO - ðŸªœ Batch step - 2745 -- sub batch step 10983 -- lr 3.00e-04
2025-03-02 17:13:41,630 - INFO - Step 2745 -- ðŸ”„ Training Metrics
2025-03-02 17:13:41,630 - INFO - â”œâ”€â”€ Loss: 6.2908
2025-03-02 17:13:41,631 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:13:41,631 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:13:42,303 - INFO - ðŸªœ Batch step - 2746 -- sub batch step 10984 -- lr 3.00e-04
2025-03-02 17:13:44,456 - INFO - ðŸªœ Batch step - 2746 -- sub batch step 10985 -- lr 3.00e-04
2025-03-02 17:13:46,603 - INFO - ðŸªœ Batch step - 2746 -- sub batch step 10986 -- lr 3.00e-04
2025-03-02 17:13:48,777 - INFO - ðŸªœ Batch step - 2746 -- sub batch step 10987 -- lr 3.00e-04
2025-03-02 17:13:50,338 - INFO - Step 2746 -- ðŸ”„ Training Metrics
2025-03-02 17:13:50,338 - INFO - â”œâ”€â”€ Loss: 6.2335
2025-03-02 17:13:50,338 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:13:50,338 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:13:51,004 - INFO - ðŸªœ Batch step - 2747 -- sub batch step 10988 -- lr 3.00e-04
2025-03-02 17:13:53,156 - INFO - ðŸªœ Batch step - 2747 -- sub batch step 10989 -- lr 3.00e-04
2025-03-02 17:13:55,306 - INFO - ðŸªœ Batch step - 2747 -- sub batch step 10990 -- lr 3.00e-04
2025-03-02 17:13:58,150 - INFO - ðŸªœ Batch step - 2747 -- sub batch step 10991 -- lr 3.00e-04
2025-03-02 17:13:59,638 - INFO - Step 2747 -- ðŸ”„ Training Metrics
2025-03-02 17:13:59,639 - INFO - â”œâ”€â”€ Loss: 6.2715
2025-03-02 17:13:59,639 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:13:59,639 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:14:00,311 - INFO - ðŸªœ Batch step - 2748 -- sub batch step 10992 -- lr 3.00e-04
2025-03-02 17:14:02,458 - INFO - ðŸªœ Batch step - 2748 -- sub batch step 10993 -- lr 3.00e-04
2025-03-02 17:14:04,613 - INFO - ðŸªœ Batch step - 2748 -- sub batch step 10994 -- lr 3.00e-04
2025-03-02 17:14:06,784 - INFO - ðŸªœ Batch step - 2748 -- sub batch step 10995 -- lr 3.00e-04
2025-03-02 17:14:08,359 - INFO - Step 2748 -- ðŸ”„ Training Metrics
2025-03-02 17:14:08,359 - INFO - â”œâ”€â”€ Loss: 6.2763
2025-03-02 17:14:08,359 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:14:08,359 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:14:09,027 - INFO - ðŸªœ Batch step - 2749 -- sub batch step 10996 -- lr 3.00e-04
2025-03-02 17:14:11,180 - INFO - ðŸªœ Batch step - 2749 -- sub batch step 10997 -- lr 3.00e-04
2025-03-02 17:14:13,327 - INFO - ðŸªœ Batch step - 2749 -- sub batch step 10998 -- lr 3.00e-04
2025-03-02 17:14:15,712 - INFO - ðŸªœ Batch step - 2749 -- sub batch step 10999 -- lr 3.00e-04
2025-03-02 17:14:17,549 - INFO - Step 2749 -- ðŸ”„ Training Metrics
2025-03-02 17:14:17,550 - INFO - â”œâ”€â”€ Loss: 6.2836
2025-03-02 17:14:17,550 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:14:17,550 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:14:18,224 - INFO - ðŸªœ Batch step - 2750 -- sub batch step 11000 -- lr 3.00e-04
2025-03-02 17:14:20,374 - INFO - ðŸªœ Batch step - 2750 -- sub batch step 11001 -- lr 3.00e-04
2025-03-02 17:14:22,528 - INFO - ðŸªœ Batch step - 2750 -- sub batch step 11002 -- lr 3.00e-04
2025-03-02 17:14:24,693 - INFO - ðŸªœ Batch step - 2750 -- sub batch step 11003 -- lr 3.00e-04
2025-03-02 17:14:26,246 - INFO - Step 2750 -- ðŸ”„ Training Metrics
2025-03-02 17:14:26,246 - INFO - â”œâ”€â”€ Loss: 6.2530
2025-03-02 17:14:26,246 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:14:26,246 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:14:26,919 - INFO - ðŸªœ Batch step - 2751 -- sub batch step 11004 -- lr 3.00e-04
2025-03-02 17:14:29,071 - INFO - ðŸªœ Batch step - 2751 -- sub batch step 11005 -- lr 3.00e-04
2025-03-02 17:14:31,480 - INFO - ðŸªœ Batch step - 2751 -- sub batch step 11006 -- lr 3.00e-04
2025-03-02 17:14:33,635 - INFO - ðŸªœ Batch step - 2751 -- sub batch step 11007 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 90802541-a8a6-4338-b408-dc8354357eea)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00137-of-10000.parquet
Retrying in 1s [Retry 1/5].
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: e7d58dd0-3d9f-4611-bc9e-9acc5ad46562)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00137-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:14:46,293 - INFO - Step 2751 -- ðŸ”„ Training Metrics
2025-03-02 17:14:46,294 - INFO - â”œâ”€â”€ Loss: 6.2587
2025-03-02 17:14:46,294 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:14:46,294 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:14:46,960 - INFO - ðŸªœ Batch step - 2752 -- sub batch step 11008 -- lr 3.00e-04
2025-03-02 17:14:49,113 - INFO - ðŸªœ Batch step - 2752 -- sub batch step 11009 -- lr 3.00e-04
2025-03-02 17:14:51,285 - INFO - ðŸªœ Batch step - 2752 -- sub batch step 11010 -- lr 3.00e-04
2025-03-02 17:14:53,434 - INFO - ðŸªœ Batch step - 2752 -- sub batch step 11011 -- lr 3.00e-04
2025-03-02 17:14:54,993 - INFO - Step 2752 -- ðŸ”„ Training Metrics
2025-03-02 17:14:54,993 - INFO - â”œâ”€â”€ Loss: 6.2835
2025-03-02 17:14:54,993 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:14:54,993 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:14:55,666 - INFO - ðŸªœ Batch step - 2753 -- sub batch step 11012 -- lr 3.00e-04
2025-03-02 17:14:57,814 - INFO - ðŸªœ Batch step - 2753 -- sub batch step 11013 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: c6b5092c-4308-4533-97c0-5cab1762d3c9)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00137-of-10000.parquet
Retrying in 1s [Retry 1/5].
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: cd64f8c7-7b3a-43d6-b0b0-3b22530af6f9)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00137-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:15:11,411 - INFO - ðŸªœ Batch step - 2753 -- sub batch step 11014 -- lr 3.00e-04
2025-03-02 17:15:13,575 - INFO - ðŸªœ Batch step - 2753 -- sub batch step 11015 -- lr 3.00e-04
2025-03-02 17:15:15,068 - INFO - Step 2753 -- ðŸ”„ Training Metrics
2025-03-02 17:15:15,069 - INFO - â”œâ”€â”€ Loss: 6.2730
2025-03-02 17:15:15,069 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:15:15,069 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:15:15,743 - INFO - ðŸªœ Batch step - 2754 -- sub batch step 11016 -- lr 3.00e-04
2025-03-02 17:15:17,901 - INFO - ðŸªœ Batch step - 2754 -- sub batch step 11017 -- lr 3.00e-04
2025-03-02 17:15:20,072 - INFO - ðŸªœ Batch step - 2754 -- sub batch step 11018 -- lr 3.00e-04
2025-03-02 17:15:22,226 - INFO - ðŸªœ Batch step - 2754 -- sub batch step 11019 -- lr 3.00e-04
2025-03-02 17:15:23,770 - INFO - Step 2754 -- ðŸ”„ Training Metrics
2025-03-02 17:15:23,770 - INFO - â”œâ”€â”€ Loss: 6.2698
2025-03-02 17:15:23,770 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:15:23,770 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:15:24,447 - INFO - ðŸªœ Batch step - 2755 -- sub batch step 11020 -- lr 3.00e-04
2025-03-02 17:15:26,597 - INFO - ðŸªœ Batch step - 2755 -- sub batch step 11021 -- lr 3.00e-04
2025-03-02 17:15:29,398 - INFO - ðŸªœ Batch step - 2755 -- sub batch step 11022 -- lr 3.00e-04
2025-03-02 17:15:31,551 - INFO - ðŸªœ Batch step - 2755 -- sub batch step 11023 -- lr 3.00e-04
2025-03-02 17:15:33,263 - INFO - Step 2755 -- ðŸ”„ Training Metrics
2025-03-02 17:15:33,264 - INFO - â”œâ”€â”€ Loss: 6.2987
2025-03-02 17:15:33,264 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:15:33,264 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:15:33,940 - INFO - ðŸªœ Batch step - 2756 -- sub batch step 11024 -- lr 3.00e-04
2025-03-02 17:15:36,092 - INFO - ðŸªœ Batch step - 2756 -- sub batch step 11025 -- lr 3.00e-04
2025-03-02 17:15:38,256 - INFO - ðŸªœ Batch step - 2756 -- sub batch step 11026 -- lr 3.00e-04
2025-03-02 17:15:40,408 - INFO - ðŸªœ Batch step - 2756 -- sub batch step 11027 -- lr 3.00e-04
2025-03-02 17:15:41,970 - INFO - Step 2756 -- ðŸ”„ Training Metrics
2025-03-02 17:15:41,970 - INFO - â”œâ”€â”€ Loss: 6.2660
2025-03-02 17:15:41,970 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:15:41,970 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:15:42,635 - INFO - ðŸªœ Batch step - 2757 -- sub batch step 11028 -- lr 3.00e-04
2025-03-02 17:15:44,792 - INFO - ðŸªœ Batch step - 2757 -- sub batch step 11029 -- lr 3.00e-04
2025-03-02 17:15:47,433 - INFO - ðŸªœ Batch step - 2757 -- sub batch step 11030 -- lr 3.00e-04
2025-03-02 17:15:49,582 - INFO - ðŸªœ Batch step - 2757 -- sub batch step 11031 -- lr 3.00e-04
2025-03-02 17:15:51,317 - INFO - Step 2757 -- ðŸ”„ Training Metrics
2025-03-02 17:15:51,317 - INFO - â”œâ”€â”€ Loss: 6.2995
2025-03-02 17:15:51,317 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:15:51,317 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:15:51,992 - INFO - ðŸªœ Batch step - 2758 -- sub batch step 11032 -- lr 3.00e-04
2025-03-02 17:15:54,138 - INFO - ðŸªœ Batch step - 2758 -- sub batch step 11033 -- lr 3.00e-04
2025-03-02 17:15:56,309 - INFO - ðŸªœ Batch step - 2758 -- sub batch step 11034 -- lr 3.00e-04
2025-03-02 17:15:58,461 - INFO - ðŸªœ Batch step - 2758 -- sub batch step 11035 -- lr 3.00e-04
2025-03-02 17:16:00,020 - INFO - Step 2758 -- ðŸ”„ Training Metrics
2025-03-02 17:16:00,020 - INFO - â”œâ”€â”€ Loss: 6.2463
2025-03-02 17:16:00,021 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:16:00,021 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:16:00,686 - INFO - ðŸªœ Batch step - 2759 -- sub batch step 11036 -- lr 3.00e-04
2025-03-02 17:16:02,838 - INFO - ðŸªœ Batch step - 2759 -- sub batch step 11037 -- lr 3.00e-04
2025-03-02 17:16:05,125 - INFO - ðŸªœ Batch step - 2759 -- sub batch step 11038 -- lr 3.00e-04
2025-03-02 17:16:07,280 - INFO - ðŸªœ Batch step - 2759 -- sub batch step 11039 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 20920cdb-649d-44a4-9aba-c641154f19e7)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00137-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:16:19,570 - INFO - Step 2759 -- ðŸ”„ Training Metrics
2025-03-02 17:16:19,571 - INFO - â”œâ”€â”€ Loss: 6.2553
2025-03-02 17:16:19,571 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:16:19,571 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:16:20,582 - INFO - ðŸªœ Batch step - 2760 -- sub batch step 11040 -- lr 3.00e-04
2025-03-02 17:16:22,738 - INFO - ðŸªœ Batch step - 2760 -- sub batch step 11041 -- lr 3.00e-04
2025-03-02 17:16:24,899 - INFO - ðŸªœ Batch step - 2760 -- sub batch step 11042 -- lr 3.00e-04
2025-03-02 17:16:27,064 - INFO - ðŸªœ Batch step - 2760 -- sub batch step 11043 -- lr 3.00e-04
2025-03-02 17:16:30,518 - INFO - Step 2760 -- ðŸ”„ Training Metrics
2025-03-02 17:16:30,518 - INFO - â”œâ”€â”€ Loss: 6.2548
2025-03-02 17:16:30,519 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:16:30,519 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:16:31,191 - INFO - ðŸªœ Batch step - 2761 -- sub batch step 11044 -- lr 3.00e-04
2025-03-02 17:16:33,345 - INFO - ðŸªœ Batch step - 2761 -- sub batch step 11045 -- lr 3.00e-04
2025-03-02 17:16:35,490 - INFO - ðŸªœ Batch step - 2761 -- sub batch step 11046 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 98e6ce99-7a47-4451-942c-63e843c1d27b)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00138-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:16:49,079 - INFO - ðŸªœ Batch step - 2761 -- sub batch step 11047 -- lr 3.00e-04
2025-03-02 17:16:50,570 - INFO - Step 2761 -- ðŸ”„ Training Metrics
2025-03-02 17:16:50,570 - INFO - â”œâ”€â”€ Loss: 6.2396
2025-03-02 17:16:50,570 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:16:50,570 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:16:51,237 - INFO - ðŸªœ Batch step - 2762 -- sub batch step 11048 -- lr 3.00e-04
2025-03-02 17:16:53,392 - INFO - ðŸªœ Batch step - 2762 -- sub batch step 11049 -- lr 3.00e-04
2025-03-02 17:16:55,546 - INFO - ðŸªœ Batch step - 2762 -- sub batch step 11050 -- lr 3.00e-04
2025-03-02 17:16:57,713 - INFO - ðŸªœ Batch step - 2762 -- sub batch step 11051 -- lr 3.00e-04
2025-03-02 17:16:59,270 - INFO - Step 2762 -- ðŸ”„ Training Metrics
2025-03-02 17:16:59,270 - INFO - â”œâ”€â”€ Loss: 6.2751
2025-03-02 17:16:59,270 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:16:59,270 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:16:59,943 - INFO - ðŸªœ Batch step - 2763 -- sub batch step 11052 -- lr 3.00e-04
2025-03-02 17:17:02,092 - INFO - ðŸªœ Batch step - 2763 -- sub batch step 11053 -- lr 3.00e-04
2025-03-02 17:17:04,244 - INFO - ðŸªœ Batch step - 2763 -- sub batch step 11054 -- lr 3.00e-04
2025-03-02 17:17:06,834 - INFO - ðŸªœ Batch step - 2763 -- sub batch step 11055 -- lr 3.00e-04
2025-03-02 17:17:08,712 - INFO - Step 2763 -- ðŸ”„ Training Metrics
2025-03-02 17:17:08,712 - INFO - â”œâ”€â”€ Loss: 6.2875
2025-03-02 17:17:08,712 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:17:08,712 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:17:09,387 - INFO - ðŸªœ Batch step - 2764 -- sub batch step 11056 -- lr 3.00e-04
2025-03-02 17:17:11,546 - INFO - ðŸªœ Batch step - 2764 -- sub batch step 11057 -- lr 3.00e-04
2025-03-02 17:17:13,700 - INFO - ðŸªœ Batch step - 2764 -- sub batch step 11058 -- lr 3.00e-04
2025-03-02 17:17:15,881 - INFO - ðŸªœ Batch step - 2764 -- sub batch step 11059 -- lr 3.00e-04
2025-03-02 17:17:17,404 - INFO - Step 2764 -- ðŸ”„ Training Metrics
2025-03-02 17:17:17,404 - INFO - â”œâ”€â”€ Loss: 6.2744
2025-03-02 17:17:17,404 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:17:17,404 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:17:18,084 - INFO - ðŸªœ Batch step - 2765 -- sub batch step 11060 -- lr 3.00e-04
2025-03-02 17:17:20,237 - INFO - ðŸªœ Batch step - 2765 -- sub batch step 11061 -- lr 3.00e-04
2025-03-02 17:17:22,393 - INFO - ðŸªœ Batch step - 2765 -- sub batch step 11062 -- lr 3.00e-04
2025-03-02 17:17:24,979 - INFO - ðŸªœ Batch step - 2765 -- sub batch step 11063 -- lr 3.00e-04
2025-03-02 17:17:26,584 - INFO - Step 2765 -- ðŸ”„ Training Metrics
2025-03-02 17:17:26,584 - INFO - â”œâ”€â”€ Loss: 6.2646
2025-03-02 17:17:26,584 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:17:26,584 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:17:27,257 - INFO - ðŸªœ Batch step - 2766 -- sub batch step 11064 -- lr 3.00e-04
2025-03-02 17:17:29,408 - INFO - ðŸªœ Batch step - 2766 -- sub batch step 11065 -- lr 3.00e-04
2025-03-02 17:17:31,553 - INFO - ðŸªœ Batch step - 2766 -- sub batch step 11066 -- lr 3.00e-04
2025-03-02 17:17:33,725 - INFO - ðŸªœ Batch step - 2766 -- sub batch step 11067 -- lr 3.00e-04
2025-03-02 17:17:35,298 - INFO - Step 2766 -- ðŸ”„ Training Metrics
2025-03-02 17:17:35,299 - INFO - â”œâ”€â”€ Loss: 6.2727
2025-03-02 17:17:35,299 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:17:35,299 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:17:35,966 - INFO - ðŸªœ Batch step - 2767 -- sub batch step 11068 -- lr 3.00e-04
2025-03-02 17:17:38,123 - INFO - ðŸªœ Batch step - 2767 -- sub batch step 11069 -- lr 3.00e-04
2025-03-02 17:17:40,277 - INFO - ðŸªœ Batch step - 2767 -- sub batch step 11070 -- lr 3.00e-04
2025-03-02 17:17:42,683 - INFO - ðŸªœ Batch step - 2767 -- sub batch step 11071 -- lr 3.00e-04
2025-03-02 17:17:44,471 - INFO - Step 2767 -- ðŸ”„ Training Metrics
2025-03-02 17:17:44,471 - INFO - â”œâ”€â”€ Loss: 6.2709
2025-03-02 17:17:44,472 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:17:44,472 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:17:45,145 - INFO - ðŸªœ Batch step - 2768 -- sub batch step 11072 -- lr 3.00e-04
2025-03-02 17:17:47,294 - INFO - ðŸªœ Batch step - 2768 -- sub batch step 11073 -- lr 3.00e-04
2025-03-02 17:17:49,447 - INFO - ðŸªœ Batch step - 2768 -- sub batch step 11074 -- lr 3.00e-04
2025-03-02 17:17:51,618 - INFO - ðŸªœ Batch step - 2768 -- sub batch step 11075 -- lr 3.00e-04
2025-03-02 17:17:53,176 - INFO - Step 2768 -- ðŸ”„ Training Metrics
2025-03-02 17:17:53,177 - INFO - â”œâ”€â”€ Loss: 6.2488
2025-03-02 17:17:53,177 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:17:53,177 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:17:53,842 - INFO - ðŸªœ Batch step - 2769 -- sub batch step 11076 -- lr 3.00e-04
2025-03-02 17:17:55,995 - INFO - ðŸªœ Batch step - 2769 -- sub batch step 11077 -- lr 3.00e-04
2025-03-02 17:17:58,141 - INFO - ðŸªœ Batch step - 2769 -- sub batch step 11078 -- lr 3.00e-04
2025-03-02 17:18:00,790 - INFO - ðŸªœ Batch step - 2769 -- sub batch step 11079 -- lr 3.00e-04
2025-03-02 17:18:02,305 - INFO - Step 2769 -- ðŸ”„ Training Metrics
2025-03-02 17:18:02,305 - INFO - â”œâ”€â”€ Loss: 6.2467
2025-03-02 17:18:02,305 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:18:02,305 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:18:02,979 - INFO - ðŸªœ Batch step - 2770 -- sub batch step 11080 -- lr 3.00e-04
2025-03-02 17:18:05,129 - INFO - ðŸªœ Batch step - 2770 -- sub batch step 11081 -- lr 3.00e-04
2025-03-02 17:18:07,280 - INFO - ðŸªœ Batch step - 2770 -- sub batch step 11082 -- lr 3.00e-04
2025-03-02 17:18:09,443 - INFO - ðŸªœ Batch step - 2770 -- sub batch step 11083 -- lr 3.00e-04
2025-03-02 17:18:10,998 - INFO - Step 2770 -- ðŸ”„ Training Metrics
2025-03-02 17:18:10,998 - INFO - â”œâ”€â”€ Loss: 6.2521
2025-03-02 17:18:10,998 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:18:10,998 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:18:11,673 - INFO - ðŸªœ Batch step - 2771 -- sub batch step 11084 -- lr 3.00e-04
2025-03-02 17:18:13,825 - INFO - ðŸªœ Batch step - 2771 -- sub batch step 11085 -- lr 3.00e-04
2025-03-02 17:18:16,457 - INFO - ðŸªœ Batch step - 2771 -- sub batch step 11086 -- lr 3.00e-04
2025-03-02 17:18:18,615 - INFO - ðŸªœ Batch step - 2771 -- sub batch step 11087 -- lr 3.00e-04
2025-03-02 17:18:20,281 - INFO - Step 2771 -- ðŸ”„ Training Metrics
2025-03-02 17:18:20,282 - INFO - â”œâ”€â”€ Loss: 6.2492
2025-03-02 17:18:20,282 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:18:20,282 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:18:20,950 - INFO - ðŸªœ Batch step - 2772 -- sub batch step 11088 -- lr 3.00e-04
2025-03-02 17:18:23,104 - INFO - ðŸªœ Batch step - 2772 -- sub batch step 11089 -- lr 3.00e-04
2025-03-02 17:18:25,274 - INFO - ðŸªœ Batch step - 2772 -- sub batch step 11090 -- lr 3.00e-04
2025-03-02 17:18:27,423 - INFO - ðŸªœ Batch step - 2772 -- sub batch step 11091 -- lr 3.00e-04
2025-03-02 17:18:28,982 - INFO - Step 2772 -- ðŸ”„ Training Metrics
2025-03-02 17:18:28,982 - INFO - â”œâ”€â”€ Loss: 6.2522
2025-03-02 17:18:28,982 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:18:28,982 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:18:29,655 - INFO - ðŸªœ Batch step - 2773 -- sub batch step 11092 -- lr 3.00e-04
2025-03-02 17:18:31,801 - INFO - ðŸªœ Batch step - 2773 -- sub batch step 11093 -- lr 3.00e-04
2025-03-02 17:18:34,445 - INFO - ðŸªœ Batch step - 2773 -- sub batch step 11094 -- lr 3.00e-04
2025-03-02 17:18:36,603 - INFO - ðŸªœ Batch step - 2773 -- sub batch step 11095 -- lr 3.00e-04
2025-03-02 17:18:38,163 - INFO - Step 2773 -- ðŸ”„ Training Metrics
2025-03-02 17:18:38,163 - INFO - â”œâ”€â”€ Loss: 6.2669
2025-03-02 17:18:38,163 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:18:38,163 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:18:38,829 - INFO - ðŸªœ Batch step - 2774 -- sub batch step 11096 -- lr 3.00e-04
2025-03-02 17:18:40,981 - INFO - ðŸªœ Batch step - 2774 -- sub batch step 11097 -- lr 3.00e-04
2025-03-02 17:18:43,142 - INFO - ðŸªœ Batch step - 2774 -- sub batch step 11098 -- lr 3.00e-04
2025-03-02 17:18:45,295 - INFO - ðŸªœ Batch step - 2774 -- sub batch step 11099 -- lr 3.00e-04
2025-03-02 17:18:46,863 - INFO - Step 2774 -- ðŸ”„ Training Metrics
2025-03-02 17:18:46,863 - INFO - â”œâ”€â”€ Loss: 6.2490
2025-03-02 17:18:46,863 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:18:46,863 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:18:47,535 - INFO - ðŸªœ Batch step - 2775 -- sub batch step 11100 -- lr 3.00e-04
2025-03-02 17:18:49,681 - INFO - ðŸªœ Batch step - 2775 -- sub batch step 11101 -- lr 3.00e-04
2025-03-02 17:18:52,354 - INFO - ðŸªœ Batch step - 2775 -- sub batch step 11102 -- lr 3.00e-04
2025-03-02 17:18:54,507 - INFO - ðŸªœ Batch step - 2775 -- sub batch step 11103 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: ed9a339d-0e83-4907-bcff-4032f5d64f42)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00138-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:19:06,723 - INFO - Step 2775 -- ðŸ”„ Training Metrics
2025-03-02 17:19:06,723 - INFO - â”œâ”€â”€ Loss: 6.2477
2025-03-02 17:19:06,723 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:19:06,724 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:19:07,396 - INFO - ðŸªœ Batch step - 2776 -- sub batch step 11104 -- lr 3.00e-04
2025-03-02 17:19:09,546 - INFO - ðŸªœ Batch step - 2776 -- sub batch step 11105 -- lr 3.00e-04
2025-03-02 17:19:11,715 - INFO - ðŸªœ Batch step - 2776 -- sub batch step 11106 -- lr 3.00e-04
2025-03-02 17:19:13,866 - INFO - ðŸªœ Batch step - 2776 -- sub batch step 11107 -- lr 3.00e-04
2025-03-02 17:19:15,432 - INFO - Step 2776 -- ðŸ”„ Training Metrics
2025-03-02 17:19:15,433 - INFO - â”œâ”€â”€ Loss: 6.2461
2025-03-02 17:19:15,433 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:19:15,433 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:19:16,098 - INFO - ðŸªœ Batch step - 2777 -- sub batch step 11108 -- lr 3.00e-04
2025-03-02 17:19:18,274 - INFO - ðŸªœ Batch step - 2777 -- sub batch step 11109 -- lr 3.00e-04
2025-03-02 17:19:20,935 - INFO - ðŸªœ Batch step - 2777 -- sub batch step 11110 -- lr 3.00e-04
2025-03-02 17:19:23,079 - INFO - ðŸªœ Batch step - 2777 -- sub batch step 11111 -- lr 3.00e-04
2025-03-02 17:19:24,801 - INFO - Step 2777 -- ðŸ”„ Training Metrics
2025-03-02 17:19:24,801 - INFO - â”œâ”€â”€ Loss: 6.2750
2025-03-02 17:19:24,801 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:19:24,802 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:19:25,473 - INFO - ðŸªœ Batch step - 2778 -- sub batch step 11112 -- lr 3.00e-04
2025-03-02 17:19:27,619 - INFO - ðŸªœ Batch step - 2778 -- sub batch step 11113 -- lr 3.00e-04
2025-03-02 17:19:29,789 - INFO - ðŸªœ Batch step - 2778 -- sub batch step 11114 -- lr 3.00e-04
2025-03-02 17:19:31,941 - INFO - ðŸªœ Batch step - 2778 -- sub batch step 11115 -- lr 3.00e-04
2025-03-02 17:19:33,515 - INFO - Step 2778 -- ðŸ”„ Training Metrics
2025-03-02 17:19:33,515 - INFO - â”œâ”€â”€ Loss: 6.2486
2025-03-02 17:19:33,516 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:19:33,516 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:19:34,184 - INFO - ðŸªœ Batch step - 2779 -- sub batch step 11116 -- lr 3.00e-04
2025-03-02 17:19:36,336 - INFO - ðŸªœ Batch step - 2779 -- sub batch step 11117 -- lr 3.00e-04
2025-03-02 17:19:38,615 - INFO - ðŸªœ Batch step - 2779 -- sub batch step 11118 -- lr 3.00e-04
2025-03-02 17:19:40,764 - INFO - ðŸªœ Batch step - 2779 -- sub batch step 11119 -- lr 3.00e-04
2025-03-02 17:19:42,443 - INFO - Step 2779 -- ðŸ”„ Training Metrics
2025-03-02 17:19:42,444 - INFO - â”œâ”€â”€ Loss: 6.2492
2025-03-02 17:19:42,444 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:19:42,444 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:19:43,553 - INFO - ðŸªœ Batch step - 2780 -- sub batch step 11120 -- lr 3.00e-04
2025-03-02 17:19:45,705 - INFO - ðŸªœ Batch step - 2780 -- sub batch step 11121 -- lr 3.00e-04
2025-03-02 17:19:47,862 - INFO - ðŸªœ Batch step - 2780 -- sub batch step 11122 -- lr 3.00e-04
2025-03-02 17:19:50,034 - INFO - ðŸªœ Batch step - 2780 -- sub batch step 11123 -- lr 3.00e-04
2025-03-02 17:19:51,673 - INFO - Step 2780 -- ðŸ”„ Training Metrics
2025-03-02 17:19:51,673 - INFO - â”œâ”€â”€ Loss: 6.2776
2025-03-02 17:19:51,673 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:19:51,673 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:19:52,348 - INFO - ðŸªœ Batch step - 2781 -- sub batch step 11124 -- lr 3.00e-04
2025-03-02 17:19:54,500 - INFO - ðŸªœ Batch step - 2781 -- sub batch step 11125 -- lr 3.00e-04
2025-03-02 17:19:56,648 - INFO - ðŸªœ Batch step - 2781 -- sub batch step 11126 -- lr 3.00e-04
2025-03-02 17:19:59,445 - INFO - ðŸªœ Batch step - 2781 -- sub batch step 11127 -- lr 3.00e-04
2025-03-02 17:20:00,938 - INFO - Step 2781 -- ðŸ”„ Training Metrics
2025-03-02 17:20:00,939 - INFO - â”œâ”€â”€ Loss: 6.2604
2025-03-02 17:20:00,939 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:20:00,939 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:20:01,603 - INFO - ðŸªœ Batch step - 2782 -- sub batch step 11128 -- lr 3.00e-04
2025-03-02 17:20:03,764 - INFO - ðŸªœ Batch step - 2782 -- sub batch step 11129 -- lr 3.00e-04
2025-03-02 17:20:05,917 - INFO - ðŸªœ Batch step - 2782 -- sub batch step 11130 -- lr 3.00e-04
2025-03-02 17:20:08,083 - INFO - ðŸªœ Batch step - 2782 -- sub batch step 11131 -- lr 3.00e-04
2025-03-02 17:20:09,651 - INFO - Step 2782 -- ðŸ”„ Training Metrics
2025-03-02 17:20:09,652 - INFO - â”œâ”€â”€ Loss: 6.2485
2025-03-02 17:20:09,652 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:20:09,652 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:20:10,325 - INFO - ðŸªœ Batch step - 2783 -- sub batch step 11132 -- lr 3.00e-04
2025-03-02 17:20:12,475 - INFO - ðŸªœ Batch step - 2783 -- sub batch step 11133 -- lr 3.00e-04
2025-03-02 17:20:14,633 - INFO - ðŸªœ Batch step - 2783 -- sub batch step 11134 -- lr 3.00e-04
2025-03-02 17:20:17,259 - INFO - ðŸªœ Batch step - 2783 -- sub batch step 11135 -- lr 3.00e-04
2025-03-02 17:20:18,785 - INFO - Step 2783 -- ðŸ”„ Training Metrics
2025-03-02 17:20:18,786 - INFO - â”œâ”€â”€ Loss: 6.2514
2025-03-02 17:20:18,786 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:20:18,786 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:20:19,452 - INFO - ðŸªœ Batch step - 2784 -- sub batch step 11136 -- lr 3.00e-04
2025-03-02 17:20:21,613 - INFO - ðŸªœ Batch step - 2784 -- sub batch step 11137 -- lr 3.00e-04
2025-03-02 17:20:23,762 - INFO - ðŸªœ Batch step - 2784 -- sub batch step 11138 -- lr 3.00e-04
2025-03-02 17:20:25,934 - INFO - ðŸªœ Batch step - 2784 -- sub batch step 11139 -- lr 3.00e-04
2025-03-02 17:20:27,496 - INFO - Step 2784 -- ðŸ”„ Training Metrics
2025-03-02 17:20:27,497 - INFO - â”œâ”€â”€ Loss: 6.2529
2025-03-02 17:20:27,497 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:20:27,497 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:20:28,168 - INFO - ðŸªœ Batch step - 2785 -- sub batch step 11140 -- lr 3.00e-04
2025-03-02 17:20:30,316 - INFO - ðŸªœ Batch step - 2785 -- sub batch step 11141 -- lr 3.00e-04
2025-03-02 17:20:32,470 - INFO - ðŸªœ Batch step - 2785 -- sub batch step 11142 -- lr 3.00e-04
2025-03-02 17:20:35,171 - INFO - ðŸªœ Batch step - 2785 -- sub batch step 11143 -- lr 3.00e-04
2025-03-02 17:20:36,679 - INFO - Step 2785 -- ðŸ”„ Training Metrics
2025-03-02 17:20:36,679 - INFO - â”œâ”€â”€ Loss: 6.2725
2025-03-02 17:20:36,679 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:20:36,679 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:20:37,353 - INFO - ðŸªœ Batch step - 2786 -- sub batch step 11144 -- lr 3.00e-04
2025-03-02 17:20:39,511 - INFO - ðŸªœ Batch step - 2786 -- sub batch step 11145 -- lr 3.00e-04
2025-03-02 17:20:41,659 - INFO - ðŸªœ Batch step - 2786 -- sub batch step 11146 -- lr 3.00e-04
2025-03-02 17:20:43,835 - INFO - ðŸªœ Batch step - 2786 -- sub batch step 11147 -- lr 3.00e-04
2025-03-02 17:20:45,400 - INFO - Step 2786 -- ðŸ”„ Training Metrics
2025-03-02 17:20:45,400 - INFO - â”œâ”€â”€ Loss: 6.2361
2025-03-02 17:20:45,401 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:20:45,401 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:20:46,067 - INFO - ðŸªœ Batch step - 2787 -- sub batch step 11148 -- lr 3.00e-04
2025-03-02 17:20:48,224 - INFO - ðŸªœ Batch step - 2787 -- sub batch step 11149 -- lr 3.00e-04
2025-03-02 17:20:50,380 - INFO - ðŸªœ Batch step - 2787 -- sub batch step 11150 -- lr 3.00e-04
2025-03-02 17:20:52,780 - INFO - ðŸªœ Batch step - 2787 -- sub batch step 11151 -- lr 3.00e-04
2025-03-02 17:20:54,825 - INFO - Step 2787 -- ðŸ”„ Training Metrics
2025-03-02 17:20:54,825 - INFO - â”œâ”€â”€ Loss: 6.2520
2025-03-02 17:20:54,825 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:20:54,826 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:20:55,497 - INFO - ðŸªœ Batch step - 2788 -- sub batch step 11152 -- lr 3.00e-04
2025-03-02 17:20:57,648 - INFO - ðŸªœ Batch step - 2788 -- sub batch step 11153 -- lr 3.00e-04
2025-03-02 17:20:59,805 - INFO - ðŸªœ Batch step - 2788 -- sub batch step 11154 -- lr 3.00e-04
2025-03-02 17:21:01,979 - INFO - ðŸªœ Batch step - 2788 -- sub batch step 11155 -- lr 3.00e-04
2025-03-02 17:21:03,539 - INFO - Step 2788 -- ðŸ”„ Training Metrics
2025-03-02 17:21:03,539 - INFO - â”œâ”€â”€ Loss: 6.2388
2025-03-02 17:21:03,539 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:21:03,539 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:21:04,206 - INFO - ðŸªœ Batch step - 2789 -- sub batch step 11156 -- lr 3.00e-04
2025-03-02 17:21:06,365 - INFO - ðŸªœ Batch step - 2789 -- sub batch step 11157 -- lr 3.00e-04
2025-03-02 17:21:08,514 - INFO - ðŸªœ Batch step - 2789 -- sub batch step 11158 -- lr 3.00e-04
2025-03-02 17:21:11,115 - INFO - ðŸªœ Batch step - 2789 -- sub batch step 11159 -- lr 3.00e-04
2025-03-02 17:21:12,739 - INFO - Step 2789 -- ðŸ”„ Training Metrics
2025-03-02 17:21:12,740 - INFO - â”œâ”€â”€ Loss: 6.2545
2025-03-02 17:21:12,740 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:21:12,740 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:21:13,409 - INFO - ðŸªœ Batch step - 2790 -- sub batch step 11160 -- lr 3.00e-04
2025-03-02 17:21:15,558 - INFO - ðŸªœ Batch step - 2790 -- sub batch step 11161 -- lr 3.00e-04
2025-03-02 17:21:17,717 - INFO - ðŸªœ Batch step - 2790 -- sub batch step 11162 -- lr 3.00e-04
2025-03-02 17:21:19,888 - INFO - ðŸªœ Batch step - 2790 -- sub batch step 11163 -- lr 3.00e-04
2025-03-02 17:21:21,459 - INFO - Step 2790 -- ðŸ”„ Training Metrics
2025-03-02 17:21:21,459 - INFO - â”œâ”€â”€ Loss: 6.2516
2025-03-02 17:21:21,459 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:21:21,459 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:21:22,137 - INFO - ðŸªœ Batch step - 2791 -- sub batch step 11164 -- lr 3.00e-04
2025-03-02 17:21:24,294 - INFO - ðŸªœ Batch step - 2791 -- sub batch step 11165 -- lr 3.00e-04
2025-03-02 17:21:27,015 - INFO - ðŸªœ Batch step - 2791 -- sub batch step 11166 -- lr 3.00e-04
2025-03-02 17:21:29,180 - INFO - ðŸªœ Batch step - 2791 -- sub batch step 11167 -- lr 3.00e-04
2025-03-02 17:21:30,693 - INFO - Step 2791 -- ðŸ”„ Training Metrics
2025-03-02 17:21:30,694 - INFO - â”œâ”€â”€ Loss: 6.2427
2025-03-02 17:21:30,694 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:21:30,694 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:21:31,367 - INFO - ðŸªœ Batch step - 2792 -- sub batch step 11168 -- lr 3.00e-04
2025-03-02 17:21:33,533 - INFO - ðŸªœ Batch step - 2792 -- sub batch step 11169 -- lr 3.00e-04
2025-03-02 17:21:35,714 - INFO - ðŸªœ Batch step - 2792 -- sub batch step 11170 -- lr 3.00e-04
2025-03-02 17:21:37,863 - INFO - ðŸªœ Batch step - 2792 -- sub batch step 11171 -- lr 3.00e-04
2025-03-02 17:21:39,411 - INFO - Step 2792 -- ðŸ”„ Training Metrics
2025-03-02 17:21:39,411 - INFO - â”œâ”€â”€ Loss: 6.2752
2025-03-02 17:21:39,411 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:21:39,412 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:21:40,082 - INFO - ðŸªœ Batch step - 2793 -- sub batch step 11172 -- lr 3.00e-04
2025-03-02 17:21:42,224 - INFO - ðŸªœ Batch step - 2793 -- sub batch step 11173 -- lr 3.00e-04
2025-03-02 17:21:44,941 - INFO - ðŸªœ Batch step - 2793 -- sub batch step 11174 -- lr 3.00e-04
2025-03-02 17:21:47,100 - INFO - ðŸªœ Batch step - 2793 -- sub batch step 11175 -- lr 3.00e-04
2025-03-02 17:21:48,633 - INFO - Step 2793 -- ðŸ”„ Training Metrics
2025-03-02 17:21:48,633 - INFO - â”œâ”€â”€ Loss: 6.2230
2025-03-02 17:21:48,633 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:21:48,633 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:21:49,308 - INFO - ðŸªœ Batch step - 2794 -- sub batch step 11176 -- lr 3.00e-04
2025-03-02 17:21:51,467 - INFO - ðŸªœ Batch step - 2794 -- sub batch step 11177 -- lr 3.00e-04
2025-03-02 17:21:53,637 - INFO - ðŸªœ Batch step - 2794 -- sub batch step 11178 -- lr 3.00e-04
2025-03-02 17:21:55,794 - INFO - ðŸªœ Batch step - 2794 -- sub batch step 11179 -- lr 3.00e-04
2025-03-02 17:21:57,361 - INFO - Step 2794 -- ðŸ”„ Training Metrics
2025-03-02 17:21:57,361 - INFO - â”œâ”€â”€ Loss: 6.2520
2025-03-02 17:21:57,361 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:21:57,361 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:21:58,043 - INFO - ðŸªœ Batch step - 2795 -- sub batch step 11180 -- lr 3.00e-04
2025-03-02 17:22:00,195 - INFO - ðŸªœ Batch step - 2795 -- sub batch step 11181 -- lr 3.00e-04
2025-03-02 17:22:02,922 - INFO - ðŸªœ Batch step - 2795 -- sub batch step 11182 -- lr 3.00e-04
2025-03-02 17:22:05,075 - INFO - ðŸªœ Batch step - 2795 -- sub batch step 11183 -- lr 3.00e-04
2025-03-02 17:22:06,580 - INFO - Step 2795 -- ðŸ”„ Training Metrics
2025-03-02 17:22:06,580 - INFO - â”œâ”€â”€ Loss: 6.2216
2025-03-02 17:22:06,580 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:22:06,580 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:22:07,255 - INFO - ðŸªœ Batch step - 2796 -- sub batch step 11184 -- lr 3.00e-04
2025-03-02 17:22:09,411 - INFO - ðŸªœ Batch step - 2796 -- sub batch step 11185 -- lr 3.00e-04
2025-03-02 17:22:11,576 - INFO - ðŸªœ Batch step - 2796 -- sub batch step 11186 -- lr 3.00e-04
2025-03-02 17:22:13,737 - INFO - ðŸªœ Batch step - 2796 -- sub batch step 11187 -- lr 3.00e-04
2025-03-02 17:22:15,287 - INFO - Step 2796 -- ðŸ”„ Training Metrics
2025-03-02 17:22:15,287 - INFO - â”œâ”€â”€ Loss: 6.2264
2025-03-02 17:22:15,287 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:22:15,287 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:22:15,958 - INFO - ðŸªœ Batch step - 2797 -- sub batch step 11188 -- lr 3.00e-04
2025-03-02 17:22:18,110 - INFO - ðŸªœ Batch step - 2797 -- sub batch step 11189 -- lr 3.00e-04
2025-03-02 17:22:20,796 - INFO - ðŸªœ Batch step - 2797 -- sub batch step 11190 -- lr 3.00e-04
2025-03-02 17:22:22,942 - INFO - ðŸªœ Batch step - 2797 -- sub batch step 11191 -- lr 3.00e-04
2025-03-02 17:22:24,536 - INFO - Step 2797 -- ðŸ”„ Training Metrics
2025-03-02 17:22:24,537 - INFO - â”œâ”€â”€ Loss: 6.2546
2025-03-02 17:22:24,537 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:22:24,537 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:22:25,210 - INFO - ðŸªœ Batch step - 2798 -- sub batch step 11192 -- lr 3.00e-04
2025-03-02 17:22:27,359 - INFO - ðŸªœ Batch step - 2798 -- sub batch step 11193 -- lr 3.00e-04
2025-03-02 17:22:29,535 - INFO - ðŸªœ Batch step - 2798 -- sub batch step 11194 -- lr 3.00e-04
2025-03-02 17:22:31,690 - INFO - ðŸªœ Batch step - 2798 -- sub batch step 11195 -- lr 3.00e-04
2025-03-02 17:22:33,261 - INFO - Step 2798 -- ðŸ”„ Training Metrics
2025-03-02 17:22:33,261 - INFO - â”œâ”€â”€ Loss: 6.2610
2025-03-02 17:22:33,262 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:22:33,262 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:22:33,932 - INFO - ðŸªœ Batch step - 2799 -- sub batch step 11196 -- lr 3.00e-04
2025-03-02 17:22:36,087 - INFO - ðŸªœ Batch step - 2799 -- sub batch step 11197 -- lr 3.00e-04
2025-03-02 17:22:38,368 - INFO - ðŸªœ Batch step - 2799 -- sub batch step 11198 -- lr 3.00e-04
2025-03-02 17:22:40,520 - INFO - ðŸªœ Batch step - 2799 -- sub batch step 11199 -- lr 3.00e-04
2025-03-02 17:22:42,212 - INFO - Step 2799 -- ðŸ”„ Training Metrics
2025-03-02 17:22:42,213 - INFO - â”œâ”€â”€ Loss: 6.2484
2025-03-02 17:22:42,213 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:22:42,213 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:22:43,445 - INFO - ðŸªœ Batch step - 2800 -- sub batch step 11200 -- lr 3.00e-04
2025-03-02 17:22:45,603 - INFO - ðŸªœ Batch step - 2800 -- sub batch step 11201 -- lr 3.00e-04
2025-03-02 17:22:47,765 - INFO - ðŸªœ Batch step - 2800 -- sub batch step 11202 -- lr 3.00e-04
2025-03-02 17:22:49,947 - INFO - ðŸªœ Batch step - 2800 -- sub batch step 11203 -- lr 3.00e-04
2025-03-02 17:22:51,536 - INFO - Step 2800 -- ðŸ”„ Training Metrics
2025-03-02 17:22:51,536 - INFO - â”œâ”€â”€ Loss: 6.2175
2025-03-02 17:22:51,536 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:22:51,536 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:22:52,213 - INFO - ðŸªœ Batch step - 2801 -- sub batch step 11204 -- lr 3.00e-04
2025-03-02 17:22:54,367 - INFO - ðŸªœ Batch step - 2801 -- sub batch step 11205 -- lr 3.00e-04
2025-03-02 17:22:56,512 - INFO - ðŸªœ Batch step - 2801 -- sub batch step 11206 -- lr 3.00e-04
2025-03-02 17:22:59,319 - INFO - ðŸªœ Batch step - 2801 -- sub batch step 11207 -- lr 3.00e-04
2025-03-02 17:23:00,936 - INFO - Step 2801 -- ðŸ”„ Training Metrics
2025-03-02 17:23:00,936 - INFO - â”œâ”€â”€ Loss: 6.2564
2025-03-02 17:23:00,937 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:23:00,937 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:23:01,620 - INFO - ðŸªœ Batch step - 2802 -- sub batch step 11208 -- lr 3.00e-04
2025-03-02 17:23:03,784 - INFO - ðŸªœ Batch step - 2802 -- sub batch step 11209 -- lr 3.00e-04
2025-03-02 17:23:05,946 - INFO - ðŸªœ Batch step - 2802 -- sub batch step 11210 -- lr 3.00e-04
2025-03-02 17:23:08,129 - INFO - ðŸªœ Batch step - 2802 -- sub batch step 11211 -- lr 3.00e-04
2025-03-02 17:23:09,671 - INFO - Step 2802 -- ðŸ”„ Training Metrics
2025-03-02 17:23:09,672 - INFO - â”œâ”€â”€ Loss: 6.2555
2025-03-02 17:23:09,672 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:23:09,672 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:23:10,356 - INFO - ðŸªœ Batch step - 2803 -- sub batch step 11212 -- lr 3.00e-04
2025-03-02 17:23:12,510 - INFO - ðŸªœ Batch step - 2803 -- sub batch step 11213 -- lr 3.00e-04
2025-03-02 17:23:14,674 - INFO - ðŸªœ Batch step - 2803 -- sub batch step 11214 -- lr 3.00e-04
2025-03-02 17:23:17,290 - INFO - ðŸªœ Batch step - 2803 -- sub batch step 11215 -- lr 3.00e-04
2025-03-02 17:23:18,852 - INFO - Step 2803 -- ðŸ”„ Training Metrics
2025-03-02 17:23:18,852 - INFO - â”œâ”€â”€ Loss: 6.2441
2025-03-02 17:23:18,852 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:23:18,852 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:23:19,517 - INFO - ðŸªœ Batch step - 2804 -- sub batch step 11216 -- lr 3.00e-04
2025-03-02 17:23:21,673 - INFO - ðŸªœ Batch step - 2804 -- sub batch step 11217 -- lr 3.00e-04
2025-03-02 17:23:23,823 - INFO - ðŸªœ Batch step - 2804 -- sub batch step 11218 -- lr 3.00e-04
2025-03-02 17:23:26,002 - INFO - ðŸªœ Batch step - 2804 -- sub batch step 11219 -- lr 3.00e-04
2025-03-02 17:23:27,561 - INFO - Step 2804 -- ðŸ”„ Training Metrics
2025-03-02 17:23:27,561 - INFO - â”œâ”€â”€ Loss: 6.2535
2025-03-02 17:23:27,561 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:23:27,561 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:23:28,234 - INFO - ðŸªœ Batch step - 2805 -- sub batch step 11220 -- lr 3.00e-04
2025-03-02 17:23:30,386 - INFO - ðŸªœ Batch step - 2805 -- sub batch step 11221 -- lr 3.00e-04
2025-03-02 17:23:32,542 - INFO - ðŸªœ Batch step - 2805 -- sub batch step 11222 -- lr 3.00e-04
2025-03-02 17:23:35,186 - INFO - ðŸªœ Batch step - 2805 -- sub batch step 11223 -- lr 3.00e-04
2025-03-02 17:23:36,827 - INFO - Step 2805 -- ðŸ”„ Training Metrics
2025-03-02 17:23:36,827 - INFO - â”œâ”€â”€ Loss: 6.2558
2025-03-02 17:23:36,828 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:23:36,828 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:23:37,505 - INFO - ðŸªœ Batch step - 2806 -- sub batch step 11224 -- lr 3.00e-04
2025-03-02 17:23:39,663 - INFO - ðŸªœ Batch step - 2806 -- sub batch step 11225 -- lr 3.00e-04
2025-03-02 17:23:41,816 - INFO - ðŸªœ Batch step - 2806 -- sub batch step 11226 -- lr 3.00e-04
2025-03-02 17:23:44,001 - INFO - ðŸªœ Batch step - 2806 -- sub batch step 11227 -- lr 3.00e-04
2025-03-02 17:23:45,554 - INFO - Step 2806 -- ðŸ”„ Training Metrics
2025-03-02 17:23:45,554 - INFO - â”œâ”€â”€ Loss: 6.2049
2025-03-02 17:23:45,554 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:23:45,554 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:23:46,225 - INFO - ðŸªœ Batch step - 2807 -- sub batch step 11228 -- lr 3.00e-04
2025-03-02 17:23:48,381 - INFO - ðŸªœ Batch step - 2807 -- sub batch step 11229 -- lr 3.00e-04
2025-03-02 17:23:50,532 - INFO - ðŸªœ Batch step - 2807 -- sub batch step 11230 -- lr 3.00e-04
2025-03-02 17:23:52,935 - INFO - ðŸªœ Batch step - 2807 -- sub batch step 11231 -- lr 3.00e-04
2025-03-02 17:23:54,785 - INFO - Step 2807 -- ðŸ”„ Training Metrics
2025-03-02 17:23:54,785 - INFO - â”œâ”€â”€ Loss: 6.2332
2025-03-02 17:23:54,785 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:23:54,786 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:23:55,456 - INFO - ðŸªœ Batch step - 2808 -- sub batch step 11232 -- lr 3.00e-04
2025-03-02 17:23:57,607 - INFO - ðŸªœ Batch step - 2808 -- sub batch step 11233 -- lr 3.00e-04
2025-03-02 17:23:59,762 - INFO - ðŸªœ Batch step - 2808 -- sub batch step 11234 -- lr 3.00e-04
2025-03-02 17:24:01,934 - INFO - ðŸªœ Batch step - 2808 -- sub batch step 11235 -- lr 3.00e-04
2025-03-02 17:24:03,503 - INFO - Step 2808 -- ðŸ”„ Training Metrics
2025-03-02 17:24:03,503 - INFO - â”œâ”€â”€ Loss: 6.2433
2025-03-02 17:24:03,503 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:24:03,504 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:24:04,173 - INFO - ðŸªœ Batch step - 2809 -- sub batch step 11236 -- lr 3.00e-04
2025-03-02 17:24:06,329 - INFO - ðŸªœ Batch step - 2809 -- sub batch step 11237 -- lr 3.00e-04
2025-03-02 17:24:08,475 - INFO - ðŸªœ Batch step - 2809 -- sub batch step 11238 -- lr 3.00e-04
2025-03-02 17:24:11,119 - INFO - ðŸªœ Batch step - 2809 -- sub batch step 11239 -- lr 3.00e-04
2025-03-02 17:24:12,684 - INFO - Step 2809 -- ðŸ”„ Training Metrics
2025-03-02 17:24:12,684 - INFO - â”œâ”€â”€ Loss: 6.2410
2025-03-02 17:24:12,684 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:24:12,685 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:24:13,360 - INFO - ðŸªœ Batch step - 2810 -- sub batch step 11240 -- lr 3.00e-04
2025-03-02 17:24:15,510 - INFO - ðŸªœ Batch step - 2810 -- sub batch step 11241 -- lr 3.00e-04
2025-03-02 17:24:17,664 - INFO - ðŸªœ Batch step - 2810 -- sub batch step 11242 -- lr 3.00e-04
2025-03-02 17:24:19,827 - INFO - ðŸªœ Batch step - 2810 -- sub batch step 11243 -- lr 3.00e-04
2025-03-02 17:24:21,361 - INFO - Step 2810 -- ðŸ”„ Training Metrics
2025-03-02 17:24:21,361 - INFO - â”œâ”€â”€ Loss: 6.2318
2025-03-02 17:24:21,361 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:24:21,361 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:24:22,034 - INFO - ðŸªœ Batch step - 2811 -- sub batch step 11244 -- lr 3.00e-04
2025-03-02 17:24:24,193 - INFO - ðŸªœ Batch step - 2811 -- sub batch step 11245 -- lr 3.00e-04
2025-03-02 17:24:26,817 - INFO - ðŸªœ Batch step - 2811 -- sub batch step 11246 -- lr 3.00e-04
2025-03-02 17:24:28,973 - INFO - ðŸªœ Batch step - 2811 -- sub batch step 11247 -- lr 3.00e-04
2025-03-02 17:24:30,586 - INFO - Step 2811 -- ðŸ”„ Training Metrics
2025-03-02 17:24:30,587 - INFO - â”œâ”€â”€ Loss: 6.2406
2025-03-02 17:24:30,587 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:24:30,587 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:24:31,257 - INFO - ðŸªœ Batch step - 2812 -- sub batch step 11248 -- lr 3.00e-04
2025-03-02 17:24:33,414 - INFO - ðŸªœ Batch step - 2812 -- sub batch step 11249 -- lr 3.00e-04
2025-03-02 17:24:35,584 - INFO - ðŸªœ Batch step - 2812 -- sub batch step 11250 -- lr 3.00e-04
2025-03-02 17:24:37,735 - INFO - ðŸªœ Batch step - 2812 -- sub batch step 11251 -- lr 3.00e-04
2025-03-02 17:24:39,275 - INFO - Step 2812 -- ðŸ”„ Training Metrics
2025-03-02 17:24:39,275 - INFO - â”œâ”€â”€ Loss: 6.2499
2025-03-02 17:24:39,276 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:24:39,276 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:24:39,954 - INFO - ðŸªœ Batch step - 2813 -- sub batch step 11252 -- lr 3.00e-04
2025-03-02 17:24:42,106 - INFO - ðŸªœ Batch step - 2813 -- sub batch step 11253 -- lr 3.00e-04
2025-03-02 17:24:44,721 - INFO - ðŸªœ Batch step - 2813 -- sub batch step 11254 -- lr 3.00e-04
2025-03-02 17:24:46,877 - INFO - ðŸªœ Batch step - 2813 -- sub batch step 11255 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 1dafb4f6-df23-4c1a-8b6c-e89e54069243)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00140-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:24:59,289 - INFO - Step 2813 -- ðŸ”„ Training Metrics
2025-03-02 17:24:59,289 - INFO - â”œâ”€â”€ Loss: 6.2358
2025-03-02 17:24:59,289 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:24:59,289 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:24:59,960 - INFO - ðŸªœ Batch step - 2814 -- sub batch step 11256 -- lr 3.00e-04
2025-03-02 17:25:02,119 - INFO - ðŸªœ Batch step - 2814 -- sub batch step 11257 -- lr 3.00e-04
2025-03-02 17:25:04,289 - INFO - ðŸªœ Batch step - 2814 -- sub batch step 11258 -- lr 3.00e-04
2025-03-02 17:25:06,443 - INFO - ðŸªœ Batch step - 2814 -- sub batch step 11259 -- lr 3.00e-04
2025-03-02 17:25:07,966 - INFO - Step 2814 -- ðŸ”„ Training Metrics
2025-03-02 17:25:07,966 - INFO - â”œâ”€â”€ Loss: 6.2613
2025-03-02 17:25:07,966 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:25:07,966 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:25:08,643 - INFO - ðŸªœ Batch step - 2815 -- sub batch step 11260 -- lr 3.00e-04
2025-03-02 17:25:10,788 - INFO - ðŸªœ Batch step - 2815 -- sub batch step 11261 -- lr 3.00e-04
2025-03-02 17:25:13,451 - INFO - ðŸªœ Batch step - 2815 -- sub batch step 11262 -- lr 3.00e-04
2025-03-02 17:25:15,603 - INFO - ðŸªœ Batch step - 2815 -- sub batch step 11263 -- lr 3.00e-04
2025-03-02 17:25:17,220 - INFO - Step 2815 -- ðŸ”„ Training Metrics
2025-03-02 17:25:17,220 - INFO - â”œâ”€â”€ Loss: 6.2297
2025-03-02 17:25:17,220 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:25:17,221 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:25:17,911 - INFO - ðŸªœ Batch step - 2816 -- sub batch step 11264 -- lr 3.00e-04
2025-03-02 17:25:20,406 - INFO - ðŸªœ Batch step - 2816 -- sub batch step 11265 -- lr 3.00e-04
2025-03-02 17:25:22,574 - INFO - ðŸªœ Batch step - 2816 -- sub batch step 11266 -- lr 3.00e-04
2025-03-02 17:25:24,733 - INFO - ðŸªœ Batch step - 2816 -- sub batch step 11267 -- lr 3.00e-04
2025-03-02 17:25:26,254 - INFO - Step 2816 -- ðŸ”„ Training Metrics
2025-03-02 17:25:26,254 - INFO - â”œâ”€â”€ Loss: 6.2232
2025-03-02 17:25:26,255 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:25:26,255 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:25:26,924 - INFO - ðŸªœ Batch step - 2817 -- sub batch step 11268 -- lr 3.00e-04
2025-03-02 17:25:29,085 - INFO - ðŸªœ Batch step - 2817 -- sub batch step 11269 -- lr 3.00e-04
2025-03-02 17:25:31,755 - INFO - ðŸªœ Batch step - 2817 -- sub batch step 11270 -- lr 3.00e-04
2025-03-02 17:25:33,903 - INFO - ðŸªœ Batch step - 2817 -- sub batch step 11271 -- lr 3.00e-04
2025-03-02 17:25:35,481 - INFO - Step 2817 -- ðŸ”„ Training Metrics
2025-03-02 17:25:35,481 - INFO - â”œâ”€â”€ Loss: 6.2297
2025-03-02 17:25:35,481 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:25:35,481 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:25:36,152 - INFO - ðŸªœ Batch step - 2818 -- sub batch step 11272 -- lr 3.00e-04
2025-03-02 17:25:38,299 - INFO - ðŸªœ Batch step - 2818 -- sub batch step 11273 -- lr 3.00e-04
2025-03-02 17:25:40,473 - INFO - ðŸªœ Batch step - 2818 -- sub batch step 11274 -- lr 3.00e-04
2025-03-02 17:25:42,624 - INFO - ðŸªœ Batch step - 2818 -- sub batch step 11275 -- lr 3.00e-04
2025-03-02 17:25:44,164 - INFO - Step 2818 -- ðŸ”„ Training Metrics
2025-03-02 17:25:44,164 - INFO - â”œâ”€â”€ Loss: 6.2366
2025-03-02 17:25:44,164 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:25:44,164 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:25:44,834 - INFO - ðŸªœ Batch step - 2819 -- sub batch step 11276 -- lr 3.00e-04
2025-03-02 17:25:46,987 - INFO - ðŸªœ Batch step - 2819 -- sub batch step 11277 -- lr 3.00e-04
2025-03-02 17:25:49,263 - INFO - ðŸªœ Batch step - 2819 -- sub batch step 11278 -- lr 3.00e-04
2025-03-02 17:25:51,420 - INFO - ðŸªœ Batch step - 2819 -- sub batch step 11279 -- lr 3.00e-04
2025-03-02 17:25:52,967 - INFO - Step 2819 -- ðŸ”„ Training Metrics
2025-03-02 17:25:52,968 - INFO - â”œâ”€â”€ Loss: 6.2298
2025-03-02 17:25:52,968 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:25:52,968 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:25:54,209 - INFO - ðŸªœ Batch step - 2820 -- sub batch step 11280 -- lr 3.00e-04
2025-03-02 17:25:56,356 - INFO - ðŸªœ Batch step - 2820 -- sub batch step 11281 -- lr 3.00e-04
2025-03-02 17:25:58,510 - INFO - ðŸªœ Batch step - 2820 -- sub batch step 11282 -- lr 3.00e-04
2025-03-02 17:26:00,683 - INFO - ðŸªœ Batch step - 2820 -- sub batch step 11283 -- lr 3.00e-04
2025-03-02 17:26:02,538 - INFO - Step 2820 -- ðŸ”„ Training Metrics
2025-03-02 17:26:02,538 - INFO - â”œâ”€â”€ Loss: 6.2343
2025-03-02 17:26:02,538 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:26:02,538 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:26:03,209 - INFO - ðŸªœ Batch step - 2821 -- sub batch step 11284 -- lr 3.00e-04
2025-03-02 17:26:05,367 - INFO - ðŸªœ Batch step - 2821 -- sub batch step 11285 -- lr 3.00e-04
2025-03-02 17:26:07,513 - INFO - ðŸªœ Batch step - 2821 -- sub batch step 11286 -- lr 3.00e-04
2025-03-02 17:26:09,970 - INFO - ðŸªœ Batch step - 2821 -- sub batch step 11287 -- lr 3.00e-04
2025-03-02 17:26:16,557 - INFO - Step 2821 -- ðŸ”„ Training Metrics
2025-03-02 17:26:16,557 - INFO - â”œâ”€â”€ Loss: 6.2514
2025-03-02 17:26:16,557 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:26:16,557 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:26:17,223 - INFO - ðŸªœ Batch step - 2822 -- sub batch step 11288 -- lr 3.00e-04
2025-03-02 17:26:19,381 - INFO - ðŸªœ Batch step - 2822 -- sub batch step 11289 -- lr 3.00e-04
2025-03-02 17:26:21,538 - INFO - ðŸªœ Batch step - 2822 -- sub batch step 11290 -- lr 3.00e-04
2025-03-02 17:26:23,707 - INFO - ðŸªœ Batch step - 2822 -- sub batch step 11291 -- lr 3.00e-04
2025-03-02 17:26:25,249 - INFO - Step 2822 -- ðŸ”„ Training Metrics
2025-03-02 17:26:25,249 - INFO - â”œâ”€â”€ Loss: 6.2248
2025-03-02 17:26:25,249 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:26:25,250 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:26:25,922 - INFO - ðŸªœ Batch step - 2823 -- sub batch step 11292 -- lr 3.00e-04
2025-03-02 17:26:28,070 - INFO - ðŸªœ Batch step - 2823 -- sub batch step 11293 -- lr 3.00e-04
2025-03-02 17:26:30,228 - INFO - ðŸªœ Batch step - 2823 -- sub batch step 11294 -- lr 3.00e-04
2025-03-02 17:26:32,668 - INFO - ðŸªœ Batch step - 2823 -- sub batch step 11295 -- lr 3.00e-04
2025-03-02 17:26:34,657 - INFO - Step 2823 -- ðŸ”„ Training Metrics
2025-03-02 17:26:34,657 - INFO - â”œâ”€â”€ Loss: 6.2332
2025-03-02 17:26:34,657 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:26:34,657 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:26:35,322 - INFO - ðŸªœ Batch step - 2824 -- sub batch step 11296 -- lr 3.00e-04
2025-03-02 17:26:37,855 - INFO - ðŸªœ Batch step - 2824 -- sub batch step 11297 -- lr 3.00e-04
2025-03-02 17:26:40,003 - INFO - ðŸªœ Batch step - 2824 -- sub batch step 11298 -- lr 3.00e-04
2025-03-02 17:26:42,514 - INFO - ðŸªœ Batch step - 2824 -- sub batch step 11299 -- lr 3.00e-04
2025-03-02 17:26:44,014 - INFO - Step 2824 -- ðŸ”„ Training Metrics
2025-03-02 17:26:44,015 - INFO - â”œâ”€â”€ Loss: 6.2283
2025-03-02 17:26:44,015 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:26:44,015 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:26:44,691 - INFO - ðŸªœ Batch step - 2825 -- sub batch step 11300 -- lr 3.00e-04
2025-03-02 17:26:46,845 - INFO - ðŸªœ Batch step - 2825 -- sub batch step 11301 -- lr 3.00e-04
2025-03-02 17:26:49,003 - INFO - ðŸªœ Batch step - 2825 -- sub batch step 11302 -- lr 3.00e-04
2025-03-02 17:26:51,633 - INFO - ðŸªœ Batch step - 2825 -- sub batch step 11303 -- lr 3.00e-04
2025-03-02 17:26:53,355 - INFO - Step 2825 -- ðŸ”„ Training Metrics
2025-03-02 17:26:53,355 - INFO - â”œâ”€â”€ Loss: 6.2238
2025-03-02 17:26:53,355 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:26:53,356 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:26:54,026 - INFO - ðŸªœ Batch step - 2826 -- sub batch step 11304 -- lr 3.00e-04
2025-03-02 17:26:56,185 - INFO - ðŸªœ Batch step - 2826 -- sub batch step 11305 -- lr 3.00e-04
2025-03-02 17:26:58,335 - INFO - ðŸªœ Batch step - 2826 -- sub batch step 11306 -- lr 3.00e-04
2025-03-02 17:27:00,515 - INFO - ðŸªœ Batch step - 2826 -- sub batch step 11307 -- lr 3.00e-04
2025-03-02 17:27:02,121 - INFO - Step 2826 -- ðŸ”„ Training Metrics
2025-03-02 17:27:02,122 - INFO - â”œâ”€â”€ Loss: 6.2400
2025-03-02 17:27:02,122 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:27:02,122 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:27:02,967 - INFO - ðŸªœ Batch step - 2827 -- sub batch step 11308 -- lr 3.00e-04
2025-03-02 17:27:05,122 - INFO - ðŸªœ Batch step - 2827 -- sub batch step 11309 -- lr 3.00e-04
2025-03-02 17:27:07,274 - INFO - ðŸªœ Batch step - 2827 -- sub batch step 11310 -- lr 3.00e-04
2025-03-02 17:27:09,691 - INFO - ðŸªœ Batch step - 2827 -- sub batch step 11311 -- lr 3.00e-04
2025-03-02 17:27:11,528 - INFO - Step 2827 -- ðŸ”„ Training Metrics
2025-03-02 17:27:11,528 - INFO - â”œâ”€â”€ Loss: 6.2186
2025-03-02 17:27:11,528 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:27:11,529 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:27:12,200 - INFO - ðŸªœ Batch step - 2828 -- sub batch step 11312 -- lr 3.00e-04
2025-03-02 17:27:14,352 - INFO - ðŸªœ Batch step - 2828 -- sub batch step 11313 -- lr 3.00e-04
2025-03-02 17:27:16,510 - INFO - ðŸªœ Batch step - 2828 -- sub batch step 11314 -- lr 3.00e-04
2025-03-02 17:27:18,693 - INFO - ðŸªœ Batch step - 2828 -- sub batch step 11315 -- lr 3.00e-04
2025-03-02 17:27:20,215 - INFO - Step 2828 -- ðŸ”„ Training Metrics
2025-03-02 17:27:20,215 - INFO - â”œâ”€â”€ Loss: 6.2581
2025-03-02 17:27:20,215 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:27:20,215 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:27:20,885 - INFO - ðŸªœ Batch step - 2829 -- sub batch step 11316 -- lr 3.00e-04
2025-03-02 17:27:23,045 - INFO - ðŸªœ Batch step - 2829 -- sub batch step 11317 -- lr 3.00e-04
2025-03-02 17:27:25,195 - INFO - ðŸªœ Batch step - 2829 -- sub batch step 11318 -- lr 3.00e-04
2025-03-02 17:27:27,854 - INFO - ðŸªœ Batch step - 2829 -- sub batch step 11319 -- lr 3.00e-04
2025-03-02 17:27:29,513 - INFO - Step 2829 -- ðŸ”„ Training Metrics
2025-03-02 17:27:29,513 - INFO - â”œâ”€â”€ Loss: 6.2239
2025-03-02 17:27:29,513 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:27:29,513 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:27:30,188 - INFO - ðŸªœ Batch step - 2830 -- sub batch step 11320 -- lr 3.00e-04
2025-03-02 17:27:32,343 - INFO - ðŸªœ Batch step - 2830 -- sub batch step 11321 -- lr 3.00e-04
2025-03-02 17:27:34,504 - INFO - ðŸªœ Batch step - 2830 -- sub batch step 11322 -- lr 3.00e-04
2025-03-02 17:27:36,673 - INFO - ðŸªœ Batch step - 2830 -- sub batch step 11323 -- lr 3.00e-04
2025-03-02 17:27:38,202 - INFO - Step 2830 -- ðŸ”„ Training Metrics
2025-03-02 17:27:38,203 - INFO - â”œâ”€â”€ Loss: 6.2776
2025-03-02 17:27:38,203 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:27:38,203 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:27:38,881 - INFO - ðŸªœ Batch step - 2831 -- sub batch step 11324 -- lr 3.00e-04
2025-03-02 17:27:41,040 - INFO - ðŸªœ Batch step - 2831 -- sub batch step 11325 -- lr 3.00e-04
2025-03-02 17:27:43,746 - INFO - ðŸªœ Batch step - 2831 -- sub batch step 11326 -- lr 3.00e-04
2025-03-02 17:27:45,911 - INFO - ðŸªœ Batch step - 2831 -- sub batch step 11327 -- lr 3.00e-04
2025-03-02 17:27:47,478 - INFO - Step 2831 -- ðŸ”„ Training Metrics
2025-03-02 17:27:47,478 - INFO - â”œâ”€â”€ Loss: 6.2354
2025-03-02 17:27:47,478 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:27:47,478 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:27:48,146 - INFO - ðŸªœ Batch step - 2832 -- sub batch step 11328 -- lr 3.00e-04
2025-03-02 17:27:50,303 - INFO - ðŸªœ Batch step - 2832 -- sub batch step 11329 -- lr 3.00e-04
2025-03-02 17:27:52,485 - INFO - ðŸªœ Batch step - 2832 -- sub batch step 11330 -- lr 3.00e-04
2025-03-02 17:27:54,635 - INFO - ðŸªœ Batch step - 2832 -- sub batch step 11331 -- lr 3.00e-04
2025-03-02 17:27:56,175 - INFO - Step 2832 -- ðŸ”„ Training Metrics
2025-03-02 17:27:56,175 - INFO - â”œâ”€â”€ Loss: 6.2538
2025-03-02 17:27:56,175 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:27:56,175 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:27:56,844 - INFO - ðŸªœ Batch step - 2833 -- sub batch step 11332 -- lr 3.00e-04
2025-03-02 17:27:58,989 - INFO - ðŸªœ Batch step - 2833 -- sub batch step 11333 -- lr 3.00e-04
2025-03-02 17:28:01,662 - INFO - ðŸªœ Batch step - 2833 -- sub batch step 11334 -- lr 3.00e-04
2025-03-02 17:28:03,819 - INFO - ðŸªœ Batch step - 2833 -- sub batch step 11335 -- lr 3.00e-04
2025-03-02 17:28:05,407 - INFO - Step 2833 -- ðŸ”„ Training Metrics
2025-03-02 17:28:05,407 - INFO - â”œâ”€â”€ Loss: 6.2307
2025-03-02 17:28:05,407 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:28:05,407 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:28:06,075 - INFO - ðŸªœ Batch step - 2834 -- sub batch step 11336 -- lr 3.00e-04
2025-03-02 17:28:08,234 - INFO - ðŸªœ Batch step - 2834 -- sub batch step 11337 -- lr 3.00e-04
2025-03-02 17:28:10,405 - INFO - ðŸªœ Batch step - 2834 -- sub batch step 11338 -- lr 3.00e-04
2025-03-02 17:28:12,561 - INFO - ðŸªœ Batch step - 2834 -- sub batch step 11339 -- lr 3.00e-04
2025-03-02 17:28:14,105 - INFO - Step 2834 -- ðŸ”„ Training Metrics
2025-03-02 17:28:14,105 - INFO - â”œâ”€â”€ Loss: 6.2347
2025-03-02 17:28:14,105 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:28:14,105 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:28:14,779 - INFO - ðŸªœ Batch step - 2835 -- sub batch step 11340 -- lr 3.00e-04
2025-03-02 17:28:16,931 - INFO - ðŸªœ Batch step - 2835 -- sub batch step 11341 -- lr 3.00e-04
2025-03-02 17:28:19,532 - INFO - ðŸªœ Batch step - 2835 -- sub batch step 11342 -- lr 3.00e-04
2025-03-02 17:28:21,684 - INFO - ðŸªœ Batch step - 2835 -- sub batch step 11343 -- lr 3.00e-04
2025-03-02 17:28:23,386 - INFO - Step 2835 -- ðŸ”„ Training Metrics
2025-03-02 17:28:23,387 - INFO - â”œâ”€â”€ Loss: 6.2431
2025-03-02 17:28:23,387 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:28:23,387 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:28:24,061 - INFO - ðŸªœ Batch step - 2836 -- sub batch step 11344 -- lr 3.00e-04
2025-03-02 17:28:26,212 - INFO - ðŸªœ Batch step - 2836 -- sub batch step 11345 -- lr 3.00e-04
2025-03-02 17:28:28,382 - INFO - ðŸªœ Batch step - 2836 -- sub batch step 11346 -- lr 3.00e-04
2025-03-02 17:28:30,536 - INFO - ðŸªœ Batch step - 2836 -- sub batch step 11347 -- lr 3.00e-04
2025-03-02 17:28:32,075 - INFO - Step 2836 -- ðŸ”„ Training Metrics
2025-03-02 17:28:32,075 - INFO - â”œâ”€â”€ Loss: 6.2274
2025-03-02 17:28:32,075 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:28:32,075 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:28:32,744 - INFO - ðŸªœ Batch step - 2837 -- sub batch step 11348 -- lr 3.00e-04
2025-03-02 17:28:34,901 - INFO - ðŸªœ Batch step - 2837 -- sub batch step 11349 -- lr 3.00e-04
2025-03-02 17:28:37,574 - INFO - ðŸªœ Batch step - 2837 -- sub batch step 11350 -- lr 3.00e-04
2025-03-02 17:28:39,725 - INFO - ðŸªœ Batch step - 2837 -- sub batch step 11351 -- lr 3.00e-04
2025-03-02 17:28:41,304 - INFO - Step 2837 -- ðŸ”„ Training Metrics
2025-03-02 17:28:41,305 - INFO - â”œâ”€â”€ Loss: 6.2177
2025-03-02 17:28:41,305 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:28:41,305 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:28:41,982 - INFO - ðŸªœ Batch step - 2838 -- sub batch step 11352 -- lr 3.00e-04
2025-03-02 17:28:44,137 - INFO - ðŸªœ Batch step - 2838 -- sub batch step 11353 -- lr 3.00e-04
2025-03-02 17:28:46,315 - INFO - ðŸªœ Batch step - 2838 -- sub batch step 11354 -- lr 3.00e-04
2025-03-02 17:28:48,472 - INFO - ðŸªœ Batch step - 2838 -- sub batch step 11355 -- lr 3.00e-04
2025-03-02 17:28:50,004 - INFO - Step 2838 -- ðŸ”„ Training Metrics
2025-03-02 17:28:50,005 - INFO - â”œâ”€â”€ Loss: 6.2380
2025-03-02 17:28:50,005 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:28:50,005 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:28:50,674 - INFO - ðŸªœ Batch step - 2839 -- sub batch step 11356 -- lr 3.00e-04
2025-03-02 17:28:52,835 - INFO - ðŸªœ Batch step - 2839 -- sub batch step 11357 -- lr 3.00e-04
2025-03-02 17:28:55,114 - INFO - ðŸªœ Batch step - 2839 -- sub batch step 11358 -- lr 3.00e-04
2025-03-02 17:28:57,269 - INFO - ðŸªœ Batch step - 2839 -- sub batch step 11359 -- lr 3.00e-04
2025-03-02 17:28:58,937 - INFO - Step 2839 -- ðŸ”„ Training Metrics
2025-03-02 17:28:58,937 - INFO - â”œâ”€â”€ Loss: 6.2398
2025-03-02 17:28:58,938 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:28:58,938 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:29:00,338 - INFO - ðŸªœ Batch step - 2840 -- sub batch step 11360 -- lr 3.00e-04
2025-03-02 17:29:02,495 - INFO - ðŸªœ Batch step - 2840 -- sub batch step 11361 -- lr 3.00e-04
2025-03-02 17:29:04,656 - INFO - ðŸªœ Batch step - 2840 -- sub batch step 11362 -- lr 3.00e-04
2025-03-02 17:29:06,830 - INFO - ðŸªœ Batch step - 2840 -- sub batch step 11363 -- lr 3.00e-04
2025-03-02 17:29:08,412 - INFO - Step 2840 -- ðŸ”„ Training Metrics
2025-03-02 17:29:08,412 - INFO - â”œâ”€â”€ Loss: 6.2424
2025-03-02 17:29:08,412 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:29:08,412 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:29:09,094 - INFO - ðŸªœ Batch step - 2841 -- sub batch step 11364 -- lr 3.00e-04
2025-03-02 17:29:11,257 - INFO - ðŸªœ Batch step - 2841 -- sub batch step 11365 -- lr 3.00e-04
2025-03-02 17:29:13,419 - INFO - ðŸªœ Batch step - 2841 -- sub batch step 11366 -- lr 3.00e-04
2025-03-02 17:29:18,470 - INFO - ðŸªœ Batch step - 2841 -- sub batch step 11367 -- lr 3.00e-04
2025-03-02 17:29:19,963 - INFO - Step 2841 -- ðŸ”„ Training Metrics
2025-03-02 17:29:19,963 - INFO - â”œâ”€â”€ Loss: 6.2338
2025-03-02 17:29:19,964 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:29:19,964 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:29:20,644 - INFO - ðŸªœ Batch step - 2842 -- sub batch step 11368 -- lr 3.00e-04
2025-03-02 17:29:22,801 - INFO - ðŸªœ Batch step - 2842 -- sub batch step 11369 -- lr 3.00e-04
2025-03-02 17:29:24,960 - INFO - ðŸªœ Batch step - 2842 -- sub batch step 11370 -- lr 3.00e-04
2025-03-02 17:29:27,143 - INFO - ðŸªœ Batch step - 2842 -- sub batch step 11371 -- lr 3.00e-04
2025-03-02 17:29:28,645 - INFO - Step 2842 -- ðŸ”„ Training Metrics
2025-03-02 17:29:28,645 - INFO - â”œâ”€â”€ Loss: 6.2517
2025-03-02 17:29:28,645 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:29:28,646 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:29:29,318 - INFO - ðŸªœ Batch step - 2843 -- sub batch step 11372 -- lr 3.00e-04
2025-03-02 17:29:31,477 - INFO - ðŸªœ Batch step - 2843 -- sub batch step 11373 -- lr 3.00e-04
2025-03-02 17:29:33,636 - INFO - ðŸªœ Batch step - 2843 -- sub batch step 11374 -- lr 3.00e-04
2025-03-02 17:29:36,260 - INFO - ðŸªœ Batch step - 2843 -- sub batch step 11375 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 41b40262-1305-422c-bc15-56ce8783a00a)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00142-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:29:48,715 - INFO - Step 2843 -- ðŸ”„ Training Metrics
2025-03-02 17:29:48,715 - INFO - â”œâ”€â”€ Loss: 6.2128
2025-03-02 17:29:48,715 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:29:48,715 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:29:49,382 - INFO - ðŸªœ Batch step - 2844 -- sub batch step 11376 -- lr 3.00e-04
2025-03-02 17:29:51,534 - INFO - ðŸªœ Batch step - 2844 -- sub batch step 11377 -- lr 3.00e-04
2025-03-02 17:29:53,680 - INFO - ðŸªœ Batch step - 2844 -- sub batch step 11378 -- lr 3.00e-04
2025-03-02 17:29:55,850 - INFO - ðŸªœ Batch step - 2844 -- sub batch step 11379 -- lr 3.00e-04
2025-03-02 17:29:57,951 - INFO - Step 2844 -- ðŸ”„ Training Metrics
2025-03-02 17:29:57,951 - INFO - â”œâ”€â”€ Loss: 6.2213
2025-03-02 17:29:57,951 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:29:57,951 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:29:58,624 - INFO - ðŸªœ Batch step - 2845 -- sub batch step 11380 -- lr 3.00e-04
2025-03-02 17:30:00,770 - INFO - ðŸªœ Batch step - 2845 -- sub batch step 11381 -- lr 3.00e-04
2025-03-02 17:30:02,923 - INFO - ðŸªœ Batch step - 2845 -- sub batch step 11382 -- lr 3.00e-04
2025-03-02 17:30:05,528 - INFO - ðŸªœ Batch step - 2845 -- sub batch step 11383 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: f1c2c1d9-977c-4f26-96e0-78c02c2546d0)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00142-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:30:17,987 - INFO - Step 2845 -- ðŸ”„ Training Metrics
2025-03-02 17:30:17,988 - INFO - â”œâ”€â”€ Loss: 6.2489
2025-03-02 17:30:17,988 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:30:17,988 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:30:18,658 - INFO - ðŸªœ Batch step - 2846 -- sub batch step 11384 -- lr 3.00e-04
2025-03-02 17:30:20,810 - INFO - ðŸªœ Batch step - 2846 -- sub batch step 11385 -- lr 3.00e-04
2025-03-02 17:30:22,955 - INFO - ðŸªœ Batch step - 2846 -- sub batch step 11386 -- lr 3.00e-04
2025-03-02 17:30:25,124 - INFO - ðŸªœ Batch step - 2846 -- sub batch step 11387 -- lr 3.00e-04
2025-03-02 17:30:26,682 - INFO - Step 2846 -- ðŸ”„ Training Metrics
2025-03-02 17:30:26,682 - INFO - â”œâ”€â”€ Loss: 6.2267
2025-03-02 17:30:26,682 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:30:26,682 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:30:27,348 - INFO - ðŸªœ Batch step - 2847 -- sub batch step 11388 -- lr 3.00e-04
2025-03-02 17:30:29,502 - INFO - ðŸªœ Batch step - 2847 -- sub batch step 11389 -- lr 3.00e-04
2025-03-02 17:30:31,654 - INFO - ðŸªœ Batch step - 2847 -- sub batch step 11390 -- lr 3.00e-04
2025-03-02 17:30:34,280 - INFO - ðŸªœ Batch step - 2847 -- sub batch step 11391 -- lr 3.00e-04
2025-03-02 17:30:35,967 - INFO - Step 2847 -- ðŸ”„ Training Metrics
2025-03-02 17:30:35,968 - INFO - â”œâ”€â”€ Loss: 6.2475
2025-03-02 17:30:35,968 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:30:35,968 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:30:36,641 - INFO - ðŸªœ Batch step - 2848 -- sub batch step 11392 -- lr 3.00e-04
2025-03-02 17:30:38,788 - INFO - ðŸªœ Batch step - 2848 -- sub batch step 11393 -- lr 3.00e-04
2025-03-02 17:30:40,943 - INFO - ðŸªœ Batch step - 2848 -- sub batch step 11394 -- lr 3.00e-04
2025-03-02 17:30:43,115 - INFO - ðŸªœ Batch step - 2848 -- sub batch step 11395 -- lr 3.00e-04
2025-03-02 17:30:44,650 - INFO - Step 2848 -- ðŸ”„ Training Metrics
2025-03-02 17:30:44,650 - INFO - â”œâ”€â”€ Loss: 6.2381
2025-03-02 17:30:44,650 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:30:44,650 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:30:45,316 - INFO - ðŸªœ Batch step - 2849 -- sub batch step 11396 -- lr 3.00e-04
2025-03-02 17:30:47,467 - INFO - ðŸªœ Batch step - 2849 -- sub batch step 11397 -- lr 3.00e-04
2025-03-02 17:30:49,612 - INFO - ðŸªœ Batch step - 2849 -- sub batch step 11398 -- lr 3.00e-04
2025-03-02 17:30:52,259 - INFO - ðŸªœ Batch step - 2849 -- sub batch step 11399 -- lr 3.00e-04
2025-03-02 17:30:53,971 - INFO - Step 2849 -- ðŸ”„ Training Metrics
2025-03-02 17:30:53,971 - INFO - â”œâ”€â”€ Loss: 6.1958
2025-03-02 17:30:53,971 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:30:53,971 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:30:54,649 - INFO - ðŸªœ Batch step - 2850 -- sub batch step 11400 -- lr 3.00e-04
2025-03-02 17:30:56,796 - INFO - ðŸªœ Batch step - 2850 -- sub batch step 11401 -- lr 3.00e-04
2025-03-02 17:30:58,952 - INFO - ðŸªœ Batch step - 2850 -- sub batch step 11402 -- lr 3.00e-04
2025-03-02 17:31:01,116 - INFO - ðŸªœ Batch step - 2850 -- sub batch step 11403 -- lr 3.00e-04
2025-03-02 17:31:02,653 - INFO - Step 2850 -- ðŸ”„ Training Metrics
2025-03-02 17:31:02,653 - INFO - â”œâ”€â”€ Loss: 6.2055
2025-03-02 17:31:02,653 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:31:02,653 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:31:03,331 - INFO - ðŸªœ Batch step - 2851 -- sub batch step 11404 -- lr 3.00e-04
2025-03-02 17:31:05,487 - INFO - ðŸªœ Batch step - 2851 -- sub batch step 11405 -- lr 3.00e-04
2025-03-02 17:31:08,281 - INFO - ðŸªœ Batch step - 2851 -- sub batch step 11406 -- lr 3.00e-04
2025-03-02 17:31:10,438 - INFO - ðŸªœ Batch step - 2851 -- sub batch step 11407 -- lr 3.00e-04
2025-03-02 17:31:11,930 - INFO - Step 2851 -- ðŸ”„ Training Metrics
2025-03-02 17:31:11,930 - INFO - â”œâ”€â”€ Loss: 6.2330
2025-03-02 17:31:11,931 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:31:11,931 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:31:12,603 - INFO - ðŸªœ Batch step - 2852 -- sub batch step 11408 -- lr 3.00e-04
2025-03-02 17:31:14,756 - INFO - ðŸªœ Batch step - 2852 -- sub batch step 11409 -- lr 3.00e-04
2025-03-02 17:31:16,929 - INFO - ðŸªœ Batch step - 2852 -- sub batch step 11410 -- lr 3.00e-04
2025-03-02 17:31:19,078 - INFO - ðŸªœ Batch step - 2852 -- sub batch step 11411 -- lr 3.00e-04
2025-03-02 17:31:20,617 - INFO - Step 2852 -- ðŸ”„ Training Metrics
2025-03-02 17:31:20,618 - INFO - â”œâ”€â”€ Loss: 6.2098
2025-03-02 17:31:20,618 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:31:20,618 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:31:21,295 - INFO - ðŸªœ Batch step - 2853 -- sub batch step 11412 -- lr 3.00e-04
2025-03-02 17:31:23,449 - INFO - ðŸªœ Batch step - 2853 -- sub batch step 11413 -- lr 3.00e-04
2025-03-02 17:31:25,860 - INFO - ðŸªœ Batch step - 2853 -- sub batch step 11414 -- lr 3.00e-04
2025-03-02 17:31:28,019 - INFO - ðŸªœ Batch step - 2853 -- sub batch step 11415 -- lr 3.00e-04
2025-03-02 17:31:29,960 - INFO - Step 2853 -- ðŸ”„ Training Metrics
2025-03-02 17:31:29,960 - INFO - â”œâ”€â”€ Loss: 6.2065
2025-03-02 17:31:29,961 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:31:29,961 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:31:30,631 - INFO - ðŸªœ Batch step - 2854 -- sub batch step 11416 -- lr 3.00e-04
2025-03-02 17:31:32,787 - INFO - ðŸªœ Batch step - 2854 -- sub batch step 11417 -- lr 3.00e-04
2025-03-02 17:31:34,954 - INFO - ðŸªœ Batch step - 2854 -- sub batch step 11418 -- lr 3.00e-04
2025-03-02 17:31:37,114 - INFO - ðŸªœ Batch step - 2854 -- sub batch step 11419 -- lr 3.00e-04
2025-03-02 17:31:38,654 - INFO - Step 2854 -- ðŸ”„ Training Metrics
2025-03-02 17:31:38,654 - INFO - â”œâ”€â”€ Loss: 6.2430
2025-03-02 17:31:38,654 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:31:38,654 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:31:39,339 - INFO - ðŸªœ Batch step - 2855 -- sub batch step 11420 -- lr 3.00e-04
2025-03-02 17:31:41,489 - INFO - ðŸªœ Batch step - 2855 -- sub batch step 11421 -- lr 3.00e-04
2025-03-02 17:31:44,299 - INFO - ðŸªœ Batch step - 2855 -- sub batch step 11422 -- lr 3.00e-04
2025-03-02 17:31:46,452 - INFO - ðŸªœ Batch step - 2855 -- sub batch step 11423 -- lr 3.00e-04
2025-03-02 17:31:48,020 - INFO - Step 2855 -- ðŸ”„ Training Metrics
2025-03-02 17:31:48,021 - INFO - â”œâ”€â”€ Loss: 6.2149
2025-03-02 17:31:48,021 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:31:48,021 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:31:48,697 - INFO - ðŸªœ Batch step - 2856 -- sub batch step 11424 -- lr 3.00e-04
2025-03-02 17:31:50,854 - INFO - ðŸªœ Batch step - 2856 -- sub batch step 11425 -- lr 3.00e-04
2025-03-02 17:31:53,025 - INFO - ðŸªœ Batch step - 2856 -- sub batch step 11426 -- lr 3.00e-04
2025-03-02 17:31:55,185 - INFO - ðŸªœ Batch step - 2856 -- sub batch step 11427 -- lr 3.00e-04
2025-03-02 17:31:56,711 - INFO - Step 2856 -- ðŸ”„ Training Metrics
2025-03-02 17:31:56,711 - INFO - â”œâ”€â”€ Loss: 6.2107
2025-03-02 17:31:56,711 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:31:56,711 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:31:57,384 - INFO - ðŸªœ Batch step - 2857 -- sub batch step 11428 -- lr 3.00e-04
2025-03-02 17:31:59,538 - INFO - ðŸªœ Batch step - 2857 -- sub batch step 11429 -- lr 3.00e-04
2025-03-02 17:32:02,154 - INFO - ðŸªœ Batch step - 2857 -- sub batch step 11430 -- lr 3.00e-04
2025-03-02 17:32:04,307 - INFO - ðŸªœ Batch step - 2857 -- sub batch step 11431 -- lr 3.00e-04
2025-03-02 17:32:05,987 - INFO - Step 2857 -- ðŸ”„ Training Metrics
2025-03-02 17:32:05,987 - INFO - â”œâ”€â”€ Loss: 6.2365
2025-03-02 17:32:05,987 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:32:05,987 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:32:06,667 - INFO - ðŸªœ Batch step - 2858 -- sub batch step 11432 -- lr 3.00e-04
2025-03-02 17:32:08,818 - INFO - ðŸªœ Batch step - 2858 -- sub batch step 11433 -- lr 3.00e-04
2025-03-02 17:32:10,990 - INFO - ðŸªœ Batch step - 2858 -- sub batch step 11434 -- lr 3.00e-04
2025-03-02 17:32:13,150 - INFO - ðŸªœ Batch step - 2858 -- sub batch step 11435 -- lr 3.00e-04
2025-03-02 17:32:14,684 - INFO - Step 2858 -- ðŸ”„ Training Metrics
2025-03-02 17:32:14,684 - INFO - â”œâ”€â”€ Loss: 6.2323
2025-03-02 17:32:14,684 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:32:14,684 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:32:15,351 - INFO - ðŸªœ Batch step - 2859 -- sub batch step 11436 -- lr 3.00e-04
2025-03-02 17:32:17,508 - INFO - ðŸªœ Batch step - 2859 -- sub batch step 11437 -- lr 3.00e-04
2025-03-02 17:32:19,783 - INFO - ðŸªœ Batch step - 2859 -- sub batch step 11438 -- lr 3.00e-04
2025-03-02 17:32:21,939 - INFO - ðŸªœ Batch step - 2859 -- sub batch step 11439 -- lr 3.00e-04
2025-03-02 17:32:23,507 - INFO - Step 2859 -- ðŸ”„ Training Metrics
2025-03-02 17:32:23,507 - INFO - â”œâ”€â”€ Loss: 6.2239
2025-03-02 17:32:23,507 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:32:23,507 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:32:24,754 - INFO - ðŸªœ Batch step - 2860 -- sub batch step 11440 -- lr 3.00e-04
2025-03-02 17:32:26,907 - INFO - ðŸªœ Batch step - 2860 -- sub batch step 11441 -- lr 3.00e-04
2025-03-02 17:32:29,071 - INFO - ðŸªœ Batch step - 2860 -- sub batch step 11442 -- lr 3.00e-04
2025-03-02 17:32:31,248 - INFO - ðŸªœ Batch step - 2860 -- sub batch step 11443 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: cc7fd909-a6a7-44b9-8981-d8e86d06330c)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00143-of-10000.parquet
Retrying in 1s [Retry 1/5].
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: f7114275-c33b-45dd-9a1e-09c1e2bb71e8)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00143-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:32:43,684 - INFO - Step 2860 -- ðŸ”„ Training Metrics
2025-03-02 17:32:43,684 - INFO - â”œâ”€â”€ Loss: 6.2225
2025-03-02 17:32:43,684 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:32:43,685 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:32:44,368 - INFO - ðŸªœ Batch step - 2861 -- sub batch step 11444 -- lr 3.00e-04
2025-03-02 17:32:46,527 - INFO - ðŸªœ Batch step - 2861 -- sub batch step 11445 -- lr 3.00e-04
2025-03-02 17:32:48,678 - INFO - ðŸªœ Batch step - 2861 -- sub batch step 11446 -- lr 3.00e-04
2025-03-02 17:32:51,371 - INFO - ðŸªœ Batch step - 2861 -- sub batch step 11447 -- lr 3.00e-04
2025-03-02 17:32:52,916 - INFO - Step 2861 -- ðŸ”„ Training Metrics
2025-03-02 17:32:52,916 - INFO - â”œâ”€â”€ Loss: 6.2056
2025-03-02 17:32:52,916 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:32:52,916 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:32:53,589 - INFO - ðŸªœ Batch step - 2862 -- sub batch step 11448 -- lr 3.00e-04
2025-03-02 17:32:55,753 - INFO - ðŸªœ Batch step - 2862 -- sub batch step 11449 -- lr 3.00e-04
2025-03-02 17:32:57,904 - INFO - ðŸªœ Batch step - 2862 -- sub batch step 11450 -- lr 3.00e-04
2025-03-02 17:33:00,075 - INFO - ðŸªœ Batch step - 2862 -- sub batch step 11451 -- lr 3.00e-04
2025-03-02 17:33:01,606 - INFO - Step 2862 -- ðŸ”„ Training Metrics
2025-03-02 17:33:01,606 - INFO - â”œâ”€â”€ Loss: 6.2373
2025-03-02 17:33:01,606 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:33:01,606 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:33:02,279 - INFO - ðŸªœ Batch step - 2863 -- sub batch step 11452 -- lr 3.00e-04
2025-03-02 17:33:04,431 - INFO - ðŸªœ Batch step - 2863 -- sub batch step 11453 -- lr 3.00e-04
2025-03-02 17:33:06,590 - INFO - ðŸªœ Batch step - 2863 -- sub batch step 11454 -- lr 3.00e-04
2025-03-02 17:33:09,206 - INFO - ðŸªœ Batch step - 2863 -- sub batch step 11455 -- lr 3.00e-04
2025-03-02 17:33:10,797 - INFO - Step 2863 -- ðŸ”„ Training Metrics
2025-03-02 17:33:10,797 - INFO - â”œâ”€â”€ Loss: 6.2192
2025-03-02 17:33:10,797 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:33:10,797 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:33:11,465 - INFO - ðŸªœ Batch step - 2864 -- sub batch step 11456 -- lr 3.00e-04
2025-03-02 17:33:13,624 - INFO - ðŸªœ Batch step - 2864 -- sub batch step 11457 -- lr 3.00e-04
2025-03-02 17:33:15,776 - INFO - ðŸªœ Batch step - 2864 -- sub batch step 11458 -- lr 3.00e-04
2025-03-02 17:33:17,956 - INFO - ðŸªœ Batch step - 2864 -- sub batch step 11459 -- lr 3.00e-04
2025-03-02 17:33:19,486 - INFO - Step 2864 -- ðŸ”„ Training Metrics
2025-03-02 17:33:19,487 - INFO - â”œâ”€â”€ Loss: 6.1896
2025-03-02 17:33:19,487 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:33:19,487 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:33:20,160 - INFO - ðŸªœ Batch step - 2865 -- sub batch step 11460 -- lr 3.00e-04
2025-03-02 17:33:22,315 - INFO - ðŸªœ Batch step - 2865 -- sub batch step 11461 -- lr 3.00e-04
2025-03-02 17:33:24,470 - INFO - ðŸªœ Batch step - 2865 -- sub batch step 11462 -- lr 3.00e-04
2025-03-02 17:33:27,102 - INFO - ðŸªœ Batch step - 2865 -- sub batch step 11463 -- lr 3.00e-04
2025-03-02 17:33:28,678 - INFO - Step 2865 -- ðŸ”„ Training Metrics
2025-03-02 17:33:28,679 - INFO - â”œâ”€â”€ Loss: 6.1936
2025-03-02 17:33:28,679 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:33:28,679 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:33:29,357 - INFO - ðŸªœ Batch step - 2866 -- sub batch step 11464 -- lr 3.00e-04
2025-03-02 17:33:31,513 - INFO - ðŸªœ Batch step - 2866 -- sub batch step 11465 -- lr 3.00e-04
2025-03-02 17:33:33,666 - INFO - ðŸªœ Batch step - 2866 -- sub batch step 11466 -- lr 3.00e-04
2025-03-02 17:33:35,851 - INFO - ðŸªœ Batch step - 2866 -- sub batch step 11467 -- lr 3.00e-04
2025-03-02 17:33:37,369 - INFO - Step 2866 -- ðŸ”„ Training Metrics
2025-03-02 17:33:37,370 - INFO - â”œâ”€â”€ Loss: 6.2045
2025-03-02 17:33:37,370 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:33:37,370 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:33:38,040 - INFO - ðŸªœ Batch step - 2867 -- sub batch step 11468 -- lr 3.00e-04
2025-03-02 17:33:40,202 - INFO - ðŸªœ Batch step - 2867 -- sub batch step 11469 -- lr 3.00e-04
2025-03-02 17:33:42,362 - INFO - ðŸªœ Batch step - 2867 -- sub batch step 11470 -- lr 3.00e-04
2025-03-02 17:33:44,961 - INFO - ðŸªœ Batch step - 2867 -- sub batch step 11471 -- lr 3.00e-04
2025-03-02 17:33:46,604 - INFO - Step 2867 -- ðŸ”„ Training Metrics
2025-03-02 17:33:46,604 - INFO - â”œâ”€â”€ Loss: 6.2078
2025-03-02 17:33:46,605 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:33:46,605 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:33:47,286 - INFO - ðŸªœ Batch step - 2868 -- sub batch step 11472 -- lr 3.00e-04
2025-03-02 17:33:49,438 - INFO - ðŸªœ Batch step - 2868 -- sub batch step 11473 -- lr 3.00e-04
2025-03-02 17:33:51,601 - INFO - ðŸªœ Batch step - 2868 -- sub batch step 11474 -- lr 3.00e-04
2025-03-02 17:33:53,785 - INFO - ðŸªœ Batch step - 2868 -- sub batch step 11475 -- lr 3.00e-04
2025-03-02 17:33:55,311 - INFO - Step 2868 -- ðŸ”„ Training Metrics
2025-03-02 17:33:55,311 - INFO - â”œâ”€â”€ Loss: 6.2183
2025-03-02 17:33:55,311 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:33:55,311 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:33:55,986 - INFO - ðŸªœ Batch step - 2869 -- sub batch step 11476 -- lr 3.00e-04
2025-03-02 17:33:58,149 - INFO - ðŸªœ Batch step - 2869 -- sub batch step 11477 -- lr 3.00e-04
2025-03-02 17:34:00,309 - INFO - ðŸªœ Batch step - 2869 -- sub batch step 11478 -- lr 3.00e-04
2025-03-02 17:34:03,111 - INFO - ðŸªœ Batch step - 2869 -- sub batch step 11479 -- lr 3.00e-04
2025-03-02 17:34:04,603 - INFO - Step 2869 -- ðŸ”„ Training Metrics
2025-03-02 17:34:04,603 - INFO - â”œâ”€â”€ Loss: 6.2186
2025-03-02 17:34:04,603 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:34:04,603 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:34:05,284 - INFO - ðŸªœ Batch step - 2870 -- sub batch step 11480 -- lr 3.00e-04
2025-03-02 17:34:07,435 - INFO - ðŸªœ Batch step - 2870 -- sub batch step 11481 -- lr 3.00e-04
2025-03-02 17:34:09,589 - INFO - ðŸªœ Batch step - 2870 -- sub batch step 11482 -- lr 3.00e-04
2025-03-02 17:34:11,749 - INFO - ðŸªœ Batch step - 2870 -- sub batch step 11483 -- lr 3.00e-04
2025-03-02 17:34:13,300 - INFO - Step 2870 -- ðŸ”„ Training Metrics
2025-03-02 17:34:13,300 - INFO - â”œâ”€â”€ Loss: 6.2066
2025-03-02 17:34:13,300 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:34:13,300 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:34:13,973 - INFO - ðŸªœ Batch step - 2871 -- sub batch step 11484 -- lr 3.00e-04
2025-03-02 17:34:16,137 - INFO - ðŸªœ Batch step - 2871 -- sub batch step 11485 -- lr 3.00e-04
2025-03-02 17:34:18,932 - INFO - ðŸªœ Batch step - 2871 -- sub batch step 11486 -- lr 3.00e-04
2025-03-02 17:34:21,091 - INFO - ðŸªœ Batch step - 2871 -- sub batch step 11487 -- lr 3.00e-04
2025-03-02 17:34:22,586 - INFO - Step 2871 -- ðŸ”„ Training Metrics
2025-03-02 17:34:22,586 - INFO - â”œâ”€â”€ Loss: 6.1998
2025-03-02 17:34:22,586 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:34:22,586 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:34:23,257 - INFO - ðŸªœ Batch step - 2872 -- sub batch step 11488 -- lr 3.00e-04
2025-03-02 17:34:25,406 - INFO - ðŸªœ Batch step - 2872 -- sub batch step 11489 -- lr 3.00e-04
2025-03-02 17:34:27,577 - INFO - ðŸªœ Batch step - 2872 -- sub batch step 11490 -- lr 3.00e-04
2025-03-02 17:34:29,726 - INFO - ðŸªœ Batch step - 2872 -- sub batch step 11491 -- lr 3.00e-04
2025-03-02 17:34:31,269 - INFO - Step 2872 -- ðŸ”„ Training Metrics
2025-03-02 17:34:31,269 - INFO - â”œâ”€â”€ Loss: 6.2042
2025-03-02 17:34:31,269 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:34:31,270 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:34:31,942 - INFO - ðŸªœ Batch step - 2873 -- sub batch step 11492 -- lr 3.00e-04
2025-03-02 17:34:34,089 - INFO - ðŸªœ Batch step - 2873 -- sub batch step 11493 -- lr 3.00e-04
2025-03-02 17:34:36,454 - INFO - ðŸªœ Batch step - 2873 -- sub batch step 11494 -- lr 3.00e-04
2025-03-02 17:34:38,607 - INFO - ðŸªœ Batch step - 2873 -- sub batch step 11495 -- lr 3.00e-04
2025-03-02 17:34:40,555 - INFO - Step 2873 -- ðŸ”„ Training Metrics
2025-03-02 17:34:40,555 - INFO - â”œâ”€â”€ Loss: 6.2409
2025-03-02 17:34:40,555 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:34:40,555 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:34:41,223 - INFO - ðŸªœ Batch step - 2874 -- sub batch step 11496 -- lr 3.00e-04
2025-03-02 17:34:43,375 - INFO - ðŸªœ Batch step - 2874 -- sub batch step 11497 -- lr 3.00e-04
2025-03-02 17:34:45,541 - INFO - ðŸªœ Batch step - 2874 -- sub batch step 11498 -- lr 3.00e-04
2025-03-02 17:34:47,698 - INFO - ðŸªœ Batch step - 2874 -- sub batch step 11499 -- lr 3.00e-04
2025-03-02 17:34:49,247 - INFO - Step 2874 -- ðŸ”„ Training Metrics
2025-03-02 17:34:49,248 - INFO - â”œâ”€â”€ Loss: 6.2117
2025-03-02 17:34:49,248 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:34:49,248 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:34:49,926 - INFO - ðŸªœ Batch step - 2875 -- sub batch step 11500 -- lr 3.00e-04
2025-03-02 17:34:52,079 - INFO - ðŸªœ Batch step - 2875 -- sub batch step 11501 -- lr 3.00e-04
2025-03-02 17:34:54,895 - INFO - ðŸªœ Batch step - 2875 -- sub batch step 11502 -- lr 3.00e-04
2025-03-02 17:34:57,048 - INFO - ðŸªœ Batch step - 2875 -- sub batch step 11503 -- lr 3.00e-04
2025-03-02 17:35:01,467 - INFO - Step 2875 -- ðŸ”„ Training Metrics
2025-03-02 17:35:01,467 - INFO - â”œâ”€â”€ Loss: 6.2153
2025-03-02 17:35:01,467 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:35:01,468 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:35:02,140 - INFO - ðŸªœ Batch step - 2876 -- sub batch step 11504 -- lr 3.00e-04
2025-03-02 17:35:04,295 - INFO - ðŸªœ Batch step - 2876 -- sub batch step 11505 -- lr 3.00e-04
2025-03-02 17:35:06,460 - INFO - ðŸªœ Batch step - 2876 -- sub batch step 11506 -- lr 3.00e-04
2025-03-02 17:35:08,613 - INFO - ðŸªœ Batch step - 2876 -- sub batch step 11507 -- lr 3.00e-04
2025-03-02 17:35:10,161 - INFO - Step 2876 -- ðŸ”„ Training Metrics
2025-03-02 17:35:10,161 - INFO - â”œâ”€â”€ Loss: 6.2133
2025-03-02 17:35:10,161 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:35:10,161 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:35:10,829 - INFO - ðŸªœ Batch step - 2877 -- sub batch step 11508 -- lr 3.00e-04
2025-03-02 17:35:12,982 - INFO - ðŸªœ Batch step - 2877 -- sub batch step 11509 -- lr 3.00e-04
2025-03-02 17:35:15,340 - INFO - ðŸªœ Batch step - 2877 -- sub batch step 11510 -- lr 3.00e-04
2025-03-02 17:35:17,488 - INFO - ðŸªœ Batch step - 2877 -- sub batch step 11511 -- lr 3.00e-04
2025-03-02 17:35:19,502 - INFO - Step 2877 -- ðŸ”„ Training Metrics
2025-03-02 17:35:19,502 - INFO - â”œâ”€â”€ Loss: 6.2179
2025-03-02 17:35:19,502 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:35:19,502 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:35:20,175 - INFO - ðŸªœ Batch step - 2878 -- sub batch step 11512 -- lr 3.00e-04
2025-03-02 17:35:22,319 - INFO - ðŸªœ Batch step - 2878 -- sub batch step 11513 -- lr 3.00e-04
2025-03-02 17:35:24,490 - INFO - ðŸªœ Batch step - 2878 -- sub batch step 11514 -- lr 3.00e-04
2025-03-02 17:35:26,644 - INFO - ðŸªœ Batch step - 2878 -- sub batch step 11515 -- lr 3.00e-04
2025-03-02 17:35:28,197 - INFO - Step 2878 -- ðŸ”„ Training Metrics
2025-03-02 17:35:28,197 - INFO - â”œâ”€â”€ Loss: 6.2217
2025-03-02 17:35:28,197 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:35:28,197 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:35:28,866 - INFO - ðŸªœ Batch step - 2879 -- sub batch step 11516 -- lr 3.00e-04
2025-03-02 17:35:31,020 - INFO - ðŸªœ Batch step - 2879 -- sub batch step 11517 -- lr 3.00e-04
2025-03-02 17:35:33,289 - INFO - ðŸªœ Batch step - 2879 -- sub batch step 11518 -- lr 3.00e-04
2025-03-02 17:35:35,442 - INFO - ðŸªœ Batch step - 2879 -- sub batch step 11519 -- lr 3.00e-04
2025-03-02 17:35:37,135 - INFO - Step 2879 -- ðŸ”„ Training Metrics
2025-03-02 17:35:37,135 - INFO - â”œâ”€â”€ Loss: 6.2281
2025-03-02 17:35:37,135 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:35:37,135 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:35:38,152 - INFO - ðŸªœ Batch step - 2880 -- sub batch step 11520 -- lr 3.00e-04
2025-03-02 17:35:40,317 - INFO - ðŸªœ Batch step - 2880 -- sub batch step 11521 -- lr 3.00e-04
2025-03-02 17:35:42,484 - INFO - ðŸªœ Batch step - 2880 -- sub batch step 11522 -- lr 3.00e-04
2025-03-02 17:35:44,670 - INFO - ðŸªœ Batch step - 2880 -- sub batch step 11523 -- lr 3.00e-04
2025-03-02 17:35:46,507 - INFO - Step 2880 -- ðŸ”„ Training Metrics
2025-03-02 17:35:46,508 - INFO - â”œâ”€â”€ Loss: 6.2151
2025-03-02 17:35:46,508 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:35:46,508 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:35:47,190 - INFO - ðŸªœ Batch step - 2881 -- sub batch step 11524 -- lr 3.00e-04
2025-03-02 17:35:49,356 - INFO - ðŸªœ Batch step - 2881 -- sub batch step 11525 -- lr 3.00e-04
2025-03-02 17:35:51,515 - INFO - ðŸªœ Batch step - 2881 -- sub batch step 11526 -- lr 3.00e-04
2025-03-02 17:35:54,091 - INFO - ðŸªœ Batch step - 2881 -- sub batch step 11527 -- lr 3.00e-04
2025-03-02 17:35:55,658 - INFO - Step 2881 -- ðŸ”„ Training Metrics
2025-03-02 17:35:55,658 - INFO - â”œâ”€â”€ Loss: 6.2333
2025-03-02 17:35:55,658 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:35:55,658 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:35:56,332 - INFO - ðŸªœ Batch step - 2882 -- sub batch step 11528 -- lr 3.00e-04
2025-03-02 17:35:58,498 - INFO - ðŸªœ Batch step - 2882 -- sub batch step 11529 -- lr 3.00e-04
2025-03-02 17:36:00,662 - INFO - ðŸªœ Batch step - 2882 -- sub batch step 11530 -- lr 3.00e-04
2025-03-02 17:36:02,843 - INFO - ðŸªœ Batch step - 2882 -- sub batch step 11531 -- lr 3.00e-04
2025-03-02 17:36:04,388 - INFO - Step 2882 -- ðŸ”„ Training Metrics
2025-03-02 17:36:04,388 - INFO - â”œâ”€â”€ Loss: 6.2173
2025-03-02 17:36:04,388 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:36:04,388 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:36:05,069 - INFO - ðŸªœ Batch step - 2883 -- sub batch step 11532 -- lr 3.00e-04
2025-03-02 17:36:07,222 - INFO - ðŸªœ Batch step - 2883 -- sub batch step 11533 -- lr 3.00e-04
2025-03-02 17:36:09,384 - INFO - ðŸªœ Batch step - 2883 -- sub batch step 11534 -- lr 3.00e-04
2025-03-02 17:36:11,757 - INFO - ðŸªœ Batch step - 2883 -- sub batch step 11535 -- lr 3.00e-04
2025-03-02 17:36:13,546 - INFO - Step 2883 -- ðŸ”„ Training Metrics
2025-03-02 17:36:13,546 - INFO - â”œâ”€â”€ Loss: 6.2153
2025-03-02 17:36:13,547 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:36:13,547 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:36:14,213 - INFO - ðŸªœ Batch step - 2884 -- sub batch step 11536 -- lr 3.00e-04
2025-03-02 17:36:16,372 - INFO - ðŸªœ Batch step - 2884 -- sub batch step 11537 -- lr 3.00e-04
2025-03-02 17:36:18,522 - INFO - ðŸªœ Batch step - 2884 -- sub batch step 11538 -- lr 3.00e-04
2025-03-02 17:36:20,702 - INFO - ðŸªœ Batch step - 2884 -- sub batch step 11539 -- lr 3.00e-04
2025-03-02 17:36:22,254 - INFO - Step 2884 -- ðŸ”„ Training Metrics
2025-03-02 17:36:22,254 - INFO - â”œâ”€â”€ Loss: 6.2146
2025-03-02 17:36:22,254 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:36:22,254 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:36:22,930 - INFO - ðŸªœ Batch step - 2885 -- sub batch step 11540 -- lr 3.00e-04
2025-03-02 17:36:25,082 - INFO - ðŸªœ Batch step - 2885 -- sub batch step 11541 -- lr 3.00e-04
2025-03-02 17:36:27,240 - INFO - ðŸªœ Batch step - 2885 -- sub batch step 11542 -- lr 3.00e-04
2025-03-02 17:36:29,882 - INFO - ðŸªœ Batch step - 2885 -- sub batch step 11543 -- lr 3.00e-04
2025-03-02 17:36:31,493 - INFO - Step 2885 -- ðŸ”„ Training Metrics
2025-03-02 17:36:31,493 - INFO - â”œâ”€â”€ Loss: 6.2178
2025-03-02 17:36:31,493 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:36:31,493 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:36:32,169 - INFO - ðŸªœ Batch step - 2886 -- sub batch step 11544 -- lr 3.00e-04
2025-03-02 17:36:34,326 - INFO - ðŸªœ Batch step - 2886 -- sub batch step 11545 -- lr 3.00e-04
2025-03-02 17:36:36,472 - INFO - ðŸªœ Batch step - 2886 -- sub batch step 11546 -- lr 3.00e-04
2025-03-02 17:36:38,645 - INFO - ðŸªœ Batch step - 2886 -- sub batch step 11547 -- lr 3.00e-04
2025-03-02 17:36:40,185 - INFO - Step 2886 -- ðŸ”„ Training Metrics
2025-03-02 17:36:40,185 - INFO - â”œâ”€â”€ Loss: 6.2056
2025-03-02 17:36:40,185 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:36:40,185 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:36:40,853 - INFO - ðŸªœ Batch step - 2887 -- sub batch step 11548 -- lr 3.00e-04
2025-03-02 17:36:43,013 - INFO - ðŸªœ Batch step - 2887 -- sub batch step 11549 -- lr 3.00e-04
2025-03-02 17:36:45,171 - INFO - ðŸªœ Batch step - 2887 -- sub batch step 11550 -- lr 3.00e-04
2025-03-02 17:36:47,809 - INFO - ðŸªœ Batch step - 2887 -- sub batch step 11551 -- lr 3.00e-04
2025-03-02 17:36:55,353 - INFO - Step 2887 -- ðŸ”„ Training Metrics
2025-03-02 17:36:55,354 - INFO - â”œâ”€â”€ Loss: 6.2137
2025-03-02 17:36:55,354 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:36:55,354 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:36:56,024 - INFO - ðŸªœ Batch step - 2888 -- sub batch step 11552 -- lr 3.00e-04
2025-03-02 17:36:58,174 - INFO - ðŸªœ Batch step - 2888 -- sub batch step 11553 -- lr 3.00e-04
2025-03-02 17:37:00,330 - INFO - ðŸªœ Batch step - 2888 -- sub batch step 11554 -- lr 3.00e-04
2025-03-02 17:37:02,504 - INFO - ðŸªœ Batch step - 2888 -- sub batch step 11555 -- lr 3.00e-04
2025-03-02 17:37:04,042 - INFO - Step 2888 -- ðŸ”„ Training Metrics
2025-03-02 17:37:04,043 - INFO - â”œâ”€â”€ Loss: 6.2341
2025-03-02 17:37:04,043 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:37:04,043 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:37:04,711 - INFO - ðŸªœ Batch step - 2889 -- sub batch step 11556 -- lr 3.00e-04
2025-03-02 17:37:06,868 - INFO - ðŸªœ Batch step - 2889 -- sub batch step 11557 -- lr 3.00e-04
2025-03-02 17:37:09,012 - INFO - ðŸªœ Batch step - 2889 -- sub batch step 11558 -- lr 3.00e-04
2025-03-02 17:37:11,607 - INFO - ðŸªœ Batch step - 2889 -- sub batch step 11559 -- lr 3.00e-04
2025-03-02 17:37:13,374 - INFO - Step 2889 -- ðŸ”„ Training Metrics
2025-03-02 17:37:13,375 - INFO - â”œâ”€â”€ Loss: 6.1893
2025-03-02 17:37:13,375 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:37:13,375 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:37:14,046 - INFO - ðŸªœ Batch step - 2890 -- sub batch step 11560 -- lr 3.00e-04
2025-03-02 17:37:16,196 - INFO - ðŸªœ Batch step - 2890 -- sub batch step 11561 -- lr 3.00e-04
2025-03-02 17:37:18,356 - INFO - ðŸªœ Batch step - 2890 -- sub batch step 11562 -- lr 3.00e-04
2025-03-02 17:37:20,519 - INFO - ðŸªœ Batch step - 2890 -- sub batch step 11563 -- lr 3.00e-04
2025-03-02 17:37:22,050 - INFO - Step 2890 -- ðŸ”„ Training Metrics
2025-03-02 17:37:22,050 - INFO - â”œâ”€â”€ Loss: 6.2188
2025-03-02 17:37:22,050 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:37:22,050 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:37:22,722 - INFO - ðŸªœ Batch step - 2891 -- sub batch step 11564 -- lr 3.00e-04
2025-03-02 17:37:24,879 - INFO - ðŸªœ Batch step - 2891 -- sub batch step 11565 -- lr 3.00e-04
2025-03-02 17:37:27,498 - INFO - ðŸªœ Batch step - 2891 -- sub batch step 11566 -- lr 3.00e-04
2025-03-02 17:37:29,652 - INFO - ðŸªœ Batch step - 2891 -- sub batch step 11567 -- lr 3.00e-04
2025-03-02 17:37:31,546 - INFO - Step 2891 -- ðŸ”„ Training Metrics
2025-03-02 17:37:31,546 - INFO - â”œâ”€â”€ Loss: 6.1986
2025-03-02 17:37:31,546 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:37:31,546 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:37:32,213 - INFO - ðŸªœ Batch step - 2892 -- sub batch step 11568 -- lr 3.00e-04
2025-03-02 17:37:34,369 - INFO - ðŸªœ Batch step - 2892 -- sub batch step 11569 -- lr 3.00e-04
2025-03-02 17:37:36,548 - INFO - ðŸªœ Batch step - 2892 -- sub batch step 11570 -- lr 3.00e-04
2025-03-02 17:37:38,700 - INFO - ðŸªœ Batch step - 2892 -- sub batch step 11571 -- lr 3.00e-04
2025-03-02 17:37:40,261 - INFO - Step 2892 -- ðŸ”„ Training Metrics
2025-03-02 17:37:40,261 - INFO - â”œâ”€â”€ Loss: 6.2128
2025-03-02 17:37:40,261 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:37:40,262 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:37:40,937 - INFO - ðŸªœ Batch step - 2893 -- sub batch step 11572 -- lr 3.00e-04
2025-03-02 17:37:43,089 - INFO - ðŸªœ Batch step - 2893 -- sub batch step 11573 -- lr 3.00e-04
2025-03-02 17:37:45,467 - INFO - ðŸªœ Batch step - 2893 -- sub batch step 11574 -- lr 3.00e-04
2025-03-02 17:37:47,619 - INFO - ðŸªœ Batch step - 2893 -- sub batch step 11575 -- lr 3.00e-04
2025-03-02 17:37:49,519 - INFO - Step 2893 -- ðŸ”„ Training Metrics
2025-03-02 17:37:49,520 - INFO - â”œâ”€â”€ Loss: 6.2209
2025-03-02 17:37:49,520 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:37:49,520 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:37:50,189 - INFO - ðŸªœ Batch step - 2894 -- sub batch step 11576 -- lr 3.00e-04
2025-03-02 17:37:52,346 - INFO - ðŸªœ Batch step - 2894 -- sub batch step 11577 -- lr 3.00e-04
2025-03-02 17:37:54,518 - INFO - ðŸªœ Batch step - 2894 -- sub batch step 11578 -- lr 3.00e-04
2025-03-02 17:37:56,678 - INFO - ðŸªœ Batch step - 2894 -- sub batch step 11579 -- lr 3.00e-04
2025-03-02 17:37:58,211 - INFO - Step 2894 -- ðŸ”„ Training Metrics
2025-03-02 17:37:58,211 - INFO - â”œâ”€â”€ Loss: 6.1919
2025-03-02 17:37:58,211 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:37:58,211 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:37:58,886 - INFO - ðŸªœ Batch step - 2895 -- sub batch step 11580 -- lr 3.00e-04
2025-03-02 17:38:01,041 - INFO - ðŸªœ Batch step - 2895 -- sub batch step 11581 -- lr 3.00e-04
2025-03-02 17:38:03,684 - INFO - ðŸªœ Batch step - 2895 -- sub batch step 11582 -- lr 3.00e-04
2025-03-02 17:38:05,832 - INFO - ðŸªœ Batch step - 2895 -- sub batch step 11583 -- lr 3.00e-04
2025-03-02 17:38:07,914 - INFO - Step 2895 -- ðŸ”„ Training Metrics
2025-03-02 17:38:07,914 - INFO - â”œâ”€â”€ Loss: 6.2086
2025-03-02 17:38:07,915 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:38:07,915 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:38:08,593 - INFO - ðŸªœ Batch step - 2896 -- sub batch step 11584 -- lr 3.00e-04
2025-03-02 17:38:10,749 - INFO - ðŸªœ Batch step - 2896 -- sub batch step 11585 -- lr 3.00e-04
2025-03-02 17:38:12,919 - INFO - ðŸªœ Batch step - 2896 -- sub batch step 11586 -- lr 3.00e-04
2025-03-02 17:38:15,076 - INFO - ðŸªœ Batch step - 2896 -- sub batch step 11587 -- lr 3.00e-04
2025-03-02 17:38:16,596 - INFO - Step 2896 -- ðŸ”„ Training Metrics
2025-03-02 17:38:16,597 - INFO - â”œâ”€â”€ Loss: 6.2152
2025-03-02 17:38:16,597 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:38:16,597 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:38:17,265 - INFO - ðŸªœ Batch step - 2897 -- sub batch step 11588 -- lr 3.00e-04
2025-03-02 17:38:19,427 - INFO - ðŸªœ Batch step - 2897 -- sub batch step 11589 -- lr 3.00e-04
2025-03-02 17:38:22,089 - INFO - ðŸªœ Batch step - 2897 -- sub batch step 11590 -- lr 3.00e-04
2025-03-02 17:38:24,238 - INFO - ðŸªœ Batch step - 2897 -- sub batch step 11591 -- lr 3.00e-04
2025-03-02 17:38:25,892 - INFO - Step 2897 -- ðŸ”„ Training Metrics
2025-03-02 17:38:25,892 - INFO - â”œâ”€â”€ Loss: 6.2050
2025-03-02 17:38:25,892 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:38:25,892 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:38:26,565 - INFO - ðŸªœ Batch step - 2898 -- sub batch step 11592 -- lr 3.00e-04
2025-03-02 17:38:28,714 - INFO - ðŸªœ Batch step - 2898 -- sub batch step 11593 -- lr 3.00e-04
2025-03-02 17:38:30,891 - INFO - ðŸªœ Batch step - 2898 -- sub batch step 11594 -- lr 3.00e-04
2025-03-02 17:38:33,051 - INFO - ðŸªœ Batch step - 2898 -- sub batch step 11595 -- lr 3.00e-04
2025-03-02 17:38:34,588 - INFO - Step 2898 -- ðŸ”„ Training Metrics
2025-03-02 17:38:34,589 - INFO - â”œâ”€â”€ Loss: 6.2151
2025-03-02 17:38:34,589 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:38:34,589 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:38:35,254 - INFO - ðŸªœ Batch step - 2899 -- sub batch step 11596 -- lr 3.00e-04
2025-03-02 17:38:37,411 - INFO - ðŸªœ Batch step - 2899 -- sub batch step 11597 -- lr 3.00e-04
2025-03-02 17:38:39,747 - INFO - ðŸªœ Batch step - 2899 -- sub batch step 11598 -- lr 3.00e-04
2025-03-02 17:38:41,907 - INFO - ðŸªœ Batch step - 2899 -- sub batch step 11599 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: b0f02489-41d1-4bfb-9802-17a473747e36)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00144-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:38:54,344 - INFO - Step 2899 -- ðŸ”„ Training Metrics
2025-03-02 17:38:54,344 - INFO - â”œâ”€â”€ Loss: 6.1872
2025-03-02 17:38:54,344 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:38:54,344 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:38:55,640 - INFO - ðŸªœ Batch step - 2900 -- sub batch step 11600 -- lr 3.00e-04
2025-03-02 17:38:57,797 - INFO - ðŸªœ Batch step - 2900 -- sub batch step 11601 -- lr 3.00e-04
2025-03-02 17:38:59,958 - INFO - ðŸªœ Batch step - 2900 -- sub batch step 11602 -- lr 3.00e-04
2025-03-02 17:39:02,135 - INFO - ðŸªœ Batch step - 2900 -- sub batch step 11603 -- lr 3.00e-04
2025-03-02 17:39:03,701 - INFO - Step 2900 -- ðŸ”„ Training Metrics
2025-03-02 17:39:03,702 - INFO - â”œâ”€â”€ Loss: 6.2064
2025-03-02 17:39:03,702 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:39:03,702 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:39:04,382 - INFO - ðŸªœ Batch step - 2901 -- sub batch step 11604 -- lr 3.00e-04
2025-03-02 17:39:06,537 - INFO - ðŸªœ Batch step - 2901 -- sub batch step 11605 -- lr 3.00e-04
2025-03-02 17:39:08,684 - INFO - ðŸªœ Batch step - 2901 -- sub batch step 11606 -- lr 3.00e-04
2025-03-02 17:39:11,046 - INFO - ðŸªœ Batch step - 2901 -- sub batch step 11607 -- lr 3.00e-04
2025-03-02 17:39:12,851 - INFO - Step 2901 -- ðŸ”„ Training Metrics
2025-03-02 17:39:12,851 - INFO - â”œâ”€â”€ Loss: 6.2132
2025-03-02 17:39:12,851 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:39:12,851 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:39:13,520 - INFO - ðŸªœ Batch step - 2902 -- sub batch step 11608 -- lr 3.00e-04
2025-03-02 17:39:15,682 - INFO - ðŸªœ Batch step - 2902 -- sub batch step 11609 -- lr 3.00e-04
2025-03-02 17:39:17,841 - INFO - ðŸªœ Batch step - 2902 -- sub batch step 11610 -- lr 3.00e-04
2025-03-02 17:39:20,015 - INFO - ðŸªœ Batch step - 2902 -- sub batch step 11611 -- lr 3.00e-04
2025-03-02 17:39:21,569 - INFO - Step 2902 -- ðŸ”„ Training Metrics
2025-03-02 17:39:21,569 - INFO - â”œâ”€â”€ Loss: 6.2423
2025-03-02 17:39:21,569 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:39:21,569 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:39:22,242 - INFO - ðŸªœ Batch step - 2903 -- sub batch step 11612 -- lr 3.00e-04
2025-03-02 17:39:24,392 - INFO - ðŸªœ Batch step - 2903 -- sub batch step 11613 -- lr 3.00e-04
2025-03-02 17:39:26,547 - INFO - ðŸªœ Batch step - 2903 -- sub batch step 11614 -- lr 3.00e-04
2025-03-02 17:39:29,178 - INFO - ðŸªœ Batch step - 2903 -- sub batch step 11615 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 7e2b0d61-1711-4eb2-9246-0d9b53366467)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00145-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:39:41,605 - INFO - Step 2903 -- ðŸ”„ Training Metrics
2025-03-02 17:39:41,605 - INFO - â”œâ”€â”€ Loss: 6.1991
2025-03-02 17:39:41,605 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:39:41,605 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:39:42,277 - INFO - ðŸªœ Batch step - 2904 -- sub batch step 11616 -- lr 3.00e-04
2025-03-02 17:39:44,440 - INFO - ðŸªœ Batch step - 2904 -- sub batch step 11617 -- lr 3.00e-04
2025-03-02 17:39:46,588 - INFO - ðŸªœ Batch step - 2904 -- sub batch step 11618 -- lr 3.00e-04
2025-03-02 17:39:48,775 - INFO - ðŸªœ Batch step - 2904 -- sub batch step 11619 -- lr 3.00e-04
2025-03-02 17:39:50,286 - INFO - Step 2904 -- ðŸ”„ Training Metrics
2025-03-02 17:39:50,287 - INFO - â”œâ”€â”€ Loss: 6.2244
2025-03-02 17:39:50,287 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:39:50,287 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:39:50,961 - INFO - ðŸªœ Batch step - 2905 -- sub batch step 11620 -- lr 3.00e-04
2025-03-02 17:39:53,118 - INFO - ðŸªœ Batch step - 2905 -- sub batch step 11621 -- lr 3.00e-04
2025-03-02 17:39:55,279 - INFO - ðŸªœ Batch step - 2905 -- sub batch step 11622 -- lr 3.00e-04
2025-03-02 17:39:57,978 - INFO - ðŸªœ Batch step - 2905 -- sub batch step 11623 -- lr 3.00e-04
2025-03-02 17:39:59,569 - INFO - Step 2905 -- ðŸ”„ Training Metrics
2025-03-02 17:39:59,569 - INFO - â”œâ”€â”€ Loss: 6.1979
2025-03-02 17:39:59,570 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:39:59,570 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:40:00,244 - INFO - ðŸªœ Batch step - 2906 -- sub batch step 11624 -- lr 3.00e-04
2025-03-02 17:40:02,405 - INFO - ðŸªœ Batch step - 2906 -- sub batch step 11625 -- lr 3.00e-04
2025-03-02 17:40:04,556 - INFO - ðŸªœ Batch step - 2906 -- sub batch step 11626 -- lr 3.00e-04
2025-03-02 17:40:06,735 - INFO - ðŸªœ Batch step - 2906 -- sub batch step 11627 -- lr 3.00e-04
2025-03-02 17:40:08,258 - INFO - Step 2906 -- ðŸ”„ Training Metrics
2025-03-02 17:40:08,259 - INFO - â”œâ”€â”€ Loss: 6.2225
2025-03-02 17:40:08,259 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:40:08,259 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:40:08,927 - INFO - ðŸªœ Batch step - 2907 -- sub batch step 11628 -- lr 3.00e-04
2025-03-02 17:40:11,086 - INFO - ðŸªœ Batch step - 2907 -- sub batch step 11629 -- lr 3.00e-04
2025-03-02 17:40:13,244 - INFO - ðŸªœ Batch step - 2907 -- sub batch step 11630 -- lr 3.00e-04
2025-03-02 17:40:15,893 - INFO - ðŸªœ Batch step - 2907 -- sub batch step 11631 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: a05ee0a1-461c-42e2-86ef-0d7810781b8c)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00145-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:40:28,301 - INFO - Step 2907 -- ðŸ”„ Training Metrics
2025-03-02 17:40:28,301 - INFO - â”œâ”€â”€ Loss: 6.1963
2025-03-02 17:40:28,301 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:40:28,302 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:40:28,981 - INFO - ðŸªœ Batch step - 2908 -- sub batch step 11632 -- lr 3.00e-04
2025-03-02 17:40:31,135 - INFO - ðŸªœ Batch step - 2908 -- sub batch step 11633 -- lr 3.00e-04
2025-03-02 17:40:33,295 - INFO - ðŸªœ Batch step - 2908 -- sub batch step 11634 -- lr 3.00e-04
2025-03-02 17:40:35,471 - INFO - ðŸªœ Batch step - 2908 -- sub batch step 11635 -- lr 3.00e-04
2025-03-02 17:40:37,000 - INFO - Step 2908 -- ðŸ”„ Training Metrics
2025-03-02 17:40:37,000 - INFO - â”œâ”€â”€ Loss: 6.2011
2025-03-02 17:40:37,000 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:40:37,001 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:40:37,670 - INFO - ðŸªœ Batch step - 2909 -- sub batch step 11636 -- lr 3.00e-04
2025-03-02 17:40:39,829 - INFO - ðŸªœ Batch step - 2909 -- sub batch step 11637 -- lr 3.00e-04
2025-03-02 17:40:41,981 - INFO - ðŸªœ Batch step - 2909 -- sub batch step 11638 -- lr 3.00e-04
2025-03-02 17:40:44,616 - INFO - ðŸªœ Batch step - 2909 -- sub batch step 11639 -- lr 3.00e-04
2025-03-02 17:40:46,253 - INFO - Step 2909 -- ðŸ”„ Training Metrics
2025-03-02 17:40:46,253 - INFO - â”œâ”€â”€ Loss: 6.2122
2025-03-02 17:40:46,253 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:40:46,253 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:40:46,930 - INFO - ðŸªœ Batch step - 2910 -- sub batch step 11640 -- lr 3.00e-04
2025-03-02 17:40:49,080 - INFO - ðŸªœ Batch step - 2910 -- sub batch step 11641 -- lr 3.00e-04
2025-03-02 17:40:51,233 - INFO - ðŸªœ Batch step - 2910 -- sub batch step 11642 -- lr 3.00e-04
2025-03-02 17:40:53,397 - INFO - ðŸªœ Batch step - 2910 -- sub batch step 11643 -- lr 3.00e-04
2025-03-02 17:40:54,935 - INFO - Step 2910 -- ðŸ”„ Training Metrics
2025-03-02 17:40:54,936 - INFO - â”œâ”€â”€ Loss: 6.1657
2025-03-02 17:40:54,936 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:40:54,936 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:40:55,610 - INFO - ðŸªœ Batch step - 2911 -- sub batch step 11644 -- lr 3.00e-04
2025-03-02 17:40:57,762 - INFO - ðŸªœ Batch step - 2911 -- sub batch step 11645 -- lr 3.00e-04
2025-03-02 17:41:00,431 - INFO - ðŸªœ Batch step - 2911 -- sub batch step 11646 -- lr 3.00e-04
2025-03-02 17:41:02,589 - INFO - ðŸªœ Batch step - 2911 -- sub batch step 11647 -- lr 3.00e-04
2025-03-02 17:41:04,098 - INFO - Step 2911 -- ðŸ”„ Training Metrics
2025-03-02 17:41:04,098 - INFO - â”œâ”€â”€ Loss: 6.2096
2025-03-02 17:41:04,099 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:41:04,099 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:41:04,766 - INFO - ðŸªœ Batch step - 2912 -- sub batch step 11648 -- lr 3.00e-04
2025-03-02 17:41:06,922 - INFO - ðŸªœ Batch step - 2912 -- sub batch step 11649 -- lr 3.00e-04
2025-03-02 17:41:09,094 - INFO - ðŸªœ Batch step - 2912 -- sub batch step 11650 -- lr 3.00e-04
2025-03-02 17:41:11,241 - INFO - ðŸªœ Batch step - 2912 -- sub batch step 11651 -- lr 3.00e-04
2025-03-02 17:41:12,921 - INFO - Step 2912 -- ðŸ”„ Training Metrics
2025-03-02 17:41:12,922 - INFO - â”œâ”€â”€ Loss: 6.1941
2025-03-02 17:41:12,922 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:41:12,922 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:41:13,598 - INFO - ðŸªœ Batch step - 2913 -- sub batch step 11652 -- lr 3.00e-04
2025-03-02 17:41:15,747 - INFO - ðŸªœ Batch step - 2913 -- sub batch step 11653 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 910a543a-c7a9-416c-8e0d-60f91588c981)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00145-of-10000.parquet
Retrying in 1s [Retry 1/5].
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: fafe58f5-7e81-4bd4-898e-81e1869b43b3)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00145-of-10000.parquet
Retrying in 2s [Retry 2/5].
2025-03-02 17:41:41,601 - INFO - ðŸªœ Batch step - 2913 -- sub batch step 11654 -- lr 3.00e-04
2025-03-02 17:41:44,092 - INFO - ðŸªœ Batch step - 2913 -- sub batch step 11655 -- lr 3.00e-04
2025-03-02 17:41:45,672 - INFO - Step 2913 -- ðŸ”„ Training Metrics
2025-03-02 17:41:45,672 - INFO - â”œâ”€â”€ Loss: 6.2016
2025-03-02 17:41:45,673 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:41:45,673 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:41:46,480 - INFO - ðŸªœ Batch step - 2914 -- sub batch step 11656 -- lr 3.00e-04
2025-03-02 17:41:48,644 - INFO - ðŸªœ Batch step - 2914 -- sub batch step 11657 -- lr 3.00e-04
2025-03-02 17:41:50,815 - INFO - ðŸªœ Batch step - 2914 -- sub batch step 11658 -- lr 3.00e-04
2025-03-02 17:41:52,971 - INFO - ðŸªœ Batch step - 2914 -- sub batch step 11659 -- lr 3.00e-04
2025-03-02 17:41:54,499 - INFO - Step 2914 -- ðŸ”„ Training Metrics
2025-03-02 17:41:54,499 - INFO - â”œâ”€â”€ Loss: 6.2101
2025-03-02 17:41:54,499 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:41:54,499 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:41:55,178 - INFO - ðŸªœ Batch step - 2915 -- sub batch step 11660 -- lr 3.00e-04
2025-03-02 17:41:57,329 - INFO - ðŸªœ Batch step - 2915 -- sub batch step 11661 -- lr 3.00e-04
2025-03-02 17:41:59,956 - INFO - ðŸªœ Batch step - 2915 -- sub batch step 11662 -- lr 3.00e-04
2025-03-02 17:42:02,113 - INFO - ðŸªœ Batch step - 2915 -- sub batch step 11663 -- lr 3.00e-04
2025-03-02 17:42:06,615 - INFO - Step 2915 -- ðŸ”„ Training Metrics
2025-03-02 17:42:06,615 - INFO - â”œâ”€â”€ Loss: 6.1960
2025-03-02 17:42:06,616 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:42:06,616 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:42:07,299 - INFO - ðŸªœ Batch step - 2916 -- sub batch step 11664 -- lr 3.00e-04
2025-03-02 17:42:09,460 - INFO - ðŸªœ Batch step - 2916 -- sub batch step 11665 -- lr 3.00e-04
2025-03-02 17:42:11,626 - INFO - ðŸªœ Batch step - 2916 -- sub batch step 11666 -- lr 3.00e-04
2025-03-02 17:42:13,779 - INFO - ðŸªœ Batch step - 2916 -- sub batch step 11667 -- lr 3.00e-04
2025-03-02 17:42:15,305 - INFO - Step 2916 -- ðŸ”„ Training Metrics
2025-03-02 17:42:15,305 - INFO - â”œâ”€â”€ Loss: 6.2137
2025-03-02 17:42:15,306 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:42:15,306 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:42:16,010 - INFO - ðŸªœ Batch step - 2917 -- sub batch step 11668 -- lr 3.00e-04
2025-03-02 17:42:18,170 - INFO - ðŸªœ Batch step - 2917 -- sub batch step 11669 -- lr 3.00e-04
2025-03-02 17:42:20,646 - INFO - ðŸªœ Batch step - 2917 -- sub batch step 11670 -- lr 3.00e-04
2025-03-02 17:42:22,796 - INFO - ðŸªœ Batch step - 2917 -- sub batch step 11671 -- lr 3.00e-04
2025-03-02 17:42:24,643 - INFO - Step 2917 -- ðŸ”„ Training Metrics
2025-03-02 17:42:24,644 - INFO - â”œâ”€â”€ Loss: 6.1936
2025-03-02 17:42:24,644 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:42:24,644 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:42:25,314 - INFO - ðŸªœ Batch step - 2918 -- sub batch step 11672 -- lr 3.00e-04
2025-03-02 17:42:27,459 - INFO - ðŸªœ Batch step - 2918 -- sub batch step 11673 -- lr 3.00e-04
2025-03-02 17:42:29,629 - INFO - ðŸªœ Batch step - 2918 -- sub batch step 11674 -- lr 3.00e-04
2025-03-02 17:42:31,782 - INFO - ðŸªœ Batch step - 2918 -- sub batch step 11675 -- lr 3.00e-04
2025-03-02 17:42:33,398 - INFO - Step 2918 -- ðŸ”„ Training Metrics
2025-03-02 17:42:33,398 - INFO - â”œâ”€â”€ Loss: 6.1906
2025-03-02 17:42:33,398 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:42:33,398 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:42:34,068 - INFO - ðŸªœ Batch step - 2919 -- sub batch step 11676 -- lr 3.00e-04
2025-03-02 17:42:36,224 - INFO - ðŸªœ Batch step - 2919 -- sub batch step 11677 -- lr 3.00e-04
2025-03-02 17:42:38,510 - INFO - ðŸªœ Batch step - 2919 -- sub batch step 11678 -- lr 3.00e-04
2025-03-02 17:42:40,660 - INFO - ðŸªœ Batch step - 2919 -- sub batch step 11679 -- lr 3.00e-04
2025-03-02 17:42:42,434 - INFO - Step 2919 -- ðŸ”„ Training Metrics
2025-03-02 17:42:42,434 - INFO - â”œâ”€â”€ Loss: 6.1950
2025-03-02 17:42:42,434 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:42:42,435 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:42:43,597 - INFO - ðŸªœ Batch step - 2920 -- sub batch step 11680 -- lr 3.00e-04
2025-03-02 17:42:45,749 - INFO - ðŸªœ Batch step - 2920 -- sub batch step 11681 -- lr 3.00e-04
2025-03-02 17:42:47,905 - INFO - ðŸªœ Batch step - 2920 -- sub batch step 11682 -- lr 3.00e-04
2025-03-02 17:42:50,076 - INFO - ðŸªœ Batch step - 2920 -- sub batch step 11683 -- lr 3.00e-04
2025-03-02 17:42:51,848 - INFO - Step 2920 -- ðŸ”„ Training Metrics
2025-03-02 17:42:51,849 - INFO - â”œâ”€â”€ Loss: 6.2138
2025-03-02 17:42:51,849 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:42:51,849 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:42:52,525 - INFO - ðŸªœ Batch step - 2921 -- sub batch step 11684 -- lr 3.00e-04
2025-03-02 17:42:54,677 - INFO - ðŸªœ Batch step - 2921 -- sub batch step 11685 -- lr 3.00e-04
2025-03-02 17:42:56,822 - INFO - ðŸªœ Batch step - 2921 -- sub batch step 11686 -- lr 3.00e-04
2025-03-02 17:42:59,426 - INFO - ðŸªœ Batch step - 2921 -- sub batch step 11687 -- lr 3.00e-04
2025-03-02 17:43:00,919 - INFO - Step 2921 -- ðŸ”„ Training Metrics
2025-03-02 17:43:00,920 - INFO - â”œâ”€â”€ Loss: 6.2030
2025-03-02 17:43:00,920 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:43:00,920 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:43:01,585 - INFO - ðŸªœ Batch step - 2922 -- sub batch step 11688 -- lr 3.00e-04
2025-03-02 17:43:03,738 - INFO - ðŸªœ Batch step - 2922 -- sub batch step 11689 -- lr 3.00e-04
2025-03-02 17:43:05,889 - INFO - ðŸªœ Batch step - 2922 -- sub batch step 11690 -- lr 3.00e-04
2025-03-02 17:43:08,054 - INFO - ðŸªœ Batch step - 2922 -- sub batch step 11691 -- lr 3.00e-04
2025-03-02 17:43:09,602 - INFO - Step 2922 -- ðŸ”„ Training Metrics
2025-03-02 17:43:09,602 - INFO - â”œâ”€â”€ Loss: 6.1810
2025-03-02 17:43:09,602 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:43:09,602 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:43:10,274 - INFO - ðŸªœ Batch step - 2923 -- sub batch step 11692 -- lr 3.00e-04
2025-03-02 17:43:12,421 - INFO - ðŸªœ Batch step - 2923 -- sub batch step 11693 -- lr 3.00e-04
2025-03-02 17:43:14,577 - INFO - ðŸªœ Batch step - 2923 -- sub batch step 11694 -- lr 3.00e-04
2025-03-02 17:43:17,260 - INFO - ðŸªœ Batch step - 2923 -- sub batch step 11695 -- lr 3.00e-04
2025-03-02 17:43:18,848 - INFO - Step 2923 -- ðŸ”„ Training Metrics
2025-03-02 17:43:18,848 - INFO - â”œâ”€â”€ Loss: 6.2060
2025-03-02 17:43:18,848 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:43:18,849 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:43:19,513 - INFO - ðŸªœ Batch step - 2924 -- sub batch step 11696 -- lr 3.00e-04
2025-03-02 17:43:21,664 - INFO - ðŸªœ Batch step - 2924 -- sub batch step 11697 -- lr 3.00e-04
2025-03-02 17:43:23,813 - INFO - ðŸªœ Batch step - 2924 -- sub batch step 11698 -- lr 3.00e-04
2025-03-02 17:43:25,986 - INFO - ðŸªœ Batch step - 2924 -- sub batch step 11699 -- lr 3.00e-04
2025-03-02 17:43:27,546 - INFO - Step 2924 -- ðŸ”„ Training Metrics
2025-03-02 17:43:27,546 - INFO - â”œâ”€â”€ Loss: 6.2242
2025-03-02 17:43:27,547 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:43:27,547 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:43:28,216 - INFO - ðŸªœ Batch step - 2925 -- sub batch step 11700 -- lr 3.00e-04
2025-03-02 17:43:30,360 - INFO - ðŸªœ Batch step - 2925 -- sub batch step 11701 -- lr 3.00e-04
2025-03-02 17:43:32,508 - INFO - ðŸªœ Batch step - 2925 -- sub batch step 11702 -- lr 3.00e-04
2025-03-02 17:43:35,163 - INFO - ðŸªœ Batch step - 2925 -- sub batch step 11703 -- lr 3.00e-04
2025-03-02 17:43:36,854 - INFO - Step 2925 -- ðŸ”„ Training Metrics
2025-03-02 17:43:36,854 - INFO - â”œâ”€â”€ Loss: 6.1840
2025-03-02 17:43:36,854 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:43:36,854 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:43:37,526 - INFO - ðŸªœ Batch step - 2926 -- sub batch step 11704 -- lr 3.00e-04
2025-03-02 17:43:39,679 - INFO - ðŸªœ Batch step - 2926 -- sub batch step 11705 -- lr 3.00e-04
2025-03-02 17:43:41,822 - INFO - ðŸªœ Batch step - 2926 -- sub batch step 11706 -- lr 3.00e-04
2025-03-02 17:43:43,992 - INFO - ðŸªœ Batch step - 2926 -- sub batch step 11707 -- lr 3.00e-04
2025-03-02 17:43:45,559 - INFO - Step 2926 -- ðŸ”„ Training Metrics
2025-03-02 17:43:45,559 - INFO - â”œâ”€â”€ Loss: 6.1869
2025-03-02 17:43:45,559 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:43:45,559 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:43:46,226 - INFO - ðŸªœ Batch step - 2927 -- sub batch step 11708 -- lr 3.00e-04
2025-03-02 17:43:48,380 - INFO - ðŸªœ Batch step - 2927 -- sub batch step 11709 -- lr 3.00e-04
2025-03-02 17:43:50,532 - INFO - ðŸªœ Batch step - 2927 -- sub batch step 11710 -- lr 3.00e-04
2025-03-02 17:43:53,248 - INFO - ðŸªœ Batch step - 2927 -- sub batch step 11711 -- lr 3.00e-04
2025-03-02 17:43:54,740 - INFO - Step 2927 -- ðŸ”„ Training Metrics
2025-03-02 17:43:54,741 - INFO - â”œâ”€â”€ Loss: 6.2052
2025-03-02 17:43:54,741 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:43:54,741 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:43:55,412 - INFO - ðŸªœ Batch step - 2928 -- sub batch step 11712 -- lr 3.00e-04
2025-03-02 17:43:57,560 - INFO - ðŸªœ Batch step - 2928 -- sub batch step 11713 -- lr 3.00e-04
2025-03-02 17:43:59,716 - INFO - ðŸªœ Batch step - 2928 -- sub batch step 11714 -- lr 3.00e-04
2025-03-02 17:44:01,883 - INFO - ðŸªœ Batch step - 2928 -- sub batch step 11715 -- lr 3.00e-04
2025-03-02 17:44:03,435 - INFO - Step 2928 -- ðŸ”„ Training Metrics
2025-03-02 17:44:03,435 - INFO - â”œâ”€â”€ Loss: 6.1709
2025-03-02 17:44:03,435 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:44:03,435 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:44:04,101 - INFO - ðŸªœ Batch step - 2929 -- sub batch step 11716 -- lr 3.00e-04
2025-03-02 17:44:06,253 - INFO - ðŸªœ Batch step - 2929 -- sub batch step 11717 -- lr 3.00e-04
2025-03-02 17:44:08,401 - INFO - ðŸªœ Batch step - 2929 -- sub batch step 11718 -- lr 3.00e-04
2025-03-02 17:44:11,111 - INFO - ðŸªœ Batch step - 2929 -- sub batch step 11719 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: bc8cf1d1-104e-410c-a472-6dfc98eb0d6f)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00146-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:44:24,495 - INFO - Step 2929 -- ðŸ”„ Training Metrics
2025-03-02 17:44:24,495 - INFO - â”œâ”€â”€ Loss: 6.1959
2025-03-02 17:44:24,496 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:44:24,496 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:44:25,959 - INFO - ðŸªœ Batch step - 2930 -- sub batch step 11720 -- lr 3.00e-04
2025-03-02 17:44:28,504 - INFO - ðŸªœ Batch step - 2930 -- sub batch step 11721 -- lr 3.00e-04
2025-03-02 17:44:30,653 - INFO - ðŸªœ Batch step - 2930 -- sub batch step 11722 -- lr 3.00e-04
2025-03-02 17:44:32,824 - INFO - ðŸªœ Batch step - 2930 -- sub batch step 11723 -- lr 3.00e-04
2025-03-02 17:44:34,366 - INFO - Step 2930 -- ðŸ”„ Training Metrics
2025-03-02 17:44:34,366 - INFO - â”œâ”€â”€ Loss: 6.1724
2025-03-02 17:44:34,366 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:44:34,366 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:44:35,039 - INFO - ðŸªœ Batch step - 2931 -- sub batch step 11724 -- lr 3.00e-04
2025-03-02 17:44:37,190 - INFO - ðŸªœ Batch step - 2931 -- sub batch step 11725 -- lr 3.00e-04
2025-03-02 17:44:39,850 - INFO - ðŸªœ Batch step - 2931 -- sub batch step 11726 -- lr 3.00e-04
2025-03-02 17:44:42,006 - INFO - ðŸªœ Batch step - 2931 -- sub batch step 11727 -- lr 3.00e-04
2025-03-02 17:44:43,639 - INFO - Step 2931 -- ðŸ”„ Training Metrics
2025-03-02 17:44:43,640 - INFO - â”œâ”€â”€ Loss: 6.1741
2025-03-02 17:44:43,640 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:44:43,640 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:44:44,308 - INFO - ðŸªœ Batch step - 2932 -- sub batch step 11728 -- lr 3.00e-04
2025-03-02 17:44:46,463 - INFO - ðŸªœ Batch step - 2932 -- sub batch step 11729 -- lr 3.00e-04
2025-03-02 17:44:48,629 - INFO - ðŸªœ Batch step - 2932 -- sub batch step 11730 -- lr 3.00e-04
2025-03-02 17:44:50,776 - INFO - ðŸªœ Batch step - 2932 -- sub batch step 11731 -- lr 3.00e-04
2025-03-02 17:44:52,336 - INFO - Step 2932 -- ðŸ”„ Training Metrics
2025-03-02 17:44:52,336 - INFO - â”œâ”€â”€ Loss: 6.1856
2025-03-02 17:44:52,337 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:44:52,337 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:44:53,009 - INFO - ðŸªœ Batch step - 2933 -- sub batch step 11732 -- lr 3.00e-04
2025-03-02 17:44:55,157 - INFO - ðŸªœ Batch step - 2933 -- sub batch step 11733 -- lr 3.00e-04
2025-03-02 17:44:57,545 - INFO - ðŸªœ Batch step - 2933 -- sub batch step 11734 -- lr 3.00e-04
2025-03-02 17:44:59,702 - INFO - ðŸªœ Batch step - 2933 -- sub batch step 11735 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 89237fa0-ed91-468f-a4a8-63036ade4ef6)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00146-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:45:12,525 - INFO - Step 2933 -- ðŸ”„ Training Metrics
2025-03-02 17:45:12,525 - INFO - â”œâ”€â”€ Loss: 6.1840
2025-03-02 17:45:12,525 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:45:12,525 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:45:13,194 - INFO - ðŸªœ Batch step - 2934 -- sub batch step 11736 -- lr 3.00e-04
2025-03-02 17:45:15,345 - INFO - ðŸªœ Batch step - 2934 -- sub batch step 11737 -- lr 3.00e-04
2025-03-02 17:45:17,508 - INFO - ðŸªœ Batch step - 2934 -- sub batch step 11738 -- lr 3.00e-04
2025-03-02 17:45:19,665 - INFO - ðŸªœ Batch step - 2934 -- sub batch step 11739 -- lr 3.00e-04
2025-03-02 17:45:21,214 - INFO - Step 2934 -- ðŸ”„ Training Metrics
2025-03-02 17:45:21,214 - INFO - â”œâ”€â”€ Loss: 6.1923
2025-03-02 17:45:21,214 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:45:21,214 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:45:21,888 - INFO - ðŸªœ Batch step - 2935 -- sub batch step 11740 -- lr 3.00e-04
2025-03-02 17:45:24,034 - INFO - ðŸªœ Batch step - 2935 -- sub batch step 11741 -- lr 3.00e-04
2025-03-02 17:45:26,755 - INFO - ðŸªœ Batch step - 2935 -- sub batch step 11742 -- lr 3.00e-04
2025-03-02 17:45:28,900 - INFO - ðŸªœ Batch step - 2935 -- sub batch step 11743 -- lr 3.00e-04
2025-03-02 17:45:30,435 - INFO - Step 2935 -- ðŸ”„ Training Metrics
2025-03-02 17:45:30,435 - INFO - â”œâ”€â”€ Loss: 6.2100
2025-03-02 17:45:30,435 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:45:30,435 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:45:31,108 - INFO - ðŸªœ Batch step - 2936 -- sub batch step 11744 -- lr 3.00e-04
2025-03-02 17:45:33,259 - INFO - ðŸªœ Batch step - 2936 -- sub batch step 11745 -- lr 3.00e-04
2025-03-02 17:45:35,423 - INFO - ðŸªœ Batch step - 2936 -- sub batch step 11746 -- lr 3.00e-04
2025-03-02 17:45:37,579 - INFO - ðŸªœ Batch step - 2936 -- sub batch step 11747 -- lr 3.00e-04
2025-03-02 17:45:39,122 - INFO - Step 2936 -- ðŸ”„ Training Metrics
2025-03-02 17:45:39,122 - INFO - â”œâ”€â”€ Loss: 6.1758
2025-03-02 17:45:39,123 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:45:39,123 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:45:39,789 - INFO - ðŸªœ Batch step - 2937 -- sub batch step 11748 -- lr 3.00e-04
2025-03-02 17:45:41,942 - INFO - ðŸªœ Batch step - 2937 -- sub batch step 11749 -- lr 3.00e-04
2025-03-02 17:45:44,567 - INFO - ðŸªœ Batch step - 2937 -- sub batch step 11750 -- lr 3.00e-04
2025-03-02 17:45:46,717 - INFO - ðŸªœ Batch step - 2937 -- sub batch step 11751 -- lr 3.00e-04
2025-03-02 17:45:48,314 - INFO - Step 2937 -- ðŸ”„ Training Metrics
2025-03-02 17:45:48,314 - INFO - â”œâ”€â”€ Loss: 6.1692
2025-03-02 17:45:48,314 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:45:48,314 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:45:48,986 - INFO - ðŸªœ Batch step - 2938 -- sub batch step 11752 -- lr 3.00e-04
2025-03-02 17:45:51,131 - INFO - ðŸªœ Batch step - 2938 -- sub batch step 11753 -- lr 3.00e-04
2025-03-02 17:45:53,305 - INFO - ðŸªœ Batch step - 2938 -- sub batch step 11754 -- lr 3.00e-04
2025-03-02 17:45:55,460 - INFO - ðŸªœ Batch step - 2938 -- sub batch step 11755 -- lr 3.00e-04
2025-03-02 17:45:57,002 - INFO - Step 2938 -- ðŸ”„ Training Metrics
2025-03-02 17:45:57,002 - INFO - â”œâ”€â”€ Loss: 6.1830
2025-03-02 17:45:57,002 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:45:57,002 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:45:57,668 - INFO - ðŸªœ Batch step - 2939 -- sub batch step 11756 -- lr 3.00e-04
2025-03-02 17:45:59,820 - INFO - ðŸªœ Batch step - 2939 -- sub batch step 11757 -- lr 3.00e-04
2025-03-02 17:46:02,109 - INFO - ðŸªœ Batch step - 2939 -- sub batch step 11758 -- lr 3.00e-04
2025-03-02 17:46:04,262 - INFO - ðŸªœ Batch step - 2939 -- sub batch step 11759 -- lr 3.00e-04
2025-03-02 17:46:05,973 - INFO - Step 2939 -- ðŸ”„ Training Metrics
2025-03-02 17:46:05,973 - INFO - â”œâ”€â”€ Loss: 6.1806
2025-03-02 17:46:05,973 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:46:05,973 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:46:07,138 - INFO - ðŸªœ Batch step - 2940 -- sub batch step 11760 -- lr 3.00e-04
2025-03-02 17:46:09,293 - INFO - ðŸªœ Batch step - 2940 -- sub batch step 11761 -- lr 3.00e-04
2025-03-02 17:46:11,456 - INFO - ðŸªœ Batch step - 2940 -- sub batch step 11762 -- lr 3.00e-04
2025-03-02 17:46:13,628 - INFO - ðŸªœ Batch step - 2940 -- sub batch step 11763 -- lr 3.00e-04
2025-03-02 17:46:15,449 - INFO - Step 2940 -- ðŸ”„ Training Metrics
2025-03-02 17:46:15,449 - INFO - â”œâ”€â”€ Loss: 6.1895
2025-03-02 17:46:15,449 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:46:15,449 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:46:16,127 - INFO - ðŸªœ Batch step - 2941 -- sub batch step 11764 -- lr 3.00e-04
2025-03-02 17:46:18,283 - INFO - ðŸªœ Batch step - 2941 -- sub batch step 11765 -- lr 3.00e-04
2025-03-02 17:46:20,434 - INFO - ðŸªœ Batch step - 2941 -- sub batch step 11766 -- lr 3.00e-04
2025-03-02 17:46:23,092 - INFO - ðŸªœ Batch step - 2941 -- sub batch step 11767 -- lr 3.00e-04
2025-03-02 17:46:24,642 - INFO - Step 2941 -- ðŸ”„ Training Metrics
2025-03-02 17:46:24,642 - INFO - â”œâ”€â”€ Loss: 6.2116
2025-03-02 17:46:24,642 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:46:24,642 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:46:25,310 - INFO - ðŸªœ Batch step - 2942 -- sub batch step 11768 -- lr 3.00e-04
2025-03-02 17:46:27,472 - INFO - ðŸªœ Batch step - 2942 -- sub batch step 11769 -- lr 3.00e-04
2025-03-02 17:46:29,629 - INFO - ðŸªœ Batch step - 2942 -- sub batch step 11770 -- lr 3.00e-04
2025-03-02 17:46:31,803 - INFO - ðŸªœ Batch step - 2942 -- sub batch step 11771 -- lr 3.00e-04
2025-03-02 17:46:33,334 - INFO - Step 2942 -- ðŸ”„ Training Metrics
2025-03-02 17:46:33,334 - INFO - â”œâ”€â”€ Loss: 6.1880
2025-03-02 17:46:33,334 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:46:33,334 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:46:34,016 - INFO - ðŸªœ Batch step - 2943 -- sub batch step 11772 -- lr 3.00e-04
2025-03-02 17:46:36,164 - INFO - ðŸªœ Batch step - 2943 -- sub batch step 11773 -- lr 3.00e-04
2025-03-02 17:46:38,321 - INFO - ðŸªœ Batch step - 2943 -- sub batch step 11774 -- lr 3.00e-04
2025-03-02 17:46:41,042 - INFO - ðŸªœ Batch step - 2943 -- sub batch step 11775 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 5234177e-b214-46ae-87f7-d941ddef027c)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00147-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:46:53,149 - INFO - Step 2943 -- ðŸ”„ Training Metrics
2025-03-02 17:46:53,150 - INFO - â”œâ”€â”€ Loss: 6.1914
2025-03-02 17:46:53,150 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:46:53,150 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:46:53,817 - INFO - ðŸªœ Batch step - 2944 -- sub batch step 11776 -- lr 3.00e-04
2025-03-02 17:46:55,977 - INFO - ðŸªœ Batch step - 2944 -- sub batch step 11777 -- lr 3.00e-04
2025-03-02 17:46:58,125 - INFO - ðŸªœ Batch step - 2944 -- sub batch step 11778 -- lr 3.00e-04
2025-03-02 17:47:00,302 - INFO - ðŸªœ Batch step - 2944 -- sub batch step 11779 -- lr 3.00e-04
2025-03-02 17:47:01,835 - INFO - Step 2944 -- ðŸ”„ Training Metrics
2025-03-02 17:47:01,836 - INFO - â”œâ”€â”€ Loss: 6.2165
2025-03-02 17:47:01,836 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:47:01,836 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:47:02,515 - INFO - ðŸªœ Batch step - 2945 -- sub batch step 11780 -- lr 3.00e-04
2025-03-02 17:47:04,665 - INFO - ðŸªœ Batch step - 2945 -- sub batch step 11781 -- lr 3.00e-04
2025-03-02 17:47:06,820 - INFO - ðŸªœ Batch step - 2945 -- sub batch step 11782 -- lr 3.00e-04
2025-03-02 17:47:09,517 - INFO - ðŸªœ Batch step - 2945 -- sub batch step 11783 -- lr 3.00e-04
2025-03-02 17:47:11,138 - INFO - Step 2945 -- ðŸ”„ Training Metrics
2025-03-02 17:47:11,138 - INFO - â”œâ”€â”€ Loss: 6.1697
2025-03-02 17:47:11,138 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:47:11,138 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:47:11,813 - INFO - ðŸªœ Batch step - 2946 -- sub batch step 11784 -- lr 3.00e-04
2025-03-02 17:47:13,966 - INFO - ðŸªœ Batch step - 2946 -- sub batch step 11785 -- lr 3.00e-04
2025-03-02 17:47:16,115 - INFO - ðŸªœ Batch step - 2946 -- sub batch step 11786 -- lr 3.00e-04
2025-03-02 17:47:18,295 - INFO - ðŸªœ Batch step - 2946 -- sub batch step 11787 -- lr 3.00e-04
2025-03-02 17:47:19,832 - INFO - Step 2946 -- ðŸ”„ Training Metrics
2025-03-02 17:47:19,833 - INFO - â”œâ”€â”€ Loss: 6.2027
2025-03-02 17:47:19,833 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:47:19,833 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:47:20,500 - INFO - ðŸªœ Batch step - 2947 -- sub batch step 11788 -- lr 3.00e-04
2025-03-02 17:47:22,658 - INFO - ðŸªœ Batch step - 2947 -- sub batch step 11789 -- lr 3.00e-04
2025-03-02 17:47:24,814 - INFO - ðŸªœ Batch step - 2947 -- sub batch step 11790 -- lr 3.00e-04
2025-03-02 17:47:27,223 - INFO - ðŸªœ Batch step - 2947 -- sub batch step 11791 -- lr 3.00e-04
2025-03-02 17:47:29,012 - INFO - Step 2947 -- ðŸ”„ Training Metrics
2025-03-02 17:47:29,012 - INFO - â”œâ”€â”€ Loss: 6.1875
2025-03-02 17:47:29,012 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:47:29,012 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:47:29,682 - INFO - ðŸªœ Batch step - 2948 -- sub batch step 11792 -- lr 3.00e-04
2025-03-02 17:47:31,831 - INFO - ðŸªœ Batch step - 2948 -- sub batch step 11793 -- lr 3.00e-04
2025-03-02 17:47:33,987 - INFO - ðŸªœ Batch step - 2948 -- sub batch step 11794 -- lr 3.00e-04
2025-03-02 17:47:36,164 - INFO - ðŸªœ Batch step - 2948 -- sub batch step 11795 -- lr 3.00e-04
2025-03-02 17:47:37,699 - INFO - Step 2948 -- ðŸ”„ Training Metrics
2025-03-02 17:47:37,699 - INFO - â”œâ”€â”€ Loss: 6.1905
2025-03-02 17:47:37,699 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:47:37,700 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:47:38,368 - INFO - ðŸªœ Batch step - 2949 -- sub batch step 11796 -- lr 3.00e-04
2025-03-02 17:47:40,532 - INFO - ðŸªœ Batch step - 2949 -- sub batch step 11797 -- lr 3.00e-04
2025-03-02 17:47:42,685 - INFO - ðŸªœ Batch step - 2949 -- sub batch step 11798 -- lr 3.00e-04
2025-03-02 17:47:45,345 - INFO - ðŸªœ Batch step - 2949 -- sub batch step 11799 -- lr 3.00e-04
2025-03-02 17:47:47,026 - INFO - Step 2949 -- ðŸ”„ Training Metrics
2025-03-02 17:47:47,027 - INFO - â”œâ”€â”€ Loss: 6.1789
2025-03-02 17:47:47,027 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:47:47,027 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:47:47,701 - INFO - ðŸªœ Batch step - 2950 -- sub batch step 11800 -- lr 3.00e-04
2025-03-02 17:47:49,854 - INFO - ðŸªœ Batch step - 2950 -- sub batch step 11801 -- lr 3.00e-04
2025-03-02 17:47:52,010 - INFO - ðŸªœ Batch step - 2950 -- sub batch step 11802 -- lr 3.00e-04
2025-03-02 17:47:54,180 - INFO - ðŸªœ Batch step - 2950 -- sub batch step 11803 -- lr 3.00e-04
2025-03-02 17:47:55,702 - INFO - Step 2950 -- ðŸ”„ Training Metrics
2025-03-02 17:47:55,703 - INFO - â”œâ”€â”€ Loss: 6.2024
2025-03-02 17:47:55,703 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:47:55,703 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:47:56,379 - INFO - ðŸªœ Batch step - 2951 -- sub batch step 11804 -- lr 3.00e-04
2025-03-02 17:47:58,533 - INFO - ðŸªœ Batch step - 2951 -- sub batch step 11805 -- lr 3.00e-04
2025-03-02 17:48:01,180 - INFO - ðŸªœ Batch step - 2951 -- sub batch step 11806 -- lr 3.00e-04
2025-03-02 17:48:03,339 - INFO - ðŸªœ Batch step - 2951 -- sub batch step 11807 -- lr 3.00e-04
2025-03-02 17:48:05,180 - INFO - Step 2951 -- ðŸ”„ Training Metrics
2025-03-02 17:48:05,181 - INFO - â”œâ”€â”€ Loss: 6.2152
2025-03-02 17:48:05,181 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:48:05,181 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:48:05,847 - INFO - ðŸªœ Batch step - 2952 -- sub batch step 11808 -- lr 3.00e-04
2025-03-02 17:48:08,007 - INFO - ðŸªœ Batch step - 2952 -- sub batch step 11809 -- lr 3.00e-04
2025-03-02 17:48:10,185 - INFO - ðŸªœ Batch step - 2952 -- sub batch step 11810 -- lr 3.00e-04
2025-03-02 17:48:12,332 - INFO - ðŸªœ Batch step - 2952 -- sub batch step 11811 -- lr 3.00e-04
2025-03-02 17:48:13,864 - INFO - Step 2952 -- ðŸ”„ Training Metrics
2025-03-02 17:48:13,864 - INFO - â”œâ”€â”€ Loss: 6.1787
2025-03-02 17:48:13,864 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:48:13,864 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:48:14,541 - INFO - ðŸªœ Batch step - 2953 -- sub batch step 11812 -- lr 3.00e-04
2025-03-02 17:48:16,689 - INFO - ðŸªœ Batch step - 2953 -- sub batch step 11813 -- lr 3.00e-04
2025-03-02 17:48:19,315 - INFO - ðŸªœ Batch step - 2953 -- sub batch step 11814 -- lr 3.00e-04
2025-03-02 17:48:21,476 - INFO - ðŸªœ Batch step - 2953 -- sub batch step 11815 -- lr 3.00e-04
2025-03-02 17:48:23,118 - INFO - Step 2953 -- ðŸ”„ Training Metrics
2025-03-02 17:48:23,119 - INFO - â”œâ”€â”€ Loss: 6.1962
2025-03-02 17:48:23,119 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:48:23,119 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:48:23,788 - INFO - ðŸªœ Batch step - 2954 -- sub batch step 11816 -- lr 3.00e-04
2025-03-02 17:48:25,948 - INFO - ðŸªœ Batch step - 2954 -- sub batch step 11817 -- lr 3.00e-04
2025-03-02 17:48:28,121 - INFO - ðŸªœ Batch step - 2954 -- sub batch step 11818 -- lr 3.00e-04
2025-03-02 17:48:30,276 - INFO - ðŸªœ Batch step - 2954 -- sub batch step 11819 -- lr 3.00e-04
2025-03-02 17:48:31,818 - INFO - Step 2954 -- ðŸ”„ Training Metrics
2025-03-02 17:48:31,819 - INFO - â”œâ”€â”€ Loss: 6.1727
2025-03-02 17:48:31,819 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:48:31,819 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:48:32,491 - INFO - ðŸªœ Batch step - 2955 -- sub batch step 11820 -- lr 3.00e-04
2025-03-02 17:48:34,645 - INFO - ðŸªœ Batch step - 2955 -- sub batch step 11821 -- lr 3.00e-04
2025-03-02 17:48:37,273 - INFO - ðŸªœ Batch step - 2955 -- sub batch step 11822 -- lr 3.00e-04
2025-03-02 17:48:39,420 - INFO - ðŸªœ Batch step - 2955 -- sub batch step 11823 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: e5ff3a3c-6924-4a06-916e-b4309b10a3d9)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00147-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:48:51,661 - INFO - Step 2955 -- ðŸ”„ Training Metrics
2025-03-02 17:48:51,662 - INFO - â”œâ”€â”€ Loss: 6.2111
2025-03-02 17:48:51,662 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:48:51,662 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:48:52,336 - INFO - ðŸªœ Batch step - 2956 -- sub batch step 11824 -- lr 3.00e-04
2025-03-02 17:48:54,491 - INFO - ðŸªœ Batch step - 2956 -- sub batch step 11825 -- lr 3.00e-04
2025-03-02 17:48:56,659 - INFO - ðŸªœ Batch step - 2956 -- sub batch step 11826 -- lr 3.00e-04
2025-03-02 17:48:58,812 - INFO - ðŸªœ Batch step - 2956 -- sub batch step 11827 -- lr 3.00e-04
2025-03-02 17:49:00,373 - INFO - Step 2956 -- ðŸ”„ Training Metrics
2025-03-02 17:49:00,373 - INFO - â”œâ”€â”€ Loss: 6.1898
2025-03-02 17:49:00,373 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:49:00,374 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:49:01,040 - INFO - ðŸªœ Batch step - 2957 -- sub batch step 11828 -- lr 3.00e-04
2025-03-02 17:49:03,197 - INFO - ðŸªœ Batch step - 2957 -- sub batch step 11829 -- lr 3.00e-04
2025-03-02 17:49:05,795 - INFO - ðŸªœ Batch step - 2957 -- sub batch step 11830 -- lr 3.00e-04
2025-03-02 17:49:07,947 - INFO - ðŸªœ Batch step - 2957 -- sub batch step 11831 -- lr 3.00e-04
2025-03-02 17:49:09,705 - INFO - Step 2957 -- ðŸ”„ Training Metrics
2025-03-02 17:49:09,705 - INFO - â”œâ”€â”€ Loss: 6.1674
2025-03-02 17:49:09,705 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:49:09,705 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:49:10,377 - INFO - ðŸªœ Batch step - 2958 -- sub batch step 11832 -- lr 3.00e-04
2025-03-02 17:49:12,529 - INFO - ðŸªœ Batch step - 2958 -- sub batch step 11833 -- lr 3.00e-04
2025-03-02 17:49:14,704 - INFO - ðŸªœ Batch step - 2958 -- sub batch step 11834 -- lr 3.00e-04
2025-03-02 17:49:16,859 - INFO - ðŸªœ Batch step - 2958 -- sub batch step 11835 -- lr 3.00e-04
2025-03-02 17:49:18,395 - INFO - Step 2958 -- ðŸ”„ Training Metrics
2025-03-02 17:49:18,395 - INFO - â”œâ”€â”€ Loss: 6.1995
2025-03-02 17:49:18,395 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:49:18,395 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:49:19,066 - INFO - ðŸªœ Batch step - 2959 -- sub batch step 11836 -- lr 3.00e-04
2025-03-02 17:49:21,220 - INFO - ðŸªœ Batch step - 2959 -- sub batch step 11837 -- lr 3.00e-04
2025-03-02 17:49:23,495 - INFO - ðŸªœ Batch step - 2959 -- sub batch step 11838 -- lr 3.00e-04
2025-03-02 17:49:25,654 - INFO - ðŸªœ Batch step - 2959 -- sub batch step 11839 -- lr 3.00e-04
2025-03-02 17:49:27,252 - INFO - Step 2959 -- ðŸ”„ Training Metrics
2025-03-02 17:49:27,252 - INFO - â”œâ”€â”€ Loss: 6.2009
2025-03-02 17:49:27,252 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:49:27,253 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:49:28,435 - INFO - ðŸªœ Batch step - 2960 -- sub batch step 11840 -- lr 3.00e-04
2025-03-02 17:49:30,585 - INFO - ðŸªœ Batch step - 2960 -- sub batch step 11841 -- lr 3.00e-04
2025-03-02 17:49:32,739 - INFO - ðŸªœ Batch step - 2960 -- sub batch step 11842 -- lr 3.00e-04
2025-03-02 17:49:34,908 - INFO - ðŸªœ Batch step - 2960 -- sub batch step 11843 -- lr 3.00e-04
2025-03-02 17:49:36,534 - INFO - Step 2960 -- ðŸ”„ Training Metrics
2025-03-02 17:49:36,534 - INFO - â”œâ”€â”€ Loss: 6.1826
2025-03-02 17:49:36,534 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:49:36,534 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:49:37,210 - INFO - ðŸªœ Batch step - 2961 -- sub batch step 11844 -- lr 3.00e-04
2025-03-02 17:49:39,363 - INFO - ðŸªœ Batch step - 2961 -- sub batch step 11845 -- lr 3.00e-04
2025-03-02 17:49:41,511 - INFO - ðŸªœ Batch step - 2961 -- sub batch step 11846 -- lr 3.00e-04
2025-03-02 17:49:44,365 - INFO - ðŸªœ Batch step - 2961 -- sub batch step 11847 -- lr 3.00e-04
2025-03-02 17:49:45,856 - INFO - Step 2961 -- ðŸ”„ Training Metrics
2025-03-02 17:49:45,856 - INFO - â”œâ”€â”€ Loss: 6.1576
2025-03-02 17:49:45,857 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:49:45,857 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:49:46,525 - INFO - ðŸªœ Batch step - 2962 -- sub batch step 11848 -- lr 3.00e-04
2025-03-02 17:49:48,684 - INFO - ðŸªœ Batch step - 2962 -- sub batch step 11849 -- lr 3.00e-04
2025-03-02 17:49:50,839 - INFO - ðŸªœ Batch step - 2962 -- sub batch step 11850 -- lr 3.00e-04
2025-03-02 17:49:53,009 - INFO - ðŸªœ Batch step - 2962 -- sub batch step 11851 -- lr 3.00e-04
2025-03-02 17:49:54,569 - INFO - Step 2962 -- ðŸ”„ Training Metrics
2025-03-02 17:49:54,570 - INFO - â”œâ”€â”€ Loss: 6.2068
2025-03-02 17:49:54,570 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:49:54,570 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:49:55,248 - INFO - ðŸªœ Batch step - 2963 -- sub batch step 11852 -- lr 3.00e-04
2025-03-02 17:49:57,399 - INFO - ðŸªœ Batch step - 2963 -- sub batch step 11853 -- lr 3.00e-04
2025-03-02 17:49:59,553 - INFO - ðŸªœ Batch step - 2963 -- sub batch step 11854 -- lr 3.00e-04
2025-03-02 17:50:01,979 - INFO - ðŸªœ Batch step - 2963 -- sub batch step 11855 -- lr 3.00e-04
2025-03-02 17:50:09,269 - INFO - Step 2963 -- ðŸ”„ Training Metrics
2025-03-02 17:50:09,270 - INFO - â”œâ”€â”€ Loss: 6.1931
2025-03-02 17:50:09,270 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:50:09,270 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:50:09,947 - INFO - ðŸªœ Batch step - 2964 -- sub batch step 11856 -- lr 3.00e-04
2025-03-02 17:50:12,112 - INFO - ðŸªœ Batch step - 2964 -- sub batch step 11857 -- lr 3.00e-04
2025-03-02 17:50:14,268 - INFO - ðŸªœ Batch step - 2964 -- sub batch step 11858 -- lr 3.00e-04
2025-03-02 17:50:16,459 - INFO - ðŸªœ Batch step - 2964 -- sub batch step 11859 -- lr 3.00e-04
2025-03-02 17:50:17,985 - INFO - Step 2964 -- ðŸ”„ Training Metrics
2025-03-02 17:50:17,986 - INFO - â”œâ”€â”€ Loss: 6.1767
2025-03-02 17:50:17,986 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:50:17,986 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:50:18,670 - INFO - ðŸªœ Batch step - 2965 -- sub batch step 11860 -- lr 3.00e-04
2025-03-02 17:50:20,832 - INFO - ðŸªœ Batch step - 2965 -- sub batch step 11861 -- lr 3.00e-04
2025-03-02 17:50:22,996 - INFO - ðŸªœ Batch step - 2965 -- sub batch step 11862 -- lr 3.00e-04
2025-03-02 17:50:25,842 - INFO - ðŸªœ Batch step - 2965 -- sub batch step 11863 -- lr 3.00e-04
2025-03-02 17:50:27,335 - INFO - Step 2965 -- ðŸ”„ Training Metrics
2025-03-02 17:50:27,336 - INFO - â”œâ”€â”€ Loss: 6.1752
2025-03-02 17:50:27,336 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:50:27,336 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:50:28,020 - INFO - ðŸªœ Batch step - 2966 -- sub batch step 11864 -- lr 3.00e-04
2025-03-02 17:50:30,183 - INFO - ðŸªœ Batch step - 2966 -- sub batch step 11865 -- lr 3.00e-04
2025-03-02 17:50:32,340 - INFO - ðŸªœ Batch step - 2966 -- sub batch step 11866 -- lr 3.00e-04
2025-03-02 17:50:34,522 - INFO - ðŸªœ Batch step - 2966 -- sub batch step 11867 -- lr 3.00e-04
2025-03-02 17:50:36,055 - INFO - Step 2966 -- ðŸ”„ Training Metrics
2025-03-02 17:50:36,056 - INFO - â”œâ”€â”€ Loss: 6.1686
2025-03-02 17:50:36,056 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:50:36,056 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:50:36,724 - INFO - ðŸªœ Batch step - 2967 -- sub batch step 11868 -- lr 3.00e-04
2025-03-02 17:50:38,884 - INFO - ðŸªœ Batch step - 2967 -- sub batch step 11869 -- lr 3.00e-04
2025-03-02 17:50:41,040 - INFO - ðŸªœ Batch step - 2967 -- sub batch step 11870 -- lr 3.00e-04
2025-03-02 17:50:43,710 - INFO - ðŸªœ Batch step - 2967 -- sub batch step 11871 -- lr 3.00e-04
2025-03-02 17:50:45,339 - INFO - Step 2967 -- ðŸ”„ Training Metrics
2025-03-02 17:50:45,340 - INFO - â”œâ”€â”€ Loss: 6.1667
2025-03-02 17:50:45,340 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:50:45,340 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:50:46,017 - INFO - ðŸªœ Batch step - 2968 -- sub batch step 11872 -- lr 3.00e-04
2025-03-02 17:50:48,167 - INFO - ðŸªœ Batch step - 2968 -- sub batch step 11873 -- lr 3.00e-04
2025-03-02 17:50:50,324 - INFO - ðŸªœ Batch step - 2968 -- sub batch step 11874 -- lr 3.00e-04
2025-03-02 17:50:52,499 - INFO - ðŸªœ Batch step - 2968 -- sub batch step 11875 -- lr 3.00e-04
2025-03-02 17:50:54,058 - INFO - Step 2968 -- ðŸ”„ Training Metrics
2025-03-02 17:50:54,058 - INFO - â”œâ”€â”€ Loss: 6.1542
2025-03-02 17:50:54,058 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:50:54,058 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:50:54,727 - INFO - ðŸªœ Batch step - 2969 -- sub batch step 11876 -- lr 3.00e-04
2025-03-02 17:50:56,887 - INFO - ðŸªœ Batch step - 2969 -- sub batch step 11877 -- lr 3.00e-04
2025-03-02 17:50:59,035 - INFO - ðŸªœ Batch step - 2969 -- sub batch step 11878 -- lr 3.00e-04
2025-03-02 17:51:01,759 - INFO - ðŸªœ Batch step - 2969 -- sub batch step 11879 -- lr 3.00e-04
2025-03-02 17:51:03,347 - INFO - Step 2969 -- ðŸ”„ Training Metrics
2025-03-02 17:51:03,347 - INFO - â”œâ”€â”€ Loss: 6.1955
2025-03-02 17:51:03,347 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:51:03,347 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:51:04,022 - INFO - ðŸªœ Batch step - 2970 -- sub batch step 11880 -- lr 3.00e-04
2025-03-02 17:51:06,175 - INFO - ðŸªœ Batch step - 2970 -- sub batch step 11881 -- lr 3.00e-04
2025-03-02 17:51:08,332 - INFO - ðŸªœ Batch step - 2970 -- sub batch step 11882 -- lr 3.00e-04
2025-03-02 17:51:10,505 - INFO - ðŸªœ Batch step - 2970 -- sub batch step 11883 -- lr 3.00e-04
2025-03-02 17:51:12,049 - INFO - Step 2970 -- ðŸ”„ Training Metrics
2025-03-02 17:51:12,050 - INFO - â”œâ”€â”€ Loss: 6.1714
2025-03-02 17:51:12,050 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:51:12,050 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:51:12,725 - INFO - ðŸªœ Batch step - 2971 -- sub batch step 11884 -- lr 3.00e-04
2025-03-02 17:51:14,884 - INFO - ðŸªœ Batch step - 2971 -- sub batch step 11885 -- lr 3.00e-04
2025-03-02 17:51:17,545 - INFO - ðŸªœ Batch step - 2971 -- sub batch step 11886 -- lr 3.00e-04
2025-03-02 17:51:19,706 - INFO - ðŸªœ Batch step - 2971 -- sub batch step 11887 -- lr 3.00e-04
2025-03-02 17:51:21,352 - INFO - Step 2971 -- ðŸ”„ Training Metrics
2025-03-02 17:51:21,353 - INFO - â”œâ”€â”€ Loss: 6.1719
2025-03-02 17:51:21,353 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:51:21,353 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:51:22,022 - INFO - ðŸªœ Batch step - 2972 -- sub batch step 11888 -- lr 3.00e-04
2025-03-02 17:51:24,179 - INFO - ðŸªœ Batch step - 2972 -- sub batch step 11889 -- lr 3.00e-04
2025-03-02 17:51:26,356 - INFO - ðŸªœ Batch step - 2972 -- sub batch step 11890 -- lr 3.00e-04
2025-03-02 17:51:28,505 - INFO - ðŸªœ Batch step - 2972 -- sub batch step 11891 -- lr 3.00e-04
2025-03-02 17:51:30,065 - INFO - Step 2972 -- ðŸ”„ Training Metrics
2025-03-02 17:51:30,065 - INFO - â”œâ”€â”€ Loss: 6.1701
2025-03-02 17:51:30,065 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:51:30,065 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:51:30,738 - INFO - ðŸªœ Batch step - 2973 -- sub batch step 11892 -- lr 3.00e-04
2025-03-02 17:51:32,886 - INFO - ðŸªœ Batch step - 2973 -- sub batch step 11893 -- lr 3.00e-04
2025-03-02 17:51:35,544 - INFO - ðŸªœ Batch step - 2973 -- sub batch step 11894 -- lr 3.00e-04
2025-03-02 17:51:37,707 - INFO - ðŸªœ Batch step - 2973 -- sub batch step 11895 -- lr 3.00e-04
2025-03-02 17:51:39,422 - INFO - Step 2973 -- ðŸ”„ Training Metrics
2025-03-02 17:51:39,422 - INFO - â”œâ”€â”€ Loss: 6.1753
2025-03-02 17:51:39,422 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:51:39,423 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:51:40,090 - INFO - ðŸªœ Batch step - 2974 -- sub batch step 11896 -- lr 3.00e-04
2025-03-02 17:51:42,246 - INFO - ðŸªœ Batch step - 2974 -- sub batch step 11897 -- lr 3.00e-04
2025-03-02 17:51:44,414 - INFO - ðŸªœ Batch step - 2974 -- sub batch step 11898 -- lr 3.00e-04
2025-03-02 17:51:46,572 - INFO - ðŸªœ Batch step - 2974 -- sub batch step 11899 -- lr 3.00e-04
2025-03-02 17:51:48,122 - INFO - Step 2974 -- ðŸ”„ Training Metrics
2025-03-02 17:51:48,122 - INFO - â”œâ”€â”€ Loss: 6.1722
2025-03-02 17:51:48,122 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:51:48,122 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:51:48,800 - INFO - ðŸªœ Batch step - 2975 -- sub batch step 11900 -- lr 3.00e-04
2025-03-02 17:51:50,951 - INFO - ðŸªœ Batch step - 2975 -- sub batch step 11901 -- lr 3.00e-04
2025-03-02 17:51:53,623 - INFO - ðŸªœ Batch step - 2975 -- sub batch step 11902 -- lr 3.00e-04
2025-03-02 17:51:55,774 - INFO - ðŸªœ Batch step - 2975 -- sub batch step 11903 -- lr 3.00e-04
2025-03-02 17:51:57,260 - INFO - Step 2975 -- ðŸ”„ Training Metrics
2025-03-02 17:51:57,260 - INFO - â”œâ”€â”€ Loss: 6.1859
2025-03-02 17:51:57,260 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:51:57,260 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:51:57,937 - INFO - ðŸªœ Batch step - 2976 -- sub batch step 11904 -- lr 3.00e-04
2025-03-02 17:52:00,089 - INFO - ðŸªœ Batch step - 2976 -- sub batch step 11905 -- lr 3.00e-04
2025-03-02 17:52:02,260 - INFO - ðŸªœ Batch step - 2976 -- sub batch step 11906 -- lr 3.00e-04
2025-03-02 17:52:04,413 - INFO - ðŸªœ Batch step - 2976 -- sub batch step 11907 -- lr 3.00e-04
2025-03-02 17:52:05,979 - INFO - Step 2976 -- ðŸ”„ Training Metrics
2025-03-02 17:52:05,980 - INFO - â”œâ”€â”€ Loss: 6.1776
2025-03-02 17:52:05,980 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:52:05,980 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:52:06,646 - INFO - ðŸªœ Batch step - 2977 -- sub batch step 11908 -- lr 3.00e-04
2025-03-02 17:52:08,811 - INFO - ðŸªœ Batch step - 2977 -- sub batch step 11909 -- lr 3.00e-04
2025-03-02 17:52:11,302 - INFO - ðŸªœ Batch step - 2977 -- sub batch step 11910 -- lr 3.00e-04
2025-03-02 17:52:13,448 - INFO - ðŸªœ Batch step - 2977 -- sub batch step 11911 -- lr 3.00e-04
2025-03-02 17:52:15,351 - INFO - Step 2977 -- ðŸ”„ Training Metrics
2025-03-02 17:52:15,351 - INFO - â”œâ”€â”€ Loss: 6.1488
2025-03-02 17:52:15,351 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:52:15,351 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:52:16,024 - INFO - ðŸªœ Batch step - 2978 -- sub batch step 11912 -- lr 3.00e-04
2025-03-02 17:52:18,175 - INFO - ðŸªœ Batch step - 2978 -- sub batch step 11913 -- lr 3.00e-04
2025-03-02 17:52:20,358 - INFO - ðŸªœ Batch step - 2978 -- sub batch step 11914 -- lr 3.00e-04
2025-03-02 17:52:22,511 - INFO - ðŸªœ Batch step - 2978 -- sub batch step 11915 -- lr 3.00e-04
2025-03-02 17:52:24,066 - INFO - Step 2978 -- ðŸ”„ Training Metrics
2025-03-02 17:52:24,067 - INFO - â”œâ”€â”€ Loss: 6.1960
2025-03-02 17:52:24,067 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:52:24,067 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:52:24,736 - INFO - ðŸªœ Batch step - 2979 -- sub batch step 11916 -- lr 3.00e-04
2025-03-02 17:52:26,894 - INFO - ðŸªœ Batch step - 2979 -- sub batch step 11917 -- lr 3.00e-04
2025-03-02 17:52:29,178 - INFO - ðŸªœ Batch step - 2979 -- sub batch step 11918 -- lr 3.00e-04
2025-03-02 17:52:31,335 - INFO - ðŸªœ Batch step - 2979 -- sub batch step 11919 -- lr 3.00e-04
2025-03-02 17:52:32,910 - INFO - Step 2979 -- ðŸ”„ Training Metrics
2025-03-02 17:52:32,911 - INFO - â”œâ”€â”€ Loss: 6.1879
2025-03-02 17:52:32,911 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:52:32,911 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:52:34,019 - INFO - ðŸªœ Batch step - 2980 -- sub batch step 11920 -- lr 3.00e-04
2025-03-02 17:52:36,171 - INFO - ðŸªœ Batch step - 2980 -- sub batch step 11921 -- lr 3.00e-04
2025-03-02 17:52:38,326 - INFO - ðŸªœ Batch step - 2980 -- sub batch step 11922 -- lr 3.00e-04
2025-03-02 17:52:40,500 - INFO - ðŸªœ Batch step - 2980 -- sub batch step 11923 -- lr 3.00e-04
2025-03-02 17:52:42,354 - INFO - Step 2980 -- ðŸ”„ Training Metrics
2025-03-02 17:52:42,355 - INFO - â”œâ”€â”€ Loss: 6.1890
2025-03-02 17:52:42,355 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:52:42,355 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:52:43,033 - INFO - ðŸªœ Batch step - 2981 -- sub batch step 11924 -- lr 3.00e-04
2025-03-02 17:52:45,192 - INFO - ðŸªœ Batch step - 2981 -- sub batch step 11925 -- lr 3.00e-04
2025-03-02 17:52:47,344 - INFO - ðŸªœ Batch step - 2981 -- sub batch step 11926 -- lr 3.00e-04
2025-03-02 17:52:49,985 - INFO - ðŸªœ Batch step - 2981 -- sub batch step 11927 -- lr 3.00e-04
2025-03-02 17:52:51,523 - INFO - Step 2981 -- ðŸ”„ Training Metrics
2025-03-02 17:52:51,524 - INFO - â”œâ”€â”€ Loss: 6.1391
2025-03-02 17:52:51,524 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:52:51,524 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:52:52,187 - INFO - ðŸªœ Batch step - 2982 -- sub batch step 11928 -- lr 3.00e-04
2025-03-02 17:52:54,349 - INFO - ðŸªœ Batch step - 2982 -- sub batch step 11929 -- lr 3.00e-04
2025-03-02 17:52:56,508 - INFO - ðŸªœ Batch step - 2982 -- sub batch step 11930 -- lr 3.00e-04
2025-03-02 17:52:58,679 - INFO - ðŸªœ Batch step - 2982 -- sub batch step 11931 -- lr 3.00e-04
2025-03-02 17:53:00,244 - INFO - Step 2982 -- ðŸ”„ Training Metrics
2025-03-02 17:53:00,244 - INFO - â”œâ”€â”€ Loss: 6.1462
2025-03-02 17:53:00,245 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:53:00,245 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:53:00,921 - INFO - ðŸªœ Batch step - 2983 -- sub batch step 11932 -- lr 3.00e-04
2025-03-02 17:53:03,076 - INFO - ðŸªœ Batch step - 2983 -- sub batch step 11933 -- lr 3.00e-04
2025-03-02 17:53:05,235 - INFO - ðŸªœ Batch step - 2983 -- sub batch step 11934 -- lr 3.00e-04
2025-03-02 17:53:07,643 - INFO - ðŸªœ Batch step - 2983 -- sub batch step 11935 -- lr 3.00e-04
2025-03-02 17:53:09,626 - INFO - Step 2983 -- ðŸ”„ Training Metrics
2025-03-02 17:53:09,626 - INFO - â”œâ”€â”€ Loss: 6.1815
2025-03-02 17:53:09,626 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:53:09,626 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:53:10,295 - INFO - ðŸªœ Batch step - 2984 -- sub batch step 11936 -- lr 3.00e-04
2025-03-02 17:53:12,455 - INFO - ðŸªœ Batch step - 2984 -- sub batch step 11937 -- lr 3.00e-04
2025-03-02 17:53:14,610 - INFO - ðŸªœ Batch step - 2984 -- sub batch step 11938 -- lr 3.00e-04
2025-03-02 17:53:16,789 - INFO - ðŸªœ Batch step - 2984 -- sub batch step 11939 -- lr 3.00e-04
2025-03-02 17:53:18,349 - INFO - Step 2984 -- ðŸ”„ Training Metrics
2025-03-02 17:53:18,350 - INFO - â”œâ”€â”€ Loss: 6.1848
2025-03-02 17:53:18,350 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:53:18,350 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:53:19,023 - INFO - ðŸªœ Batch step - 2985 -- sub batch step 11940 -- lr 3.00e-04
2025-03-02 17:53:21,177 - INFO - ðŸªœ Batch step - 2985 -- sub batch step 11941 -- lr 3.00e-04
2025-03-02 17:53:23,331 - INFO - ðŸªœ Batch step - 2985 -- sub batch step 11942 -- lr 3.00e-04
2025-03-02 17:53:26,164 - INFO - ðŸªœ Batch step - 2985 -- sub batch step 11943 -- lr 3.00e-04
2025-03-02 17:53:27,666 - INFO - Step 2985 -- ðŸ”„ Training Metrics
2025-03-02 17:53:27,666 - INFO - â”œâ”€â”€ Loss: 6.1989
2025-03-02 17:53:27,666 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:53:27,666 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:53:28,339 - INFO - ðŸªœ Batch step - 2986 -- sub batch step 11944 -- lr 3.00e-04
2025-03-02 17:53:30,495 - INFO - ðŸªœ Batch step - 2986 -- sub batch step 11945 -- lr 3.00e-04
2025-03-02 17:53:32,641 - INFO - ðŸªœ Batch step - 2986 -- sub batch step 11946 -- lr 3.00e-04
2025-03-02 17:53:34,818 - INFO - ðŸªœ Batch step - 2986 -- sub batch step 11947 -- lr 3.00e-04
2025-03-02 17:53:36,400 - INFO - Step 2986 -- ðŸ”„ Training Metrics
2025-03-02 17:53:36,400 - INFO - â”œâ”€â”€ Loss: 6.1736
2025-03-02 17:53:36,400 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:53:36,400 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:53:37,064 - INFO - ðŸªœ Batch step - 2987 -- sub batch step 11948 -- lr 3.00e-04
2025-03-02 17:53:39,222 - INFO - ðŸªœ Batch step - 2987 -- sub batch step 11949 -- lr 3.00e-04
2025-03-02 17:53:41,377 - INFO - ðŸªœ Batch step - 2987 -- sub batch step 11950 -- lr 3.00e-04
2025-03-02 17:53:44,025 - INFO - ðŸªœ Batch step - 2987 -- sub batch step 11951 -- lr 3.00e-04
2025-03-02 17:53:45,518 - INFO - Step 2987 -- ðŸ”„ Training Metrics
2025-03-02 17:53:45,518 - INFO - â”œâ”€â”€ Loss: 6.1814
2025-03-02 17:53:45,518 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:53:45,518 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:53:46,191 - INFO - ðŸªœ Batch step - 2988 -- sub batch step 11952 -- lr 3.00e-04
2025-03-02 17:53:48,342 - INFO - ðŸªœ Batch step - 2988 -- sub batch step 11953 -- lr 3.00e-04
2025-03-02 17:53:50,498 - INFO - ðŸªœ Batch step - 2988 -- sub batch step 11954 -- lr 3.00e-04
2025-03-02 17:53:52,679 - INFO - ðŸªœ Batch step - 2988 -- sub batch step 11955 -- lr 3.00e-04
2025-03-02 17:53:54,242 - INFO - Step 2988 -- ðŸ”„ Training Metrics
2025-03-02 17:53:54,242 - INFO - â”œâ”€â”€ Loss: 6.1768
2025-03-02 17:53:54,242 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:53:54,242 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:53:54,909 - INFO - ðŸªœ Batch step - 2989 -- sub batch step 11956 -- lr 3.00e-04
2025-03-02 17:53:57,067 - INFO - ðŸªœ Batch step - 2989 -- sub batch step 11957 -- lr 3.00e-04
2025-03-02 17:53:59,215 - INFO - ðŸªœ Batch step - 2989 -- sub batch step 11958 -- lr 3.00e-04
2025-03-02 17:54:01,926 - INFO - ðŸªœ Batch step - 2989 -- sub batch step 11959 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 2282efa6-9fb3-4a84-93ae-87b89f13de6d)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00149-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:54:14,228 - INFO - Step 2989 -- ðŸ”„ Training Metrics
2025-03-02 17:54:14,228 - INFO - â”œâ”€â”€ Loss: 6.1739
2025-03-02 17:54:14,229 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:54:14,229 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:54:14,906 - INFO - ðŸªœ Batch step - 2990 -- sub batch step 11960 -- lr 3.00e-04
2025-03-02 17:54:17,054 - INFO - ðŸªœ Batch step - 2990 -- sub batch step 11961 -- lr 3.00e-04
2025-03-02 17:54:19,215 - INFO - ðŸªœ Batch step - 2990 -- sub batch step 11962 -- lr 3.00e-04
2025-03-02 17:54:21,377 - INFO - ðŸªœ Batch step - 2990 -- sub batch step 11963 -- lr 3.00e-04
2025-03-02 17:54:22,933 - INFO - Step 2990 -- ðŸ”„ Training Metrics
2025-03-02 17:54:22,934 - INFO - â”œâ”€â”€ Loss: 6.1701
2025-03-02 17:54:22,934 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:54:22,934 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:54:23,610 - INFO - ðŸªœ Batch step - 2991 -- sub batch step 11964 -- lr 3.00e-04
2025-03-02 17:54:25,765 - INFO - ðŸªœ Batch step - 2991 -- sub batch step 11965 -- lr 3.00e-04
2025-03-02 17:54:28,499 - INFO - ðŸªœ Batch step - 2991 -- sub batch step 11966 -- lr 3.00e-04
2025-03-02 17:54:30,657 - INFO - ðŸªœ Batch step - 2991 -- sub batch step 11967 -- lr 3.00e-04
2025-03-02 17:54:32,245 - INFO - Step 2991 -- ðŸ”„ Training Metrics
2025-03-02 17:54:32,246 - INFO - â”œâ”€â”€ Loss: 6.2066
2025-03-02 17:54:32,246 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:54:32,246 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:54:32,915 - INFO - ðŸªœ Batch step - 2992 -- sub batch step 11968 -- lr 3.00e-04
2025-03-02 17:54:35,074 - INFO - ðŸªœ Batch step - 2992 -- sub batch step 11969 -- lr 3.00e-04
2025-03-02 17:54:37,249 - INFO - ðŸªœ Batch step - 2992 -- sub batch step 11970 -- lr 3.00e-04
2025-03-02 17:54:39,399 - INFO - ðŸªœ Batch step - 2992 -- sub batch step 11971 -- lr 3.00e-04
2025-03-02 17:54:40,953 - INFO - Step 2992 -- ðŸ”„ Training Metrics
2025-03-02 17:54:40,953 - INFO - â”œâ”€â”€ Loss: 6.1930
2025-03-02 17:54:40,953 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:54:40,953 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:54:41,626 - INFO - ðŸªœ Batch step - 2993 -- sub batch step 11972 -- lr 3.00e-04
2025-03-02 17:54:43,777 - INFO - ðŸªœ Batch step - 2993 -- sub batch step 11973 -- lr 3.00e-04
2025-03-02 17:54:46,302 - INFO - ðŸªœ Batch step - 2993 -- sub batch step 11974 -- lr 3.00e-04
2025-03-02 17:54:48,459 - INFO - ðŸªœ Batch step - 2993 -- sub batch step 11975 -- lr 3.00e-04
2025-03-02 17:54:54,910 - INFO - Step 2993 -- ðŸ”„ Training Metrics
2025-03-02 17:54:54,910 - INFO - â”œâ”€â”€ Loss: 6.1791
2025-03-02 17:54:54,910 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:54:54,910 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:54:55,579 - INFO - ðŸªœ Batch step - 2994 -- sub batch step 11976 -- lr 3.00e-04
2025-03-02 17:54:57,736 - INFO - ðŸªœ Batch step - 2994 -- sub batch step 11977 -- lr 3.00e-04
2025-03-02 17:54:59,902 - INFO - ðŸªœ Batch step - 2994 -- sub batch step 11978 -- lr 3.00e-04
2025-03-02 17:55:02,062 - INFO - ðŸªœ Batch step - 2994 -- sub batch step 11979 -- lr 3.00e-04
2025-03-02 17:55:03,626 - INFO - Step 2994 -- ðŸ”„ Training Metrics
2025-03-02 17:55:03,626 - INFO - â”œâ”€â”€ Loss: 6.1892
2025-03-02 17:55:03,626 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:55:03,627 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:55:04,298 - INFO - ðŸªœ Batch step - 2995 -- sub batch step 11980 -- lr 3.00e-04
2025-03-02 17:55:06,448 - INFO - ðŸªœ Batch step - 2995 -- sub batch step 11981 -- lr 3.00e-04
2025-03-02 17:55:09,111 - INFO - ðŸªœ Batch step - 2995 -- sub batch step 11982 -- lr 3.00e-04
2025-03-02 17:55:11,259 - INFO - ðŸªœ Batch step - 2995 -- sub batch step 11983 -- lr 3.00e-04
2025-03-02 17:55:12,830 - INFO - Step 2995 -- ðŸ”„ Training Metrics
2025-03-02 17:55:12,831 - INFO - â”œâ”€â”€ Loss: 6.1859
2025-03-02 17:55:12,831 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:55:12,831 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:55:13,504 - INFO - ðŸªœ Batch step - 2996 -- sub batch step 11984 -- lr 3.00e-04
2025-03-02 17:55:15,658 - INFO - ðŸªœ Batch step - 2996 -- sub batch step 11985 -- lr 3.00e-04
2025-03-02 17:55:17,825 - INFO - ðŸªœ Batch step - 2996 -- sub batch step 11986 -- lr 3.00e-04
2025-03-02 17:55:19,982 - INFO - ðŸªœ Batch step - 2996 -- sub batch step 11987 -- lr 3.00e-04
2025-03-02 17:55:21,564 - INFO - Step 2996 -- ðŸ”„ Training Metrics
2025-03-02 17:55:21,564 - INFO - â”œâ”€â”€ Loss: 6.1757
2025-03-02 17:55:21,564 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:55:21,564 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:55:22,231 - INFO - ðŸªœ Batch step - 2997 -- sub batch step 11988 -- lr 3.00e-04
2025-03-02 17:55:24,384 - INFO - ðŸªœ Batch step - 2997 -- sub batch step 11989 -- lr 3.00e-04
2025-03-02 17:55:27,056 - INFO - ðŸªœ Batch step - 2997 -- sub batch step 11990 -- lr 3.00e-04
2025-03-02 17:55:29,208 - INFO - ðŸªœ Batch step - 2997 -- sub batch step 11991 -- lr 3.00e-04
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: c910ebae-f12b-46fd-9568-218929f4c61a)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00149-of-10000.parquet
Retrying in 1s [Retry 1/5].
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: cff0ee9b-f8d0-430c-a5cf-64da12c0db26)')' thrown while requesting GET https://huggingface.co/datasets/pico-lm/pretokenized-dolma/resolve/65f6857c948eddb87d412f6d5a19cf1c01c2450f/data/train-00149-of-10000.parquet
Retrying in 1s [Retry 1/5].
2025-03-02 17:55:41,441 - INFO - Step 2997 -- ðŸ”„ Training Metrics
2025-03-02 17:55:41,441 - INFO - â”œâ”€â”€ Loss: 6.1676
2025-03-02 17:55:41,441 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:55:41,441 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:55:42,119 - INFO - ðŸªœ Batch step - 2998 -- sub batch step 11992 -- lr 3.00e-04
2025-03-02 17:55:44,268 - INFO - ðŸªœ Batch step - 2998 -- sub batch step 11993 -- lr 3.00e-04
2025-03-02 17:55:46,442 - INFO - ðŸªœ Batch step - 2998 -- sub batch step 11994 -- lr 3.00e-04
2025-03-02 17:55:48,594 - INFO - ðŸªœ Batch step - 2998 -- sub batch step 11995 -- lr 3.00e-04
2025-03-02 17:55:50,151 - INFO - Step 2998 -- ðŸ”„ Training Metrics
2025-03-02 17:55:50,151 - INFO - â”œâ”€â”€ Loss: 6.1749
2025-03-02 17:55:50,152 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:55:50,152 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:55:50,824 - INFO - ðŸªœ Batch step - 2999 -- sub batch step 11996 -- lr 3.00e-04
2025-03-02 17:55:52,980 - INFO - ðŸªœ Batch step - 2999 -- sub batch step 11997 -- lr 3.00e-04
2025-03-02 17:55:55,274 - INFO - ðŸªœ Batch step - 2999 -- sub batch step 11998 -- lr 3.00e-04
2025-03-02 17:55:57,427 - INFO - ðŸªœ Batch step - 2999 -- sub batch step 11999 -- lr 3.00e-04
2025-03-02 17:55:59,057 - INFO - Step 2999 -- ðŸ”„ Training Metrics
2025-03-02 17:55:59,057 - INFO - â”œâ”€â”€ Loss: 6.1588
2025-03-02 17:55:59,057 - INFO - â”œâ”€â”€ Learning Rate: 3.00e-04
2025-03-02 17:55:59,057 - INFO - â””â”€â”€ Inf/NaN count: 0
2025-03-02 17:55:59,063 - INFO - Step 3000 -- ðŸ’¾ Saving Checkpoint
model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]model.safetensors:   9%|â–‰         | 4.10M/46.8M [00:00<00:01, 37.7MB/s]model.safetensors:  17%|â–ˆâ–‹        | 7.88M/46.8M [00:00<00:01, 21.9MB/s]model.safetensors:  22%|â–ˆâ–ˆâ–       | 10.4M/46.8M [00:00<00:01, 22.1MB/s]model.safetensors:  34%|â–ˆâ–ˆâ–ˆâ–      | 16.0M/46.8M [00:00<00:01, 17.0MB/s]model.safetensors:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21.9M/46.8M [00:00<00:01, 23.4MB/s]model.safetensors:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 24.8M/46.8M [00:01<00:00, 24.5MB/s]model.safetensors:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28.5M/46.8M [00:01<00:00, 25.0MB/s]model.safetensors:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 32.0M/46.8M [00:01<00:00, 16.4MB/s]model.safetensors:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38.2M/46.8M [00:01<00:00, 22.6MB/s]model.safetensors:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 41.2M/46.8M [00:01<00:00, 23.9MB/s]model.safetensors:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44.2M/46.8M [00:01<00:00, 24.8MB/s]model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46.8M/46.8M [00:02<00:00, 19.1MB/s]
0[0] -> 4[0] [send] via NET/IB/1
gpu-q-9:206472:206995 [0] NCCL INFO Channel 00/0 : 8[0] -> 0[0] [receive] via NET/IB/0
gpu-q-9:206472:206995 [0] NCCL INFO Channel 01/0 : 8[0] -> 0[0] [receive] via NET/IB/1
gpu-q-9:206472:206995 [0] NCCL INFO Channel 00/0 : 0[0] -> 8[0] [send] via NET/IB/0
gpu-q-9:206472:206995 [0] NCCL INFO Channel 01/0 : 0[0] -> 8[0] [send] via NET/IB/1
gpu-q-9:206472:206995 [0] NCCL INFO Channel 04/0 : 4[0] -> 0[0] [receive] via NET/IB/0
gpu-q-9:206472:206995 [0] NCCL INFO Channel 05/0 : 4[0] -> 0[0] [receive] via NET/IB/1
gpu-q-9:206472:206995 [0] NCCL INFO Connected all trees
gpu-q-9:206472:206995 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-9:206472:206995 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-9:206472:206995 [0] NCCL INFO ncclCommInitRank comm 0x56545988ee90 rank 0 nranks 16 cudaDev 0 nvmlDev 0 busId 1000 commId 0xf5599d8a92473923 - Init COMPLETE
[rank0]:[E302 18:27:37.010047350 ProcessGroupNCCL.cpp:616] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24549, OpType=ALLREDUCE, NumelIn=20, NumelOut=20, Timeout(ms)=1800000) ran for 1800088 milliseconds before timing out.
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 01/0 : 12[0] -> 8[0] [receive] via NET/IB/1
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 04/0 : 8[0] -> 5[1] [send] via NET/IB/0
gpu-q-35:2680339:2680855 [0] NCCL INFO Channel 05/0 : 8[0] -> 5[1] [send] via NET/IB/1
gpu-q-35:2680339:2680855 [0] NCCL INFO Connected all trees
gpu-q-35:2680339:2680855 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-35:2680339:2680855 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-35:2680339:2680855 [0] NCCL INFO ncclCommInitRank comm 0x55ccee7a3f20 rank 8 nranks 16 cudaDev 0 nvmlDev 0 busId 1000 commId 0xf5599d8a92473923 - Init COMPLETE
gpu-q-49:1203803:1204308 [0] NCCL INFO ncclCommInitRank comm 0x558a079fb5f0 rank 12 nranks 16 cudaDev 0 nvmlDev 0 busId 1000 commId 0xf5599d8a92473923 - Init COMPLETE
[rank8]:[E302 18:27:37.209315625 ProcessGroupNCCL.cpp:616] [Rank 8] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800011 milliseconds before timing out.
gpu-q-49:1203805:1204307 [2] NCCL INFO ncclCommInitRank comm 0x556b20db2230 rank 14 nranks 16 cudaDev 2 nvmlDev 2 busId 81000 commId 0xf5599d8a92473923 - Init COMPLETE
gpu-q-35:2680340:2680699 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-35:2680340:2680699 [1] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gpu-q-35:2680340:2680699 [1] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gpu-q-35:2680340:2680699 [1] NCCL INFO ncclCommInitRank comm 0x55f8eb51a040 rank 9 nranks 16 cudaDev 1 nvmlDev 1 busId 41000 commId 0xab369c58f444f4f9 - Init COMPLETE
gpu-q-35:2680340:2680856 [1] NCCL INFO Using non-device net plugin version 0
gpu-q-35:2680340:2680856 [1] NCCL INFO Using network IB
gpu-q-35:2680340:2680856 [1] NCCL INFO ncclCommInitRank comm 0x55f8ee334f70 rank 9 nranks 16 cudaDev 1 nvmlDev 1 busId 41000 commId 0xf5599d8a92473923 - Init START
gpu-q-35:2680340:2680856 [1] NCCL INFO Setting affinity for GPU 1 to ffff0000
gpu-q-49:1203806:1204159 [3] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gpu-q-49:1203806:1204159 [3] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gpu-q-49:1203806:1204159 [3] NCCL INFO ncclCommInitRank comm 0x5573a3eb8540 rank 15 nranks 16 cudaDev 3 nvmlDev 3 busId c1000 commId 0xab369c58f444f4f9 - Init COMPLETE
gpu-q-49:1203806:1204342 [3] NCCL INFO Using non-device net plugin version 0
gpu-q-49:1203806:1204342 [3] NCCL INFO Using network IB
gpu-q-49:1203806:1204342 [3] NCCL INFO ncclCommInitRank comm 0x5573a72ba180 rank 15 nranks 16 cudaDev 3 nvmlDev 3 busId c1000 commId 0xf5599d8a92473923 - Init START
gpu-q-49:1203806:1204342 [3] NCCL INFO Setting affinity for GPU 3 to ffff0000,00000000,00000000
gpu-q-49:1203806:1204342 [3] NCCL INFO NVLS multicast support is not available on dev 3
gpu-q-35:2680340:2680856 [1] NCCL INFO NVLS multicast support is not available on dev 1
gpu-q-35:2680340:2680856 [1] NCCL INFO comm 0x55f8ee334f70 rank 9 nRanks 16 nNodes 4 localRanks 4 localRank 1 MNNVL 0
gpu-q-35:2680340:2680856 [1] NCCL INFO Trees [0] 10/4/-1->9->8 [1] 10/4/-1->9->8 [2] -1/-1/-1->9->8 [3] 10/7/-1->9->11 [4] 10/-1/-1->9->8 [5] 10/-1/-1->9->8 [6] -1/-1/-1->9->8 [7] 10/-1/-1->9->11
gpu-q-35:2680340:2680856 [1] NCCL INFO P2P Chunksize set to 131072
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 00/0 : 9[1] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 01/0 : 9[1] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 04/0 : 9[1] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 05/0 : 9[1] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 02/0 : 9[1] -> 14[2] [send] via NET/IB/0
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 03/0 : 9[1] -> 14[2] [send] via NET/IB/1
gpu-q-49:1203806:1204342 [3] NCCL INFO comm 0x5573a72ba180 rank 15 nRanks 16 nNodes 4 localRanks 4 localRank 3 MNNVL 0
gpu-q-49:1203806:1204342 [3] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] -1/-1/-1->15->14 [2] 12/-1/-1->15->14 [3] 13/-1/-1->15->11 [4] -1/-1/-1->15->14 [5] -1/-1/-1->15->14 [6] 12/-1/-1->15->14 [7] 13/7/-1->15->-1
gpu-q-49:1203806:1204342 [3] NCCL INFO P2P Chunksize set to 131072
gpu-q-49:1203806:1204342 [3] NCCL INFO Channel 00/0 : 15[3] -> 0[0] [send] via NET/IB/0
gpu-q-49:1203806:1204342 [3] NCCL INFO Channel 01/0 : 15[3] -> 0[0] [send] via NET/IB/1
gpu-q-49:1203806:1204342 [3] NCCL INFO Channel 04/0 : 15[3] -> 0[0] [send] via NET/IB/0
gpu-q-49:1203806:1204342 [3] NCCL INFO Channel 05/0 : 15[3] -> 0[0] [send] via NET/IB/1
gpu-q-49:1203806:1204342 [3] NCCL INFO Channel 02/0 : 15[3] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203806:1204342 [3] NCCL INFO Channel 03/0 : 15[3] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203806:1204342 [3] NCCL INFO Channel 06/0 : 15[3] -> 13[1] via P2P/CUMEM/read
[rank12]:[E302 18:27:37.977311319 ProcessGroupNCCL.cpp:616] [Rank 12] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800054 milliseconds before timing out.
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 06/0 : 9[1] -> 14[2] [send] via NET/IB/0
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 07/0 : 9[1] -> 14[2] [send] via NET/IB/1
gpu-q-35:2680340:2680856 [1] NCCL INFO Connected all rings
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 03/0 : 9[1] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 07/0 : 9[1] -> 10[2] via P2P/CUMEM/read
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 03/0 : 7[3] -> 9[1] [receive] via NET/IB/1
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 03/0 : 9[1] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 07/0 : 9[1] -> 11[3] via P2P/CUMEM/read
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 00/0 : 4[0] -> 9[1] [receive] via NET/IB/0
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 01/0 : 4[0] -> 9[1] [receive] via NET/IB/1
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 00/0 : 9[1] -> 4[0] [send] via NET/IB/0
[rank9]:[E302 18:27:37.232790337 ProcessGroupNCCL.cpp:616] [Rank 9] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800069 milliseconds before timing out.
gpu-q-49:1203806:1204342 [3] NCCL INFO Channel 07/0 : 15[3] -> 13[1] via P2P/CUMEM/read
gpu-q-49:1203806:1204342 [3] NCCL INFO Connected all rings
gpu-q-49:1203806:1204342 [3] NCCL INFO Channel 03/0 : 11[3] -> 15[3] [receive] via NET/IB/1
gpu-q-49:1203806:1204342 [3] NCCL INFO Channel 07/0 : 7[3] -> 15[3] [receive] via NET/IB/1
gpu-q-49:1203806:1204342 [3] NCCL INFO Channel 07/0 : 15[3] -> 7[3] [send] via NET/IB/1
gpu-q-49:1203806:1204342 [3] NCCL INFO Channel 03/0 : 15[3] -> 11[3] [send] via NET/IB/1
gpu-q-49:1203806:1204342 [3] NCCL INFO Channel 02/0 : 15[3] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203806:1204342 [3] NCCL INFO Channel 06/0 : 15[3] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203806:1204342 [3] NCCL INFO Channel 00/0 : 15[3] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203806:1204342 [3] NCCL INFO Channel 01/0 : 15[3] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203806:1204342 [3] NCCL INFO Channel 02/0 : 15[3] -> 14[2] via P2P/CUMEM/read
[rank4]:[E302 18:27:37.936186855 ProcessGroupNCCL.cpp:616] [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800051 milliseconds before timing out.
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 01/0 : 9[1] -> 4[0] [send] via NET/IB/1
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 03/0 : 9[1] -> 7[3] [send] via NET/IB/1
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 00/0 : 9[1] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 01/0 : 9[1] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 02/0 : 9[1] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 04/0 : 9[1] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 05/0 : 9[1] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680340:2680856 [1] NCCL INFO Channel 06/0 : 9[1] -> 8[0] via P2P/CUMEM/read
gpu-q-35:2680340:2680856 [1] NCCL INFO Connected all trees
gpu-q-35:2680340:2680856 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-35:2680340:2680856 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
[rank10]:[E302 18:27:37.220949761 ProcessGroupNCCL.cpp:616] [Rank 10] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800057 milliseconds before timing out.
gpu-q-49:1203806:1204342 [3] NCCL INFO Channel 04/0 : 15[3] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203806:1204342 [3] NCCL INFO Channel 05/0 : 15[3] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203806:1204342 [3] NCCL INFO Channel 06/0 : 15[3] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203806:1204342 [3] NCCL INFO Connected all trees
gpu-q-49:1203806:1204342 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-49:1203806:1204342 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-49:1203806:1204342 [3] NCCL INFO ncclCommInitRank comm 0x5573a72ba180 rank 15 nranks 16 cudaDev 3 nvmlDev 3 busId c1000 commId 0xf5599d8a92473923 - Init COMPLETE
gpu-q-35:2680340:2680856 [1] NCCL INFO ncclCommInitRank comm 0x55f8ee334f70 rank 9 nranks 16 cudaDev 1 nvmlDev 1 busId 41000 commId 0xf5599d8a92473923 - Init COMPLETE
[rank11]:[E302 18:27:37.209369217 ProcessGroupNCCL.cpp:616] [Rank 11] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800040 milliseconds before timing out.
gpu-q-29:272945:273472 [0] NCCL INFO Channel 05/0 : 4[0] -> 0[0] [send] via NET/IB/1
gpu-q-29:272945:273472 [0] NCCL INFO Connected all trees
gpu-q-29:272945:273472 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-29:272945:273472 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-29:272945:273472 [0] NCCL INFO ncclCommInitRank comm 0x5586ea84d9c0 rank 4 nranks 16 cudaDev 0 nvmlDev 0 busId 1000 commId 0xf5599d8a92473923 - Init COMPLETE
[rank13]:[E302 18:27:37.959246377 ProcessGroupNCCL.cpp:616] [Rank 13] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800009 milliseconds before timing out.
gpu-q-49:1203804:1204156 [1] NCCL INFO ncclCommInitRank comm 0x557776b83ec0 rank 13 nranks 16 cudaDev 1 nvmlDev 1 busId 41000 commId 0xab369c58f444f4f9 - Init COMPLETE
gpu-q-49:1203804:1204309 [1] NCCL INFO Using non-device net plugin version 0
gpu-q-49:1203804:1204309 [1] NCCL INFO Using network IB
gpu-q-49:1203804:1204309 [1] NCCL INFO ncclCommInitRank comm 0x55777997e190 rank 13 nranks 16 cudaDev 1 nvmlDev 1 busId 41000 commId 0xf5599d8a92473923 - Init START
gpu-q-49:1203804:1204309 [1] NCCL INFO Setting affinity for GPU 1 to ffff0000
gpu-q-49:1203804:1204309 [1] NCCL INFO NVLS multicast support is not available on dev 1
gpu-q-49:1203804:1204309 [1] NCCL INFO comm 0x55777997e190 rank 13 nRanks 16 nNodes 4 localRanks 4 localRank 1 MNNVL 0
gpu-q-49:1203804:1204309 [1] NCCL INFO Trees [0] 14/-1/-1->13->12 [1] 14/-1/-1->13->12 [2] -1/-1/-1->13->12 [3] 14/-1/-1->13->15 [4] 14/-1/-1->13->12 [5] 14/-1/-1->13->12 [6] -1/-1/-1->13->12 [7] 14/-1/-1->13->15
[rank14]:[E302 18:27:37.959247559 ProcessGroupNCCL.cpp:616] [Rank 14] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800002 milliseconds before timing out.
gpu-q-35:2680341:2680857 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-35:2680341:2680857 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-35:2680341:2680857 [2] NCCL INFO ncclCommInitRank comm 0x557cce50ec90 rank 10 nranks 16 cudaDev 2 nvmlDev 2 busId 81000 commId 0xf5599d8a92473923 - Init COMPLETE
[rank5]:[E302 18:27:37.956159373 ProcessGroupNCCL.cpp:616] [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800070 milliseconds before timing out.
gpu-q-49:1203804:1204309 [1] NCCL INFO P2P Chunksize set to 131072
gpu-q-49:1203804:1204309 [1] NCCL INFO Channel 00/0 : 13[1] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203804:1204309 [1] NCCL INFO Channel 01/0 : 13[1] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203804:1204309 [1] NCCL INFO Channel 04/0 : 13[1] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203804:1204309 [1] NCCL INFO Channel 05/0 : 13[1] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203804:1204309 [1] NCCL INFO Channel 02/0 : 13[1] -> 2[2] [send] via NET/IB/0
gpu-q-49:1203804:1204309 [1] NCCL INFO Channel 03/0 : 13[1] -> 2[2] [send] via NET/IB/1
gpu-q-49:1203804:1204309 [1] NCCL INFO Channel 06/0 : 13[1] -> 2[2] [send] via NET/IB/0
gpu-q-49:1203804:1204309 [1] NCCL INFO Channel 07/0 : 13[1] -> 2[2] [send] via NET/IB/1
gpu-q-49:1203804:1204309 [1] NCCL INFO Connected all rings
gpu-q-49:1203804:1204309 [1] NCCL INFO Channel 03/0 : 13[1] -> 14[2] via P2P/CUMEM/read
gpu-q-49:1203804:1204309 [1] NCCL INFO Channel 07/0 : 13[1] -> 14[2] via P2P/CUMEM/read
[rank15]:[E302 18:27:37.970179715 ProcessGroupNCCL.cpp:616] [Rank 15] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800047 milliseconds before timing out.
gpu-q-29:272946:273305 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-29:272946:273305 [1] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gpu-q-29:272946:273305 [1] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gpu-q-29:272946:273305 [1] NCCL INFO ncclCommInitRank comm 0x5558aedaef00 rank 5 nranks 16 cudaDev 1 nvmlDev 1 busId 41000 commId 0xab369c58f444f4f9 - Init COMPLETE
gpu-q-29:272946:273471 [1] NCCL INFO Using non-device net plugin version 0
gpu-q-29:272946:273471 [1] NCCL INFO Using network IB
gpu-q-29:272946:273471 [1] NCCL INFO ncclCommInitRank comm 0x5558b1ba5b90 rank 5 nranks 16 cudaDev 1 nvmlDev 1 busId 41000 commId 0xf5599d8a92473923 - Init START
gpu-q-29:272946:273471 [1] NCCL INFO Setting affinity for GPU 1 to ffff0000
gpu-q-29:272946:273471 [1] NCCL INFO NVLS multicast support is not available on dev 1
[rank6]:[E302 18:27:37.968307449 ProcessGroupNCCL.cpp:616] [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800082 milliseconds before timing out.
gpu-q-49:1203804:1204309 [1] NCCL INFO Channel 03/0 : 13[1] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203804:1204309 [1] NCCL INFO Channel 07/0 : 13[1] -> 15[3] via P2P/CUMEM/read
gpu-q-49:1203804:1204309 [1] NCCL INFO Channel 00/0 : 13[1] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203804:1204309 [1] NCCL INFO Channel 01/0 : 13[1] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203804:1204309 [1] NCCL INFO Channel 02/0 : 13[1] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203804:1204309 [1] NCCL INFO Channel 04/0 : 13[1] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203804:1204309 [1] NCCL INFO Channel 05/0 : 13[1] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203804:1204309 [1] NCCL INFO Channel 06/0 : 13[1] -> 12[0] via P2P/CUMEM/read
gpu-q-49:1203804:1204309 [1] NCCL INFO Connected all trees
gpu-q-49:1203804:1204309 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-49:1203804:1204309 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-35:2680342:2680858 [3] NCCL INFO ncclCommInitRank comm 0x55d74830c8e0 rank 11 nranks 16 cudaDev 3 nvmlDev 3 busId c1000 commId 0xf5599d8a92473923 - Init COMPLETE
gpu-q-29:272946:273471 [1] NCCL INFO comm 0x5558b1ba5b90 rank 5 nRanks 16 nNodes 4 localRanks 4 localRank 1 MNNVL 0
gpu-q-29:272946:273471 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] -1/-1/-1->5->4 [3] 6/-1/-1->5->7 [4] 6/8/-1->5->4 [5] 6/8/-1->5->4 [6] -1/-1/-1->5->4 [7] 6/11/-1->5->7
gpu-q-29:272946:273471 [1] NCCL INFO P2P Chunksize set to 131072
gpu-q-29:272946:273471 [1] NCCL INFO Channel 00/0 : 5[1] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272946:273471 [1] NCCL INFO Channel 01/0 : 5[1] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272946:273471 [1] NCCL INFO Channel 04/0 : 5[1] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272946:273471 [1] NCCL INFO Channel 05/0 : 5[1] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272946:273471 [1] NCCL INFO Channel 02/0 : 5[1] -> 10[2] [send] via NET/IB/2
gpu-q-29:272946:273471 [1] NCCL INFO Channel 03/0 : 5[1] -> 10[2] [send] via NET/IB/0
gpu-q-29:272946:273471 [1] NCCL INFO Channel 06/0 : 5[1] -> 10[2] [send] via NET/IB/2
gpu-q-49:1203804:1204309 [1] NCCL INFO ncclCommInitRank comm 0x55777997e190 rank 13 nranks 16 cudaDev 1 nvmlDev 1 busId 41000 commId 0xf5599d8a92473923 - Init COMPLETE
gpu-q-29:272946:273471 [1] NCCL INFO Channel 07/0 : 5[1] -> 10[2] [send] via NET/IB/0
gpu-q-29:272946:273471 [1] NCCL INFO Connected all rings
gpu-q-29:272946:273471 [1] NCCL INFO Channel 03/0 : 5[1] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272946:273471 [1] NCCL INFO Channel 07/0 : 5[1] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272946:273471 [1] NCCL INFO Channel 03/0 : 5[1] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272946:273471 [1] NCCL INFO Channel 07/0 : 5[1] -> 7[3] via P2P/CUMEM/read
gpu-q-29:272946:273471 [1] NCCL INFO Channel 04/0 : 5[1] -> 8[0] [send] via NET/IB/0
gpu-q-29:272946:273471 [1] NCCL INFO Channel 05/0 : 5[1] -> 8[0] [send] via NET/IB/1
gpu-q-29:272946:273471 [1] NCCL INFO Channel 07/0 : 5[1] -> 11[3] [send] via NET/IB/0
gpu-q-29:272946:273471 [1] NCCL INFO Channel 07/0 : 11[3] -> 5[1] [receive] via NET/IB/0
gpu-q-29:272946:273471 [1] NCCL INFO Channel 04/0 : 8[0] -> 5[1] [receive] via NET/IB/0
gpu-q-29:272946:273471 [1] NCCL INFO Channel 05/0 : 8[0] -> 5[1] [receive] via NET/IB/1
[rank7]:[E302 18:27:37.933616606 ProcessGroupNCCL.cpp:616] [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800046 milliseconds before timing out.
gpu-q-29:272946:273471 [1] NCCL INFO Channel 00/0 : 5[1] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272946:273471 [1] NCCL INFO Channel 01/0 : 5[1] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272946:273471 [1] NCCL INFO Channel 02/0 : 5[1] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272946:273471 [1] NCCL INFO Channel 04/0 : 5[1] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272946:273471 [1] NCCL INFO Channel 05/0 : 5[1] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272946:273471 [1] NCCL INFO Channel 06/0 : 5[1] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272946:273471 [1] NCCL INFO Connected all trees
gpu-q-29:272946:273471 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-29:272946:273471 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-29:272946:273471 [1] NCCL INFO ncclCommInitRank comm 0x5558b1ba5b90 rank 5 nranks 16 cudaDev 1 nvmlDev 1 busId 41000 commId 0xf5599d8a92473923 - Init COMPLETE
gpu-q-29:272947:273469 [2] NCCL INFO ncclCommInitRank comm 0x5602fc98ca80 rank 6 nranks 16 cudaDev 2 nvmlDev 2 busId 81000 commId 0xf5599d8a92473923 - Init COMPLETE
gpu-q-29:272948:273308 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-29:272948:273308 [3] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gpu-q-29:272948:273308 [3] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gpu-q-29:272948:273308 [3] NCCL INFO ncclCommInitRank comm 0x558edf434400 rank 7 nranks 16 cudaDev 3 nvmlDev 3 busId c1000 commId 0xab369c58f444f4f9 - Init COMPLETE
gpu-q-29:272948:273470 [3] NCCL INFO Using non-device net plugin version 0
gpu-q-29:272948:273470 [3] NCCL INFO Using network IB
gpu-q-29:272948:273470 [3] NCCL INFO ncclCommInitRank comm 0x558ee2276e00 rank 7 nranks 16 cudaDev 3 nvmlDev 3 busId c1000 commId 0xf5599d8a92473923 - Init START
gpu-q-29:272948:273470 [3] NCCL INFO Setting affinity for GPU 3 to ffff0000,00000000,00000000
gpu-q-29:272948:273470 [3] NCCL INFO NVLS multicast support is not available on dev 3
gpu-q-29:272948:273470 [3] NCCL INFO comm 0x558ee2276e00 rank 7 nRanks 16 nNodes 4 localRanks 4 localRank 3 MNNVL 0
gpu-q-29:272948:273470 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] 4/-1/-1->7->6 [3] 5/-1/-1->7->9 [4] -1/-1/-1->7->6 [5] -1/-1/-1->7->6 [6] 4/10/-1->7->6 [7] 5/3/-1->7->15
gpu-q-29:272948:273470 [3] NCCL INFO P2P Chunksize set to 131072
gpu-q-29:272948:273470 [3] NCCL INFO Channel 00/0 : 7[3] -> 8[0] [send] via NET/IB/0
gpu-q-29:272948:273470 [3] NCCL INFO Channel 01/0 : 7[3] -> 8[0] [send] via NET/IB/1
gpu-q-29:272948:273470 [3] NCCL INFO Channel 04/0 : 7[3] -> 8[0] [send] via NET/IB/0
gpu-q-29:272948:273470 [3] NCCL INFO Channel 05/0 : 7[3] -> 8[0] [send] via NET/IB/1
gpu-q-29:272948:273470 [3] NCCL INFO Channel 02/0 : 7[3] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272948:273470 [3] NCCL INFO Channel 03/0 : 7[3] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272948:273470 [3] NCCL INFO Channel 06/0 : 7[3] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272948:273470 [3] NCCL INFO Channel 07/0 : 7[3] -> 5[1] via P2P/CUMEM/read
gpu-q-29:272948:273470 [3] NCCL INFO Connected all rings
gpu-q-29:272948:273470 [3] NCCL INFO Channel 03/0 : 7[3] -> 9[1] [send] via NET/IB/0
gpu-q-29:272948:273470 [3] NCCL INFO Channel 06/0 : 7[3] -> 10[2] [send] via NET/IB/2
gpu-q-29:272948:273470 [3] NCCL INFO Channel 07/0 : 3[3] -> 7[3] [receive] via NET/IB/0
gpu-q-29:272948:273470 [3] NCCL INFO Channel 07/0 : 15[3] -> 7[3] [receive] via NET/IB/0
gpu-q-29:272948:273470 [3] NCCL INFO Channel 07/0 : 7[3] -> 15[3] [send] via NET/IB/0
gpu-q-29:272948:273470 [3] NCCL INFO Channel 07/0 : 7[3] -> 3[3] [send] via NET/IB/0
gpu-q-29:272948:273470 [3] NCCL INFO Channel 06/0 : 10[2] -> 7[3] [receive] via NET/IB/2
gpu-q-29:272948:273470 [3] NCCL INFO Channel 02/0 : 7[3] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272948:273470 [3] NCCL INFO Channel 06/0 : 7[3] -> 4[0] via P2P/CUMEM/read
gpu-q-29:272948:273470 [3] NCCL INFO Channel 03/0 : 9[1] -> 7[3] [receive] via NET/IB/0
gpu-q-29:272948:273470 [3] NCCL INFO Channel 00/0 : 7[3] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272948:273470 [3] NCCL INFO Channel 01/0 : 7[3] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272948:273470 [3] NCCL INFO Channel 02/0 : 7[3] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272948:273470 [3] NCCL INFO Channel 04/0 : 7[3] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272948:273470 [3] NCCL INFO Channel 05/0 : 7[3] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272948:273470 [3] NCCL INFO Channel 06/0 : 7[3] -> 6[2] via P2P/CUMEM/read
gpu-q-29:272948:273470 [3] NCCL INFO Connected all trees
gpu-q-29:272948:273470 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-29:272948:273470 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-29:272948:273470 [3] NCCL INFO ncclCommInitRank comm 0x558ee2276e00 rank 7 nranks 16 cudaDev 3 nvmlDev 3 busId c1000 commId 0xf5599d8a92473923 - Init COMPLETE
[rank5]:[E302 18:27:38.436559404 ProcessGroupNCCL.cpp:1785] [PG ID 0 PG GUID 0(default_pg) Rank 5] Exception (either an error or timeout) detected by watchdog at work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank5]:[E302 18:27:38.436581626 ProcessGroupNCCL.cpp:1834] [PG ID 0 PG GUID 0(default_pg) Rank 5] Timeout at NCCL work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank5]:[E302 18:27:38.436589821 ProcessGroupNCCL.cpp:630] [Rank 5] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank5]:[E302 18:27:38.436595722 ProcessGroupNCCL.cpp:636] [Rank 5] To avoid data inconsistency, we are taking the entire process down.
[rank4]:[E302 18:27:38.436564162 ProcessGroupNCCL.cpp:1785] [PG ID 0 PG GUID 0(default_pg) Rank 4] Exception (either an error or timeout) detected by watchdog at work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank4]:[E302 18:27:38.436591524 ProcessGroupNCCL.cpp:1834] [PG ID 0 PG GUID 0(default_pg) Rank 4] Timeout at NCCL work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank4]:[E302 18:27:38.436601022 ProcessGroupNCCL.cpp:630] [Rank 4] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank4]:[E302 18:27:38.436608667 ProcessGroupNCCL.cpp:636] [Rank 4] To avoid data inconsistency, we are taking the entire process down.
[rank6]:[E302 18:27:38.436574312 ProcessGroupNCCL.cpp:1785] [PG ID 0 PG GUID 0(default_pg) Rank 6] Exception (either an error or timeout) detected by watchdog at work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank6]:[E302 18:27:38.436599990 ProcessGroupNCCL.cpp:1834] [PG ID 0 PG GUID 0(default_pg) Rank 6] Timeout at NCCL work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank6]:[E302 18:27:38.436608907 ProcessGroupNCCL.cpp:630] [Rank 6] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank6]:[E302 18:27:38.436616481 ProcessGroupNCCL.cpp:636] [Rank 6] To avoid data inconsistency, we are taking the entire process down.
[rank12]:[E302 18:27:38.469173873 ProcessGroupNCCL.cpp:1785] [PG ID 0 PG GUID 0(default_pg) Rank 12] Exception (either an error or timeout) detected by watchdog at work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank12]:[E302 18:27:38.469203880 ProcessGroupNCCL.cpp:1834] [PG ID 0 PG GUID 0(default_pg) Rank 12] Timeout at NCCL work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank12]:[E302 18:27:38.469211474 ProcessGroupNCCL.cpp:630] [Rank 12] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank12]:[E302 18:27:38.469216534 ProcessGroupNCCL.cpp:636] [Rank 12] To avoid data inconsistency, we are taking the entire process down.
[rank7]:[E302 18:27:38.436558472 ProcessGroupNCCL.cpp:1785] [PG ID 0 PG GUID 0(default_pg) Rank 7] Exception (either an error or timeout) detected by watchdog at work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank7]:[E302 18:27:38.436597035 ProcessGroupNCCL.cpp:1834] [PG ID 0 PG GUID 0(default_pg) Rank 7] Timeout at NCCL work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank7]:[E302 18:27:38.436605641 ProcessGroupNCCL.cpp:630] [Rank 7] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank7]:[E302 18:27:38.436621391 ProcessGroupNCCL.cpp:636] [Rank 7] To avoid data inconsistency, we are taking the entire process down.
[rank13]:[E302 18:27:38.469198880 ProcessGroupNCCL.cpp:1785] [PG ID 0 PG GUID 0(default_pg) Rank 13] Exception (either an error or timeout) detected by watchdog at work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank13]:[E302 18:27:38.469231903 ProcessGroupNCCL.cpp:1834] [PG ID 0 PG GUID 0(default_pg) Rank 13] Timeout at NCCL work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank13]:[E302 18:27:38.469243304 ProcessGroupNCCL.cpp:630] [Rank 13] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank13]:[E302 18:27:38.469250858 ProcessGroupNCCL.cpp:636] [Rank 13] To avoid data inconsistency, we are taking the entire process down.
[rank14]:[E302 18:27:38.469181928 ProcessGroupNCCL.cpp:1785] [PG ID 0 PG GUID 0(default_pg) Rank 14] Exception (either an error or timeout) detected by watchdog at work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank14]:[E302 18:27:38.469216925 ProcessGroupNCCL.cpp:1834] [PG ID 0 PG GUID 0(default_pg) Rank 14] Timeout at NCCL work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank14]:[E302 18:27:38.469227324 ProcessGroupNCCL.cpp:630] [Rank 14] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank14]:[E302 18:27:38.469233376 ProcessGroupNCCL.cpp:636] [Rank 14] To avoid data inconsistency, we are taking the entire process down.
[rank15]:[E302 18:27:38.469192829 ProcessGroupNCCL.cpp:1785] [PG ID 0 PG GUID 0(default_pg) Rank 15] Exception (either an error or timeout) detected by watchdog at work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank15]:[E302 18:27:38.469235820 ProcessGroupNCCL.cpp:1834] [PG ID 0 PG GUID 0(default_pg) Rank 15] Timeout at NCCL work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank15]:[E302 18:27:38.469246751 ProcessGroupNCCL.cpp:630] [Rank 15] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank15]:[E302 18:27:38.469253253 ProcessGroupNCCL.cpp:636] [Rank 15] To avoid data inconsistency, we are taking the entire process down.
[rank0]:[E302 18:27:38.531090216 ProcessGroupNCCL.cpp:1785] [PG ID 0 PG GUID 0(default_pg) Rank 0] Exception (either an error or timeout) detected by watchdog at work: 24549, last enqueued NCCL work: 24550, last completed NCCL work: 24548.
[rank0]:[E302 18:27:38.531111817 ProcessGroupNCCL.cpp:1834] [PG ID 0 PG GUID 0(default_pg) Rank 0] Timeout at NCCL work: 24549, last enqueued NCCL work: 24550, last completed NCCL work: 24548.
[rank0]:[E302 18:27:38.531118679 ProcessGroupNCCL.cpp:630] [Rank 0] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank0]:[E302 18:27:38.531124971 ProcessGroupNCCL.cpp:636] [Rank 0] To avoid data inconsistency, we are taking the entire process down.
gpu-q-9:206473:206998 [1] NCCL INFO Using network IB
gpu-q-9:206473:206998 [1] NCCL INFO ncclCommInitRank comm 0x5631f5c28f80 rank 1 nranks 16 cudaDev 1 nvmlDev 1 busId 41000 commId 0xf5599d8a92473923 - Init START
gpu-q-9:206473:206998 [1] NCCL INFO Setting affinity for GPU 1 to ffff0000
gpu-q-9:206473:206998 [1] NCCL INFO NVLS multicast support is not available on dev 1
gpu-q-9:206473:206998 [1] NCCL INFO comm 0x5631f5c28f80 rank 1 nRanks 16 nNodes 4 localRanks 4 localRank 1 MNNVL 0
gpu-q-9:206473:206998 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] 2/-1/-1->1->3 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] 2/-1/-1->1->3
gpu-q-9:206473:206998 [1] NCCL INFO P2P Chunksize set to 131072
gpu-q-9:206473:206998 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206473:206998 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206473:206998 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206473:206998 [1] NCCL INFO Channel 05/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206473:206998 [1] NCCL INFO Channel 02/0 : 1[1] -> 6[2] [send] via NET/IB/2
gpu-q-9:206473:206998 [1] NCCL INFO Channel 03/0 : 1[1] -> 6[2] [send] via NET/IB/0
gpu-q-9:206473:206998 [1] NCCL INFO Channel 06/0 : 1[1] -> 6[2] [send] via NET/IB/2
gpu-q-9:206473:206998 [1] NCCL INFO Channel 07/0 : 1[1] -> 6[2] [send] via NET/IB/0
gpu-q-9:206473:206998 [1] NCCL INFO Connected all rings
gpu-q-9:206473:206998 [1] NCCL INFO Channel 03/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206473:206998 [1] NCCL INFO Channel 07/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206473:206998 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206473:206998 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206473:206998 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206473:206998 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206473:206998 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206473:206998 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206473:206998 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206473:206998 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206473:206998 [1] NCCL INFO Connected all trees
gpu-q-9:206473:206998 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-9:206473:206998 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-9:206473:206998 [1] NCCL INFO ncclCommInitRank comm 0x5631f5c28f80 rank 1 nranks 16 cudaDev 1 nvmlDev 1 busId 41000 commId 0xf5599d8a92473923 - Init COMPLETE
[rank1]:[E302 18:27:38.544038723 ProcessGroupNCCL.cpp:616] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24548, OpType=ALLGATHER, NumelIn=32784, NumelOut=524544, Timeout(ms)=1800000) ran for 1800029 milliseconds before timing out.
[rank1]:[E302 18:27:38.544361153 ProcessGroupNCCL.cpp:1785] [PG ID 0 PG GUID 0(default_pg) Rank 1] Exception (either an error or timeout) detected by watchdog at work: 24548, last enqueued NCCL work: 24548, last completed NCCL work: 24547.
[rank1]:[E302 18:27:38.544372765 ProcessGroupNCCL.cpp:1834] [PG ID 0 PG GUID 0(default_pg) Rank 1] Timeout at NCCL work: 24548, last enqueued NCCL work: 24548, last completed NCCL work: 24547.
[rank1]:[E302 18:27:38.544378436 ProcessGroupNCCL.cpp:630] [Rank 1] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank1]:[E302 18:27:38.544384848 ProcessGroupNCCL.cpp:636] [Rank 1] To avoid data inconsistency, we are taking the entire process down.
[rank9]:[E302 18:27:38.746755994 ProcessGroupNCCL.cpp:1785] [PG ID 0 PG GUID 0(default_pg) Rank 9] Exception (either an error or timeout) detected by watchdog at work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank9]:[E302 18:27:38.746782263 ProcessGroupNCCL.cpp:1834] [PG ID 0 PG GUID 0(default_pg) Rank 9] Timeout at NCCL work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank9]:[E302 18:27:38.746789807 ProcessGroupNCCL.cpp:630] [Rank 9] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank9]:[E302 18:27:38.746795709 ProcessGroupNCCL.cpp:636] [Rank 9] To avoid data inconsistency, we are taking the entire process down.
[rank8]:[E302 18:27:38.746780309 ProcessGroupNCCL.cpp:1785] [PG ID 0 PG GUID 0(default_pg) Rank 8] Exception (either an error or timeout) detected by watchdog at work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank8]:[E302 18:27:38.746814554 ProcessGroupNCCL.cpp:1834] [PG ID 0 PG GUID 0(default_pg) Rank 8] Timeout at NCCL work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank8]:[E302 18:27:38.746822520 ProcessGroupNCCL.cpp:630] [Rank 8] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank8]:[E302 18:27:38.746847988 ProcessGroupNCCL.cpp:636] [Rank 8] To avoid data inconsistency, we are taking the entire process down.
[rank10]:[E302 18:27:38.746835133 ProcessGroupNCCL.cpp:1785] [PG ID 0 PG GUID 0(default_pg) Rank 10] Exception (either an error or timeout) detected by watchdog at work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank10]:[E302 18:27:38.746872334 ProcessGroupNCCL.cpp:1834] [PG ID 0 PG GUID 0(default_pg) Rank 10] Timeout at NCCL work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank10]:[E302 18:27:38.746883074 ProcessGroupNCCL.cpp:630] [Rank 10] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank10]:[E302 18:27:38.746892251 ProcessGroupNCCL.cpp:636] [Rank 10] To avoid data inconsistency, we are taking the entire process down.
[rank11]:[E302 18:27:38.746826808 ProcessGroupNCCL.cpp:1785] [PG ID 0 PG GUID 0(default_pg) Rank 11] Exception (either an error or timeout) detected by watchdog at work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank11]:[E302 18:27:38.746874197 ProcessGroupNCCL.cpp:1834] [PG ID 0 PG GUID 0(default_pg) Rank 11] Timeout at NCCL work: 24547, last enqueued NCCL work: 24547, last completed NCCL work: 24546.
[rank11]:[E302 18:27:38.746884627 ProcessGroupNCCL.cpp:630] [Rank 11] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank11]:[E302 18:27:38.746892893 ProcessGroupNCCL.cpp:636] [Rank 11] To avoid data inconsistency, we are taking the entire process down.
gpu-q-9:206474:206835 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-9:206474:206835 [2] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gpu-q-9:206474:206835 [2] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gpu-q-9:206474:206835 [2] NCCL INFO ncclCommInitRank comm 0x55d159a68f00 rank 2 nranks 16 cudaDev 2 nvmlDev 2 busId 81000 commId 0xab369c58f444f4f9 - Init COMPLETE
gpu-q-9:206474:206997 [2] NCCL INFO Using non-device net plugin version 0
gpu-q-9:206474:206997 [2] NCCL INFO Using network IB
gpu-q-9:206474:206997 [2] NCCL INFO ncclCommInitRank comm 0x55d15c861250 rank 2 nranks 16 cudaDev 2 nvmlDev 2 busId 81000 commId 0xf5599d8a92473923 - Init START
gpu-q-9:206474:206997 [2] NCCL INFO Setting affinity for GPU 2 to ffff0000,00000000,00000000,00000000
gpu-q-9:206474:206997 [2] NCCL INFO NVLS multicast support is not available on dev 2
gpu-q-9:206474:206997 [2] NCCL INFO comm 0x55d15c861250 rank 2 nRanks 16 nNodes 4 localRanks 4 localRank 2 MNNVL 0
gpu-q-9:206474:206997 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/10/-1->2->-1 [3] 0/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->6 [7] 0/-1/-1->2->1
gpu-q-9:206474:206997 [2] NCCL INFO P2P Chunksize set to 131072
gpu-q-9:206474:206997 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206474:206997 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206474:206997 [2] NCCL INFO Channel 04/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206474:206997 [2] NCCL INFO Channel 05/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206474:206997 [2] NCCL INFO Channel 02/0 : 13[1] -> 2[2] [receive] via NET/IB/2
gpu-q-9:206474:206997 [2] NCCL INFO Channel 03/0 : 13[1] -> 2[2] [receive] via NET/IB/0
gpu-q-9:206474:206997 [2] NCCL INFO Channel 06/0 : 13[1] -> 2[2] [receive] via NET/IB/2
gpu-q-9:206474:206997 [2] NCCL INFO Channel 07/0 : 13[1] -> 2[2] [receive] via NET/IB/0
gpu-q-9:206474:206997 [2] NCCL INFO Channel 02/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206474:206997 [2] NCCL INFO Channel 03/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206474:206997 [2] NCCL INFO Channel 06/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206474:206997 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206474:206997 [2] NCCL INFO Connected all rings
gpu-q-9:206474:206997 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206474:206997 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gpu-q-9:206474:206997 [2] NCCL INFO Channel 06/0 : 2[2] -> 6[2] [send] via NET/IB/2
gpu-q-9:206474:206997 [2] NCCL INFO Channel 02/0 : 10[2] -> 2[2] [receive] via NET/IB/2
gpu-q-9:206474:206997 [2] NCCL INFO Channel 02/0 : 2[2] -> 10[2] [send] via NET/IB/2
gpu-q-9:206474:206997 [2] NCCL INFO Channel 06/0 : 6[2] -> 2[2] [receive] via NET/IB/2
gpu-q-9:206474:206997 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206474:206997 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206474:206997 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206474:206997 [2] NCCL INFO Channel 04/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206474:206997 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206474:206997 [2] NCCL INFO Channel 07/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206474:206997 [2] NCCL INFO Connected all trees
gpu-q-9:206474:206997 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-9:206474:206997 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-9:206474:206997 [2] NCCL INFO ncclCommInitRank comm 0x55d15c861250 rank 2 nranks 16 cudaDev 2 nvmlDev 2 busId 81000 commId 0xf5599d8a92473923 - Init COMPLETE
[rank2]:[E302 18:27:38.556558909 ProcessGroupNCCL.cpp:616] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24548, OpType=ALLGATHER, NumelIn=32784, NumelOut=524544, Timeout(ms)=1800000) ran for 1800041 milliseconds before timing out.
[rank2]:[E302 18:27:38.556985556 ProcessGroupNCCL.cpp:1785] [PG ID 0 PG GUID 0(default_pg) Rank 2] Exception (either an error or timeout) detected by watchdog at work: 24548, last enqueued NCCL work: 24548, last completed NCCL work: 24547.
[rank2]:[E302 18:27:38.557020773 ProcessGroupNCCL.cpp:1834] [PG ID 0 PG GUID 0(default_pg) Rank 2] Timeout at NCCL work: 24548, last enqueued NCCL work: 24548, last completed NCCL work: 24547.
[rank2]:[E302 18:27:38.557027897 ProcessGroupNCCL.cpp:630] [Rank 2] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank2]:[E302 18:27:38.557036844 ProcessGroupNCCL.cpp:636] [Rank 2] To avoid data inconsistency, we are taking the entire process down.
gpu-q-9:206475:206833 [3] NCCL INFO ncclCommInitRank comm 0x55bcafb12ec0 rank 3 nranks 16 cudaDev 3 nvmlDev 3 busId c1000 commId 0xab369c58f444f4f9 - Init COMPLETE
gpu-q-9:206475:206996 [3] NCCL INFO Using non-device net plugin version 0
gpu-q-9:206475:206996 [3] NCCL INFO Using network IB
gpu-q-9:206475:206996 [3] NCCL INFO ncclCommInitRank comm 0x55bcb290da50 rank 3 nranks 16 cudaDev 3 nvmlDev 3 busId c1000 commId 0xf5599d8a92473923 - Init START
gpu-q-9:206475:206996 [3] NCCL INFO Setting affinity for GPU 3 to ffff0000,00000000,00000000
gpu-q-9:206475:206996 [3] NCCL INFO NVLS multicast support is not available on dev 3
gpu-q-9:206475:206996 [3] NCCL INFO comm 0x55bcb290da50 rank 3 nRanks 16 nNodes 4 localRanks 4 localRank 3 MNNVL 0
gpu-q-9:206475:206996 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] 0/-1/-1->3->2 [3] 1/11/-1->3->-1 [4] -1/-1/-1->3->2 [5] -1/-1/-1->3->2 [6] 0/-1/-1->3->2 [7] 1/-1/-1->3->7
gpu-q-9:206475:206996 [3] NCCL INFO P2P Chunksize set to 131072
gpu-q-9:206475:206996 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[0] [send] via NET/IB/0
gpu-q-9:206475:206996 [3] NCCL INFO Channel 01/0 : 3[3] -> 4[0] [send] via NET/IB/1
gpu-q-9:206475:206996 [3] NCCL INFO Channel 04/0 : 3[3] -> 4[0] [send] via NET/IB/0
gpu-q-9:206475:206996 [3] NCCL INFO Channel 05/0 : 3[3] -> 4[0] [send] via NET/IB/1
gpu-q-9:206475:206996 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206475:206996 [3] NCCL INFO Channel 03/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206475:206996 [3] NCCL INFO Channel 06/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206475:206996 [3] NCCL INFO Channel 07/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gpu-q-9:206475:206996 [3] NCCL INFO Connected all rings
gpu-q-9:206475:206996 [3] NCCL INFO Channel 07/0 : 3[3] -> 7[3] [send] via NET/IB/0
gpu-q-9:206475:206996 [3] NCCL INFO Channel 03/0 : 11[3] -> 3[3] [receive] via NET/IB/0
gpu-q-9:206475:206996 [3] NCCL INFO Channel 03/0 : 3[3] -> 11[3] [send] via NET/IB/0
gpu-q-9:206475:206996 [3] NCCL INFO Channel 07/0 : 7[3] -> 3[3] [receive] via NET/IB/0
gpu-q-9:206475:206996 [3] NCCL INFO Channel 02/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206475:206996 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gpu-q-9:206475:206996 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206475:206996 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206475:206996 [3] NCCL INFO Channel 02/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206475:206996 [3] NCCL INFO Channel 04/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206475:206996 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206475:206996 [3] NCCL INFO Channel 06/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gpu-q-9:206475:206996 [3] NCCL INFO Connected all trees
gpu-q-9:206475:206996 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
gpu-q-9:206475:206996 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
gpu-q-9:206475:206996 [3] NCCL INFO ncclCommInitRank comm 0x55bcb290da50 rank 3 nranks 16 cudaDev 3 nvmlDev 3 busId c1000 commId 0xf5599d8a92473923 - Init COMPLETE
[rank3]:[E302 18:27:38.591608172 ProcessGroupNCCL.cpp:616] [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24548, OpType=ALLGATHER, NumelIn=32784, NumelOut=524544, Timeout(ms)=1800000) ran for 1800076 milliseconds before timing out.
[rank3]:[E302 18:27:38.592189843 ProcessGroupNCCL.cpp:1785] [PG ID 0 PG GUID 0(default_pg) Rank 3] Exception (either an error or timeout) detected by watchdog at work: 24548, last enqueued NCCL work: 24548, last completed NCCL work: 24547.
[rank3]:[E302 18:27:38.592211073 ProcessGroupNCCL.cpp:1834] [PG ID 0 PG GUID 0(default_pg) Rank 3] Timeout at NCCL work: 24548, last enqueued NCCL work: 24548, last completed NCCL work: 24547.
[rank3]:[E302 18:27:38.592219078 ProcessGroupNCCL.cpp:630] [Rank 3] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank3]:[E302 18:27:38.592229728 ProcessGroupNCCL.cpp:636] [Rank 3] To avoid data inconsistency, we are taking the entire process down.
[rank5]:[E302 18:27:39.762802493 ProcessGroupNCCL.cpp:1595] [PG ID 0 PG GUID 0(default_pg) Rank 5] Process group watchdog thread terminated with exception: [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800070 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x152c39c5d446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x152c3af70772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x152c3af77bb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x152c3af7961d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x152d05b985c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x152d051001ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x152d045d18d3 in /lib64/libc.so.6)

[rank6]:[E302 18:27:39.762806891 ProcessGroupNCCL.cpp:1595] [PG ID 0 PG GUID 0(default_pg) Rank 6] Process group watchdog thread terminated with exception: [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800082 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x148243012446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x148244325772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x14824432cbb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x14824432e61d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x14830f04d5c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x14830e5b51ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x14830da868d3 in /lib64/libc.so.6)

[rank4]:[E302 18:27:39.762819756 ProcessGroupNCCL.cpp:1595] [PG ID 0 PG GUID 0(default_pg) Rank 4] Process group watchdog thread terminated with exception: [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800051 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x148f63a07446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x148f64d1a772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x148f64d21bb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x148f64d2361d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x14902f9425c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x14902eeaa1ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x14902e37b8d3 in /lib64/libc.so.6)

[rank7]:[E302 18:27:39.762825546 ProcessGroupNCCL.cpp:1595] [PG ID 0 PG GUID 0(default_pg) Rank 7] Process group watchdog thread terminated with exception: [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800046 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x155408378446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x15540968b772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x155409692bb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x15540969461d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x1554d43b35c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x1554d391b1ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x1554d2dec8d3 in /lib64/libc.so.6)

[rank14]:[E302 18:27:39.795742057 ProcessGroupNCCL.cpp:1595] [PG ID 0 PG GUID 0(default_pg) Rank 14] Process group watchdog thread terminated with exception: [Rank 14] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800002 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x149860676446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x149861989772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
terminate called after throwing an instance of 'c10::DistBackendError'
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x149861990bb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x14986199261d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x14992c6b15c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x14992bc191ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x14992b0ea8d3 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
[rank15]:[E302 18:27:39.795753348 ProcessGroupNCCL.cpp:1595] [PG ID 0 PG GUID 0(default_pg) Rank 15] Process group watchdog thread terminated with exception: [Rank 15] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800047 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x149c63081446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x149c64394772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
terminate called after throwing an instance of 'c10::DistBackendError'
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x149c6439bbb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x149c6439d61d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x149d2efbc5c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x149d2e5241ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x149d2d9f58d3 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
[rank12]:[E302 18:27:39.795754861 ProcessGroupNCCL.cpp:1595] [PG ID 0 PG GUID 0(default_pg) Rank 12] Process group watchdog thread terminated with exception: [Rank 12] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800054 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x15433e16f446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x15433f482772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x15433f489bb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x15433f48b61d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x15440a0895c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x1544096121ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x154408ae38d3 in /lib64/libc.so.6)

[rank13]:[E302 18:27:39.795765491 ProcessGroupNCCL.cpp:1595] [PG ID 0 PG GUID 0(default_pg) Rank 13] Process group watchdog thread terminated with exception: [Rank 13] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800009 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x150ebcdfc446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x150ebe10f772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x150ebe116bb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x150ebe11861d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x150f88e375c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x150f8839f1ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x150f878708d3 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
terminate called after throwing an instance of 'c10::DistBackendError'
terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG ID 0 PG GUID 0(default_pg) Rank 4] Process group watchdog thread terminated with exception: [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800051 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x148f63a07446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x148f64d1a772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
terminate called after throwing an instance of 'c10::DistBackendError'
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x148f64d21bb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x148f64d2361d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x14902f9425c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x14902eeaa1ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x14902e37b8d3 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1601 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x148f63a07446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
  what():  [PG ID 0 PG GUID 0(default_pg) Rank 12] Process group watchdog thread terminated with exception: [Rank 12] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800054 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x15433e16f446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x15433f482772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #1: <unknown function> + 0xe4271b (0x148f6499071b in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x145c0 (0x14902f9425c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0x81ca (0x14902eeaa1ca in /lib64/libpthread.so.0)
frame #4: clone + 0x43 (0x14902e37b8d3 in /lib64/libc.so.6)

Fatal Python error: Aborted

Thread 0x0000148ee429b700 (most recent call first):
  <no Python frame>

Thread 0x0000148f20734700 (most recent call first):
  <no Python frame>

Thread 0x0000148ec1bfd700 (most recent call first):
  <no Python frame>

Thread 0x0000148ec07f3700 (most recent call first):
  <no Python frame>

Thread 0x0000148eb17ff700 (most recent call first):
  File "/usr/lib64/python3.11/threading.py", line 331 in wait
  File "/usr/lib64/python3.11/threading.py", line 629 in wait
  what():  [PG ID 0 PG GUID 0(default_pg) Rank 5] Process group watchdog thread terminated with exception: [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800070 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x152c39c5d446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x152c3af70772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x152c3af77bb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x152c3af7961d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x152d05b985c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x152d051001ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x152d045d18d3 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1601 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x152c39c5d446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe4271b (0x152c3abe671b in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x145c0 (0x152d05b985c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0x81ca (0x152d051001ca in /lib64/libpthread.so.0)
frame #4: clone + 0x43 (0x152d045d18d3 in /lib64/libc.so.6)

Fatal Python error: Aborted

Thread 0x0000152b91bfd700 (most recent call first):
  <no Python frame>

Thread 0x0000152b90bf5700 (most recent call first):
  <no Python frame>

Thread 0x0000152b90df6700 (most recent call first):
  <no Python frame>

Thread 0x0000152b915fa700 (most recent call first):
  <no Python frame>

Thread 0x0000152b27bff700 (most recent call first):
  File "/usr/lib64/python3.11/threading.py", line 331 in wait
  File "/usr/lib64/python3.11/threading.py", line 629 in wait
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x15433f489bb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x15433f48b61d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x15440a0895c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x1544096121ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x154408ae38d3 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1601 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x15433e16f446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
  what():  [PG ID 0 PG GUID 0(default_pg) Rank 6] Process group watchdog thread terminated with exception: [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800082 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x148243012446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x148244325772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #1: <unknown function> + 0xe4271b (0x15433f0f871b in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x145c0 (0x15440a0895c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0x81ca (0x1544096121ca in /lib64/libpthread.so.0)
frame #4: clone + 0x43 (0x154408ae38d3 in /lib64/libc.so.6)

frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x14824432cbb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x14824432e61d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x14830f04d5c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x14830e5b51ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x14830da868d3 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1601 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x148243012446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
  what():  [PG ID 0 PG GUID 0(default_pg) Rank 13] Process group watchdog thread terminated with exception: [Rank 13] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800009 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x150ebcdfc446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x150ebe10f772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #1: <unknown function> + 0xe4271b (0x148243f9b71b in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x145c0 (0x14830f04d5c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0x81ca (0x14830e5b51ca in /lib64/libpthread.so.0)
frame #4: clone + 0x43 (0x14830da868d3 in /lib64/libc.so.6)

Fatal Python error: Aborted

Thread 0x00001481c4ef9700 (most recent call first):
  <no Python frame>

Thread 0x00001481c48f6700 (most recent call first):
  <no Python frame>

Thread 0x00001481c56fd700 (most recent call first):
  <no Python frame>

Thread 0x00001481c46f5700 (most recent call first):
  <no Python frame>

Thread 0x0000148136efd700 (most recent call first):
  File "/usr/lib64/python3.11/threading.py", line 331 in wait
  File "/usr/lib64/python3.11/threading.py", line 629 in wait
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x150ebe116bb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x150ebe11861d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x150f88e375c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x150f8839f1ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x150f878708d3 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1601 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x150ebcdfc446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/tqdm/_monitor.py", line 60 in run
  File "/usr/lib64/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/lib64/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x000014830f1c2200 (most recent call first):
frame #1: <unknown function> + 0xe4271b (0x150ebdd8571b in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x145c0 (0x150f88e375c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0x81ca (0x150f8839f1ca in /lib64/libpthread.so.0)
frame #4: clone + 0x43 (0x150f878708d3 in /lib64/libc.so.6)

  what():  [PG ID 0 PG GUID 0(default_pg) Rank 7] Process group watchdog thread terminated with exception: [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800046 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x155408378446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x15540968b772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
  what():  [PG ID 0 PG GUID 0(default_pg) Rank 14] Process group watchdog thread terminated with exception: [Rank 14] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800002 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x149860676446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x149861989772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x155409692bb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x15540969461d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x1554d43b35c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x1554d391b1ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x1554d2dec8d3 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1601 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x155408378446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x149861990bb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x14986199261d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x14992c6b15c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x14992bc191ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x14992b0ea8d3 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1601 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x149860676446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe4271b (0x15540930171b in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x145c0 (0x1554d43b35c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0x81ca (0x1554d391b1ca in /lib64/libpthread.so.0)
frame #4: clone + 0x43 (0x1554d2dec8d3 in /lib64/libc.so.6)

Fatal Python error: Aborted

Thread 0x0000155358206700 (most recent call first):
  <no Python frame>

Thread 0x00001553291f8700 (most recent call first):
  <no Python frame>

Thread 0x0000155358608700 (most recent call first):
  <no Python frame>

Thread 0x0000155329fff700 (most recent call first):
  <no Python frame>

Thread 0x00001553282f7700 (most recent call first):
  File "/usr/lib64/python3.11/threading.py", line 331 in wait
frame #1: <unknown function> + 0xe4271b (0x1498615ff71b in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x145c0 (0x14992c6b15c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0x81ca (0x14992bc191ca in /lib64/libpthread.so.0)
frame #4: clone + 0x43 (0x14992b0ea8d3 in /lib64/libc.so.6)

  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/tqdm/_monitor.py", line 60 in run
  File "/usr/lib64/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/lib64/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x000014902fab7200 (most recent call first):
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 4164 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/c10d_logger.py", line 83 in wrapper
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/strategies/ddp.py", line 160 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/fabric.py", line 541 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/src/evaluation/__init__.py", line 108 in run_evaluation
  what():  [PG ID 0 PG GUID 0(default_pg) Rank 15] Process group watchdog thread terminated with exception: [Rank 15] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800047 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x149c63081446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x149c64394772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 595 in _training_loop
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 305 in train
  File "/rds/user/yw580/hpc-work/relora-pico/scripts/train.py", line 25 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 788 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1443 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1082 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1161 in __call__
  File "<string>", line 1 in <module>
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x149c6439bbb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x149c6439d61d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x149d2efbc5c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x149d2e5241ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x149d2d9f58d3 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1601 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x149c63081446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/tqdm/_monitor.py", line 60 in run
  File "/usr/lib64/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/lib64/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x0000152d05d0d200 (most recent call first):
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 4164 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/c10d_logger.py", line 83 in wrapper
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/strategies/ddp.py", line 160 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/fabric.py", line 541 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/src/evaluation/__init__.py", line 108 in run_evaluation
frame #1: <unknown function> + 0xe4271b (0x149c6400a71b in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x145c0 (0x149d2efbc5c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0x81ca (0x149d2e5241ca in /lib64/libpthread.so.0)
frame #4: clone + 0x43 (0x149d2d9f58d3 in /lib64/libc.so.6)

Fatal Python error: Aborted

Thread 0x0000149bec98c700 (most recent call first):
  <no Python frame>

Thread 0x0000149c0e2fe700 (most recent call first):
  <no Python frame>

Thread 0x0000149becb8d700 (most recent call first):
  <no Python frame>
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 595 in _training_loop
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 305 in train
  File "/rds/user/yw580/hpc-work/relora-pico/scripts/train.py", line 25 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 788 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1443 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1082 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1161 in __call__
  File "<string>", line 1 in <module>
Fatal Python error: Aborted

Thread 0x00001542faac4700 (most recent call first):
  <no Python frame>

Thread 0x00001542be34d700 (most recent call first):
  <no Python frame>

Thread 0x000015428dbfd700 (most recent call first):
  <no Python frame>

Thread 0x000015428ddfe700 (most recent call first):
  <no Python frame>

Thread 0x000015428c3f7700 (most recent call first):
  File "/usr/lib64/python3.11/threading.py", line 331 in wait
  File "/usr/lib64/python3.11/threading.py", line 629 in wait
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/tqdm/_monitor.py", line 60 in run
  File "/usr/lib64/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/lib64/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x000015440a21f200 (most recent call first):
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 4164 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/c10d_logger.py", line 83 in wrapper
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/strategies/ddp.py", line 160 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/fabric.py", line 541 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/src/evaluation/__init__.py", line 108 in run_evaluation
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 595 in _training_loop
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 305 in train
  File "/rds/user/yw580/hpc-work/relora-pico/scripts/train.py", line 25 in main
Fatal Python error: Aborted

Thread 0x0000150e3c4f4700 (most recent call first):
  <no Python frame>

Thread 0x0000150e3ccf8700 (most recent call first):
  <no Python frame>

Thread 0x0000150e3d4fc700 (most recent call first):
  <no Python frame>

Thread 0x0000150e3c6f5700 (most recent call first):
  <no Python frame>

Thread 0x0000150e18ffd700 (most recent call first):
  File "/usr/lib64/python3.11/threading.py", line 331 in wait
  File "/usr/lib64/python3.11/threading.py", line 629 in wait
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/tqdm/_monitor.py", line 60 in run
  File "/usr/lib64/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/lib64/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x0000150f88fac200 (most recent call first):
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 4164 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 788 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1443 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1082 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1161 in __call__
  File "<string>", line 1 in <module>
Fatal Python error: Aborted

Thread 0x00001497866f8700 (most recent call first):
  <no Python frame>

Thread 0x00001497870fd700 (most recent call first):
  <no Python frame>

Thread 0x00001497868f9700 (most recent call first):
  <no Python frame>

Thread 0x00001497864f7700 (most recent call first):
  <no Python frame>

Thread 0x00001497849f0700 (most recent call first):
  File "/usr/lib64/python3.11/threading.py", line 331 in wait
  File "/usr/lib64/python3.11/threading.py", line 629 in wait
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/tqdm/_monitor.py", line 60 in run
  File "/usr/lib64/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/lib64/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x000014992c826200 (most recent call first):
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 4164 in barrier
  File "/usr/lib64/python3.11/threading.py", line 629 in wait
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/tqdm/_monitor.py", line 60 in run
  File "/usr/lib64/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/lib64/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x00001554d4528200 (most recent call first):
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 4164 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/c10d_logger.py", line 83 in wrapper
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/strategies/ddp.py", line 160 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/fabric.py", line 541 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/src/evaluation/__init__.py", line 108 in run_evaluation

Thread 0x0000149be59fc700 (most recent call first):
  <no Python frame>

Thread 0x0000149be48f9700 (most recent call first):
  File "/usr/lib64/python3.11/threading.py", line 331 in wait
  File "/usr/lib64/python3.11/threading.py", line 629 in wait
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/tqdm/_monitor.py", line 60 in run
  File "/usr/lib64/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/lib64/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x0000149d2f131200 (most recent call first):
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 4164 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/c10d_logger.py", line 83 in wrapper
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 595 in _training_loop
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 305 in train
  File "/rds/user/yw580/hpc-work/relora-pico/scripts/train.py", line 25 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 4164 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/c10d_logger.py", line 83 in wrapper
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/strategies/ddp.py", line 160 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/fabric.py", line 541 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/src/evaluation/__init__.py", line 108 in run_evaluation
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 595 in _training_loop
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 788 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1443 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/c10d_logger.py", line 83 in wrapper
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/strategies/ddp.py", line 160 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/fabric.py", line 541 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/src/evaluation/__init__.py", line 108 in run_evaluation
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 595 in _training_loop
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1082 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1161 in __call__
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/c10d_logger.py", line 83 in wrapper
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/strategies/ddp.py", line 160 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/fabric.py", line 541 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/src/evaluation/__init__.py", line 108 in run_evaluation
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 595 in _training_loop
  File "<string>", line 1 in <module>
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/strategies/ddp.py", line 160 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/fabric.py", line 541 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/src/evaluation/__init__.py", line 108 in run_evaluation
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 595 in _training_loop
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 305 in train

  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 305 in train
  File "/rds/user/yw580/hpc-work/relora-pico/scripts/train.py", line 25 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 788 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1443 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1082 in main

  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 305 in train
  File "/rds/user/yw580/hpc-work/relora-pico/scripts/train.py", line 25 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 788 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1443 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1082 in main

  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 305 in train
  File "/rds/user/yw580/hpc-work/relora-pico/scripts/train.py", line 25 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 788 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1443 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1082 in main

  File "/rds/user/yw580/hpc-work/relora-pico/scripts/train.py", line 25 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 788 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1443 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1082 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1161 in __call__
  File "<string>", line 1 in <module>
Extension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, PIL._imaging, kiwisolver._cext, regex._regex, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, markupsafe._speedups, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.p  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1161 in __call__
  File "<string>", line 1 in <module>
Extension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, PIL._imaging, kiwisolver._cext, regex._regex, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, markupsafe._speedups, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.p  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1161 in __call__
  File "<string>", line 1 in <module>
Extension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, PIL._imaging, kiwisolver._cext, regex._regex, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, markupsafe._speedups, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.p  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1161 in __call__
  File "<string>", line 1 in <module>
roperties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, xxhash._xxhash, pyarro
w._json, google._upb._message, psutil._psutil_linux, psutil._psutil_posix, msgpack._cmsgpack (total: 92)

roperties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, xxhash._xxhash, pyarro
roperties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, xxhash._xxhash, pyarro
Extension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, PIL._imaging, kiwisolver._cext, regex._regex, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, markupsafe._speedups, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.pExtension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, PIL._imaging, kiwisolver._cext, regex._regex, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, markupsafe._speedups, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.pw._json, google._upb._message, psutil._psutil_linux, psutil._psutil_posix, msgpack._cmsgpack (total: 92)
Extension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, PIL._imaging, kiwisolver._cext, regex._regex, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, markupsafe._speedups, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.pw._json, google._upb._message, psutil._psutil_linux, psutil._psutil_posix, msgpack._cmsgpack (total: 92)
Extension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, PIL._imaging, kiwisolver._cext, regex._regex, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, markupsafe._speedups, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, xxhash._xxhash, pyarroExtension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, PIL._imaging, kiwisolver._cext, regex._regex, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, markupsafe._speedups, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, xxhash._xxhash, pyarrow._json, google._upb._message, psutil._psutil_linux, psutil._psutil_posix, msgpack._cmsgpack (total: 92)
roperties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, xxhash._xxhash, pyarrow._json, google._upb._message, psutil._psutil_linux, psutil._psutil_posix, msgpack._cmsgpack (total: 92)
w._json, google._upb._message, psutil._psutil_linux, psutil._psutil_posix, msgpack._cmsgpack (total: 92)
roperties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, xxhash._xxhash, pyarrow._json, google._upb._message, psutil._psutil_linux, psutil._psutil_posix, msgpack._cmsgpack (total: 92)
roperties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, xxhash._xxhash, pyarrow._json, google._upb._message, psutil._psutil_linux, psutil._psutil_posix, msgpack._cmsgpack (total: 92)
[rank0]:[E302 18:27:39.863104118 ProcessGroupNCCL.cpp:1595] [PG ID 0 PG GUID 0(default_pg) Rank 0] Process group watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24549, OpType=ALLREDUCE, NumelIn=20, NumelOut=20, Timeout(ms)=1800000) ran for 1800088 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14f3afa63446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x14f3b0d76772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x14f3b0d7dbb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x14f3b0d7f61d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x14f47b99e5c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x14f47af061ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x14f47a3d78d3 in /lib64/libc.so.6)

[rank1]:[E302 18:27:39.863108647 ProcessGroupNCCL.cpp:1595] [PG ID 0 PG GUID 0(default_pg) Rank 1] Process group watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24548, OpType=ALLGATHER, NumelIn=32784, NumelOut=524544, Timeout(ms)=1800000) ran for 1800029 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14d6124b0446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x14d6137c3772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x14d6137cabb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x14d6137cc61d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x14d6de4eb5c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x14d6dda531ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x14d6dcf248d3 in /lib64/libc.so.6)

[rank8]:[E302 18:27:39.062401512 ProcessGroupNCCL.cpp:1595] [PG ID 0 PG GUID 0(default_pg) Rank 8] Process group watchdog thread terminated with exception: [Rank 8] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800011 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14a31385f446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x14a314b72772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
[rank2]:[E302 18:27:39.863114387 ProcessGroupNCCL.cpp:1595] [PG ID 0 PG GUID 0(default_pg) Rank 2] Process group watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24548, OpType=ALLGATHER, NumelIn=32784, NumelOut=524544, Timeout(ms)=1800000) ran for 1800041 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x149302904446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x149303c17772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x14a314b79bb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x14a314b7b61d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x14a3df79a5c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x14a3ded021ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x14a3de1d38d3 in /lib64/libc.so.6)

frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x149303c1ebb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x149303c2061d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x1493ce93f5c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x1493cdea71ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x1493cd3788d3 in /lib64/libc.so.6)

[rank9]:[E302 18:27:39.062424656 ProcessGroupNCCL.cpp:1595] [PG ID 0 PG GUID 0(default_pg) Rank 9] Process group watchdog thread terminated with exception: [Rank 9] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800069 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14746779e446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x147468ab1772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
[rank3]:[E302 18:27:39.863131330 ProcessGroupNCCL.cpp:1595] [PG ID 0 PG GUID 0(default_pg) Rank 3] Process group watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24548, OpType=ALLGATHER, NumelIn=32784, NumelOut=524544, Timeout(ms)=1800000) ran for 1800076 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14b813bf2446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x14b814f05772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x147468ab8bb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x147468aba61d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x1475337d95c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x147532d411ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x1475322128d3 in /lib64/libc.so.6)

frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x14b814f0cbb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x14b814f0e61d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x14b8dfc2d5c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x14b8df1951ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x14b8de6668d3 in /lib64/libc.so.6)

[rank10]:[E302 18:27:39.062469590 ProcessGroupNCCL.cpp:1595] [PG ID 0 PG GUID 0(default_pg) Rank 10] Process group watchdog thread terminated with exception: [Rank 10] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800057 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x153c902fd446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x153c91610772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
terminate called after throwing an instance of 'c10::DistBackendError'
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x153c91617bb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x153c9161961d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x153d5c2385c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x153d5b7a01ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x153d5ac718d3 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
[rank11]:[E302 18:27:39.062453470 ProcessGroupNCCL.cpp:1595] [PG ID 0 PG GUID 0(default_pg) Rank 11] Process group watchdog thread terminated with exception: [Rank 11] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800040 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14741502a446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x14741633d772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
terminate called after throwing an instance of 'c10::DistBackendError'
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x147416344bb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x14741634661d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x1474e10655c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x1474e05cd1ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x1474dfa9e8d3 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG ID 0 PG GUID 0(default_pg) Rank 0] Process group watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24549, OpType=ALLREDUCE, NumelIn=20, NumelOut=20, Timeout(ms)=1800000) ran for 1800088 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14f3afa63446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x14f3b0d76772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
terminate called after throwing an instance of 'c10::DistBackendError'
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x14f3b0d7dbb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x14f3b0d7f61d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x14f47b99e5c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x14f47af061ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x14f47a3d78d3 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1601 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14f3afa63446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
terminate called after throwing an instance of 'c10::DistBackendError'
frame #1: <unknown function> + 0xe4271b (0x14f3b09ec71b in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x145c0 (0x14f47b99e5c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0x81ca (0x14f47af061ca in /lib64/libpthread.so.0)
frame #4: clone + 0x43 (0x14f47a3d78d3 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG ID 0 PG GUID 0(default_pg) Rank 1] Process group watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24548, OpType=ALLGATHER, NumelIn=32784, NumelOut=524544, Timeout(ms)=1800000) ran for 1800029 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14d6124b0446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x14d6137c3772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
  what():  [PG ID 0 PG GUID 0(default_pg) Rank 8] Process group watchdog thread terminated with exception: [Rank 8] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800011 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14a31385f446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x14a314b72772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x14d6137cabb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x14d6137cc61d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x14d6de4eb5c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x14d6dda531ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x14d6dcf248d3 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1601 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14d6124b0446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x14a314b79bb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x14a314b7b61d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x14a3df79a5c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x14a3ded021ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x14a3de1d38d3 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1601 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14a31385f446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe4271b (0x14d61343971b in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x145c0 (0x14d6de4eb5c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0x81ca (0x14d6dda531ca in /lib64/libpthread.so.0)
frame #4: clone + 0x43 (0x14d6dcf248d3 in /lib64/libc.so.6)

Fatal Python error: Aborted

Thread 0x000014d5bd8fa700 (most recent call first):
frame #1: <unknown function> + 0xe4271b (0x14a3147e871b in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x145c0 (0x14a3df79a5c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0x81ca (0x14a3ded021ca in /lib64/libpthread.so.0)
frame #4: clone + 0x43 (0x14a3de1d38d3 in /lib64/libc.so.6)

Fatal Python error: Aborted

Thread 0x000014f168de7700 (most recent call first):
  <no Python frame>

Thread 0x000014f168be6700 (most recent call first):
  <no Python frame>

Thread 0x000014f168fe8700 (most recent call first):
  <no Python frame>

Thread 0x000014f1691e9700 (most recent call first):
  <no Python frame>

Thread 0x000014f2cc9fb700 (most recent call first):
  File "/usr/lib64/python3.11/threading.py", line 331 in wait
  File "/usr/lib64/python3.11/threading.py", line 629 in wait
Fatal Python error: Aborted

Thread 0x000014a271dfe700 (most recent call first):
  <no Python frame>

Thread 0x000014a2715fa700 (most recent call first):
  <no Python frame>

Thread 0x000014a2709f4700 (most recent call first):
  <no Python frame>

Thread 0x000014a29459c700 (most recent call first):
  <no Python frame>

Thread 0x000014a2698ff700 (most recent call first):
  <no Python frame>

Thread 0x000014d5613f9700 (most recent call first):
  <no Python frame>

Thread 0x000014d5619fc700 (most recent call first):
  <no Python frame>

Thread 0x000014d570afc700 (most recent call first):
  <no Python frame>

Thread 0x000014d5605f8700 (most recent call first):
  File "/usr/lib64/python3.11/threading.py", line 331 in wait
  File "/usr/lib64/python3.11/threading.py", line 331 in wait
  File "/usr/lib64/python3.11/threading.py", line 629 in wait
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/tqdm/_monitor.py", line 60 in run
  File "/usr/lib64/python3.11/threading.py", line 1045 in _bootstrap_inner
  what():  [PG ID 0 PG GUID 0(default_pg) Rank 2] Process group watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24548, OpType=ALLGATHER, NumelIn=32784, NumelOut=524544, Timeout(ms)=1800000) ran for 1800041 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x149302904446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x149303c17772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
  what():  [PG ID 0 PG GUID 0(default_pg) Rank 9] Process group watchdog thread terminated with exception: [Rank 9] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800069 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14746779e446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x147468ab1772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x149303c1ebb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x149303c2061d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x1493ce93f5c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x1493cdea71ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x1493cd3788d3 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1601 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x149302904446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x147468ab8bb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x147468aba61d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x1475337d95c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x147532d411ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x1475322128d3 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1601 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14746779e446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe4271b (0x14930388d71b in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x145c0 (0x1493ce93f5c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0x81ca (0x1493cdea71ca in /lib64/libpthread.so.0)
frame #4: clone + 0x43 (0x1493cd3788d3 in /lib64/libc.so.6)

Fatal Python error: Aborted

Thread 0x00001492295fa700 (most recent call first):
  <no Python frame>

Thread 0x0000149284bfb700 (most recent call first):
  <no Python frame>

Thread 0x00001492845f8700 (most recent call first):
  <no Python frame>

Thread 0x00001492851fe700 (most recent call first):
  <no Python frame>

Thread 0x00001492288f9700 (most recent call first):
frame #1: <unknown function> + 0xe4271b (0x14746872771b in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x145c0 (0x1475337d95c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0x81ca (0x147532d411ca in /lib64/libpthread.so.0)
frame #4: clone + 0x43 (0x1475322128d3 in /lib64/libc.so.6)

Fatal Python error: Aborted

Thread 0x000014738cdf6700 (most recent call first):
  <no Python frame>

Thread 0x000014738d9fc700 (most recent call first):
  <no Python frame>

Thread 0x000014738d7fb700 (most recent call first):
  <no Python frame>

  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 263 in _loop_check_status
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 325 in check_internal_messages
  File "/usr/lib64/python3.11/threading.py", line 982 in run
  File "/usr/lib64/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/lib64/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x000014f2ccbfc700 (most recent call first):
  File "/usr/lib64/python3.11/threading.py", line 331 in wait
  File "/usr/lib64/python3.11/threading.py", line 629 in wait
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/wandb/sdk/lib/mailbox.py", line 122 in _wait
  File "/usr/lib64/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x000014a3df90f200 (most recent call first):
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 4164 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/c10d_logger.py", line 83 in wrapper
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/strategies/ddp.py", line 160 in barrier
  File "/usr/lib64/python3.11/threading.py", line 629 in wait
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/tqdm/_monitor.py", line 60 in run
  File "/usr/lib64/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/lib64/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x000014d6de660200 (most recent call first):
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 465 in _training_loop
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 305 in train
  File "/rds/user/yw580/hpc-work/relora-pico/scripts/train.py", line 25 in main
Thread 0x000014738dfff700 (most recent call first):
  <no Python frame>

Thread 0x000014734f8ff700 (most recent call first):
  File "/usr/lib64/python3.11/threading.py", line 331 in wait
  File "/usr/lib64/python3.11/threading.py", line 629 in wait
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/tqdm/_monitor.py", line 60 in run
  File "/usr/lib64/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/lib64/python3.11/threading.py", line 331 in wait
  File "/usr/lib64/python3.11/threading.py", line 629 in wait
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/tqdm/_monitor.py", line 60 in run
  File "/usr/lib64/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/lib64/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x00001493ceab4200 (most recent call first):
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 465 in _training_loop
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 305 in train
  File "/rds/user/yw580/hpc-work/relora-pico/scripts/train.py", line 25 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/fabric.py", line 541 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/src/evaluation/__init__.py", line 108 in run_evaluation
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/wandb/sdk/lib/mailbox.py", line 126 in _get_and_clear
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/wandb/sdk/lib/mailbox.py", line 279 in wait
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 243 in _loop_check_status
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 281 in check_network_status
  File "/usr/lib64/python3.11/threading.py", line 982 in run
  File "/usr/lib64/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/lib64/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x000014f2ccdfd700 (most recent call first):
  File "/usr/lib64/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x000014753394e200 (most recent call first):
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 788 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1443 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1082 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1161 in __call__
  File "<string>", line 1 in <module>
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 595 in _training_loop
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 305 in train
  File "/rds/user/yw580/hpc-work/relora-pico/scripts/train.py", line 25 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 788 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 788 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1443 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1082 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1161 in __call__
  File "<string>", line 1 in <module>
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 4164 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/c10d_logger.py", line 83 in wrapper
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/strategies/ddp.py", line 160 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/fabric.py", line 541 in barrier
  File "/usr/lib64/python3.11/threading.py", line 331 in wait
  File "/usr/lib64/python3.11/threading.py", line 629 in wait
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 263 in _loop_check_status
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 305 in check_stop_status
  File "/usr/lib64/python3.11/threading.py", line 982 in run
  File "/usr/lib64/python3.11/threading.py", line 1045 in _bootstrap_inner
  what():  [PG ID 0 PG GUID 0(default_pg) Rank 11] Process group watchdog thread terminated with exception: [Rank 11] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800040 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14741502a446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x14741633d772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
  what():  [PG ID 0 PG GUID 0(default_pg) Rank 3] Process group watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24548, OpType=ALLGATHER, NumelIn=32784, NumelOut=524544, Timeout(ms)=1800000) ran for 1800076 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14b813bf2446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x14b814f05772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x147416344bb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x14741634661d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x1474e10655c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x1474e05cd1ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x1474dfa9e8d3 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1601 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14741502a446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x14b814f0cbb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x14b814f0e61d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x14b8dfc2d5c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x14b8df1951ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x14b8de6668d3 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1601 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14b813bf2446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe4271b (0x147415fb371b in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x145c0 (0x1474e10655c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0x81ca (0x1474e05cd1ca in /lib64/libpthread.so.0)
frame #4: clone + 0x43 (0x1474dfa9e8d3 in /lib64/libc.so.6)

frame #1: <unknown function> + 0xe4271b (0x14b814b7b71b in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x145c0 (0x14b8dfc2d5c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0x81ca (0x14b8df1951ca in /lib64/libpthread.so.0)
frame #4: clone + 0x43 (0x14b8de6668d3 in /lib64/libc.so.6)

  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1443 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1082 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1161 in __call__
  File "<string>", line 1 in <module>
  File "/usr/lib64/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x000014f2cdfff700 (most recent call first):
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 256 in _read_packet_bytes
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 285 in read_server_response
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/wandb/sdk/interface/router_sock.py", line 27 in _read_message
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/wandb/sdk/interface/router.py", line 68 in message_loop
  File "/usr/lib64/python3.11/threading.py", line 982 in run
  File "/usr/lib64/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/rds/user/yw580/hpc-work/relora-pico/src/evaluation/__init__.py", line 108 in run_evaluation
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 595 in _training_loop
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 305 in train
  File "/rds/user/yw580/hpc-work/relora-pico/scripts/train.py", line 25 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 788 in invoke
Fatal Python error: Aborted

Thread 0x000014b7bcf1d700 (most recent call first):
  <no Python frame>

Thread 0x000014b771dfe700 (most recent call first):
  <no Python frame>

Thread 0x000014b770bf5700 (most recent call first):
Fatal Python error: Aborted

Thread 0x00001473959fe700 (most recent call first):
  <no Python frame>

Thread 0x00001473947f5700 (most recent call first):
  <no Python frame>

  File "/usr/lib64/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x000014f330748700 (most recent call first):
  File "/usr/lib64/python3.11/threading.py", line 331 in wait
  File "/usr/lib64/python3.11/threading.py", line 629 in wait
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1443 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1082 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1161 in __call__
  <no Python frame>

Thread 0x000014b7719fc700 (most recent call first):
  <no Python frame>

Thread 0x000014b761bff700 (most recent call first):
  File "/usr/lib64/python3.11/threading.py", line 331 in wait
Thread 0x00001473949f6700 (most recent call first):
  <no Python frame>

Thread 0x00001473d0581700 (most recent call first):
  <no Python frame>

Thread 0x0000147370ffd700 (most recent call first):
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/tqdm/_monitor.py", line 60 in run
  File "/usr/lib64/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/lib64/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x000014f304bfb700 (most recent call first):
  File "<string>", line 1 in <module>
  File "/usr/lib64/python3.11/threading.py", line 629 in wait
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/tqdm/_monitor.py", line 60 in run
  File "/usr/lib64/python3.11/threading.py", line 331 in wait
  File "/usr/lib64/python3.11/threading.py", line 629 in wait
  File "/usr/lib64/python3.11/threading.py", line 331 in wait
  File "/usr/lib64/python3.11/threading.py", line 629 in wait
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/tqdm/_monitor.py", line 60 in run
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/tqdm/_monitor.py", line 60 in run
  File "/usr/lib64/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/lib64/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/lib64/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x000014b8dfda2200 (most recent call first):
  File "/usr/lib64/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x00001474e11da200 (most recent call first):
  File "/usr/lib64/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/lib64/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x000014f47bb13200 (most recent call first):
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/deepspeed/runtime/engine.py", line 3136 in _checkpoint_tag_validation
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 4164 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 465 in _training_loop
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 305 in train
  File "/rds/user/yw580/hpc-work/relora-pico/scripts/train.py", line 25 in main

  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/deepspeed/runtime/engine.py", line 3183 in save_checkpoint
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/strategies/deepspeed.py", line 449 in save_checkpoint
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/fabric.py", line 741 in save
  what():  [PG ID 0 PG GUID 0(default_pg) Rank 10] Process group watchdog thread terminated with exception: [Rank 10] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=24547, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800057 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x153c902fd446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x153c91610772 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)

frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x153c91617bb3 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x153c9161961d in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x153d5c2385c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x81ca (0x153d5b7a01ca in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x153d5ac718d3 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1601 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x153c902fd446 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libc10.so)
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 788 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1443 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1082 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1161 in __call__
frame #1: <unknown function> + 0xe4271b (0x153c9128671b in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x145c0 (0x153d5c2385c0 in /rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0x81ca (0x153d5b7a01ca in /lib64/libpthread.so.0)
frame #4: clone + 0x43 (0x153d5ac718d3 in /lib64/libc.so.6)

Fatal Python error: Aborted

  File "/rds/user/yw580/hpc-work/relora-pico/src/checkpointing/training.py", line 204 in save_checkpoint
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/utils/io.py", line 37 in wrapper
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 584 in _training_loop
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 305 in train
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/c10d_logger.py", line 83 in wrapper
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/strategies/ddp.py", line 160 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/fabric.py", line 541 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/src/evaluation/__init__.py", line 108 in run_evaluation
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 595 in _training_loop
  File "<string>", line 1 in <module>
Thread 0x0000153b977fb700 (most recent call first):
  <no Python frame>

Thread 0x0000153bb4a0a700 (most recent call first):
  <no Python frame>

Thread 0x0000153bb4608700 (most recent call first):
  <no Python frame>

Thread 0x0000153b97fff700 (most recent call first):
  <no Python frame>

Thread 0x0000153b963f7700 (most recent call first):
  File "/usr/lib64/python3.11/threading.py", line 331 in wait
  File "/rds/user/yw580/hpc-work/relora-pico/scripts/train.py", line 25 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 788 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1443 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1082 in main
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 305 in train
  File "/rds/user/yw580/hpc-work/relora-pico/scripts/train.py", line 25 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 788 in invoke

  File "/usr/lib64/python3.11/threading.py", line 629 in wait
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/tqdm/_monitor.py", line 60 in run
  File "/usr/lib64/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/lib64/python3.11/threading.py", line 1002 in _bootstrap

  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1161 in __call__
  File "<string>", line 1 in <module>
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1443 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1082 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1161 in __call__
  File "<string>", line 1 in <module>


Thread 0x0000153d5c3ad200 (most recent call first):
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/distributed_c10d.py", line 4164 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib64/python3.11/site-packages/torch/distributed/c10d_logger.py", line 83 in wrapper
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/strategies/ddp.py", line 160 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/lightning/fabric/fabric.py", line 541 in barrier
  File "/rds/user/yw580/hpc-work/relora-pico/src/evaluation/__init__.py", line 108 in run_evaluation
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 595 in _training_loop
  File "/rds/user/yw580/hpc-work/relora-pico/src/training/trainer.py", line 305 in train
  File "/rds/user/yw580/hpc-work/relora-pico/scripts/train.py", line 25 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 788 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1443 in invoke
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1082 in main
  File "/rds/user/yw580/hpc-work/relora-pico/.venv/lib/python3.11/site-packages/click/core.py", line 1161 in __call__
  File "<string>", line 1 in <module>


Extension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, PIL._imaging, kiwisolver._cext, regex._regex, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, markupsafe._speedups, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.pExtension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, PIL._imaging, kiwisolver._cext, regex._regex, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, markupsafe._speedups, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, xxhash._xxhash, pyarroroperties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, xxhash._xxhash, pyarrow._json, google._upb._message, psutil._psutil_linux, psutil._psutil_posix, msgpack._cmsgpack (total: 92)
Extension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, PIL._imaging, kiwisolver._cext, regex._regex, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, markupsafe._speedups, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.pw._json, google._upb._message, psutil._psutil_linux, psutil._psutil_posix, msgpack._cmsgpack (total: 92)
Extension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, PIL._imaging, kiwisolver._cext, regex._regex, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, markupsafe._speedups, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, xxhash._xxhash, pyarrow._json, google._upb._message, psutil._psutil_linux, psutil._psutil_posix, msgpack._cmsgpack (total: 92)
roperties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, xxhash._xxhash, pyarrow._json, google._upb._message, psutil._psutil_linux, psutil._psutil_posix, msgpack._cmsgpack (total: 92)

Extension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, PIL._imaging, kiwisolver._cext, regex._regex, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, markupsafe._speedups, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.pExtension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, PIL._imaging, kiwisolver._cext, regex._regex, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, markupsafe._speedups, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.pExtension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, PIL._imaging, kiwisolver._cext, regex._regex, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, markupsafe._speedups, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, xxhash._xxhash, pyarroroperties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, xxhash._xxhash, pyarrow._json, google._upb._message, psutil._psutil_linux, psutil._psutil_posix, msgpack._cmsgpack (total: 92)
w._json, google._upb._message, psutil._psutil_linux, psutil._psutil_posix, msgpack._cmsgpack (total: 92)
Extension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, PIL._imaging, kiwisolver._cext, regex._regex, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, markupsafe._speedups, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, xxhash._xxhash, pyarrow._json, google._upb._message, psutil._psutil_linux, psutil._psutil_posix, msgpack._cmsgpack (total: 92)
roperties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, xxhash._xxhash, pyarrow._json, google._upb._message, psutil._psutil_linux, psutil._psutil_posix, msgpack._cmsgpack (total: 92)
srun: error: gpu-q-49: tasks 12-15: Aborted
srun: error: gpu-q-29: tasks 4-7: Aborted
srun: error: gpu-q-35: tasks 8-11: Aborted
srun: error: gpu-q-9: tasks 0-3: Aborted
